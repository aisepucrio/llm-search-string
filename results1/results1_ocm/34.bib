@inproceedings{10.1145/3358960.3379137,
author = {Alves Pereira, Juliana and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc},
title = {Sampling Effect on Performance Prediction of Configurable Systems: A Case Study},
year = {2020},
isbn = {9781450369916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358960.3379137},
doi = {10.1145/3358960.3379137},
abstract = {Numerous software systems are highly configurable and provide a myriad of configuration options that users can tune to fit their functional and performance requirements (e.g., execution time). Measuring all configurations of a system is the most obvious way to understand the effect of options and their interactions, but is too costly or infeasible in practice. Numerous works thus propose to measure only a few configurations (a sample) to learn and predict the performance of any combination of options' values. A challenging issue is to sample a small and representative set of configurations that leads to a good accuracy of performance prediction models. A recent study devised a new algorithm, called distance-based sampling, that obtains state-of-the-art accurate performance predictions on different subject systems. In this paper, we replicate this study through an in-depth analysis of x264, a popular and configurable video encoder. We systematically measure all 1,152 configurations of x264 with 17 input videos and two quantitative properties (encoding time and encoding size). Our goal is to understand whether there is a dominant sampling strategy over the very same subject system (x264), i.e., whatever the workload and targeted performance properties. The findings from this study show that random sampling leads to more accurate performance models. However, without considering random, there is no single "dominant" sampling, instead different strategies perform best on different inputs and non-functional properties, further challenging practitioners and researchers.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {277–288},
numpages = {12},
keywords = {software product lines, performance prediction, machine learning, configurable systems},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1145/3611643.3616334,
author = {Gong, Jingzhi and Chen, Tao},
title = {Predicting Software Performance with Divide-and-Learn},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616334},
doi = {10.1145/3611643.3616334},
abstract = {Predicting the performance of highly configurable software systems is the foundation for performance testing and quality assurance. To that end, recent work has been relying on machine/deep learning to model software performance. However, a crucial yet unaddressed challenge is how to cater for the sparsity inherited from the configuration landscape: the influence of configuration options (features) and the distribution of data samples are highly sparse. In this paper, we propose an approach based on the concept of “divide-and-learn”, dubbed DaL. The basic idea is that, to handle sample sparsity, we divide the samples from the configuration landscape into distant divisions, for each of which we build a regularized Deep Neural Network as the local model to deal with the feature sparsity. A newly given configuration would then be assigned to the right model of division for the final prediction. Experiment results from eight real-world systems and five sets of training data reveal that, compared with the state-of-the-art approaches, DaL performs no worse than the best counterpart on 33 out of 40 cases (within which 26 cases are significantly better) with up to 1.94\texttimes{} improvement on accuracy; requires fewer samples to reach the same/better accuracy; and producing acceptable training overhead. Practically, DaL also considerably improves different global models when using them as the underlying local models, which further strengthens its flexibility. To promote open science, all the data, code, and supplementary figures of this work can be accessed at our repository: https://github.com/ideas-labo/DaL.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {858–870},
numpages = {13},
keywords = {Configurable System, Configuration Learning, Deep Learning, Machine Learning, Performance Learning, Performance Prediction},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1109/ASE.2015.45,
author = {Sarkar, Atri and Guo, Jianmei and Siegmund, Norbert and Apel, Sven and Czarnecki, Krzysztof},
title = {Cost-efficient sampling for performance prediction of configurable systems},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.45},
doi = {10.1109/ASE.2015.45},
abstract = {A key challenge of the development and maintenance of configurable systems is to predict the performance of individual system variants based on the features selected. It is usually infeasible to measure the performance of all possible variants, due to feature combinatorics. Previous approaches predict performance based on small samples of measured variants, but it is still open how to dynamically determine an ideal sample that balances prediction accuracy and measurement effort. In this paper, we adapt two widely-used sampling strategies for performance prediction to the domain of configurable systems and evaluate them in terms of sampling cost, which considers prediction accuracy and measurement effort simultaneously. To generate an initial sample, we introduce a new heuristic based on feature frequencies and compare it to a traditional method based on t-way feature coverage. We conduct experiments on six real-world systems and provide guidelines for stakeholders to predict performance by sampling.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {342–352},
numpages = {11},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@inproceedings{10.1145/3236024.3236074,
author = {Jamshidi, Pooyan and Velez, Miguel and K\"{a}stner, Christian and Siegmund, Norbert},
title = {Learning to sample: exploiting similarities across environments to learn performance models for configurable systems},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236074},
doi = {10.1145/3236024.3236074},
abstract = {Most software systems provide options that allow users to tailor the system in terms of functionality and qualities. The increased flexibility raises challenges for understanding the configuration space and the effects of options and their interactions on performance and other non-functional properties. To identify how options and interactions affect the performance of a system, several sampling and learning strategies have been recently proposed. However, existing approaches usually assume a fixed environment (hardware, workload, software release) such that learning has to be repeated once the environment changes. Repeating learning and measurement for each environment is expensive and often practically infeasible. Instead, we pursue a strategy that transfers knowledge across environments but sidesteps heavyweight and expensive transfer-learning strategies. Based on empirical insights about common relationships regarding (i) influential options, (ii) their interactions, and (iii) their performance distributions, our approach, L2S (Learning to Sample), selects better samples in the target environment based on information from the source environment. It progressively shrinks and adaptively concentrates on interesting regions of the configuration space. With both synthetic benchmarks and several real systems, we demonstrate that L2S outperforms state of the art performance learning and transfer-learning approaches in terms of measurement effort and learning accuracy.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {71–82},
numpages = {12},
keywords = {transfer learning, configurable systems, Software performance},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {regularization, configurable systems, adversarial learning, Software performance prediction},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1145/3324884.3416573,
author = {M\"{u}hlbauer, Stefan and Apel, Sven and Siegmund, Norbert},
title = {Identifying software performance changes across variants and versions},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416573},
doi = {10.1145/3324884.3416573},
abstract = {We address the problem of identifying performance changes in the evolution of configurable software systems. Finding optimal configurations and configuration options that influence performance is already difficult, but in the light of software evolution, configuration-dependent performance changes may lurk in a potentially large number of different versions of the system.In this work, we combine two perspectives---variability and time---into a novel perspective. We propose an approach to identify configuration-dependent performance changes retrospectively across the software variants and versions of a software system. In a nutshell, we iteratively sample pairs of configurations and versions and measure the respective performance, which we use to update a model of likelihoods for performance changes. Pursuing a search strategy with the goal of measuring selectively and incrementally further pairs, we increase the accuracy of identified change points related to configuration options and interactions.We have conducted a number of experiments both on controlled synthetic data sets as well as in real-world scenarios with different software systems. Our evaluation demonstrates that we can pinpoint performance shifts to individual configuration options and interactions as well as commits introducing change points with high accuracy and at scale. Experiments on three real-world systems explore the effectiveness and practicality of our approach.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {611–622},
numpages = {12},
keywords = {active learning, configurable software systems, machine learning, software evolution, software performance},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3238147.3238201,
author = {Mukelabai, Mukelabai and Ne\v{s}i\'{c}, Damir and Maro, Salome and Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp},
title = {Tackling combinatorial explosion: a study of industrial needs and practices for analyzing highly configurable systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238201},
doi = {10.1145/3238147.3238201},
abstract = {Highly configurable systems are complex pieces of software. To tackle this complexity, hundreds of dedicated analysis techniques have been conceived, many of which able to analyze system properties for all possible system configurations, as opposed to traditional, single-system analyses. Unfortunately, it is largely unknown whether these techniques are adopted in practice, whether they address actual needs, or what strategies practitioners actually apply to analyze highly configurable systems. We present a study of analysis practices and needs in industry. It relied on a survey with 27 practitioners engineering highly configurable systems and follow-up interviews with 15 of them, covering 18 different companies from eight countries. We confirm that typical properties considered in the literature (e.g., reliability) are relevant, that consistency between variability models and artifacts is critical, but that the majority of analyses for specifications of configuration options (a.k.a., variability model analysis) is not perceived as needed. We identified rather pragmatic analysis strategies, including practices to avoid the need for analysis. For instance, testing with experience-based sampling is the most commonly applied strategy, while systematic sampling is rarely applicable. We discuss analyses that are missing and synthesize our insights into suggestions for future research.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {155–166},
numpages = {12},
keywords = {Product Lines, Highly Configurable Systems, Analysis},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1145/3450264,
author = {Chennupati, Gopinath and Santhi, Nandakishore and Romero, Phill and Eidenbenz, Stephan},
title = {Machine Learning–enabled Scalable Performance Prediction of Scientific Codes},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {1049-3301},
url = {https://doi.org/10.1145/3450264},
doi = {10.1145/3450264},
abstract = {Hardware architectures become increasingly complex as the compute capabilities grow to exascale. We present the Analytical Memory Model with Pipelines (AMMP) of the Performance Prediction Toolkit (PPT). PPT-AMMP takes high-level source code and hardware architecture parameters as input and predicts runtime of that code on the target hardware platform, which is defined in the input parameters. PPT-AMMP transforms the code to an (architecture-independent) intermediate representation, then (i) analyzes the basic block structure of the code, (ii) processes architecture-independent virtual memory access patterns that it uses to build memory reuse distance distribution models for each basic block, and (iii) runs detailed basic-block level simulations to determine hardware pipeline usage.PPT-AMMP uses machine learning and regression techniques to build the prediction models based on small instances of the input code, then integrates into a higher-order discrete-event simulation model of PPT running on Simian PDES engine. We validate PPT-AMMP on four standard computational physics benchmarks and present a use case of hardware parameter sensitivity analysis to identify bottleneck hardware resources on different code inputs. We further extend PPT-AMMP to predict the performance of a scientific application code, namely, the radiation transport mini-app SNAP. To this end, we analyze multi-variate regression models that accurately predict the reuse profiles and the basic block counts. We validate predicted SNAP runtimes against actual measured times.},
journal = {ACM Trans. Model. Comput. Simul.},
month = apr,
articleno = {11},
numpages = {28},
keywords = {symbolic regression, performance modeling, genetic programming, deep learning, Performance modeling}
}

@inproceedings{10.1145/3316480.3325518,
author = {Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
title = {Scalable Performance Prediction of Codes with Memory Hierarchy and Pipelines},
year = {2019},
isbn = {9781450367233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316480.3325518},
doi = {10.1145/3316480.3325518},
abstract = {We present the Analytical Memory Model with Pipelines (AMMP) of the Performance Prediction Toolkit (PPT). PPT-AMMP takes high-level source code and hardware architecture parameters as input, predicts runtime of that code on the target hardware platform, which is defined in the input parameters. PPT-AMMP transforms the code to an (architecture-independent) intermediate representation, then (i) analyzes the basic block structure of the code, (ii) processes architecture-independent virtual memory access patterns that it uses to build memory reuse distance distribution models for each basic block, (iii) runs detailed basic-block level simulations to determine hardware pipeline usage. Further, PPT-AMMP uses machine learning and regression techniques to build the prediction models based on small instances of the input code, then integrates into a higher-order discrete-event simulation model of PPT running on Simian PDES engine. We validate PPT-AMMP on four standard computational physics benchmarks, finally present a use case of hardware parameter sensitivity analysis to identify bottleneck hardware resources on different code inputs.},
booktitle = {Proceedings of the 2019 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {13–24},
numpages = {12},
keywords = {simulation, program analysis, pipeline, performance prediction, performance modeling, co-design, analytical modeling},
location = {Chicago, IL, USA},
series = {SIGSIM-PADS '19}
}

@inproceedings{10.1109/PACT.2019.00042,
author = {Zhu, Gangyi and Jiang, Peng and Agrawal, Gagan},
title = {A Methodology for Characterizing Sparse Datasets and Its Application to SIMD Performance Prediction},
year = {2024},
isbn = {9781728136134},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/PACT.2019.00042},
doi = {10.1109/PACT.2019.00042},
abstract = {Irregular computations are commonly seen in many scientific and engineering domains that use unstructured meshes or sparse matrices. The performance of an irregular application is very dependent upon the dataset. This paper poses the following question: "given an unstructured mesh or a graph, what method(s) can be used to sample it, such that the execution on the resulting sampled dataset can accurately reflect performance characteristics on the full dataset". Our first insight is that developing a universal sampling approach for all sparse matrices is unpractical. According to the non-zero distribution of the sparse matrix, we propose two novel sampling strategies: Stride Average sampling and Random Tile sampling, which are suitable for uniform and skewed sparse matrices respectively. To help categorize a sparse matrix as uniform or skewed, we introduce clustering coefficient as an important feature which can be propagated into the decision tree model. We also adapt Random Node Neighbor sampling approach for efficient estimation of clustering coefficient.We apply our unstructured dataset characterization approach to modeling the performance for SIMD irregular applications, where the sampled dataset obtained is used to predict cache miss rate and SIMD utilization ratio. We also build analytical models to estimate overheads incurred by load imbalance among threads. With knowledge of these factors, we adapt a code skeleton framework SKOPE to capture the workload behaviors and aggregate performance statistics for execution time prediction.},
booktitle = {Proceedings of the International Conference on Parallel Architectures and Compilation Techniques},
pages = {444–455},
numpages = {12},
location = {Seattle, WA, USA},
series = {PACT '19}
}

@inproceedings{10.1145/3030207.3030216,
author = {Valov, Pavel and Petkovich, Jean-Christophe and Guo, Jianmei and Fischmeister, Sebastian and Czarnecki, Krzysztof},
title = {Transferring Performance Prediction Models Across Different Hardware Platforms},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3030216},
doi = {10.1145/3030207.3030216},
abstract = {Many software systems provide configuration options relevant to users, which are often called features. Features influence functional properties of software systems as well as non-functional ones, such as performance and memory consumption. Researchers have successfully demonstrated the correlation between feature selection and performance. However, the generality of these performance models across different hardware platforms has not yet been evaluated.We propose a technique for enhancing generality of performance models across different hardware environments using linear transformation. Empirical studies on three real-world software systems show that our approach is computationally efficient and can achieve high accuracy (less than 10% mean relative error) when predicting system performance across 23 different hardware platforms. Moreover, we investigate why the approach works by comparing performance distributions of systems and structure of performance models across different platforms.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {39–50},
numpages = {12},
keywords = {regression trees, performance modelling, model transfer, linear transformation},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3660317.3660322,
author = {Schmid, Larissa and Sa\u{g}lam, Timur and Selzer, Michael and Koziolek, Anne},
title = {Cost-Efficient Construction of Performance Models},
year = {2024},
isbn = {9798400706455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660317.3660322},
doi = {10.1145/3660317.3660322},
abstract = {Modern high-performance applications are highly-configurable systems that provide hundreds of configuration options. Performance models offer insights into the performance of these applications and help users understand the impact of these options. Yet, crafting models for such applications proves costly due to the many configuration options and their unknown performance impacts that need to be modeled. However, some options are performance-irrelevant, and removing them can reduce construction costs without compromising accuracy. This paper explores an approach to automatically identify performance-irrelevant configuration options empirically. By leveraging established performance modeling methods, we devise cost-efficient preliminary prediction models that rely on fewer samples and analyze them to identify such options. We evaluate our approach using a real-world HPC application to demonstrate our method's effectiveness in recognizing performance-irrelevant options and the potential to save costs for performance modeling.},
booktitle = {Proceedings of the 4th Workshop on Performance EngineeRing, Modelling, Analysis, and VisualizatiOn STrategy},
pages = {1–7},
numpages = {7},
keywords = {automatic performance modeling, empirical performance modeling, configurable systems, sampling},
location = {Pisa, Italy},
series = {PERMAVOST '24}
}

@article{10.1145/3702986,
author = {Gong, Jingzhi and Chen, Tao},
title = {Deep Configuration Performance Learning: A Systematic Survey and Taxonomy},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3702986},
doi = {10.1145/3702986},
abstract = {Performance is arguably the most crucial attribute that reflects the quality of a configurable software system. However, given the increasing scale and complexity of modern software, modeling and predicting how various configurations can impact performance becomes one of the major challenges in software maintenance. As such, performance is often modeled without having a thorough knowledge of the software system, but relying mainly on data, which fits precisely with the purpose of deep learning. In this article, we conduct a comprehensive review exclusively on the topic of deep learning for performance learning of configurable software, covering 1,206 searched papers spanning six indexing services, based on which 99 primary papers were extracted and analyzed. Our results outline key statistics, taxonomy, strengths, weaknesses, and optimal usage scenarios for techniques related to the preparation of configuration data, the construction of deep learning performance models, the evaluation of these models, and their utilization in various software configuration-related tasks. We also identify the good practices and potentially problematic phenomena from the studies surveyed, together with a comprehensive summary of actionable suggestions and insights into future opportunities within the field. To promote open science, all the raw results of this survey can be accessed at our repository: .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {25},
numpages = {62},
keywords = {Configuration Performance, Deep Learning, Configurable Software, Performance Modeling, Performance Prediction, Software Engineering}
}

@inproceedings{10.1145/2188286.2188295,
author = {Faber, Michael and Happe, Jens},
title = {Systematic adoption of genetic programming for deriving software performance curves},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188295},
doi = {10.1145/2188286.2188295},
abstract = {Measurement-based approaches to software performance engineering apply analysis methods (e.g., statistical inference or machine learning) on raw measurement data with the goal to build a mathematical model describing the performance-relevant behavior of a system under test (SUT). The main challenge for such approaches is to find a reasonable trade-off between minimizing the amount of necessary measurement data used to build the model and maximizing the model's accuracy. Most existing methods require prior knowledge about parameter dependencies or their models are limited to only linear correlations. In this paper, we investigate the applicability of genetic programming (GP) to derive a mathematical equation expressing the performance behavior of the measured system (software performance curve). We systematically optimized the parameters of the GP algorithm to derive accurate software performance curves and applied techniques to prevent overfitting. We conducted an evaluation with a representative MySQL database system. The results clearly show that the GP algorithm outperforms other analysis techniques like inverse distance weighting (IDW) and multivariate adaptive regression splines (MARS) in terms of model accuracy.},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {33–44},
numpages = {12},
keywords = {software performance engineering, model inference, machine learning, black-box approach},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@inproceedings{10.1145/3358960.3379127,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Transferring Pareto Frontiers across Heterogeneous Hardware Environments},
year = {2020},
isbn = {9781450369916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358960.3379127},
doi = {10.1145/3358960.3379127},
abstract = {Software systems provide user-relevant configuration options called features. Features affect functional and non-functional system properties, whereas selections of features represent system configurations. A subset of configuration space forms a Pareto frontier of optimal configurations in terms of multiple properties, from which a user can choose the best configuration for a particular scenario. However, when a well-studied system is redeployed on a different hardware, information about property value and the Pareto frontier might not apply. We investigate whether it is possible to transfer this information across heterogeneous hardware environments. We propose a methodology for approximating and transferring Pareto frontiers of configurable systems across different hardware environments. We approximate a Pareto frontier by training an individual predictor model for each system property, and by aggregating predictions of each property into an approximated frontier. We transfer the approximated frontier across hardware by training a transfer model for each property, by applying it to a respective predictor, and by combining transferred properties into a frontier. We evaluate our approach by modeling Pareto frontiers as binary classifiers that separate all system configurations into optimal and non-optimal ones. Thus we can assess quality of approximated and transferred frontiers using common statistical measures like sensitivity and specificity. We test our approach using five real-world software systems from the compression domain, while paying special attention to their performance. Evaluation results demonstrate that accuracy of approximated frontiers depends linearly on predictors' training sample sizes, whereas transferring introduces only minor additional error to a frontier even for small training sizes.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {12–23},
numpages = {12},
keywords = {regression trees, performance prediction, linear regression, configurable software, Pareto frontier transferring, Pareto frontier},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1145/3503229.3547026,
author = {Friesel, Birte and Elmenhorst, Kathrin and Kaiser, Lennart and M\"{u}ller, Michael and Spinczyk, Olaf},
title = {kconfig-webconf: retrofitting performance models onto kconfig-based software product lines},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547026},
doi = {10.1145/3503229.3547026},
abstract = {Despite decades of research and clear advantages, performance-aware configuration of real-world software product lines is still an exception rather than the norm. One reason for this may be tooling: configuration software with support for non-functional property models is generally not compatible with the configuration and build process of existing product lines. Specifically, the Kconfig language is popular in open source software projects, but neither language nor configuration frontends support performance models. To address this, we present kconfig-webconf: a performance-aware, Kconfig-compatible software product line configuration frontend. It is part of a toolchain that can automatically generate performance models with a minimal amount of changes to a software product line's build process. With such a performance model, kconfig-webconf can serve as a performance-aware drop-in replacement for existing Kconfig frontends. We evaluate its usage in five examples, including the busybox multi-call binary and the resKIL agricultural AI product line.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {58–61},
numpages = {4},
keywords = {kconfig, performance prediction, product lines, regression trees},
location = {Graz, Austria},
series = {SPLC '22}
}

@article{10.1145/3280986,
author = {Rhein, Alexander Von and Liebig, J\"{o}RG and Janker, Andreas and K\"{a}stner, Christian and Apel, Sven},
title = {Variability-Aware Static Analysis at Scale: An Empirical Study},
year = {2018},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3280986},
doi = {10.1145/3280986},
abstract = {The advent of variability management and generator technology enables users to derive individual system variants from a configurable code base by selecting desired configuration options. This approach gives rise to the generation of possibly billions of variants, which, however, cannot be efficiently analyzed for bugs and other properties with classic analysis techniques. To address this issue, researchers and practitioners have developed sampling heuristics and, recently, variability-aware analysis techniques. While sampling reduces the analysis effort significantly, the information obtained is necessarily incomplete, and it is unknown whether state-of-the-art sampling techniques scale to billions of variants. Variability-aware analysis techniques process the configurable code base directly, exploiting similarities among individual variants with the goal of reducing analysis effort. However, while being promising, so far, variability-aware analysis techniques have been applied mostly only to small academic examples. To learn about the mutual strengths and weaknesses of variability-aware and sample-based static-analysis techniques, we compared the two by means of seven concrete control-flow and data-flow analyses, applied to five real-world subject systems: Busybox, OpenSSL, SQLite, the x86 Linux kernel, and uClibc. In particular, we compare the efficiency (analysis execution time) of the static analyses and their effectiveness (potential bugs found). Overall, we found that variability-aware analysis outperforms most sample-based static-analysis techniques with respect to efficiency and effectiveness. For example, checking all variants of OpenSSL with a variability-aware static analysis is faster than checking even only two variants with an analysis that does not exploit similarities among variants.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {18},
numpages = {33},
keywords = {variability-aware analysis, configuration sampling, TypeChef, Highly configurable systems}
}

@inproceedings{10.1109/ICSE48619.2023.00176,
author = {M\"{u}hlbauer, Stefan and Sattler, Florian and Kaltenecker, Christian and Dorn, Johannes and Apel, Sven and Siegmund, Norbert},
title = {Analyzing the Impact of Workloads on Modeling the Performance of Configurable Software Systems},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00176},
doi = {10.1109/ICSE48619.2023.00176},
abstract = {Modern software systems often exhibit numerous configuration options to tailor them to user requirements, including the system's performance behavior. Performance models derived via machine learning are an established approach for estimating and optimizing configuration-dependent software performance. Most existing approaches in this area rely on software performance measurements conducted with a single workload (i.e., input fed to a system). This single workload, however, is often not representative of a software system's real-world application scenarios. Understanding to what extent configuration and workload---individually and combined---cause a software system's performance to vary is key to understand whether performance models are generalizable across different configurations and workloads. Yet, so far, this aspect has not been systematically studied.To fill this gap, we conducted a systematic empirical study across 25 258 configurations from nine real-world configurable software systems to investigate the effects of workload variation at system-level performance and for individual configuration options. We explore driving causes for workload-configuration interactions by enriching performance observations with option-specific code coverage information.Our results demonstrate that workloads can induce substantial performance variation and interact with configuration options, often in non-monotonous ways. This limits not only the generaliz-ability of single-workload models, but also challenges assumptions for existing transfer-learning techniques. As a result, workloads should be considered when building performance prediction models to maintain and improve representativeness and reliability.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2085–2097},
numpages = {13},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3324884.3416620,
author = {Dorn, Johannes and Apel, Sven and Siegmund, Norbert},
title = {Mastering uncertainty in performance estimations of configurable software systems},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416620},
doi = {10.1145/3324884.3416620},
abstract = {Understanding the influence of configuration options on performance is key for finding optimal system configurations, system understanding, and performance debugging. In prior research, a number of performance-influence modeling approaches have been proposed, which model a configuration option's influence and a configuration's performance as a scalar value. However, these point estimates falsely imply a certainty regarding an option's influence that neglects several sources of uncertainty within the assessment process, such as (1) measurement bias, (2) model representation and learning process, and (3) incomplete data. This leads to the situation that different approaches and even different learning runs assign different scalar performance values to options and interactions among them. The true influence is uncertain, though. There is no way to quantify this uncertainty with state-of-the-art performance modeling approaches. We propose a novel approach, P4, based on probabilistic programming that explicitly models uncertainty for option influences and consequently provides a confidence interval for each prediction of a configuration's performance alongside a scalar. This way, we can explain, for the first time, why predictions may cause errors and which option's influences may be unreliable. An evaluation on 12 real-world subject systems shows that P4's accuracy is in line with the state of the art while providing reliable confidence intervals, in addition to scalar predictions.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {684–696},
numpages = {13},
keywords = {P4, configurable software systems, performance-influence modeling, probabilistic programming},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1109/ICSE-NIER.2019.00028,
author = {Trubiani, Catia and Apel, Sven},
title = {PLUS: performance learning for uncertainty of software},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00028},
doi = {10.1109/ICSE-NIER.2019.00028},
abstract = {Uncertainty is particularly critical in software performance engineering when it relates to the values of important parameters such as workload, operational profile, and resource demand, because such parameters inevitably affect the overall system performance. Prior work focused on monitoring the performance characteristics of software systems while considering influence of configuration options. The problem of incorporating uncertainty as a first-class concept in the software development process to identify performance issues is still challenging. The PLUS (Performance Learning for Uncertainty of Software) approach aims at addressing these limitations by investigating the specification of a new class of performance models capturing how the different uncertainties underlying a software system affect its performance characteristics. The main goal of PLUS is to answer a fundamental question in the software performance engineering domain: How to model the variable configuration options (i.e., software and hardware resources) and their intrinsic uncertainties (e.g., resource demand, processor speed) to represent the performance characteristics of software systems? This way, software engineers are exposed to a quantitative evaluation of their systems that supports them in the task of identifying performance critical configurations along with their uncertainties.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {77–80},
numpages = {4},
keywords = {uncertainty, machine learning},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@proceedings{10.1145/3660317,
title = {PERMAVOST '24: Proceedings of the 4th Workshop on Performance EngineeRing, Modelling, Analysis, and VisualizatiOn STrategy},
year = {2024},
isbn = {9798400706455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Pisa, Italy}
}

@inproceedings{10.1145/3238147.3238175,
author = {Bao, Liang and Liu, Xin and Xu, Ziheng and Fang, Baoyin},
title = {AutoConfig: automatic configuration tuning for distributed message systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238175},
doi = {10.1145/3238147.3238175},
abstract = {Distributed message systems (DMSs) serve as the communication backbone for many real-time streaming data processing applications. To support the vast diversity of such applications, DMSs provide a large number of parameters to configure. However, It overwhelms for most users to configure these parameters well for better performance. Although many automatic configuration approaches have been proposed to address this issue, critical challenges still remain: 1) to train a better and robust performance prediction model using a limited number of samples, and 2) to search for a high-dimensional parameter space efficiently within a time constraint. In this paper, we propose AutoConfig -- an automatic configuration system that can optimize producer-side throughput on DMSs. AutoConfig constructs a novel comparison-based model (CBM) that is more robust that the prediction-based model (PBM) used by previous learning-based approaches. Furthermore, AutoConfig uses a weighted Latin hypercube sampling (wLHS) approach to select a set of samples that can provide a better coverage over the high-dimensional parameter space. wLHS allows AutoConfig to search for more promising configurations using the trained CBM. We have implemented AutoConfig on the Kafka platform, and evaluated it using eight different testing scenarios deployed on a public cloud. Experimental results show that our CBM can obtain better results than that of PBM under the same random forests based model. Furthermore, AutoConfig outperforms default configurations by 215.40% on average, and five state-of-the-art configuration algorithms by 7.21%-64.56%.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {29–40},
numpages = {12},
keywords = {weighted Latin hypercube sampling, distributed message system, comparison-based model, automatic configuration tuning},
location = {Montpellier, France},
series = {ASE '18}
}

@inproceedings{10.1145/3510003.3510200,
author = {Dubslaff, Clemens and Weis, Kallistos and Baier, Christel and Apel, Sven},
title = {Causality in configurable software systems},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510200},
doi = {10.1145/3510003.3510200},
abstract = {Detecting and understanding reasons for defects and inadvertent behavior in software is challenging due to their increasing complexity. In configurable software systems, the combinatorics that arises from the multitude of features a user might select from adds a further layer of complexity. We introduce the notion of feature causality, which is based on counterfactual reasoning and inspired by the seminal definition of actual causality by Halpern and Pearl. Feature causality operates at the level of system configurations and is capable of identifying features and their interactions that are the reason for emerging functional and non-functional properties. We present various methods to explicate these reasons, in particular well-established notions of responsibility and blame that we extend to the feature-oriented setting. Establishing a close connection of feature causality to prime implicants, we provide algorithms to effectively compute feature causes and causal explications. By means of an evaluation on a wide range of configurable software systems, including community benchmarks and real-world systems, we demonstrate the feasibility of our approach: We illustrate how our notion of causality facilitates to identify root causes, estimate the effects of features, and detect feature interactions.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {325–337},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3581784.3607069,
author = {Hutter, Edward and Solomonik, Edgar},
title = {Application Performance Modeling via Tensor Completion},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607069},
doi = {10.1145/3581784.3607069},
abstract = {Performance tuning, software/hardware co-design, and job scheduling are among the many tasks that rely on models to predict application performance. We propose and evaluate low-rank tensor decomposition for modeling application performance. We discretize the input and configuration domains of an application using regular grids. Application execution times mapped within grid-cells are averaged and represented by tensor elements. We show that low-rank canonical-polyadic (CP) tensor decomposition is effective in approximating these tensors. We further show that this decomposition enables accurate extrapolation of unobserved regions of an application's parameter space. We then employ tensor completion to optimize a CP decomposition given a sparse set of observed execution times. We consider alternative piecewise/grid-based models and supervised learning models for six applications and demonstrate that CP decomposition optimized using tensor completion offers higher prediction accuracy and memory-efficiency for high-dimensional performance modeling.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {65},
numpages = {14},
location = {Denver, CO, USA},
series = {SC '23}
}

@inproceedings{10.1109/ICSE43902.2021.00099,
author = {Weber, Max and Apel, Sven and Siegmund, Norbert},
title = {White-Box Performance-Influence Models: A Profiling and Learning Approach},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00099},
doi = {10.1109/ICSE43902.2021.00099},
abstract = {Many modern software systems are highly configurable, allowing the user to tune them for performance and more. Current performance modeling approaches aim at finding performance-optimal configurations by building performance models in a black-box manner. While these models provide accurate estimates, they cannot pinpoint causes of observed performance behavior to specific code regions. This does not only hinder system understanding, but it also complicates tracing the influence of configuration options to individual methods.We propose a white-box approach that models configuration-dependent performance behavior at the method level. This allows us to predict the influence of configuration decisions on individual methods, supporting system understanding and performance debugging. The approach consists of two steps: First, we use a coarse-grained profiler and learn performance-influence models for all methods, potentially identifying some methods that are highly configuration- and performance-sensitive, causing inaccurate predictions. Second, we re-measure these methods with a fine-grained profiler and learn more accurate models, at higher cost, though. By means of 9 real-world Java software systems, we demonstrate that our approach can efficiently identify configuration-relevant methods and learn accurate performance-influence models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1059–1071},
numpages = {13},
keywords = {software variability, software product lines, performance, Configuration management},
location = {Madrid, Spain},
series = {ICSE '21}
}

@proceedings{10.1145/3629527,
title = {ICPE '24 Companion: Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the ICPE 2024 workshops program. ICPE workshops extend the main conference by providing a forum to foster discussion on hot and emerging topics from the broad field of performance engineering. They offer a highly dynamic venue to exchange ideas, establish new collaborations, and bootstrap debates on novel techniques, methodologies, and their associated early research results. Workshops feature various presentation formats, including research paper presentations, panel discussions, and keynote talks. Through these presentations and discussions with peer researchers, ICPE workshops help shape future research and identify promising research directions for performance engineering.},
location = {London, United Kingdom}
}

@proceedings{10.1145/3656019,
title = {PACT '24: Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques},
year = {2024},
isbn = {9798400706318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the International Conference on Parallel Architectures and Compilation Techniques (PACT), held in Long Beach, California, USA, October 13-16, 2024. PACT continues its tradition of a unique technical conference sitting at the intersection of hardware and software, with a special emphasis on parallelism. The PACT conference series brings together researchers from computer architectures, compilers, execution environments, programming languages, and applications, to share and discuss their latest research findings. This year's program showcases a wide range of topics, from classic parallel programming languages, compiles, reconfigurable parallelism, to distributed, heterogeneous architectures, in-memory computing, and architectures for AI. Additionally, PACT'24 introduced an exciting new focus on quantum and neuromorphic computing, exploring these areas both as applications and tools for architectures and compilers. In addition to the regular research papers, PACT 2024 features a special category of papers called "tools and practical experiences" (TPE). These papers emphasize applicability, such as traditional methods employed in emerging fields, aiming to highlight the challenges and experiences faced by the industry as opportunities to guide future research.},
location = {Long Beach, CA, USA}
}

@proceedings{10.1145/3710848,
title = {PPoPP '25: Proceedings of the 30th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
year = {2025},
isbn = {9798400714436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Las Vegas, NV, USA}
}

@inproceedings{10.1145/1277741.1277820,
author = {Azzopardi, Leif and de Rijke, Maarten and Balog, Krisztian},
title = {Building simulated queries for known-item topics: an analysis using six european languages},
year = {2007},
isbn = {9781595935977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1277741.1277820},
doi = {10.1145/1277741.1277820},
abstract = {There has been increased interest in the use of simulated queries for evaluation and estimation purposes in Information Retrieval. However, there are still many unaddressed issues regarding their usage and impact on evaluation because their quality, in terms of retrieval performance, is unlike real queries. In this paper, wefocus on methods for building simulated known-item topics and explore their quality against real known-item topics. Using existing generation models as our starting point, we explore factors which may influence the generation of the known-item topic. Informed by this detailed analysis (on six European languages) we propose a model with improved document and term selection properties, showing that simulated known-item topics can be generated that are comparable to real known-item topics. This is a significant step towards validating the potential usefulness of simulated queries: for evaluation purposes, and becausebuilding models of querying behavior provides a deeper insight into the querying process so that better retrieval mechanisms can be developed to support the user.},
booktitle = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {455–462},
numpages = {8},
keywords = {query simulation, query generation, multilingual retrieval},
location = {Amsterdam, The Netherlands},
series = {SIGIR '07}
}

@proceedings{10.1145/3559009,
title = {PACT '22: Proceedings of the International Conference on Parallel Architectures and Compilation Techniques},
year = {2022},
isbn = {9781450398688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {PACT is a long-running and unique conference at the intersection of parallel architectures and compilers that brings together researchers from industry, academia, and national laboratories to present and discuss their latest research results. How applications serve as a driver for innovations in architecture and compilers is an important theme of the conference.},
location = {Chicago, Illinois}
}

@proceedings{10.1145/3700297,
title = {ISAIE '24: Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3626772,
title = {SIGIR '24: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2024), taking place in Washington D.C., USA, from July 14 to 18, 2024.SIGIR serves as the foremost international forum for the presentation of groundbreaking research findings, the demonstration of innovative systems and techniques, and the exploration of forwardthinking research directions in the field of information retrieval.This year's SIGIR is an in-person conference. We believe that an in-person conference is beneficial for several reasons: it fosters direct engagement and networking opportunities, enhances the exchange of research ideas, contributes to a more dynamic and productive conference experience, and nurtures our research community by welcoming newcomers, providing them with the opportunity to become acquainted with SIGIR traditions. This decision has not been made lightly. We understand the challenges that can pose in the aftermath of a pandemic and amidst the uncertainties of the world around us. To accommodate those who cannot attend, we have implemented a series of measures such as proxy presenters, livestreaming, and recording sessions. These steps are taken to ensure that everyone has access to the valuable content that the conference offers.},
location = {Washington DC, USA}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@proceedings{10.1145/3638529,
title = {GECCO '24: Proceedings of the Genetic and Evolutionary Computation Conference},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3640457,
title = {RecSys '24: Proceedings of the 18th ACM Conference on Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bari, Italy}
}

@proceedings{10.1145/3669940,
title = {ASPLOS '25: Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to introduce the first volume of the ASPLOS proceedings for 2025. The conference is in its third year of an experiment with a three-deadline structure: authors can submit to any of three separate review cycles handled by a single year-long program committee. This volume includes papers from the first two review cycles, which had submission deadlines in the spring and summer of 2024. We combined the two cycles because submission volumes in the spring cycle were disproportionately small.This volume contains 72 of the 74 papers accepted to ASPLOS 2025 to date. This includes papers accepted in the spring and summer cycles and those invited to submit a revision in the spring cycle that was ultimately accepted. Two of these 74 accepted papers are still undergoing artifact evaluation and will be published in a subsequent volume. The spring and summer review cycles saw a combined 586 submissions. These submissions were reviewed by a 208-person Program Committee augmented by 57 External Review Committee members. On occasion, we solicited a small number of external expert reviews. On the PC, 129 members self-reported they were in an academic role and 77 self-reported they were in an industrial role. On the ERC it was 43 and 13 respectively. The median PhD year of the combined committees was 2014. In addition to these committees, we engaged ten vice chairs, experienced and trusted reviewers who helped us monitor the review process for each paper.These committees reviewed all of the submissions that were not desk rejected (11 papers) or withdrawn (4 papers). In keeping with recent norms, the technical review happened in two phases. Each paper received three reviews in the first round, with, in most cases, two additional reviews in the second round for the 54% of submissions that advanced. To assign reviews, we used the Toronto Paper Matching System (TPMS) to provide a preliminary review assignment that matched reviewer expertise. We then manually inspected and adjusted these assignments as needed: for example, to correct errors in TPMS's topic modeling or adjust to late-discovered conflicts. In addition, each paper was assigned a non-conflicted chair and a non-conflicted vice chair to provide two extra sets of eyes to monitor and facilitate the process. Due to the size and distribution of the PC, which spanned 14 time zones, the PC did not meet synchronously. Instead, each paper was discussed by the reviewers via comments in the HotCRP system. Ultimately, the discussion for each paper reached one of three outcomes: rejection, conditional acceptance, or major revision. All conditionally accepted papers were shepherded. Major revision papers were invited to revise and resubmit their paper for a second round of review by a subset of the original reviewers. All authors of papers that advanced to the second round of review were given the opportunity to see and respond to their reviewer questions prior to the reviewer discussion.},
location = {Rotterdam, Netherlands}
}

@proceedings{10.1145/3581784,
title = {SC '23: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Started in 1988, the SC Conference has become the annual nexus for researchers and practitioners from academia, industry and government to share information and foster collaborations to advance the state of the art in High Performance Computing (HPC), Networking, Storage, and Analysis.},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3672758,
title = {CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi' an, China}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3673038,
title = {ICPP '24: Proceedings of the 53rd International Conference on Parallel Processing},
year = {2024},
isbn = {9798400717932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gotland, Sweden}
}

@proceedings{10.1145/3605573,
title = {ICPP '23: Proceedings of the 52nd International Conference on Parallel Processing},
year = {2023},
isbn = {9798400708435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3583133,
title = {GECCO '23 Companion: Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@proceedings{10.5555/3715674,
title = {SC-W '24: Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2024},
isbn = {9798350355543},
publisher = {IEEE Press},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3671016,
title = {Internetware '24: Proceedings of the 15th Asia-Pacific Symposium on Internetware},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3689031,
title = {EuroSys '25: Proceedings of the Twentieth European Conference on Computer Systems},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to EuroSys 2025, the 20th edition of the European Conference on Computer Systems! We are excited to host EuroSys 2025 in the modern and dynamic city of Rotterdam, Netherlands. This year's EuroSys is very special as it is co-located (for the first time) with the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2025). We hope you will enjoy an excellent technical program, engaging discussions, and networking opportunities in this vibrant city known for its innovative architecture, bustling port, and rich cultural scene.},
location = {Rotterdam, Netherlands}
}

@proceedings{10.1145/3653081,
title = {IoTAAI '23: Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
year = {2023},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@proceedings{10.1145/3577193,
title = {ICS '23: Proceedings of the 37th ACM International Conference on Supercomputing},
year = {2023},
isbn = {9798400700569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICS is a well-known and outstanding forum for the presentation of significant research in high performance computing.},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3583131,
title = {GECCO '23: Proceedings of the Genetic and Evolutionary Computation Conference},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3638530,
title = {GECCO '24 Companion: Proceedings of the Genetic and Evolutionary Computation Conference Companion},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@book{10.1145/3674127,
editor = {Alonso, Omar and Baeza-Yates, Ricardo},
title = {Information Retrieval: Advanced Topics and Techniques},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {60},
abstract = {In the last decade, deep learning and word embeddings have made significant impacts on information retrieval (IR) by adding techniques based in neural networks and language models. At the same time, certain search modalities such as neural IR and conversational search have become more popular. This book, written by international academic and industry experts, brings the field up to date with detailed discussions of these new approaches and techniques. The book is organized in three sections: Foundations, Adaptations and Concerns, and Verticals.Under Foundations, we address topics that form the basic structure of any modern IR system, including recommender systems. These new techniques are developed to augment indexing, retrieval, and ranking. Neural IR, recommender systems, evaluation, query-driven functionality, and knowledge graphs are covered in this section.IR systems need to adapt to specific user characteristics and preferences, and techniques that were considered too niche a few years ago are now a matter of system design consideration. The Adaptations and Concerns section covers the following topics: conversational search, cross-language retrieval, temporal extraction and retrieval, bias in retrieval systems, and privacy in search.While web search engines are the most popular information access point, there are cases where specific verticals provide a better experience in terms of content and relevance. The Verticals section describes eCommerce, professional search, personal collections, music retrieval, and biomedicine as examples.}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@proceedings{10.1145/3626246,
title = {SIGMOD '24: Companion of the 2024 International Conference on Management of Data},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the SIGMOD 2024 organizing committee, it is our distinct honor, as General Chairs, to welcome you to the 2024 ACM International Conference on Management of Data - SIGMOD 2024. We are thrilled to be hosting this prestigious event for the very first time in Latin America, and specifically in Santiago de Chile, a recognized leader in data technology within the region. This marks a significant milestone for the SIGMOD community, and we are honored to have you join us for a fully in-person experience in this vibrant and innovative city.},
location = {Santiago AA, Chile}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@proceedings{10.1145/3566097,
title = {ASPDAC '23: Proceedings of the 28th Asia and South Pacific Design Automation Conference},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded SystemsWeek (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities to learn about the advancements on LSI design and design automation fields, as well as to communicate with each other for researchers and designers around Asia and South Pacific regions.},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3652628,
title = {ICAICE '23: Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
year = {2023},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@proceedings{10.1145/3569966,
title = {CSSE '22: Proceedings of the 5th International Conference on Computer Science and Software Engineering},
year = {2022},
isbn = {9781450397780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@proceedings{10.1145/3308558,
title = {WWW '19: The World Wide Web Conference},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3603781,
title = {CNIOT '23: Proceedings of the 2023 4th International Conference on Computing, Networks and Internet of Things},
year = {2023},
isbn = {9798400700705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3711129,
title = {EITCE '24: Proceedings of the 2024 8th International Conference on Electronic Information Technology and Computer Engineering},
year = {2024},
isbn = {9798400710094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3545008,
title = {ICPP '22: Proceedings of the 51st International Conference on Parallel Processing},
year = {2022},
isbn = {9781450397339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bordeaux, France}
}

@proceedings{10.1145/3689236,
title = {ICCSIE '24: Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1109/3655039,
title = {ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.},
location = {Incheon, Republic of Korea}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@proceedings{10.5555/3571885,
title = {SC '22: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
year = {2022},
isbn = {9784665454445},
publisher = {IEEE Press},
abstract = {This volume, containing the accepted technical papers and ACM Gordon Bell prize finalists, captures the best current research in all aspects of High Performance Computing (HPC). The SC22 Archive at the conference web site sc22.supercomputing.org complements this volume by collecting other high quality, peer-reviewed material including research posters, the visualization &amp; data analytics showcase, panels, birds of a feather, workshops, and tutorials.},
location = {Dallas, Texas}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@proceedings{10.1145/3607947,
title = {IC3-2023: Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@proceedings{10.1145/3563357,
title = {BuildSys '22: Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2022},
isbn = {9781450398909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Over the past thirteen years, BuildSys has been an interdisciplinary conference that brings together various stakeholders, including researchers, practitioners, and policymakers from different disciplines, including civil engineering, mechanical engineering, environmental science, electrical and computer engineering, computer science, system management and control, and many others. This year is no exception, with papers and attendees from all these disciplines and regions worldwide. The conference's focus extends beyond building systems to the built environment more generally.},
location = {Boston, Massachusetts}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

