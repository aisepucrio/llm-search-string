@inproceedings{10.1145/3646548.3676599,
author = {Gomez-Vazquez, Marcos and Cabot, Jordi},
title = {Exploring the Use of Software Product Lines for the Combination of Machine Learning Models},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3676599},
doi = {10.1145/3646548.3676599},
abstract = {The size of Large Language Models (LLMs), and Machine Learning (ML) models in general, is a key factor of their capacity and quality of their responses. But it comes with a high cost, both during the training and the model execution phase. Recently, various model merging techniques and Mixture of Experts (MoE) architectures are gaining popularity as they enable the creation of large models by combining other existing ones (the "experts" in the MoE approach). Creating these combinations remains a deep technical task with many possible configurations to consider. In this sense, this paper aims to democratize the creation of combined ML models by presenting a product line approach to the specification and training of this type of ML architectures from an initial feature model that helps users define, among other aspects, the type of models they want to combine, the combination strategy and even, for the MoE approach, the tasks that should be associated to each expert.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {26–29},
numpages = {4},
keywords = {Feature Model, Large Language Model, Machine Learning, Mixture of Experts, Model Merging, Software Product Line},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.1145/3579028.3609019,
author = {Bazin, Alexandre and Huchard, Marianne and Martin, Pierre},
title = {Towards Analyzing Variability in Space and Time of Products from a Product Line using Triadic Concept Analysis},
year = {2023},
isbn = {9798400700927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579028.3609019},
doi = {10.1145/3579028.3609019},
abstract = {In this paper, we report an ongoing work on exploring the ability of Triadic Concept Analysis to provide a framework for analyzing products evolution in time and space, and highlight possible usages in the lifecycle of a product line.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume B},
pages = {85–89},
numpages = {5},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using machine learning to infer constraints for product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {constraints and variability mining, machine learning, software product lines, software testing, variability modeling},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3461001.3471152,
author = {Silva, Publio and Bezerra, Carla I. M. and Machado, Ivan},
title = {A machine learning model to classify the feature model maintainability},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471152},
doi = {10.1145/3461001.3471152},
abstract = {Software Product Lines (SPL) are generally specified using a Feature Model (FM), an artifact designed in the early stages of the SPL development life cycle. This artifact can quickly become too complex, which makes it challenging to maintain an SPL. Therefore, it is essential to evaluate the artifact's maintainability continuously. The literature brings some approaches that evaluate FM maintainability through the aggregation of maintainability measures. Machine Learning (ML) models can be used to create these approaches. They can aggregate the values of independent variables into a single target data, also called a dependent variable. Besides, when using white-box ML models, it is possible to interpret and explain the ML model results. This work proposes white-box ML models intending to classify the FM maintainability based on 15 measures. To build the models, we performed the following steps: (i) we compared two approaches to evaluate the FM maintainability through a human-based oracle of FM maintainability classifications; (ii) we used the best approach to pre-classify the ML training dataset; (iii) we generated three ML models and compared them against classification accuracy, precision, recall, F1 and AUC-ROC; and, (iv) we used the best model to create a mechanism capable of providing improvement indicators to domain engineers. The best model used the decision tree algorithm that obtained accuracy, precision, and recall of 0.81, F1-Score of 0.79, and AUC-ROC of 0.91. Using this model, we could reduce the number of measures needed to evaluate the FM maintainability from 15 to 9 measures.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {35–45},
numpages = {11},
keywords = {feature model, machine learning, quality evaluation, software product line},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {configuration, machine learning, multi-objective search, product line, rule mining},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {machine learning, quality assurance, software product line, software testing, software variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3233027.3233029,
author = {Sree-Kumar, Anjali and Planas, Elena and Claris\'{o}, Robert},
title = {Extracting software product line feature models from natural language specifications},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233029},
doi = {10.1145/3233027.3233029},
abstract = {The specification of a family of software products may include documents written in natural language. Automatically extracting knowledge from these documents is a challenging problem that requires using Natural Language Processing (NLP) techniques. This knowledge can be formalized as a Feature Model (FM), a diagram capturing the key features and the relationships among them.In this paper, we first review previous works that have presented tools for extracting FMs from textual specifications and compare their strengths and limitations. Then, we propose a framework for feature and relationship extraction, which overcomes the identified limitations and is built upon state-of-the-art open-source NLP tools. This framework is evaluated against previous works using several case studies, showing improved results.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {43–53},
numpages = {11},
keywords = {NLTK, feature model extraction, natural language processing, requirements engineering, software product line},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@proceedings{10.1145/3697467,
title = {IoTML '24: Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3650215,
title = {ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
year = {2023},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3589883,
title = {ICMLT '23: Proceedings of the 2023 8th International Conference on Machine Learning Technologies},
year = {2023},
isbn = {9781450398329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stockholm, Sweden}
}

@proceedings{10.1145/3587716,
title = {ICMLC '23: Proceedings of the 2023 15th International Conference on Machine Learning and Computing},
year = {2023},
isbn = {9781450398411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhuhai, China}
}

@inproceedings{10.1145/3646548.3672596,
author = {Chueca, Jorge and Blasco, Daniel and Cetina, Carlos and Font, Jaime},
title = {Leveraging Phylogenetics in Software Product Families: The Case of Latent Content Generation in Video Games},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672596},
doi = {10.1145/3646548.3672596},
abstract = {A family of software products comprises similar products within a defined scope that share common characteristics, often due to reuse techniques applied during development. This paper introduces an approach that applies biological insights to map the landscape of a software product family, identifying potential gaps within its scope. Phylogenetics studies the gene similarity among groups of organisms to understand ancestry among species. Leveraging Phylogenetics in software, our approach offers a structured view of a product family, aiding in the discovery of unexplored areas fitting the scope of the family. Our approach creates a phylogenetic tree that enables to easily identify latent products (ancestors) that did not exist in the original family. Those ancestors can then be reconstructed from existing products (descendants). The product family evaluated is a set of industry-scale video game non-playable characters. We assess this approach through video game simulations and scope metrics to determine how closely the reconstructed products align with the family’s scope. The results confirm that the content generated with phylogenetics aligns better with the family scope than the state-of-the-art procedural content generation techniques using evolutionary algorithms. Phylogenetics enhances content generation by providing a framework to understand and expand the product family with new content.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {113–124},
numpages = {12},
keywords = {Game Software Engineering, Phylogenetics, Procedural Content Generation, Software Product Families},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.1145/3461001.3471155,
author = {Martin, Hugo and Acher, Mathieu and Pereira, Juliana Alves and J\'{e}z\'{e}quel, Jean-Marc},
title = {A comparison of performance specialization learning for configurable systems},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471155},
doi = {10.1145/3461001.3471155},
abstract = {The specialization of the configuration space of a software system has been considered for targeting specific configuration profiles, usages, deployment scenarios, or hardware settings. The challenge is to find constraints among options' values that only retain configurations meeting a performance objective. Since the exponential nature of configurable systems makes a manual specialization unpractical, several approaches have considered its automation using machine learning, i.e., measuring a sample of configurations and then learning what options' values should be constrained. Even focusing on learning techniques based on decision trees for their built-in explainability, there is still a wide range of possible approaches that need to be evaluated, i.e., how accurate is the specialization with regards to sampling size, performance thresholds, and kinds of configurable systems. In this paper, we compare six learning techniques: three variants of decision trees (including a novel algorithm) with and without the use of model-based feature selection. We first perform a study on 8 configurable systems considered in previous related works and show that the accuracy reaches more than 90% and that feature selection can improve the results in the majority of cases. We then perform a study on the Linux kernel and show that these techniques performs as well as on the other systems. Overall, our results show that there is no one-size-fits-all learning variant (though high accuracy can be achieved): we present guidelines and discuss tradeoffs.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {46–57},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3168365.3168373,
author = {Pereira, Juliana Alves and Schulze, Sandro and Krieter, Sebastian and Ribeiro, M\'{a}rcio and Saake, Gunter},
title = {A Context-Aware Recommender System for Extended Software Product Line Configurations},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168373},
doi = {10.1145/3168365.3168373},
abstract = {Mass customization of standardized products has become a trend to succeed in today's market environment. Software Product Lines (SPLs) address this trend by describing a family of software products that share a common set of features. However, choosing the appropriate set of features that matches a user's individual interests is hampered due to the overwhelming amount of possible SPL configurations. Recommender systems can address this challenge by filtering the number of configurations and suggesting a suitable set of features for the user's requirements. In this paper, we propose a context-aware recommender system for predicting feature selections in an extended SPL configuration scenario, i.e. taking nonfunctional properties of features into consideration. We present an empirical evaluation based on a large real-world dataset of configurations derived from industrial experience in the Enterprise Resource Planning domain. Our results indicate significant improvements in the predictive accuracy of our context-aware recommendation approach over a state-of-the-art binary-based approach.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {97–104},
numpages = {8},
keywords = {Configuration, Feature Model, Non-Functional Properties, Recommender Systems, Software Product Lines},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/3546932.3546998,
author = {Trasobares, Jose Ignacio and Domingo, \'{A}frica and Arcega, Lorena and Cetina, Carlos},
title = {Evaluating the benefits of software product lines in game software engineering},
year = {2022},
isbn = {9781450394437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546932.3546998},
doi = {10.1145/3546932.3546998},
abstract = {Video game development is one of the fastest-growing industries in the world. The use of software product lines (SPLs) has proven to be effective in developing different types of software at a lower cost, in less time, and with higher quality. There are recent research efforts that propose to apply SPLs in the domain of video games. Video games present characteristics that differentiate their development from the development of classic software; for example, game developers perceive more difficulties than other non-game developers when reusing code. In this paper, we evaluate if the adoption of an SPL in game software engineering (GSE) can generate the same benefits as in classic software engineering (CSE) considering the case study of Kromaia. As in other disciplines dealing with human behaviour, empirical research allows for building a reliable knowledge base in software engineering. We present an experiment comparing two development approaches, Clone and Own (CaO) and an SPL in terms of correctness, efficiency, and satisfaction when subjects develop elements of a commercial video game. The results indicate that the elements developed using the SPL are more correct than those developed with CaO but do not indicate significant improvement in efficiency or satisfaction. Our findings suggest that SPLs in GSE may play a different role than the one they have played for decades in CSE. Specifically, SPLs can be relevant to generating new video game content or to balancing video game difficulty.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A},
pages = {120–130},
numpages = {11},
keywords = {empirical comparison, game software engineering, software product line engineering},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1007/978-3-642-33666-9_46,
author = {Ali, Shaukat and Yue, Tao and Briand, Lionel and Walawege, Suneth},
title = {A product line modeling and configuration methodology to support model-based testing: an industrial case study},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_46},
doi = {10.1007/978-3-642-33666-9_46},
abstract = {Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behavioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {726–742},
numpages = {17},
keywords = {UML state machine, aspect-oriented modeling, behavioral variability, model-based testing, product line engineering},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/3503229.3547027,
author = {Korsman, David and Damasceno, Carlos Diego N. and Str\"{u}ber, Daniel},
title = {A tool for analysing higher-order feature interactions in preprocessor annotations in C and C++ projects},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547027},
doi = {10.1145/3503229.3547027},
abstract = {Feature interactions are an intricate phenomenon: they can add value to software systems, but also lead to subtle bugs and complex, emergent behavior. Having a clearer understanding of feature interactions in practice can help practitioners to select appropriate quality assurance techniques for their systems and researchers to guide further research efforts. In this paper, we present pdparser, a Python-based tool for analysing structural feature interactions in software systems developed with C and C++ preprocessor. Our tool relies on a lightweight methodology to quantify the frequency of pairwise and higher-order feature interactions and the percentage of code affected by them. We showcase the individual characteristics brought forward by the automated analysis of one toy example and two open-source text editors: Vim and Emacs. The source code and a demo video are available on GitHub at https://github.com/dkorsman/pdparser.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {70–73},
numpages = {4},
keywords = {feature interaction, preprocessors, product lines, static analysis},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3461002.3473070,
author = {Acher, Mathieu and Perrouin, Gilles and Cordy, Maxime},
title = {BURST: a benchmarking platform for uniform random sampling techniques},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473070},
doi = {10.1145/3461002.3473070},
abstract = {We present BURST, a benchmarking platform for uniform random sampling techniques. With BURST, researchers have a flexible, controlled environment in which they can evaluate the scalability and uniformity of their sampling. BURST comes with an extensive --- and extensible --- benchmark dataset comprising 128 feature models, including challenging, real-world models of the Linux kernel. BURST takes as inputs a sampling tool, a set of feature models and a sampling budget. It automatically translates any feature model of the set in DIMACS and invokes the sampling tool to generate the budgeted number of samples. To evaluate the scalability of the sampling tool, BURST measures the time the tool needs to produce the requested sample. To evaluate the uniformity of the produced sample, BURST integrates the state-of-the-art and proven statistical test Barbarik. We envision BURST to become the starting point of a standardisation initiative of sampling tool evaluation. Given the huge interest of research for sampling algorithms and tools, this initiative would have the potential to reach and crosscut multiple research communities including AI, ML, SAT and SPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {36–40},
numpages = {5},
keywords = {SAT, benchmark, configurable systems, sampling, software product lines, variability model},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3546932.3547007,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Quality-aware analysis and optimisation of virtual network functions},
year = {2022},
isbn = {9781450394437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546932.3547007},
doi = {10.1145/3546932.3547007},
abstract = {The softwarisation and virtualisation of network functionality is the last milestone in the networking industry. Software-Defined Networks (SDN) and Network Function Virtualization (NFV) offer the possibility of using software to manage computer and mobile networks and build novel Virtual Network Functions (VNFs) deployed in heterogeneous devices. To reason about the variability of network functions and especially about the quality of a software product defined as a set of VNFs instantiated as part of a service (i.e., Service Function Chaining), a variability model along with a quality model is required.However, this domain imposes certain challenges to quality-aware reasoning of service function chains, such as numerical features or configuration-level Quality Attributes (QAs) (e.g., energy consumption). Incorporating numerical reasoning with quality data into SPL analyses is challenging and tool support is rare. In this work, we present 3 groups of operations: model report, aggregate functions to dynamically convert QAs at the feature-level into the configuration-level, and quality-aware optimisation. Our objective is to test the most complete reasoning tools to exploit the extended variability with quality attributes needed for VNFs.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A},
pages = {210–221},
numpages = {12},
keywords = {numerical feature, optimization, quality attribute, reasoning, variability, virtual network function},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/2791060.2791103,
author = {Mazo, Ra\'{u}l and Mu\~{n}oz-Fern\'{a}ndez, Juan C. and Rinc\'{o}n, Luisa and Salinesi, Camille and Tamura, Gabriel},
title = {VariaMos: an extensible tool for engineering (dynamic) product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791103},
doi = {10.1145/2791060.2791103},
abstract = {This paper presents the new release of VariaMos, a Java-based tool for defining variability modeling languages, modeling (dynamic) product lines and cyber-physical self-adaptive systems, and supporting automated verification, analysis, configuration and simulation of these models. In particular, we describe the characteristics of this new version regarding its first release: (1) the capability to create languages for modeling systems with variability, even with different views; (2) the capability to use the created language to model (dynamic) product lines; (3) the capability to analyze and configure these models according to the changing context and requirements; and (4) the capability to execute them over several simulation scenarios. Finally, we show how to use VariaMos with an example, and we compare it with other tools found in the literature.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {374–379},
numpages = {6},
keywords = {constraints, dynamic product line models, product line engineering, simulation, tool, variability},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3097983.3098186,
author = {Sharma, Ashlesh and Srinivasan, Vidyuth and Kanchan, Vishal and Subramanian, Lakshminarayanan},
title = {The Fake vs Real Goods Problem: Microscopy and Machine Learning to the Rescue},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098186},
doi = {10.1145/3097983.3098186},
abstract = {Counterfeiting of physical goods is a global problem amounting to nearly 7% of world trade. While there have been a variety of overt technologies like holograms and specialized barcodes and covert technologies like taggants and PUFs, these solutions have had a limited impact on the counterfeit market due to a variety of factors - clonability, cost or adoption barriers. In this paper, we introduce a new mechanism that uses machine learning algorithms on microscopic images of physical objects to distinguish between genuine and counterfeit versions of the same product. The underlying principle of our system stems from the idea that microscopic characteristics in a genuine product or a class of products (corresponding to the same larger product line), exhibit inherent similarities that can be used to distinguish these products from their corresponding counterfeit versions. A key building block for our system is a wide-angle microscopy device compatible with a mobile device that enables a user to easily capture the microscopic image of a large area of a physical object. Based on the captured microscopic images, we show that using machine learning algorithms (ConvNets and bag of words), one can generate a highly accurate classification engine for separating the genuine versions of a product from the counterfeit ones; this property also holds for "super-fake" counterfeits observed in the marketplace that are not easily discernible from the human eye. We describe the design of an end-to-end physical authentication system leveraging mobile devices, portable hardware and a cloud-based object verification ecosystem. We evaluate our system using a large dataset of 3 million images across various objects and materials such as fabrics, leather, pills, electronics, toys and shoes. The classification accuracy is more than 98% and we show how our system works with a cellphone to verify the authenticity of everyday objects.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2011–2019},
numpages = {9},
keywords = {computer vision, conventional neural networks, microscopy, physical authentication},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/2791060.2791069,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Empirical comparison of regression methods for variability-aware performance prediction},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791069},
doi = {10.1145/2791060.2791069},
abstract = {Product line engineering derives product variants by selecting features. Understanding the correlation between feature selection and performance is important for stakeholders to acquire a desirable product variant. We infer such a correlation using four regression methods based on small samples of measured configurations, without additional effort to detect feature interactions. We conduct experiments on six real-world case studies to evaluate the prediction accuracy of the regression methods. A key finding in our empirical study is that one regression method, called Bagging, is identified as the best to make accurate and robust predictions for the studied systems.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {186–190},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3233027.3233039,
author = {Pereira, Juliana Alves and Schulze, Sandro and Figueiredo, Eduardo and Saake, Gunter},
title = {N-dimensional tensor factorization for self-configuration of software product lines at runtime},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233039},
doi = {10.1145/3233027.3233039},
abstract = {Dynamic software product lines demand self-adaptation of their behavior to deal with runtime contextual changes in their environment and offer a personalized product to the user. However, taking user preferences and context into account impedes the manual configuration process, and thus, an efficient and automated procedure is required. To automate the configuration process, context-aware recommendation techniques have been acknowledged as an effective mean to provide suggestions to a user based on their recognized context. In this work, we propose a collaborative filtering method based on tensor factorization that allows an integration of contextual data by modeling an N-dimensional tensor User-Feature-Context instead of the traditional two-dimensional User-Feature matrix. In the proposed approach, different types of non-functional properties are considered as additional contextual dimensions. Moreover, we show how to self-configure software product lines by applying our N-dimensional tensor factorization recommendation approach. We evaluate our approach by means of an empirical study using two datasets of configurations derived for medium-sized product lines. Our results reveal significant improvements in the predictive accuracy of the configuration over a state-of-the-art non-contextual matrix factorization approach. Moreover, it can scale up to a 7-dimensional tensor containing hundred of configurations in a couple of milliseconds.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {87–97},
numpages = {11},
keywords = {recommender systems, runtime decision-making, self-configuration, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3697467.3697591,
author = {Bian, Yifan and Luo, Dongxiang and Zhang, Menglong},
title = {A Review of FPGA Accelerated Computing Methods for YOLO Models},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697467.3697591},
doi = {10.1145/3697467.3697591},
abstract = {In recent years, with the rapid evolution of deep learning and neural networks, combined with the advent of the big data and intelligence era, one of the models in the field of object detection, YOLO (You Only Look Once) has also become a hot research topic. Addressing the critical benchmarks of object detection—Timeliness Rate and Accuracy Rate—has prompted a surge in research dedicated to constructing an FPGA (Field-Programmable Gate Array)-based acceleration scheme. In this article, we first provide an overview of neural networks and hardware platforms, followed by an in-depth exploration of the implementation of the YOLO model on FPGA hardware platforms. Additionally, we consolidate and review the current state of FPGA acceleration for YOLO models. Subsequently, we undertake a thorough analysis of the performance of different acceleration techniques. Finally, we delve into the exploration and discussion of potential future directions for development.},
booktitle = {Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
pages = {34–42},
numpages = {9},
keywords = {FPGA (Field-Programmable Gate Array), YOLO (You Only Look Once), hardware acceleration, model acceleration},
location = {
},
series = {IoTML '24}
}

@article{10.1145/3464939,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat},
title = {Recommending Faulty Configurations for Interacting Systems Under Test Using Multi-objective Search},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3464939},
doi = {10.1145/3464939},
abstract = {Modern systems, such as cyber-physical systems, often consist of multiple products within/across product lines communicating with each other through information networks. Consequently, their runtime behaviors are influenced by product configurations and networks. Such systems play a vital role in our daily life; thus, ensuring their correctness by thorough testing becomes essential. However, testing these systems is particularly challenging due to a large number of possible configurations and limited available resources. Therefore, it is important and practically useful to test these systems with specific configurations under which products will most likely fail to communicate with each other. Motivated by this, we present a search-based configuration recommendation (SBCR) approach to recommend faulty configurations for the system under test (SUT) based on cross-product line (CPL) rules. CPL rules are soft constraints, constraining product configurations while indicating the most probable system states with a certain degree of confidence. In SBCR, we defined four search objectives based on CPL rules and combined them with six commonly applied search algorithms. To evaluate SBCR (i.e., SBCRNSGA-II, SBCRIBEA, SBCRMoCell, SBCRSPEA2, SBCRPAES, and SBCRSMPSO), we performed two case studies (Cisco and Jitsi) and conducted difference analyses. Results show that for both of the case studies, SBCR significantly outperformed random search-based configuration recommendation (RBCR) for 86% of the total comparisons based on six quality indicators, and 100% of the total comparisons based on the percentage of faulty configurations (PFC). Among the six variants of SBCR, SBCRSPEA2 outperformed the others in 85% of the total comparisons based on six quality indicators and 100% of the total comparisons based on PFC.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {53},
numpages = {36},
keywords = {Product line, configuration recommendation, interacting products, mined rules, multi-objective search, testing}
}

@article{10.1145/3611663,
author = {Oh, Jeho and Batory, Don and Heradio, Rub\'{e}n},
title = {Finding Near-optimal Configurations in Colossal Spaces with Statistical Guarantees},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3611663},
doi = {10.1145/3611663},
abstract = {A Software Product Line (SPL) is a family of similar programs. Each program is defined by a unique set of features, called a configuration, that satisfies all feature constraints. “What configuration achieves the best performance for a given workload?” is the SPLOptimization (SPLO) challenge. SPLO is daunting: just 80 unconstrained features yield 1024 unique configurations, which equals the estimated number of stars in the universe. We explain (a) how uniform random sampling and random search algorithms solve SPLO more efficiently and accurately than current machine-learned performance models and (b) how to compute statistical guarantees on the quality of a returned configuration; i.e., it is within x% of optimal with y% confidence.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {7},
numpages = {36},
keywords = {Software product lines, configuration optimization, product spaces, machine learning, uniform random sampling, random search, order statistics}
}

@inproceedings{10.5555/1753235.1753267,
author = {Mendonca, Marcilio and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof},
title = {SAT-based analysis of feature models is easy},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Feature models are a popular variability modeling notation used in product line engineering. Automated analyses of feature models, such as consistency checking and interactive or offline product selection, often rely on translating models to propositional logic and using satisfiability (SAT) solvers.Efficiency of individual satisfiability-based analyses has been reported previously. We generalize and quantify these studies with a series of independent experiments. We show that previously reported efficiency is not incidental. Unlike with the general SAT instances, which fall into easy and hard classes, the instances induced by feature modeling are easy throughout the spectrum of realistic models. In particular, the phenomenon of phase transition is not observed for realistic feature models.Our main practical conclusion is a general encouragement for researchers to continued development of SAT-based methods to further exploit this efficiency in future.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {231–240},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3522664.3528602,
author = {Friesel, Birte and Spinczyk, Olaf},
title = {Black-box models for non-functional properties of AI software systems},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528602},
doi = {10.1145/3522664.3528602},
abstract = {Non-functional properties (NFPs) such as latency, memory requirements, or hardware cost are an important characteristic of AI software systems, especially in the domain of resource-constrained embedded devices. Embedded AI products require sufficient resources for satisfactory latency and accuracy, but should also be cost-efficient and therefore not use more powerful hardware than strictly necessary. Traditionally, modeling and optimization efforts focus on the AI architecture, utilizing methods such as neural architecture search (NAS). However, before developers can start optimizing, they need to know which architectures are suitable candidates for their use case. To this end, architectures must be viewed in context: model post-processing (e.g. quantization), hardware platform, and run-time configuration such as batching all have significant effects on NFPs and therefore on AI architecture performance. Moreover, scalar parameters such as batch size cannot be benchmarked exhaustively. We argue that it is worthwhile to address this issue by means of black-box models before deciding on AI architectures for optimization and hardware/software platforms for inference. To support our claim, we present an AI product line with variable hardware and software components, perform benchmarks, and present notable results. Additionally, we evaluate both compactness and generalization capabilities of regression tree-based modeling approaches from the machine learning and product line engineering communities. We find that linear model trees perform best: they can capture NFPs of known AI configurations with a mean error of up to 13 %, and can predict unseen configurations with a mean error of 10 to 26 %. We find linear model trees to be more compact and interpretable than other tree-based approaches.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {170–180},
numpages = {11},
keywords = {AI, performance prediction, product lines, regression trees},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3368089.3409700,
author = {Cambronero, Jos\'{e} P. and Cito, J\"{u}rgen and Rinard, Martin C.},
title = {AMS: generating AutoML search spaces from weak specifications},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409700},
doi = {10.1145/3368089.3409700},
abstract = {We consider a usage model for automated machine learning (AutoML) in which users can influence the generated pipeline by providing a weak pipeline specification: an unordered set of API components from which the AutoML system draws the components it places into the generated pipeline. Such specifications allow users to express preferences over the components that appear in the pipeline, for example a desire for interpretable components to appear in the pipeline. We present AMS, an approach to automatically strengthen weak specifications to include unspecified complementary and functionally related API components, populate the space of hyperparameters and their values, and pair this configuration with a search procedure to produce a strong pipeline specification: a full description of the search space for candidate pipelines. ams uses normalized pointwise mutual information on a code corpus to identify complementary components, BM25 as a lexical similarity score over the target API's documentation to identify functionally related components, and frequency distributions in the code corpus to extract key hyperparameters and values. We show that strengthened specifications can produce pipelines that outperform the pipelines generated from the initial weak specification and an expert-annotated variant, while producing pipelines that still reflect the user preferences captured in the original weak specification.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {763–774},
numpages = {12},
keywords = {automated machine learning, program mining, search-based software engineering},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.5555/3643142.3643334,
author = {Chan, Chew Wye and Gan, Boon Ping and Cai, Wentong},
title = {Combining Time Series Data and Snapshot Data for Situation Aware Dispatching in Semiconductor Manufacturing},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {Dispatch rules are commonly used to schedule lots in the semiconductor industry. Previous studies have indicated that adapting dispatch rules can improve overall factory performance. Machine learning has proven useful in learning the relationship between manufacturing situations and dispatch rules. However, using only snapshot data at a given point in time to generate features for these models does not account for trends in the manufacturing situation, which can be represented as time series data. To address this issue, the proposed method generates features from time series data and combines them with features from snapshot data to train machine learning models for dispatch rule prediction. The results demonstrate the effectiveness of this methodology, as the combination of features from both types of data achieves the highest prediction accuracy. Simulation results show that this approach can adapt the dispatch rule according to the manufacturing situation and achieve a comparable factory performance.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2310–2321},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3474624.3476016,
author = {Bezerra, Carla and Lima, Rafael and Silva, Publio},
title = {DyMMer 2.0: A Tool for Dynamic Modeling and Evaluation of Feature Model},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3476016},
doi = {10.1145/3474624.3476016},
abstract = {Managing dynamic variability has motivated several researchers to combine Dynamic Software Product Lines (DSPLs) practices with runtime variability mechanisms. By combining these approaches, a DSPL acquires important features, ranging from the ability to reconfigure by changing the context, adding or removing features, crash recovery, and re-adaptation based on changes in the model’s features. Feature model (FM) is an important artifact of a DPSL and there is a lack of tools that support the modeling of this artifact. We have extended the DyMMer tool for modeling FM of DSPLs from an adaptation mechanism based on MAPE-K to solve this problem. We migrated the DyMMer tool to a web version and incorporated new features: (i) modeling of FMs from SPLs and DSPLs, (ii) development of an adaptation mechanism for FM of DSPLs, (iii) repository of FMs, (iv) inclusion of thresholds for measures, and (v) user authentication. We believe that this tool is useful for research in the area of DSPLs, and also for dynamic domain modeling and evaluation. Video: https://youtu.be/WVHW6bI8ois},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {121–126},
numpages = {6},
keywords = {Dynamic Software Product Line, Feature Model, Modeling},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.1145/3377812.3382153,
author = {Ghamizi, Salah and Cordy, Maxime and Papadakis, Mike and Traon, Yves Le},
title = {FeatureNET: diversity-driven generation of deep learning models},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3382153},
doi = {10.1145/3377812.3382153},
abstract = {We present FeatureNET, an open-source Neural Architecture Search (NAS) tool1 that generates diverse sets of Deep Learning (DL) models. FeatureNET relies on a meta-model of deep neural networks, consisting of generic configurable entities. Then, it uses tools developed in the context of software product lines to generate diverse (maximize the differences between the generated) DL models. The models are translated to Keras and can be integrated into typical machine learning pipelines. FeatureNET allows researchers to generate seamlessly a large variety of models. Thereby, it helps choosing appropriate DL models and performing experiments with diverse models (mitigating potential threats to validity). As a NAS method, FeatureNET successfully generates models performing equally well with handcrafted models.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {41–44},
numpages = {4},
keywords = {AutoML, NAS, configuration search, neural architecture search},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1145/3492762,
author = {Sobhy, Dalia and Minku, Leandro and Bahsoon, Rami and Kazman, Rick},
title = {Continuous and Proactive Software Architecture Evaluation: An IoT Case},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3492762},
doi = {10.1145/3492762},
abstract = {Design-time evaluation is essential to build the initial software architecture to be deployed. However, experts’ assumptions made at design-time are unlikely to remain true indefinitely in systems that are characterized by scale, hyperconnectivity, dynamism, and uncertainty in operations (e.g. IoT). Therefore, experts’ design-time decisions can be challenged at run-time. A continuous architecture evaluation that systematically assesses and intertwines design-time and run-time decisions is thus necessary. This paper proposes the first proactive approach to continuous architecture evaluation of the system leveraging the support of simulation. The approach evaluates software architectures by not only tracking their performance over time, but also forecasting their likely future performance through machine learning of simulated instances of the architecture. This enables architects to make cost-effective informed decisions on potential changes to the architecture. We perform an IoT case study to show how machine learning on simulated instances of architecture can fundamentally guide the continuous evaluation process and influence the outcome of architecture decisions. A series of experiments is conducted to demonstrate the applicability and effectiveness of the approach. We also provide the architect with recommendations on how to best benefit from the approach through choice of learners and input parameters, grounded on experimentation and evidence.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {46},
numpages = {54},
keywords = {Continuous evaluation, software architecture evaluation, time series forecasting, IoT}
}

@article{10.1145/3528100,
author = {Cheng, Jiezhu and Gao, Cuiyun and Zheng, Zibin},
title = {HINNPerf: Hierarchical Interaction Neural Network for Performance Prediction of Configurable Systems},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3528100},
doi = {10.1145/3528100},
abstract = {Modern software systems are usually highly configurable, providing users with customized functionality through various configuration options. Understanding how system performance varies with different option combinations is important to determine optimal configurations that meet specific requirements. Due to the complex interactions among multiple options and the high cost of performance measurement under a huge configuration space, it is challenging to study how different configurations influence the system performance. To address these challenges, we propose HINNPerf, a novel hierarchical interaction neural network for performance prediction of configurable systems. HINNPerf employs the embedding method and hierarchic network blocks to model the complicated interplay between configuration options, which improves the prediction accuracy of the method. In addition, we devise a hierarchical regularization strategy to enhance the model robustness. Empirical results on 10 real-world configurable systems show that our method statistically significantly outperforms state-of-the-art approaches by achieving average 22.67% improvement in prediction accuracy. In addition, combined with the Integrated Gradients method, the designed hierarchical architecture provides some insights about the interaction complexity and the significance of configuration options, which might help users and developers better understand how the configurable system works and efficiently identify significant options affecting the performance.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {46},
numpages = {30},
keywords = {Software performance prediction, highly configurable systems, deep neural network, machine learning}
}

@book{10.1145/3674127,
editor = {Alonso, Omar and Baeza-Yates, Ricardo},
title = {Information Retrieval: Advanced Topics and Techniques},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {60},
abstract = {In the last decade, deep learning and word embeddings have made significant impacts on information retrieval (IR) by adding techniques based in neural networks and language models. At the same time, certain search modalities such as neural IR and conversational search have become more popular. This book, written by international academic and industry experts, brings the field up to date with detailed discussions of these new approaches and techniques. The book is organized in three sections: Foundations, Adaptations and Concerns, and Verticals.Under Foundations, we address topics that form the basic structure of any modern IR system, including recommender systems. These new techniques are developed to augment indexing, retrieval, and ranking. Neural IR, recommender systems, evaluation, query-driven functionality, and knowledge graphs are covered in this section.IR systems need to adapt to specific user characteristics and preferences, and techniques that were considered too niche a few years ago are now a matter of system design consideration. The Adaptations and Concerns section covers the following topics: conversational search, cross-language retrieval, temporal extraction and retrieval, bias in retrieval systems, and privacy in search.While web search engines are the most popular information access point, there are cases where specific verticals provide a better experience in terms of content and relevance. The Verticals section describes eCommerce, professional search, personal collections, music retrieval, and biomedicine as examples.}
}

@proceedings{10.1145/3689484,
title = {GPCE '24: Proceedings of the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2024},
isbn = {9798400712111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts &amp; Experiences (GPCE’24). GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between the programming language and software engineering research communities.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.1145/3425898.3426959,
author = {Bordis, Tabea and Runge, Tobias and Schaefer, Ina},
title = {Correctness-by-construction for feature-oriented software product lines},
year = {2020},
isbn = {9781450381741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425898.3426959},
doi = {10.1145/3425898.3426959},
abstract = {Software product lines are increasingly used to handle the growing demand of custom-tailored software variants. They provide systematic reuse of software paired with variability mechanisms in the code to implement whole product families rather than single software products. A common domain of application for product lines are safety-critical systems, which require behavioral correctness to avoid dangerous situations in-field. While most approaches concentrate on post-hoc verification for product lines, we argue that a stepwise approach to create correct programs may be beneficial for developers to manage the growing variability. Correctness-by-construction is such a stepwise approach to create programs using a set of small, tractable refinement rules that guarantee the correctness of the program with regard to its specification. In this paper, we propose the first approach to develop correct-by-construction software product lines using feature-oriented programming. First, we extend correctness-by-construction by two refinement rules for variation points in the code. Second, we give a proof for the soundness of the proposed rules. Third, we implement our technique in a tool called VarCorC and show the applicability of the tool by conducting two case studies.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {22–34},
numpages = {13},
keywords = {correctness-by-construction, feature-oriented programming, formal verification, software product lines},
location = {Virtual, USA},
series = {GPCE 2020}
}

@inproceedings{10.1145/3637528.3671801,
author = {Zhang, Wentao and Zhao, Lingxuan and Xia, Haochong and Sun, Shuo and Sun, Jiaze and Qin, Molei and Li, Xinyi and Zhao, Yuqing and Zhao, Yilei and Cai, Xinyu and Zheng, Longtao and Wang, Xinrun and An, Bo},
title = {A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671801},
doi = {10.1145/3637528.3671801},
abstract = {Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 12 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4314–4325},
numpages = {12},
keywords = {financial ai agents, large language models, quantitative trading},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3624007,
title = {GPCE 2023: Proceedings of the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2023},
isbn = {9798400704062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 22nd ACM SIGPLAN International Conference on Generative Programming: Concepts &amp; Experiences (GPCE’23). GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between the programming languages research communities.},
location = {Cascais, Portugal}
}

@proceedings{10.1145/3564719,
title = {GPCE 2022: Proceedings of the 21st ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2022},
isbn = {9781450399203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 21st ACM SIGPLAN International Conference on Generative Programming: Concept &amp; Experiences (GPCE 2022) held on December 6th and 7th, 2022 in Auckland, New Zealand. GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation, domain-specific languages, and component deployment to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between software engineering and programming language.},
location = {Auckland, New Zealand}
}

@inproceedings{10.1145/3643834.3661624,
author = {Uusitalo, Severi and Salovaara, Antti and Jokela, Tero and Salmimaa, Marja},
title = {”Clay to Play With”: Generative AI Tools in UX and Industrial Design Practice},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661624},
doi = {10.1145/3643834.3661624},
abstract = {Generative artificial intelligence (GAI) is transforming numerous professions, not least various fields intimately relying on creativity, such as design. To explore GAI’s adoption and appropriation in design, an interview-based study probed 10 specialists in user experience and industrial design, with varying tenure and GAI experience, for their adoption/application of GAI tools, reasons for not using them, problems with ownership and agency, speculations about the future of creative work, and GAI tools’ roles in design sensemaking. Insight from reflexive thematic analysis revealed wide variation in attitudes toward GAI tools – from threat-oriented negative appraisals to identification of empowerment opportunities – which depended on the sense of agency and perceived control. The paper examines this finding in light of the Coping Model of User Adaptation and discusses designers’ metacognitive skills as possible underpinnings for their attitudes. Avenues for further research are identified accordingly.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1566–1578},
numpages = {13},
keywords = {UX design, coping model of user adaptation, design, generative AI, industrial design, metacognition},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/2786805.2786845,
author = {Siegmund, Norbert and Grebhahn, Alexander and Apel, Sven and K\"{a}stner, Christian},
title = {Performance-influence models for highly configurable systems},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786845},
doi = {10.1145/2786805.2786845},
abstract = {Almost every complex software system today is configurable. While configurability has many benefits, it challenges performance prediction, optimization, and debugging. Often, the influences of individual configuration options on performance are unknown. Worse, configuration options may interact, giving rise to a configuration space of possibly exponential size. Addressing this challenge, we propose an approach that derives a performance-influence model for a given configurable system, describing all relevant influences of configuration options and their interactions. Our approach combines machine-learning and sampling heuristics in a novel way. It improves over standard techniques in that it (1) represents influences of options and their interactions explicitly (which eases debugging), (2) smoothly integrates binary and numeric configuration options for the first time, (3) incorporates domain knowledge, if available (which eases learning and increases accuracy), (4) considers complex constraints among options, and (5) systematically reduces the solution space to a tractable size. A series of experiments demonstrates the feasibility of our approach in terms of the accuracy of the models learned as well as the accuracy of the performance predictions one can make with them.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {284–294},
numpages = {11},
keywords = {Performance-influence models, machine learning, sampling},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3637528.3671604,
author = {Mukerji, Abhimanyu and More, Sushant and Kannan, Ashwin Viswanathan and Ravi, Lakshmi and Chen, Hua and Kohli, Naman and Khawand, Chris and Mandalapu, Dinesh},
title = {Valuing an Engagement Surface using a Large Scale Dynamic Causal Model},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671604},
doi = {10.1145/3637528.3671604},
abstract = {With recent rapid growth in online shopping, AI-powered Engagement Surfaces (ES) have become ubiquitous across retail services. These engagement surfaces perform an increasing range of functions, including recommending new products for purchase, reminding customers of their orders and providing delivery notifications. Understanding the causal effect of engagement surfaces on value driven for customers and businesses remains an open scientific question. In this paper, we develop a dynamic causal model at scale to disentangle value attributable to an ES, and to assess its effectiveness. We demonstrate the application of this model to inform business decision-making by understanding returns on investment in the ES, and identifying product lines and features where the ES adds the most value.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5556–5565},
numpages = {10},
keywords = {causal inference, causal modeling, dynamic causal model, engagement surface, investment decisions, large-scale modeling, observational causal model, program valuation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.5555/3291168.3291216,
author = {Yeo, Hyunho and Jung, Youngmok and Kim, Jaehong and Shin, Jinwoo and Han, Dongsu},
title = {Neural adaptive content-aware internet video delivery},
year = {2018},
isbn = {9781931971478},
publisher = {USENIX Association},
address = {USA},
abstract = {Internet video streaming has experienced tremendous growth over the last few decades. However, the quality of existing video delivery critically depends on the bandwidth resource. Consequently, user quality of experience (QoE) suffers inevitably when network conditions become unfavorable. We present a new video delivery framework that utilizes client computation and recent advances in deep neural networks (DNNs) to reduce the dependency for delivering high-quality video. The use of DNNs enables us to enhance the video quality independent to the available bandwidth. We design a practical system that addresses several challenges, such as client heterogeneity, interaction with bitrate adaptation, and DNN transfer, in enabling the idea. Our evaluation using 3G and broadband network traces shows the proposed system outperforms the current state of the art, enhancing the average QoE by 43.08% using the same bandwidth budget or saving 17.13% of bandwidth while providing the same user QoE.},
booktitle = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation},
pages = {645–661},
numpages = {17},
location = {Carlsbad, CA, USA},
series = {OSDI'18}
}

@proceedings{10.1145/3589132,
title = {SIGSPATIAL '23: Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The conference started as a series of workshops and symposia back in 1993 with the aim of promoting interdisciplinary discussions among researchers, developers, users, and practitioners and fostering research in all aspects of geographic information systems, especially in relation to novel systems based on geospatial data and knowledge. It continues to provide a forum for original research contributions covering all conceptual, design and implementation aspects of geospatial data ranging from applications, user interfaces and visualization, to data storage, query processing, indexing, machine learning and data mining. The conference is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL).},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3394486.3403365,
author = {Mehrotra, Prakhar and Pang, Linsey and Gopalswamy, Karthick and Thangali, Avinash and Winters, Timothy and Gupte, Ketki and Kulkarni, Dnyanesh and Potnuru, Sunil and Shastry, Supreeth and Vuyyuri, Harshada},
title = {Price Investment using Prescriptive Analytics and Optimization in Retail},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403365},
doi = {10.1145/3394486.3403365},
abstract = {As the world's largest retailer, Walmart's core mission is to save people money so they can live better. We call the strategy we use to accomplish this goal our Every Day Low Price strategy. By keeping operational expenses as low as possible, we can continually apply a downward pressure on our prices, in turn increasing the amount of traffic, and ultimately, sales within our stores. In this paper, we apply Machine Learning (ML) algorithms and Operations Research techniques for forecasting and optimization to build a new price recommendation system, which improves our ability to generate price recommendations accurately and automatically. Comprised of a demand forecasting step, two optimizations, and causal inference analysis, our system was evaluated in the form of forecast backtests and live pricing experiments, both of which suggested that our approach was more effective than the current rule-based pricing system.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3136–3144},
numpages = {9},
keywords = {bayesian structured time series, causal inference, optimization, prescriptive analytics},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1145/3507907,
author = {Rust, Pierre and Picard, Gauthier and Ramparany, Fano},
title = {Resilient Distributed Constraint Reasoning to Autonomously Configure and Adapt IoT Environments},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3507907},
doi = {10.1145/3507907},
abstract = {In this article, we investigate multi-agent techniques to install autonomy and adaptation in IoT-based smart environment settings, like smart home scenarios. We particularly make use of the smart environment configuration problem (SECP) framework, and map it to a distributed optimization problem (DCOP). This consists in enabling smart objects to coordinate and self-configure as to meet both user-defined requirements and energy efficiency, by operating a distributed constraint reasoning process over a computation graph. As to cope with the dynamics of the environment and infrastructure (e.g., by adding or removing devices), we also specify the k-resilient distribution of graph-structured computations supporting agent decisions, over dynamic and physical multi-agent systems. We implement a self-organizing distributed repair method, based on a distributed constraint optimization algorithm to adapt the distribution as to ensure the system still performs collective decisions and remains resilient to upcoming changes. We provide a full stack of mechanisms to install resilience in operating stateless DCOP solution methods, which results in a robust approach using a fast DCOP algorithm to repair any stateless DCOP solution methods at runtime. We experimentally evaluate the performances of these techniques when operating stateless DCOP algorithms to solve SECP instances.},
journal = {ACM Trans. Internet Technol.},
month = nov,
articleno = {100},
numpages = {31},
keywords = {IoT, smart home, DCOP, resilience, adaptation}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {Software performance prediction, adversarial learning, configurable systems, regularization},
location = {Bari, Italy},
series = {ESEM '20}
}

@proceedings{10.1145/3568834,
title = {ICIBE '22: Proceedings of the 8th International Conference on Industrial and Business Engineering},
year = {2022},
isbn = {9781450397582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@inproceedings{10.1145/3589334.3645404,
author = {Baek, Jinheon and Chandrasekaran, Nirupama and Cucerzan, Silviu and Herring, Allen and Jauhar, Sujay Kumar},
title = {Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645404},
doi = {10.1145/3589334.3645404},
abstract = {Large Language Models (LLMs) excel at tackling various natural language tasks. However, due to the significant costs involved in re-training or fine-tuning them, they remain largely static and difficult to personalize. Nevertheless, a variety of applications could benefit from generations that are tailored to users' preferences, goals, and knowledge. Among them is web search, where knowing what a user is trying to accomplish, what they care about, and what they know can lead to improved search experiences. In this work, we propose a novel and general approach that augments an LLM with relevant context from users' interaction histories with a search engine in order to personalize its outputs. Specifically, we construct an entity-centric knowledge store for each user based on their search and browsing activities on the web, which is then leveraged to provide contextually relevant LLM prompt augmentations. This knowledge store is light-weight, since it only produces user-specific aggregate projections of interests and knowledge onto public knowledge graphs, and leverages existing search log infrastructure, thereby mitigating the privacy, compliance, and scalability concerns associated with building deep user profiles for personalization. We validate our approach on the task of contextual query suggestion, which requires understanding not only the user's current search context but also what they historically know and care about. Through a number of experiments based on human evaluation, we show that our approach is significantly better than several other LLM-powered baselines, generating query suggestions that are contextually more relevant, personalized, and useful.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3355–3366},
numpages = {12},
keywords = {contextual query suggestion, entity-centric knowledge, large language models, personalization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3640310,
title = {MODELS '24: Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Linz, Austria}
}

@inproceedings{10.1145/3469213.3469219,
author = {Ren, Jing and Huang, Xishi},
title = {Rapid Transformation Estimation Using Deep Learning for Defect Detection},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3469219},
doi = {10.1145/3469213.3469219},
abstract = {Defect detection is a crucial step in the manufacturing of vehicle parts such as the engine. One major method for defect detection is to use image registration and image difference to identify and segment the defects. The key technology of this approach is to extract the accurate transformation information between the template image and the testing images. In this paper, we propose a novel deep neural network (DNN) method to learn the transformations from the training dataset. Wavelet transformation is introduced to denoise the images and reduce the image size for fast image registration. The results show that the trained DNN models are able to effectively predict the transformation between the template image and the actual test image in real time with high accuracy.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {6},
numpages = {5},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1145/3306346.3322957,
author = {Glauser, Oliver and Wu, Shihao and Panozzo, Daniele and Hilliges, Otmar and Sorkine-Hornung, Olga},
title = {Interactive hand pose estimation using a stretch-sensing soft glove},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3306346.3322957},
doi = {10.1145/3306346.3322957},
abstract = {We propose a stretch-sensing soft glove to interactively capture hand poses with high accuracy and without requiring an external optical setup. We demonstrate how our device can be fabricated and calibrated at low cost, using simple tools available in most fabrication labs. To reconstruct the pose from the capacitive sensors embedded in the glove, we propose a deep network architecture that exploits the spatial layout of the sensor itself. The network is trained only once, using an inexpensive off-the-shelf hand pose reconstruction system to gather the training data. The per-user calibration is then performed on-the-fly using only the glove. The glove's capabilities are demonstrated in a series of ablative experiments, exploring different models and calibration methods. Comparing against commercial data gloves, we achieve a 35% improvement in reconstruction accuracy.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {41},
numpages = {15},
keywords = {data glove, hand tracking, sensor array, stretch-sensing}
}

@inproceedings{10.1145/3038912.3052704,
author = {Wu, Chao-Yuan and Ahmed, Amr and Kumar, Gowtham Ramani and Datta, Ritendra},
title = {Predicting Latent Structured Intents from Shopping Queries},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052704},
doi = {10.1145/3038912.3052704},
abstract = {In online shopping, users usually express their intent through search queries. However, these queries are often ambiguous. For example, it is more likely (and easier) for users to write a query like "high-end bike" than "21 speed carbon frames jamis or giant road bike". It is challenging to interpret these ambiguous queries and thus search result accuracy suffers. A user oftentimes needs to go through the frustrating process of refining search queries or self-teaching from possibly unstructured information. However, shopping is indeed a structured domain, that is composed of category hierarchy, brands, product lines, features, etc. It would be much better if a shopping site could understand users' intent through this structure, present organized information, and then find the items with the right categories, brands or features.In this paper we study the problem of inferring the latent intent from unstructured queries and mapping them to structured attributes. We present a novel framework that jointly learns this knowledge from user consumption behaviors and product metadata. We present a hybrid Long Short-term Memory (LSTM) joint model that is accurate and robust, even though user queries are noisy and product catalog is rapidly growing. Our study is conducted on a large-scale dataset from Google Shopping, that is composed of millions of items and user queries along with their click responses. Extensive qualitative and quantitative evaluation shows that the proposed model is more accurate, concise, and robust than multiple possible alternatives. In terms of information retrieval (IR) performance, our model is able to improve the quality of current Google Shopping production system, which is a very strong baseline.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1133–1141},
numpages = {9},
keywords = {autoencoder, entity relationship modeling, query understanding, recurrent neural networks, shopping},
location = {Perth, Australia},
series = {WWW '17}
}

@book{10.1145/3368274,
author = {Halvorson, Michael J.},
title = {Code Nation: Personal Computing and the Learn to Program Movement in America},
year = {2020},
isbn = {9781450377584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
abstract = {Code Nation explores the rise of software development as a social, cultural, and technical phenomenon in American history. The movement germinated in government and university labs during the 1950s, gained momentum through corporate and counterculture experiments in the 1960s and 1970s, and became a broad-based computer literacy movement in the 1980s. As personal computing came to the fore, learning to program was transformed by a groundswell of popular enthusiasm, exciting new platforms, and an array of commercial practices that have been further amplified by distributed computing and the Internet. The resulting society can be depicted as a “Code Nation”—a globally-connected world that is saturated with computer technology and enchanted by software and its creation.Code Nation is a new history of personal computing that emphasizes the technical and business challenges that software developers faced when building applications for CP/M, MS-DOS, UNIX, Microsoft Windows, the Apple Macintosh, and other emerging platforms. It is a popular history of computing that explores the experiences of novice computer users, tinkerers, hackers, and power users, as well as the ideals and aspirations of leading computer scientists, engineers, educators, and entrepreneurs. Computer book and magazine publishers also played important, if overlooked, roles in the diffusion of new technical skills, and this book highlights their creative work and influence.Code Nation offers a “behind-the-scenes” look at application and operating-system programming practices, the diversity of historic computer languages, the rise of user communities, early attempts to market PC software, and the origins of “enterprise” computing systems. Code samples and over 80 historic photographs support the text. The book concludes with an assessment of contemporary efforts to teach computational thinking to young people.}
}

@proceedings{10.1145/3677052,
title = {ICAIF '24: Proceedings of the 5th ACM International Conference on AI in Finance},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Brooklyn, NY, USA}
}

@proceedings{10.1145/3634713,
title = {VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bern, Switzerland}
}

@proceedings{10.1145/3716895,
title = {ICAICE '24: Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering},
year = {2024},
isbn = {9798400718007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@book{10.1145/3694828,
author = {Wolf, Mark J. P.},
title = {Calculated Imagery: A History of Computer Graphics in Hollywood Cinema},
year = {2025},
isbn = {9798400712654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {64},
abstract = {This is a comprehensive history of computer graphics in Hollywood cinema. As the first such work of its kind, it is an essential reference for anyone interested in the history of cinema, visual effects, or computer graphics, and the industries of which they are a part.The book begins with a look at the history behind the calculation of images, from weaving to screen imaging, and the faux computer graphics used in movies before real computer graphics were available or affordable. Next, the author examines the rise of computer graphics and computer-animated films, and the gradual introduction of computer-generated imagery into the cinema. The narrative moves chronologically through the development of computer-generated animation and its use both for cartoonlike imagery and for photorealistic imagery. The author discusses behind-the-scenes uses of computer graphics in the film industry, and how these uses have impacted the kinds of imagery made and the technologies by which they are made. The book also looks at how computer animation is combined with approaches such as procedural generation and simulation, and the ways in which computers automate imagery.Throughout the book, the histories of individuals, companies, films, and computer graphics techniques are explored in detail, as well as changes in the visual effects (VFX) industry itself over time.Calculated Imagery: A History of Computer Graphics in Hollywood Cinema is for anyone interested in how CG changed the VFX industry, film history, and filmmaking overall, and the people, companies, and techniques that made it happen.“What a ride! I was like a kid in a computer-generated candy store, learning new stories about the people and origins of this amazing industry on every page. Not only is Calculated Imagery a thoroughly researched scholarly account of the entire history of CGI in the movies, it also invites the reader to follow along interactively by tracking down every link and watching each hidden gem for yourself. Thank you Mark J. P. Wolf for writing this book, so I didn’t have to!” – Ed Kramer, Chair, SIGGRAPH Pioneers Group, host CGI Fridays podcast, and former Senior Technical Director at Industrial Light &amp; Magic}
}

@article{10.1145/3654439,
author = {Gavidia-Calderon, Carlos and Kordoni, Anastasia and Bennaceur, Amel and Levine, Mark and Nuseibeh, Bashar},
title = {The IDEA of Us: An Identity-Aware Architecture for Autonomous Systems},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3654439},
doi = {10.1145/3654439},
abstract = {Autonomous systems, such as drones and rescue robots, are increasingly used during emergencies. They deliver services and provide situational awareness that facilitate emergency management and response. To do so, they need to interact and cooperate with humans in their environment. Human behaviour is uncertain and complex, so it can be difficult to reason about it formally. In this article, we propose IDEA: an adaptive software architecture that enables cooperation between humans and autonomous systems, by leveraging the social identity approach. This approach establishes that group membership drives human behaviour. Identity and group membership are crucial during emergencies, as they influence cooperation among survivors. IDEA systems infer the social identity of surrounding humans, thereby establishing their group membership. By reasoning about groups, we limit the number of cooperation strategies the system needs to explore. IDEA systems select a strategy from the equilibrium analysis of game-theoretic models that represent interactions between group members and the IDEA system. We demonstrate our approach using a search-and-rescue scenario, in which an IDEA rescue robot optimises evacuation by collaborating with survivors. Using an empirically validated agent-based model, we show that the deployment of the IDEA system can reduce median evacuation time by 13.6%.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {164},
numpages = {38},
keywords = {Autonomous systems, game theory, social identity, agent-based modelling}
}

@proceedings{10.1145/3571788,
title = {VaMoS '23: Proceedings of the 17th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2023},
isbn = {9798400700019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Odense, Denmark}
}

@article{10.1145/3691643,
author = {Do\u{g}ru, An\i{}l and Keskin, Mehmet Onur and Aydo\u{g}an, Reyhan},
title = {Taking into Account Opponent’s Arguments in Human-Agent Negotiations},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/3691643},
doi = {10.1145/3691643},
abstract = {Autonomous negotiating agents, which can interact with other agents, aim to solve decision-making problems involving participants with conflicting interests. Designing agents capable of negotiating with human partners requires considering some factors, such as emotional states and arguments. For this purpose, we introduce an extended taxonomy of argument types capturing human speech acts during the negotiation. We propose an argument-based automated negotiating agent that can extract human arguments from a chat-based environment using a hierarchical classifier. Consequently, the proposed agent can understand the received arguments and adapt its strategy accordingly while negotiating with its human counterparts. We initially conducted human-agent negotiation experiments to construct a negotiation corpus to train our classifier. According to the experimental results, it is seen that the proposed hierarchical classifier successfully extracted the arguments from the given text. Moreover, we conducted a second experiment where we tested the performance of the designed negotiation strategy considering the human opponent’s arguments and emotions. Our results showed that the proposed agent beats the human negotiator and gains higher utility than the baseline agent.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {2},
numpages = {35},
keywords = {Human-Agent Negotiation, Argumentation, Opponent Modeling}
}

@inbook{10.1145/3694828.3694839,
title = {Computer Graphics Behind the Scenes},
year = {2025},
isbn = {9798400712654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694828.3694839},
abstract = {This is a comprehensive history of computer graphics in Hollywood cinema. As the first such work of its kind, it is an essential reference for anyone interested in the history of cinema, visual effects, or computer graphics, and the industries of which they are a part.The book begins with a look at the history behind the calculation of images, from weaving to screen imaging, and the faux computer graphics used in movies before real computer graphics were available or affordable. Next, the author examines the rise of computer graphics and computer-animated films, and the gradual introduction of computer-generated imagery into the cinema. The narrative moves chronologically through the development of computer-generated animation and its use both for cartoonlike imagery and for photorealistic imagery. The author discusses behind-the-scenes uses of computer graphics in the film industry, and how these uses have impacted the kinds of imagery made and the technologies by which they are made. The book also looks at how computer animation is combined with approaches such as procedural generation and simulation, and the ways in which computers automate imagery.Throughout the book, the histories of individuals, companies, films, and computer graphics techniques are explored in detail, as well as changes in the visual effects (VFX) industry itself over time.Calculated Imagery: A History of Computer Graphics in Hollywood Cinema is for anyone interested in how CG changed the VFX industry, film history, and filmmaking overall, and the people, companies, and techniques that made it happen.“What a ride! I was like a kid in a computer-generated candy store, learning new stories about the people and origins of this amazing industry on every page. Not only is Calculated Imagery a thoroughly researched scholarly account of the entire history of CGI in the movies, it also invites the reader to follow along interactively by tracking down every link and watching each hidden gem for yourself. Thank you Mark J. P. Wolf for writing this book, so I didn’t have to!” – Ed Kramer, Chair, SIGGRAPH Pioneers Group, host CGI Fridays podcast, and former Senior Technical Director at Industrial Light &amp; Magic},
booktitle = {Calculated Imagery: A History of Computer Graphics in Hollywood Cinema}
}

@proceedings{10.1145/3688671,
title = {SETN '24: Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
year = {2024},
isbn = {9798400709821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3622748,
title = {SBCARS '23: Proceedings of the 17th Brazilian Symposium on Software Components, Architectures, and Reuse},
year = {2023},
isbn = {9798400709524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@article{10.1145/3685695,
author = {Greenlee, Eric and Rothrock, Blaine and Kim, Hyeonwook and Zegura, Ellen and Hester, Josiah},
title = {“The Devil You Know”: Barriers and Opportunities for Co-Designing Microclimate Sensors, A Case Study of Manoomi},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3685695},
doi = {10.1145/3685695},
abstract = {Current environmental challenges have profound local consequences and often benefit from the collection of fine-grained microclimate data. Advances in wireless sensor networks and the Internet of Things have led to technologies nominally suited to support remote sensing; however, in practice long-running deployments of in-field environmental sensors are rare. Field conditions are often remote and culturally sensitive, with limited power, Internet, transportation, and human infrastructure; advances in device technology alone will not suffice. We ask how communities, Internet of Things researchers, government, and other interested parties can work together to co-design useful, low burden, sustainability-focused infrastructure. Toward this end, we conducted 11 semi-structured interviews with 13 experts who use or rely on environmental sensing technology. To complement our interview data, we engaged in three months of participant observation while immersed in organizations specifically working toward manoomin (wild rice) conservation. We make two primary contributions. First, we confirm and enrich a five-stage model, the microclimate sensor lifecycle, focusing on desired features and persistent challenges. Second, we outline a space for co-design of microclimate sensors with emphasis on the cost of experience, the generally unaddressed issue of technical usability in the messy field, and the opportunity for community engagement to improve technical design and outcomes. Furthermore, we discuss future design opportunities, recommendations, and challenges in the microclimate sensor design, deployment, and sustainability space.},
journal = {ACM J. Comput. Sustain. Soc.},
month = sep,
articleno = {39},
numpages = {30},
keywords = {Environmental Sensors, Co-design, Community Engagement}
}

@proceedings{10.1145/3652920,
title = {AHs '24: Proceedings of the Augmented Humans International Conference 2024},
year = {2024},
isbn = {9798400709807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3600046,
title = {DEC '23: Proceedings of the Second ACM Data Economy Workshop},
year = {2023},
isbn = {9798400708466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3603166,
title = {UCC '23: Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
year = {2023},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Utility and Cloud Computing (UCC) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of Cloud and Edge utility computing and applications.},
location = {Taormina (Messina), Italy}
}

@inbook{10.1145/3694828.3694838,
title = {Photorealistic Computer Graphics},
year = {2025},
isbn = {9798400712654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694828.3694838},
abstract = {This is a comprehensive history of computer graphics in Hollywood cinema. As the first such work of its kind, it is an essential reference for anyone interested in the history of cinema, visual effects, or computer graphics, and the industries of which they are a part.The book begins with a look at the history behind the calculation of images, from weaving to screen imaging, and the faux computer graphics used in movies before real computer graphics were available or affordable. Next, the author examines the rise of computer graphics and computer-animated films, and the gradual introduction of computer-generated imagery into the cinema. The narrative moves chronologically through the development of computer-generated animation and its use both for cartoonlike imagery and for photorealistic imagery. The author discusses behind-the-scenes uses of computer graphics in the film industry, and how these uses have impacted the kinds of imagery made and the technologies by which they are made. The book also looks at how computer animation is combined with approaches such as procedural generation and simulation, and the ways in which computers automate imagery.Throughout the book, the histories of individuals, companies, films, and computer graphics techniques are explored in detail, as well as changes in the visual effects (VFX) industry itself over time.Calculated Imagery: A History of Computer Graphics in Hollywood Cinema is for anyone interested in how CG changed the VFX industry, film history, and filmmaking overall, and the people, companies, and techniques that made it happen.“What a ride! I was like a kid in a computer-generated candy store, learning new stories about the people and origins of this amazing industry on every page. Not only is Calculated Imagery a thoroughly researched scholarly account of the entire history of CGI in the movies, it also invites the reader to follow along interactively by tracking down every link and watching each hidden gem for yourself. Thank you Mark J. P. Wolf for writing this book, so I didn’t have to!” – Ed Kramer, Chair, SIGGRAPH Pioneers Group, host CGI Fridays podcast, and former Senior Technical Director at Industrial Light &amp; Magic},
booktitle = {Calculated Imagery: A History of Computer Graphics in Hollywood Cinema}
}

@proceedings{10.1145/3626232,
title = {CODASPY '24: Proceedings of the Fourteenth ACM Conference on Data and Application Security and Privacy},
year = {2024},
isbn = {9798400704215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the fourteenth edition of the ACM Conference on Data and Application Security and Privacy (CODASPY 2024), for the first time held outside United States of America. This conference series has been founded to foster novel and exciting research in the data and application security and privacy arena and to help generate new directions for further research and development. The initial concept was established by the two co-founders, Elisa Bertino and Ravi Sandhu, and sharpened by subsequent discussions with several fellow data security and privacy researchers. Their enthusiastic encouragement persuaded the co-founders to move ahead with the always daunting task of creating a high-quality conference. CODASPY has become a leading forum for presentation of research results and experience reports on hardware and software security. The conference gives researchers and practitioners a unique opportunity to share their perspectives with others interested in the various aspects of data and applications security and privacy.},
location = {Porto, Portugal}
}

@proceedings{10.1145/3640457,
title = {RecSys '24: Proceedings of the 18th ACM Conference on Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bari, Italy}
}

@inproceedings{10.1109/SC41406.2024.00058,
author = {Lu, Yuechen and Zeng, Lijie and Wang, Tengcheng and Fu, Xu and Li, Wenxuan and Cheng, Helin and Yang, Dechuang and Jin, Zhou and Casas, Marc and Liu, Weifeng},
title = {AmgT: Algebraic Multigrid Solver on Tensor Cores},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00058},
doi = {10.1109/SC41406.2024.00058},
abstract = {Algebraic multigrid (AMG) methods are particularly efficient to solve a wide range of sparse linear systems, due to their good flexibility and adaptability. Even though modern parallel devices, such as GPUs, brought massive parallelism to AMG, the latest major hardware features, i.e., tensor core units and their low precision compute power, have not been exploited to accelerate AMG.This paper proposes AmgT, a new AMG solver that utilizes the tensor core and mixed precision ability of the latest GPUs during multiple phases of the AMG algorithm. Considering that the sparse general matrix-matrix multiplication (SpGEMM) and sparse matrix-vector multiplication (SpMV) are extensively used in the setup and solve phases, respectively, we propose a novel method based on a new unified sparse storage format that leverages tensor cores and their variable precision. Our method improves both the performance of GPU kernels, and also reduces the cost of format conversion in the whole data flow of AMG. To better utilize the algorithm components in existing libraries, the data format and compute kernels of the AmgT solver are incorporated into the HYPRE library. The experimental results on NVIDIA A100, H100 and AMD MI210 GPUs show that our AmgT outperforms the original GPU version of HYPRE by a factor of on geomean 1.46\texttimes{}, 1.32\texttimes{} and 2.24\texttimes{}(up to 2.10\texttimes{}, 2.06\texttimes{} and 3.67\texttimes{}), respectively.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {52},
numpages = {16},
keywords = {AMG, SpGEMM, SpMV, mixed precision, tensor core unit},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@proceedings{10.1145/3607947,
title = {IC3-2023: Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@proceedings{10.1145/3603287,
title = {ACMSE '24: Proceedings of the 2024 ACM Southeast Conference},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome you to the 2024 ACM Southeast Conference (ACMSE 2024) sponsored by ACM and the College of Computing and Software Engineering (CCSE) at Kennesaw State University, Marietta, Georgia, USA. ACMSE 2024 continues the ACM Southeast Conference tradition of participation in all areas of computing disciplines. We hope this conference will be an excellent opportunity to share current and future hot research trends amongst researchers from around the world.},
location = {Marietta, GA, USA}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@inproceedings{10.1145/1985793.1985819,
author = {Dumitru, Horatiu and Gibiec, Marek and Hariri, Negar and Cleland-Huang, Jane and Mobasher, Bamshad and Castro-Herrera, Carlos and Mirakhorli, Mehdi},
title = {On-demand feature recommendations derived from mining public product descriptions},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985819},
doi = {10.1145/1985793.1985819},
abstract = {We present a recommender system that models and recommends product features for a given domain. Our approach mines product descriptions from publicly available online specifications, utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain-specific features, generates a probabilistic feature model that represents commonalities, variants, and cross-category features, and then uses association rule mining and the k-Nearest-Neighbor machine learning strategy to generate product specific feature recommendations. Our recommender system supports the relatively labor-intensive task of domain analysis, potentially increasing opportunities for re-use, reducing time-to-market, and delivering more competitive software products. The approach is empirically validated against 20 different product categories using thousands of product descriptions mined from a repository of free software applications.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {181–190},
numpages = {10},
keywords = {clustering, domain analysis, recommender systems},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3368089.3409675,
author = {Siegmund, Norbert and Ruckel, Nicolai and Siegmund, Janet},
title = {Dimensions of software configuration: on the configuration context in modern software development},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409675},
doi = {10.1145/3368089.3409675},
abstract = {With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure. This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined. However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings, translate them to practice, and to generalize the results. Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {338–349},
numpages = {12},
keywords = {Dimensions of software configuration, configuration management and life cycle, developer study, variability},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3660515,
title = {EICS '24 Companion: Companion Proceedings of the 16th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
year = {2024},
isbn = {9798400706516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cagliari, Italy}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3698038,
title = {SoCC '24: Proceedings of the 2024 ACM Symposium on Cloud Computing},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Redmond, WA, USA}
}

@proceedings{10.1145/3677333,
title = {ICPP Workshops '24: Workshop Proceedings of the 53rd International Conference on Parallel Processing},
year = {2024},
isbn = {9798400718021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gotland, Sweden}
}

@proceedings{10.1109/3655039,
title = {ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.},
location = {Incheon, Republic of Korea}
}

@proceedings{10.1145/3594806,
title = {PETRA '23: Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Corfu, Greece}
}

@proceedings{10.1145/3607199,
title = {RAID '23: Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, China}
}

@proceedings{10.1145/3559712,
title = {SBCARS '22: Proceedings of the 16th Brazilian Symposium on Software Components, Architectures, and Reuse},
year = {2022},
isbn = {9781450397452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Uberlandia, Brazil}
}

@proceedings{10.1145/3604915,
title = {RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3528227,
title = {SERP4IoT '22: Proceedings of the 4th International Workshop on Software Engineering Research and Practice for the IoT},
year = {2022},
isbn = {9781450393324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SERP4IoT begins to be recognised as an annual venue gathering researchers, industrials, and practitioners to share their vision, experience, and opinion on how to address the challenges of, find solutions for, and share experiences with the development, release, and testing of robust software systems for IoT devices.},
location = {Pittsburgh, Pennsylvania}
}

@proceedings{10.1145/3575879,
title = {PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatics},
year = {2022},
isbn = {9781450398541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Athens, Greece}
}

@proceedings{10.1145/3675417,
title = {DEAI '24: Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hongkong, China}
}

@proceedings{10.1145/3670105,
title = {CNIOT '24: Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

@proceedings{10.1145/3606843,
title = {ITCC '23: Proceedings of the 2023 5th International Conference on Information Technology and Computer Communications},
year = {2023},
isbn = {9798400700583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tianjin, China}
}

@proceedings{10.1145/3629264,
title = {ICCDA '23: Proceedings of the 2023 7th International Conference on Computing and Data Analysis},
year = {2023},
isbn = {9798400700576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guiyang, China}
}

@proceedings{10.1145/3701625,
title = {SBQS '24: Proceedings of the XXIII Brazilian Symposium on Software Quality},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3563357,
title = {BuildSys '22: Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2022},
isbn = {9781450398909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Over the past thirteen years, BuildSys has been an interdisciplinary conference that brings together various stakeholders, including researchers, practitioners, and policymakers from different disciplines, including civil engineering, mechanical engineering, environmental science, electrical and computer engineering, computer science, system management and control, and many others. This year is no exception, with papers and attendees from all these disciplines and regions worldwide. The conference's focus extends beyond building systems to the built environment more generally.},
location = {Boston, Massachusetts}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@inproceedings{10.1145/3486607.3486753,
author = {Jouneaux, Gwendal and Barais, Olivier and Combemale, Benoit and Mussbacher, Gunter},
title = {Towards self-adaptable languages},
year = {2021},
isbn = {9781450391108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486607.3486753},
doi = {10.1145/3486607.3486753},
abstract = {Over recent years, self-adaptation has become a concern for many software systems that have to operate in complex and changing environments. At the core of self-adaptation, there is a feedback loop and associated trade-off reasoning to decide on the best course of action. However, existing software languages do not abstract the development and execution of such feedback loops for self-adaptable systems. Developers have to fall back to ad-hoc solutions to implement self-adaptable systems, often with wide-ranging design implications (e.g., explicit MAPE-K loop). Furthermore, existing software languages do not capitalize on monitored usage data of a language and its modeling environment. This hinders the continuous and automatic evolution of a software language based on feedback loops from the modeling environment and runtime software system. To address the aforementioned issues, this paper introduces the concept of Self-Adaptable Language (SAL) to abstract the feedback loops at both system and language levels. We propose L-MODA (Language, Models, and Data) as a conceptual reference framework that characterizes the possible feedback loops abstracted into a SAL. To demonstrate SALs, we present emerging results on the abstraction of the system feedback loop into the language semantics. We report on the concept of Self-Adaptable Virtual Machines as an example of semantic adaptation in a language interpreter and present a roadmap for SALs.},
booktitle = {Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {97–113},
numpages = {17},
keywords = {L-MODA framework, feedback loop, self-adaptation, software language, trade-off analysis},
location = {Chicago, IL, USA},
series = {Onward! 2021}
}

@proceedings{10.1145/3677182,
title = {ASENS '24: Proceedings of the International Conference on Algorithms, Software Engineering, and Network Security},
year = {2024},
isbn = {9798400709784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@proceedings{10.1145/3624875,
title = {MISNC '23: Proceedings of the 10th Multidisciplinary International Social Networks Conference},
year = {2023},
isbn = {9798400708176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@article{10.1145/3647640,
author = {Jord\~{a}o, Rodolfo and Becker, Matthias and Sander, Ingo},
title = {IDeSyDe: Systematic Design Space Exploration via Design Space Identification},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3647640},
doi = {10.1145/3647640},
abstract = {Design space exploration (DSE) is a key activity in embedded design processes, where a mapping between applications and platforms that meets the process design requirements must be found. Finding such mappings is very challenging due to the complexity of modern embedded platforms and applications. DSE tools aid in this challenge by potentially covering sections of the design space that could be unintuitive to designers, leading to more optimised designs. Despite this potential benefit, DSE tools remain relatively niche in the embedded industry. A significant obstacle hindering their wider adoption is integrating such tools into embedded design processes.We present two contributions that address this integration issue. First, we present the design space identification (DSI) approach for systematically constructing DSE solutions that are modular and tuneable. Modularity means that DSE solutions can be reused to construct other DSE solutions, while tuneability means that the most specific DSE solution is chosen for the target DSE problem. Moreover, DSI enables transparent cooperation between exploration algorithms. Second, we present IDeSyDe, an extensible DSE framework for DSE solutions based on DSI. IDeSyDe allows extensions to be developed in different programming languages in a manner compliant with the DSI approach.We showcase the relevance of these contributions through five different case studies. The case study evaluations showed that non-exploration DSI procedures create overheads, which are marginal compared to the exploration algorithms. Empirically, most evaluations average 2% of the total DSE request. More importantly, the case studies have shown that IDeSyDe indeed provides a modular and incremental framework for constructing DSE solutions. In particular, the last case study required minimal extensions over the previous case studies so that support for a new application type was added to IDeSyDe.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = sep,
articleno = {87},
numpages = {45},
keywords = {Design space exploration, design space identification, embedded system design}
}

@proceedings{10.1145/3573428,
title = {EITCE '22: Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
year = {2022},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3624288,
title = {ICBDC '23: Proceedings of the 2023 8th International Conference on Big Data and Computing},
year = {2023},
isbn = {9781450399975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@proceedings{10.1145/3538969,
title = {ARES '22: Proceedings of the 17th International Conference on Availability, Reliability and Security},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@article{10.1145/3476052,
author = {Kross, Sean and Guo, Philip},
title = {Orienting, Framing, Bridging, Magic, and Counseling: How Data Scientists Navigate the Outer Loop of Client Collaborations in Industry and Academia},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3476052},
doi = {10.1145/3476052},
abstract = {Data scientists often collaborate with clients to analyze data to meet a client's needs. What does the end-to-end workflow of a data scientist's collaboration with clients look like throughout the lifetime of a project? To investigate this question, we interviewed ten data scientists (5 female, 4 male, 1 non-binary) in diverse roles across industry and academia. We discovered that they work with clients in a six-stage outer-loop workflow, which involves 1) laying groundwork by building trust before a project begins, 2) orienting to the constraints of the client's environment, 3) collaboratively framing the problem, 4) bridging the gap between data science and domain expertise, 5) the inner loop of technical data analysis work, 6) counseling to help clients emotionally cope with analysis results. This novel outer-loop workflow contributes to CSCW by expanding the notion of what collaboration means in data science beyond the widely-known inner-loop technical workflow stages of acquiring, cleaning, analyzing, modeling, and visualizing data. We conclude by discussing the implications of our findings for data science education, parallels to design work, and unmet needs for tool development.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {311},
numpages = {28},
keywords = {collaborative work, data science, interview study}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@proceedings{10.1145/3571697,
title = {ESSE '22: Proceedings of the 2022 European Symposium on Software Engineering},
year = {2022},
isbn = {9781450397308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3539637,
title = {WebMedia '22: Proceedings of the Brazilian Symposium on Multimedia and the Web},
year = {2022},
isbn = {9781450394093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Curitiba, Brazil}
}

@proceedings{10.1145/3569966,
title = {CSSE '22: Proceedings of the 5th International Conference on Computer Science and Software Engineering},
year = {2022},
isbn = {9781450397780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@proceedings{10.1145/3581791,
title = {MobiSys '23: Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the entire organizing committee, it is with immense pleasure that we welcome you to the 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023) hosted in Helsinki, Finland on June 18 - 22, 2023. ACM MobiSys is the leading conference in research on mobile systems, applications and services, and a flagship conference of ACM SIGMOBILE.},
location = {Helsinki, Finland}
}

@proceedings{10.1145/3689492,
title = {Onward! '24: Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2024), the premier multidisciplinary conference focused on everything to do with programming and software, including processes, methods, languages, communities and applications. Onward! is more radical, more visionary and more open than other conferences to ideas that are well-argued but not yet proven. We welcome different ways of thinking about, approaching, and reporting on programming language and software engineering research.},
location = {Pasadena, CA, USA}
}

@article{10.1145/3659098,
author = {Maciel, Rita Suzana Pitangueira and Valle, Pedro Henrique Dias and Santos, K\'{e}cia Souza and Nakagawa, Elisa Yumi},
title = {Systems Interoperability Types: A Tertiary Study},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3659098},
doi = {10.1145/3659098},
abstract = {Interoperability has been a focus of attention over at least four decades, with the emergence of several interoperability types (or levels), diverse models, frameworks, and solutions, also as a result of a continuous effort from different domains. The current heterogeneity in technologies such as blockchain, IoT and new application domains such as Industry 4.0 brings not only new interaction possibilities but also challenges for interoperability. Moreover, confusion and ambiguity in the current understanding of interoperability types exist, hampering stakeholders’ communication and decision-making. This work presents an updated panorama of software-intensive systems interoperability with particular attention to its types. For this, we conducted a tertiary study that scrutinized 37 secondary studies published from 2012 to 2023, from which we found 36 interoperability types associated with 117 different definitions, besides 13 interoperability models and six frameworks in various domains. This panorama reveals that the concern with interoperability has migrated from technical to social-technical issues going beyond the software systems’ boundary and still requiring solving many open issues. We also address the urgent actions and also potential research opportunities to leverage interoperability as a multidisciplinary research field to achieve low-coupled, cost-effective, and interoperable systems.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {254},
numpages = {37},
keywords = {Interoperability type, interoperability model, interoperability framework, tertiary study}
}

@proceedings{10.1145/3545729,
title = {ICMHI '22: Proceedings of the 6th International Conference on Medical and Health Informatics},
year = {2022},
isbn = {9781450396301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Japan}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@article{10.1145/3571854,
author = {Zampetti, Fiorella and Tamburri, Damian and Panichella, Sebastiano and Panichella, Annibale and Canfora, Gerardo and Di Penta, Massimiliano},
title = {Continuous Integration and Delivery Practices for Cyber-Physical Systems: An Interview-Based Study},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3571854},
doi = {10.1145/3571854},
abstract = {Continuous Integration and Delivery (CI/CD) practices have shown several benefits for software development and operations, such as faster release cycles and early discovery of defects. For Cyber-Physical System (CPS) development, CI/CD can help achieving required goals, such as high dependability, yet it may be challenging to apply. This article empirically investigates challenges, barriers, and their mitigation occurring when applying CI/CD practices to develop CPSs in 10 organizations working in eight different domains. The study has been conducted through semi-structured interviews, by applying an open card sorting procedure together with a member-checking survey within the same organizations, and by validating the results through a further survey involving 55 professional developers. The study reveals several peculiarities in the application of CI/CD to CPSs. These include the need for (i) combining continuous and periodic builds while balancing the use of Hardware-in-the-Loop and simulators, (ii) coping with difficulties in software deployment (iii) accounting for simulators and Hardware-in-the-Loop differing in their behavior, and (vi) combining hardware/software expertise in the development team. Our findings open the road toward recommenders aimed at supporting the setting and evolution of CI/CD pipelines, as well as university curricula requiring interdisciplinarity, such as knowledge about hardware, software, and their interplay.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {73},
numpages = {44},
keywords = {Continuous Integration and Delivery, Cyber-Physical Systems, empirical software engineering}
}

@proceedings{10.1145/3705677,
title = {CITCE '24: Proceedings of the 4th International Conference on Computer, Internet of Things and Control Engineering},
year = {2024},
isbn = {9798400711848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3566099,
title = {AIIOT '22: Proceedings of the 1st Workshop on Digital Twin &amp; Edge AI for Industrial IoT},
year = {2022},
isbn = {9781450397841},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3627508,
title = {CHIIR '24: Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sheffield, United Kingdom}
}

@article{10.1145/3610880,
author = {Mamish, John and Guo, Amy and Cohen, Thomas and Richey, Julian and Zhang, Yang and Hester, Josiah},
title = {Interaction Harvesting: A Design Probe of User-Powered Widgets},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610880},
doi = {10.1145/3610880},
abstract = {Whenever a user interacts with a device, mechanical work is performed to actuate the user interface elements; the resulting energy is typically wasted, dissipated as sound and heat. Previous work has shown that many devices can be powered entirely from this otherwise wasted user interface energy. For these devices, wires and batteries, along with the related hassles of replacement and charging, become unnecessary and onerous. So far, these works have been restricted to proof-of-concept demonstrations; a specific bespoke harvesting and sensing circuit is constructed for the application at hand. The challenge of harvesting energy while simultaneously sensing fine-grained input signals from diverse modalities makes prototyping new devices difficult. To fill this gap, we present a hardware toolkit which provides a common electrical interface for harvesting energy from user interface elements. This facilitates exploring the composability, utility, and breadth of enabled applications of interaction-powered smart devices. We design a set of "energy as input" harvesting circuits, a standard connective interface with 3D printed enclosures, and software libraries to enable the exploration of devices where the user action generates the energy needed to perform the device's primary function. This exploration culminated in a demonstration campaign where we prototype several exemplar popular toys and gadgets, including battery-free Bop-It--- a popular 90s rhythm game, an electronic Etch-a-sketch, a "Simon-Says"-style memory game, and a service rating device. We run exploratory user studies to understand how generativity, creativity, and composability are hampered or facilitated by these devices. These demonstrations, user study takeaways, and the toolkit itself provide a foundation for building interactive and user-focused gadgets whose usability is not affected by battery charge and whose service lifetime is not limited by battery wear.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {112},
numpages = {31},
keywords = {Bop-it, Embedded, Energy Harvesting, Interaction Power}
}

@proceedings{10.1145/3629378,
title = {ICIBE '23: Proceedings of the 2023 9th International Conference on Industrial and Business Engineering},
year = {2023},
isbn = {9798400708824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@proceedings{10.1145/3526071,
title = {RoSE '22: Proceedings of the 4th International Workshop on Robotics Software Engineering},
year = {2022},
isbn = {9781450393171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Software engineering is a crucial enabler for successful deployment of robotic applications. The research communities advancing software engineering in robotics, however, are spread over various spe-cialized conferences, such as ICRA, IROS, SIMPAR - each attended mostly by robotics researchers and practitioners - or ICSE andMODELS - mostly attended by software engineering researchers and practitioners. At robotics conferences, software engineering lacks visibility and vice versa.The objective of RoSE is bringing together researchers and practitioners from both domains at a prominent conference to foster cross-fertilization between the two domains. Being the most prominent conference in software engineering, ICSE is the best venue to attract experts from both domains. Hosting this workshop at ICSE enables software engineering researchers to learn more about the challenges of robotics practitioners that (i) require further research from the software engineering community or (ii) are already solved but solutions are unnoticed by roboticists, yet.},
location = {Pittsburgh, Pennsylvania}
}

@article{10.1145/3494519,
author = {Marijan, Dusica and Sen, Sagar},
title = {Industry–Academia Research Collaboration and Knowledge Co-creation: Patterns and Anti-patterns},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3494519},
doi = {10.1145/3494519},
abstract = {Increasing the impact of software engineering research in the software industry and the society at large has long been a concern of high priority for the software engineering community. The problem of two cultures, research conducted in a vacuum (disconnected from the real world), or misaligned time horizons are just some of the many complex challenges standing in the way of successful industry–academia collaborations. This article reports on the experience of research collaboration and knowledge co-creation between industry and academia in software engineering as a way to bridge the research–practice collaboration gap. Our experience spans 14 years of collaboration between researchers in software engineering and the European and Norwegian software and IT industry. Using the participant observation and interview methods, we have collected and afterwards analyzed an extensive record of qualitative data. Drawing upon the findings made and the experience gained, we provide a set of 14 patterns and 14 anti-patterns for industry–academia collaborations, aimed to support other researchers and practitioners in establishing and running research collaboration projects in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {45},
numpages = {52},
keywords = {Industry-academia collaboration, research collaboration, research co-creation, software engineering, technology transfer, knowledge transfer, collaboration gap, collaboration model, patterns, anti-patterns}
}

@proceedings{10.1145/3508352,
title = {ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Jointly sponsored by ACM and IEEE, ICCAD is the premier forum to explore new challenges, present leading-edge innovative solutions, and identify emerging technologies in the Electronic Design Automation (EDA) research areas. ICCAD covers the full range of Computer-Aided Design (CAD) topics - from device and circuit-level up through system-level, as well as post-CMOS design.},
location = {San Diego, California}
}

@proceedings{10.1145/3576841,
title = {ICCPS '23: Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023)},
year = {2023},
isbn = {9798400700361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Antonio, TX, USA}
}

@article{10.1145/3517189,
author = {Suhail, Sabah and Hussain, Rasheed and Jurdak, Raja and Oracevic, Alma and Salah, Khaled and Hong, Choong Seon and Matulevi\v{c}ius, Raimundas},
title = {Blockchain-Based Digital Twins: Research Trends, Issues, and Future Challenges},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3517189},
doi = {10.1145/3517189},
abstract = {Industrial processes rely on sensory data for decision-making processes, risk assessment, and performance evaluation. Extracting actionable insights from the collected data calls for an infrastructure that can ensure the dissemination of trustworthy data. For the physical data to be trustworthy, it needs to be cross validated through multiple sensor sources with overlapping fields of view. Cross-validated data can then be stored on the blockchain, to maintain its integrity and trustworthiness. Once trustworthy data is recorded on the blockchain, product lifecycle events can be fed into data-driven systems for process monitoring, diagnostics, and optimized control. In this regard, digital twins (DTs) can be leveraged to draw intelligent conclusions from data by identifying the faults and recommending precautionary measures ahead of critical events. Empowering DTs with blockchain in industrial use cases targets key challenges of disparate data repositories, untrustworthy data dissemination, and the need for predictive maintenance. In this survey, while highlighting the key benefits of using blockchain-based DTs, we present a comprehensive review of the state-of-the-art research results for blockchain-based DTs. Based on the current research trends, we discuss a trustworthy blockchain-based DTs framework. We also highlight the role of artificial intelligence in blockchain-based DTs. Furthermore, we discuss the current and future research and deployment challenges of blockchain-supported DTs that require further investigation.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {240},
numpages = {34},
keywords = {Artificial intelligence (AI), blockchain, cyber-physical systems (CPSs), digital twins (DTs), industrial control systems (ICSs), Internet of Things (IoT), Industry 4.0}
}

@proceedings{10.1145/3689050,
title = {TEI '25: Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3623476,
title = {SLE 2023: Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM SIGPLAN International Conference on Software Language Engineering (SLE) held in October 2023 as part of SPLASH 2023. Software Language Engineering (SLE) is a thriving research discipline targeted at establishing an engineering approach to the development, use, and maintenance of software languages, that is, of languages for the specification, modeling and tooling of software. Key topics of interest for SLE include approaches, methodologies and tools for language design and implementation with a focus on techniques for static and behavioral semantics, generative or interpretative approaches (including transformation languages and code generation) as well as meta-languages and tools (including language workbenches). Techniques enabling the testing, simulation or formal verification for language validation purposes are also of particular interest. SLE also accommodates empirical evaluation and experience reports of language engineering tools, such as user studies evaluating usability, performance benchmarks or industrial applications.},
location = {Cascais, Portugal}
}

@inproceedings{10.1145/3478384.3478408,
author = {Lostanlen, Vincent and Bernabeu, Antoine and B\'{e}chennec, Jean-Luc and Briday, Mika\"{e}l and Faucou, S\'{e}bastien and Lagrange, Mathieu},
title = {Energy Efficiency is Not Enough:Towards a Batteryless Internet of Sounds},
year = {2021},
isbn = {9781450385695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478384.3478408},
doi = {10.1145/3478384.3478408},
abstract = {This position paper advocates for digital sobriety in the design and usage of wireless acoustic sensors. As of today, these devices all rely on batteries, which are either recharged by a human operator or via solar panels. Yet, batteries contain chemical pollutants and have a shorter lifespan than electronic components: as such, they hinder the autonomy and sustainability of the Internet of Sounds at large. Against this problem, our radical answer is to avoid the use of batteries altogether; and instead, to harvest ambient energy in real time and store it in a supercapacitor allowing a few minutes of operation. We show the inherent limitations of battery-dependent technologies for acoustic sensing. Then, we describe how a low-cost Micro-Controller Unit (MCU) could serve for audio acquisition and feature extraction on the edge. In particular, we stress the advantage of storing intermediate computations in ferroelectric random-access memory (FeRAM), which is nonvolatile, fast, endurant and consumes little. As a proof of concept, we present a simple-minded detector of sine tones in background noise, which relies on a fixed-point implementation of the fast Fourier transform (FFT). We outline future directions towards bioacoustic event detection and urban acoustic monitoring without batteries nor wires.},
booktitle = {Proceedings of the 16th International Audio Mostly Conference},
pages = {147–155},
numpages = {9},
keywords = {acoustic sensor networks, batteryless computing, digital sobriety, intermittent computing, nonvolatile random access memory},
location = {virtual/Trento, Italy},
series = {AM '21}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@proceedings{10.1145/3607505,
title = {CSET '23: Proceedings of the 16th Cyber Security Experimentation and Test Workshop},
year = {2023},
isbn = {9798400707889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Marina del Rey, CA, USA}
}

@proceedings{10.1145/3527188,
title = {HAI '22: Proceedings of the 10th International Conference on Human-Agent Interaction},
year = {2022},
isbn = {9781450393232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Christchurch, New Zealand}
}

@proceedings{10.1145/3603955,
title = {MSIE '23: Proceedings of the 2023 5th International Conference on Management Science and Industrial Engineering},
year = {2023},
isbn = {9798400708381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chiang Mai, Thailand}
}

@inproceedings{10.1145/2535838.2535857,
author = {Li, Yi and Albarghouthi, Aws and Kincaid, Zachary and Gurfinkel, Arie and Chechik, Marsha},
title = {Symbolic optimization with SMT solvers},
year = {2014},
isbn = {9781450325448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2535838.2535857},
doi = {10.1145/2535838.2535857},
abstract = {The rise in efficiency of Satisfiability Modulo Theories (SMT) solvers has created numerous uses for them in software verification, program synthesis, functional programming, refinement types, etc. In all of these applications, SMT solvers are used for generating satisfying assignments (e.g., a witness for a bug) or proving unsatisfiability/validity(e.g., proving that a subtyping relation holds). We are often interested in finding not just an arbitrary satisfying assignment, but one that optimizes (minimizes/maximizes) certain criteria. For example, we might be interested in detecting program executions that maximize energy usage (performance bugs), or synthesizing short programs that do not make expensive API calls. Unfortunately, none of the available SMT solvers offer such optimization capabilities.In this paper, we present SYMBA, an efficient SMT-based optimization algorithm for objective functions in the theory of linear real arithmetic (LRA). Given a formula φ and an objective function t, SYMBA finds a satisfying assignment of φthat maximizes the value of t. SYMBA utilizes efficient SMT solvers as black boxes. As a result, it is easy to implement and it directly benefits from future advances in SMT solvers. Moreover, SYMBA can optimize a set of objective functions, reusing information between them to speed up the analysis. We have implemented SYMBA and evaluated it on a large number of optimization benchmarks drawn from program analysis tasks. Our results indicate the power and efficiency of SYMBA in comparison with competing approaches, and highlight the importance of its multi-objective-function feature.},
booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {607–618},
numpages = {12},
keywords = {invariant generation, optimization, program analysis, satisfiability modulo theories, symbolic abstraction},
location = {San Diego, California, USA},
series = {POPL '14}
}

@inproceedings{10.1145/1030397.1030431,
author = {Simske, Steven J. and Baggs, Scott C.},
title = {Digital capture for automated scanner workflows},
year = {2004},
isbn = {1581139381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1030397.1030431},
doi = {10.1145/1030397.1030431},
abstract = {The use of scanners and other capture devices to incorporate film- and paper-based materials into digital workflows is an important part of "digital convergence", or the bringing of paper-based and electronic documents together into the same electronic workflows. The diversity of captured information-from text and mixed-type documents to photos, negatives, slides and transparencies-requires a combination of document analysis techniques to perform, automatically, the segmentation, classification and workflow assignment of the scanned images. We herein present technologies that provide fast (&lt; 1.0 sec) and reliable (&gt; 95% job accuracy) capture solutions for all of these input content types. These solutions offer near real-time capture that provides automated workflow capabilities to a repertoire of scanning hardware: scanners, all-in-one devices, copiers and multifunctional printers. The techniques used to categorize the documents, perform zoning analysis on the documents, and then perform closed loop quality assurance on the documents are presented.},
booktitle = {Proceedings of the 2004 ACM Symposium on Document Engineering},
pages = {171–177},
numpages = {7},
keywords = {classification, negatives, photos, scanning, segmentation, slides, user interface, zoning},
location = {Milwaukee, Wisconsin, USA},
series = {DocEng '04}
}

@inproceedings{10.1145/3447568.3448537,
author = {Sang, Go Muan and Xu, Lai and de Vrieze, Paul and Bai, Yuewei and Pan, Fangyu},
title = {Predictive Maintenance in Industry 4.0},
year = {2021},
isbn = {9781450376556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447568.3448537},
doi = {10.1145/3447568.3448537},
abstract = {In the context of Industry 4.0, the manufacturing related processes have shifted from conventional processes within one organization to collaborative processes cross different organizations, for example, product design processes, manufacturing processes, and maintenance processes across different factories and enterprises. The application of Internet of things, i.e. smart devices and sensors increases collection and availability of diverse data. Advanced technologies such as big data analytics and cloud computing offer new opportunities for effective optimization of manufacturing related processes, e.g. predictive maintenance. Predictive maintenance provides a detailed examination of the detection, location and diagnosis of faults in related machineries using various analyses. RAMI4.0 is a framework for thinking about the various efforts that constitute Industry 4.0. It spans the entire product life cycle &amp; value stream axis, hierarchical structure axis and functional classification axis. The Industrial Data Space (now International Data Space) is a virtual data space using standards and common governance models to facilitate the secure exchange and easy linkage of data in business ecosystems. It thereby provides a basis for creating and using smart services and innovative business processes, while at the same time ensuring digital sovereignty of data owners. This paper looks at how to support predictive maintenance in the context of Industry 4.0? Especially, applying RAMI 4.0 architecture supports the predictive maintenance using FIWARE framework, which leads to deal with data exchanging among different organizations with different security requirements as well as modularizing of related functions.},
booktitle = {Proceedings of the 10th International Conference on Information Systems and Technologies},
articleno = {29},
numpages = {11},
keywords = {Blockchain, Collaborative business process, FIWARE, Industrial data space, Industry 4.0, Predictive maintenance},
location = {Lecce, Italy},
series = {ICIST '20}
}

@book{10.1145/3477355,
editor = {Jones, Cliff B. and Misra, Jayadev},
title = {Theories of Programming: The Life and Works of Tony Hoare},
year = {2021},
isbn = {9781450387286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {39},
abstract = {Sir Tony Hoare has had an enormous influence on computer science, from the Quicksort algorithm to the science of software development, concurrency and program verification. His contributions have been widely recognised: He was awarded the ACM’s Turing Award in 1980, the Kyoto Prize from the Inamori Foundation in 2000, and was knighted for “services to education and computer science” by Queen Elizabeth II of England in 2000.This book presents the essence of his various works—the quest for effective abstractions—both in his own words as well as chapters written by leading experts in the field, including many of his research collaborators. In addition, this volume contains biographical material, his Turing award lecture, the transcript of an interview and some of his seminal papers.Hoare’s foundational paper “An Axiomatic Basis for Computer Programming”, presented his approach, commonly known as Hoare Logic, for proving the correctness of programs by using logical assertions. Hoare Logic and subsequent developments have formed the basis of a wide variety of software verification efforts. Hoare was instrumental in proposing the Verified Software Initiative, a cooperative international project directed at the scientific challenges of large-scale software verification, encompassing theories, tools and experiments.Tony Hoare’s contributions to the theory and practice of concurrent software systems are equally impressive. The process algebra called Communicating Sequential Processes (CSP) has been one of the fundamental paradigms, both as a mathematical theory to reason about concurrent computation as well as the basis for the programming language occam. CSP served as a framework for exploring several ideas in denotational semantics such as powerdomains, as well as notions of abstraction and refinement. It is the basis for a series of industrial-strength tools which have been employed in a wide range of applications.This book also presents Hoare’s work in the last few decades. These works include a rigorous approach to specifications in software engineering practice, including procedural and data abstractions, data refinement, and a modular theory of designs. More recently, he has worked with collaborators to develop Unifying Theories of Programming (UTP). Their goal is to identify the common algebraic theories that lie at the core of sequential, concurrent, reactive and cyber-physical computations. Theories of Programming: The Life and Works of Tony Hoare’ is available as a printed book (DOI: ) and an on-line version. In addition to the book itself, a number of on-line resources might be of interest to readers:
A bibliography of Tony Hoare’s papers with clickable DOIs/URLs where available (ACM: INSERT URL)Appendix E of the book provides links to talks and interviews featuring Tony Hoare ()The Oxford archive of Hoare’s manuscripts:  
Supplementary Material: Tony Hoare’ is a PDF of additional material (not included in the book) containing the following:
Stories from a Life in Interesting Times (A transcription by Jayadev Misra of Tony Hoare’s acceptance speech for the 2000 Kyoto prize)Tony Hoare’s Heidelberg comments: (A transcription by Margaret Gray of Tony Hoare’s part in the 2020 Heidelberg event)Milestones in Tony’s Life and Work: A ‘cv’ of Tony Hoare prepared by Margaret GrayExtended version - ’Bernard Sufrin: Teaching at Belfast and Oxford’}
}

@article{10.1145/3542947,
author = {Burgue\~{n}o, Lola and Mu\~{n}oz, Paula and Claris\'{o}, Robert and Cabot, Jordi and G\'{e}rard, S\'{e}bastien and Vallecillo, Antonio},
title = {Dealing with Belief Uncertainty in Domain Models},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3542947},
doi = {10.1145/3542947},
abstract = {There are numerous domains in which information systems need to deal with uncertain information. These uncertainties may originate from different reasons such as vagueness, imprecision, incompleteness, or inconsistencies, and in many cases, they cannot be neglected. In this article, we are interested in representing and processing uncertain information in domain models, considering the stakeholders’ beliefs (opinions). We show how to associate beliefs to model elements and how to propagate and operate with their associated uncertainty so that domain experts can individually reason about their models enriched with their personal opinions. In addition, we address the challenge of combining the opinions of different domain experts on the same model elements, with the goal to come up with informed collective decisions. We provide different strategies and a methodology to optimally merge individual opinions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {31},
numpages = {34},
keywords = {Information systems, software, domain models, uncertainty, belief, belief fusion, consensus, subjective logic, vagueness, decision-making}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3555228,
title = {SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Brazil}
}

@inproceedings{10.1145/3368089.3409743,
author = {Garc\'{\i}a, Sergio and Str\"{u}ber, Daniel and Brugali, Davide and Berger, Thorsten and Pelliccione, Patrizio},
title = {Robotics software engineering: a perspective from the service robotics domain},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409743},
doi = {10.1145/3368089.3409743},
abstract = {Robots that support humans by performing useful tasks (a.k.a., service robots) are booming worldwide. In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments. As a domain with critical safety implications, service robotics faces a need for sound software development practices. In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering. We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain. Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including processes, paradigms, languages, tools, frameworks, and reuse practices, (ii) the distinguishing characteristics of robotics software engineering, and (iii) recurrent challenges usually faced, together with adopted solutions. The paper concludes by discussing observations, derived hypotheses, and proposed actions for researchers and practitioners.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {593–604},
numpages = {12},
keywords = {interviews, online survey, robotics software engineering},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3510003.3510200,
author = {Dubslaff, Clemens and Weis, Kallistos and Baier, Christel and Apel, Sven},
title = {Causality in configurable software systems},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510200},
doi = {10.1145/3510003.3510200},
abstract = {Detecting and understanding reasons for defects and inadvertent behavior in software is challenging due to their increasing complexity. In configurable software systems, the combinatorics that arises from the multitude of features a user might select from adds a further layer of complexity. We introduce the notion of feature causality, which is based on counterfactual reasoning and inspired by the seminal definition of actual causality by Halpern and Pearl. Feature causality operates at the level of system configurations and is capable of identifying features and their interactions that are the reason for emerging functional and non-functional properties. We present various methods to explicate these reasons, in particular well-established notions of responsibility and blame that we extend to the feature-oriented setting. Establishing a close connection of feature causality to prime implicants, we provide algorithms to effectively compute feature causes and causal explications. By means of an evaluation on a wide range of configurable software systems, including community benchmarks and real-world systems, we demonstrate the feasibility of our approach: We illustrate how our notion of causality facilitates to identify root causes, estimate the effects of features, and detect feature interactions.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {325–337},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@book{10.1145/3544585,
editor = {Apt, Krzysztof R. and Hoare, Tony},
title = {Edsger Wybe Dijkstra: His Life,Work, and Legacy},
year = {2022},
isbn = {9781450397735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {45},
abstract = {Edsger Wybe Dijkstra (1930–2002) was one of the most influential researchers in the history of computer science, making fundamental contributions to both the theory and practice of computing. Early in his career, he proposed the single-source shortest path algorithm, now commonly referred to as Dijkstra’s algorithm. He wrote (with Jaap Zonneveld) the first ALGOL 60 compiler, and designed and implemented with his colleagues the influential THE operating system. Dijkstra invented the field of concurrent algorithms, with concepts such as mutual exclusion, deadlock detection, and synchronization. A prolific writer and forceful proponent of the concept of structured programming, he convincingly argued against the use of the Go To statement. In 1972 he was awarded the ACM Turing Award for ‘fundamental contributions to programming as a high, intellectual challenge; for eloquent insistence and practical demonstration that programs should be composed correctly, not just debugged into correctness; for illuminating perception of problems at the foundations of program design.’ Subsequently he invented the concept of self-stabilization relevant to fault-tolerant computing. He also devised an elegant language for nondeterministic programming and its weakest precondition semantics, featured in his influential 1976 book A Discipline of Programming in which he advocated the development of programs in concert with their correctness proofs. In the later stages of his life, he devoted much attention to the development and presentation of mathematical proofs, providing further support to his long-held view that the programming process should be viewed as a mathematical activity.In this unique new book, 31 computer scientists, including five recipients of the Turing Award, present and discuss Dijkstra’s numerous contributions to computing science and assess their impact. Several authors knew Dijkstra as a friend, teacher, lecturer, or colleague. Their biographical essays and tributes provide a fascinating multi-author picture of Dijkstra, from the early days of his career up to the end of his life}
}

@proceedings{10.1145/3579370,
title = {SYSTOR '23: Proceedings of the 16th ACM International Conference on Systems and Storage},
year = {2023},
isbn = {9781450399623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Haifa, Israel}
}

@proceedings{10.1145/3568231,
title = {SIET '22: Proceedings of the 7th International Conference on Sustainable Information Engineering and Technology},
year = {2022},
isbn = {9781450397117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Malang, Indonesia}
}

@inproceedings{10.1145/3357141.3357142,
author = {Oliveira, Anderson and Sousa, Leonardo and Oizumi, Willian and Garcia, Alessandro},
title = {On the Prioritization of Design-Relevant Smelly Elements: A Mixed-Method, Multi-Project Study},
year = {2019},
isbn = {9781450376372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357141.3357142},
doi = {10.1145/3357141.3357142},
abstract = {Software systems are likely to face what is called design problems. Given the typical lack of design documentation, developers have to rely on implementation-level symptoms, the so-called code smells, to identify and remove design problems. A code smell is a microstructure in the program that can indicate the presence of a design problem. Large programs have hundreds or thousands of program elements (e.g., classes) in which a significant proportion may be affected by smells. Consequently, due to time constraints and the large number of elements, developers have to prioritize the designrelevant program elements, i.e., locate a shortlist of elements that are suspects of having design-relevant smells. However, this task is hard and time-consuming. Unfortunately, the literature fails to provide developers with effective heuristics that automate such prioritization task. The objective of this paper is to propose heuristics that effectively locate a shortlist of design-relevant smelly program elements. For this purpose, we report two studies. In the first one, we investigated the criteria that developers used in practice to accurately prioritize design-relevant smelly elements. Based on these criteria, we derived a preliminary suite of prioritization heuristics. Since we do not know if the heuristics are suitable for an effective prioritization across multiple projects, we performed a second study to evaluate the proposed heuristics. We found that two out of nine heuristics reached an average precision higher than 75% for the four projects we analyzed. Thus, our findings suggest these heuristics are promising to support developers in prioritizing design-relevant smelly elements.},
booktitle = {Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {83–92},
numpages = {10},
keywords = {design problems, heuristics, prioritization},
location = {Salvador, Brazil},
series = {SBCARS '19}
}

@proceedings{10.1145/3567512,
title = {SLE 2022: Proceedings of the 15th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2022},
isbn = {9781450399197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 15th ACM SIGPLAN International Conference on Software Language Engineering (SLE), co-located with the ACM SIGPLAN conference on Systems, Programming, Languages, and Applications (SPLASH) in Auckland, a vibrant port city in northern New Zealand, from December 5th to December 10th 2022. Like its predecessors, the this edition of the SLE conference, SLE 2022, is devoted to the principles of software languages: their design, their implementation, and their evolution. As such, SLE brings together researchers united by their common interest in the creation, capture, and tooling of software languages.},
location = {Auckland, New Zealand}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to &lt;I&gt;The Web Conference 2019&lt;/I&gt;. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

@proceedings{10.1145/3084873,
title = {SIGGRAPH '17: ACM SIGGRAPH 2017 Courses},
year = {2017},
isbn = {9781450350143},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SIGGRAPH 2017 Courses are instructional sessions in which attendees learn new concepts and skills. They give attendees an in-depth overview of the state of-the-art in a particular area or provide a comprehensive overview of an emerging topic that is of interest to the SIGGRAPH audience. They are presented in short (1.5 hours), medium (3.25 hours), or all-day formats and often include elements of interactive demonstration, performance, or other imaginative approaches to teaching.The spectrum of Courses ranges from an introduction to the foundations of computer graphics and interactive techniques to advanced instruction on current and future technologies.},
location = {Los Angeles, California}
}

@inproceedings{10.1145/2970276.2970327,
author = {Moonen, Leon and Di Alesio, Stefano and Binkley, David and Rolfsnes, Thomas},
title = {Practical guidelines for change recommendation using association rule mining},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970327},
doi = {10.1145/2970276.2970327},
abstract = {Association rule mining is an unsupervised learning technique that infers relationships among items in a data set. This technique has been successfully used to analyze a system's change history and uncover evolutionary coupling between system artifacts. Evolutionary coupling can, in turn, be used to recommend artifacts that are potentially affected by a given set of changes to the system. In general, the quality of such recommendations is affected by (1) the values selected for various parameters of the mining algorithm, (2) characteristics of the set of changes used to derive a recommendation, and (3) characteristics of the system's change history for which recommendations are generated.In this paper, we empirically investigate the extent to which certain choices for these factors affect change recommendation. Specifically, we conduct a series of systematic experiments on the change histories of two large industrial systems and eight large open source systems, in which we control the size of the change set for which to derive a recommendation, the measure used to assess the strength of the evolutionary coupling, and the maximum size of historical changes taken into account when inferring these couplings. We use the results from our study to derive a number of practical guidelines for applying association rule mining for change recommendation.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {732–743},
numpages = {12},
keywords = {Evolutionary coupling, association rule mining, change impact analysis, change recommendations, parameter tuning},
location = {Singapore, Singapore},
series = {ASE '16}
}

@article{10.1145/3457950,
author = {Shatilov, Kirill A. and Chatzopoulos, Dimitris and Lee, Lik-Hang and Hui, Pan},
title = {Emerging ExG-based NUI Inputs in Extended Realities: A&nbsp;Bottom-up&nbsp;Survey},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3457950},
doi = {10.1145/3457950},
abstract = {Incremental and quantitative improvements of two-way interactions with extended realities (XR) are contributing toward a qualitative leap into a state of XR ecosystems being efficient, user-friendly, and widely adopted. However, there are multiple barriers on the way toward the omnipresence of XR; among them are the following: computational and power limitations of portable hardware, social acceptance of novel interaction protocols, and usability and efficiency of interfaces. In this article, we overview and analyse novel natural user interfaces based on sensing electrical bio-signals that can be leveraged to tackle the challenges of XR input interactions. Electroencephalography-based brain-machine interfaces that enable thought-only hands-free interaction, myoelectric input methods that track body gestures employing electromyography, and gaze-tracking electrooculography input interfaces are the examples of electrical bio-signal sensing technologies united under a collective concept of ExG. ExG signal acquisition modalities provide a way to interact with computing systems using natural intuitive actions enriching interactions with XR. This survey will provide a bottom-up overview starting from (i) underlying biological aspects and signal acquisition techniques, (ii) ExG hardware solutions, (iii) ExG-enabled applications, (iv) discussion on social acceptance of such applications and technologies, as well as (v) research challenges, application directions, and open problems; evidencing the benefits that ExG-based Natural User Interfaces inputs can introduce to the area of XR.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jul,
articleno = {10},
numpages = {49},
keywords = {Mobile augmented reality, user interactions, Electromyography, Electroencephalography, Silent Speech Interfaces, Extended Reality}
}

@book{10.1145/3382097,
author = {Allemang, Dean and Hendler, Jim and Gandon, Fabien},
title = {Semantic Web for the Working Ontologist: Effective Modeling for Linked Data, RDFS, and OWL},
year = {2020},
isbn = {9781450376174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {3},
volume = {33},
abstract = {Enterprises have made amazing advances by taking advantage of data about their business to provide predictions and understanding of their customers, markets, and products. But as the world of business becomes more interconnected and global, enterprise data is no long a monolith; it is just a part of a vast web of data. Managing data on a world-wide scale is a key capability for any business today.The Semantic Web treats data as a distributed resource on the scale of the World Wide Web, and incorporates features to address the challenges of massive data distribution as part of its basic design. The aim of the first two editions was to motivate the Semantic Web technology stack from end-to-end; to describe not only what the Semantic Web standards are and how they work, but also what their goals are and why they were designed as they are. It tells a coherent story from beginning to end of how the standards work to manage a world-wide distributed web of knowledge in a meaningful way.The third edition builds on this foundation to bring Semantic Web practice to enterprise. Fabien Gandon joins Dean Allemang and Jim Hendler, bringing with him years of experience in global linked data, to open up the story to a modern view of global linked data. While the overall story is the same, the examples have been brought up to date and applied in a modern setting, where enterprise and global data come together as a living, linked network of data. Also included with the third edition, all of the data sets and queries are available online for study and experimentation at data.world/swwo.}
}

@article{10.1145/3131608,
author = {Oulasvirta, Antti and Feit, Anna and L\"{a}hteenlahti, Perttu and Karrenbauer, Andreas},
title = {Computational Support for Functionality Selection in Interaction Design},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3131608},
doi = {10.1145/3131608},
abstract = {Designing interactive technology entails several objectives, one of which is identifying and selecting appropriate functionality. Given candidate functionalities such as “print,” “bookmark,” and “share,” a designer has to choose which functionalities to include and which to leave out. Such choices critically affect the acceptability, productivity, usability, and experience of the design. However, designers may overlook reasonable designs because there is an exponential number of functionality sets and multiple factors to consider. This article is the first to formally define this problem and propose an algorithmic method to support designers to explore alternative functionality sets in early stage design. Based on interviews of professional designers, we mathematically define the task of identifying functionality sets that strike the best balance among four objectives: usefulness, satisfaction, ease of use, and profitability. We develop an integer linear programming solution that can efficiently solve very large instances (set size over 1,300) on a regular computer. Further, we build on techniques of robust optimization to search for diverse and surprising functionality designs. Empirical results from a controlled study and field deployment are encouraging. Most designers rated computationally created sets to be of the comparable or superior quality than their own. Designers reported gaining better understanding of available functionalities and the design space.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = oct,
articleno = {34},
numpages = {30},
keywords = {Functionality selection, computer-supported design, creativity, design tools, integer linear programming, interaction design, optimization methods, user-centered design}
}

@article{10.1145/3241383,
author = {Avrahami, Daniel and Patel, Mitesh and Yamaura, Yusuke and Kratz, Sven and Cooper, Matthew},
title = {Unobtrusive Activity Recognition and Position Estimation for Work Surfaces Using RF-Radar Sensing},
year = {2019},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/3241383},
doi = {10.1145/3241383},
abstract = {Activity recognition is a core component of many intelligent and context-aware systems. We present a solution for discreetly and unobtrusively recognizing common work activities above a work surface without using cameras. We demonstrate our approach, which utilizes an RF-radar sensor mounted under the work surface, in three domains: recognizing work activities at a convenience-store counter, recognizing common office deskwork activities, and estimating the position of customers in a showroom environment. Our examples illustrate potential benefits for both post-hoc business analytics and for real-time applications. Our solution was able to classify seven clerk activities with 94.9% accuracy using data collected in a lab environment and able to recognize six common deskwork activities collected in real offices with 95.3% accuracy. Using two sensors simultaneously, we demonstrate coarse position estimation around a large surface with 95.4% accuracy. We show that using multiple projections of RF signal leads to improved recognition accuracy. Finally, we show how smartwatches worn by users can be used to attribute an activity, recognized with the RF sensor, to a particular user in multi-user scenarios. We believe our solution can mitigate some of users’ privacy concerns associated with cameras and is useful for a wide range of intelligent systems.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = aug,
articleno = {11},
numpages = {28},
keywords = {Activity recognition, IMU, deskwork, radio frequency radar sensor, retail, sensing}
}

@article{10.1145/221296.221308,
author = {Meyer, Andr\'{e}},
title = {Pen computing: a technology overview and a vision},
year = {1995},
issue_date = {July 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0736-6906},
url = {https://doi.org/10.1145/221296.221308},
doi = {10.1145/221296.221308},
abstract = {This work gives an overview of a new technology that is attracting growing interest in public as well as in the computer industry itself. The visible difference from other technologies is in the use of a pen or pencil as the primary means of interaction between a user and a machine, picking up the familiar pen and paper interface metaphor. From this follows a set of consequences that will be analyzed and put into context with other emerging technologies and visions.Starting with a short historical background and the technical advances that begin making Pen Computing a reality, the new paradigms created by Pen Computing will be explained and discussed. Handwriting recognition, mobility and global information access are other central topics. This is followed by a categorization and an overview of current and future systems using pens as their primary user interface component.},
journal = {SIGCHI Bull.},
month = jul,
pages = {46–90},
numpages = {45}
}

@inproceedings{10.5555/2337223.2337243,
author = {Siegmund, Norbert and Kolesnikov, Sergiy S. and K\"{a}stner, Christian and Apel, Sven and Batory, Don and Rosenm\"{u}ller, Marko and Saake, Gunter},
title = {Predicting performance via automated feature-interaction detection},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However, when features interact, accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end, we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g., databases, encoding libraries, and web servers) using different configuration techniques (e.g., configuration files and preprocessor flags). Results show an average prediction accuracy of 95%.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {167–177},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@article{10.1145/3386325,
author = {Syme, Don},
title = {The early history of F#},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {HOPL},
url = {https://doi.org/10.1145/3386325},
doi = {10.1145/3386325},
abstract = {This paper describes the genesis and early history of the F# programming language. I start with the origins of strongly-typed functional programming (FP) in the 1970s, 80s and 90s. During the same period, Microsoft was founded and grew to dominate the software industry. In 1997, as a response to Java, Microsoft initiated internal projects which eventually became the .NET programming framework and the C# language. From 1997 the worlds of academic functional programming and industry combined at Microsoft Research, Cambridge. The researchers engaged with the company through Project 7, the initial effort to bring multiple languages to .NET, leading to the initiation of .NET Generics in 1998 and F# in 2002. F# was one of several responses by advocates of strongly-typed functional programming to the "object-oriented tidal wave" of the mid-1990s. The development of the core features of F# 1.0 happened from 2004-2007, and I describe the decision-making process that led to the "productization" of F# by Microsoft in 2007-10 and the release of F# 2.0. The origins of F#'s characteristic features are covered: object programming, quotations, statically resolved type parameters, active patterns, computation expressions, async, units-of-measure and type providers. I describe key developments in F# since 2010, including F# 3.0-4.5, and its evolution as an open source, cross-platform language with multiple delivery channels. I conclude by examining some uses of F# and the influence F# has had on other languages so far.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {75},
numpages = {58},
keywords = {Asynchronous Programming, Dimensions, F#, Functional Programming, Object-oriented Programming, Pattern Matching, Programming Languages, Type Providers, Units of Measure}
}

@book{10.1145/3502372,
author = {Pelkey, James L. and Russell, Andrew L. and Robbins, Loring G.},
title = {Circuits, Packets, and Protocols: Entrepreneurs and Computer Communications, 1968–1988},
year = {2022},
isbn = {9781450397261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {40},
abstract = {As recently as 1968, computer scientists were uncertain how best to interconnect even two computers. The notion that within a few decades the challenge would be how to interconnect millions of computers around the globe was too far-fetched to contemplate. Yet, by 1988, that is precisely what was happening. The products and devices developed in the intervening years—such as modems, multiplexers, local area networks, and routers—became the linchpins of the global digital society. How did such revolutionary innovation occur? This book tells the story of the entrepreneurs who were able to harness and join two factors: the energy of computer science researchers supported by governments and universities, and the tremendous commercial demand for Internetworking computers. The centerpiece of this history comes from unpublished interviews from the late 1980s with over 80 computing industry pioneers, including Paul Baran, J.C.R. Licklider, Vint Cerf, Robert Kahn, Larry Roberts, and Robert Metcalfe. These individuals give us unique insights into the creation of multi-billion dollar markets for computer-communications equipment, and they reveal how entrepreneurs struggled with failure, uncertainty, and the limits of knowledge.“The key technologies that brought us our modern networked society—routers, packet switching, multiplexers, Internet protocols—were all invented by people in the short period between 1968 and 1988. James Pelkey interviewed these people at that time and recorded their stories. This book is the result: a detailed and up-close personal history of a world being born. Fascinating.” - W. Brian Arthur, Author of The Nature of Technology: What It Is and How It Evolves“Circuits, Packets, and Protocols is full of revelations for me even though I was there. Never had it explained so clearly how my distributed computing strategy was the wrong one for 3Com in the 1980s.” - Bob Metcalfe, Internet Pioneer, Ethernet inventor, 3Com founder; University of Texas at Austin Professor of Innovation}
}

@proceedings{10.1145/3564858,
title = {IMMS '22: Proceedings of the 5th International Conference on Information Management and Management Science},
year = {2022},
isbn = {9781450396721},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@article{10.1145/3386331,
author = {Moler, Cleve and Little, Jack},
title = {A history of MATLAB},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {HOPL},
url = {https://doi.org/10.1145/3386331},
doi = {10.1145/3386331},
abstract = {The first MATLAB (the name is short for “Matrix Laboratory”) was not a programming language. Written in Fortran in the late 1970s, it was a simple interactive matrix calculator built on top of about a dozen subroutines from the LINPACK and EISPACK matrix software libraries. There were only 71 reserved words and built-in functions. It could be extended only by modifying the Fortran source code and recompiling it. The programming language appeared in 1984 when MATLAB became a commercial product. The calculator was reimplemented in C and significantly enhanced with the addition of user functions, toolboxes, and graphics. It was available initially on the IBM PC and clones; versions for Unix workstations and the Apple Macintosh soon followed. In addition to the matrix functions from the calculator, the 1984 MATLAB included fast Fourier transforms (FFT). The Control System Toolbox appeared in 1985 and the Signal Processing Toolbox in 1987. Built-in support for the numerical solution of ordinary differential equations also appeared in 1987. The first significant new data structure, the sparse matrix, was introduced in 1992. The Image Processing Toolbox and the Symbolic Math Toolbox were both introduced in 1993. Several new data types and data structures, including single precision floating point, various integer and logical types, cell arrays, structures, and objects were introduced in the late 1990s. Enhancements to the MATLAB computing environment have dominated development in recent years. Included are extensions to the desktop, major enhancements to the object and graphics systems, support for parallel computing and GPUs, and the “Live Editor”, which combines programs, descriptive text, output and graphics into a single interactive, formatted document. Today there are over 60 Toolboxes, many programmed in the MATLAB language, providing extended capabilities in specialized technical fields.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {81},
numpages = {67},
keywords = {MATLAB, linear algebra, matrix computation}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@article{10.1145/3273982.3273991,
author = {Xie, Shaolin and Davidson, Scott and Magaki, Ikuo and Khazraee, Moein and Vega, Luis and Zhang, Lu and Taylor, Michael B.},
title = {Extreme Datacenter Specialization for Planet-Scale Computing: ASIC Clouds},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/3273982.3273991},
doi = {10.1145/3273982.3273991},
abstract = {Planet-scale applications are driving the exponential growth of the cloud, and datacenter specialization is the key enabler of this trend, providing order of magnitudes improvements in cost-effectiveness and energy-efficiency. While exascale computing remains a goal for supercomputing, specialized datacenters have emerged and have demonstrated beyond-exascale performance and efficiency in specific domains. This paper generalizes the applications, design methodology, and deployment challenges of the most extreme form of specialized datacenter: ASIC Clouds. It analyzes two game-changing, real-world ASIC Clouds-Bitcoin Cryptocurrency Clouds and Tensor Processing Clouds-discuss their incentives, the empowering technologies and how they benefit from the specialized ASICs. Their business models, architectures and deployment methods are useful for envisioning future potential ASIC Clouds and forecasting how they will transform computing, the economy and society.},
journal = {SIGOPS Oper. Syst. Rev.},
month = aug,
pages = {96–108},
numpages = {13},
keywords = {ASIC, Accelerator, Datacenter}
}

@proceedings{10.1145/3580507,
title = {EC '23: Proceedings of the 24th ACM Conference on Economics and Computation},
year = {2023},
isbn = {9798400701047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Over the course of two decades, EC has established itself as one of the few truly successful interdisciplinary conferences, attracting papers and participants with a broad range of interests in economics and computer science, and fostering work in the intersection.},
location = {London, United Kingdom}
}

@article{10.1145/3084225,
author = {Storer, Tim},
title = {Bridging the Chasm: A Survey of Software Engineering Practice in Scientific Programming},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3084225},
doi = {10.1145/3084225},
abstract = {The use of software is pervasive in all fields of science. Associated software development efforts may be very large, long lived, and complex, requiring the commitment of significant resources. However, several authors have argued that the “gap” or “chasm” between software engineering and scientific programming is a serious risk to the production of reliable scientific results, as demonstrated in a number of case studies. This article reviews the research that addresses the gap, exploring how both software engineering and research practice may need to evolve to accommodate the use of software in science.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {47},
numpages = {32},
keywords = {Software engineering, scientific programming}
}

@proceedings{10.1145/3468013,
title = {APCORISE '21: Proceedings of the 4th Asia Pacific Conference on Research in Industrial and Systems Engineering},
year = {2021},
isbn = {9781450390385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Depok, Indonesia}
}

@proceedings{10.1145/2998181,
title = {CSCW '17: Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to CSCW 2017, the ACM 2017 Conference on Computer Supported Cooperative Work and Social Computing! We are excited to welcome the CSCW community back to Portland, Oregon, where the second CSCW conference was held in 1988. Both Portland and CSCW have matured a great deal during the intervening 29 years. We hope that you will find that Portland provides a stimulating environment for our conference.CSCW is the premier venue for presenting research in the design and use of technologies that affect groups, organizations, communities, and networks. Bringing together top researchers and practitioners from academia and industry, CSCW explores the technical, social, material, and theoretical challenges of designing technology to support collaborative work and life activities. CSCW welcomes a diverse range of topics and research methodologies. Studies often involve the development and application of novel technologies and/or ethnographic studies that inform design practice or theory. The mission of the conference is to share research that advances the state of human knowledge and improves both the design of systems and the ways they are used. The diversity of work in our conference program reflects the diversity of technology use in people's work, social, and civic lives as well as the geographic and cultural diversity of contributors.As many of you know, CSCW follows a rigorous "revise and resubmit" review process that uses peer review to improve submitted papers while maintaining a high-quality threshold for final acceptance. We also help prepare the next generation of reviewers with a mentorship program in which students review papers under the guidance of an experienced reviewer. This year we have the largest CSCW program ever. We had 530 submitted papers and 183 were accepted for presentation at the conference. The program also includes 4 papers published in ACM Transactions on Human- Computer Interaction (TOCHI). In addition, we will feature 14 workshops, 56 posters, 12 demos, and 3 panels.Lili Cheng of Microsoft Research will open the conference, speaking on "Conversational AI &amp; Lessons Learned." Our closing plenary will feature Jorge Cham, the creator of PhD Comics, who will talk about, "The Science Gap." We also welcome Paul Luff and Christian Heath from King's College as the recipients of this year's CSCW Lasting Impact award for their influential 1998 paper, "Mobility in Collaboration."},
location = {Portland, Oregon, USA}
}

@inproceedings{10.1145/3313831.3376598,
author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
title = {"And This, Kids, Is How I Met Your Mother": Consumerist, Mundane, and Uncanny Futures with Sex Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376598},
doi = {10.1145/3313831.3376598},
abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {ethics, human-robot interaction, research fiction, sex robots, sexual HCI, speculative design, story completion method},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@proceedings{10.1145/3623462,
title = {KUI '23: Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality},
year = {2023},
isbn = {9798400708367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@book{10.1145/3549993,
editor = {Slayton, Rebecca},
title = {Democratizing Cryptography: The Work of Whitfield Diffie and Martin Hellman},
year = {2022},
isbn = {9781450398275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {42},
abstract = {In the mid-1970s, Whitfield Diffie and Martin Hellman invented public key cryptography, an innovation that ultimately changed the world. Today public key cryptography provides the primary basis for secure communication over the internet, enabling online work, socializing, shopping, government services, and much more.While other books have documented the development of public key cryptography, this is the first to provide a comprehensive insiders’ perspective on the full impacts of public key cryptography, including six original chapters by nine distinguished scholars. The book begins with an original joint biography of the lives and careers of Diffie and Hellman, highlighting parallels and intersections, and contextualizing their work. Subsequent chapters show how public key cryptography helped establish an open cryptography community and made lasting impacts on computer and network security, theoretical computer science, mathematics, public policy, and society. The volume includes particularly influential articles by Diffie and Hellman, as well as newly transcribed interviews and Turing Award Lectures by both Diffie and Hellman.The contributed chapters provide new insights that are accessible to a wide range of readers, from computer science students and computer security professionals, to historians of technology and members of the general public. The chapters can be readily integrated into undergraduate and graduate courses on a range of topics, including computer security, theoretical computer science and mathematics, the history of computing, and science and technology policy.}
}

@inproceedings{10.1145/3151848.3151859,
author = {Fonteles, Andr\'{e} Sales and Bouveret, Sylvain and Gensel, J\'{e}r\^{o}me},
title = {A programming framework for Spatial Crowdsourcing},
year = {2017},
isbn = {9781450353007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3151848.3151859},
doi = {10.1145/3151848.3151859},
abstract = {Spatial crowdsourcing platforms (SCP) are systems that allow someone to publish spatial tasks in order to find a suitable workforce to achieve it. These tasks require people, often using mobile devices, to be at a given location in order to accomplish them. SCPs have been source of much interest for academy and industry. For this reason, Doan et al. [4] argued in 2011 that the race was now on "toward building general crowdsourcing platforms that can be used to develop such systems quickly". Since then, little has been done in this matter. Besides, what has been proposed does not take into account real commercial SCPs and its requirements. We propose GENIUS-C, a framework to support the development of SCPs. It is based on a generic architecture proposed by Fonteles et al. [7] designed to reduce the gap between academy and industry. GENIUS-C is meant to decrease development cost and effort and increase overall quality of SCPs. A case study SCP has been created using GENIUS-C to demonstrate its benefits and how it can be used in the developments of SCPs.},
booktitle = {Proceedings of the 15th International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {131–140},
numpages = {10},
keywords = {crowdsourcing, framework, spatial crowdsourcing},
location = {Salzburg, Austria},
series = {MoMM2017}
}

@article{10.1145/3381038,
author = {Figueroa-Lorenzo, Santiago and A\~{n}orga, Javier and Arrizabalaga, Saioa},
title = {A Survey of IIoT Protocols: A Measure of Vulnerability Risk Analysis Based on CVSS},
year = {2020},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3381038},
doi = {10.1145/3381038},
abstract = {Industrial Internet of Things (IIoT) is present in many participants from the energy, health, manufacturing, transport, and public sectors. Many factors catalyze IIoT, such as robotics, artificial intelligence, and intelligent decentralized manufacturing. However, the convergence between IT, OT, and IoT environments involves the integration of heterogeneous technologies through protocols, standards, and buses. However, this integration brings with it security risks. To avoid the security risks, especially when systems in different environments interact, it is important and urgent to create an early consensus among the stakeholders on the IIoT security. The default Common Vulnerability Scoring System (CVSS) offers a mechanism to measure the severity of an asset's vulnerability and therefore a way to characterize the risk. However, CVSS by default has two drawbacks. On the one hand, to carry out a risk analysis, it is necessary to have additional metrics to the one established by CVSSv3.1. On the other hand, this index has been used mostly in IT environments and although there are numerous efforts to develop a model that suits industrial environments, there is no established proposal. Therefore, we first propose a survey of the main 33 protocols, standards, and buses used in an IIoT environment. This survey will focus on the security of each one. The second part of our study consists of the creation of a framework to characterize risk in industrial environments, i.e., to solve both problems of the CVSS index. To this end, we created the Vulnerability Analysis Framework (VAF), which is a methodology that allows the analysis of 1,363 vulnerabilities to establish a measure to describe the risk in IIoT environments.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {44},
numpages = {53},
keywords = {Attack Patterns, CVSS, Cybersecurity pillars, IIoT, Industrial Internet of Things, Industrial Security, Information Technologies, Operational Technologies, Risk analysis}
}

@inproceedings{10.1145/2429069.2429094,
author = {Delaware, Benjamin and d. S. Oliveira, Bruno C. and Schrijvers, Tom},
title = {Meta-theory \`{a} la carte},
year = {2013},
isbn = {9781450318327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2429069.2429094},
doi = {10.1145/2429069.2429094},
abstract = {Formalizing meta-theory, or proofs about programming languages, in a proof assistant has many well-known benefits. Unfortunately, the considerable effort involved in mechanizing proofs has prevented it from becoming standard practice. This cost can be amortized by reusing as much of existing mechanized formalizations as possible when building a new language or extending an existing one. One important challenge in achieving reuse is that the inductive definitions and proofs used in these formalizations are closed to extension. This forces language designers to cut and paste existing definitions and proofs in an ad-hoc manner and to expend considerable effort to patch up the results.The key contribution of this paper is the development of an induction technique for extensible Church encodings using a novel reinterpretation of the universal property of folds. These encodings provide the foundation for a framework, formalized in Coq, which uses type classes to automate the composition of proofs from modular components. This framework enables a more structured approach to the reuse of meta-theory formalizations through the composition of modular inductive definitions and proofs.Several interesting language features, including binders and general recursion, illustrate the capabilities of our framework. We reuse these features to build fully mechanized definitions and proofs for a number of languages, including a version of mini-ML. Bounded induction enables proofs of properties for non-inductive semantic functions, and mediating type classes enable proof adaptation for more feature-rich languages.},
booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {207–218},
numpages = {12},
keywords = {coq, extensible church encodings, modular mechanized meta-theory},
location = {Rome, Italy},
series = {POPL '13}
}

@proceedings{10.1145/3001854,
title = {Mobile! 2016: Proceedings of the 1st International Workshop on Mobile Development},
year = {2016},
isbn = {9781450346436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@book{10.1145/3544564,
author = {Ullmer, Brygg and Shaer, Orit and Mazalek, Ali and Hummels, Caroline},
title = {Weaving Fire into Form: Aspirations for Tangible and Embodied Interaction},
year = {2022},
isbn = {9781450397698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {44},
abstract = {This book investigates multiple facets of the emerging discipline of Tangible, Embodied, and Embedded Interaction (TEI). This is a story of atoms and bits. We explore the interweaving of the physical and digital, toward understanding some of their wildly varying hybrid forms and behaviors. Spanning conceptual, philosophical, cognitive, design, and technical aspects of interaction, this book charts both history and aspirations for the future of TEI. We examine and celebrate diverse trailblazing works, and provide wide-ranging conceptual and pragmatic tools toward weaving the animating fires of computation and technology into evocative tangible forms. We also chart a path forward for TEI engagement with broader societal and sustainability challenges that will profoundly (re)shape our children’s and grandchildren’s futures. We invite you all to join this quest.}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@inproceedings{10.1007/978-3-642-33666-9_41,
author = {Iqbal, Muhammad Zohaib and Ali, Shaukat and Yue, Tao and Briand, Lionel},
title = {Experiences of applying UML/MARTE on three industrial projects},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_41},
doi = {10.1007/978-3-642-33666-9_41},
abstract = {MARTE (Modeling and Analysis of Real-Time and Embedded Systems) is a UML profile, which has been developed to model concepts specific to Real-Time and Embedded Systems (RTES). In previous years, we have applied UML/MARTE to three distinct industrial problems in various industry sectors: architecture modeling and configuration of large-scale and highly configurable integrated control systems, model-based robustness testing of communication-intensive systems, and model-based environment simulator generation of large-scale RTES for testing. In this paper, we report on our experiences of solving these problems by applying UML/MARTE on four industrial case studies. Based on our common experiences, we derive a framework to help practitioners for future applications of UML/MARTE. The framework provides a set of detailed guidelines on how to apply MARTE in industrial contexts and will help reduce the gap between the modeling standards and industrial needs.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {642–658},
numpages = {17},
keywords = {MARTE, UML, architecture modeling, model-based testing, real-time embedded systems},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@proceedings{10.1145/2997364,
title = {SLE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/2984043,
title = {SPLASH Companion 2016: Companion Proceedings of the 2016 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity},
year = {2016},
isbn = {9781450344371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/1774088.1774562,
author = {K\"{a}tev\"{a}, Janne and Laurinen, Perttu and Rautio, Taneli and Suutala, Jaakko and Tuovinen, Lauri and R\"{o}ning, Juha},
title = {SE-155 DBSA: a device-based software architecture for data mining},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774562},
doi = {10.1145/1774088.1774562},
abstract = {In this paper a new architecture for a variety of data mining tasks is introduced. The Device-Based Software Architecture (DBSA) is a highly portable and generic data mining software framework where processing tasks are modeled as components linked together to form a data mining application. The name of the architecture comes from the analogy that each processing task in the framework can be thought of as a device. The framework handles all the devices in the same manner, regardless of whether they have a counterpart in the real world or whether they are just logical devices inside the framework. The DBSA offers many reusable devices, ready to be included in applications, and the application programmer can easily code new devices for the architecture. The framework is bundled with connections to several widely used external tools and languages, making prototyping new applications easy and fast. In the paper we compare DBSA to existing data mining frameworks, review its design and present a case study application implemented with the framework. The paper shows that the DBSA can act as a base for diverse data mining applications.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2273–2280},
numpages = {8},
keywords = {data mining, software frameworks},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@book{10.1145/3548585,
editor = {van Lente, Dick},
title = {Prophets of Computing: Visions of Society Transformed by Computing},
year = {2022},
isbn = {9781450398176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {50},
abstract = {When electronic digital computers first appeared after World War II, they appeared as a revolutionary force. Business management, the world of work, administrative life, the nation state, and soon enough everyday life were expected to change dramatically with these machines’ use. Ever since, diverse prophecies of computing have continually emerged, through to the present day.As computing spread beyond the US and UK, such prophecies emerged from strikingly different economic, political, and cultural conditions. This volume explores how these expectations differed, assesses unexpected commonalities, and suggests ways to understand the divergences and convergences.This book examines thirteen countries, based on source material in ten different languages—the effort of an international team of scholars. In addition to analyses of debates, political changes, and popular speculations, we also show a wide range of pictorial representations of “the future with computers.”}
}

@proceedings{10.1145/3132787,
title = {SA '17: SIGGRAPH Asia 2017 Mobile Graphics &amp; Interactive Applications},
year = {2017},
isbn = {9781450354103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SIGGRAPH Asia Symposium on Mobile Graphics and Interactive Applications will offer attendees the opportunity to explore the opportunities and challenges of mobile applications relevant to the global graphics community.The program will cover the development, technology, and marketing of mobile graphics and interactive applications. It will especially highlight novel uses of graphics and interactivity on mobile devices. Attendees can expect to be exposed to the latest in mobile graphics and interactive applications through expert keynote talks, paper presentations, panel discussions, industry case studies, and hands-on demonstrations.},
location = {Bangkok, Thailand}
}

@article{10.1145/1516533.1516538,
author = {Salehie, Mazeiar and Tahvildari, Ladan},
title = {Self-adaptive software: Landscape and research challenges},
year = {2009},
issue_date = {May 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1556-4665},
url = {https://doi.org/10.1145/1516533.1516538},
doi = {10.1145/1516533.1516538},
abstract = {Software systems dealing with distributed applications in changing environments normally require human supervision to continue operation in all conditions. These (re-)configuring, troubleshooting, and in general maintenance tasks lead to costly and time-consuming procedures during the operating phase. These problems are primarily due to the open-loop structure often followed in software development. Therefore, there is a high demand for management complexity reduction, management automation, robustness, and achieving all of the desired quality requirements within a reasonable cost and time range during operation. Self-adaptive software is a response to these demands; it is a closed-loop system with a feedback loop aiming to adjust itself to changes during its operation. These changes may stem from the software system's self (internal causes, e.g., failure) or context (external events, e.g., increasing requests from users). Such a system is required to monitor itself and its context, detect significant changes, decide how to react, and act to execute such decisions. These processes depend on adaptation properties (called self-* properties), domain characteristics (context information or models), and preferences of stakeholders. Noting these requirements, it is widely believed that new models and frameworks are needed to design self-adaptive software. This survey article presents a taxonomy, based on concerns of adaptation, that is, how, what, when and where, towards providing a unified view of this emerging area. Moreover, as adaptive systems are encountered in many disciplines, it is imperative to learn from the theories and models developed in these other areas. This survey article presents a landscape of research in self-adaptive software by highlighting relevant disciplines and some prominent research projects. This landscape helps to identify the underlying research gaps and elaborates on the corresponding challenges.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = may,
articleno = {14},
numpages = {42},
keywords = {Adaptation processes, research challenges, self-adaptive software, self-properties, survey}
}

@proceedings{10.1145/2504435,
title = {SIGGRAPH '13: ACM SIGGRAPH 2013 Courses},
year = {2013},
isbn = {9781450323390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In SIGGRAPH 2013 Courses, attendees learn from the experts in the field and gain inside knowledge that is critical to career advancement. Courses are short (1.5 hours) or half-day (3.25 hours) structured sessions that often include elements of interactive demonstration, performance, or other imaginative approaches to teaching.The spectrum of Courses ranges from an introduction to the foundations of computer graphics and interactive techniques for those new to the field to advanced instruction on the most current techniques and topics. Courses include core curricula taught by invited instructors as well as Courses selected from juried proposals.},
location = {Anaheim, California}
}

@article{10.1145/1082983.1085124,
title = {Frontmatter (TOC, Letters, Election results, Software Reliability Resources!, Computing Curricula 2004 and the Software Engineering Volume SE2004, Software Reuse Research, ICSE 2005 Forward)},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1085124},
doi = {10.1145/1082983.1085124},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {0},
numpages = {63}
}

@inproceedings{10.1145/1869459.1869534,
author = {Quillien, Jenny and West, Dave},
title = {Rubber ducks, nightmares, and unsaturated predicates: proto-scientific schemata are good for agile},
year = {2010},
isbn = {9781450302036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1869459.1869534},
doi = {10.1145/1869459.1869534},
abstract = {Fine-grain case studies of scientific inquiry, lessons from linguistics on metaphoric thinking, the epistemology of Charles Sanders Peirce, recent work on architectural image-schemata, along with the computer world's own theorist, Peter Naur, all suggest that software developers (frequently dulled and desiccated from overdosing on 'Cartesian' methodologies) could benefit from imbibing a little 'mysticism' not the wave-your-hands woo-woo kind but the more ineffable hunch and gut side of human cognition. Scholarly publications in their final polished forms rarely admit that stories, jokes, eroticism, and dreams were the fertile seeds that germinated into 'serious' results. This essay looks to these 'closet' sources, non-reductionist, non-self conscious, metaphorical, aformal modes of thought as the salvation of a profession gone awry. It is notably proto-scientific image-schemata that retain our attention as a pragmatic tool for improving the fecundity of Agile methodology, at its roots, so to speak. The necessary context is provided by Peter Naur's fundamental insights about software development as 'theory building' coupled with an elaboration of the Agile concept of storytelling.},
booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
pages = {901–917},
numpages = {17},
keywords = {agile, alexander, stories, theory-building},
location = {Reno/Tahoe, Nevada, USA},
series = {OOPSLA '10}
}

@article{10.1145/352029.352035,
author = {van Deursen, Arie and Klint, Paul and Visser, Joost},
title = {Domain-specific languages: an annotated bibliography},
year = {2000},
issue_date = {June 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/352029.352035},
doi = {10.1145/352029.352035},
abstract = {We survey the literature available on the topic of domain-specific languages as used for the construction and maintenance of software systems. We list a selection of 75 key publications in the area, and provide a summary for each of the papers. Moreover, we discuss terminology, risks and benefits, example domain-specific languages, design methodologies, and implementation techniques.},
journal = {SIGPLAN Not.},
month = jun,
pages = {26–36},
numpages = {11}
}

@inproceedings{10.5555/782010.782022,
author = {Kunz, Thomas and Seuren, Michiel F. H.},
title = {Fast detection of communication patterns in distributed executions},
year = {1997},
publisher = {IBM Press},
abstract = {Understanding distributed applications is a tedious and difficult task. Visualizations based on process-time diagrams are often used to obtain a better understanding of the execution of the application. The visualization tool we use is Poet, an event tracer developed at the University of Waterloo. However, these diagrams are often very complex and do not provide the user with the desired overview of the application. In our experience, such tools display repeated occurrences of non-trivial communication patterns, appearing throughout the trace data and cluttering the display space. This paper describes an event abstraction facility which tries to simplify the execution visualization shown by Poet by efficiently detecting and abstracting such patterns.A user can define patterns, subject to only very few constraints, and store them in a hierarchical pattern library. We also provide the user with the possibility to annotate the source code as a help in the abstraction process. We detect these communication patterns by employing an enhanced efficient multiple string matching algorithm. The results indicate that the matching process is indeed very fast. A user can experiment with multiple patterns at potentially different levels in the hierarchy, checking for their occurrence in the trace file, while trying to gain some understanding in a short period of time.},
booktitle = {Proceedings of the 1997 Conference of the Centre for Advanced Studies on Collaborative Research},
pages = {12},
location = {Toronto, Ontario, Canada},
series = {CASCON '97}
}

@article{10.1145/358141.358148,
author = {Markus, M. Lynne},
title = {Power, politics, and MIS implementation},
year = {1983},
issue_date = {June 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/358141.358148},
doi = {10.1145/358141.358148},
abstract = {Theories of resistance to management information systems (MIS) are important because they guide the implementation strategies and tactics chosen by implementors. Three basic theories of the causes of resistance underlie many prescriptions and rules for MIS implementation. Simply stated, people resist MIS because of their own internal factors, because of poor system design, and because of the interaction of specific system design features with aspects of the organizational context of system use. These theories differ in their basic assumptions about systems, organizations, and resistance; they also differ in predictions that can be derived from them and in their implications for the implementation process. These differences are described and the task of evaluating the theories on the bases of the differences is begun. Data from a case study are used to illustrate the theories and to demonstrate the superiority, for implementors, of the interaction theory.},
journal = {Commun. ACM},
month = jun,
pages = {430–444},
numpages = {15},
keywords = {implementation, intraorganizational power, politics, resistance}
}

@book{10.1145/1387148,
author = {Fry, James P. and Hawes, Mary K. and McGee, William C. and Metaxides, Tax A. and Olle, T. William and Rabin, Jonas and Rich, Martin J. and Schubert, Richard F. and Sibley, Edgar H. and Weinert, Aria E. and Vorhaus, Alfred H. and Young, John W.},
title = {A survey of generalized data base management systems, May 1969},
year = {1969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@techreport{10.1145/2594501,
author = {Ashenhurst, R. L.},
title = {ACM Curricula Recommendations for Information Systems},
year = {1983},
isbn = {089791 1180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This report contains curriculum recommendations prepared by the ACM Curriculum Committee on Computer Education for Management.}
}

