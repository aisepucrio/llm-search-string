@inproceedings{10.1145/3336294.3336304,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Software Product Line Engineering: A Practical Experience},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336304},
doi = {10.1145/3336294.3336304},
abstract = {The lack of mature tool support is one of the main reasons that make the industry to be reluctant to adopt Software Product Line (SPL) approaches. A number of systematic literature reviews exist that identify the main characteristics offered by existing tools and the SPL phases in which they can be applied. However, these reviews do not really help to understand if those tools are offering what is really needed to apply SPLs to complex projects. These studies are mainly based on information extracted from the tool documentation or published papers. In this paper, we follow a different approach, in which we firstly identify those characteristics that are currently essential for the development of an SPL, and secondly analyze whether the tools provide or not support for those characteristics. We focus on those tools that satisfy certain selection criteria (e.g., they can be downloaded and are ready to be used). The paper presents a state of practice with the availability and usability of the existing tools for SPL, and defines different roadmaps that allow carrying out a complete SPL process with the existing tool support.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {164–176},
numpages = {13},
keywords = {tooling roadmap, tool support, state of practice, spl in practice},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461001.3473060,
author = {Sch\"{a}fer, Andreas and Becker, Martin and Andres, Markus and Kistenfeger, Tim and Rohlf, Florian},
title = {Variability realization in model-based system engineering using software product line techniques: an industrial perspective},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473060},
doi = {10.1145/3461001.3473060},
abstract = {Efficiently handling system variants is rising of importance in industry and challenges the application of model-based systems engineering.This paper reveals the increasing industrial demand of guidance and decision support on how to handle variants and variability within SysML and UML models. While a substantial amount of variability realization approaches has already been published on source code level, there is little guidance for practitioners on system model level. Hence, there is major uncertainty in dealing with system changes or concurrent system modeling of related system. Due to a poor modularization and variability realization these model variants are ending up in interwoven and complex system models.In this paper, we aim to raise awareness of the need for appropriate guidance and decision support, identify important contextual factors of MBSE that influence variability realization, and derive well known variability mechanisms used in software coding for their applicability in system modeling.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {25–34},
numpages = {10},
keywords = {variant management, variability realization, variability mechanism, system and software product line engineering, model-based systems engineering, decision support, UML, SysML},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {product-line analysis, Software product lines}
}

@inproceedings{10.1145/1629716.1629723,
author = {Apel, Sven and Liebig, J\"{o}rg and K\"{a}stner, Christian and Kuhlemann, Martin and Leich, Thomas},
title = {An orthogonal access modifier model for feature-oriented programming},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629723},
doi = {10.1145/1629716.1629723},
abstract = {In feature-oriented programming (FOP), a programmer decomposes a program in terms of features. Ideally, features are implemented modularly so that they can be developed in isolation. Access control is an important ingredient to attain feature modularity as it provides mechanisms to hide and expose internal details of a module's implementation. But developers of contemporary feature-oriented languages did not consider access control mechanisms so far. The absence of a well-defined access control model for FOP breaks the encapsulation of feature code and leads to unexpected and undefined program behaviors as well as inadvertent type errors, as we will demonstrate. The reason for these problems is that common object-oriented modifiers, typically provided by the base language, are not expressive enough for FOP and interact in subtle ways with feature-oriented language mechanisms. We raise awareness of this problem, propose three feature-oriented modifiers for access control, and present an orthogonal access modifier model.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {27–33},
numpages = {7},
keywords = {feature-oriented programming, orthogonal access modifier model},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1145/3461001.3471141,
author = {Casquina, Junior Cupe and Montecchi, Leonardo},
title = {A proposal for organizing source code variability in the git version control system},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471141},
doi = {10.1145/3461001.3471141},
abstract = {Often, either to expand the target market or to satisfy specific new requirements, software systems inside a company are cloned, refactored, and customized, generating new derived software systems. Although this is a practical solution, it is not effective in the long-term because of the high maintenance costs when maintaining each of these derived software systems. Software product lines (SPLs) were proposed to reduce these costs; however, the lack of integration between variability realization mechanisms and version control systems reduces its attractiveness in the software development industry, especially in small and medium software companies. In this paper we propose an approach to integrate the conditional compilation mechanism used to implement the SPL variabilities and the Git version control system used to manage software versions in order to increase the attractiveness of the SPLs in the industry. The proposed solution also could be seen as a method to manage software system families' evolution in space and time.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {82–88},
numpages = {7},
keywords = {software product lines, conditional compilation, VarCS, SPL, Git},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2814204.2814212,
author = {Seidl, Christoph and Schuster, Sven and Schaefer, Ina},
title = {Generative software product line development using variability-aware design patterns},
year = {2015},
isbn = {9781450336871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814204.2814212},
doi = {10.1145/2814204.2814212},
abstract = {Software Product Lines (SPLs) are an approach to reuse in-the-large that models a set of closely related software systems in terms of commonalities and variabilities. Design patterns are best practices for addressing recurring design problems in object-oriented source code. In the practice of implementing an SPL, instances of certain design patterns are employed to handle variability, which makes these "variability-aware design patterns" a best practice for SPL design. However, there currently is no dedicated method for proactively developing SPL using design patterns suitable for realizing variable functionality. In this paper, we present a method to perform generative SPL development with design patterns. We use role models to capture design patterns and their relation to a variability model. We further allow mapping of individual design pattern roles to elements of realization artifacts to be generated (e.g., classes, methods) and check the conformance of the realization with the specification of the pattern. With this method, we support proactive development of SPL using design patterns to apply best practices for the realization of variability. We present an implementation of our approach within the Eclipse IDE and demonstrate it within a case study.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {151–160},
numpages = {10},
keywords = {Software Product Line (SPL), Role Modeling, Generative Development, Design Pattern},
location = {Pittsburgh, PA, USA},
series = {GPCE 2015}
}

@inproceedings{10.1145/3132498.3133835,
author = {Cardoso, Mateus Passos Soares and Lima, Crescencio and de Almeida, Eduardo Santana and do Carmo Machado, Ivan and von Flach G. Chavez, Christina},
title = {Investigating the variability impact on the recovery of software product line architectures: an exploratory study},
year = {2017},
isbn = {9781450353250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132498.3133835},
doi = {10.1145/3132498.3133835},
abstract = {The Product Line Architecture (PLA) of a Software Product Line (SPL) is the core architecture that represents a high-level design for all the products of an SPL, including variation points and variants. If PLA documentation is missing, it can be recovered by reverse engineering the products. The recovered PLA is a relevant asset for developers and architects, that can be used to drive specific activities of SPL development and evolution, such as, understanding its structure and its variation points, and assessing reuse. This paper presents an exploratory study that investigated the effectiveness of recovered PLAs to address variability identification and support reuse assessment. We recovered the PLA of 15 open source SPL projects using the PLAR, a tool that supports PLA recovery and assessment based on information extracted from SPL products' source code. For each project, reuse assessment was supported by existing reuse metrics. The yielded results revealed that the number of products used in PLA recovery affected the variability identification, and the number of optional features affected the components reuse rate. These findings suggest that a minimum set of representative products should be identified and selected for PLA recovery, and the component reuse rate is a candidate metric for SPL reuse assessment.},
booktitle = {Proceedings of the 11th Brazilian Symposium on Software Components, Architectures, and Reuse},
articleno = {12},
numpages = {10},
keywords = {variability, software product lines, product line architecture recovery, product line architecture},
location = {Fortaleza, Cear\'{a}, Brazil},
series = {SBCARS '17}
}

@inproceedings{10.1145/2593882.2593888,
author = {Metzger, Andreas and Pohl, Klaus},
title = {Software product line engineering and variability management: achievements and challenges},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593888},
doi = {10.1145/2593882.2593888},
abstract = {Software product line engineering has proven to empower organizations to develop a diversity of similar software-intensive systems (applications) at lower cost, in shorter time, and with higher quality when compared with the development of single systems. Over the last decade the software product line engineering research community has grown significantly. It has produced impressive research results both in terms of quality as well as quantity. We identified over 600 relevant research and experience papers published within the last seven years in established conferences and journals. We briefly summarize the major research achievements of these past seven years. We structure this research summary along a standardized software product line framework. Further, we outline current and future research challenges anticipated from major trends in software engineering and technology.},
booktitle = {Future of Software Engineering Proceedings},
pages = {70–84},
numpages = {15},
keywords = {variability modeling, variability management, requirements engineering, quality assurance, design, Software product lines},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@inproceedings{10.1145/3546932.3546989,
author = {Bertolotti, Francesco and Cazzola, Walter and Favalli, Luca},
title = {Features, believe it or not! a design pattern for first-class citizen features on stock JVM},
year = {2022},
isbn = {9781450394437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546932.3546989},
doi = {10.1145/3546932.3546989},
abstract = {Modern software systems must fulfill the needs of an ever-growing customer base. Due to the innate diversity of human needs, software should be highly customizable and reconfigurable. Researchers and practitioners gained interest in software product lines (SPL), mimicking aspects of product lines in industrial production for the engineering of highly-variable systems. There are two main approaches towards the engineering of SPLs. The first uses macros---such as the #ifdef macro in C. The second---called feature-oriented programming (FOP)---uses variability-aware preprocessors called composers to generate a program variant from a set of features and a configuration. Both approaches have disadvantages. Most notably, these approaches are usually not supported by the base language; for instance Java is one of the most commonly used FOP languages among researchers, but it does not support macros rather it relies on the C preprocessor or a custom one to translate macros into actual Java code. As a result, developers must struggle to keep up with the evolution of the base language, hindering the general applicability of SPL engineering. Moreover, to effectively evolve a software configuration and its features, their location must be known. The problem of recording and maintaining traceability information is considered expensive and error-prone and it is once again handled externally through dedicated modeling languages and tools. Instead, to properly convey the FOP paradigm, software features should be treated as first-class citizens using concepts that are proper to the host language, so that the variability can be expressed and analyzed with the same tools used to develop any other software in the same language. In this paper, we present a simple and flexible design pattern for JVM-based languages---dubbed devise pattern---that can be used to express feature dependencies and behaviors with a light-weight syntax both at domain analysis and at domain implementation level. To showcase the qualities and feasibility of our approach, we present several variability-aware implementations of a MNIST-encoder---including one using the devise pattern---and compare strengths and weaknesses of each approach.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A},
pages = {32–42},
numpages = {11},
keywords = {variability modeling, software product lines, design patterns},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3646548.3672585,
author = {Landsberg, Tobias and Dietrich, Christian and Lohmann, Daniel},
title = {Should I Bother? Fast Patch Filtering for Statically-Configured Software Variants},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672585},
doi = {10.1145/3646548.3672585},
abstract = {In the face of critical security vulnerabilities, patch and update management are a crucial and challenging part of the software life cycle. In software product families, patching becomes even more challenging as we have to support different variants, which are not equally affected by critical patches. While the naive “better-patched-than-sorry” approach will apply all necessary updates, it provokes avoidable costs for developers and customers. In this paper we introduce SiB (Should I Bother?), a heuristic patch-filtering method for statically-configurable software that efficiently identifies irrelevant patches for specific variants. To solve the variability-aware patch-filtering problem, SiB compares modified line ranges from patches with those source-code ranges included in variants currently deployed. We apply our prototype for CPP-managed variability to four open-source projects (Linux, OpenSSL, SQLite, Bochs), demonstrating that SiB is both effective and efficient in reducing the number of to-be-considered patches for unaffected software variants. It correctly classifies up to 68 percent of variants as unaffected, with a recall of 100 percent, thus reducing deployments significantly, without missing any relevant patches.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {12–23},
numpages = {12},
keywords = {Patch Filtering, Software Evolution, Software Product Lines},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.1145/3579027.3608972,
author = {Acher, Mathieu and Duarte, Jos\'{e} Galindo and J\'{e}z\'{e}quel, Jean-Marc},
title = {On Programming Variability with Large Language Model-based Assistant},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608972},
doi = {10.1145/3579027.3608972},
abstract = {Programming variability is central to the design and implementation of software systems that can adapt to a variety of contexts and requirements, providing increased flexibility and customization. Managing the complexity that arises from having multiple features, variations, and possible configurations is known to be highly challenging for software developers. In this paper, we explore how large language model (LLM)-based assistants can support the programming of variability.We report on new approaches made possible with LLM-based assistants, like: features and variations can be implemented as prompts; augmentation of variability out of LLM-based domain knowledge; seamless implementation of variability in different kinds of artefacts, programming languages, and frameworks, at different binding times (compile-time or run-time). We are sharing our data (prompts, sessions, generated code, etc.) to support the assessment of the effectiveness and robustness of LLMs for variability-related tasks.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {8–14},
numpages = {7},
keywords = {variability, software product lines, programming, large language model, generative AI},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3236405.3236426,
author = {Belarbi, Maouaheb},
title = {A methodological framework to enable the generation of code from DSML in SPL},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236426},
doi = {10.1145/3236405.3236426},
abstract = {Software Product Line has acquired a significant momentum at the end of the 1990ies since it allows the production of variable software systems corresponding to the same domain portfolio. The effectiveness of the derivation process depends on how well variability is defined and implemented which is a crucial topic area that was addressed among two essential trends: On the one hand, starting from Domain Specific Modelling Language to express domain requirements and automate the code generation with Model-Driven Engineering techniques and on the second hand, exploiting the soar of variability mechanisms.In this context, the current research presents a method that unifies the two aforementioned approaches to cover the overall strategies by defining a framework that allows a better code generation in terms of documentation, maintainability, rapidity,etc. The starting point is the usage of the Domain Specific Modelling Language to represent the stakeholders requirements. Then, the resulting meta-model will be converted into one our several Feature Diagrams on which variability mechanisms can be applied to generate all the family products.A preliminary experiment has been undertaken to design the methodology of the proposed software factory in a meta-model. The validation task was evaluated with an academic use case called HandiWeb developed to facilitate handicap persons access to the internet. The first results allow us to put the hand on the key challenges that must be resolved by the proposed methodology.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {64–71},
numpages = {8},
keywords = {variability, software factory, methodology, SPL, DSML},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2048066.2048128,
author = {K\"{a}stner, Christian and Giarrusso, Paolo G. and Rendel, Tillmann and Erdweg, Sebastian and Ostermann, Klaus and Berger, Thorsten},
title = {Variability-aware parsing in the presence of lexical macros and conditional compilation},
year = {2011},
isbn = {9781450309400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2048066.2048128},
doi = {10.1145/2048066.2048128},
abstract = {In many projects, lexical preprocessors are used to manage different variants of the project (using conditional compilation) and to define compile-time code transformations (using macros). Unfortunately, while being a simple way to implement variability, conditional compilation and lexical macros hinder automatic analysis, even though such analysis is urgently needed to combat variability-induced complexity. To analyze code with its variability, we need to parse it without preprocessing it. However, current parsing solutions use unsound heuristics, support only a subset of the language, or suffer from exponential explosion. As part of the TypeChef project, we contribute a novel variability-aware parser that can parse almost all unpreprocessed code without heuristics in practicable time. Beyond the obvious task of detecting syntax errors, our parser paves the road for further analysis, such as variability-aware type checking. We implement variability-aware parsers for Java and GNU C and demonstrate practicability by parsing the product line MobileMedia and the entire X86 architecture of the Linux kernel with 6065 variable features.},
booktitle = {Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications},
pages = {805–824},
numpages = {20},
keywords = {variability, software product lines, preprocessor, parsing, linux, conditional compilation, c, #ifdef},
location = {Portland, Oregon, USA},
series = {OOPSLA '11}
}

@inproceedings{10.1145/3461002.3473947,
author = {Pinnecke, Marcus},
title = {Product-lining the elinvar wealthtech microservice platform},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473947},
doi = {10.1145/3461002.3473947},
abstract = {Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {60–68},
numpages = {9},
keywords = {variability management, technologies and concepts, product families, microservice platforms, configuration management},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382026.3425775,
author = {Nair, Suparna S. and Becker, Martin and Tenev, Vasil},
title = {A Comparative Study on Variability Code Analysis Technology},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425775},
doi = {10.1145/3382026.3425775},
abstract = {Product line engineering is often conducted in an incremental way, in which the variability artifacts evolve in the space, the time, as well as the asset dimension. In order to cope with the evolution of the variability, the VITAL approach and tool have been developed and used in different industrial settings to analyze variability realizations relying on the C preprocessor. Over the last decade, further promising analysis approaches and tools have been developed. To understand, if and how they could enhance the VITAL approach, we have conducted an analysis of promising technologies.In this paper, we share some of our findings along our comparative study on variability code analysis technologies. As we have conducted the study in the light of the intended VITAL enhancement, the study does not claim completeness. Nevertheless, we believe that the findings can help researchers and industrial practitioners to gain an overview and find entry points for their own investigations.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {37–43},
numpages = {7},
keywords = {software product line, reverse engineering, configuration knowledge, Variability realization},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3579027.3608985,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Greiner, Sandra and Moosherr, Benjamin and Krieter, Sebastian and Tinnes, Christof and Kehrer, Timo and Th\"{u}m, Thomas},
title = {Views on Edits to Variational Software},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608985},
doi = {10.1145/3579027.3608985},
abstract = {Software systems are subject to frequent changes, for example to fix bugs or meet new customer requirements. In variational software systems, developers are confronted with the complexity of evolution and configurability on a daily basis; essentially handling changes to many distinct software variants simultaneously. To reduce the complexity of configurability for developers, filtered or projectional editing was introduced: By providing a partial or complete configuration, developers can interact with a simpler view of the variational system that shows only artifacts belonging to that configuration. Yet, such views are available for individual revisions only but not for edits performed across revisions. To reduce the complexity of evolution in variational software for developers, we extend the concept of views to edits. We formulate a correctness criterion for views on edits and introduce two correct operators for view generation, one operator suitable for formal reasoning, and a runtime optimized operator. In an empirical study, we demonstrate the feasibility of our operators by applying them to the change histories of 44 open-source software systems.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {141–152},
numpages = {12},
keywords = {variation control, software variability, software product lines, software evolution, projectional editing},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3546932.3547009,
author = {J\'{e}z\'{e}quel, Jean-Marc and Kienzle, J\"{o}rg and Acher, Mathieu},
title = {From feature models to feature toggles in practice},
year = {2022},
isbn = {9781450394437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546932.3547009},
doi = {10.1145/3546932.3547009},
abstract = {Feature Toggles (often also referred to as Feature Flags) are a powerful technique, providing an alternative to maintaining multiple feature branches in source code. A condition within the code enables or disables a feature at runtime, hence providing a kind of runtime variability resolution. Several works have already identified the proximity of this concept with the notion of Feature found in Software Product Lines. In this paper, we propose to go one step further in unifying these concepts to provide a seamless transition between design time and runtime variability resolutions. We propose to model all the variability using a feature model. Then this feature model can be partially resolved at design time (yielding an incomplete product derivation), the unresolved variability being used to generate feature toggles that can be enabled/disabled at runtime. We first demonstrate these ideas on the toy example of the Expression Product Line, and then show how it can scale to build a configurable authentication system, where a partially resolved feature model can interface with popular feature toggle frameworks such as Togglz.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A},
pages = {234–244},
numpages = {11},
keywords = {variability, feature toggles and flags, configuration, binding times},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3579027.3608984,
author = {Krieter, Sebastian and Kr\"{u}ger, Jacob and Leich, Thomas and Saake, Gunter},
title = {VariantInc: Automatically Pruning and Integrating Versioned Software Variants},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608984},
doi = {10.1145/3579027.3608984},
abstract = {Developers use version-control systems and software-hosting platforms to manage their software systems. They rely on the provided branching and forking mechanisms to implement new features, fix bugs, and develop customized system variants. A particular problem arises when forked variants are not re-integrated (i.e., merged), but kept and co-evolved as individual systems. This can cause maintenance overheads, due to change propagation and limitations in simultaneously managing variations in space (variants) and time (revisions). Thus, most organizations decide to integrate their set of variants into a single platform at some point, and several techniques have been proposed to semi-automate such an integration. However, existing techniques usually consider only a single revision of each variant and do not merge the revision histories, disregarding that not only variants (i.e., configuring the features of the system) but also revisions (i.e., checking out specific versions of the features) are important. We propose an automated technique, VariantInc, for analyzing, pruning, and integrating variants of a system that also merges the revision history of each variant into the resulting platform (i.e., using presence conditions). To validate VariantInc, we employed it on 160 open-source C systems of various sizes (i.e., number of forks, revisions, source code). The results show that VariantInc works as intended, and allows developers or researchers to automatically integrate variants into a platform as well as to perform software analyses.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {129–140},
numpages = {12},
keywords = {Version control, Variant-rich systems, Variant integration, Forks},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3579027.3608996,
author = {Fischer, Stefan and Ramler, Rudolf and Assun\c{c}\~{a}o, Wesley K. G. and Egyed, Alexander and Gradl, Christian and Auberger, Sebastian},
title = {Model-based Testing for a Family of Mobile Applications: Industrial Experiences},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608996},
doi = {10.1145/3579027.3608996},
abstract = {Testing is a fundamental verification activity to produce high-quality software. However, testing is a costly and complex activity. The success of software testing depends on the quality of test cases but finding a good set of test cases is laborious. To make matters worse, when dealing with a family of systems (e.g., variants of a mobile applications), test cases must assure that a diversity of configurations in potentially many variants work as expected. This is the case of hello again GmbH, a company that develops mobile applications for customer loyalty (e.g., discounts, free products, rewards, or insider perks). The company targets several business domains, and currently supports about 700 application variants. Testing such applications including all their variability is a cumbersome task. Even simple test cases designed for one variant most likely cannot be reused for other variants. To support developers at hello again GmbH, we present a solution to employ a model-based testing approach to their family of mobile apps. Model-based testing focuses on automatizing the design and generation of test cases. We present results of applying model-based testing on 27 applications from hello again GmbH and report the challenges and lessons learned for designing a variable test model. Our expected contribution is to support companies and practitioners looking for solutions to test families of software products.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {242–253},
numpages = {12},
keywords = {Variability Testing, Software Product Lines, Mobile Testing},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/1176887.1176897,
author = {Yoshimura, Kentaro and Ganesan, Dharmalingam and Muthig, Dirk},
title = {Defining a strategy to introduce a software product line using existing embedded systems},
year = {2006},
isbn = {1595935428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1176887.1176897},
doi = {10.1145/1176887.1176897},
abstract = {Engine Control Systems (ECS) for automobiles have numerous variants for many manufactures and different markets. To improve development efficiency, exploiting ECS commonalities and predicting their variability are mandatory. The concept of software product line engineering meets the business background of ECS. However, we should carefully investigate the expected technical, economical, and organizational effects of introducing this strategy into existing products.This paper explains an approach for assessing the potential of merging existing embedded software into a product line approach. The definition of an economically useful product line approach requires two things: analyzing return on investment (ROI) expectations of a product line and understanding the effort required for building reusable assets. We did a clone analysis to provide the basis for effort estimation for merge potential assessment of existing variants. We also report on a case study with ECS. We package the lessons learned and open issues that arose during the case study.},
booktitle = {Proceedings of the 6th ACM &amp; IEEE International Conference on Embedded Software},
pages = {63–72},
numpages = {10},
keywords = {software product line, software, reverse rngineering, engine control systems, economics, clone detection and classification},
location = {Seoul, Korea},
series = {EMSOFT '06}
}

@inproceedings{10.1109/ASE.2015.106,
author = {Pietsch, Christopher and Kehrer, Timo and Kelter, Udo and Reuling, Dennis and Ohrndorf, Manuel},
title = {SiPL: a delta-based modeling framework for software product line engineering},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.106},
doi = {10.1109/ASE.2015.106},
abstract = {Model-based development has become a widely-used approach to implement software, e.g. for embedded systems. Models replace source code as primary executable artifacts in these cases. Software product line technologies for these domains must be able to generate models as instances of an SPL. This need is addressed among others by an implementation technology for SPLs known as delta modeling. Current approaches to delta modeling require deltas to be written manually using delta languages, and they offer only very limited support for creating and testing a network of deltas. This paper presents a new approach to delta modeling and a supporting tool suite: the abstract notion of a delta is refined to be a consistency-preserving edit script which is generated by comparing two models. The rich structure of edit scripts allows us to detect conflicts and further relations between deltas statically and to implement restructurings in delta sets such as the merging of two deltas. We illustrate the tooling using a case study.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {852–857},
numpages = {6},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@inproceedings{10.1145/3336294.3336321,
author = {Ghofrani, Javad and Kozegar, Ehsan and Fehlhaber, Anna Lena and Soorati, Mohammad Divband},
title = {Applying Product Line Engineering Concepts to Deep Neural Networks},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336321},
doi = {10.1145/3336294.3336321},
abstract = {Deep Neural Networks (DNNs) are increasingly being used as a machine learning solution thanks to the complexity of their architecture and hyperparameters-weights. A drawback is the excessive demand for massive computational power during the training process. Not only as a whole but parts of neural networks can also be in charge of certain functionalities. We present a novel challenge in an intersection between machine learning and variability management communities to reuse modules of DNNs without further training. Let us assume that we are given a DNN for image processing that recognizes cats and dogs. By extracting a part of the network, without additional training a new DNN should be divisible with the functionality of recognizing only cats. Existing research in variability management can offer a foundation for a product line of DNNs composing the reusable functionalities. An ideal solution can be evaluated based on its speed, granularity of determined functionalities, and the support for adding variability to the network. The challenge is decomposed in three subchallenges: feature extraction, feature abstraction, and the implementation of a product line of DNNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {72–77},
numpages = {6},
keywords = {variability, transfer learning, software product lines, machine learning, deep neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/1217935.1217955,
author = {Krishna, Arvind S. and Gokhale, Aniruddha S. and Schmidt, Douglas C.},
title = {Context-specific middleware specialization techniques for optimizing software product-line architectures},
year = {2006},
isbn = {1595933220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1217935.1217955},
doi = {10.1145/1217935.1217955},
abstract = {Product-line architectures (PLAs) are an emerging paradigm for developing software families for distributed real-time and embedded (DRE) systems by customizing reusable artifacts, rather than hand-crafting software from scratch. To reduce the effort of developing software PLAs and product variants for DRE systems, developers are applying general-purpose -- ideally standard -- middleware platforms whose reusable services and mechanisms support a range of application quality of service (QoS) requirements, such as low latency and jitter. The generality and flexibility of standard middleware, however, often results in excessive time/space overhead for DRE systems, due to lack of optimizations tailored to meet the specific QoS requirements of different product variants in a PLA.This paper provides the following contributions to the study of middleware specialization techniques for PLA-based DRE systems. First, we identify key dimensions of generality in standard middleware stemming from framework implementations, deployment platforms, and middleware standards. Second, we illustrate how context-specific specialization techniques can be automated and used to tailor standard middleware to better meet the QoS needs of different PLA product variants. Third, we quantify the benefits of applying automated tools to specialize a standard Realtime CORBA middleware implementation. When applied together, these middleware specializations improved our application product variant throughput by ~65%, average- and worst-case end-to-end latency measures by ~43% and ~45%, respectively, and predictability by a factor of two over an already optimized middleware implementation, with little or no effect on portability, standard middleware APIs, or application software implementations, and interoperability.},
booktitle = {Proceedings of the 1st ACM SIGOPS/EuroSys European Conference on Computer Systems 2006},
pages = {205–218},
numpages = {14},
keywords = {specializations, product lines, middleware},
location = {Leuven, Belgium},
series = {EuroSys '06}
}

@inproceedings{10.1145/3233027.3233043,
author = {Masri, Samer AL and Nadi, Sarah and Gaudet, Matthew and Liang, Xiaoli and Young, Robert W.},
title = {Using static analysis to support variability implementation decisions in C++},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233043},
doi = {10.1145/3233027.3233043},
abstract = {Eclipse OMR is an open-source C++ framework for building robust language runtimes. The OMR toolkit includes a dynamic Just-In-Time (JIT) compiler, a garbage collector, a platform abstraction library, and a set of developer tooling capabilities. To support the diverse languages and architectures targeted by the framework, OMR's variability implementation uses a combination of build-system variability and static polymorphism. That is, all implementation classes that depend on the selected language and architecture are decided at compile time. However, OMR developers now realize that the current variability design decision, specifically the static polymorphism implementation, has its drawbacks. They are considering using dynamic polymorphism instead of static polymorphism. Before making such a fundamental design change, however, it is crucial to collect function information and overload/override statistics about the current variability in the code base.In this paper, we present OMRStatistics, a static analysis tool that we built for OMR developers to help them collect this information. Specifically, OMRStatistics (1) visualizes the class hierarchy from OMR's current static polymorphic implementation, (2) visualizes the function overloads and overrides with their respective locations in the source code, (3) collects important information about the classes and functions, and (4) stores all the collected information in a database for further analysis. Our tool OMRStatistics allows OMR developers to make better design decisions on which variability extension points should be switched from static polymorphism to dynamic polymorphism.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {236–245},
numpages = {10},
keywords = {static polymorphism, static analysis, software variability analysis, dynamic polymorphism, clang plugin, build path variability, C++},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106213,
author = {Fu\ss{}berger, Nicolas and Zhang, Bo and Becker, Martin},
title = {A Deep Dive into Android's Variability Realizations},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106213},
doi = {10.1145/3106195.3106213},
abstract = {The open source Android operation system is widely used in both mobile consumer electronics as well as other industrial devices. It has actually become a variability-intensive system that can be highly customized to support different customers' requirements and hardware environments, which is a good inspiration for both practitioners and researchers. However, it is still unclear where and how variability is realized in its source code repository. In this paper, we conduct a systematic analysis on the variability realization of the Android operation system. The analysis focuses on the usage of different variability realization mechanisms (e.g., Conditional Compilation) in the Android source code and build environment. Finally, the study provides qualitative and quantitative results that help to understand i) what variability-specific artefacts exist in the Android source repository using which variability mechanisms and techniques; ii) how these artefacts express and instantiate variability along the layered Android realization architecture.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {69–78},
numpages = {10},
keywords = {Variability Realization, Variability Mechanisms, Android},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3106195.3106214,
author = {Couto, Marco and Borba, Paulo and Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and Pereira, Rui and Saraiva, Jo\~{a}o},
title = {Products go Green: Worst-Case Energy Consumption in Software Product Lines},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106214},
doi = {10.1145/3106195.3106214},
abstract = {The optimization of software to be (more) energy efficient is becoming a major concern for the software industry. Although several techniques have been presented to measure energy consumption for software, none has addressed software product lines (SPLs). Thus, to measure energy consumption of a SPL, the products must be generated and measured individually, which is too costly.In this paper, we present a technique and a prototype tool to statically estimate the worst case energy consumption for SPL. The goal is to provide developers with techniques and tools to reason about the energy consumption of all products in a SPL, without having to produce, run and measure the energy in all of them.Our technique combines static program analysis techniques and worst case execution time prediction with energy consumption analysis. This technique analyzes all products in a feature-sensitive manner, that is, a feature used in several products is analyzed only once, while the energy consumption is estimated once per product.We implemented our technique in a tool called Serapis. We did a preliminary evaluation using a product line for image processing implemented in C. Our experiments considered 7 products from such line and our initial results show that the tool was able to estimate the worst-case energy consumption with a mean error percentage of 9.4% and standard deviation of 6.2% when compared with the energy measured when running the products.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {84–93},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2647908.2655972,
author = {Meinicke, Jens and Th\"{u}m, Thomas and Schr\"{o}ter, Reimar and Benduhn, Fabian and Saake, Gunter},
title = {An overview on analysis tools for software product lines},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655972},
doi = {10.1145/2647908.2655972},
abstract = {A software product line is a set of different software products that share commonalities. For a selection of features, specialized products of one domain can be generated automatically from domain artifacts. However, analyses of software product lines need to handle a large number of products that can be exponential in the number of features. In the last decade, many approaches have been proposed to analyze software product lines efficiently. For some of these approaches tool support is available. Based on a recent survey on analysis for software product lines, we provide a first overview on such tools. While our discussion is limited to analysis tools, we provide an accompanying website covering further tools for product-line development. We compare tools according to their analysis and implementation strategy to identify underrepresented areas. In addition, we want to ease the reuse of existing tools for researchers and students, and to simplify research transfer to practice.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {94–101},
numpages = {8},
keywords = {type checking, tool support, theorem proving, testing, static analysis, software product lines, sampling, non-functional properties, model checking, code metrics},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/1868688.1868690,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Apel, Sven},
title = {Automating energy optimization with features},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868690},
doi = {10.1145/1868688.1868690},
abstract = {Mobile devices such as cell phones and notebooks rely on battery power supply. For these systems, optimizing the power consumption is important to increase the system's lifetime. However, this is hard to achieve because energy-saving functions often depend on the hardware, and operating systems. The diversity of hardware components and operating systems makes the implementation time consuming and difficult. We propose an approach to automate energy optimization of programs by implementing energy-saving functionality as modular, separate implementation units (e.g., feature modules or aspects). These units are bundled as energy features into an energy-optimization feature library. Based on aspect-oriented and feature-oriented programming, we discuss different techniques to compose the source code of a client program and the implementation units of the energy features.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {2–9},
numpages = {8},
keywords = {software product lines, feature-oriented programming, energy consumption},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/2791060.2791108,
author = {Berger, Thorsten and Lettner, Daniela and Rubin, Julia and Gr\"{u}nbacher, Paul and Silva, Adeline and Becker, Martin and Chechik, Marsha and Czarnecki, Krzysztof},
title = {What is a feature? a qualitative study of features in industrial software product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791108},
doi = {10.1145/2791060.2791108},
abstract = {The notion of features is commonly used to describe the functional and non-functional characteristics of a system. In software product line engineering, features often become the prime entities of software reuse and are used to distinguish the individual products of a product line. Properly decomposing a product line into features, and correctly using features in all engineering phases, is core to the immediate and long-term success of such a system. Yet, although more than ten different definitions of the term feature exist, it is still a very abstract concept. Definitions lack concrete guidelines on how to use the notion of features in practice.To address this gap, we present a qualitative empirical study on actual feature usage in industry. Our study covers three large companies and an in-depth, contextualized analysis of 23 features, perceived by the interviewees as typical, atypical (outlier), good, or bad representatives of features. Using structured interviews, we investigate the rationales that lead to a feature's perception, and identify and analyze core characteristics (facets) of these features. Among others, we find that good features precisely describe customer-relevant functionality, while bad features primarily arise from rashly executed processes. Outlier features, serving unusual purposes, are necessary, but do not require the full engineering process of typical features.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {16–25},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2491627.2491644,
author = {Rubin, Julia and Czarnecki, Krzysztof and Chechik, Marsha},
title = {Managing cloned variants: a framework and experience},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491644},
doi = {10.1145/2491627.2491644},
abstract = {In our earlier work, we have proposed a generic framework for managing collections of related products realized via cloning -- both in the case when such products are refactored into a single-copy software product line representation and the case when they are maintained as distinct clones. In this paper, we ground the framework in empirical evidence and exemplify its usefulness. In particular, we systematically analyze three industrial case studies of organizations with cloned product lines and derive the set of basic operators comprising the framework. We discuss options for implementing the operators and benefits of the operator-based view.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {101–110},
numpages = {10},
keywords = {legacy software product lines, industrial case studies, cloned product variants},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2791060.2791099,
author = {Filho, Jo\~{a}o Bosco Ferreira and Allier, Simon and Barais, Olivier and Acher, Mathieu and Baudry, Benoit},
title = {Assessing product line derivation operators applied to Java source code: an empirical study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791099},
doi = {10.1145/2791060.2791099},
abstract = {Product Derivation is a key activity in Software Product Line Engineering. During this process, derivation operators modify or create core assets (e.g., model elements, source code instructions, components) by adding, removing or substituting them according to a given configuration. The result is a derived product that generally needs to conform to a programming or modeling language. Some operators lead to invalid products when applied to certain assets, some others do not; knowing this in advance can help to better use them, however this is challenging, specially if we consider assets expressed in extensive and complex languages such as Java. In this paper, we empirically answer the following question: which product line operators, applied to which program elements, can synthesize variants of programs that are incorrect, correct or perhaps even conforming to test suites? We implement source code transformations, based on the derivation operators of the Common Variability Language. We automatically synthesize more than 370,000 program variants from a set of 8 real large Java projects (up to 85,000 lines of code), obtaining an extensive panorama of the sanity of the operations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {36–45},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3001867.3001869,
author = {Schuster, Sven and Nieke, Michael and Schaefer, Ina},
title = {Name resolution strategies in variability realization languages for software product lines},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001869},
doi = {10.1145/3001867.3001869},
abstract = {Software Product Lines (SPLs) exploit reuse-in-the-large to enable customization by explicitly modeling commonalities and variabilities of closely related software systems. Different approaches exist to enable SPL development and product creation by using modular languages, such as Feature-Oriented Programming (FOP) (compositional) or Delta-Oriented Programming (DOP) (transformational). These languages incorporate, e.g., object-oriented languages, adding a layer of variability. Creating a variabilityaware Abstract Syntax Graph (ASG), i.e., an ASG that contains the complete variability of the SPL, facilitates family-based analyses and is essential for supporting developers during SPL development. To this end, name resolution has to be performed. However, name resolution for these languages is a challenge as multiple declarations for the same element may occur in different modules. In this paper, we propose four name resolution strategies for compositional and transformational SPL realization languages and discuss their benefits and drawbacks, categorized by relevant application scenarios of the ASG.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {11–17},
numpages = {7},
keywords = {name resolution, Software Product Lines, Feature-Oriented Programming, Delta-Oriented Programming, Abstract Syntax Graph},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@inproceedings{10.1145/3336294.3336319,
author = {Carvalho, Luiz and Garcia, Alessandro and Assun\c{c}\~{a}o, Wesley K. G. and Bonif\'{a}cio, Rodrigo and Tizzei, Leonardo P. and Colanzi, Thelma Elita},
title = {Extraction of Configurable and Reusable Microservices from Legacy Systems: An Exploratory Study},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336319},
doi = {10.1145/3336294.3336319},
abstract = {Microservices is an emerging industrial technique to promote better modularization and management of small and autonomous services. Microservice architecture is widely used to overcome the limitations of monolithic legacy systems, such as limited maintainability and reusability. Migration to a microservice architecture is increasingly becoming the focus of academic research. However, there is little knowledge on how microservices are extracted from legacy systems in practice. Among these limitations, there is a lack of understanding if variability is considered useful along the microservice extraction from a configurable system. In order to address this gap, we performed an exploratory study composed of two phases. Firstly, we conducted an online survey with 26 specialists that contributed to the migration of existing systems to a microservice architecture. Secondly, we performed individual interviews with seven survey participants. A subset of the participants (13 out of 26) dealt with systems with variability during the extraction, which stated that variability is a key criterion for structuring the microservices. Moreover, variability in the legacy system is usually implemented with simple mechanisms. Finally, initial evidence points out that microservices extraction can increase software customization.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {26–31},
numpages = {6},
keywords = {software variability, microservice customization, microservice architecture, architecture migration},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342414,
author = {Th\"{u}m, Thomas and Teixeira, Leopoldo and Schmid, Klaus and Walkingshaw, Eric and Mukelabai, Mukelabai and Varshosaz, Mahsa and Botterweck, Goetz and Schaefer, Ina and Kehrer, Timo},
title = {Towards Efficient Analysis of Variation in Time and Space},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342414},
doi = {10.1145/3307630.3342414},
abstract = {Variation is central to today's software development. There are two fundamental dimensions to variation: Variation in time refers to the fact that software exists in numerous revisions that typically replace each other (i.e., a newer version supersedes an older one). Variation in space refers to differences among variants that are designed to coexist in parallel. There are numerous analyses to cope with variation in space (i.e., product-line analyses) and others that cope with variation in time (i.e., regression analyses). The goal of this work is to discuss to which extent product-line analyses can be applied to revisions and, conversely, where regression analyses can be applied to variants. In addition, we discuss challenges related to the combination of product-line and regression analyses. The overall goal is to increase the efficiency of analyses by exploiting the inherent commonality between variants and revisions.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {57–64},
numpages = {8},
keywords = {variability-aware analysis, variability management, software variation, software product lines, software evolution, software configuration management, regression analysis, product-line analysis},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2491627.2491636,
author = {Kato, Tadahisa and Kawakami, Masumi and Myojin, Tomoyuki and Ogawa, Hideto and Hirono, Koji and Hasegawa, Takashi},
title = {Case study of applying SPLE to development of network switch products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491636},
doi = {10.1145/2491627.2491636},
abstract = {Software product line engineering has spread as a technique for promoting the efficient development of embedded products with many product line-ups. During the development of network switch products at Hitachi Metals, Ltd., the number of development man-months increased as the number of product line-ups increased. Therefore, we shifted our development paradigm to product line development for efficient product development. We classified software assets as implementation assets, test assets, and design assets, and from these three assets, we extracted common objects and integrated them as reusable elements. By doing so, we promoted the efficient development of software assets and reduced the contradictions between the contents of the software assets. As a result, we reduced the amount of the source code by 53.1%. In this paper, we discuss the details of our technique and the effect of applying it. In addition, we discuss how you can apply our technique in the development of other products.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {198–207},
numpages = {10},
keywords = {test automation, software reuse, software maintenance, software integration, document integration},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2362536.2362553,
author = {Andersen, Nele and Czarnecki, Krzysztof and She, Steven and W\k{a}sowski, Andrzej},
title = {Efficient synthesis of feature models},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362553},
doi = {10.1145/2362536.2362553},
abstract = {Variability modeling, and in particular feature modeling, is a central element of model-driven software product line architectures. Such architectures often emerge from legacy code, but, unfortunately creating feature models from large, legacy systems is a long and arduous task.We address the problem of automatic synthesis of feature models from propositional constraints. We show that this problem is NP-hard. We design efficient techniques for synthesis of models from respectively CNF and DNF formulas, showing a 10- to 1000-fold performance improvement over known techniques for realistic benchmarks.Our algorithms are the first known techniques that are efficient enough to be applied to dependencies extracted from real systems, opening new possibilities of creating reverse engineering and model management tools for variability models. We discuss several such scenarios in the paper.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {106–115},
numpages = {10},
keywords = {variability models, software product lines, feature models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/1629716.1629729,
author = {Liebig, J\"{o}rg and Apel, Sven and Lengauer, Christian and Leich, Thomas},
title = {RobbyDBMS: a case study on hardware/software product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629729},
doi = {10.1145/1629716.1629729},
abstract = {The development of a highly configurable data management system is a challenging task, especially if it is to be implemented on an embedded system that provides limited resources. We present a case study of such a data management system, called RobbyDBMS, and give it a feature-oriented design. In our case study, we evaluate the system's efficiency and variability. We pay particular attention to the interaction between the features of the data management system and the components of the underlying embedded platform. We also propose an integrated development process covering both hardware and software.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {63–68},
numpages = {6},
keywords = {FeatureC++, domain engineering, feature oriented software development, hardware product lines, software product lines},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1145/2517208.2517213,
author = {Kolesnikov, Sergiy and von Rhein, Alexander and Hunsen, Claus and Apel, Sven},
title = {A comparison of product-based, feature-based, and family-based type checking},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517213},
doi = {10.1145/2517208.2517213},
abstract = {Analyzing software product lines is difficult, due to their inherent variability. In the past, several strategies for product-line analysis have been proposed, in particular, product-based, feature-based, and family-based strategies. Despite recent attempts to conceptually and empirically compare different strategies, there is no work that empirically compares all of the three strategies in a controlled setting. We close this gap by extending a compiler for feature-oriented programming with support for product-based, feature-based, and family-based type checking. We present and discuss the results of a comparative performance evaluation that we conducted on a set of 12 feature-oriented, Java-based product lines. Most notably, we found that the family-based strategy is superior for all subject product lines: it is substantially faster, it detects all kinds of errors, and provides the most detailed information about them.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {115–124},
numpages = {10},
keywords = {type checking, product-line analysis, fuji, feature-oriented programming},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@inproceedings{10.1145/3168365.3170425,
author = {Lienhardt, Michael and Damiani, Ferruccio and Donetti, Simone and Paolini, Luca},
title = {Multi Software Product Lines in the Wild},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3170425},
doi = {10.1145/3168365.3170425},
abstract = {Modern software systems are often built from customizable and inter-dependent components. Such customizations usually define which features are offered by the components, and may depend on backend components being configured in a specific way. As such system become very large, with a huge number of possible configurations and complex dependencies between components, maintenance and ensuring the consistency of such systems is a challenge.In this paper, we propose a Multi Software Product Line model to capture the complexity of such systems and pave the way to formal studies on them. We applied and implemented our model on a full Linux Distribution of almost 40,000 interconnected components and 3 million features, and present some initial analysis we did on this model.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {89–96},
numpages = {8},
keywords = {Variability Modeling, Software Product Line, Multi Software Product Line, Linux Distribution, Configurable Software, Composition},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/2648511.2648533,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Generation, composition, and verification of families of human-intensive systems},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648533},
doi = {10.1145/2648511.2648533},
abstract = {Software products are rarely developed without providing different sets of features to better meet varying user needs, whether through tiered products as part of a product line or different subscription levels for software as a service (SaaS). Software product line approaches for generating and maintaining a family of different variants of software products address such needs for variation quite well. Real-world human-intensive systems (HISs) display similar needs for families of variants. A key contribution of this paper is to show how many of these needs can be rigorously and systematically addressed by adapting established techniques from system and software product line engineering (SPLE).In this paper, we present an approach for creating such families by explicitly modeling variation in HISs. We focus on two kinds of variation we have previously described in other work---functional detail variation and service variation. We describe a prototype system that is able to meet the need for these kinds of variation within an existing modeling framework and present a case study of the application of our prototype system to generate a family in an HIS from the domain of elections. Our approach also demonstrates how to perform model-checking of this family to discover whether any variants in the family may violate specified system requirements.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {207–216},
numpages = {10},
keywords = {system variation, software product lines, process families},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2377816.2377823,
author = {Sobernig, Stefan and Neumann, Gustaf and Adelsberger, Stephan},
title = {Supporting multiple feature binding strategies in NX},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377823},
doi = {10.1145/2377816.2377823},
abstract = {Feature-oriented programming (FOP) toolkits restrict implementers of software product lines to certain implementation choices. One is left with the choices between, for example, class-level or object-level extensions and between static or dynamic feature bindings. These choices are typically made at an early development stage causing an unwanted lock-in. We present a feature-oriented development framework based on dynamic, object-oriented constructs for deferring such design decisions by piggybacking on first-class language entities (metaclasses, mixins). A framework proto-type is available for the scripting language NX. NX provides the required object-oriented language infrastructure: a reflective language model, metaclasses, multiple class-based inheritance, decorator mixins, and open entity declarations. We exemplify the approach based on a Graph Product Line.},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {45–53},
numpages = {9},
keywords = {static feature binding, feature-oriented programming, dynamic software product lines, dynamic feature binding},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1145/2364412.2364449,
author = {Helvensteijn, Michiel},
title = {Abstract delta modeling: my research plan},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364449},
doi = {10.1145/2364412.2364449},
abstract = {Software product lines are sets of software programs with well defined commonalities and variabilities that are distinguished by which features they support. There is need of a way to organize the underlying code to clearly link features on the feature modeling level to code artifacts on the implementation level, without code duplication or overspecification, so we can support automated product derivation. Existing approaches are still lacking in one way or another. My answer to this problem is delta modeling. My thesis will approach delta modeling from an abstract algebraic perspective called Abstract Delta Modeling. It will give a thorough formal treatment of the subject and extend it in several directions. A workflow for building a product line from scratch, a way to model dynamic product lines as well as plenty of practical examples and case studies.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {217–224},
numpages = {8},
keywords = {type systems, product lines, modal logic, dynamic product lines, development workflow, delta modeling, PhD thesis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2556624.2556637,
author = {Machado, Ivan do Carmo and Santos, Alcemir Rodrigues and Cavalcanti, Yguarat\~{a} Cerqueira and Trzan, Eduardo Gomes and de Souza, Marcio Magalh\~{a}es and de Almeida, Eduardo Santana},
title = {Low-level variability support for web-based software product lines},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556637},
doi = {10.1145/2556624.2556637},
abstract = {The Web systems domain has faced an increasing number of devices, browsers, and platforms to cope with, driving software systems to be more flexible to accomodate them. Software product line (SPL) engineering can be used as a strategy to implement systems capable of handling such a diversity. To this end, automated tool support is almost indispensable. However, current tool support gives more emphasis to modeling variability in the problem domain, over the support of variability at the solution domain. There is a need for mapping the variability between both abstraction levels, so as to determine what implementation impact a certain variability has. In this paper, we propose the FeatureJS, a FeatureIDE extension aiming at Javascript and HTML support for SPL engineering. The tool combines feature-oriented programming and preprocessors, as a strategy to map variability at source code with the variability modeled at a higher level of abstraction. We carried out a preliminary evaluation with an industrial project, aiming to characterize the capability of the tool to handle SPL engineering in the Web systems domain.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {8},
keywords = {web systems domain, software product line engineering, feature oriented software development, feature composition, FeatureIDE, Eclipse plugin},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.5555/1753235.1753274,
author = {Pech, Daniel and Knodel, Jens and Carbon, Ralf and Schitter, Clemens and Hein, Dirk},
title = {Variability management in small development organizations: experiences and lessons learned from a case study},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Product line practices promise to reduce development and maintenance efforts, to improve the productivity and to reduce the time to market by systematic reuse of commonalities and variabilities. However, in order to reap the fruits of exploiting those, an upfront investment is required. This paper presents a case study, which analyzes the cost-benefit ratio for one product line discipline -- variability management. Wikon GmbH -- a small German development organization evolving a product line of remote monitoring and controlling devices -- switched from manual, file-based conditional compilation to tool-supported decision models. We discuss experiences made and show that the break-even was reached with the 4th product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {285–294},
numpages = {10},
keywords = {decision model, evolution, product line engineering, software architecture, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1145/2580950,
author = {Th\"{u}m, Thomas and Apel, Sven and K\"{a}stner, Christian and Schaefer, Ina and Saake, Gunter},
title = {A Classification and Survey of Analysis Strategies for Software Product Lines},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2580950},
doi = {10.1145/2580950},
abstract = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {6},
numpages = {45},
keywords = {type checking, theorem proving, static analysis, software product line, software analysis, program family, model checking, Product-line analysis}
}

@inproceedings{10.1145/1960275.1960284,
author = {Kim, Chang Hwan Peter and Batory, Don S. and Khurshid, Sarfraz},
title = {Reducing combinatorics in testing product lines},
year = {2011},
isbn = {9781450306058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1960275.1960284},
doi = {10.1145/1960275.1960284},
abstract = {A Software Product Line (SPL) is a family of programs where each program is defined by a unique combination of features. Testing or checking properties of an SPL is hard as it may require the examination of a combinatorial number of programs. In reality, however, features are often irrelevant for a given test - they augment, but do not change, existing behavior, making many feature combinations unnecessary as far as testing is concerned. In this paper we show how to reduce the amount of effort in testing an SPL. We represent an SPL in a form where conventional static program analysis techniques can be applied to find irrelevant features for a test. We use this information to reduce the combinatorial number of SPL programs to examine.},
booktitle = {Proceedings of the Tenth International Conference on Aspect-Oriented Software Development},
pages = {57–68},
numpages = {12},
keywords = {testing, static analysis, software product lines, feature oriented programming},
location = {Porto de Galinhas, Brazil},
series = {AOSD '11}
}

@inproceedings{10.1145/2509136.2509522,
author = {Bhattacharya, Suparna and Gopinath, Kanchi and Nanda, Mangala Gowri},
title = {Combining concern input with program analysis for bloat detection},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509522},
doi = {10.1145/2509136.2509522},
abstract = {Framework based software tends to get bloated by accumulating optional features (or concerns) just-in-case they are needed. The good news is that such feature bloat need not always cause runtime execution bloat. The bad news is that often enough, only a few statements from an optional concern may cause execution bloat that may result in as much as 50% runtime overhead.We present a novel technique to analyze the connection between optional concerns and the potential sources of execution bloat induced by them. Our analysis automatically answers questions such as (1) whether a given set of optional concerns could lead to execution bloat and (2) which particular statements are the likely sources of bloat when those concerns are not required. The technique combines coarse grain concern input from an external source with a fine-grained static analysis. Our experimental evaluation highlights the effectiveness of such concern augmented program analysis in execution bloat assessment of ten programs.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {745–764},
numpages = {20},
keywords = {software bloat, program concerns, feature oriented programming},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@inproceedings{10.1145/2047862.2047866,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Pukall, Mario and Apel, Sven},
title = {Tailoring dynamic software product lines},
year = {2011},
isbn = {9781450306898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2047862.2047866},
doi = {10.1145/2047862.2047866},
abstract = {Software product lines (SPLs) and adaptive systems aim at variability to cope with changing requirements. Variability can be described in terms of features, which are central for development and configuration of SPLs. In traditional SPLs, features are bound statically before runtime. By contrast, adaptive systems support feature binding at runtime and are sometimes called dynamic SPLs (DSPLs). DSPLs are usually built from coarse-grained components, which reduces the number of possible application scenarios. To overcome this limitation, we closely integrate static binding of traditional SPLs and runtime adaptation of DSPLs. We achieve this integration by statically generating a tailor-made DSPL from a highly customizable SPL. The generated DSPL provides only the runtime variability required by a particular application scenario and the execution environment. The DSPL supports self-configuration based on coarse-grained modules. We provide a feature-based adaptation mechanism that reduces the effort of computing an optimal configuration at runtime. In a case study, we demonstrate the practicability of our approach and show that a seamless integration of static binding and runtime adaptation reduces the complexity of the adaptation process.},
booktitle = {Proceedings of the 10th ACM International Conference on Generative Programming and Component Engineering},
pages = {3–12},
numpages = {10},
keywords = {software product lines, feature-oriented programming, dynamic binding},
location = {Portland, Oregon, USA},
series = {GPCE '11}
}

@inproceedings{10.1145/3350768.3350774,
author = {Souza, Iuri Santos and Machado, Ivan and Seaman, Carolyn and Gomes, Gecynalda and Chavez, Christina and de Almeida, Eduardo Santana and Masiero, Paulo},
title = {Investigating Variability-aware Smells in SPLs: An Exploratory Study},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350774},
doi = {10.1145/3350768.3350774},
abstract = {Variability-aware smell is a concept referring to artifact shortcomings in the context of highly-configurable systems that can degrade aspects such as program comprehension, maintainability, and evolvability. To the best of our knowledge, there is very little evidence that variability-aware smells exist in Software Product Lines (SPLs). This work presents an exploratory study that investigated (I) evidence that variability-aware smells exist in SPLs and (II) new types of variability-aware smell not yet documented in the literature based on a quantitative study with open source SPL projects. We collected quantitative data to generate reliable research evidence, by performing feature model and source code inspections on eleven open-source SPL projects. Our findings revealed that (1) instances of variability-aware smells exist in open-source SPL projects and (2) feature information presented significant associations with variability-aware smells. Furthermore, (3) the study presented six new types of variability-aware smells.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {367–376},
numpages = {10},
keywords = {Variability-Aware Smells, Software Product Lines, Exploratory Study, Empirical Study},
location = {Salvador, Brazil},
series = {SBES '19}
}

@article{10.1145/2211616.2211617,
author = {K\"{a}stner, Christian and Apel, Sven and Th\"{u}m, Thomas and Saake, Gunter},
title = {Type checking annotation-based product lines},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2211616.2211617},
doi = {10.1145/2211616.2211617},
abstract = {Software product line engineering is an efficient means of generating a family of program variants for a domain from a single code base. However, because of the potentially high number of possible program variants, it is difficult to test them all and ensure properties like type safety for the entire product line. We present a product-line-aware type system that can type check an entire software product line without generating each variant in isolation. Specifically, we extend the Featherweight Java calculus with feature annotations for product-line development and prove formally that all program variants generated from a well typed product line are well typed. Furthermore, we present a solution to the problem of typing mutually exclusive features. We discuss how results from our formalization helped implement our own product-line tool CIDE for full Java and report of our experience with detecting type errors in four existing software product line implementations.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {14},
numpages = {39},
keywords = {type system, software product lines, conditional compilation, Featherweight Java, CIDE, CFJ, #ifdef}
}

@inproceedings{10.1145/3634713.3634714,
author = {Kodetzki, Maximilian and Bordis, Tabea and Runge, Tobias and Schaefer, Ina},
title = {Partial Proofs to Optimize Deductive Verification of Feature-Oriented Software Product Lines},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634713.3634714},
doi = {10.1145/3634713.3634714},
abstract = {Software product lines (SPLs) are a technique to efficiently develop families of software products. Code is implemented in functional features which are composed to individual software variants. SPLs are oftentimes used in safety-critical systems, which is why functional correctness is more important than ever. As an advanced approach, deductive verification offers the possibility to verify the behaviour of software against a formal specification. When deductive verification is applied for SPLs, it meets the challenges of an SPLs variability. Since most verification approaches do not scale for variant-rich product lines, we take up existing approaches of reuse of proof parts to develop our concept of partial proofs. We split proofs into a feature-specific and a product-specific part. The feature-specific part is only proven once for all products enabling advanced proof reuse. We implement our concept of partial proofs in the tool VarCorC and evaluate it on three case studies. We found that both the number of proof steps and the verification time can be reduced by using partial proofs. Further, we determine a trend of increasing improvements of verification costs for large-scale SPLs.},
booktitle = {Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
pages = {17–26},
numpages = {10},
keywords = {deductive verification, formal methods, software product lines},
location = {Bern, Switzerland},
series = {VaMoS '24}
}

@inproceedings{10.1145/1621607.1621634,
author = {Kuhlemann, Martin and Batory, Don and K\"{a}stner, Christian},
title = {Safe composition of non-monotonic features},
year = {2009},
isbn = {9781605584942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1621607.1621634},
doi = {10.1145/1621607.1621634},
abstract = {Programs can be composed from features. We want to verify automatically that all legal combinations of features can be composed safely without errors. Prior work on this problem assumed that features add code monotonically. We generalize prior work to enable features to add and remove code, describe our analyses and implementation, and review case studies. We observe that more expressive features increase the complexity of developed programs rapidly -- up to the point where tools and automated concepts as presented in this paper are indispensable for verification.},
booktitle = {Proceedings of the Eighth International Conference on Generative Programming and Component Engineering},
pages = {177–186},
numpages = {10},
keywords = {safe composition, refactoring, feature-oriented programming, AHEAD},
location = {Denver, Colorado, USA},
series = {GPCE '09}
}

@inproceedings{10.1145/1868294.1868300,
author = {Sincero, Julio and Tartler, Reinhard and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Efficient extraction and analysis of preprocessor-based variability},
year = {2010},
isbn = {9781450301541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868294.1868300},
doi = {10.1145/1868294.1868300},
abstract = {The C Preprocessor (CPP) is the tool of choice for the implementation of variability in many large-scale configurable software projects. Linux, probably the most-configurable piece of software ever, employs more than 10,000 preprocessor variables for this purpose. However, this de-facto variability tends to be "hidden in the code"; which on the long term leads to variability defects, such as dead code or inconsistencies with respect to the intended (modeled) variability of the software. This calls for tool support for the efficient extraction of (and reasoning over) CPP-based variability.We suggest a novel approach to extract CPP-based variability. Our tool transforms CPP-based variability in O(n) complexity into a propositional formula that "mimics" all valid effects of conditional compilation and can be analyzed with standard SAT or BDD packages.Our evaluation results demonstrate the scalability and practicability of the approach. A dead-block-analysis on the complete Linux source tree takes less than 30 minutes; we thereby have revealed 60 dead blocks, 2 of which meanwhile have been confirmed as new (and long-lasting) bugs; the rest is still under investigation.},
booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
pages = {33–42},
numpages = {10},
keywords = {variability, linux, conditional compilation},
location = {Eindhoven, The Netherlands},
series = {GPCE '10}
}

@inproceedings{10.1145/3510466.3511272,
author = {Kuiter, Elias and Kn\"{u}ppel, Alexander and Bordis, Tabea and Runge, Tobias and Schaefer, Ina},
title = {Verification Strategies for Feature-Oriented Software Product Lines},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3511272},
doi = {10.1145/3510466.3511272},
abstract = {Highly-customizable software systems in form of software product lines are becoming increasingly relevant for safety-critical systems, in which the correctness of software is a major concern. To ensure the correct behavior of a software product line, each product can be verified in isolation—however, this strategy quickly becomes infeasible for a large number of products. In this paper, we propose proof plans, a novel strategy for verifying feature-oriented software product lines based on partial proofs. Our technique splits the verification task into small proofs that can be reused across method variants, which gives rise to a wider spectrum of verification strategies for software product lines. We describe applications of our technique and evaluate one of them on a case study by comparing it with established verification strategies.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {12},
numpages = {9},
keywords = {Software Product Lines, Proof Reuse, Deductive Verification},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/2647508.2647512,
author = {Koscielny, Jonathan and Holthusen, S\"{o}nke and Schaefer, Ina and Schulze, Sandro and Bettini, Lorenzo and Damiani, Ferruccio},
title = {DeltaJ 1.5: delta-oriented programming for Java 1.5},
year = {2014},
isbn = {9781450329262},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647508.2647512},
doi = {10.1145/2647508.2647512},
abstract = {Delta-oriented programming (DOP) is a modular, yet flexible approach to implement software product lines. In DOP, a product line is implemented by a set of deltas, which are containers of modifications to a program. A delta-oriented product line is specified by its code base, i.e., the set of delta modules, and a product line declaration specifying the set of possible product variants. In this paper, we present DOP for Java 1.5 extending previous proof-of-concept realizations of DOP for simple core Java-like languages. The novel prototypical implementation DeltaJ 1.5 provides full integrated access to the object-oriented features of Java. The extensions include delta operations to fully integrate the Java package system, to declare and modify interfaces, to explicitly change the inheritance hierarchy, to access nested types and enum types, to alter field declarations, and to unambiguously remove overloaded methods. Furthermore, we improve the specification of the product line declaration by providing a separate language. We have evaluated DeltaJ 1.5 using a case study.},
booktitle = {Proceedings of the 2014 International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools},
pages = {63–74},
numpages = {12},
keywords = {software product line, program generation, delta-oriented programming},
location = {Cracow, Poland},
series = {PPPJ '14}
}

@inproceedings{10.5555/3172795.3172831,
author = {Masri, Samer Al and Bhuiyan, Nazim Uddin and Nadi, Sarah and Gaudet, Matthew},
title = {Software variability through C++ static polymorphism: a case study of challenges and open problems in eclipse OMR},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software Product Line Engineering (SPLE) creates configurable platforms that can be used to efficiently produce similar, and yet different, product variants. SPLs are typically modular such that it is easy to connect different blocks of code together, creating different variations of the product. There are many variability implementation mechanisms to achieve an SPL. This paper shows how static polymorphism can be used to implement variability, through a case study of IBM's open-source Eclipse OMR project. We discuss the current open problems and challenges this variability implementation mechanism raises and highlight technology gaps for reasoning about variability in OMR. We then suggest steps to close these gaps.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {285–291},
numpages = {7},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.1145/1449913.1449917,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Saake, Gunter and Apel, Sven},
title = {Code generation to support static and dynamic composition of software product lines},
year = {2008},
isbn = {9781605582672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1449913.1449917},
doi = {10.1145/1449913.1449917},
abstract = {Software product lines (SPLs) are used to create tailor-made software products by managing and composing reusable assets. Generating a software product from the assets of an SPL is possible statically before runtime or dynamically at load-time or runtime. Both approaches have benefits and drawbacks with respect to composition flexibility, performance, and resource consumption. Which type of composition is preferable should be decided by taking the application scenario into account. Current tools and languages, however, force a programmer to decide between static and dynamic composition during development. In this paper, we present an approach that employs code generation to support static and dynamic composition of features of a single code base. We offer an implementation on top of FeatureC++, an extension of the C++ programming language that supports software composition based on features. To simplify dynamic composition and to avoid creation of invalid products we furthermore provide means to (1) validate the correctness of a composition at runtime, (2) automatically instantiate SPLs in case of stand-alone applications, and (3) automatically apply interaction code of crosscutting concerns.},
booktitle = {Proceedings of the 7th International Conference on Generative Programming and Component Engineering},
pages = {3–12},
numpages = {10},
keywords = {static feature binding, software product lines, feature-oriented programming, dynamic feature binding},
location = {Nashville, TN, USA},
series = {GPCE '08}
}

@inproceedings{10.1145/1173706.1173736,
author = {Trujillo, Salvador and Batory, Don and Diaz, Oscar},
title = {Feature refactoring a multi-representation program into a product line},
year = {2006},
isbn = {1595932372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1173706.1173736},
doi = {10.1145/1173706.1173736},
abstract = {Feature refactoring is the process of decomposing a program into aset of modules, called features, that encapsulate increments in program functionality. Different compositions of features yield different programs. As programs are defined using multiple representations, such as code, makefiles, and documentation, feature refactoring requires all representations to be factored. Thus, composing features produces consistent representations of code, make files, documentation, etc. for a target program. We present acase study of feature refactoring a substantial tool suite that usesmultiple representations. We describe the key technical problems encountered, and sketch the tool support needed for simplifying such refactorings in the future.},
booktitle = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering},
pages = {191–200},
numpages = {10},
keywords = {software product lines, refinements, refactoring, program synthesis, multiple representations, feature-oriented programming, AHEAD},
location = {Portland, Oregon, USA},
series = {GPCE '06}
}

@inproceedings{10.1145/1960275.1960283,
author = {Schaefer, Ina and Bettini, Lorenzo and Damiani, Ferruccio},
title = {Compositional type-checking for delta-oriented programming},
year = {2011},
isbn = {9781450306058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1960275.1960283},
doi = {10.1145/1960275.1960283},
abstract = {Delta-oriented programming is a compositional approach to flexibly implementing software product lines. A product line is represented by a code base and a product line declaration. The code base consists of a set of delta modules specifying modifications to object-oriented programs. The product line declaration provides the connection of the delta modules with the product features. This separation increases the reusability of delta modules. In this paper, we provide a foundation for compositional type checking of delta-oriented product lines of Java programs by presenting a minimal core calculus for delta-oriented programming. The calculus is equipped with a constraint-based type system that allows analyzing each delta module in isolation, such that that also the results of the analysis can be reused. By combining the analysis results for the delta modules with the product line declaration it is possible to establish that all the products of the product line are well-typed according to the Java type system.},
booktitle = {Proceedings of the Tenth International Conference on Aspect-Oriented Software Development},
pages = {43–56},
numpages = {14},
keywords = {type system, software product line, java},
location = {Porto de Galinhas, Brazil},
series = {AOSD '11}
}

@inproceedings{10.1145/3141848.3141853,
author = {Schuster, Sven and Seidl, Christoph and Schaefer, Ina},
title = {Towards a development process for maturing Delta-oriented software product lines},
year = {2017},
isbn = {9781450355186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141848.3141853},
doi = {10.1145/3141848.3141853},
abstract = {A Software Product Line (SPL) exploits reuse-in-the-large to enable customization by explicitly modeling commonalities and variabilities of closely related software systems. Delta-Oriented Programming (DOP) is a flexible implementation approach to SPL engineering, which transforms an existing core product to another desired product by applying transformation operations. By capturing product alterations related to configurable functionality within delta modules, DOP closely resembles a natural process of software development, which proves beneficial in early stages of development. However, increasing complexity for a growing SPL in later development stages caused by the invasiveness of DOP drastically impairs maintenance and extensibility. Hence, a process utilizing the invasiveness of DOP in early development stages and restricting it in later stages would allow developers to mature growing delta-oriented SPLs. Moreover, ever-increasing complexity requires means to migrate into less invasive development approaches that are more suited for large-scale configurable applications. To this end, we propose a development process for delta-oriented SPLs including explicit variability points, metrics and refactorings as well as a semi-automatic reengineering of a delta-oriented SPL into a development approach based on blackbox-components. In this paper, we sketch this development process with its constituents and point out required research essential for successfully maturing a delta-oriented SPL.},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Workshop on Feature-Oriented Software Development},
pages = {41–50},
numpages = {10},
keywords = {Software Product Lines, Delta-Oriented Programming},
location = {Vancouver, BC, Canada},
series = {FOSD 2017}
}

@proceedings{10.1145/3571788,
title = {VaMoS '23: Proceedings of the 17th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2023},
isbn = {9798400700019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Odense, Denmark}
}

@inproceedings{10.1109/ICSE.2007.36,
author = {Trujillo, Salvador and Batory, Don and Diaz, Oscar},
title = {Feature Oriented Model Driven Development: A Case Study for Portlets},
year = {2007},
isbn = {0769528287},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSE.2007.36},
doi = {10.1109/ICSE.2007.36},
abstract = {Model Driven Development (MDD) is an emerging paradigm for software construction that uses models to specify programs, and model transformations to synthesize executables. Feature Oriented Programming (FOP) is a paradigm for software product lines where programs are synthesized by composing features. Feature Oriented Model Driven Development (FOMDD) is a blend of FOP and MDD that shows how products in a software product line can be synthesized in an MDD way by composing features to create models, and then transforming these models into executables. We present a case study of FOMDD on a product line of portlets, which are components of web portals. We reveal mathematical properties of portlet synthesis that helped us to validate the correctness of our abstractions, tools, and specifications, as well as optimize portlet synthesis.},
booktitle = {Proceedings of the 29th International Conference on Software Engineering},
pages = {44–53},
numpages = {10},
series = {ICSE '07}
}

@inproceedings{10.1145/3377024.3377031,
author = {El-Sharkawy, Sascha and Krafczyk, Adam and Schmid, Klaus},
title = {Fast static analyses of software product lines: an example with more than 42,000 metrics},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377031},
doi = {10.1145/3377024.3377031},
abstract = {Context: Software metrics, as one form of static analyses, is a commonly used approach in software engineering in order to understand the state of a software system, in particular to identify potential areas prone to defects. Family-based techniques extract variability information from code artifacts in Software Product Lines (SPLs) to perform static analysis for all available variants. Many different types of metrics with numerous variants have been defined in literature. When counting all metrics including such variants, easily thousands of metrics can be defined. Computing all of them for large product lines can be an extremely expensive process in terms of performance and resource consumption.Objective: We address these performance and resource challenges while supporting customizable metric suites, which allow running both, single system and variability-aware code metrics.Method: In this paper, we introduce a partial parsing approach used for the efficient measurement of more than 42,000 code metric variations. The approach covers variability information and restricts parsing to the relevant parts of the Abstract Syntax Tree (AST).Conclusions: This partial parsing approach is designed to cover all relevant information to compute a broad variety of variability-aware code metrics on code artifacts containing annotation-based variability, e.g., realized with C-preprocessor statements. It allows for the flexible combination of single system and variability-aware metrics, which is not supported by existing tools. This is achieved by a novel representation of partially parsed product line code artifacts, which is tailored to the computation of the metrics. Our approach consumes considerably less resources, especially when computing many metric variants in parallel.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {9},
keywords = {variability models, software product lines, metrics, implementation, feature models, abstract syntax trees, SPL, AST},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@article{10.1145/3034827,
author = {Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
title = {CASE Tool Support for Variability Management in Software Product Lines},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3034827},
doi = {10.1145/3034827},
abstract = {Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools’ characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {14},
numpages = {45},
keywords = {software variability, computer-aided software engineering, Software engineering}
}

@inproceedings{10.1145/1385486.1385488,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Schirmeier, Horst and Sincero, Julio and Apel, Sven and Leich, Thomas and Spinczyk, Olaf and Saake, Gunter},
title = {FAME-DBMS: tailor-made data management solutions for embedded systems},
year = {2008},
isbn = {9781595939647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385486.1385488},
doi = {10.1145/1385486.1385488},
abstract = {Data management functionality is not only needed in large-scale server systems, but also in embedded systems. Resource restrictions and heterogeneity of hardware, however, complicate the development of data management solutions for those systems. In current practice, this typically leads to the redevelopment of data management because existing solutions cannot be reused and adapted appropriately. In this paper, we present our ongoing work on FAME-DBMS, a research project that explores techniques to implement highly customizable data management solutions, and illustrate how such systems can be created with a software product line approach. With this approach a concrete instance of a DBMS is derived by composing features of the DBMS product line that are needed for a specific application scenario. This product derivation process is getting complex if a large number of features is available. Furthermore, in embedded systems also non-functional properties, e.g., memory consumption, have to be considered when creating a DBMS instance. To simplify the derivation process we present approaches for its automation.},
booktitle = {Proceedings of the 2008 EDBT Workshop on Software Engineering for Tailor-Made Data Management},
pages = {1–6},
numpages = {6},
location = {Nantes, France},
series = {SETMDM '08}
}

@article{10.1145/3596217,
author = {Cazzola, Walter and Favalli, Luca},
title = {Scrambled Features for Breakfast: Concepts of Agile Language Development},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3596217},
doi = {10.1145/3596217},
abstract = {Describing a framework to support simpler development of languages best suited to express the problems and solutions of each particular domain.},
journal = {Commun. ACM},
month = oct,
pages = {50–60},
numpages = {11}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00012,
author = {Nuryyev, Batyr and Nadi, Sarah and Bhuiyan, Nazim Uddin and Banderali, Leonardo},
title = {Challenges of implementing software variability in eclipse OMR: an interview study},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00012},
doi = {10.1109/ICSE-SEIP52600.2021.00012},
abstract = {Software variability is the ability of a software system to be customized or configured for a particular context. In this paper, we discuss our experience investigating software variability implementation challenges in practice. Eclipse OMR, developed by IBM, is a set of highly configurable C++ components for building language runtimes; it supports multiple programming languages and target architectures. We conduct an interview study with 6 Eclipse OMR developers and identify 8 challenges incurred by the existing variability implementation, and 3 constraints that need to be taken into account for any reengineering effort. We discuss these challenges and investigate the literature and existing open-source systems for potential solutions. We contribute a solution for one of the challenges, namely adding variability to enumerations and arrays. We also share our experiences and lessons learned working with a large-scale highly configurable industry project. For example, we found that the "latest and greatest" research solutions may not always be favoured by developers due to small practical considerations such as build dependencies, or even C++ version constraints.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {31–40},
numpages = {10},
keywords = {variability implementation, software variability, language runtimes, eclipse OMR},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1145/3377024.3377039,
author = {Ludwig, Kai and Kr\"{u}ger, Jacob and Leich, Thomas},
title = {FeatureCoPP: unfolding preprocessor variability},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377039},
doi = {10.1145/3377024.3377039},
abstract = {Annotation-based and composition-based variability mechanisms have complementary strengths regarding software maintenance and evolution. Consequently, several proposals have been made to combine, integrate, and substitute both mechanisms. An open challenge is to provide a unified, automatic, and practical technique to adopt such proposals. In this paper, we present a technique to convert variable feature code that is enclosed in the C preprocessor's conditional compilation into compositional feature modules and vice versa. We facilitate the usability of our technique by keeping the annotation-based representation of the C preprocessor. Besides contributing a practicable implementation, we describe the core principles of our technique and demonstrate its functionality based on previous empirical studies and by analyzing the Linux kernel. While our technique is fast in transforming projects, we also illustrate the challenges of maintaining fine-grained feature modules.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {24},
numpages = {9},
keywords = {variability analysis, software product lines, software metrics, preprocessor, empirical study},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@article{10.1145/3428225,
author = {Shahin, Ramy and Chechik, Marsha},
title = {Automatic and efficient variability-aware lifting of functional programs},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428225},
doi = {10.1145/3428225},
abstract = {A software analysis is a computer program that takes some representation of a software product as input and produces some useful information about that product as output. A software product line encompasses many software product variants, and thus existing analyses can be applied to each of the product variations individually, but not to the entire product line as a whole. Enumerating all product variants and analyzing them one by one is usually intractable due to the combinatorial explosion of the number of product variants with respect to product line features. Several software analyses (e.g., type checkers, model checkers, data flow analyses) have been redesigned/re-implemented to support variability. This usually requires a lot of time and effort, and the variability-aware version of the analysis might have new errors/bugs that do not exist in the original one. Given an analysis program written in a functional language based on PCF, in this paper we present two approaches to transforming (lifting) it into a semantically equivalent variability-aware analysis. A light-weight approach (referred to as shallow lifting) wraps the analysis program into a variability-aware version, exploring all combinations of its input arguments. Deep lifting, on the other hand, is a program rewriting mechanism where the syntactic constructs of the input program are rewritten into their variability-aware counterparts. Compositionally this results in an efficient program semantically equivalent to the input program, modulo variability. We present the correctness criteria for functional program lifting, together with correctness proof sketches of shallow lifting. We evaluate our approach on a set of program analyses applied to the BusyBox C-language product line.},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {157},
numpages = {27},
keywords = {Variability-aware Programming, Software Product Lines, Program Rewriting, PCF, Lifting}
}

@inproceedings{10.1145/3571788.3571800,
author = {Sharma, Shubham and Fadhlillah, Hafiyyan Sayyid and Guti\'{e}rrez Fern\'{a}ndez, Antonio Manuel and Rabiser, Rick and Zoitl, Alois},
title = {Modularization Technique to Support Software Variability in Cyber-Physical Production Systems},
year = {2023},
isbn = {9798400700019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571788.3571800},
doi = {10.1145/3571788.3571800},
abstract = {Industries still have problems managing and organizing control software variants for different machine processes in Cyber-Physical Production Systems (CPPSs). They still rely mostly on clone-and-own approaches to create new control software variants when introducing new process variability in reaction to customers’ requirements. This approach not only results in code duplication but over time particularly makes it more difficult to maintain and evolve the software. Due to a lack of modularization, this approach also often results in unnecessary code in delivered software, locked by parameters, which can have a further negative effect on maintenance. In this paper, we discuss modularization approaches to organize control software in CPPSs. Specifically, for IEC 61499-based control software, we propose the combination of explicit variants described in 150% modules, standardized interfaces, and separation of concerns. We discuss how our approach could help industry to decrease the effort for new projects and at the same time get a better overview of the product and process variability of their CPPSs.},
booktitle = {Proceedings of the 17th International Working Conference on Variability Modelling of Software-Intensive Systems},
pages = {71–76},
numpages = {6},
keywords = {Software Product lines, Modularization, Model-Based System Engineering, Distributed Design, Cyber-Physical Production System, 150 Percent Model},
location = {Odense, Denmark},
series = {VaMoS '23}
}

@inproceedings{10.5555/2337223.2337243,
author = {Siegmund, Norbert and Kolesnikov, Sergiy S. and K\"{a}stner, Christian and Apel, Sven and Batory, Don and Rosenm\"{u}ller, Marko and Saake, Gunter},
title = {Predicting performance via automated feature-interaction detection},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However, when features interact, accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end, we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g., databases, encoding libraries, and web servers) using different configuration techniques (e.g., configuration files and preprocessor flags). Results show an average prediction accuracy of 95%.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {167–177},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1145/1837154.1837157,
author = {Siegmund, Norbert and Feigenspan, Janet and Soffner, Michael and Fruth, Jana and K\"{o}ppen, Veit},
title = {Challenges of secure and reliable data management in heterogeneous environments},
year = {2010},
isbn = {9781605589923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837154.1837157},
doi = {10.1145/1837154.1837157},
abstract = {Ubiquitous computing is getting more important since requirements for complex systems grow fast. In these systems, embedded devices have to fulfill different tasks. They have to monitor the environment, store data, communicate with other devices, and react to user input. In addition to this complexity, quality issues such as security and reliability have to be considered, as well, due to their increasing use in life critical application scenarios. Finally, different devices with different application goals are used, which results in interoperability problems. In this paper, we highlight challenges for interoperability, data management, and security, which arise with complex systems. Furthermore, we present approaches to overcome different problems and how an integrated solution can be realized using software product line techniques.},
booktitle = {Proceedings of the First International Workshop on Digital Engineering},
pages = {17–24},
numpages = {8},
keywords = {software product lines, security, digital engineering, data management},
location = {Magdeburg, Germany},
series = {IWDE '10}
}

@inproceedings{10.1145/1062455.1062552,
author = {Schmid, Klaus and John, Isabel and Kolb, Ronny and Meier, Gerald},
title = {Introducing the puLSE approach to an embedded system population at testo AG},
year = {2005},
isbn = {1581139632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1062455.1062552},
doi = {10.1145/1062455.1062552},
abstract = {Over the last few years, product line engineering has become a major theme in software engineering research, and is increasingly becoming a central topic of software engineering practice in the embedded domain.Migrating towards a product line approach is not an easy feat. It is even less so, if it is done under tight technology constraints in an embedded environment. It becomes even more difficult if the transition directly aims at integrating two product families into a single product population. In this paper, we discuss our experiences with a project where we successfully dealt with these difficulties and achieved a successful product line transition. In our paper we strongly emphasize the role of technology transfer, as many facets of product line know-how had to be transferred to guarantee a complete transition to product line engineering. From the experiences of this project many lessons learned can be deduced, which can be transferred to different environments.},
booktitle = {Proceedings of the 27th International Conference on Software Engineering},
pages = {544–552},
numpages = {9},
keywords = {technology transfer, systematic software reuse, software product line, product line introduction},
location = {St. Louis, MO, USA},
series = {ICSE '05}
}

@inproceedings{10.1145/2162049.2162052,
author = {Brabrand, Claus and Ribeiro, M\'{a}rcio and Tol\^{e}do, T\'{a}rsis and Borba, Paulo},
title = {Intraprocedural dataflow analysis for software product lines},
year = {2012},
isbn = {9781450310925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2162049.2162052},
doi = {10.1145/2162049.2162052},
abstract = {Software product lines (SPLs) are commonly developed using annotative approaches such as conditional compilation that come with an inherent risk of constructing erroneous products. For this reason, it is essential to be able to analyze SPLs. However, as dataflow analysis techniques are not able to deal with SPLs, developers must generate and analyze all valid methods individually, which is expensive for non-trivial SPLs. In this paper, we demonstrate how to take any standard intraprocedural dataflow analysis and automatically turn it into a feature-sensitive dataflow analysis in three different ways. All are capable of analyzing all valid methods of an SPL without having to generate all of them explicitly. We have implemented all analyses as extensions of SOOT's intraprocedural dataflow analysis framework and experimentally evaluated their performance and memory characteristics on four qualitatively different SPLs. The results indicate that the feature-sensitive analyses are on average 5.6 times faster than the brute force approach on our SPLs, and that they have different time and space tradeoffs.},
booktitle = {Proceedings of the 11th Annual International Conference on Aspect-Oriented Software Development},
pages = {13–24},
numpages = {12},
keywords = {software product lines, dataflow analysis},
location = {Potsdam, Germany},
series = {AOSD '12}
}

@inproceedings{10.1145/2568225.2568267,
author = {Salay, Rick and Famelis, Michalis and Rubin, Julia and Di Sandro, Alessio and Chechik, Marsha},
title = {Lifting model transformations to product lines},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568267},
doi = {10.1145/2568225.2568267},
abstract = {Software product lines and model transformations are two techniques used in industry for managing the development of highly complex software. Product line approaches simplify the handling of software variants while model transformations automate software manipulations such as refactoring, optimization, code generation, etc. While these techniques are well understood independently, combining them to get the benefit of both poses a challenge because most model transformations apply to individual models while model-level product lines represent sets of models. In this paper, we address this challenge by providing an approach for automatically ``lifting'' model transformations so that they can be applied to product lines. We illustrate our approach using a case study and evaluate it through a set of experiments.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {117–128},
numpages = {12},
keywords = {Software Product Lines, Model Transformations, Model Driven Engineering},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/1868688.1868694,
author = {Kuhlemann, Martin and Sturm, Martin},
title = {Patching product line programs},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868694},
doi = {10.1145/1868688.1868694},
abstract = {Software product line engineering is one approach to implement sets of related programs efficiently. Software product lines (SPLs) can be implemented using code transformations which are combined in order to generate a program. A code transformation may add functionality to a program or may alter its structure. Though implemented with less effort, a single malfunctioning SPL program is harder to patch because patches must effect the SPL transformations which the program was generated from. In this paper, we present a new approach to patch programs of a transformation-based SPL. We demonstrate the feasibility of this approach using a prototype.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {33–40},
numpages = {8},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/2491956.2491976,
author = {Bodden, Eric and Tol\^{e}do, T\'{a}rsis and Ribeiro, M\'{a}rcio and Brabrand, Claus and Borba, Paulo and Mezini, Mira},
title = {SPLLIFT: statically analyzing software product lines in minutes instead of years},
year = {2013},
isbn = {9781450320146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491956.2491976},
doi = {10.1145/2491956.2491976},
abstract = {A software product line (SPL) encodes a potentially large variety of software products as variants of some common code base. Up until now, re-using traditional static analyses for SPLs was virtually intractable, as it required programmers to generate and analyze all products individually. In this work, however, we show how an important class of existing inter-procedural static analyses can be transparently lifted to SPLs. Without requiring programmers to change a single line of code, our approach SPLLIFT automatically converts any analysis formulated for traditional programs within the popular IFDS framework for inter-procedural, finite, distributive, subset problems to an SPL-aware analysis formulated in the IDE framework, a well-known extension to IFDS. Using a full implementation based on Heros, Soot, CIDE and JavaBDD, we show that with SPLLIFT one can reuse IFDS-based analyses without changing a single line of code. Through experiments using three static analyses applied to four Java-based product lines, we were able to show that our approach produces correct results and outperforms the traditional approach by several orders of magnitude.},
booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {355–364},
numpages = {10},
keywords = {software product lines, inter-procedural static analysis, flow sensitive, context sensitive},
location = {Seattle, Washington, USA},
series = {PLDI '13}
}

@inproceedings{10.1145/3510455.3512792,
author = {Randrianaina, Georges Aaron and Khelladi, Djamel Eddine and Zendra, Olivier and Acher, Mathieu},
title = {Towards incremental build of software configurations},
year = {2022},
isbn = {9781450392242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510455.3512792},
doi = {10.1145/3510455.3512792},
abstract = {Building software is a crucial task to compile, test, and deploy software systems while continuously ensuring quality. As software is more and more configurable, building multiple configurations is a pressing need, yet, costly and challenging to instrument. The common practice is to independently build (a.k.a., clean build) a software for a subset of configurations. While incremental build has been considered for software evolution and relatively small modifications of the source code, it has surprisingly not been considered for software configurations. In this vision paper, we formulate the hypothesis that incremental build can reduce the cost of exploring the configuration space of software systems. We detail how we apply incremental build for two real-world application scenarios and conduct a preliminary evaluation on two case studies, namely x264 and Linux Kernel. For x264, we found that one can incrementally build configurations in an order such that overall build time is reduced. Nevertheless, we could not find any optimal order with the Linux Kernel, due to a high distance between random configurations. Therefore, we show it is possible to control the process of generating configurations: we could reuse commonality and gain up to 66% of build time compared to only clean builds.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {101–105},
numpages = {5},
keywords = {incremental build, highly configurable system, build system},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-NIER '22}
}

@inproceedings{10.1145/2517208.2517214,
author = {Kramer, Dean and Oussena, Samia and Komisarczuk, Peter and Clark, Tony},
title = {Using document-oriented GUIs in dynamic software product lines},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517214},
doi = {10.1145/2517208.2517214},
abstract = {Dynamic Software Product Line (DSPL) Engineering has gained interest through its promise of being able to unify software adaptation whereby software adaptation can be realised at compile time and runtime. While previous work has enabled program logic adaptation by the use of language extensions and platform support, little attention has been placed on Graphical User Interface (GUI) variability. Different design patterns including the Model View Controller are commonly used in GUI implementation, with GUI documents being used for declaring the GUI. To handle dynamic GUI variability currently, the developer needs to implement GUI refinements using multiple techniques. This paper proposes a solution for dealing with GUI document variability, statically and dynamically, in a unified way. In our approach, we currently use a compile time method for producing GUI variants, and code transformations to handle these variants within the application at runtime. To avoid GUI duplicates, only GUI variants that are unique, and related to a valid product configuration, are produced. To validate our approach, we implemented tool support to enable this for Android based applications.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {85–94},
numpages = {10},
keywords = {graphical user interfaces, dynamic software product lines},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@proceedings{10.1145/3001867,
title = {FOSD 2016: Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/3634713,
title = {VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bern, Switzerland}
}

@inproceedings{10.1145/2866614.2866628,
author = {Th\"{u}m, Thomas and Winkelmann, Tim and Schr\"{o}ter, Reimar and Hentschel, Martin and Kr\"{u}ger, Stefan},
title = {Variability Hiding in Contracts for Dependent Software Product Lines},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866628},
doi = {10.1145/2866614.2866628},
abstract = {Software product lines are used to efficiently develop and verify similar software products. While they focus on reuse of artifacts between products, a product line may also be reused itself in other product lines. A challenge with such dependent product lines is evolution; every change in a product line may influence all dependent product lines. With variability hiding, we aim to hide certain features and their artifacts in dependent product lines. In prior work, we focused on feature models and implementation artifacts. We build on this by discussing how variability hiding can be extended to specifications in terms of method contracts. We illustrate variability hiding in contracts by means of a running example and share our insights with preliminary experiments on the benefits for formal verification. In particular, we find that not every change in a certain product line requires a re-verification of other dependent product lines.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {97–104},
numpages = {8},
keywords = {method contracts, deductive verification, Multi product line},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@inproceedings{10.1145/3510003.3510190,
author = {Randrianaina, Georges Aaron and T\"{e}rnava, Xhevahire and Khelladi, Djamel Eddine and Acher, Mathieu},
title = {On the benefits and limits of incremental build of software configurations: an exploratory study},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510190},
doi = {10.1145/3510003.3510190},
abstract = {Software projects use build systems to automate the compilation, testing, and continuous deployment of their software products. As software becomes increasingly configurable, the build of multiple configurations is a pressing need, but expensive and challenging to implement. The current state of practice is to build independently (a.k.a., clean build) a software for a subset of configurations. While incremental build has been studied for software evolution and relatively small changes of the source code, it has surprisingly not been considered for software configurations. In this exploratory study, we examine the benefits and limits of building software configurations incrementally, rather than always building them cleanly. By using five real-life configurable systems as subjects, we explore whether incremental build works, outperforms a sequence of clean builds, is correct w.r.t. clean build, and can be used to find an optimal ordering for building configurations. Our results show that incremental build is feasible in 100% of the times in four subjects and in 78% of the times in one subject. In average, 88.5% of the configurations could be built faster with incremental build while also finding several alternatives faster incremental builds. However, only 60% of faster incremental builds are correct. Still, when considering those correct incremental builds with clean builds, we could always find an optimal order that is faster than just a collection of clean builds with a gain up to 11.76%.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1584–1596},
numpages = {13},
keywords = {build systems, configurable software systems, configuration build},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3571788.3571791,
author = {Di Sandro, Alessio and Shahin, Ramy and Chechik, Marsha},
title = {Adding Product-Line Capabilities to Your Favourite Modeling Language},
year = {2023},
isbn = {9798400700019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571788.3571791},
doi = {10.1145/3571788.3571791},
abstract = {Software product lines are commonly adopted in industry to manage the development of complex families of software systems. Software engineering activities use models at their core, and extending a modeling language to support product lines is an expensive task. Moreover, many useful techniques and analyses such as model querying and model refactoring, are defined at the level of individual products. Before they can take advantage of a product line representation, they need to be lifted, i.e., reengineered to handle variability in a product line. Not only is this process non-trivial, it needs to be redone for each modeling language. In this paper, we propose an Eclipse-based framework, MMINT-PL, for creating and managing annotative product lines of software models in a language-agnostic way. Our framework allows extending any modeling language with product line capabilities, and facilitates lifting of a variety of modeling activities to the product line level. We also demonstrate how to use MMINT-PL to lift the Viatra Query Language.},
booktitle = {Proceedings of the 17th International Working Conference on Variability Modelling of Software-Intensive Systems},
pages = {3–12},
numpages = {10},
keywords = {variability, queries., modeling languages, Product lines},
location = {Odense, Denmark},
series = {VaMoS '23}
}

@inproceedings{10.1145/2307636.2307676,
author = {Borchert, Christoph and Lohmann, Daniel and Spinczyk, Olaf},
title = {CiAO/IP: a highly configurable aspect-oriented IP stack},
year = {2012},
isbn = {9781450313018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2307636.2307676},
doi = {10.1145/2307636.2307676},
abstract = {Internet protocols are constantly gaining relevance for the domain of mobile and embedded systems. However, building complex network protocol stacks for small resource-constrained devices is more than just porting a reference implementation. Due to the cost pressure in this area especially the memory footprint has to be minimized. Therefore, embedded TCP/IP implementations tend to be statically configurable with respect to the concrete application scenario. This paper describes our software engineering approach for building CiAO/IP - a tailorable TCP/IP stack for small embedded systems, which pushes the limits of static configurability while retaining source code maintainability. Our evaluation results show that CiAO/IP thereby outperforms both lwIP and uIP in terms of code size (up to 90% less than uIP), throughput (up to 20% higher than lwIP), energy consumption (at least 40% lower than uIP) and, most importantly, tailorability.},
booktitle = {Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services},
pages = {435–448},
numpages = {14},
keywords = {tcp/ip, operating systems, network protocol stacks, internet protocol, embedded systems, aspectc++, aspect-oriented programming, aop},
location = {Low Wood Bay, Lake District, UK},
series = {MobiSys '12}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3622748,
title = {SBCARS '23: Proceedings of the 17th Brazilian Symposium on Software Components, Architectures, and Reuse},
year = {2023},
isbn = {9798400709524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@inproceedings{10.1145/1353482.1353496,
author = {Chakravarthy, Venkat and Regehr, John and Eide, Eric},
title = {Edicts: implementing features with flexible binding times},
year = {2008},
isbn = {9781605580449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1353482.1353496},
doi = {10.1145/1353482.1353496},
abstract = {In a software product line, the binding time of a feature is the time at which one decides to include or exclude a feature from a product. Typical binding site implementations are intended to support a single binding time only, e.g., compile time or run time. Sometimes, however, a product line must support features with variable binding times. For instance, a product line may need to include both embedded system configurations, in which features are selected and optimized early, and desktop configurations, in which client programs choose features on demand.We present a new technique for implementing the binding sites of features that require flexible binding times. Our technique combines design patterns and aspect-oriented programming: a pattern encapsulates the variation point, and targeted aspects---called edicts---set the binding times of the pattern participants. We describe our approach and demonstrate its usefulness by creating a middleware product line capable of serving the desktop and embedded domains. Our product line is based on JacORB, a middleware platform with many dynamically configurable features. By using edicts to select features at compile time, we create a version of JacORB more suited to resource-constrained environments. By configuring four JacORB subsystems via edicts, we achieve a 32.2% reduction in code size. Our examples show that our technique effectively modularizes binding-time concerns, supporting both compile-time optimization and run-time flexibility as needed.},
booktitle = {Proceedings of the 7th International Conference on Aspect-Oriented Software Development},
pages = {108–119},
numpages = {12},
location = {Brussels, Belgium},
series = {AOSD '08}
}

@inproceedings{10.1145/3510466.3510484,
author = {Ratzenb\"{o}ck, Michael and Gr\"{u}nbacher, Paul and Assun\c{c}ao, Wesley K. G. and Egyed, Alexander and Linsbauer, Lukas},
title = {Refactoring Product Lines by Replaying Version Histories},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3510484},
doi = {10.1145/3510466.3510484},
abstract = {When evolving software product lines, new features are added over time and existing features are revised. Engineers also decide to merge different features or split features in other cases. Such refactoring tasks are difficult when using manually maintained feature-to-code mappings. Intensional version control systems such as ECCO overcome this issue with automatically computed feature-to-code mappings. Furthermore, they allow creating variants that have not been explicitly committed before. However, such systems are still rarely used compared to extensional version control systems like Git, which keep track of the evolution history by assigning revisions to states of a system. This paper presents an approach combining both extensional and intensional version control systems, which relies on the extensional version control system Git to store versions. Developers selectively tag existing versions to describe the evolution at the level of features. Our approach then automatically replays the evolution history to create a repository of the intensional variation control system ECCO. The approach contributes to research on refactoring features of existing product lines and migrating existing systems to product lines. We provide an initial evaluation of the approach regarding correctness and performance based on an existing system.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {10},
keywords = {version control systems, refactoring, feature-level evolution},
location = {Florence, Italy},
series = {VaMoS '22}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/375212.375269,
author = {Gacek, Critina and Anastasopoules, Michalis},
title = {Implementing product line variabilities},
year = {2001},
isbn = {1581133588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/375212.375269},
doi = {10.1145/375212.375269},
abstract = {Software product lines have numerous members. Thus, a product line infrastructure must cover various systems. This is the significant difference to usual software systems and the reason for additional requirements on the various assets present during software product line engineering. It is imperative that they support the description of the product line as a whole, as well as its instantiation for the derivation of individual products.Literature has already addressed how to create and instantiate generic product line assets, such as domain models and architectures to generate instance specific ones [1, 2, 3], yet little attention has been given on how to actually deal with this genericity at the code level.This paper addresses the issue of handling product line variability at the code level. To this end various implementation approaches are examined with respect to their use in a product line context.},
booktitle = {Proceedings of the 2001 Symposium on Software Reusability: Putting Software Reuse in Context},
pages = {109–117},
numpages = {9},
keywords = {traceability, software product lines, product line variability, implementing variabilities, implementation approaches},
location = {Toronto, Ontario, Canada},
series = {SSR '01}
}

@proceedings{10.1145/3607890,
title = {EMSOFT '23: Proceedings of the International Conference on Embedded Software},
year = {2023},
isbn = {9798400702914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {EMSOFT is the flagship conference of ACM SIGBED, the Special Interest Group on Embedded Systems, and a premier academic forum that brings together researchers and developers from academia, industry, and government to advance the science and practice of embedded software and systems. EMSOFT is held as part of ESWEEK, the annual highlight event of the embedded systems community. ESWEEK also features the International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (CASES) and the International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS).},
location = {Hamburg, Germany}
}

@article{10.1145/2063239.2063245,
author = {Erwig, Martin and Walkingshaw, Eric},
title = {The Choice Calculus: A Representation for Software Variation},
year = {2011},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2063239.2063245},
doi = {10.1145/2063239.2063245},
abstract = {Many areas of computer science are concerned with some form of variation in software---from managing changes to software over time to supporting families of related artifacts. We present the choice calculus, a fundamental representation for software variation that can serve as a common language of discourse for variation research, filling a role similar to the lambda calculus in programming language research. We also develop an associated theory of software variation, including sound transformations of variation artifacts, the definition of strategic normal forms, and a design theory for variation structures, which will support the development of better algorithms and tools.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {6},
numpages = {27},
keywords = {representation, Variation}
}

@inproceedings{10.1145/1944892.1944908,
author = {K\"{a}stner, Christian and Giarrusso, Paolo G. and Ostermann, Klaus},
title = {Partial preprocessing C code for variability analysis},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944908},
doi = {10.1145/1944892.1944908},
abstract = {The C preprocessor is commonly used to implement variability. Given a feature selection, code fragments can be excluded from compilation with #ifdef and similar directives. However, the token-based nature of the C preprocessor makes variability implementation difficult and error-prone. Additionally, variability mechanisms are intertwined with macro definitions, macro expansion, and file inclusion. To determine whether a code fragment is compiled, the entire file must be preprocessed. We present a partial preprocessor that preprocesses file inclusion and macro expansion, but retains variability information for further analysis. We describe the mechanisms of the partial preprocessor, provide a full implementation, and present some initial experimental results. The partial preprocessor is part of a larger endeavor in the TypeChef project to check variability implementations (syntactic correctness, type correctness) in C projects such as the Linux kernel.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {127–136},
numpages = {10},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/3338906.3338928,
author = {Shahin, Ramy and Chechik, Marsha and Salay, Rick},
title = {Lifting Datalog-based analyses to software product lines},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338928},
doi = {10.1145/3338906.3338928},
abstract = {Applying program analyses to Software Product Lines (SPLs) has been a fundamental research problem at the intersection of Product Line Engineering and software analysis. Different attempts have been made to ”lift” particular product-level analyses to run on the entire product line. In this paper, we tackle the class of Datalog-based analyses (e.g., pointer and taint analyses), study the theoretical aspects of lifting Datalog inference, and implement a lifted inference algorithm inside the Souffl\'{e} Datalog engine. We evaluate our implementation on a set of benchmark product lines. We show significant savings in processing time and fact database size (billions of times faster on one of the benchmarks) compared to brute-force analysis of each product individually.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {39–49},
numpages = {11},
keywords = {Souffl'{e}, Software Product Lines, Program Analysis, Pointer Analysis, Lifting, Doop, Datalog},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/2897045.2897048,
author = {Zhang, Bo and Duszynski, Slawomir and Becker, Martin},
title = {Variability mechanisms and lessons learned in practice},
year = {2016},
isbn = {9781450341769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897045.2897048},
doi = {10.1145/2897045.2897048},
abstract = {In the design of complex and variable software systems, one of the key steps is to select the variability mechanism that defines how variable features are realized on the design and code level. Although different variability mechanisms were invented and applied in practice for decades, there are not many studies that compare these mechanisms based on practical experiences. This paper characterizes and compares seven variability mechanisms in terms of their techniques, binding time, granularity, and further aspects. It provides experiences of their usage, the practical benefits and challenges, as well as discusses existing solutions to the challenges based on related studies and our practice in industry.},
booktitle = {Proceedings of the 1st International Workshop on Variability and Complexity in Software Design},
pages = {14–20},
numpages = {7},
keywords = {variability mechanisms, variability design, practical experience},
location = {Austin, Texas},
series = {VACE '16}
}

@inproceedings{10.1145/3276604.3276622,
author = {Leduc, Manuel and Degueule, Thomas and Combemale, Benoit},
title = {Modular language composition for the masses},
year = {2018},
isbn = {9781450360296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276604.3276622},
doi = {10.1145/3276604.3276622},
abstract = {The goal of modular language development is to enable the definition of new languages as assemblies of pre-existing ones. Recent approaches in this area are plentiful but usually suffer from two main problems: either they do not support modular language composition both at the specification and implementation levels, or they require advanced knowledge of specific paradigms which hampers wide adoption in the industry. In this paper, we introduce a non-intrusive approach to modular development of language concerns with well-defined interfaces that can be composed modularly at the specification and implementation levels. We present an implementation of our approach atop the Eclipse Modeling Framework, namely Alex, an object-oriented meta-language for semantics definition and language composition. We evaluate Alex in the development of a new DSL for IoT systems modeling resulting from the composition of three independently defined languages (UML activity diagrams, Lua, and the OMG Interface Description Language). We evaluate the effort required to implement and compose these languages using Alex with regards to similar approaches of the literature.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {47–59},
numpages = {13},
keywords = {modular language development, language interface, language concern, language composition},
location = {Boston, MA, USA},
series = {SLE 2018}
}

@proceedings{10.1145/3567512,
title = {SLE 2022: Proceedings of the 15th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2022},
isbn = {9781450399197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 15th ACM SIGPLAN International Conference on Software Language Engineering (SLE), co-located with the ACM SIGPLAN conference on Systems, Programming, Languages, and Applications (SPLASH) in Auckland, a vibrant port city in northern New Zealand, from December 5th to December 10th 2022. Like its predecessors, the this edition of the SLE conference, SLE 2022, is devoted to the principles of software languages: their design, their implementation, and their evolution. As such, SLE brings together researchers united by their common interest in the creation, capture, and tooling of software languages.},
location = {Auckland, New Zealand}
}

@proceedings{10.1145/2993236,
title = {GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/3564719,
title = {GPCE 2022: Proceedings of the 21st ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2022},
isbn = {9781450399203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 21st ACM SIGPLAN International Conference on Generative Programming: Concept &amp; Experiences (GPCE 2022) held on December 6th and 7th, 2022 in Auckland, New Zealand. GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation, domain-specific languages, and component deployment to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between software engineering and programming language.},
location = {Auckland, New Zealand}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@inproceedings{10.1145/1985793.1985851,
author = {Apel, Sven and Beyer, Dirk},
title = {Feature cohesion in software product lines: an exploratory study},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985851},
doi = {10.1145/1985793.1985851},
abstract = {Software product lines gain momentum in research and industry. Many product-line approaches use features as a central abstraction mechanism. Feature-oriented software development aims at encapsulating features in cohesive units to support program comprehension, variability, and reuse. Surprisingly, not much is known about the characteristics of cohesion in feature-oriented product lines, although proper cohesion is of special interest in product-line engineering due to its focus on variability and reuse. To fill this gap, we conduct an exploratory study on forty software product lines of different sizes and domains. A distinguishing property of our approach is that we use both classic software measures and novel measures that are based on distances in clustering layouts, which can be used also for visual exploration of product-line architectures. This way, we can draw a holistic picture of feature cohesion. In our exploratory study, we found several interesting correlations (e.g., between development process and feature cohesion) and we discuss insights and perspectives of investigating feature cohesion (e.g., regarding feature interfaces and programming style).},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {421–430},
numpages = {10},
keywords = {visual clustering, software product lines, featurevisu, feature-oriented software development, feature cohesion},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2591028.2600810,
author = {Santos, Jadson and Lima, Gleydson and Kulesza, Uir\'{a} and Sena, Demostenes and Pinto, Felipe and Lima, Jalerson and Vianna, Alexandre and Pereira, David and Fernandes, Victor},
title = {Conditional execution: a pattern for the implementation of fine-grained variabilities in software product lines},
year = {2012},
isbn = {9781450327879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591028.2600810},
doi = {10.1145/2591028.2600810},
abstract = {This paper presents the Conditional Execution design pattern that aims to help the implementation of fine-grained variabilities in the context of software product lines of information systems. The pattern has been used successfully in three product lines of web information systems developed by Informatics Superintendence (SINFO) at Federal University of Rio Grande do Norte.},
booktitle = {Proceedings of the 9th Latin-American Conference on Pattern Languages of Programming},
articleno = {1},
numpages = {17},
keywords = {software product lines, fine-grained variabilities, design pattern},
location = {Natal, Rio Grande do Norte, Brazil},
series = {SugarLoafPLoP '12}
}

@inproceedings{10.1145/3239372.3239377,
author = {de Lara, Juan and Guerra, Esther and Chechik, Marsha and Salay, Rick},
title = {Model Transformation Product Lines},
year = {2018},
isbn = {9781450349499},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239372.3239377},
doi = {10.1145/3239372.3239377},
abstract = {Model transformations enable automation in Model-Driven Engineering (MDE) and are key to its success. The emphasis of MDE on using domain-specific languages has caused a proliferation of meta-models, many of them capturing variants of base languages. In this scenario, developing a transformation for a new meta-model is usually performed manually with no reuse, even if comparable transformations for similar meta-models exist. This is a suboptimal process that precludes a wider adoption of MDE in industry.To improve this situation, we propose applying ideas from software product lines to transformation engineering. Our proposal enables the definition of meta-model product lines to capture the variability within a domain, on top of which transformations can be defined in a modular way. We call this construction transformation product line (TPL), and propose mechanisms for their construction, extension and analysis. TPLs are supported by a tool, Merlin, which is agnostic to the transformation language and lifts analyses based on model finding to the TPL. Finally, we report on an evaluation showing the benefits of building and analysing TPLs compared to building and analysing each individual transformation.},
booktitle = {Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {67–77},
numpages = {11},
keywords = {Reusability, Product Lines, Model Transformations},
location = {Copenhagen, Denmark},
series = {MODELS '18}
}

@article{10.1145/2094091.2094095,
author = {Tartler, Reinhard and Lohmann, Daniel and Dietrich, Christian and Egger, Christoph and Sincero, Julio},
title = {Configuration coverage in the analysis of large-scale system software},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0163-5980},
url = {https://doi.org/10.1145/2094091.2094095},
doi = {10.1145/2094091.2094095},
abstract = {System software, especially operating systems, tends to be highly configurable. Like every complex piece of software, a considerable amount of bugs in the implementation has to be expected. In order to improve the general code quality, tools for static analysis provide means to check for source code defects without having to run actual test cases on real hardware. Still, for proper type checking a specific configuration is required so that all header include paths are available and all types are properly resolved.In order to find as many bugs as possible, usually a "full configuration" is used for the check. However, mainly because of alternative blocks in form of #else-blocks, a single configuration is insufficient to achieve full coverage. In this paper, we present a metric for configuration coverage (CC) and explain the challenges for (properly) calculating it. Furthermore, we present an efficient approach for determining a sufficiently small set of configurations that achieve (nearly) full coverage and evaluate it on a recent Linux kernel version.},
journal = {SIGOPS Oper. Syst. Rev.},
month = jan,
pages = {10–14},
numpages = {5}
}

@inproceedings{10.1145/3357765.3359518,
author = {Dimovski, Aleksandar S.},
title = {Lifted static analysis using a binary decision diagram abstract domain},
year = {2019},
isbn = {9781450369800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357765.3359518},
doi = {10.1145/3357765.3359518},
abstract = {Many software systems are today variational. They can produce a potentially large variety of related programs (variants) by selecting suitable configuration options (features) at compile time. Specialized variability-aware (lifted, family-based) static analyses allow analyzing all variants of the family, simultaneously, in a single run without generating any of the variants explicitly. In effect, they produce precise analysis results for all individual variants. The elements of the lifted analysis domain represent tuples (i.e. disjunction of properties), which maintain one property from an existing single-program analysis domain per variant. Nevertheless, explicit property enumeration in tuples, one by one for all variants, immediately yields to combinatorial explosion given that the number of variants can grow exponentially with the number of features. Therefore, such lifted analyses may be too costly or even infeasible for families with a large number of variants. In this work, we propose a more efficient lifted static analysis where sharing is explicitly possible between analysis elements corresponding to different variants. This is achieved by giving a symbolic representation of the lifted analysis domain, which can efficiently handle disjunctive properties in program families. The elements of the new lifted domain are binary decision diagrams where decision nodes are labeled with features, and the leaf nodes belong to an existing single-program analysis domain. We have developed a lifted static analysis which uses APRON and BDDAPRON libraries for implementing the new lifted analysis domain. The APRON library, used for the leaves, is a widely accepted API for numerical abstract domains (e.g. polyhedra, octagons, intervals), while the BDDAPRON is an extension of &nbsp; which adds the power domain of Boolean formulae and any APRON domain. Through experiments applied to C program families, we show that our new BDD-based approach outperforms the old tuple-based approach for lifted analysis.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {102–114},
numpages = {13},
keywords = {Software product lines, Lifted static analysis, Binary decision diagram domai, Abstract interpretation},
location = {Athens, Greece},
series = {GPCE 2019}
}

@inproceedings{10.1145/1868688.1868697,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Kuhlemann, Martin},
title = {Improving reuse of component families by generating component hierarchies},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868697},
doi = {10.1145/1868688.1868697},
abstract = {Feature-oriented software development (FOSD) enables developers to generate families of similar components. However, current FOSD approaches degrade component reuse because they do not allow a developer to combine multiple components of the same family in a larger program. This is because individual family members cannot be distinguished from each other. We present an approach to model and generate component hierarchies that allow a programmer to combine multiple component variants. A component hierarchy structures the components of a family according to their functionality. Due to subtyping between the components of a hierarchy, client developers can write generic code that works with different component variants.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {57–64},
numpages = {8},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/1134650.1134678,
author = {Pandey, Raju and Wu, Jeffrey},
title = {BOTS: a constraint-based component system for synthesizing scalable software systems},
year = {2006},
isbn = {159593362X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134650.1134678},
doi = {10.1145/1134650.1134678},
abstract = {Embedded application developers create applications for a wide range of devices with different resource constraints. Developers want to maximize the use of the limited resources available on the device while still not exceeding the capabilities of the device. To do this, the developer must be able to scale his software for different platforms. In this paper, we present a software engineering methodology that automatically scales software to different platforms. We intend to have the application developer write high level functional specifications of his software and have tools that automatically scale the underlying runtime. These tools will use the functional and non-functional constraints of both the hardware and client application to produce an appropriate runtime. Our initial results show that the proposed approach can scale operating systems and virtual machines that satisfy the constraints of varying hardware/application combinations.},
booktitle = {Proceedings of the 2006 ACM SIGPLAN/SIGBED Conference on Language, Compilers, and Tool Support for Embedded Systems},
pages = {189–198},
numpages = {10},
keywords = {wireless sensor networks, runtime systems, generative programming, embedded systems, constraints, components},
location = {Ottawa, Ontario, Canada},
series = {LCTES '06}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2658761.2658767,
author = {Ruprecht, Andreas and Heinloth, Bernhard and Lohmann, Daniel},
title = {Automatic feature selection in large-scale system-software product lines},
year = {2014},
isbn = {9781450331616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658761.2658767},
doi = {10.1145/2658761.2658767},
abstract = {System software can typically be configured at compile time via a comfortable feature-based interface to tailor its functionality towards a specific use case. However, with the growing number of features, this tailoring process becomes increasingly difficult: As a prominent example, the Linux kernel in v3.14 provides nearly 14 000 configuration options to choose from. Even developers of embedded systems refrain from trying to build a minimized distinctive kernel configuration for their device – and thereby waste memory and money for unneeded functionality. In this paper, we present an approach for the automatic use-case specific tailoring of system software for special-purpose embedded systems. We evaluate the effectiveness of our approach on the example of Linux by generating tailored kernels for well-known applications of the Rasperry Pi and a Google Nexus 4 smartphone. Compared to the original configurations, our approach leads to memory savings of 15–70 percent and requires only very little manual intervention.},
booktitle = {Proceedings of the 2014 International Conference on Generative Programming: Concepts and Experiences},
pages = {39–48},
numpages = {10},
keywords = {Software Tailoring, Software Product Lines, Linux, Feature Selection},
location = {V\"{a}ster\r{a}s, Sweden},
series = {GPCE 2014}
}

@proceedings{10.1145/3689031,
title = {EuroSys '25: Proceedings of the Twentieth European Conference on Computer Systems},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to EuroSys 2025, the 20th edition of the European Conference on Computer Systems! We are excited to host EuroSys 2025 in the modern and dynamic city of Rotterdam, Netherlands. This year's EuroSys is very special as it is co-located (for the first time) with the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2025). We hope you will enjoy an excellent technical program, engaging discussions, and networking opportunities in this vibrant city known for its innovative architecture, bustling port, and rich cultural scene.},
location = {Rotterdam, Netherlands}
}

@inproceedings{10.1145/1869542.1869545,
author = {Ribeiro, M\'{a}rcio and Pacheco, Humberto and Teixeira, Leopoldo and Borba, Paulo},
title = {Emergent feature modularization},
year = {2010},
isbn = {9781450302401},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1869542.1869545},
doi = {10.1145/1869542.1869545},
abstract = {Virtual Separation of Concerns reduces the drawbacks of implementing product line variability with preprocessors. Developers can focus on certain features and hide others of no interest. However, these features eventually share elements between them, which might break feature modularization, since modifications in a feature result in problems for another. We present the concept of emergent feature modularization, which aims to establish contracts between features, to prevent developers from breaking other features when performing a maintenance task. These interfaces are product-line-aware, in the sense that it only considers valid feature combinations. We also present a prototype tool that implements the concept.},
booktitle = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion},
pages = {11–18},
numpages = {8},
keywords = {product lines, preprocessors, modularity},
location = {Reno/Tahoe, Nevada, USA},
series = {OOPSLA '10}
}

@article{10.1145/2807593,
author = {Baudry, Benoit and Monperrus, Martin},
title = {The Multiple Facets of Software Diversity: Recent Developments in Year 2000 and Beyond},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2807593},
doi = {10.1145/2807593},
abstract = {Early experiments with software diversity in the mid 1970s investigated N-version programming and recovery blocks to increase the reliability of embedded systems. Four decades later, the literature about software diversity has expanded in multiple directions: goals (fault tolerance, security, software engineering), means (managed or automated diversity), and analytical studies (quantification of diversity and its impact). Our article contributes to the field of software diversity as the first work that adopts an inclusive vision of the area, with an emphasis on the most recent advances in the field. This survey includes classical work about design and data diversity for fault tolerance, as well as the cybersecurity literature that investigates randomization at different system levels. It broadens this standard scope of diversity to include the study and exploitation of natural diversity and the management of diverse software products. Our survey includes the most recent works, with an emphasis from 2000 to the present. The targeted audience is researchers and practitioners in one of the surveyed fields who miss the big picture of software diversity. Assembling the multiple facets of this fascinating topic sheds a new light on the field.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {16},
numpages = {26},
keywords = {program transformation, design principles, Software diversity}
}

@inproceedings{10.1145/2162049.2162071,
author = {Cardoso, Jo\~{a}o M.P. and Carvalho, Tiago and Coutinho, Jos\'{e} G.F. and Luk, Wayne and Nobre, Ricardo and Diniz, Pedro and Petrov, Zlatko},
title = {LARA: an aspect-oriented programming language for embedded systems},
year = {2012},
isbn = {9781450310925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2162049.2162071},
doi = {10.1145/2162049.2162071},
abstract = {The development of applications for high-performance embedded systems is typically a long and error-prone process. In addition to the required functions, developers must consider various and often conflicting non-functional application requirements such as performance and energy efficiency. The complexity of this process is exacerbated by the multitude of target architectures and the associated retargetable mapping tools. This paper introduces an As-pect-Oriented Programming (AOP) approach that conveys domain knowledge and non-functional requirements to optimizers and mapping tools. We describe a novel AOP language, LARA, which allows the specification of compi-lation strategies to enable efficient generation of software code and hardware cores for alternative target architectures. We illustrate the use of LARA for code instrumentation and analysis, and for guiding the application of compiler and hardware synthesis optimizations. An important LARA feature is its capability to deal with different join points, action models, and attributes, and to generate an aspect intermediate representation. We present examples of our aspect-oriented hardware/software design flow for mapping real-life application codes to embedded platforms based on Field Programmable Gate Array (FPGA) technology.},
booktitle = {Proceedings of the 11th Annual International Conference on Aspect-Oriented Software Development},
pages = {179–190},
numpages = {12},
keywords = {reconfigurable computing, embedded systems, domain-specific languages, compilers, aspect-oriented programming, FPGAs},
location = {Potsdam, Germany},
series = {AOSD '12}
}

@inproceedings{10.1145/1289971.1289990,
author = {Trujillo, Salvador and Azanza, Maider and Diaz, Oscar},
title = {Generative metaprogramming},
year = {2007},
isbn = {9781595938558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1289971.1289990},
doi = {10.1145/1289971.1289990},
abstract = {Recent advances in Software Engineering have reduced the cost of coding programs at the expense of increasing the complexity of program synthesis, i.e. metaprograms, which when executed, will synthesize a target program. The traditional cycle of configuring-linking-compiling, now needs to be supplemented with additional transformation steps that refine and enhance an initial specification until the target program is obtained. So far, these synthesis processes are based on error-prone, hand-crafted scripting. To depart from this situation, this paper addresses generative metaprogramming, i.e. the generation of program-synthesis metaprograms from declarative specifications. To this end, we explore (i) the (meta) primitives for program synthesis, (ii) the architecture that dictates how these primitives can be intertwined, and (iii) the declarative specification of the metaprogram from which the code counterpart is generated.},
booktitle = {Proceedings of the 6th International Conference on Generative Programming and Component Engineering},
pages = {105–114},
numpages = {10},
keywords = {software product lines, metaprogramming, generative programming, generative metaprogramming, feature oriented model-driven development},
location = {Salzburg, Austria},
series = {GPCE '07}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2577080.2579816,
author = {Kamina, Tetsuo and Aotani, Tomoyuki and Masuhara, Hidehiko and Tamai, Tetsuo},
title = {Context-oriented software engineering: a modularity vision},
year = {2014},
isbn = {9781450327725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2577080.2579816},
doi = {10.1145/2577080.2579816},
abstract = {There are a number of constructs to implement context-dependent behavior, such as conditional branches using if statements, method dispatching in object-oriented programming (such as the state design pattern), dynamic deployment of aspects in aspect-oriented programming, and layers in context-oriented programming (COP). Uses of those constructs significantly affect the modularity of the obtained implementation. While there are a number of cases where COP improves modularity, it is not clear when we should use COP in general.This paper presents a preliminary study on our software development methodology, the context-oriented software engineering (COSE), which is a use-case-driven software development methodology that guides us to a specification of context-dependent requirements and design. We provide a way to map the requirements and design formed by COSE to the implementation in our COP language ServalCJ. We applied COSE to two applications in order to assess its feasibility. We also identify key linguistic constructs that make COSE effective by examining existing COP languages. These feasibility studies and examination raise a number of interesting open issues. We finally show our future research roadmap to address those issues.},
booktitle = {Proceedings of the 13th International Conference on Modularity},
pages = {85–98},
numpages = {14},
keywords = {use cases, methodology, context-oriented programming},
location = {Lugano, Switzerland},
series = {MODULARITY '14}
}

@inproceedings{10.1145/1868688.1868692,
author = {Hofer, Wanja and Elsner, Christoph and Blendinger, Frank and Schr\"{o}der-Preikschat, Wolfgang and Lohmann, Daniel},
title = {Toolchain-independent variant management with the Leviathan filesystem},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868692},
doi = {10.1145/1868688.1868692},
abstract = {Preprocessor-configured software needs tool support for the developer to be able to cope with the complexity introduced by optional and alternative code blocks in the source. Current approaches, which assist the software developer by providing preprocessed views, are all bound to a special integrated development environment. This eliminates them from being used both in industry settings (where domain-specific toolchains are often mandated) and in open-source projects (where diverse sets of editors and tools are being used and freedom of tool choice is crucial for the project success).We therefore propose to tackle the problem at a lower level by implementing variant views at the filesystem level. By mounting one or more variants using our Leviathan filesystem, we enable the use of standard tools such as syntax validators, code metric analysis tools, or arbitrary editors to view or modify a variant. The major benefit (and challenge) is the support for automatically writing back to the configurable code base when editing one of the mounted variant views.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {18–24},
numpages = {7},
keywords = {variability implementation, toolchain-independent variability support, software product lines, preprocessor-based configuration, filesystem views, Leviathan},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@proceedings{10.1145/3658644,
title = {CCS '24: Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great enthusiasm that we, on behalf of the Organizing Committee, invite you to join us for the 31st ACM SIGSAC Conference on Computer and Communications Security (CCS), a premier security and privacy conference where researchers, practitioners, and educators come together to present, learn, and debate research, innovation, and trends in the field of Computer and Communications Security and Privacy.This year, we are proud to introduce our conference theme to be "Inclusion, Mentorship, Community." These three pillars reflect our collective commitment to fostering a vibrant, supportive, and forwardthinking environment within the CCS community. Particularly, we host our inaugural Doctoral Symposium, which offers PhD students a unique platform to receive timely, constructive feedback on their dissertation research from leading experts in our community. Additionally, our first-ever Diversity, Equity, and Inclusion (DEI) Workshop is designed to cultivate a culture that embraces diversity and champions equity in our field. Moreover, understanding the importance of guidance and support, we have organized panels focusing on Student Mentoring, Faculty Mentoring, and Public Service. These panels are designed to facilitate mentorship connections, share valuable experiences, and encourage service that extends the impact of our work beyond academia. These new initiatives are also opportunities to strengthen the bonds within our CCS community.Regarding the main conference, this year's main conference is our largest ever, featuring 328 paper presentations that showcase the latest research and developments in our field. We are also honored to have two distinguished keynote speakers: Dr. Dan Boneh and Dr. Gene Tsudik, who will share their invaluable insights and perspectives on pressing topics in security and privacy. Additionally, 18 specialized workshops will take place on the pre-conference and post-conference days, providing platforms for focused discussions and collaborations on numerous specialized topics.},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3238147.3238201,
author = {Mukelabai, Mukelabai and Ne\v{s}i\'{c}, Damir and Maro, Salome and Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp},
title = {Tackling combinatorial explosion: a study of industrial needs and practices for analyzing highly configurable systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238201},
doi = {10.1145/3238147.3238201},
abstract = {Highly configurable systems are complex pieces of software. To tackle this complexity, hundreds of dedicated analysis techniques have been conceived, many of which able to analyze system properties for all possible system configurations, as opposed to traditional, single-system analyses. Unfortunately, it is largely unknown whether these techniques are adopted in practice, whether they address actual needs, or what strategies practitioners actually apply to analyze highly configurable systems. We present a study of analysis practices and needs in industry. It relied on a survey with 27 practitioners engineering highly configurable systems and follow-up interviews with 15 of them, covering 18 different companies from eight countries. We confirm that typical properties considered in the literature (e.g., reliability) are relevant, that consistency between variability models and artifacts is critical, but that the majority of analyses for specifications of configuration options (a.k.a., variability model analysis) is not perceived as needed. We identified rather pragmatic analysis strategies, including practices to avoid the need for analysis. For instance, testing with experience-based sampling is the most commonly applied strategy, while systematic sampling is rarely applicable. We discuss analyses that are missing and synthesize our insights into suggestions for future research.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {155–166},
numpages = {12},
keywords = {Product Lines, Highly Configurable Systems, Analysis},
location = {Montpellier, France},
series = {ASE '18}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@inproceedings{10.1145/2642937.2642990,
author = {Abal, Iago and Brabrand, Claus and Wasowski, Andrzej},
title = {42 variability bugs in the linux kernel: a qualitative analysis},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2642990},
doi = {10.1145/2642937.2642990},
abstract = {Feature-sensitive verification pursues effective analysis of the exponentially many variants of a program family. However, researchers lack examples of concrete bugs induced by variability, occurring in real large-scale systems. Such a collection of bugs is a requirement for goal-oriented research, serving to evaluate tool implementations of feature-sensitive analyses by testing them on real bugs. We present a qualitative study of 42 variability bugs collected from bug-fixing commits to the Linux kernel repository. We analyze each of the bugs, and record the results in a database. In addition, we provide self-contained simplified C99 versions of the bugs, facilitating understanding and tool evaluation. Our study provides insights into the nature and occurrence of variability bugs in a large C software system, and shows in what ways variability affects and increases the complexity of software bugs.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {421–432},
numpages = {12},
keywords = {software variability, linux, feature interactions, bugs},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@proceedings{10.1145/3634737,
title = {ASIA CCS '24: Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM AsiaCCS 2024, the 19th ACM Asia Conference on Computer and Communications Security. AsiaCCS 2024 takes place in Singapore from 1 July to 5 July.},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@article{10.1007/s00165-019-00479-y,
author = {Dimovski, Aleksandar S. and Brabrand, Claus and W\k{a}sowski, Andrzej},
title = {Finding suitable variability abstractions for lifted analysis},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {2},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-019-00479-y},
doi = {10.1007/s00165-019-00479-y},
abstract = {Many software systems are today variational: they are built as program families or Software Product Lines. They can produce a potentially huge number of related programs, known as products or variants, by selecting suitable configuration options (features) at compile time. Many such program families are safety critical, yet the appropriate tools only rarely are able to analyze them effeciently. Researchers have addressed this problem by designing specialized variability-aware static (dataflow) analyses, which allow analyzing all variants of the family, simultaneously, in a single run without generating any of the variants explicitly. They are also known as lifted or family-based analyses. They take as input the common code base, which encodes all variants of a program family, and produce precise analysis results corresponding to all variants. These analyses scale much better than “brute force” approach, where all individual variants are analyzed in isolation, one-by-one, using off-the-shelf single-program analyzers. Nevertheless, the computational cost of lifted analyses still greatly depends on the number of features and variants (which is often huge). For families with a large number of features and variants, the lifted analyses may be too costly or even infeasible. In order to speed up lifted analyses and make them computationally cheaper, variability abstractions which simplify variability away from program families and lifted analyses have been introduced. However, the space of possible variability abstractions is still intractably large to search naively, with most abstractions being either too imprecise or too costly. We introduce here a method to efficiently find suitable variability abstractions from a large space of possible abstractions for a lifted static analysis. The main idea is to use a pre-analysis to estimate the impact of variability-specific parts of the program family on the analysis’s precision. The pre-analysis is fully variability-aware while it aggressively abstracts the other semantics aspects. Then we use the pre-analysis results to find out when and where the subsequent abstract lifted analysis should turn off or on its variability-awareness. The abstraction constructed in this way is effective in discarding variability-specific program details that are irrelevant for showing the analysis’s ultimate goal. We formalize this approach and we illustrate its effectiveness on several Java case studies. The evaluation shows that our approach which consists of running a pre-analysis followed by a subsequent abstract lifted analysis achieves competitive the precision-speed tradeoff compared to the standard lifted analysis.},
journal = {Form. Asp. Comput.},
month = apr,
pages = {231–259},
numpages = {29},
keywords = {Abstract interpretation, Variability abstractions, Lifted static analysis, Program families}
}

@article{10.1145/979743.979745,
author = {ACM SIGSOFT Software Engineering Notes staff},
title = {Back matter (abstracts and calendar)},
year = {2004},
issue_date = {March 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/979743.979745},
doi = {10.1145/979743.979745},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {27–62},
numpages = {36}
}

@inproceedings{10.1145/976270.976279,
author = {Colyer, Adrian and Clement, Andrew},
title = {Large-scale AOSD for middleware},
year = {2004},
isbn = {1581138423},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/976270.976279},
doi = {10.1145/976270.976279},
abstract = {For a variety of reasons, today's middleware systems are highly complex. This complexity surfaces internally in the middleware construction, and externally in the programming models supported and features offered. We believed that aspect-orientation could help with these problems, and undertook a case study based on members of an IBM® middleware product-line. We also wanted to know whether aspect-oriented techniques could scale to commercial project sizes with tens of thousands of classes, many millions of lines of code, hundreds of developers, and sophisticated build systems. This paper describes the motivation for our research, the challenges involved, and key lessons that we learnt in refactoring both homogeneous and heterogeneous crosscutting concerns in the middleware.},
booktitle = {Proceedings of the 3rd International Conference on Aspect-Oriented Software Development},
pages = {56–65},
numpages = {10},
keywords = {refactoring, middleware, aspect-oriented},
location = {Lancaster, UK},
series = {AOSD '04}
}

@inproceedings{10.5555/1022685.1022938,
author = {Gotze, Marco},
title = {A Flexible Object-Oriented Software Architecture for Smart Wireless Communication Devices},
year = {2003},
isbn = {0769518702},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper describes the design considerations of and preliminary conclusions drawn from an ongoing project dealing with the design of a software architecture for a family of so-called smart wireless communication devices (SWCDs). More specifically, based on an existing hardware platform, the software architecture is being modeled using UML in conjunction with suitable framework and product line modeling approaches to achieve a high degree of flexibility with respect to variability at both the hardware and application software end of the spectrum. To this effect, the design is split into a middleware framework encapsulating specifics of the underlying hardware platform and OS, and product line modeling of a comprehensive, versatile application on top of it.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe: Designers' Forum - Volume 2},
pages = {20126},
series = {DATE '03}
}

@proceedings{10.1145/2984043,
title = {SPLASH Companion 2016: Companion Proceedings of the 2016 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity},
year = {2016},
isbn = {9781450344371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/3562939,
title = {VRST '22: Proceedings of the 28th ACM Symposium on Virtual Reality Software and Technology},
year = {2022},
isbn = {9781450398893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tsukuba, Japan}
}

@inproceedings{10.1145/800236.807090,
author = {Russell, Robert D.},
title = {Experience in the design, implementation and use of PL-11, a programming language for the PDP-11},
year = {1976},
isbn = {9781450378949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800236.807090},
doi = {10.1145/800236.807090},
abstract = {PL-11 is a programming language for the PDP-11 family of computers designed and implemented as part of the OMEGA Project at CERN (the European Organization for Nuclear Research). Its purpose is to provide an effective tool for both physicists and systems programmers to use in building real-time data acquisition systems that are on-line to high-energy physics experiments. It is a fairly typical member of the PL-class of programming languages (44) which are based on the initial design of PL360 (41) (see Table 1). Each of these languages represents a linguistic model of its specific machine architecture, thereby providing a Systems Implementation Language (SIL) that is extremely efficient on its target machine, yet is also highly effective for human programmers to use. The need for such a tool is obvious on all computer systems, but especially on minicomputers, where most applications are in fact “systems programs”. For example, in any data acquisition environment the distinction between “user” and “operating system” largely disappears—the user's prime concern is to handle time-dependent sequences of events involving the manipulation of special I/O devices through direct status checking and data streaming—all functions which are usually buried in the operating system of conventional computing systems.This paper discusses four years of experience with PL-11, especially as this relates to the general topic of SILs on minicomputers.},
booktitle = {Proceedings of the ACM SIGMINI/SIGPLAN Interface Meeting on Programming Systems in the Small Processor Environment},
pages = {27–34},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {SIGMINI '76}
}

