@inproceedings{10.1145/3646548.3672587,
author = {Becker, Martin and Rabiser, Rick and Botterweck, Goetz},
title = {Not Quite There Yet: Remaining Challenges in Systems and Software Product Line Engineering as Perceived by Industry Practitioners},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672587},
doi = {10.1145/3646548.3672587},
abstract = {Research on system and software product line engineering (SPLE) and the community around it have been inspired by industrial applications. However, despite decades of research, industry is still struggling with adopting product line approaches and more generally with managing system variability. We argue that it is essential to better understand why this is the case. Particularly, we need to understand the current challenges industry is facing wrt. adopting SPLE practices, how far existing research helps industry practitioners to cope with their challenges, and where additional research would be required. We conducted a hybrid workshop at the 2023 Systems and Software Product Line Conference (SPLC) with over 30 participants from industry and academia. 9 companies from diverse domains and in different phases of SPLE adoption presented their context and perceived challenges. We grouped, discussed, and rated the relevance of the articulated challenges. We then formed clusters of relevant research topics to discuss existing literature as well as research opportunities. In this paper, we report the industry cases, the identified challenges and clusters of research topics, provide pointers to existing work, and discuss research opportunities. With this, we want to enable industry practitioners to become aware of typical challenges and find their way into the existing body of knowledge and to relevant fields of research.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {179–190},
numpages = {12},
keywords = {Software product line engineering, industry challenges},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@article{10.1145/3695987,
author = {Oliveria de Souza, Leandro and Santana de Almeida, Eduardo and Silveira Neto, Paulo Anselmo da Mota and Barr, Earl T. and Petke, Justyna},
title = {Software Product Line Engineering via Software Transplantation},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695987},
doi = {10.1145/3695987},
abstract = {Software Product Lines (SPLs) improve time-to-market, enhance software quality, and reduce maintenance costs. Current SPL reengineering practices are largely manual and require domain knowledge. Thus, adopting and, to a lesser extent, maintaining SPLs are expensive tasks, preventing many companies from enjoying their benefits. To address these challenges, we introduce Foundry, an approach utilising software transplantation to reduce the manual effort of SPL adoption and maintenance. Foundry enables integrating features across different codebases, even codebases that are unaware that they are contributing features to a software product line. Each product produced by Foundry is pure code, without variability annotation, unlike feature flags, which eases variability management and reduces code bloat.We realise Foundry in prodScalpel, a tool that transplants multiple organs (i.e., a set of interesting features) from donor systems into an emergent product line for codebases written in C. Given tests and lightweight annotations identifying features and implantation points, prodScalpel automates feature extraction and integration. To evaluate its effectiveness, our evaluation compares feature transplantation using prodScalpel to the current state of practice: on our dataset, prodScalpel’s use speeds up feature migration by an average of 4.8 times when compared to current practice.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {31},
numpages = {27},
keywords = {Software Product Lines, Software Transplantation, Genetic Improvement}
}

@inproceedings{10.1145/3646548.3676551,
author = {Ramos-Vidal, Delfina},
title = {Advancing Legacy Software Modernization through Software Product Line Engineering: A Case Study in Digital Libraries},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3676551},
doi = {10.1145/3646548.3676551},
abstract = {Legacy Document Information Systems (DIS) pose significant challenges due to their outdated architectures and the criticality of their business functions. This paper proposes a novel approach utilizing Software Product Line Engineering (SPLE) to modernize DIS, aiming to reduce development time and costs while enhancing system sustainability and adaptability. The framework integrates strategies for database migration and evolution modeling, crucial for seamless modernization. Case studies involving real-world digital libraries validate the framework’s effectiveness, comparing it against traditional methods. Results indicate substantial improvements in efficiency and cost-effectiveness, positioning SPLE as a promising strategy for legacy system modernization in digital library domains.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {17–21},
numpages = {5},
keywords = {Digital Libraries, Document Information Systems, Legacy Systems, Modernization, Software Product Lines},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {product-line analysis, Software product lines}
}

@inproceedings{10.1145/2701319.2701326,
author = {Soares, Larissa Rocha and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Non-Functional Properties in Software Product Lines: A Reuse Approach},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701326},
doi = {10.1145/2701319.2701326},
abstract = {Software Product Line Engineering (SPLE) emerges for software organizations interested in customized products at reasonable costs. Based on the selection of features, stakeholders can derive programs satisfying a range of functional properties and non-functional ones. The explicit definition of Non-Functional Properties (NFP) during software configuration has been considered a challenging task. Dealing with them is not well established yet, neither in theory nor in practice. In this sense, we present a framework to specify NFP for SPLE and we also propose a reuse approach that promotes the reuse of NFP values during the product configuration. We discuss the results of a case study aimed to evaluate the applicability of the proposed work.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {67–74},
numpages = {8},
keywords = {Software Product Line, Quality Attributes, Empirical Software Engineering},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@inproceedings{10.1145/3233027.3233028,
author = {Rabiser, Rick and Schmid, Klaus and Becker, Martin and Botterweck, Goetz and Galster, Matthias and Groher, Iris and Weyns, Danny},
title = {A study and comparison of industrial vs. academic software product line research published at SPLC},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233028},
doi = {10.1145/3233027.3233028},
abstract = {The study presented in this paper aims to provide evidence for the hypothesis that software product line research has been changing and that the works in industry and academia have diverged over time. We analysed a subset (140) of all (593) papers published at the Software Product Line Conference (SPLC) until 2017. The subset was randomly selected to cover all years as well as types of papers. We assessed the research type of the papers (academic or industry), the kind of evaluation (application example, empirical, etc.), and the application domain. Also, we assessed which product line life-cycle phases, development practices, and topics the papers address. We present an analysis of the topics covered by academic vs. industry research and discuss the evolution of these topics and their relation over the years. We also discuss implications for researchers and practitioners. We conclude that even though several topics have received more attention than others, academic and industry research on software product lines are actually rather in line with each other.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {14–24},
numpages = {11},
keywords = {software product lines, industry, academia, SPLC},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3307630.3342385,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {HADAS: Analysing Quality Attributes of Software Configurations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342385},
doi = {10.1145/3307630.3342385},
abstract = {Software Product Lines (SPLs) are highly configurable systems. Automatic analyses of SPLs rely on solvers to navigate complex dependencies among features and find legal solutions. Variability analysis tools are complex due to the diversity of products and domain-specific knowledge. On that, while there are experimental studies that analyse quality attributes, the knowledge is not easily accessible for developers, and its appliance is not trivial. Aiming to allow the industry to quality-explore SPL design spaces, we developed the HADAS assistant that: (1) models systems and collects quality attributes metrics in a cloud repository, and (2) reasons about it helping developers with quality attributes requirements.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {13–16},
numpages = {4},
keywords = {variability, software product line, numerical, model, attribute, NFQA},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3646548.3672582,
author = {Corti\~{n}as, Alejandro and Lamas, Victor and R. Luaces, Miguel},
title = {SensorPublisher: Applying Software Product Lines to the development of IoT dashboards},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672582},
doi = {10.1145/3646548.3672582},
abstract = {Geosciences have witnessed a revolution in data collection thanks to the Internet of Things (IoT), which has made it possible to monitor complex phenomena using sensor networks. However, developing web-centric, sensor-based, data warehousing information systems presents challenges because of their complexity and cost. This paper presents an intuitive low-code development system (called SensorPublisher), based on a software product line (SPL) and a domain-specific language (DSL), that speeds up the creation of data warehousing applications for geographic sensor data. SensorPublisher allows the geoscientist to define the sensor network, to generate a software product, and to deploy the product to a local or a remote server. Our tool seeks to encourage scientists to share the outcomes of their sensor data analysis projects with their communities by means of a simple, user-friendly and cost-effective approach. We showcase the system in different geoscientific domains, such as meteorological monitoring services, traffic data and air quality monitoring in urban areas, and marine area monitoring systems.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {153–163},
numpages = {11},
keywords = {Domain Specific Language (DSL), Internet of Things (IoT), Software Product Line (SPL)},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.1145/2934466.2934481,
author = {Sion, Laurens and Van Landuyt, Dimitri and Joosen, Wouter and de Jong, Gjalt},
title = {Systematic quality trade-off support in the software product-line configuration process},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934481},
doi = {10.1145/2934466.2934481},
abstract = {Software product line engineering is a compelling methodology that accomplishes systematic reuse in families of systems by relying on two key principles: (i) the decomposition of complex systems into composable and reusable building blocks (often logical units called features), and (ii) on-demand construction of products and product variants by composing these building blocks.However, unless the stakeholder responsible for product configuration has detailed knowledge of the technical ins and outs of the software product line (e.g., the architectural impact of a specific feature, or potential feature interactions), he is in many cases flying in the dark. Although many initial approaches and techniques have been proposed that take into account quality considerations and involve trade-off decisions during product configuration, no systematic support exists.In this paper, we present a reference architecture for product configuration tooling, providing support for (i) up-front generation of variants, and (ii) quality analysis of these variants. This allows pro-actively assessing and predicting architectural quality properties for each product variant and in turn, product configuration tools can take into account architectural considerations. In addition, we provide an in-depth discussion of techniques and tactics for dealing with the problem of variant explosion, and as such to maintain practical feasibility of such approaches.We validated and implemented our reference architecture in the context of a real-world industrial application, a product-line for the firmware of an automotive sensor. Our prototype, based on FeatureIDE, is open for extension and readily available.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {164–173},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3233027.3233050,
author = {Kuiter, Elias and Kr\"{u}ger, Jacob and Krieter, Sebastian and Leich, Thomas and Saake, Gunter},
title = {Getting rid of clone-and-own: moving to a software product line for temperature monitoring},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233050},
doi = {10.1145/3233027.3233050},
abstract = {Due to its fast and simple applicability, clone-and-own is widely used in industry to develop software variants. In cooperation with different companies for thermoelectric products, we implemented multiple variants of a heat monitoring tool based on clone-and-own. After encountering redundancy-related problems during development and maintenance, we decided to migrate towards a software product line. Within this paper, we describe this case study of migrating cloned variants to a software product line based on the extractive approach. The resulting software product line encapsulates variability on several levels, including the underlying hardware systems, interfaces, and use cases. Currently, we support monitoring hardware from three different companies that use the same core system and provide a configurable front-end. We share our experiences and encountered problems with cloning and migration towards a software product line---focusing on feature extraction and modeling in particular. Furthermore, we provide a lightweight, web-based tool for modeling, configuring, and implementing software product lines, which we use to migrate and manage features. Besides this experience report, we contribute most of the created artifacts as open-source and freely available for the research community.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {179–189},
numpages = {11},
keywords = {software product line, feature modeling, extraction, case study},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3579027.3608994,
author = {Fadhlillah, Hafiyyan Sayyid and Fern\'{a}ndez, Antonio M. Guti\'{e}rrez and Rabiser, Rick and Zoitl, Alois},
title = {Managing Cyber-Physical Production Systems Variability using V4rdiac: Industrial Experiences},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608994},
doi = {10.1145/3579027.3608994},
abstract = {Cyber-Physical Production Systems (CPPSs) are highly robust and versatile production systems that utilize diverse hardware components through control software. Employing a systematic variability management approach for developing variants of control software can reduce cost and time-to-market to build such complex systems. However, employing this approach in the CPPS domain is challenging. Engineering CPPSs require multidisciplinary engineering knowledge (e.g., process, signal, mechanical). Knowledge about CPPS variability is thus typically scattered across diverse engineering artifacts. Also, variability knowledge is usually not documented explicitly but rather tacit knowledge of mostly senior engineers. Furthermore, control software is commonly implemented using a graphical Domain-Specific Modeling Language (DSML) which only provides minimal support to express variability. This paper describes our experiences dealing with these challenges in an industrial context using a multidisciplinary variability management approach called Variability for 4diac (V4rdiac). V4rdiac is an integrated approach that allows CPPS engineers to conduct stepwise product configuration based on heterogeneous variability models from multiple engineering disciplines. V4rdiac also provides a mechanism to automatically generate control software based on a set of selected configuration options. We evaluate how V4rdiac implements and manages CPPS control software variants in the metallurgical production plant domain. We describe the benefits and lessons learned from using V4rdiac in this domain based on feedback from industrial practitioners.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {223–233},
numpages = {11},
keywords = {Variability Modeling, Software Product Line, Software Configuration, Cyber-Physical Production System},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/2362536.2362557,
author = {Elsner, Christoph},
title = {Light-weight tool support for staged product derivation},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362557},
doi = {10.1145/2362536.2362557},
abstract = {Tool support that checks for configuration errors and generates product parts from configurations can significantly improve on product derivation in product line engineering. Up to now, however, derivation tools commonly disregard the staged derivation process. They do not restrict configuration consistency checks to process entities such as configuration stages, stakeholders, or build tasks. As a result, constraints that are only valid for certain process entities must either be checked permanently, leading to false positive errors, or one must refrain from defining them at all.This paper contributes a light-weight approach to provide tailored tool support for staged product derivation. Compared to previous approaches, it is not tied to a single configuration mechanism (e.g., feature modeling), and also accounts for the stakeholders involved and the build tasks that generate product parts. First, the product line engineer describes the derivation process in a concise model. Then, based on constraint checks on the configuration (e.g., a feature model configuration) that are linked to the modeled entities, comprehensive tool support can be provided: Configuration actions can be guided and restricted depending on the configuring stakeholder in a fine-grained manner, and constraints attached to a build task will only be checked if it actually shall be executed. Finally, in combination with previous work, the paper provides evidence that the approach is applicable to legacy product lines in a light-weight manner and that it technically scales to thousands of constraint checks.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {146–155},
numpages = {10},
keywords = {tool support, staged product derivation, product line},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2019136.2019182,
author = {McGregor, John D. and Monteith, J. Yates and Zhang, Jie},
title = {Quantifying value in software product line design},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019182},
doi = {10.1145/2019136.2019182},
abstract = {A software product line is a strategic investment for an organization. Besides the initial decision to use a product line approach other strategic decisions are made, including which variations to accommodate. In this paper we present an adaptation of an equation for computing option values. The equation can be used to understand the economic impact of adding a variation point to the product line architecture. The equation was exercised on multiple sets of hypothetical data and and produced the expected changes from one data set to another. In the future the equation will be validated with data from real projects. We describe some practical sources of values for the parameters of the equation.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {40},
numpages = {7},
keywords = {strategic software design, software engineering},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2892664.2892686,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Towards the dynamic reconfiguration of quality attributes},
year = {2016},
isbn = {9781450340335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2892664.2892686},
doi = {10.1145/2892664.2892686},
abstract = {There are some Quality Attributes (QAs) whose variability is addressed through functional variability in the software architecture. Separately modelling the variability of these QAs from the variability of the base functionality of the application has many advantages (e.g., a better reusability), and facilitates the reconfiguration of the QA variants at runtime. Many factors may vary the QA functionality: variations in the user preferences and usage needs; variations in the non-functional QAs; variations in resources, hardware, or even in the functionality of the base application, that directly affect the product's QAs. In this paper, we aim to elicit the relationships and dependencies between the functionalities required to satisfy the QAs and all those factors that can provoke a reconfiguration of the software architecture at runtime. We follow an approach in which the variability of the QAs is modelled separately from the base application functionality, and propose a dynamic approach to reconfigure the software architecture based on those reconfiguration criteria.},
booktitle = {Companion Proceedings of the 15th International Conference on Modularity},
pages = {131–136},
numpages = {6},
keywords = {variability, software architecture, reconfiguration, SPL, Quality attributes},
location = {M\'{a}laga, Spain},
series = {MODULARITY Companion 2016}
}

@inproceedings{10.1145/2491627.2491649,
author = {Lanman, Jeremy and Darbin, Rowland and Rivera, Jorge and Clements, Paul and Krueger, Charles},
title = {The challenges of applying service orientation to the U.S. Army's live training software product line},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491649},
doi = {10.1145/2491627.2491649},
abstract = {Live Training Transformation (LT2) is the product line strategy put in place by the United States Army Program Executive Office for Simulation, Training and Instrumentation (PEO STRI). The purpose of the LT2 product line is to provide a common set of core assets including architectures, software components, standards and processes that form the basis of all Army Live Training systems. As products consuming LT2 core assets evolve to meet the latest requirements of the military live training community, changes to the core product line architecture must also be made. Based on thorough analysis of the LT2 core capabilities and user trends toward web-enabled and mobile computing technologies, a Service Oriented Architecture (SOA) strategy was identified and adopted as the objective architecture for the evolving LT2 product line. Future success of the LT2 product line now depends on the alignment of product line engineering concepts with the business and technical benefits of SOA, and to ensure that systematic reuse continues to provide substantial return-on-investment for the Army. This paper addresses the challenges of adopting SOA into an existing software product line, the unique circumstances of the LT2 SOA environment, and present a set of analysis and design considerations for the product line engineering community.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {244–253},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product derivation, product configurator, product baselines, product audit, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3646548.3672595,
author = {Bounouas, Nassim and Blay-Fornarino, Mireille and Collet, Philippe},
title = {Tracing and Fixing Inconsistencies in Clone-and-Own Tabular Data Models},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672595},
doi = {10.1145/3646548.3672595},
abstract = {Many data-intensive applications handle tabular data with more advanced structuring and processes than spreadsheets, enabling end-users to copy and adapt tabular data and processes to create new templates or datasets anytime. Recent research advances demonstrated that, in such clone-and-own scenarios, actions performed on the data structure, together with cloning and adaptation actions, can be captured within an operation-based model to prevent the drift of the internal tabular data model. However, this approach is limited by the assumption that each operation must maintain consistency regarding dependencies generated by the domain-specific languages that connect the observed and computed data. To address this challenge, this paper first introduces an evolved operation-based model that is designed to capture inconsistent tabular data while keeping a fine-grained trace of what part of the model is inconsistent. We then define specific trace operations to either fix a dependency in a model or remove one if its creating process is no longer relevant to the user. These operations support high-level editing scenarios on the tabular data, which enables easily fixing the equivalent of a spreadsheet formula or a process statement, or making the user aware that some part of the model is inconsistent while it is cloned. Additionally, we report on a positive scalability experiment on the tracing of large tabular data models with inconsistencies.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {191–202},
numpages = {12},
keywords = {Tabular data, agronomy, clone-and-own, model-driven engineering, operation-based modeling, variability management},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.5555/1753235.1753250,
author = {Jepsen, Hans Peter and Beuche, Danilo},
title = {Running a software product line: standing still is going backwards},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Danfoss Drives - one of the largest producers of frequency converters in the world - has been doing Software Product Line development for its frequency converter products for about 3 years. This paper describes the approach used and the experiences with it. It discusses processes, ways to convince the unconvinced and arising tool issues when doing product line development.This paper is a follow-up on a previous article which described the product line migration process in detail.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {101–110},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3368089.3409675,
author = {Siegmund, Norbert and Ruckel, Nicolai and Siegmund, Janet},
title = {Dimensions of software configuration: on the configuration context in modern software development},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409675},
doi = {10.1145/3368089.3409675},
abstract = {With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure. This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined. However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings, translate them to practice, and to generalize the results. Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {338–349},
numpages = {12},
keywords = {variability, developer study, configuration management and life cycle, Dimensions of software configuration},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3503229.3547026,
author = {Friesel, Birte and Elmenhorst, Kathrin and Kaiser, Lennart and M\"{u}ller, Michael and Spinczyk, Olaf},
title = {kconfig-webconf: retrofitting performance models onto kconfig-based software product lines},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547026},
doi = {10.1145/3503229.3547026},
abstract = {Despite decades of research and clear advantages, performance-aware configuration of real-world software product lines is still an exception rather than the norm. One reason for this may be tooling: configuration software with support for non-functional property models is generally not compatible with the configuration and build process of existing product lines. Specifically, the Kconfig language is popular in open source software projects, but neither language nor configuration frontends support performance models. To address this, we present kconfig-webconf: a performance-aware, Kconfig-compatible software product line configuration frontend. It is part of a toolchain that can automatically generate performance models with a minimal amount of changes to a software product line's build process. With such a performance model, kconfig-webconf can serve as a performance-aware drop-in replacement for existing Kconfig frontends. We evaluate its usage in five examples, including the busybox multi-call binary and the resKIL agricultural AI product line.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {58–61},
numpages = {4},
keywords = {kconfig, performance prediction, product lines, regression trees},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.5555/2525401.2525415,
author = {Tan, Lei and Lin, Yuqing and Ye, Huilin and Zhang, Guoheng},
title = {Improving product configuration in software product line engineering},
year = {2013},
isbn = {9781921770203},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Software Product Line Engineering (SPLE) is a emerging software reuse paradigm. SPLE focuses on systematic software reuse from requirement engineering to product derivation throughout the software development life-cycle. Feature model is one of the most important reusable assets which represents all design considerations of a software product line. Feature model will be used in the product configuration process to produce a software. The product configuration is a decision-making process, where all kinds of relationships among configurable features will be considered to select the desired features for the product. To improve the efficiency and quality of product configuration, we are proposing a new approach which aims at identifying a small set of key features. The product configuration should always start from this set of features since, based on the feature dependencies, the decisions made on these features will imply decisions on the rest of the features of the product line, thus reduce the features visited in the configuration process. We have also conducted some experiments to demonstrate how the proposed approach works and evaluate the efficiency of the approach.},
booktitle = {Proceedings of the Thirty-Sixth Australasian Computer Science Conference - Volume 135},
pages = {125–133},
numpages = {9},
keywords = {software product line, product configuration, minimum vertex cover, feature model},
location = {Adelaide, Australia},
series = {ACSC '13}
}

@inproceedings{10.1145/3579028.3609008,
author = {Galindo, Jos\'{e} A. and Horcas, Jose-Miguel and Felferning, Alexander and Fernandez-Amoros, David and Benavides, David},
title = {FLAMA: A collaborative effort to build a new framework for the automated analysis of feature models},
year = {2023},
isbn = {9798400700927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579028.3609008},
doi = {10.1145/3579028.3609008},
abstract = {Nowadays, feature models are the de facto standard when representing commonalities and variability, with modern examples spanning up to 7000 features. Manual analysis of such models is challenging and error-prone due to sheer size. To help in this task, automated analysis of feature models (AAFM) has emerged over the past three decades. However, the diversity of these tools and their supported languages presents a significant challenge that motivated the MOD-EVAR community to initiate a project for a new tool that supports the UVL language. Despite the rise of machine learning and data science, along with robust Python-based libraries, most AAFM tools have been implemented in Java, creating a collaboration gap. This paper introduces Flama, an innovative framework that automates the analysis of variability models. It focuses on UVL model analysis and aims for easy integration and extensibility to bridge this gap and foster better community and cross-community collaboration.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume B},
pages = {16–19},
numpages = {4},
keywords = {visualization design process, variability, software product line, graphs and tables, effective communication, data visualization},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1109/ICSE.2019.00112,
author = {Kaltenecker, Christian and Grebhahn, Alexander and Siegmund, Norbert and Guo, Jianmei and Apel, Sven},
title = {Distance-based sampling of software configuration spaces},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00112},
doi = {10.1109/ICSE.2019.00112},
abstract = {Configurable software systems provide a multitude of configuration options to adjust and optimize their functional and non-functional properties. For instance, to find the fastest configuration for a given setting, a brute-force strategy measures the performance of all configurations, which is typically intractable. Addressing this challenge, state-of-the-art strategies rely on machine learning, analyzing only a few configurations (i.e., a sample set) to predict the performance of other configurations. However, to obtain accurate performance predictions, a representative sample set of configurations is required. Addressing this task, different sampling strategies have been proposed, which come with different advantages (e.g., covering the configuration space systematically) and disadvantages (e.g., the need to enumerate all configurations). In our experiments, we found that most sampling strategies do not achieve a good coverage of the configuration space with respect to covering relevant performance values. That is, they miss important configurations with distinct performance behavior. Based on this observation, we devise a new sampling strategy, called distance-based sampling, that is based on a distance metric and a probability distribution to spread the configurations of the sample set according to a given probability distribution across the configuration space. This way, we cover different kinds of interactions among configuration options in the sample set. To demonstrate the merits of distance-based sampling, we compare it to state-of-the-art sampling strategies, such as t-wise sampling, on 10 real-world configurable software systems. Our results show that distance-based sampling leads to more accurate performance models for medium to large sample sets.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {1084–1094},
numpages = {11},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3646548.3672585,
author = {Landsberg, Tobias and Dietrich, Christian and Lohmann, Daniel},
title = {Should I Bother? Fast Patch Filtering for Statically-Configured Software Variants},
year = {2024},
isbn = {9798400705939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646548.3672585},
doi = {10.1145/3646548.3672585},
abstract = {In the face of critical security vulnerabilities, patch and update management are a crucial and challenging part of the software life cycle. In software product families, patching becomes even more challenging as we have to support different variants, which are not equally affected by critical patches. While the naive “better-patched-than-sorry” approach will apply all necessary updates, it provokes avoidable costs for developers and customers. In this paper we introduce SiB (Should I Bother?), a heuristic patch-filtering method for statically-configurable software that efficiently identifies irrelevant patches for specific variants. To solve the variability-aware patch-filtering problem, SiB compares modified line ranges from patches with those source-code ranges included in variants currently deployed. We apply our prototype for CPP-managed variability to four open-source projects (Linux, OpenSSL, SQLite, Bochs), demonstrating that SiB is both effective and efficient in reducing the number of to-be-considered patches for unaffected software variants. It correctly classifies up to 68 percent of variants as unaffected, with a recall of 100 percent, thus reducing deployments significantly, without missing any relevant patches.},
booktitle = {Proceedings of the 28th ACM International Systems and Software Product Line Conference},
pages = {12–23},
numpages = {12},
keywords = {Patch Filtering, Software Evolution, Software Product Lines},
location = {Dommeldange, Luxembourg},
series = {SPLC '24}
}

@inproceedings{10.1145/1808937.1808938,
author = {Hanssen, Geir Kjetil},
title = {Opening up software product line engineering},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808938},
doi = {10.1145/1808937.1808938},
abstract = {The software industry is experiencing a shift towards more open processes, a globalized market and more active and engaged customers and end users. This change seems natural and inevitable, imposing necessary changes in how software product line organizations plan and drive the development of their products. This paper gives insight into some recent developments in a product line organization and discusses how their efforts have helped them in improving their development processes and their product line. Based on this experience, this paper provides some preliminary guidelines to both industry and research, indicating that software product line organizations should exploit open innovation, engage customers, build communities and simplify processes and organization.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {1–7},
numpages = {7},
keywords = {software product line engineering, open processes},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@inproceedings{10.1145/3267183.3267188,
author = {Barbosa, Jefferson and Andrade, Rossana M. C. and Filho, Jo\~{a}o Bosco F. and Bezerra, Carla I. M. and Barreto, Isaac and Capilla, Rafael},
title = {Cloning in Customization Classes: A Case of a Worldwide Software Product Line},
year = {2018},
isbn = {9781450365543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267183.3267188},
doi = {10.1145/3267183.3267188},
abstract = {Cloning-and-owning, in the long run, can severely affect evolution, as changes in cloned fragments may require modifications in various parts of the system. This problem scales if cloning is used in classes that derive products in a Software Product Line, because these classes can impact in several features and products. However, it is hard to know to which extent cloning in customization classes can impact in a project. We conduct a study, within an SPL that generates mobile software for over 150 countries, to analyze cloning practices and how cloned parts relate to the maintainability of customization classes. We collect and identify clones inside customization classes during a period of 13 months, involving 70 customization classes and 5 branches. In parallel, we collect the respective issues from the issue tracking tool of the SPL project, obtaining over 140 issues related to customization classes. We then confront the time spent to solve each issue with its nature (i.e., if it relates to cloned code or not). As first result, we verify that issues related to cloning take in average 136% more time to be solved. Our study helps to understand how cloning relates to maintainability in the context of mass customization, giving insights about cloned code evolution and its impacts in a software product line project.},
booktitle = {Proceedings of the VII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {43–52},
numpages = {10},
keywords = {Software Product Line, Customization, Clone},
location = {Sao Carlos, Brazil},
series = {SBCARS '18}
}

@inproceedings{10.1145/2593882.2593888,
author = {Metzger, Andreas and Pohl, Klaus},
title = {Software product line engineering and variability management: achievements and challenges},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593888},
doi = {10.1145/2593882.2593888},
abstract = {Software product line engineering has proven to empower organizations to develop a diversity of similar software-intensive systems (applications) at lower cost, in shorter time, and with higher quality when compared with the development of single systems. Over the last decade the software product line engineering research community has grown significantly. It has produced impressive research results both in terms of quality as well as quantity. We identified over 600 relevant research and experience papers published within the last seven years in established conferences and journals. We briefly summarize the major research achievements of these past seven years. We structure this research summary along a standardized software product line framework. Further, we outline current and future research challenges anticipated from major trends in software engineering and technology.},
booktitle = {Future of Software Engineering Proceedings},
pages = {70–84},
numpages = {15},
keywords = {variability modeling, variability management, requirements engineering, quality assurance, design, Software product lines},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@inproceedings{10.1145/1842752.1842773,
author = {McGregor, John D.},
title = {A method for analyzing software product line ecosystems},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842773},
doi = {10.1145/1842752.1842773},
abstract = {The ecosystem for a software product line includes all of the entities with which the software product line organization interacts. Information, artifacts, customers, money and products move among these entities as a part of the planning, development, and deployment processes. In this paper we present an analysis technique that uses the economic notion of a transaction to examine the transfers between the entities. The result of the analysis is data that is used to evaluate and structure the organization. We illustrate with an example.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {73–80},
numpages = {8},
keywords = {software product line, software ecosystem},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/3382025.3414953,
author = {Abbas, Muhammad and Jongeling, Robbert and Lindskog, Claes and Enoiu, Eduard Paul and Saadatmand, Mehrdad and Sundmark, Daniel},
title = {Product line adoption in industry: an experience report from the railway domain},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414953},
doi = {10.1145/3382025.3414953},
abstract = {The software system controlling a train is typically deployed on various hardware architectures and must process various signals across those deployments. The increase of such customization scenarios and the needed adherence of the software to various safety standards in different application domains has led to the adoption of product line engineering within the railway domain. This paper explores the current state-of-practice of software product line development within a team developing industrial embedded software for a train propulsion control system. Evidence is collected using a focus group session with several engineers and through inspection of archival data. We report several benefits and challenges experienced during product line adoption and deployment. Furthermore, we identify and discuss improvement opportunities, focusing mainly on product line evolution and test automation.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {3},
numpages = {11},
keywords = {software product-line engineering, overloaded assets, challenges and opportunities},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {software variability, software testing, software product line, quality assurance, machine learning},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3579027.3608991,
author = {Bounouas, Nassim and Blay-Fornarino, Mireille and Collet, Philippe},
title = {An Action-based Model to Handle Cloning and Adaptation in Tabular Data Applications},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608991},
doi = {10.1145/3579027.3608991},
abstract = {Many software systems require diverse data gathering and handling through processes that manipulate tabular data, often with a spreadsheet orientation. Variability in tabular data cannot be captured in a complete up-front analysis as everything is done at the final user level. She progressively adapts or clones some tabular data organized to conduct a process. Consequently these organized data are constantly both a final usable product and a potential candidate for cloning. This huge diversity, the high frequency of their evolution over time, and the intrinsic need to use cloning lead naturally to the usage of a clone-and-own approach with well-known negative impacts on maintenance and quality. In this paper we advocate that this can be replaced by controlling the clone-and-own process with provenance information that completely captures, at the domain level, the cloning actions and the adaptations applied on a product defining its clones. Each action over the process, its observations, and its data are captured in a complete model through traces of atomic adaptations, complemented with specific derivation and extraction actions. This model enables obtaining the whole history of both data and processes over time, as well as the accountability of variability-related actions. We report on a study showing the relevance of tackled problem in a variability-rich agronomy software of an industrial partner. We also show that a first prototype covers the extracted usage scenarios, from simple and entire cloning to more complex partial cloning.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {201–212},
numpages = {12},
keywords = {variability management, operation-based modeling, model-driven engineering, clone-and-own, agronomy, Tabular data},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/2554850.2554987,
author = {Parra, Carlos and Joya, Diego and Giral, Leonardo and Infante, Alvaro},
title = {An SOA approach for automating software product line adoption},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554987},
doi = {10.1145/2554850.2554987},
abstract = {Nowadays, the software industry is faced with challenges regarding complexity, time to market, quality standards and evolution. To face those challenges, two strategies that are gaining interest both in academy and industry are Service Oriented Architecture (SOA) and Software Product Lines (SPL). While SOA aims at building applications from an orchestration of services, SPL consists in building a set of core-assets and a derivation strategy based on such assets. Adopting such approaches involves important challenges with regard to existing software artifacts that must be transformed in order to respect an architecture that focus on modularity and reuse. This paper presents an industrial experience of such transformation. We propose a non-intrusive reverse engineering process for the development of modular services obtained automatically from existing software artifacts, and a variability-driven derivation process to assembly products out of such services. To validate our approach, we have implemented the reverse engineering and derivation processes using real software JEE artifacts from a component framework of reusable functionalities in several different enterprise applications. The results show important benefits in terms of the development time and flexibility.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1231–1238},
numpages = {8},
keywords = {software product lines, service oriented architecture, reverse engineering, model-driven engineering},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.5555/2666064.2666075,
author = {Fant, Julie Street and Gomaa, Hassan and Pettit, Robert G.},
title = {Software product line engineering of space flight software},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {This paper presents a practical solution to a real-life industrial problem in the unmanned space flight software (FSW) domain using software product lines and software architectural design patterns. In the FSW domain, there exists a significant amount of variability in the required capabilities. For example, some FSW have a significant amount of hardware to control and operate in a nearly autonomous fashion. In contrast, other FSW have a small amount of hardware to control and rely heavily of commanding from the ground station to operate the spacecraft. The underlying architecture and component interactions needed for the different FSWs are quite different. This amount of architectural variability makes it difficult to develop a SPL architecture that covers the all possible variability in the FSW domain. Therefore, this paper presents a practical solution to this real world problem that leverages software product line concepts and software architectural design patterns.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {41–44},
numpages = {4},
keywords = {unmanned space flight software, software product lines, software architectural design patterns, UML},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1145/3183399.3183403,
author = {Xu, Tianyin and Marinov, Darko},
title = {Mining container image repositories for software configuration and beyond},
year = {2018},
isbn = {9781450356626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183399.3183403},
doi = {10.1145/3183399.3183403},
abstract = {This paper introduces the idea of mining container image repositories for configuration and other deployment information of software systems. Unlike traditional software repositories (e.g., source code repositories and app stores), image repositories encapsulate the entire execution ecosystem for running target software, including its configurations, dependent libraries and components, and OS-level utilities, which contributes to a wealth of data and information. We showcase the opportunities based on concrete software engineering tasks that can benefit from mining image repositories. To facilitate future mining efforts, we summarize the challenges of analyzing image repositories and the approaches that can address these challenges. We hope that this paper will stimulate exciting research agenda of mining this emerging type of software repositories.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {49–52},
numpages = {4},
keywords = {software repository, image, docker, container, configuration},
location = {Gothenburg, Sweden},
series = {ICSE-NIER '18}
}

@inproceedings{10.1145/1868688.1868691,
author = {Torres, M\'{a}rio and Kulesza, Uir\'{a} and Sousa, Matheus and Batista, Thais and Teixeira, Leopoldo and Borba, Paulo and Cirilo, Elder and Lucena, Carlos and Braga, Rosana and Masiero, Paulo},
title = {Assessment of product derivation tools in the evolution of software product lines: an empirical study},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868691},
doi = {10.1145/1868688.1868691},
abstract = {Product derivation approaches automate the customization process of software product lines. Over the last years, many tools have been proposed aiming at synthesize and generate products from a set of reusable assets. These tools adopt different techniques and strategies to implement and automate the product derivation activities. In this paper, we analyzed six modern product derivation tools (Captor, CIDE, GenArch, MSVCM, pure::variants, XVCL) in the context of evolution scenarios of a software product line. Our study has adopted several metrics to analyze the modularity, complexity and stability of product derivation artifacts related to configuration knowledge along different releases of a mobile product line. The preliminary results of our study have shown that approaches with a dedicated model or file to represent the CK specification can bring several benefits to the modularization and stability of a software product line.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {10–17},
numpages = {8},
keywords = {product derivation tools, measurement},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/3546932.3547014,
author = {Tavassoli, Shaghayegh and Damasceno, Carlos Diego N. and Mousavi, Mohammad Reza and Khosravi, Ramtin},
title = {A benchmark for active learning of variability-intensive systems},
year = {2022},
isbn = {9781450394437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546932.3547014},
doi = {10.1145/3546932.3547014},
abstract = {Behavioral models are the key enablers for behavioral analysis of Software Product Lines (SPL), including testing and model checking. Active model learning comes to the rescue when family behavioral models are non-existent or outdated. A key challenge on active model learning is to detect commonalities and variability efficiently and combine them into concise family models. Benchmarks and their associated metrics will play a key role in shaping the research agenda in this promising field and provide an effective means for comparing and identifying relative strengths and weaknesses in the forthcoming techniques. In this challenge, we seek benchmarks to evaluate the efficiency (e.g., learning time and memory footprint) and effectiveness (e.g., conciseness and accuracy of family models) of active model learning methods in the software product line context. These benchmark sets must contain the structural and behavioral variability models of at least one SPL. Each SPL in a benchmark must contain products that requires more than one round of model learning with respect to the basic active learning L* algorithm. Alternatively, tools supporting the synthesis of artificial benchmark models are also welcome.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A},
pages = {245–249},
numpages = {5},
keywords = {model learning, featured finite state machines, benchmarking, behavioral variability},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3579027.3608985,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Greiner, Sandra and Moosherr, Benjamin and Krieter, Sebastian and Tinnes, Christof and Kehrer, Timo and Th\"{u}m, Thomas},
title = {Views on Edits to Variational Software},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608985},
doi = {10.1145/3579027.3608985},
abstract = {Software systems are subject to frequent changes, for example to fix bugs or meet new customer requirements. In variational software systems, developers are confronted with the complexity of evolution and configurability on a daily basis; essentially handling changes to many distinct software variants simultaneously. To reduce the complexity of configurability for developers, filtered or projectional editing was introduced: By providing a partial or complete configuration, developers can interact with a simpler view of the variational system that shows only artifacts belonging to that configuration. Yet, such views are available for individual revisions only but not for edits performed across revisions. To reduce the complexity of evolution in variational software for developers, we extend the concept of views to edits. We formulate a correctness criterion for views on edits and introduce two correct operators for view generation, one operator suitable for formal reasoning, and a runtime optimized operator. In an empirical study, we demonstrate the feasibility of our operators by applying them to the change histories of 44 open-source software systems.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {141–152},
numpages = {12},
keywords = {variation control, software variability, software product lines, software evolution, projectional editing},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3579027.3608984,
author = {Krieter, Sebastian and Kr\"{u}ger, Jacob and Leich, Thomas and Saake, Gunter},
title = {VariantInc: Automatically Pruning and Integrating Versioned Software Variants},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608984},
doi = {10.1145/3579027.3608984},
abstract = {Developers use version-control systems and software-hosting platforms to manage their software systems. They rely on the provided branching and forking mechanisms to implement new features, fix bugs, and develop customized system variants. A particular problem arises when forked variants are not re-integrated (i.e., merged), but kept and co-evolved as individual systems. This can cause maintenance overheads, due to change propagation and limitations in simultaneously managing variations in space (variants) and time (revisions). Thus, most organizations decide to integrate their set of variants into a single platform at some point, and several techniques have been proposed to semi-automate such an integration. However, existing techniques usually consider only a single revision of each variant and do not merge the revision histories, disregarding that not only variants (i.e., configuring the features of the system) but also revisions (i.e., checking out specific versions of the features) are important. We propose an automated technique, VariantInc, for analyzing, pruning, and integrating variants of a system that also merges the revision history of each variant into the resulting platform (i.e., using presence conditions). To validate VariantInc, we employed it on 160 open-source C systems of various sizes (i.e., number of forks, revisions, source code). The results show that VariantInc works as intended, and allows developers or researchers to automatically integrate variants into a platform as well as to perform software analyses.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {129–140},
numpages = {12},
keywords = {Version control, Variant-rich systems, Variant integration, Forks},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/1383559.1383571,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Towards automatic derivation of a product performance model from a UML software product line model},
year = {2008},
isbn = {9781595938732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1383559.1383571},
doi = {10.1145/1383559.1383571},
abstract = {Software Product Line (SPL) engineering is a software development approach that takes advantage of the commonality and variability between products from a family, and supports the generation of specific products by reusing a set of core family assets. This paper proposes a UML model transformation approach for software product lines to derive a performance model for a specific product. The input to the proposed technique, the "source model", is a UML model of a SPL with performance annotations, which uses two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The source model is generic and therefore its performance annotations must be parameterized. The proposed derivation of a performance model for a concrete product requires two steps: a) the transformation of a SPL model to a UML model with performance annotations for a given product, and b) the transformation of the outcome of the first step into a performance model. This paper focuses on the first step, whereas the second step will use the PUMA transformation approach of annotated UML models to performance models, developed in previous work. The output of the first step, named "target model", is a UML model with MARTE annotations, where the variability expressed in the SPL model has been analyzed and bound to a specific product, and the generic performance annotations have been bound to concrete values for the product. The proposed technique is illustrated with an e-commerce case study.},
booktitle = {Proceedings of the 7th International Workshop on Software and Performance},
pages = {91–102},
numpages = {12},
keywords = {uml, software product line, software performance engineering, model transformation, marte},
location = {Princeton, NJ, USA},
series = {WOSP '08}
}

@inproceedings{10.1145/3336294.3336316,
author = {Tolvanen, Juha-Pekka and Kelly, Steven},
title = {How Domain-Specific Modeling Languages Address Variability in Product Line Development: Investigation of 23 Cases},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336316},
doi = {10.1145/3336294.3336316},
abstract = {Domain-Specific Modeling raises the level of abstraction beyond programming by specifying the solution directly with domain concepts. Within product lines domain-specific approaches are applied to specify variability and then generate final products together with commonality. Such automated product derivation is possible because both the modeling language and generator are made for a particular product line --- often inside a single company. In this paper we examine which kinds of reuse and product line approaches are applied in industry with domain-specific modeling. Our work is based on empirical analysis of 23 cases and the languages and models created there. The analysis reveals a wide variety and some commonalities in the size of languages and in the ways they apply reuse and product line approaches.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {155–163},
numpages = {9},
keywords = {product line variability, product derivation, domain-specific modeling, domain-specific language, code generation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/1629716.1629724,
author = {Elsner, Christoph and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Product derivation for solution-driven product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629724},
doi = {10.1145/1629716.1629724},
abstract = {Solution-driven product line engineering is a project business where products are created for each customer individually. Although reuse of results from former projects is widely done, configuration and integration of the results currently is often a manual, time-consuming, and error-prone task and needs considerable knowledge about implementation details.In this paper, we elaborate and approach the challenges when giving automated support for product derivation (i.e., product configuration and generation) in a large-scale solution-driven product line context. Our PLiC approach resembles the fact that, in practice, the domain of a large product line is divided into sub-domains. A PLiC (product line component) packages all results (configuration, generation, and implementation assets) of a sub-domain and offers interfaces for configuration and generation. With our approach we tackle the challenges of using multiple and different types of configuration models and text files, give support for automated product generation, and integrate feature modeling to support application engineering as an extensive development task.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {35–41},
numpages = {7},
keywords = {feature modeling, software product line development, solution-driven software development},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1145/3461001.3471149,
author = {Lesoil, Luc and Acher, Mathieu and T\'{e}rnava, Xhevahire and Blouin, Arnaud and J\'{e}z\'{e}quel, Jean-Marc},
title = {The interplay of compile-time and run-time options for performance prediction},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471149},
doi = {10.1145/3461001.3471149},
abstract = {Many software projects are configurable through compile-time options (e.g., using ./configure) and also through run-time options (e.g., command-line parameters, fed to the software at execution time). Several works have shown how to predict the effect of run-time options on performance. However it is yet to be studied how these prediction models behave when the software is built with different compile-time options. For instance, is the best run-time configuration always the best w.r.t. the chosen compilation options? In this paper, we investigate the effect of compile-time options on the performance distributions of 4 software systems. There are cases where the compiler layer effect is linear which is an opportunity to generalize performance models or to tune and measure runtime performance at lower cost. We also prove there can exist an interplay by exhibiting a case where compile-time options significantly alter the performance distributions of a configurable system.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {100–111},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1145/1640162.1640164,
author = {Catal, Cagatay},
title = {Barriers to the adoption of software product line engineering},
year = {2009},
issue_date = {November 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1640162.1640164},
doi = {10.1145/1640162.1640164},
abstract = {Software development costs and time to deploy a software-intensive system significantly decrease when Software Product Line Engineering (SPLE) approach is applied. Numerous case stu-dies in industrial and military domains have shown that reliability, quality, productivity and user interface consistency improve drasti-cally in addition to the decrease of cost and time-to-market. Also, this system engineering approach is very effective in three market strategies known as cost leadership, differentiation, and focusing. Despite these measurable benefits, product line engineering adop-tion is slower than the other technological trends such as Service Oriented Architecture (SOA), Model Driven Development (MDD), and Aspect Oriented Software Development (AOSD). In this pa-per, we investigate the barriers to the adoption of SPLE and ex-plore the root causes of them from three points of views: Project sponsor, organization, and SPLE community. We provide sugges-tions for how the industry and SPLE community can solve these multi-dimensional issues in a short term.},
journal = {SIGSOFT Softw. Eng. Notes},
month = dec,
pages = {1–4},
numpages = {4},
keywords = {variability, software reuse, software product lines, product families, core asset development, commonality}
}

@inproceedings{10.1145/3382025.3414955,
author = {Ananieva, Sofia and Greiner, Sandra and K\"{u}hn, Thomas and Kr\"{u}ger, Jacob and Linsbauer, Lukas and Gr\"{u}ner, Sten and Kehrer, Timo and Klare, Heiko and Koziolek, Anne and L\"{o}nn, Henrik and Krieter, Sebastian and Seidl, Christoph and Ramesh, S. and Reussner, Ralf and Westfechtel, Bernhard},
title = {A conceptual model for unifying variability in space and time},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414955},
doi = {10.1145/3382025.3414955},
abstract = {Software engineering faces the challenge of developing and maintaining systems that are highly variable in space (concurrent variations of the system at a single point in time) and time (sequential variations of the system due to its evolution). Recent research aims to address this need by managing variability in space and time simultaneously. However, such research often relies on nonuniform terminologies and a varying understanding of concepts, as it originates from different communities: software product-line engineering and software configuration management. These issues complicate the communication and comprehension of the concepts involved, impeding the development of techniques to unify variability in space and time. To tackle this problem, we performed an iterative, expert-driven analysis of existing tools to derive the first conceptual model that integrates and unifies terminologies and concepts of both dimensions of variability. In this paper, we present the unification process of concepts for variability in space and time, and the resulting conceptual model itself. We show that the conceptual model achieves high coverage and that its concepts are of appropriate granularity with respect to the tools for managing variability in space, time, or both that we considered. The conceptual model provides a well-defined, uniform terminology that empowers researchers and developers to compare their work, clarifies communication, and prevents redundant developments.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {15},
numpages = {12},
keywords = {version control, variability, revision management, product lines},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1145/2853073.2853082,
author = {Soujanya, K. L.S. and AnandaRao, A.},
title = {A Generic Framework for Configuration Management of SPL and Controlling Evolution of Complex Software Products},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853082},
doi = {10.1145/2853073.2853082},
abstract = {Efficient configuration management system is crucial for the success of any software product line (SPL). Due to ever changing needs of customers, SPL undergoes constant changes that are to be tracked in real time. In the context of customer-driven development, anticipation and change management are to be given paramount importance. It demands implementation of software variability that drives home changed, extended and customized configurations besides economy at scale. Moreover, the emergence of distributed technologies, the unprecedented growth of component based, serviceoriented systems throw ever increasing challenges to software product line configuration management. Derivation of a new product is a dynamic process in software product line that should consider functionality and quality attributes. Very few approaches are found on configuration management (CM) of SPL though CM is enough matured for traditional products. They are tailor made and inadequate to provide a general solution. Stated differently, a comprehensive approach for SPL configuration management and product derivation is still to be desired. In this paper, we proposed a framework that guides in doing so besides helping in SPL definitions in generic way. Our framework facilitates SPL configuration management and product derivation based on critical path analysis, weight computation and feedback. We proposed two algorithms namely Quality Driven Product Derivation (QDPD) and Composition Analysis algorithm for generating satisfied compositions and to find best possible composition respectively. The usage of weights and critical path analysis improves quality of product derivation. The framework is extensible and flexible thus it can be leveraged with variability-aware design patterns and ontology. We built a prototype that demonstrates the proof of concept. We tested our approach with Dr. School product line. The results reveal that the framework supports configuration management of SPL and derivation of high quality product in the product line. We evaluated results with ground truth to establish significance of our implementation},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–10},
numpages = {10},
keywords = {weighted approach, product derivation, critical path analysis, configuration management, Software product line}
}

@inproceedings{10.1145/3106195.3106212,
author = {Marimuthu, C. and Chandrasekaran, K.},
title = {Systematic Studies in Software Product Lines: A Tertiary Study},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106212},
doi = {10.1145/3106195.3106212},
abstract = {Software product lines are widely used in the software industries to increase the re-usability and to decrease maintenance cost. On the other hand, systematic reviews are widely used in the software engineering research community to provide the overview of the research field and practitioners guidelines. Researchers have conducted many systematic studies on the different aspects of SPLs. To the best of our knowledge, till now there is no tertiary study conducted on systematic studies of SPL related research topics. In this paper, we aim at conducting a systematic mapping study of existing systematic studies to report the overview of the findings for researchers and practitioners. We performed snowballing and automated search to find out the relevant systematic studies. As a result, we analyzed 60 relevant studies to answer 5 research questions. The main focus of this tertiary study is to highlight the research topics, type of published reviews, active researchers and publication forums. Additionally, we highlight some of the limitations of the systematic studies. The important finding of this study is that the research field is well matured as the systematic studies covered a wide range of research topics. Another important finding is that many studies provided information for practitioners as well as researchers which is a notable improvement in the systematic reviews. However, many studies failed to assess the quality of the primary studies which is the major limitation of the existing systematic studies.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {143–152},
numpages = {10},
keywords = {tertiary study, systematic review, software product line},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3233027.3236399,
author = {Kuiter, Elias and Krieter, Sebastian and Kr\"{u}ger, Jacob and Ludwig, Kai and Leich, Thomas and Saake, Gunter},
title = {PClocator: a tool suite to automatically identify configurations for code locations},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236399},
doi = {10.1145/3233027.3236399},
abstract = {The source code of highly-configurable software is challenging to comprehend, analyze, and test. In particular, it is hard to identify all configurations that comprise a certain code location. We contribute PCLocator, a tool suite that solves this problem by utilizing static analysis tools for compile-time variability. Using BusyBox and the Variability Bugs Database (VBDb), we evaluate the correctness and performance of PCLocator. The results show that we are able to analyze files in a matter of seconds and derive correct configurations in 95% of all cases.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {284–288},
numpages = {5},
keywords = {static source code analysis, software product line, preprocessor, configuration, build system},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3109729.3109737,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar and Azanza, Maider},
title = {Visualizing product customization efforts for spotting SPL reuse opportunities},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109737},
doi = {10.1145/3109729.3109737},
abstract = {Migrating a set of product variants to a managed SPL is rarely a one-shot effort. Experiences from industry revealed that a complete migration to an SPL might take years, during which customers' requirements still need to be fulfilled by the company (customization effort). Analyzing the assets that have been customized by products (customization analysis) becomes a main stepping stone in ascertaining reuse opportunities. This requires to remain vigilant to arising reuse opportunities not just at the SPL onset, but throughout the whole process. Traditionally, a common mechanism to identify reuse opportunities is the diff utility whereby differences between two files are calculated and displayed. But this mechanism might not scale up. Given the sheer number of both core-assets and SPL products, visualizations that abstract from conventional line-level diffs to higher level visualization are required to spot reuse opportunities a ta glance. To this end, we introduce visualizations that help to estimate the extent of the customization effort broken down by product and core-asset. The aim: a prompt insight into questions such as, how much effort are product developers spending on customization?; or, which core-assets needed a larger tuning to meet product requirements? This vision is realized in CUSTOMS, a visualization utility on top of FeatureHouse that resorts to alluvial diagrams and tree maps to display customization effort. CUSTOMS might serve as a first stepping stone for spotting reuse opportunities.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {73–80},
numpages = {8},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/1595808.1595819,
author = {Anastasopoulos, Michail},
title = {Increasing efficiency and effectiveness of software product line evolution: an infrastructure on top of configuration management},
year = {2009},
isbn = {9781605586786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1595808.1595819},
doi = {10.1145/1595808.1595819},
abstract = {Software Product Line Engineering entails the strategic development of software assets that are to be reused many times across the members of a product line. Assuring that the investment in reuse holds over time is an important requirement in this case. To that end it is necessary that evolution is carefully managed: Changes in reusable assets and their customized instances need to be tracked and propagated efficiently. Configuration Management is a mature discipline for that purpose. However traditional configuration management does not address product line evolution scenarios explicitly. Over time this can lead to great evolution management effort. This paper presents an infrastructure - in particular its validation - that sits on top of traditional configuration management and is tailored to evolution scenarios in Product Line Engineering. The result is a reduction of effort and an increase of correctness},
booktitle = {Proceedings of the Joint International and Annual ERCIM Workshops on Principles of Software Evolution (IWPSE) and Software Evolution (Evol) Workshops},
pages = {47–56},
numpages = {10},
keywords = {software product lines, evolution},
location = {Amsterdam, The Netherlands},
series = {IWPSE-Evol '09}
}

@inproceedings{10.1145/3503229.3547059,
author = {Wittler, Jan Willem and K\"{u}hn, Thomas and Reussner, Ralf},
title = {Towards an integrated approach for managing the variability and evolution of both software and hardware components},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547059},
doi = {10.1145/3503229.3547059},
abstract = {Although the development of mass-customized products has been successfully applied to both hardware and software, companies struggle managing the variability and evolution of software-intensive products within a coherent product engineering approach. While the variability and evolution of software alone is manageable, managing both software and hardware within one product line is a complex task and requires an integrated approach. Moreover, as the release cycle for hardware is longer than for software, a product line of hardware and software is usually developed in generations. While one generation is validated and produced, the next generation is already planned and designed, reusing both software and hardware of previous generations. Thus, the different generations and artifacts shared between them must be managed together. Finally, when approaches directly assign software to hardware, managing their evolution becomes increasingly complex. Evolved resource demands may be missed, exhausting the resources provided by the hardware, possibly leading to degraded or faulty functionality. To remedy this, we refine the Unified Conceptual Model to our Variability Model for both Software and Hardware capturing the notion of product line generations, versions and variants of both software and hardware components, as well as resource demands of software on hardware. This is the first step towards the development of an integrated product engineering approach for managing the variability and evolution of software-intensive products.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {94–98},
numpages = {5},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3336294.3336311,
author = {T\"{e}rnava, Xhevahire and Mortara, Johann and Collet, Philippe},
title = {Identifying and Visualizing Variability in Object-Oriented Variability-Rich Systems},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336311},
doi = {10.1145/3336294.3336311},
abstract = {In many variability-intensive systems, variability is implemented in code units provided by a host language, such as classes or functions, which do not align well with the domain features. Annotating or creating an orthogonal decomposition of code in terms of features implies extra effort, as well as massive and cumbersome refactoring activities. In this paper, we introduce an approach for identifying and visualizing the variability implementation places within the main decomposition structure of object-oriented code assets in a single variability-rich system. First, we propose to use symmetry, as a common property of some main implementation techniques, such as inheritance or overloading, to identify uniformly these places. We study symmetry in different constructs (e.g., classes), techniques (e.g., subtyping, overloading) and design patterns (e.g., strategy, factory), and we also show how we can use such symmetries to find variation points with variants. We then report on the implementation and application of a toolchain, symfinder, which automatically identifies and visualizes places with symmetry. The publicly available application to several large open-source systems shows that symfinder can help in characterizing code bases that are variability-rich or not, as well as in discerning zones of interest w.r.t. variability.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {231–243},
numpages = {13},
keywords = {visualizing software variability, tool support for understanding software variability, software product line engineering, object-oriented variability-rich systems, identifying software variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2362536.2362548,
author = {Soltani, Samaneh and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on functional and non-functional requirements},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362548},
doi = {10.1145/2362536.2362548},
abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {56–65},
numpages = {10},
keywords = {software product line engineering, planning techniques, feature model, configuration, artificial intelligence},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3503229.3547061,
author = {Ghofrani, Javad and Heravi, Paria and Babaei, Kambiz A. and Soorati, Mohammad D.},
title = {Trust challenges in reusing open source software: an interview-based initial study},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547061},
doi = {10.1145/3503229.3547061},
abstract = {Open source projects play a significant role in software production. Most of the software projects reuse and build upon the existing open source projects and libraries. While reusing is a time and cost saving strategy, some of the key factors are often neglected that create vulnerability in the software system. We look beyond the static code analysis and dependency chain tracing to prevent vulnerabilities at the human factors level. Literature lacks a comprehensive study of the human factors perspective to the issue of trust in reusing open source projects. We performed an interview-based initial study with software developers to get an understanding of the trust issue and limitations among the practitioners. We outline some of the key trust issues in this paper and layout the first steps towards a trustworthy reuse of software.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {110–116},
numpages = {7},
keywords = {empirical study, open source software, package dependency, reusability, systematic reuse, trust},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/2420942.2420944,
author = {Olaechea, Rafael and Stewart, Steven and Czarnecki, Krzysztof and Rayside, Derek},
title = {Modelling and multi-objective optimization of quality attributes in variability-rich software},
year = {2012},
isbn = {9781450318075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420942.2420944},
doi = {10.1145/2420942.2420944},
abstract = {Variability-rich software, such as software product lines, offers optional and alternative features to accommodate varying needs of users. Designers of variability-rich software face the challenge of reasoning about the impact of selecting such features on the quality attributes of the resulting software variant. Attributed feature models have been proposed to model such features and their impact on quality attributes, but existing variability modelling languages and tools have limited or no support for such models and the complex multi-objective optimization problem that arises. This paper presents ClaferMoo, a language and tool that addresses these shortcomings. ClaferMoo uses type inheritance to modularize the attribution of features in feature models and allows specifying multiple optimization goals. We evaluate an implementation of the language on a set of attributed feature models from the literature, showing that the optimization infrastructure can handle small-scale feature models with about a dozen features within seconds.},
booktitle = {Proceedings of the Fourth International Workshop on Nonfunctional System Properties in Domain Specific Modeling Languages},
articleno = {2},
numpages = {6},
keywords = {software product lines, multi-objective optimization},
location = {Innsbruck, Austria},
series = {NFPinDSML '12}
}

@inproceedings{10.1145/2934466.2934474,
author = {Myll\"{a}rniemi, Varvana and Raatikainen, Mikko and Savolainen, Juha and M\"{a}nnist\"{o}, Tomi},
title = {Purposeful performance variability in software product lines: a comparison of two case studies},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934474},
doi = {10.1145/2934466.2934474},
abstract = {Within software product lines, customers may have different quality needs. To produce products with purposefully different quality attributes, several challenges must be addressed. First, one must be able to distinguish product quality attributes to the customers in a meaningful way. Second, one must create the desired quality attribute differences during product-line architecture design and derivation. To study how performance is varied purposefully in software product lines, we conducted a comparison and re-analysis of two industrial case studies in the telecommunication and mobile game domains. The results show that performance variants must be communicated to the customer in a way that links to customer value and her role. When performance or its adaptation are crucial for the customer, performance differences must be explicitly "designed in" with software or hardware means. Due to the emergent nature of performance, it is important to test performance and manage how other variability affects performance.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {144–153},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3106195.3106219,
author = {Gregg, Susan P. and Albert, Denise M. and Clements, Paul},
title = {Product Line Engineering on the Right Side of the "V"},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106219},
doi = {10.1145/3106195.3106219},
abstract = {Product line engineering (PLE) is well-known for the savings it brings to organizations. This paper shows how a very large, in-service systems and software product line is achieving PLE-based savings in their verification and validation phase of development. The paper addresses how to achieve the sharing across product variants while the products being tested are evolving over time. Additionally, we will give a pragmatic set of decision criteria to help answer the longstanding issue in PLE-based testing of whether to test on the domain side or the application (product) side of the product derivation process.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {165–174},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product configurator, feature profiles, feature modeling, bill-of-features, Product line engineering, PLE factory, AEGIS Combat System},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3382025.3414952,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Gasca, Rafael M. and Carmona-Fombella, Jose Antonio and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa},
title = {AMADEUS: towards the AutoMAteD secUrity teSting},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414952},
doi = {10.1145/3382025.3414952},
abstract = {The proper configuration of systems has become a fundamental factor to avoid cybersecurity risks. Thereby, the analysis of cybersecurity vulnerabilities is a mandatory task, but the number of vulnerabilities and system configurations that can be threatened is extremely high. In this paper, we propose a method that uses software product line techniques to analyse the vulnerable configuration of the systems. We propose a solution, entitled AMADEUS, to enable and support the automatic analysis and testing of cybersecurity vulnerabilities of configuration systems based on feature models. AMADEUS is a holistic solution that is able to automate the analysis of the specific infrastructures in the organisations, the existing vulnerabilities, and the possible configurations extracted from the vulnerability repositories. By using this information, AMADEUS generates automatically the feature models, that are used for reasoning capabilities to extract knowledge, such as to determine attack vectors with certain features. AMADEUS has been validated by demonstrating the capacities of feature models to support the threat scenario, in which a wide variety of vulnerabilities extracted from a real repository are involved. Furthermore, we open the door to new applications where software product line engineering and cybersecurity can be empowered.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {11},
numpages = {12},
keywords = {vulnerable configuration, vulnerabilities, testing, reasoning, pentesting, feature model, cybersecurity},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382026.3425772,
author = {Ca\~{n}ete, Angel and Amor, Mercedes and Fuentes, Lidia},
title = {Supporting the evolution of applications deployed on edge-based infrastructures using multi-layer feature models},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425772},
doi = {10.1145/3382026.3425772},
abstract = {The proliferation of cyber-physical systems has encouraged the emergence of new technologies and paradigms to improve the performance of IoT-based applications. Edge Computing proposes using the nearby devices in the frontier/Edge of the access network for deploying application tasks. However, the functionality of cyberphysical systems, which is usually distributed in several devices and computers, imposes specific requirements on the infrastructure to run properly. The evolution of an application to meet new user requirements and the high diversity of hardware and software technologies in the edge can complicate the deployment of evolved applications.The aim of our approach is to apply Multi Layer Feature Models, which capture the variability of applications and the infrastructure, to support the deployment in edge-based environments of cyber-physical systems applications. This separation can support the evolution of application and infrastructure. Considering that IoT/Edge/Cloud infrastructures are usually shared by many applications, the SPL deployment process has to assure that there will be enough resources for all of them, informing developers about the alternatives of deployment. Prior to its deployment and leaning on the infrastructure feature models, the developer can calculate what is the configuration of minimal set of devices supporting application requirements of the evolved application. In addition, the developer can find which is the application configuration that can be hosted in the current evolved infrastructure.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {79–87},
numpages = {9},
keywords = {Software Product Line, Software Evolution, Multi Layer Feature Models, Internet of Things, Edge Computing},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@article{10.1145/3672555,
author = {Mahdavi-Hezaveh, Rezvan and Fatima, Sameeha and Williams, Laurie},
title = {Paving a Path for a Combined Family of Feature Toggle and Configuration Option Research},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672555},
doi = {10.1145/3672555},
abstract = {Feature toggles and configuration options are techniques to include or exclude functionality in software. The research contributions to these two techniques have most often been focused on either one of them. However, focusing on the similarities of these two techniques and the use of a common terminology may enable a combined family of research on software configuration (a term we use to encompass both techniques) and prevent duplication of effort. The goal of this study is to aid researchers in conducting a family of research on software configuration by extending an existing model of software configuration that provides a common terminology for feature toggles and configuration options in research studies. We started with Siegmund et al.’s Model of Software Configuration (MSC), which was developed based on configuration option-related resources. We extend the MSC by qualitative analysis of feature toggle-related resources. From our analysis, we proposed MSCv2 and evaluated it through its application on publications and an industrial system. Our results indicate researchers studying the same system may provide different definitions of software configuration in publications, similar research questions may be answered repeatedly because of a lack of a clear definition of software configuration, and having an MSC may enable generalized research on this family of research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {172},
numpages = {27},
keywords = {Feature toggle, configuration option, software configuration, software engineering}
}

@inproceedings{10.1145/3106195.3106221,
author = {Hayashi, Kengo and Aoyama, Mikio and Kobata, Keiji},
title = {Agile Tames Product Line Variability: An Agile Development Method for Multiple Product Lines of Automotive Software Systems},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106221},
doi = {10.1145/3106195.3106221},
abstract = {This article proposes an agile development method and its management method for multiple product lines of automotive software systems. In product line development, the problem area is divided into the domain engineering and application engineering for delivering diverse products. Now, the development of automotive software requires agility and extreme diversity. Conventional simple product line model could not accommodate the requirements. Therefore, we developed an agile development method for automotive multiple product lines. First, we propose an agile development method for multiple product lines by iteratively reusing process assets in application engineering. To manage the diversity of the products derived from the multiple product lines, we propose a management method which integrates the portfolio management and product development management into the agile development method. We applied the proposed method to the development of multiple product lines for our automotive software systems, and demonstrated a reduction of the cost and complexity of the multiple product lines, and improvement of on-time delivery.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {180–189},
numpages = {10},
keywords = {software product line, process asset, portfolio management, multiple product lines, automotive software, agile development},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3233027.3233049,
author = {Horcas, Jose-Miguel and Corti\~{n}as, Alejandro and Fuentes, Lidia and Luaces, Miguel R.},
title = {Integrating the common variability language with multilanguage annotations for web engineering},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233049},
doi = {10.1145/3233027.3233049},
abstract = {Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {196–207},
numpages = {12},
keywords = {web engineering, variability, composition, automation, annotations, SPL, CVL},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3382025.3414945,
author = {G\"{o}ttmann, Hendrik and Luthmann, Lars and Lochau, Malte and Sch\"{u}rr, Andy},
title = {Real-time-aware reconfiguration decisions for dynamic software product lines},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414945},
doi = {10.1145/3382025.3414945},
abstract = {Dynamic Software Product Lines (DSPL) have recently shown promising potentials as integrated engineering methodology for (self-)adaptive software systems. Based on the software-configuration principles of software product lines, DSPL additionally foster reconfiguration capabilities to continuously adapt software products to ever-changing environmental contexts. However, in most recent works concerned with finding near-optimal reconfiguration decisions, real-time aspects of reconfiguration processes are usually out of scope. In this paper, we present a model-based methodology for specifying and automatically analyzing real-time constraints of reconfiguration decisions in a feature-oriented and compositional way. Those real-time aware DSPL specifications are internally translated into timed automata, a well-founded formalism for real-time behaviors. This representation allows for formally reasoning about consistency and worst-case/best-case execution-time behaviors of sequences of reconfiguration decisions. The technique is implemented in a prototype tool and experimentally evaluated with respect to a set of case studies1.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {13},
numpages = {11},
keywords = {timed automata, reconfiguration decisions, dynamic software product lines},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2364412.2364429,
author = {Parra, Carlos and Giral, Leonardo and Infante, Alvaro and Cort\'{e}s, Camilo},
title = {Extractive SPL adoption using multi-level variability modeling},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364429},
doi = {10.1145/2364412.2364429},
abstract = {Software Product Line engineering aims at reusing and automating software development to reduce costs, have shorter development cycles, and maintain quality. However, for organizations with settled development processes and a large code base, adopting an SPL approach may prove to be a daunting task. In this paper we present an industrial experimentation and a proposal for an SPL adoption in Heinsohn Business Technology (HBT), a software development company specialized in financial, transportation, mortgage-backed securities, and pension-fund solutions. We start by identifying and modeling multiple levels of variability inherent to the kind of developments undertaken by HBT. Next, we define restrictions inside every level as well as between the levels to fully characterize an HBT software product. To limit the impact on the organization development process, we use an extractive approach. This allows us to design core assets starting from current software artifacts. The overall approach is based on real-world software artifacts developed over the years by HBT, whose combinations result in approximately 4.88e11 possible product configurations.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {99–106},
numpages = {8},
keywords = {software product lines, model-driven engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3307630.3342418,
author = {Rinc\'{o}n, Luisa and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {Analyzing the Convenience of Adopting a Product Line Engineering Approach: An Industrial Qualitative Evaluation},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342418},
doi = {10.1145/3307630.3342418},
abstract = {Engineering Software Product Lines may be a strategy to reduce costs and efforts for developing software and increasing business productivity. However, it cannot be considered as a "silver bullet" that applies to all types of organizations. Companies must consider pros and cons to determine sound reasons and justify its adoption. In previous work, we proposed the APPLIES evaluation framework to help decision-makers find arguments that may justify (or not) adopting a product line engineering approach. This paper presents our experience using this framework in a mid-sized software development company with more than 25 years of experience but without previous experience in product line engineering. This industrial experience, conducted as a qualitative empirical evaluation, helped us to evaluate to what extent APPLIES is practical to be used in a real environment and to gather ideas from real potential users to improve the framework.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {90–97},
numpages = {8},
keywords = {qualitative evaluation, product line engineering, product line adoption, empirical evaluation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2362536.2362561,
author = {de Oliveira, Thiago Henrique Burgos and Becker, Martin and Nakagawa, Elisa Yumi},
title = {Supporting the analysis of bug prevalence in software product lines with product genealogy},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362561},
doi = {10.1145/2362536.2362561},
abstract = {The term bug prevalence is derived from the medical world vocabulary and applied to Software Product Line (SPL), meaning all products that are affected by one particular bug. In single systems development, this concept is not relevant since a bug is either present or not. However, when it comes to SPL, analyzing the bug prevalence of a certain bug is still a challenge and a highly relevant topic, since the same bug may be present in several products. To support this analysis, the main contribution of this paper is the Product Genealogy approach. A core concept in our approach is the Product Genealogy Tree, in which the hierarchy of products in the SPL is represented, reflecting how each product evolved or was derived from another or from the core assets. In this context, the benefit of such a tree is the rapid visualization of the product's structure in the SPL, providing input on which products are to be examined initially. Besides that, in this paper we introduce a novel analogy between the medical genetics world and SPL in order to better explain the principles of our approach.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {181–185},
numpages = {5},
keywords = {software product line, product genealogy, change impact, bug prevalence},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3336294.3336314,
author = {Asano, Masaki and Nishiura, Yoichi and Nakanishi, Tsuneo and Fujiwara, Keiichi},
title = {Feature Oriented Refinement from Requirements to System Decomposition: Quantitative and Accountable Approach},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336314},
doi = {10.1145/3336294.3336314},
abstract = {This paper presents the revised domain engineering process to develop product lines of automotive body parts in Aisin Seiki Co., Ltd. In the process, feature analysis is conducted by a limited number of engineers with talent of abstraction and separation and other work including specifications and architecture design is conducted by average engineers who know the products. Feature analysis defines a hierarchy of abstraction, achieves separation of concerns, and disciplines other artifacts to follow the structure of abstraction and separation. Requirements and specifications are refined by the use case, use case scenario, and hierarchical tabular description (USDM) in a step-wise manner. The specification in USDM is refined to a system decomposition in a quantitative and accountable manner using the robustness diagram and design structure matrix. The revised domain engineering process reduced the issues pointed out in software reviews concerning errors on specifications and architecture design. Moreover, it reduced lead time for architecture design and produced the architecture tolerant to changes.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {195–205},
numpages = {11},
keywords = {use case approach, software product lines, robustness analysis, feature analysis, design structure matrix, automotive body parts},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3336294.3336318,
author = {Ebert, Rolf and Jolianis, Jahir and Kriebel, Stefan and Markthaler, Matthias and Pruenster, Benjamin and Rumpe, Bernhard and Salman, Karin Samira},
title = {Applying Product Line Testing for the Electric Drive System},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336318},
doi = {10.1145/3336294.3336318},
abstract = {The growth in electrification and digitalization of vehicles leads to increasing variability and complexity of automotive systems. This poses new challenges for verification and validation, identified in a Product Line Engineering case study for the electric drive system. To overcome those challenges we developed a Product Line Testing methodology called TIGRE. In this paper, we present the TIGRE methodology. TIGRE comprises the identification and documentation of relevant data for efficient product line testing and the application of this data in the test management of an agile project environment. Furthermore, we present our experiences from the introduction into a large-scale industrial context. Based on our results from the introduction, we conclude that the TIGRE approach reduces the testing effort for automotive product lines significantly and, furthermore, allows us to transfer the results to untested products.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {14–24},
numpages = {11},
keywords = {software product lines, product line testing, product line engineering, automotive industry},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3382025.3414951,
author = {Heradio, Ruben and Fernandez-Amoros, David and Galindo, Jos\'{e} A. and Benavides, David},
title = {Uniform and scalable SAT-sampling for configurable systems},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414951},
doi = {10.1145/3382025.3414951},
abstract = {Several relevant analyses on configurable software systems remain intractable because they require examining vast and highly-constrained configuration spaces. Those analyses could be addressed through statistical inference, i.e., working with a much more tractable sample that later supports generalizing the results obtained to the entire configuration space. To make this possible, the laws of statistical inference impose an indispensable requirement: each member of the population must be equally likely to be included in the sample, i.e., the sampling process needs to be "uniform". Various SAT-samplers have been developed for generating uniform random samples at a reasonable computational cost. Unfortunately, there is a lack of experimental validation over large configuration models to show whether the samplers indeed produce genuine uniform samples or not. This paper (i) presents a new statistical test to verify to what extent samplers accomplish uniformity and (ii) reports the evaluation of four state-of-the-art samplers: Spur, QuickSampler, Unigen2, and Smarch. According to our experimental results, only Spur satisfies both scalability and uniformity.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {17},
numpages = {11},
keywords = {variability modeling, uniform sampling, software product lines, configurable systems, SAT},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3233027.3233047,
author = {El-Sharkawy, Sascha and Dhar, Saura Jyoti and Krafczyk, Adam and Duszynski, Slawomir and Beichter, Tobias and Schmid, Klaus},
title = {Reverse engineering variability in an industrial product line: observations and lessons learned},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233047},
doi = {10.1145/3233027.3233047},
abstract = {Ideally, a variability model is a correct and complete representation of product line features and constraints among them. Together with a mapping between features and code, this ensures that only valid products can be configured and derived. However, in practice the modeled constraints might be neither complete nor correct, which causes problems in the configuration and product derivation phases. This paper presents an approach to reverse engineer variability constraints from the implementation, and thus improve the correctness and completeness of variability models.We extended the concept of feature effect analysis [22] to extract variability constraints from code artifacts of the Bosch PS-EC large-scale product line. We present an industrial application of the approach and discuss its required modifications to handle non-Boolean variability and heterogeneous artifact types.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {215–225},
numpages = {11},
keywords = {variability modeling, static analysis, software product lines, reverse engineering},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/1151433.1151437,
author = {Ajila, Samuel A. and Bailetti, Antonio J. and Dumitrescu, Razvan T.},
title = {Experience report on software product line evolution due to market reposition},
year = {2004},
isbn = {9781450378185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1151433.1151437},
doi = {10.1145/1151433.1151437},
abstract = {This paper presents the result of a study on the changes that occurred in the product line of a telecommunication equipments supplier because of the top management decision to change the product line's target market. The study examines six years of data and identifies potential relationships between changes in the product line and changes in the company's customer, inner context, and product layers. Some of the key findings are: (i) Sales are negatively related to product line growth and positively related to design turnover and the number of designers assigned to the product line. (ii) There is no relationship between the size of the code added to the product line and the number of designers required to develop and test it. (iii) There is a positive relationship between designer turnover and impact of change. (iv) The market downturn has an explicit impact on software development activities.},
booktitle = {Proceedings of the 2004 Workshop on Quantitative Techniques for Software Agile Process},
pages = {25–33},
numpages = {9},
keywords = {software product, product line evolution, metrics, designer, customer, change},
location = {Newport Beach, California},
series = {QUTE-SWAP '04}
}

@inproceedings{10.1145/2491627.2491629,
author = {Clements, Paul and Krueger, Charles and Shepherd, James and Winkler, Andrew},
title = {A PLE-based auditing method for protecting restricted content in derived products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491629},
doi = {10.1145/2491627.2491629},
abstract = {Many organizations that produce a portfolio of products for different customers need to ensure that sensitive or restricted content that may appear in some products must not appear in others. Examples of this need include complying with statutes in different countries of sale, protection of intellectual property developed specifically for one customer, and more. For organizations operating under these requirements and producing their products under a product line engineering paradigm that relies on automation in product derivation, there is a need for a method to ensure that the content restrictions have been met in the derived products. This paper describes an auditing method that meets this need. It was created for use in the Second Generation Product Line Engineering approach that is being applied by Lockheed Martin in their AEGIS ship combat system product line.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {218–226},
numpages = {9},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product derivation, product configurator, product baselines, product audit, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3510466.3511273,
author = {Fadhlillah, Hafiyyan Sayyid and Feichtinger, Kevin and Meixner, Kristof and Sonnleithner, Lisa and Rabiser, Rick and Zoitl, Alois},
title = {Towards Multidisciplinary Delta-Oriented Variability Management in Cyber-Physical Production Systems},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3511273},
doi = {10.1145/3510466.3511273},
abstract = {Cyber-Physical Production Systems (CPPSs) are complex systems comprised of software and hardware interacting with each other and the environment. In industry, over time, a plethora of CPPSs are developed to satisfy varying customer requirements and changing technologies. Managing variability is challenging, especially in multidisciplinary environments like in CPPS engineering. For instance, when supporting the automatic derivation and configuration of control software, one needs to understand variability from not only a software perspective, but also a mechatronic, electrical, process, and business perspective. It is unrealistic to use a single model or even one type of model across these perspectives. In this paper, we describe a Multidisciplinary Delta-Oriented Variability Management approach for CPPSs that we are currently developing. Our approach aims to express CPPS variability in different disciplines using heterogeneous variability models, relating models via cross-discipline constraints, and automatically generating control software based on variability models. We implemented a prototype of our approach by realizing delta-oriented variability modeling for IEC&nbsp;61499-based distributed control software and a configuration tool to enact the configuration options from multiple variability models. We performed a feasibility study of our approach using two systems of different size and complexity. We conclude that, despite current limitations, our approach can successfully and automatically generate control software based on related multidisciplinary variability models. We think that our approach is a good starting point to manage CPPS variability in practice.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {13},
numpages = {10},
keywords = {Variability Modeling, Software Product Line, Software Configuration, Cyber-Physical Production System},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/3233027.3233036,
author = {Hamza, Mostafa and Walker, Robert J. and Elaasar, Maged},
title = {CIAhelper: towards change impact analysis in delta-oriented software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233036},
doi = {10.1145/3233027.3233036},
abstract = {Change is inevitable for software systems to deal with the evolving environment surrounding them, and applying changes requires careful design and implementation not to break existing functionalities. Evolution in software product lines (SPLs) is more complex compared to evolution for individual products: a change applied to a single feature might affect all the products in the whole product family. In this paper we present an approach for change impact analysis in delta-oriented programming (DOP), an existing language aimed at supporting SPLs. We propose the CIAHelper tool to identify dependencies within a DOP program, by analyzing the semantics of both the code artifacts and variability models to construct a directed dependency graph. We also consider how the source code history could be used to enhance the recall of detecting the affected artifacts given a change proposal. We evaluate our approach by means of five case studies on two different DOP SPLs.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {31–42},
numpages = {12},
keywords = {variability model, feature model, delta-oriented programming, code assets, change impact analysis},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3510466.3511271,
author = {Nieke, Michael and Hoff, Adrian and Schaefer, Ina and Seidl, Christoph},
title = {Experiences with Constructing and Evolving aSoftware Product Line with Delta-Oriented Programming},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3511271},
doi = {10.1145/3510466.3511271},
abstract = {A Software Product Line (SPL) captures families of closely related software variants. The configuration options of an SPL are represented by features. Typically, SPLs are developed in a feature-centric manner and, thus, require different development methods and technologies from developing software products individually. For developers of single systems, this means a shift in paradigm and technology. Especially with invasive variability realization mechanisms, such as Delta-Oriented Programming (DOP), centering development around configurable features realized via source code transformation is commonly expected to pose an obstacle, but concrete experience reports are lacking. In this paper, we investigate how DOP and cutting-edge SPL development tools are picked up by non-expert developers. To this end, we report on our experiences from a student capstone SPL development project. Our results show that participants find easy access to SPL development concepts and tools. Based on our observations and the participants’ practices, we define guidelines for developers using DOP.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {11},
numpages = {9},
keywords = {Software Product Line, Observations, Guidelines, Experience Report, Evolution, Delta Oriented Programming, Case Study},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/2791060.2791099,
author = {Filho, Jo\~{a}o Bosco Ferreira and Allier, Simon and Barais, Olivier and Acher, Mathieu and Baudry, Benoit},
title = {Assessing product line derivation operators applied to Java source code: an empirical study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791099},
doi = {10.1145/2791060.2791099},
abstract = {Product Derivation is a key activity in Software Product Line Engineering. During this process, derivation operators modify or create core assets (e.g., model elements, source code instructions, components) by adding, removing or substituting them according to a given configuration. The result is a derived product that generally needs to conform to a programming or modeling language. Some operators lead to invalid products when applied to certain assets, some others do not; knowing this in advance can help to better use them, however this is challenging, specially if we consider assets expressed in extensive and complex languages such as Java. In this paper, we empirically answer the following question: which product line operators, applied to which program elements, can synthesize variants of programs that are incorrect, correct or perhaps even conforming to test suites? We implement source code transformations, based on the derivation operators of the Common Variability Language. We automatically synthesize more than 370,000 program variants from a set of 8 real large Java projects (up to 85,000 lines of code), obtaining an extensive panorama of the sanity of the operations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {36–45},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2791060.2791065,
author = {Gregg, Susan P. and Scharadin, Rick and Clements, Paul},
title = {The more you do, the more you save: the superlinear cost avoidance effect of systems product line engineering},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791065},
doi = {10.1145/2791060.2791065},
abstract = {Product lines that use automated tools to configure shared assets (e.g., software or requirements or test cases or user documentation) based on product descriptions have long been known to bring about substantial development cost avoidance when compared to clone-and-own or product-specific development techniques. Now, however, it can be shown that the cost avoidance for configuring multiple shared assets is superlinear -- that is, the overall cost avoidance exceeds the sum of the that brought about by working with each of the shared assets in isolation. That is, a product line that configures (for example) requirements and code will avoid more cost than the sum of code-based plus requirements-based cost avoidance. In addition, we also observe a superlinear effect in terms of the number of products in the portfolio as well. This paper explores why these effects occur, and presents analytical and empirical evidence for their existence from one of the largest and most successful product lines in the literature, the AEGIS Weapon System. The result may lead to new insight into the economics of product line engineering in the systems engineering realm.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {303–310},
numpages = {8},
keywords = {variation points, systems and software product lines, second generation product line engineering, product line measurement, product line engineering, product line economics, product derivation, product configurator, feature modeling, AEGIS},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2934466.2934492,
author = {Groher, Iris and Weinreich, Rainer and Buchgeher, Georg and Schossleitner, Robert},
title = {Reusable architecture variants for customer-specific automation solutions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934492},
doi = {10.1145/2934466.2934492},
abstract = {Manufacturing execution systems (MES) are key elements of industrial automation systems. MES can be deployed at different levels of scale from a single site or plant to a company with globally distributed production sites all over the world. Establishing or extending an MES is a complex process, which requires taking the already existing software and system architecture into account in addition to the desired MES features. We developed an approach and an associated tool to support the process of creating offers for customer-specific MES solutions based on a vendor-specific automation platform. We define architecture variants for selecting a specific MES feature set and for supporting different MES expansion stages. Additionally, we provide an architecture modeling approach to explore the integration with existing software and system infrastructures. The approach has been applied at the STIWA Group, a vendor of MES for industrial production lines.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {242–251},
numpages = {10},
keywords = {manufacturing execution system (MES), feature set, customer-specific offer, automation platform, architecture variants},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2934466.2934491,
author = {Fogdal, Thomas and Scherrebeck, Helene and Kuusela, Juha and Becker, Martin and Zhang, Bo},
title = {Ten years of product line engineering at Danfoss: lessons learned and way ahead},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934491},
doi = {10.1145/2934466.2934491},
abstract = {Software and systems product line engineering (PLE) has been an established approach for reducing time to market as well as cost and increasing quality in a set of related products for two decades now. Although there is a huge body of knowledge on PLE, adopting a concrete PLE approach is still not a trivial endeavor for interested companies. With the increasing importance of development speed, the advent of agile engineering approaches, and decreasing management interest in improvements that require large organizational transformations and only show benefits after several years, companies are facing challenges in successfully adopting this approach. They often hesitate as there is no clear adoption path, nor any certainty, that the intended improvement steps will also provide added value in the short- and mid-term perspective. In consequence, a considerable amount of PLE potential still remains unexploited.To help such companies with the adoption of PLE, the goal of this paper is to provide inspiration and evidence that PLE is a sound approach and its successful introduction is possible even in settings that differ substantially from those of pioneer product lines.To this end, this paper presents the following main contributions with the PLE adoption case at Danfoss Drives: an overview of the key change drivers and the motivation for adopting a PLE approach, a discussion of incremental PLE introduction in an agile engineering context, a presentation of the current PLE setting with a focus on key concepts, and finally a presentation of motivators and directions for future improvements.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {252–261},
numpages = {10},
keywords = {product line evaluation, product line adoption, industrial experiences},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2019136.2019165,
author = {Lettner, Daniela and Thaller, Daniel and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul and Heider, Wolfgang},
title = {Supporting business calculations in a product line engineering tool suite},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019165},
doi = {10.1145/2019136.2019165},
abstract = {Software Product Line Engineering (SPLE) involves defining the commonalities and variability of similar products to leverage extensive reuse and to accelerate the derivation of customized products. However, sales people and customers do not only care about technical properties of product features during product derivation. They also need information concerning the business value of product features. Existing approaches have addressed this issue by combining business information with variability models, e.g., by defining feature attributes or by integrating third party tools. However, a solution that seamlessly integrates variability and business calculations within a SPLE tool is still lacking. We report on our ongoing efforts to integrate business calculations in the DOPLER tool suite. We use examples of product lines from the industrial plant automation domain to motivate and demonstrate our solution.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {26},
numpages = {4},
keywords = {variability models, value-based software engineering, tool support, business calculations},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2647908.2655964,
author = {Mannion, Mike and Kaindl, Hermann},
title = {Using similarity metrics for mining variability from software repositories},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655964},
doi = {10.1145/2647908.2655964},
abstract = {Much activity within software product line engineering has been concerned with explicitly representing and exploiting commonality and variability at the feature level for the purpose of a particular engineering task e.g. requirements specification, design, coding, verification, product derivation process, but not for comparing how similar products in the product line are with each other. In contrast, a case-based approach to software development is concerned with descriptions and models as a set of software cases stored in a repository for the purpose of searching at a product level, typically as a foundation for new product development. New products are derived by finding the most similar product descriptions in the repository using similarity metrics.The new idea is to use such similarity metrics for mining variability from software repositories. In this sense, software product line engineering could be informed by the case-based approach. This approach requires defining and implementing such similarity metrics based on the representations used for the software cases in such a repository. It provides complementary benefits to the ones given through feature-based representations of variability and may help mining such variability.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {32–35},
numpages = {4},
keywords = {similarity metrics, product lines, feature-based representation, commonality and variability, case-based reasoning},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3483899.3483907,
author = {Uch\^{o}a, Anderson and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Garcia, Alessandro},
title = {Do Critical Components Smell Bad? An Empirical Study with Component-based Software Product Lines},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483907},
doi = {10.1145/3483899.3483907},
abstract = {Component-based software product line (SPL) consists of a set of software products that share common components. For a proper SPL product composition, each component has to follow three principles: encapsulating a single feature, restricting data access, and be replaceable. However, it is known that developers usually introduce anomalous structures, i.e., code smells, along the implementation of components. These code smells might violate one or more component principles and hinder the SPL product composition. Thus, developers should identify code smells in component-based SPLs, especially those affecting highly interconnected components, which are called critical components. Nevertheless, there is limited evidence of how smelly these critical components tend to be in component-based SPLs. To address this limitation, this paper presents a survey with developers of three SPLs. We inquire these developers about their perceptions of a critical component. Then, we characterize critical components per SPL, and identify nine recurring types of code smells. Finally, we quantitatively assess the smelliness of the critical components. Our results suggest that: (i) critical components are ten times more prone to have code smells than non-critical ones; (ii) the most frequent code smell types affecting critical components violate several component principles together; and (iii) these smell types affect multiple SPL components.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {21–30},
numpages = {10},
keywords = {smell, empirical study, Component-based software product line},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/2491627.2491642,
author = {Martini, Antonio and Pareto, Lars and Bosch, Jan},
title = {Communication factors for speed and reuse in large-scale agile software development},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491642},
doi = {10.1145/2491627.2491642},
abstract = {An open issue in industry is the combination of software reuse in the context of large scale Agile Software Development. The speed offered by Agile Software Development is needed for short time to market, while reuse strategies such as Software Product Line Engineering are needed for long-term productivity, efficiency, and profit. The paper investigates, through a survey, communication factors affecting both speed and reuse in 3 large companies developing embedded systems and employing Agile Software Development and Software Product Line Engineering. Our results include a prioritized list of communication related factors obtained by statistical analysis and the recognition and spread of the factors in the companies. We have recognized 5 interfaces with the Agile development team that need to be improved: system engineers (architects), product management, distributed teams, inter-project teams and sales unit. Few factors (involving inter-project communication) depend on the business drivers for the company. We also reveal that Agile teams need strategic and architectural inputs in order to be implanted in a large company employing Software Product Line Engineering. Academic and industrial training as well as different tactics for co-location would improve the communication skills of engineers. There is also a need for solutions, in the reference architecture, for fostering Agile Software Development: the goal is the combination of the focus on customer value of the teams, reusability, system requirements and avoidance of organizational dependencies.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {42–51},
numpages = {10},
keywords = {speed, software reuse, software process improvement (SPI), factors, embedded systems, development speed, communication, agile software development},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2019136.2019149,
author = {Murugesupillai, Esan and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {A preliminary mapping study of approaches bridging software product lines and service-oriented architectures},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019149},
doi = {10.1145/2019136.2019149},
abstract = {Service Oriented Architectures (SOA) and Software Product Lines (SPL) have individually proven to be software engineering concepts that create added value to the development of software systems. Recently, the research community has recognized and investigated potentials for combining these two concepts. However, there have been no mapping study and literature surveys that systematically review the present research results in combining the two. This paper presents results of a preliminary work on a systematic mapping study of research papers that report on combining SOA and SPL. The main goal of a systematic mapping study is to provide a breath overview, classification of approaches and the quantity and type of research as well as available research results, which is complimentary step toward further systematic literature review. This paper, based on selected papers published from 2002 to mid-2010, reports on various aspects of the analyzed literature, including the motivations for combining the two concepts; contributions to specific stages of software engineering lifecycles; types of synergies and characteristics that are accomplished through combinations of the two concepts; and the methods used for and the rigor of the evaluations of the research conducted on the studied topic.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {11},
numpages = {8},
keywords = {variability management, software variability, software product line, service-oriented product line, service-oriented architecture},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2491627.2491646,
author = {Marijan, Dusica and Gotlieb, Arnaud and Sen, Sagar and Hervieu, Aymeric},
title = {Practical pairwise testing for software product lines},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491646},
doi = {10.1145/2491627.2491646},
abstract = {One key challenge for software product lines is efficiently managing variability throughout their lifecycle. In this paper, we address the problem of variability in software product lines testing. We (1) identify a set of issues that must be addressed to make software product line testing work in practice and (2) provide a framework that combines a set of techniques to solve these issues. The framework integrates feature modelling, combinatorial interaction testing and constraint programming techniques. First, we extract variability in a software product line as a feature model with specified feature interdependencies. We then employ an algorithm that generates a minimal set of valid test cases covering all 2-way feature interactions for a given time interval. Furthermore, we evaluate the framework on an industrial SPL and show that using the framework saves time and provides better test coverage. In particular, our experiments show that the framework improves industrial testing practice in terms of (i) 17% smaller set of test cases that are (a) valid and (b) guarantee all 2-way feature coverage (as opposite to 19.2% 2-way feature coverage in the hand made test set), and (ii) full flexibility and adjustment of test generation to available testing time.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {227–235},
numpages = {9},
keywords = {variability management, software product lines, feature modelling},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2648511.2648528,
author = {Barreiros, Jorge and Moreira, Ana},
title = {A cover-based approach for configuration repair},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648528},
doi = {10.1145/2648511.2648528},
abstract = {Feature models are often used to describe variability and commonality in Software Product Lines, specifying admissible configurations of valid products. However, invalid configurations may arise in some scenarios. These include feature model evolution that invalidates pre-existing products or collaborative configuration by multiple stakeholders with conflicting goals, among others. This problem has been acknowledged in the literature and some techniques for configuration repair have already been proposed. However, common optimization criteria such as proximity between original and repaired configurations can result in a significant number of alternative repair possibilities, easily attaining thousands of alternatives for models of practical dimension. Consequently, rather than just efficiently providing an exhaustive list of possibilities, an approach that specifically addresses this issue should be able to offer the user a manageable and comprehensible view of the configuration problems and potential repair options. We offer a novel approach for configuration repair, based on partitioning and cover analysis, with high performance and generating high quality solutions, which allows efficient identification and presentation of multiple competing repairs.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {157–166},
numpages = {10},
keywords = {software product lines, feature modeling, configuration repair, configuration diagnosis, configuration},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2364412.2364417,
author = {Ripon, Shamim and Azad, Keya and Hossain, Sk Jahir and Hassan, Mehidee},
title = {Modeling and analysis of product-line variants},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364417},
doi = {10.1145/2364412.2364417},
abstract = {Formal verification of variant requirements has gained much interest in the software product line (SPL) community. Feature diagrams are widely used to model product line variants. However, there is a lack of precisely defined formal notation for representing and verifying such models. This paper presents an approach to modeling and analyzing SPL variant feature diagrams using first-order logic. It provides a precise and rigorous formal interpretation of the feature diagrams. Logical expressions can be built by modeling variants and their dependencies by using propositional connectives. These expressions can then be validated by any suitable verification tool such as Alloy. A case study of a Computer Aided Dispatch (CAD) system variant feature model is presented to illustrate the analysis and verification process.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {26–31},
numpages = {6},
keywords = {variants, product line, first-order logic, feature model, alloy},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791075,
author = {Fang, Miao and Leyh, Georg and Doerr, Joerg and Elsner, Christoph and Zhao, Jingjing},
title = {Towards model-based derivation of systems in the industrial automation domain},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791075},
doi = {10.1145/2791060.2791075},
abstract = {Many systems in the industrial automation domain include information systems. They manage manufacturing processes and control numerous distributed hardware and software components. In current practice, the development and reuse of such systems is costly and time-consuming, due to the variability of systems' topology and processes. Up to now, product line approaches for systematic modeling and management of variability have not been well established for such complex domains.In this paper, we present a model-based approach to support the derivation of systems in the target domain. The proposed architecture of the derivation infrastructure enables feature-, topology- and process configuration to be integrated into the multi-staged derivation process. We have developed a prototype to prove feasibility and improvement of derivation efficiency. We report the evaluation results that we collected through semi-structured interviews from domain stakeholders. The results show high potential to improve derivation efficiency by adopting the approach in practice. Finally, we report the lessons learned that raise the opportunities and challenges for future research.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {283–292},
numpages = {10},
keywords = {variability modeling, product line, model-based engineering, derivation},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3106195.3106210,
author = {Markiegi, Urtzi and Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire},
title = {Search-based product line fault detection allocating test cases iteratively},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106210},
doi = {10.1145/3106195.3106210},
abstract = {The large number of possible configurations makes it unfeasible to test every single system variant in a product line. Consequently, a small subset of the product line products must be selected, typically following combinatorial interaction testing approaches. Recently, many product line engineering approaches have considered the selection and prioritization of relevant products within the product line. In a further step, these products are thoroughly tested individually. However, the test cases that must be executed in each of the products are not always insignificant, and in systems such as Cyber-Physical System Product Lines (CPSPLs), their test execution time can vary from tens to thousands of seconds. This issue leads to spending a lot of time testing each individual product. To solve this problem we propose a search-based approach to perform the testing of product lines by allocating small number of test cases in each of the products. This approach increases the probability of detecting faults faster. Specifically, our search-based approach obtains a set of products, which are derived from using any state-of-the-art approach as inputs, and a set of attributed test cases. As an output a list of allocated test cases for each product is obtained. We also define a novel fitness function to guide the search and we propose corresponding crossover and mutation operators. The search and test process is iteratively repeated until the time budget is consumed. We performed an evaluation with a CPSPL as a case study. Results suggest that our approach can reduce the fault detection time by 61% and 65% on average when compared with the traditional test process and the Random Search algorithm respectively.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {123–132},
numpages = {10},
keywords = {Search-based Software Engineering, Product Line Testing, Fault Detection},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2648511.2648525,
author = {Stein, Jacob and Nunes, Ingrid and Cirilo, Elder},
title = {Preference-based feature model configuration with multiple stakeholders},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648525},
doi = {10.1145/2648511.2648525},
abstract = {Feature model configuration is known to be a hard, error-prone and time-consuming activity. This activity gets even more complicated when it involves multiple stakeholders in the configuration process. Research work has proposed approaches to aid multi-stakeholder feature model configuration, but they rely on systematic processes that constraint decisions of some of the stakeholders. In this paper, we propose a novel approach to improve the multi-stakeholder configuration process, considering stakeholders' preferences expressed through both hard and soft constraints. Based on such preferences, we recommend different product configurations using different strategies from the social choice theory. We conducted an empirical study to evaluate the effectiveness of our strategies with respect to individual stakeholder satisfaction and fairness among all stakeholders. Results indicate that particular strategies perform best with respect to these aspects.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {132–141},
numpages = {10},
keywords = {social choice, preferences, feature model configuration},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2362536.2362560,
author = {Lettner, Daniela and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Supporting end users with business calculations in product configuration},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362560},
doi = {10.1145/2362536.2362560},
abstract = {Business calculations like break-even, return on investment, or cost are essential in many domains to support decision making while configuring products. For instance, customers and sales people need to estimate and compare the business value of different product variants. Some product line approaches provide initial support, e.g., by defining quality attributes in relation to features. However, an approach that allows domain engineers to easily define business calculations together with variability models is still lacking. In product configuration, calculation results need to be instantly presented to end users after making configuration choices. Further, due to the often high number of calculations, the presentation of calculation results to end users can be challenging. These challenges cannot be addressed by integrating off-the-shelf applications performing the calculations with product line tools. We thus present an approach based on dedicated calculation models that are related to variability models. Our approach seamlessly integrates business calculations with product configuration and provides support for formatting calculations and calculation results. We use the DOPLER tool suite to deploy calculations together with variability models to end users in product configuration. We evaluate the expressiveness and practical relevance of the approach by investigating the development of business calculations for 15 product lines from the domain of industrial automation.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {171–180},
numpages = {10},
keywords = {variability models, product configuration, business calculations},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2362536.2362571,
author = {Flores, Rick and Krueger, Charles and Clements, Paul},
title = {Mega-scale product line engineering at General Motors},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362571},
doi = {10.1145/2362536.2362571},
abstract = {General Motors faces probably the most complex Systems and Software Product Line Engineering (PLE) challenges ever, in terms of product complexity, richness of variation, size of organization, and an unforgiving requirement to support over a dozen simultaneous development streams all geared towards each new model year. To meet this challenge, GM turned to an advanced set of explicitly defined product line engineering solutions, which have been referred to as Second Generation PLE (2GPLE). This includes reliance on features as the lingua franca to express product differences in all phases of the lifecycle, deeply nested hierarchical product lines, industrial strength automation to provide modeling consistency throughout, and more. This paper explains how 2GPLE is being applied at General Motors, and the technical and organizational lessons learned so far.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {259–268},
numpages = {10},
keywords = {variation points, software product lines, product portfolio, product line engineering, product configurator, product baselines, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2019136.2019181,
author = {Weiss, Michael},
title = {Economics of collectives},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019181},
doi = {10.1145/2019136.2019181},
abstract = {The transition from a software product line to a software ecosystem, as reported by Bosch [5], takes place, when the product line company makes its platform available to developers outside the company. A similar transition takes place from a software ecosystem to a collective, when the platform is jointly created and owned by a group of members. Building on the literature on software product line economics, this research identifies three factors affecting the economics of collectives (level of contribution, number of members, and diversity of use), and develops a model linking those factors to three economic outcomes (time, quality, and cost).},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {39},
numpages = {8},
keywords = {software product lines, software ecosystems, product line economics, open source software, collectives},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2362536.2362542,
author = {Pleuss, Andreas and Hauptmann, Benedikt and Keunecke, Markus and Botterweck, Goetz},
title = {A case study on variability in user interfaces},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362542},
doi = {10.1145/2362536.2362542},
abstract = {Software Product Lines (SPL) enable efficient derivation of products. SPL concepts have been applied successfully in many domains including interactive applications. However, the user interface (UI) part of applications has barely been addressed yet. While standard SPL concepts allow derivation of functionally correct UIs, there are additional non-functional requirements, like usability, which have to be considered. This paper presents a case study investigating UI variability found in variants of the commercial web-based information system HIS-GX/QIS. We analyze which aspects of a UI vary and to which degree. The results show that just tweaking the final UI (e.g., using stylesheets) is not sufficient but there is a need for more customization which must be supported by, e.g., UI-specific models.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {6–10},
numpages = {5},
keywords = {user interface engineering, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2362536.2362563,
author = {Heider, Wolfgang and Rabiser, Rick and Gr\"{u}nbacher, Paul and Lettner, Daniela},
title = {Using regression testing to analyze the impact of changes to variability models on products},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362563},
doi = {10.1145/2362536.2362563},
abstract = {Industrial product lines are typically maintained for a long time and evolve continuously to address changing requirements and new technologies. Already derived products often have to be re-derived after such changes to benefit from new and updated features. Product line engineers thus frequently need to analyze the impact of changes to variability models to prevent unexpected changes of re-derived products. In this paper we present a tool-supported approach that informs engineers about the impacts of variability model changes on existing products. Regression tests are used to determine whether existing product configurations and generated product outputs can be re-derived without unexpected effects. We evaluate the feasibility of the approach based on changes observed in a real-world software product line. More specifically, we show how our approach helps engineers performing specific evolution tasks to analyze the change impacts on existing products. We also evaluate the performance and scalability of our approach. Our results show that variability change impact analyses can be automated using model regression testing and can help reducing the gap between domain engineering and application engineering.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {196–205},
numpages = {10},
keywords = {variability models, regression testing, product line evolution},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753238,
author = {White, Jules and Dougherty, Brian and Schmidt, Doulas C. and Benavides, David},
title = {Automated reasoning for multi-step feature model configuration problems},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of increasing software reusability. One software reuse approach is to develop a Software Product-line (SPL), which is a reconfigurable software architecture that can be reused across projects. Creating configurations of the SPL that meets arbitrary requirements is hard.Existing research has focused on techniques that produce a configuration of the SPL in a single step. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these CSP configuration problem CSPs can be derived automatically with a constraint solver. Third, we present empirical results demonstrating that our CSP-based technique can solve multi-step configuration problems involving hundreds of features in seconds.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {11–20},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2647908.2655975,
author = {Wagner, Michael and Dudeck, Grit and Hein, Christian and Tcholtchev, Nikolay and Gebhardt, Christian and Korff, Andreas},
title = {VARIES framework to support tool integration in product line engineering},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655975},
doi = {10.1145/2647908.2655975},
abstract = {Even though product line technologies and methods are well established in today's development environments, various challenges still remain. Different ways of handling variability in system development tools have arisen posing an integration challenge to today's tool chains. This issue is further amplified by the variety of integration approaches. The VARIES framework addresses these challenges through technology adaptation, i.e. the utilization of model transformations and traceability support.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {117–120},
numpages = {4},
keywords = {variability management, transformation, traceability, tool chain, SPL, OSLC, ModelBus, CVL},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2499777.2500716,
author = {Saller, Karsten and Lochau, Malte and Reimund, Ingo},
title = {Context-aware DSPLs: model-based runtime adaptation for resource-constrained systems},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500716},
doi = {10.1145/2499777.2500716},
abstract = {Dynamic Software Product Lines (DSPLs) provide a promising approach for planning and applying runtime reconfiguration scenarios to adaptive software systems. However, applying DSPLs in the vital domain of highly context-aware systems, e.g., mobile devices, is obstructed by the inherently limited resources being insufficient to handle large, constrained (re-)configurations spaces. To tackle these drawbacks, we propose a novel model-based approach for designing DSPLs in a way that allows for a trade-off between precomputation of reconfiguration scenarios at development time and on-demand evolution at runtime. Therefore, we (1) enrich feature models with context information to reason about potential context changes, and (2) specify context-aware reconfiguration processes on the basis of a scalable transition system incorporating state space abstractions and incremental refinement at runtime. We illustrate our concepts by means of a smartphone case study and present an implementation and evaluation considering different trade-off metrics.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {106–113},
numpages = {8},
keywords = {state space reduction, feature models, contexts, adaptive systems, DSPL},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2791060.2791067,
author = {Yue, Tao and Ali, Shaukat and Selic, Bran},
title = {Cyber-physical system product line engineering: comprehensive domain analysis and experience report},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791067},
doi = {10.1145/2791060.2791067},
abstract = {Cyber-Physical Systems (CPSs) are the future generation of highly connected embedded systems having applications in diverse domains including Oil and Gas. Employing Product Line Engineering (PLE) is believed to bring potential benefits with respect to reduced cost, higher productivity, higher quality, and faster time-to-market. However, relatively few industrial field studies are reported regarding the application of PLE to develop large-scale systems, and more specifically CPSs. In this paper, we report about our experiences and insights gained from investigating the application of model-based PLE at a large international organization developing subsea production systems (typical CPSs) to manage the exploitation of oil and gas production fields. We report in this paper 1) how two systematic domain analyses (on requirements engineering and product configuration/derivation) were conducted to elicit CPS PLE requirements and challenges, 2) key results of the domain analysis (commonly observed in other domains), and 3) our initial experience of developing and applying two Model Based System Engineering (MBSE) PLE solution to address some of the requirements and challenges elicited during the domain analyses.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {338–347},
numpages = {10},
keywords = {requirements engineering, product line engineering (PLE), model based system engineering, domain analysis, cyber physical system (CPS)},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2362536.2362554,
author = {Martini, Antonio and Pareto, Lars and Bosch, Jan},
title = {Enablers and inhibitors for speed with reuse},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362554},
doi = {10.1145/2362536.2362554},
abstract = {An open issue in industry is software reuse in the context of large scale Agile product development. The speed offered by agile practices is needed to hit the market, while reuse is needed for long-term productivity, efficiency, and profit. The paper presents an empirical investigation of factors influencing speed and reuse in three large product developing organizations seeking to implement Agile practices. The paper identifies, through a multiple case study with 3 organizations, 114 business-, process-, organizational-, architecture-, knowledge- and communication factors with positive or negative influences on reuse, speed or both. Contributions are a categorized inventory of influencing factors, a display for organizing factors for the purpose of process improvement work, and a list of key improvement areas to address when implementing reuse in organizations striving to become more Agile. Categories identified include good factors with positive influences on reuse or speed, harmful factors with negative influences, and complex factors involving inverse or ambiguous relationships. Key improvement areas in the studied organizations are intra-organizational communication practices, reuse awareness and practices, architectural integration and variability management. Results are intended to support process improvement work in the direction of Agile product development. Feedback on results from the studied organizations has been that the inventory captures current situations, and is useful for software process improvement work.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {116–125},
numpages = {10},
keywords = {speed, software reuse, software process improvement (SPI), inhibitors, enablers, embedded systems, agile software development},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2364412.2364414,
author = {Derakhshanmanesh, Mahdi and Fox, Joachim and Ebert, J\"{u}rgen},
title = {Adopting feature-centric reuse of requirements assets: an industrial experience report},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364414},
doi = {10.1145/2364412.2364414},
abstract = {In this paper, we share practical experiences from an ongoing effort towards adopting a feature-centric method that enhances reuse of requirements at TRW Automotive's slip control system department (based in Koblenz, Germany). After introducing identified challenges in detail, key solution factors and a technical reuse concept for managing and deriving product-specific requirements are presented. Then, we demonstrate one way of implementing this solution approach based on industry-standard tools. In addition, identified pitfalls and lessons learned are discussed.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {2–9},
numpages = {8},
keywords = {software product lines, reuse, requirements, features},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/1774088.1774573,
author = {Espinoza, Angelina and Botterweck, Goetz and Garbajosa, Juan},
title = {A formal approach to reuse successful traceability practices in SPL projects},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774573},
doi = {10.1145/1774088.1774573},
abstract = {Software Product Line (SPL) Engineering has to deal with interrelated, complex models such as feature and architecture models, hence traceability is fundamental to keep them consistent. Commonly, a traceability schema must be started from scratch from project to project. To avoid that, useful traceability practices to solve day to day problems should be modeled explicitly and kept as part of the traceability knowledge gained, and then organizations can reduce time and effort in implementing traceability in new projects. This paper presents an approach for formalizing and reusing traceability practices in SPL Engineering. Using this formalization approach a traceability metamodel is defined, incorporating the particular traceability practices performed in SPL Engineering. Customized traceability methodologies for SPL projects will be systematically and formally generated from this metamodel. These resulting methodologies will have already incorporated the traceability knowledge proven as successful in previous projects, facilitating the reuse of such practices. In this paper, we focus specifically on the product derivation process, to show the advantages of this formalization approach to reuse traceability knowledge.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2352–2359},
numpages = {8},
keywords = {traceability methodology, traceability metamodeling, software product lines, product derivation, knowledge reuse, feature configuration},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/3023956.3023960,
author = {Pietsch, Christopher and Reuling, Dennis and Kelter, Udo and Kehrer, Timo},
title = {A tool environment for quality assurance of delta-oriented model-based SPLs},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023960},
doi = {10.1145/3023956.3023960},
abstract = {With the advent of model-driven engineering, software product line (SPL) technologies must be able to generate models as instances of a model-based SPL (MBSPL). Delta modeling is a variability mechanism which can be easily adopted for MBSPLs. The idea is to generate products by applying one or several deltas onto a core model. Hence, the main task during SPL implementation is to develop a set of deltas and to maintain several kinds of interrelations, e.g. dependencies and conflicts, in order to be able to generate all products of a MBSPL upon request. The resulting network of deltas is often complex and hard to maintain without appropriate tool support. This paper presents a tool environment for quality assurance in delta-oriented MBSPLs supporting the identification and elimination of design flaws in a network of deltas based on the principles of quality metrics and refactoring. We build upon previous work on the integration of model versioning tools with delta-oriented development of MBSPLs. Our solution is agnostic of the modeling language and may be easily extended by additional quality metrics and refactorings. We illustrate our approach using a delta-oriented MBSPL from the automation domain.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {84–91},
numpages = {8},
keywords = {refactoring, quality assurance, model-based software product line, delta modeling},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1145/2019136.2019139,
author = {Passos, Leonardo and Novakovic, Marko and Xiong, Yingfei and Berger, Thorsten and Czarnecki, Krzysztof and W\k{a}sowski, Andrzej},
title = {A study of non-Boolean constraints in variability models of an embedded operating system},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019139},
doi = {10.1145/2019136.2019139},
abstract = {Many variability modeling tasks can be supported by automated analyses of models. Unfortunately, most analyses for Boolean variability models are NP-hard, while analyses for non-Boolean models easily become undecidable. It is thus crucial to exploit the properties of realistic models to construct viable analysis algorithms. Unfortunately, little work exists about non-Boolean models, and no benchmarks are available for such.We present the non-Boolean aspects of 116 variability models available in the codebase of eCos---a real time embedded operating system. We characterize the types of non-Boolean features in the models, kinds and quantities of non-Boolean constraints in use, and the impact of these characteristics on the hardness of this model from analysis perspective. This way we provide researchers and practitioners with a basis for discussion of relevance of non-Boolean models and their analyses, along with the first ever benchmark for effectiveness of such analyses.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {2},
numpages = {8},
keywords = {variability modeling, feature models, decision models, automated model analysis},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3510466.3510470,
author = {Greiner, Sandra and Nieke, Michael and Seidl, Christoph},
title = {Towards Trace-Based Synchronization of Variability Annotations in Evolving Model-Driven Product Lines},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3510470},
doi = {10.1145/3510466.3510470},
abstract = {Annotative model-driven product lines allow to derive individual variants from a multi-variant model by exploiting annotations. Those declare the presence of each model element in a specific set of variants via a logical expression over features and may change during evolution. This provokes the risk of introducing conflicts causing logically cohesive elements of different models to appear in diverging sets of variants, which threatens the consistency of the product line. Existing work on propagating annotations across models employs the comparatively simple strategy of either overwriting or manually protecting any changed annotation in the target model but does not consider a backward propagation nor any form of synchronization. Therefore, we contribute a sophisticated method for synchronizing annotations which detects corresponding elements based on model transformation traces and resolves conflicting annotations by preserving syntactically different but semantically equal annotations according to the feature model. We demonstrate challenges and our solution method in a scenario of synchronizing two corresponding evolving multi-variant models.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {3},
numpages = {10},
keywords = {Software Evolution, Model-driven Software Product Line Engineering, Model Transformation},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/3468264.3468578,
author = {Oh, Jeho and Y\i{}ld\i{}ran, Necip Faz\i{}l and Braha, Julian and Gazzillo, Paul},
title = {Finding broken Linux configuration specifications by statically analyzing the Kconfig language},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468578},
doi = {10.1145/3468264.3468578},
abstract = {Highly-configurable software underpins much of our computing infrastructure. It enables extensive reuse, but opens the door to broken configuration specifications. The configuration specification language, Kconfig, is designed to prevent invalid configurations of the Linux kernel from being built. However, the astronomical size of the configuration space for Linux makes finding specification bugs difficult by hand or with random testing. In this paper, we introduce a software model checking framework for building Kconfig static analysis tools. We develop a formal semantics of the Kconfig language and implement the semantics in a symbolic evaluator called kclause that models Kconfig behavior as logical formulas. We then design and implement a bug finder, called kismet, that takes kclause models and leverages automated theorem proving to find unmet dependency bugs. kismet is evaluated for its precision, performance, and impact on kernel development for a recent version of Linux, which has over 140,000 lines of Kconfig across 28 architecture-specific specifications. Our evaluation finds 781 bugs (151 when considering sharing among Kconfig specifications) with 100% precision, spending between 37 and 90 minutes for each Kconfig specification, although it misses some bugs due to underapproximation. Compared to random testing, kismet finds substantially more true positive bugs in a fraction of the time.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {893–905},
numpages = {13},
keywords = {static analysis, software configuration, formal verification, Kconfig},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.5555/1753235.1753263,
author = {Than Tun, Thein and Boucher, Quentin and Classen, Andreas and Hubaux, Arnaud and Heymans, Patrick},
title = {Relating requirements and feature configurations: a systematic approach},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {A feature model captures various possible configurations of products within a product family. When configuring a product, several features are selected and composed. Selecting features at the program level has a general limitation of not being able to relate the resulting configuration to its requirements. As a result, it is difficult to decide whether a given configuration of features is optimal. An optimal configuration satisfies all stakeholder requirements and quantitative constraints, while ensuring that there is no extraneous feature in it. In relating requirements and feature configurations, we use the description of the problem world context in which the software is designed to operate as the intermediate description between them. The advantage of our approach is that feature selection can be done at the requirements level, and an optimal program level configuration can be generated from the requirements selected. Our approach is illustrated with a real-life problem of configuring a satellite communication software. The use of an existing tool to support our approach is also discussed.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {201–210},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1109/ASE56229.2023.00091,
author = {Xia, Yuanjie and Ding, Zishuo and Shang, Weiyi},
title = {CoMSA: A Modeling-Driven Sampling Approach for Configuration Performance Testing},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00091},
doi = {10.1109/ASE56229.2023.00091},
abstract = {Highly configurable systems enable customers to flexibly configure the systems in diverse deployment environments. The flexibility of configurations also poses challenges for performance testing. On one hand, there exist a massive number of possible configurations; while on the other hand, the time and resources are limited for performance testing, which is already a costly process during software development. Modeling the performance of configurations is one of the solutions to reduce the cost of configuration performance testing. Although prior research proposes various modeling and sampling techniques to build configuration performance models, the sampling approaches used in the model typically do not consider the accuracy of the performance models, leading to potential suboptimal performance modeling results in practice. In this paper, we present a modeling-driven sampling approach (CoMSA) to improve the performance modeling of highly configurable systems. The intuition of CoMSA is to select samples based on their uncertainties to the performance models. In other words, the configurations that have the more uncertain performance prediction results by the performance models are more likely to be selected as further training samples to improve the model. CoMSA is designed by considering both scenarios where 1) the software projects do not have historical performance testing results (cold start) and 2) there exist historical performance testing results (warm start). We evaluate the performance of our approach in four subjects, namely LRZIP, LLVM, x264, and SQLite. Through the evaluation result, we can conclude that our sampling approaches could highly enhance the accuracy of the prediction models and the efficiency of configuration performance testing compared to other baseline sampling approaches.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1352–1363},
numpages = {12},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.5555/1753235.1753274,
author = {Pech, Daniel and Knodel, Jens and Carbon, Ralf and Schitter, Clemens and Hein, Dirk},
title = {Variability management in small development organizations: experiences and lessons learned from a case study},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Product line practices promise to reduce development and maintenance efforts, to improve the productivity and to reduce the time to market by systematic reuse of commonalities and variabilities. However, in order to reap the fruits of exploiting those, an upfront investment is required. This paper presents a case study, which analyzes the cost-benefit ratio for one product line discipline -- variability management. Wikon GmbH -- a small German development organization evolving a product line of remote monitoring and controlling devices -- switched from manual, file-based conditional compilation to tool-supported decision models. We discuss experiences made and show that the break-even was reached with the 4th product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {285–294},
numpages = {10},
keywords = {decision model, evolution, product line engineering, software architecture, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2019136.2019140,
author = {Pichler, Christian and Huemer, Christian},
title = {Feature modeling for business document models},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019140},
doi = {10.1145/2019136.2019140},
abstract = {The United Nations Centre for Trace Facilitation and eBusiness (UN/CEFACT) provides a conceptual approach named Core Components for defining business document types based on generic, reusable building blocks. For facilitating interoperability in Electronic Data Interchange, these reusable building blocks are defined in an all-embracing manner. Accordingly, business partners customize the standard business document types for fitting their needs and requirements, resulting in different business document type variants. However, the approach is missing sufficient mechanisms for managing business document model variants. First, customizing standardized business document types is purely based on a textual specification. Second, the variability present within the Core Component approach lacks an explicit representation. In this paper, we aim at making variability explicit as well as adding a formal aspect to the business document type customization process by employing variability concepts from Product Line Engineering. Furthermore, based on having explicit variability models, business partners are provided with an approach for customizing business document types through configuring variability models.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {3},
numpages = {8},
keywords = {variability modeling, service-oriented architecture, feature modeling, business document models},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3652620.3687815,
author = {Raeisdanaei, Ali and Murphy, Logan and Di Sandro, Alessio and Askarpour, Mehrnoosh and Viger, Torin and Chechik, Marsha},
title = {Evaluation of Automotive OTA Updates Using Assurance Cases},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687815},
doi = {10.1145/3652620.3687815},
abstract = {Software-intensive vehicles require regular over-the-air (OTA) updates. To ensure that OTA updates do not compromise system safety, such updates should be assured. Automotive safety engineers need to efficiently estimate the effort it would take to assure these updates for the entire fleet. To address this challenge, we propose a process for supporting assurance of OTA updates. Our process proposes to model the fleet of vehicles as a software product line (SPL), assured with a variability-aware assurance case. It then measures the difficulty of assuring the proposed update using this variability-aware AC model via a set of heuristics.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {720–724},
numpages = {5},
keywords = {assurance, over-the-air updates, impact assessment},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.5555/1753235.1753265,
author = {Weston, Nathan and Chitchyan, Ruzanna and Rashid, Awais},
title = {A framework for constructing semantically composable feature models from natural language requirements},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Software Product Line Engineering (SPLE) requires the construction of feature models from large, unstructured and heterogeneous documents, and the reliable derivation of product variants from the resulting model. This can be an arduous task when performed manually, and can be error-prone in the presence of a change in requirements. In this paper we introduce a tool suite which automatically processes natural-language requirements documents into a candidate feature model, which can be refined by the requirements engineer. The framework also guides the process of identifying variant concerns and their composition with other features. We also provide language support for specifying semantic variant feature compositions which are resilient to change. We show that feature models produced by this framework compare favourably with those produced by domain experts by application to a real-life industrial example.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {211–220},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1145/54132.54135,
author = {Calabaugh, Jerry},
title = {Software configuration—an NP-complete problem},
year = {1988},
issue_date = {Summer 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {0095-0033},
url = {https://doi.org/10.1145/54132.54135},
doi = {10.1145/54132.54135},
abstract = {Configuration Control File (CCF) production is very complex, thousands of code packages, data blocks and parameter values must be linked under many constraints including:*Common data and code less than 8192 bytes*Maximum of 5 registers per task*All systems data must have common capabilitiesNP-complete problems are commonly known as knapsack or bin packing problems. They have no known algorithm which solves them in a time period bounded by a polynominal function of the number of inputs. Rules-of-thumb, or heuristics are the only practical approach to their solution. CCF segmentation to meet constraints discussed above is an example of Expert System technology applied to a classic NP-complete problem.Heuristics developed with traditional data processing techniques initially performed satisfactorily. However, as program development proceeded, Central Processor Unit (CPU) time for (CCF) production became a concern, both from a commitment of CPU resources and lost productivity. Traditional techniques failed to improve the heuristics and the project began to slip. Projected time to produce the CCF for a fully developed program was totally unacceptable, and jeopardized the project.Clearly another approach was required. Because existing hueristics were based on a concept of rules, research indicated an expert system using rules and a knowledge based approach had the highest probability of success.The paper emphasizes the development process of a knowledge based system from the perspective of the responsible project manager. The methodology is also applicable to common business problems.},
journal = {SIGMIS Database},
month = aug,
pages = {29–34},
numpages = {6}
}

@inproceedings{10.1145/2188286.2188304,
author = {Tawhid, Rasha and Petriu, Dorina},
title = {User-friendly approach for handling performance parameters during predictive software performance engineering},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188304},
doi = {10.1145/2188286.2188304},
abstract = {A Software Product Line (SPL) is a set of similar software systems that share a common set of features. Instead of building each product from scratch, SPL development takes advantage of the reusability of the core assets shared among the SPL members. In this work, we integrate performance analysis in the early phases of SPL development process, applying the same reusability concept to the performance annotations. Instead of annotating from scratch the UML model of every derived product, we propose to annotate the SPL model once with generic performance annotations. After deriving the model of a product from the family model by an automatic transformation, the generic performance annotations need to be bound to concrete product-specific values provided by the developer. Dealing manually with a large number of performance annotations, by asking the developer to inspect every diagram in the generated model and to extract these annotations is an error-prone process. In this paper we propose to automate the collection of all generic parameters from the product model and to present them to the developer in a user-friendly format (e.g., a spreadsheet per diagram, indicating each generic parameter together with guiding information that helps the user in providing concrete binding values). There are two kinds of generic parametric annotations handled by our approach: product-specific (corresponding to the set of features selected for the product) and platform-specific (such as device choices, network connections, middleware, and runtime environment). The following model transformations for (a) generating a product model with generic annotations from the SPL model, (b) building the spreadsheet with generic parameters and guiding information, and (c) performing the actual binding are all realized in the Atlas Transformation Language (ATL).},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {109–120},
numpages = {12},
keywords = {uml, spl, performance model, performance completion, model-driven development, marte, atl},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@article{10.1145/3088440,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {Teaching Software Product Lines: A Snapshot of Current Practices and Challenges},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
url = {https://doi.org/10.1145/3088440},
doi = {10.1145/3088440},
abstract = {Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving, as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, and what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. In this article, we report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, that is, an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {31},
keywords = {variability modeling, software product line teaching, software engineering teaching, Software product lines}
}

@inproceedings{10.1145/2771783.2771808,
author = {Tan, Tian Huat and Xue, Yinxing and Chen, Manman and Sun, Jun and Liu, Yang and Dong, Jin Song},
title = {Optimizing selection of competing features via feedback-directed evolutionary algorithms},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771808},
doi = {10.1145/2771783.2771808},
abstract = {Software that support various groups of customers usually require complicated configurations to attain different functionalities. To model the configuration options, feature model is proposed to capture the commonalities and competing variabilities of the product variants in software family or Software Product Line (SPL). A key challenge for deriving a new product is to find a set of features that do not have inconsistencies or conflicts, yet optimize multiple objectives (e.g., minimizing cost and maximizing number of features), which are often competing with each other. Existing works have attempted to make use of evolutionary algorithms (EAs) to address this problem. In this work, we incorporated a novel feedback-directed mechanism into existing EAs. Our empirical results have shown that our method has improved noticeably over all unguided version of EAs on the optimal feature selection. In particular, for case studies in SPLOT and LVAT repositories, the feedback-directed Indicator-Based EA (IBEA) has increased the number of correct solutions found by 72.33% and 75%, compared to unguided IBEA. In addition, by leveraging a pre-computed solution, we have found 34 sound solutions for Linux X86, which contains 6888 features, in less than 40 seconds.},
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {246–256},
numpages = {11},
keywords = {evolutionary algorithms, Software product line, SAT solvers},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@inproceedings{10.1145/2364412.2364442,
author = {Cavalcante, Everton and Almeida, Andr\'{e} and Batista, Thais and Cacho, N\'{e}lio and Lopes, Frederico and Delicato, Flavia C. and Sena, Thiago and Pires, Paulo F.},
title = {Exploiting software product lines to develop cloud computing applications},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364442},
doi = {10.1145/2364412.2364442},
abstract = {With the advance of the Cloud Computing paradigm, new challenges in terms of models, tools, and techniques to support developers to design, build and deploy complex software systems that make full use of the cloud technology arise. In the heterogeneous scenario of this new paradigm, the development of applications using cloud services becomes hard, and the software product lines (SPL) approach is potentially promising for this context since specificities of the cloud platforms, such as services heterogeneity, pricing model, and other aspects can be catered as variabilities to core features. In this perspective, this paper (i) proposes a seamless adaptation of the SPL-based development to include important features of cloud-based applications, and (ii) reports the experience of developing HW-CSPL, a SPL for the Health Watcher (HW) System, which allows citizens to register complaints and consult information regarding the public health system of a city. Several functionalities of this system were implemented using different Cloud Computing platforms, and run time specificities of this application deployed on the cloud were analyzed, as well as other information such as change impact and pricing.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {179–187},
numpages = {9},
keywords = {software product lines, services, health watcher system, cloud platforms, cloud computing},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {regularization, configurable systems, adversarial learning, Software performance prediction},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1145/24533.24544,
author = {Calabough, Jerry},
title = {Software configuration—an NP-complete problem},
year = {1987},
isbn = {0897912225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/24533.24544},
doi = {10.1145/24533.24544},
abstract = {Configuration Control File (CCF) production is very complex, thousands of code packages, data blocks and parameter values must be linked under many constraints including:
Common data and code less than 8192 bytesMaximum of 5 registers per taskAll systems data must have common capabilities
NP-complete problems are commonly known as knapsack or bin packing problems. They have no known algorithm which solves them in a time period bounded by a polynomial function of the number of inputs. Rules-of-thumb, or heuristics are the only practical approach to their solution. CCF segmentation to meet constraints discussed above is an example of Expert System technology applied to a classic NP-complete problem.Heuristics developed with traditional data processing techniques initially performed satisfactorily. However, as program development proceeded, Central Processor Unit (CPU) time for CCF production became a concern, both from a commitment of CPU resources and lost productivity. Traditional techniques failed to improve the heuristics and the project began to slip. Projected time to produce the CCF for a fully developed program was totally unacceptable, jeopardizing the project.Clearly another approach was required. Because existing heuristics were based on a concept of rules, research indicated an expert system using rules and a knowledge based approach had the highest probability of success.The paper emphasizes the development process of a knowledge based system from the perspective of the responsible project manager. The methodology is also applicable to common business problems.},
booktitle = {Proceedings of the Conference on The 1987 ACM SIGBDP-SIGCPR Conference},
pages = {182–194},
numpages = {13},
location = {Coral Gables, Florida, USA},
series = {SIGCPR '87}
}

@inproceedings{10.1145/2499777.2500721,
author = {Seidl, Christoph and Schaefer, Ina and A\ss{}mann, Uwe},
title = {Variability-aware safety analysis using delta component fault diagrams},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500721},
doi = {10.1145/2499777.2500721},
abstract = {Component Fault Diagrams (CFD) allow the specification of fault propagation paths, which is employed for the design of safety-critical systems as well as their certification. Even though families of safety-critical systems exist with many similar, yet not equal, variants there is no dedicated variability mechanism for CFDs to reuse commonalities of all family members and to alter only variable parts. In this paper, we present a variability representation approach for CFDs based on delta modeling that allows to transform an initial CFD within a closed or open variant space. Furthermore, we provide delta-aware analysis techniques for CFDs in order to analyse multiple variants efficiently. We show the feasibility of our approach by means of an example scenario based on the personal home robot TurtleBot using a prototypical implementation of our concepts.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {2–9},
numpages = {8},
keywords = {variability, software fault trees, safety, minimum cut set, delta modeling, component fault diagrams},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2361999.2362028,
author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
title = {Modeling variability in product lines using domain quality attribute scenarios},
year = {2012},
isbn = {9781450315685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2361999.2362028},
doi = {10.1145/2361999.2362028},
abstract = {The concept of variability is fundamental in software product lines and a successful implementation of a product line largely depends on how well domain requirements and their variability are specified, managed, and realized. While developing an educational software product line, we identified a lack of support to specify variability in quality concerns. To address this problem we propose an approach to model variability in quality concerns, which is an extension of quality attribute scenarios. In particular, we propose domain quality attribute scenarios, which extend standard quality attribute scenarios with additional information to support specification of variability and deriving product specific scenarios. We demonstrate the approach with scenarios for robustness and upgradability requirements in the educational software product line.},
booktitle = {Proceedings of the WICSA/ECSA 2012 Companion Volume},
pages = {135–142},
numpages = {8},
keywords = {variability, software product lines, scenarios, quality attributes},
location = {Helsinki, Finland},
series = {WICSA/ECSA '12}
}

@inproceedings{10.1145/2425415.2425420,
author = {Eyal-Salman, Hamzeh and Seriai, Abdelhak-Djamel and Dony, Christophe and Al-msie'deen, Ra'fat},
title = {Recovering traceability links between feature models and source code of product variants},
year = {2012},
isbn = {9781450318099},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2425415.2425420},
doi = {10.1145/2425415.2425420},
abstract = {Usually software product variants, developed by clone-and-own approach, form often a starting point for building Software Product Line (SPL). To migrate software products that deemed similar into a product line, it is essential to trace variability among software artifacts because the distinguishing factor between traditional software engineering and software product line engineering is the variability. Variability tracing is used to support conversion from traditional software development into software product line development and automate products derivation process such that core assets can be automatically configured for a product according to the features selection from the feature model. Tracing and maintaining interrelationships between artifacts within a software system also are needed to facilitate program comprehension, make the process of maintaining the system less dependent on individual experts. This paper presents a method based on information retrieval approach namely, latent semantic indexing, to establish traceability links between object-oriented source code of product variants and their feature model as representative of variability model.},
booktitle = {Proceedings of the VARiability for You Workshop: Variability Modeling Made Useful for Everyone},
pages = {21–25},
numpages = {5},
keywords = {variability, traceability links, source code, software product line, latent semantic indexing, feature models},
location = {Innsbruck, Austria},
series = {VARY '12}
}

@article{10.1145/2580950,
author = {Th\"{u}m, Thomas and Apel, Sven and K\"{a}stner, Christian and Schaefer, Ina and Saake, Gunter},
title = {A Classification and Survey of Analysis Strategies for Software Product Lines},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2580950},
doi = {10.1145/2580950},
abstract = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {6},
numpages = {45},
keywords = {type checking, theorem proving, static analysis, software product line, software analysis, program family, model checking, Product-line analysis}
}

@inproceedings{10.1145/2556624.2556631,
author = {Dintzner, Nicolas and Van Deursen, Arie and Pinzger, Martin},
title = {Extracting feature model changes from the Linux kernel using FMDiff},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556631},
doi = {10.1145/2556624.2556631},
abstract = {The Linux kernel feature model has been studied as an example of large scale evolving feature model and yet details of its evolution are not known. We present here a classification of feature changes occurring on the Linux kernel feature model, as well as a tool, FMDiff, designed to automatically extract those changes. With this tool, we obtained the history of more than twenty architecture specific feature models, over ten releases and compared the recovered information with Kconfig file changes. We establish that FMDiff provides a comprehensive view of feature changes and show that the collected data contains promising information regarding the Linux feature model evolution.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {22},
numpages = {8},
keywords = {software product line, feature model, evolution},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/302405.302409,
author = {DeBaud, Jean-Marc and Schmid, Klaus},
title = {A systematic approach to derive the scope of software product lines},
year = {1999},
isbn = {1581130740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302405.302409},
doi = {10.1145/302405.302409},
booktitle = {Proceedings of the 21st International Conference on Software Engineering},
pages = {34–43},
numpages = {10},
keywords = {software product line, reuse economic models, product line scoping, domain engineering},
location = {Los Angeles, California, USA},
series = {ICSE '99}
}

@inproceedings{10.1145/2814251.2814263,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Th\"{u}m, Thomas},
title = {Using decision rules for solving conflicts in extended feature models},
year = {2015},
isbn = {9781450336864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814251.2814263},
doi = {10.1145/2814251.2814263},
abstract = {Software Product Line Engineering has introduced feature modeling as a domain analysis technique used to represent the variability of software products and decision-making scenarios. We present a model-based transformation approach to solve conflicts among configurations performed by different stakeholders on feature models. We propose the usage of a domain-specific language named CoCo to specify attributes as non-functional properties of features, and to describe business-related decision rules in terms of costs, time, and human resources. These specifications along with the stakeholders' configurations and the feature model are transformed into a constraint programming problem, on which decision rules are executed to find a non-conflicting set of solution configurations that are aligned to business objectives. We evaluate CoCo's compositionality and model complexity simplification while using a set of motivating decision scenarios.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {149–160},
numpages = {12},
keywords = {model transformation chain, extended feature model, domain-specific language, constraint satisfaction problem, conflicting configurations, Domain engineering},
location = {Pittsburgh, PA, USA},
series = {SLE 2015}
}

@inproceedings{10.1145/3302333.3302341,
author = {Greiner, Sandra and Westfechtel, Bernhard},
title = {On Determining Variability Annotations In Partially Annotated Models},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302341},
doi = {10.1145/3302333.3302341},
abstract = {In model-driven software product line engineering (SPLE) the superset of products is developed over models. A feature model typically states the discriminating and common factors of the software. In annotative approaches model elements are associated with variability annotations which are boolean expressions over the features defining in which products the elements are visible. When the product line is defined over different models, the developer wants to annotate the model of one type and transform it to different representations, e.g., a (UML) class diagram into a relational database schema for establishing an object-relational mapping. Assigning the annotations manually to the target model is an error-prone and laborious task. In a black-box approach we automatically assign the correct annotations to the target model without analyzing the transformation specification. It is an easy task in the case of 1:1 mappings where the annotation of the source element is copied to the corresponding element in the target model. Typically this kind of information is available, e.g., in traces written during the transformation execution. In reality, more complex mappings are frequent but the correspondences harder to determine. Assuming a target model is already annotated with the annotation of 1:1 correspondences, a certain number of elements remains without annotations. This paper contributes strategies to determine missing annotations in partially annotated models. We compare a global include strategy with more sophisticated ones which take the model structure into account. Since we apply missing annotations locally on one model, we solve a general SPLE problem where completely annotated models reduce the manual user effort and are desirable for filtering.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {17},
numpages = {10},
keywords = {software evolution, feature propagation, annotative approach, Model-driven Software Product Line Engineering, (multi-variant) model transformations},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/2110147.2110166,
author = {M\ae{}rsk-M\o{}ller, Hans Martin and J\o{}rgensen, Bo N\o{}rregaard},
title = {Cardinality-dependent variability in orthogonal variability models},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110166},
doi = {10.1145/2110147.2110166},
abstract = {During our work on developing and running a software product line for eco-sustainable greenhouse-production software tools, which currently have three products members we have identified a need for extending the notation of the Orthogonal Variability Model (OVM) to support what we refer to as cardinality range dependencies. The cardinality-range-dependency type enables expressing that the binding of a certain number of variants to a variation point can influence variability in other places in the model. In other words, we acknowledge that variability can be influenced, not necessarily by the specific variants being bound, but by their sheer numbers.This paper contributes with an extension to the meta-model underlying the OVM notation, suggesting a notation for the new type of dependency and shows its applicability. The specific case, which initially required this extension, will work as running example throughout the paper and underline the need for the extension. Finally, the paper evaluates and discusses the general applicability of the proposed notation extension and future perspectives.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {165–172},
numpages = {8},
keywords = {variability modeling language, software product line engineering, orthogonal variability model (OVM), documentation},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@article{10.1145/2579281.2579294,
author = {Castelluccia, Daniela and Boffoli, Nicola},
title = {Service-oriented product lines: a systematic mapping study},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2579281.2579294},
doi = {10.1145/2579281.2579294},
abstract = {Software product line engineering and service-oriented architectures both enable organizations to capitalize on reuse of existing software assets and capabilities and improve competitive advantage in terms of development savings, product flexibility, time-to-market. Both approaches accommodate variation of assets, including services, by changing the software being reused or composing services according a new orchestration. Therefore, variability management in Service-oriented Product Lines (SoPL) is one of the main challenges today. In order to highlight the emerging evidence-based results from the research community, we apply the well-defined method of systematic mapping in order to populate a classification scheme for the SoPL field of interest. The analysis of results throws light on the current open issues. Moreover, different facets of the scheme can be combined to answer more specific research questions. The report reveals the need for more empirical research able to provide new metrics measuring efficiency and efficacy of the proposed models, new methods and tools supporting variability management in SoPL, especially during maintenance and verification and validation. The mapping study about SoPL opens further investigations by means of a complete systematic review to select and validate the most efficient solutions to variability management in SoPL.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {1–6},
numpages = {6},
keywords = {variability management, software product line, service-oriented computing, service-oriented architecture, product line development, mapping study, empirical study}
}

@inproceedings{10.1145/3510455.3512792,
author = {Randrianaina, Georges Aaron and Khelladi, Djamel Eddine and Zendra, Olivier and Acher, Mathieu},
title = {Towards incremental build of software configurations},
year = {2022},
isbn = {9781450392242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510455.3512792},
doi = {10.1145/3510455.3512792},
abstract = {Building software is a crucial task to compile, test, and deploy software systems while continuously ensuring quality. As software is more and more configurable, building multiple configurations is a pressing need, yet, costly and challenging to instrument. The common practice is to independently build (a.k.a., clean build) a software for a subset of configurations. While incremental build has been considered for software evolution and relatively small modifications of the source code, it has surprisingly not been considered for software configurations. In this vision paper, we formulate the hypothesis that incremental build can reduce the cost of exploring the configuration space of software systems. We detail how we apply incremental build for two real-world application scenarios and conduct a preliminary evaluation on two case studies, namely x264 and Linux Kernel. For x264, we found that one can incrementally build configurations in an order such that overall build time is reduced. Nevertheless, we could not find any optimal order with the Linux Kernel, due to a high distance between random configurations. Therefore, we show it is possible to control the process of generating configurations: we could reuse commonality and gain up to 66% of build time compared to only clean builds.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {101–105},
numpages = {5},
keywords = {incremental build, highly configurable system, build system},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-NIER '22}
}

@article{10.1145/1183236.1183260,
author = {Sugumaran, Vijayan and Park, Sooyong and Kang, Kyo C.},
title = {Introduction},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183260},
doi = {10.1145/1183236.1183260},
journal = {Commun. ACM},
month = dec,
pages = {28–32},
numpages = {5}
}

@inproceedings{10.1145/3644815.3644965,
author = {Barreto Simedo Pacheco, Lorena and Rahman, Musfiqur and Rabbi, Fazle and Fathollahzadeh, Pouya and Abdellatif, Ahmad and Shihab, Emad and Chen, Tse-Hsun (Peter) and Yang, Jinqiu and Zou, Ying},
title = {DVC in Open Source ML-development: The Action and the Reaction},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644965},
doi = {10.1145/3644815.3644965},
abstract = {Machine Learning (ML) systems are gaining popularity, reshaping various domains ranging from customer services to software engineering. The effectiveness of ML systems is dependent on the quality of their training data. Therefore, practitioners invest substantial time experimenting with different data, parameters, and models to guarantee the quality of the end system. Prior work highlighted unique challenges of developing ML systems, particularly concerning versioning data and models. Recently, various tools such as DVC and MLFlow have emerged to aid developers in the storage and tracking of data. Despite their growing popularity, very little is known about their usage patterns and impact on open-source software (OSS) systems. To address this gap, we conducted an empirical study on 56 GitHub OSS projects that use DVC to understand the DVC usage pattern and the impact of using DVC on the software development process. We found that Versioning and tracking is the most adopted DVC feature, being utilized by all 56 projects and being the only adopted feature in 85.7% of them. Furthermore, we found that DVC has a significant impact on the software development process indicators such as the number of created pull requests (PRs), and the number of bug-fix commits. For instance, our findings showed that DVC causes a peak in the number of commits and PRs at the moment of the adoption, followed by a long-term decrease. We believe that our findings can assist practitioners in tailoring tools to better meet user requirements and help organizations realize potential outcomes of adopting such tools.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {75–80},
numpages = {6},
keywords = {empirical software engineering, data version control, software evolution, SE4AI},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/2556624.2556637,
author = {Machado, Ivan do Carmo and Santos, Alcemir Rodrigues and Cavalcanti, Yguarat\~{a} Cerqueira and Trzan, Eduardo Gomes and de Souza, Marcio Magalh\~{a}es and de Almeida, Eduardo Santana},
title = {Low-level variability support for web-based software product lines},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556637},
doi = {10.1145/2556624.2556637},
abstract = {The Web systems domain has faced an increasing number of devices, browsers, and platforms to cope with, driving software systems to be more flexible to accomodate them. Software product line (SPL) engineering can be used as a strategy to implement systems capable of handling such a diversity. To this end, automated tool support is almost indispensable. However, current tool support gives more emphasis to modeling variability in the problem domain, over the support of variability at the solution domain. There is a need for mapping the variability between both abstraction levels, so as to determine what implementation impact a certain variability has. In this paper, we propose the FeatureJS, a FeatureIDE extension aiming at Javascript and HTML support for SPL engineering. The tool combines feature-oriented programming and preprocessors, as a strategy to map variability at source code with the variability modeled at a higher level of abstraction. We carried out a preliminary evaluation with an industrial project, aiming to characterize the capability of the tool to handle SPL engineering in the Web systems domain.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {8},
keywords = {web systems domain, software product line engineering, feature oriented software development, feature composition, FeatureIDE, Eclipse plugin},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/3023956.3023959,
author = {Ochoa, Lina and Pereira, Juliana Alves and Gonz\'{a}lez-Rojas, Oscar and Castro, Harold and Saake, Gunter},
title = {A survey on scalability and performance concerns in extended product lines configuration},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023959},
doi = {10.1145/3023956.3023959},
abstract = {Product lines have been employed as a mass customisation method that reduces production costs and time-to-market. Multiple product variants are represented in a product line, however the selection of a particular configuration depends on stakeholders' functional and non-functional requirements. Methods like constraint programming and evolutionary algorithms have been used to support the configuration process. They consider a set of product requirements like resource constraints, stakeholders' preferences, and optimization objectives. Nevertheless, scalability and performance concerns start to be an issue when facing large-scale product lines and runtime environments. Thus, this paper presents a survey that analyses strengths and drawbacks of 21 approaches that support product line configuration. This survey aims to: i) evidence which product requirements are currently supported by studied methods; ii) how scalability and performance is considered in existing approaches; and iii) point out some challenges to be addressed in future research.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {5–12},
numpages = {8},
keywords = {survey, scalability, product requirements, product line, performance, literature review, configuration},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1109/ICSE43902.2021.00147,
author = {Mahmood, Wardah and Str\"{u}ber, Daniel and Berger, Thorsten and L\"{a}mmel, Ralf and Mukelabai, Mukelabai},
title = {Seamless Variability Management With the Virtual Platform},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00147},
doi = {10.1109/ICSE43902.2021.00147},
abstract = {Customization is a general trend in software engineering, demanding systems that support variable stakeholder requirements. Two opposing strategies are commonly used to create variants: software clone&amp;own and software configuration with an integrated platform. Organizations often start with the former, which is cheap, agile, and supports quick innovation, but does not scale. The latter scales by establishing an integrated platform that shares software assets between variants, but requires high up-front investments or risky migration processes. So, could we have a method that allows an easy transition or even combine the benefits of both strategies? We propose a method and tool that supports a truly incremental development of variant-rich systems, exploiting a spectrum between both opposing strategies. We design, formalize, and prototype the variability-management framework virtual platform. It bridges clone&amp;own and platform-oriented development. Relying on programming-language-independent conceptual structures representing software assets, it offers operators for engineering and evolving a system, comprising: traditional, asset-oriented operators and novel, feature-oriented operators for incrementally adopting concepts of an integrated platform. The operators record meta-data that is exploited by other operators to support the transition. Among others, they eliminate expensive feature-location effort or the need to trace clones. Our evaluation simulates the evolution of a real-world, clone-based system, measuring its costs and benefits.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1658–1670},
numpages = {13},
keywords = {variability management, software product lines, re-engineering, framework, clone management},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3510466.3511272,
author = {Kuiter, Elias and Kn\"{u}ppel, Alexander and Bordis, Tabea and Runge, Tobias and Schaefer, Ina},
title = {Verification Strategies for Feature-Oriented Software Product Lines},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3511272},
doi = {10.1145/3510466.3511272},
abstract = {Highly-customizable software systems in form of software product lines are becoming increasingly relevant for safety-critical systems, in which the correctness of software is a major concern. To ensure the correct behavior of a software product line, each product can be verified in isolation—however, this strategy quickly becomes infeasible for a large number of products. In this paper, we propose proof plans, a novel strategy for verifying feature-oriented software product lines based on partial proofs. Our technique splits the verification task into small proofs that can be reused across method variants, which gives rise to a wider spectrum of verification strategies for software product lines. We describe applications of our technique and evaluate one of them on a case study by comparing it with established verification strategies.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {12},
numpages = {9},
keywords = {Software Product Lines, Proof Reuse, Deductive Verification},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/3350768.3350774,
author = {Souza, Iuri Santos and Machado, Ivan and Seaman, Carolyn and Gomes, Gecynalda and Chavez, Christina and de Almeida, Eduardo Santana and Masiero, Paulo},
title = {Investigating Variability-aware Smells in SPLs: An Exploratory Study},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350774},
doi = {10.1145/3350768.3350774},
abstract = {Variability-aware smell is a concept referring to artifact shortcomings in the context of highly-configurable systems that can degrade aspects such as program comprehension, maintainability, and evolvability. To the best of our knowledge, there is very little evidence that variability-aware smells exist in Software Product Lines (SPLs). This work presents an exploratory study that investigated (I) evidence that variability-aware smells exist in SPLs and (II) new types of variability-aware smell not yet documented in the literature based on a quantitative study with open source SPL projects. We collected quantitative data to generate reliable research evidence, by performing feature model and source code inspections on eleven open-source SPL projects. Our findings revealed that (1) instances of variability-aware smells exist in open-source SPL projects and (2) feature information presented significant associations with variability-aware smells. Furthermore, (3) the study presented six new types of variability-aware smells.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {367–376},
numpages = {10},
keywords = {Variability-Aware Smells, Software Product Lines, Exploratory Study, Empirical Study},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1145/1385486.1385488,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Schirmeier, Horst and Sincero, Julio and Apel, Sven and Leich, Thomas and Spinczyk, Olaf and Saake, Gunter},
title = {FAME-DBMS: tailor-made data management solutions for embedded systems},
year = {2008},
isbn = {9781595939647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385486.1385488},
doi = {10.1145/1385486.1385488},
abstract = {Data management functionality is not only needed in large-scale server systems, but also in embedded systems. Resource restrictions and heterogeneity of hardware, however, complicate the development of data management solutions for those systems. In current practice, this typically leads to the redevelopment of data management because existing solutions cannot be reused and adapted appropriately. In this paper, we present our ongoing work on FAME-DBMS, a research project that explores techniques to implement highly customizable data management solutions, and illustrate how such systems can be created with a software product line approach. With this approach a concrete instance of a DBMS is derived by composing features of the DBMS product line that are needed for a specific application scenario. This product derivation process is getting complex if a large number of features is available. Furthermore, in embedded systems also non-functional properties, e.g., memory consumption, have to be considered when creating a DBMS instance. To simplify the derivation process we present approaches for its automation.},
booktitle = {Proceedings of the 2008 EDBT Workshop on Software Engineering for Tailor-Made Data Management},
pages = {1–6},
numpages = {6},
location = {Nantes, France},
series = {SETMDM '08}
}

@inproceedings{10.1145/2786805.2786845,
author = {Siegmund, Norbert and Grebhahn, Alexander and Apel, Sven and K\"{a}stner, Christian},
title = {Performance-influence models for highly configurable systems},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786845},
doi = {10.1145/2786805.2786845},
abstract = {Almost every complex software system today is configurable. While configurability has many benefits, it challenges performance prediction, optimization, and debugging. Often, the influences of individual configuration options on performance are unknown. Worse, configuration options may interact, giving rise to a configuration space of possibly exponential size. Addressing this challenge, we propose an approach that derives a performance-influence model for a given configurable system, describing all relevant influences of configuration options and their interactions. Our approach combines machine-learning and sampling heuristics in a novel way. It improves over standard techniques in that it (1) represents influences of options and their interactions explicitly (which eases debugging), (2) smoothly integrates binary and numeric configuration options for the first time, (3) incorporates domain knowledge, if available (which eases learning and increases accuracy), (4) considers complex constraints among options, and (5) systematically reduces the solution space to a tractable size. A series of experiments demonstrates the feasibility of our approach in terms of the accuracy of the models learned as well as the accuracy of the performance predictions one can make with them.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {284–294},
numpages = {11},
keywords = {sampling, machine learning, Performance-influence models},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3510003.3510200,
author = {Dubslaff, Clemens and Weis, Kallistos and Baier, Christel and Apel, Sven},
title = {Causality in configurable software systems},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510200},
doi = {10.1145/3510003.3510200},
abstract = {Detecting and understanding reasons for defects and inadvertent behavior in software is challenging due to their increasing complexity. In configurable software systems, the combinatorics that arises from the multitude of features a user might select from adds a further layer of complexity. We introduce the notion of feature causality, which is based on counterfactual reasoning and inspired by the seminal definition of actual causality by Halpern and Pearl. Feature causality operates at the level of system configurations and is capable of identifying features and their interactions that are the reason for emerging functional and non-functional properties. We present various methods to explicate these reasons, in particular well-established notions of responsibility and blame that we extend to the feature-oriented setting. Establishing a close connection of feature causality to prime implicants, we provide algorithms to effectively compute feature causes and causal explications. By means of an evaluation on a wide range of configurable software systems, including community benchmarks and real-world systems, we demonstrate the feasibility of our approach: We illustrate how our notion of causality facilitates to identify root causes, estimate the effects of features, and detect feature interactions.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {325–337},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1145/3689747,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Moosherr, Benjamin and Young, Jeffrey M. and Teixeira, Leopoldo and Walkingshaw, Eric and Ataei, Parisa and Th\"{u}m, Thomas},
title = {On the Expressive Power of Languages for Static Variability},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689747},
doi = {10.1145/3689747},
abstract = {Variability permeates software development to satisfy ever-changing requirements and mass-customization needs. A prime example is the Linux kernel, which employs the C preprocessor to specify a set of related but distinct kernel variants. To study, analyze, and verify variational software, several formal languages have been proposed. For example, the choice calculus has been successfully applied for type checking and symbolic execution of configurable software, while other formalisms have been used for variational model checking, change impact analysis, among other use cases. Yet, these languages have not been formally compared, hence, little is known about their relationships. Crucially, it is unclear to what extent one language subsumes another, how research results from one language can be applied to other languages, and which language is suitable for which purpose or domain. In this paper, we propose a formal framework to compare the expressive power of languages for static (i.e., compile-time) variability. By establishing a common semantic domain to capture a widely used intuition of explicit variability, we can formulate the basic, yet to date neglected, properties of soundness, completeness, and expressiveness for variability languages. We then prove the (un)soundness and (in)completeness of a range of existing languages, and relate their ability to express the same variational systems. We implement our framework as an extensible open source Agda library in which proofs act as correct compilers between languages or differencing algorithms. We find different levels of expressiveness as well as complete and incomplete languages w.r.t. our unified semantic domain, with the choice calculus being among the most expressive languages.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {307},
numpages = {33},
keywords = {configuration, language semantics, software product lines, variation}
}

@inproceedings{10.1109/ICSE43902.2021.00029,
author = {Zhang, Yuanliang and He, Haochen and Legunsen, Owolabi and Li, Shanshan and Dong, Wei and Xu, Tianyin},
title = {An Evolutionary Study of Configuration Design and Implementation in Cloud Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00029},
doi = {10.1109/ICSE43902.2021.00029},
abstract = {Many techniques were proposed for detecting software misconfigurations in cloud systems and for diagnosing unintended behavior caused by such misconfigurations. Detection and diagnosis are steps in the right direction: misconfigurations cause many costly failures and severe performance issues. But, we argue that continued focus on detection and diagnosis is symptomatic of a more serious problem: configuration design and implementation are not yet first-class software engineering endeavors in cloud systems. Little is known about how and why developers evolve configuration design and implementation, and the challenges that they face in doing so.This paper presents a source-code level study of the evolution of configuration design and implementation in cloud systems. Our goal is to understand the rationale and developer practices for revising initial configuration design/implementation decisions, especially in response to consequences of misconfigurations. To this end, we studied 1178 configuration-related commits from a 2.5 year version-control history of four large-scale, actively-maintained open-source cloud systems (HDFS, HBase, Spark, and Cassandra). We derive new insights into the software configuration engineering process. Our results motivate new techniques for proactively reducing misconfigurations by improving the configuration design and implementation process in cloud systems. We highlight a number of future research directions.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {188–200},
numpages = {13},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3510003.3510190,
author = {Randrianaina, Georges Aaron and T\"{e}rnava, Xhevahire and Khelladi, Djamel Eddine and Acher, Mathieu},
title = {On the benefits and limits of incremental build of software configurations: an exploratory study},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510190},
doi = {10.1145/3510003.3510190},
abstract = {Software projects use build systems to automate the compilation, testing, and continuous deployment of their software products. As software becomes increasingly configurable, the build of multiple configurations is a pressing need, but expensive and challenging to implement. The current state of practice is to build independently (a.k.a., clean build) a software for a subset of configurations. While incremental build has been studied for software evolution and relatively small changes of the source code, it has surprisingly not been considered for software configurations. In this exploratory study, we examine the benefits and limits of building software configurations incrementally, rather than always building them cleanly. By using five real-life configurable systems as subjects, we explore whether incremental build works, outperforms a sequence of clean builds, is correct w.r.t. clean build, and can be used to find an optimal ordering for building configurations. Our results show that incremental build is feasible in 100% of the times in four subjects and in 78% of the times in one subject. In average, 88.5% of the configurations could be built faster with incremental build while also finding several alternatives faster incremental builds. However, only 60% of faster incremental builds are correct. Still, when considering those correct incremental builds with clean builds, we could always find an optimal order that is faster than just a collection of clean builds with a gain up to 11.76%.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1584–1596},
numpages = {13},
keywords = {build systems, configurable software systems, configuration build},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/2973839.2973852,
author = {Santos, Ismayle S. and Rocha, Lincoln S. and Neto, Pedro A. Santos and Andrade, Rossana M. C.},
title = {Model Verification of Dynamic Software Product Lines},
year = {2016},
isbn = {9781450342018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973839.2973852},
doi = {10.1145/2973839.2973852},
abstract = {Dynamic Software Product Lines (DSPLs) extend the concept of Software Product Lines enabling adaptation at runtime according to context changes. Such dynamic behavior is typically designed using adaptation rules, context-triggered actions responsible for features activation and deactivation at runtime. The erroneous specification and the interleaving of adaptation rules (i.e., the parallel execution of adaptation rules) can lead DSPL to reach an undesired (improperly or defective) product configuration at runtime. Thus, in order to improve the reliability of DSPL behavior, design faults must be rigorously identified and eliminated in the early stages of DSPL development. In this paper, we address this issue introducing Dynamic Feature Transition Systems (DFTSs) that allow the modeling and formal verification of the DSPLs adaptive behavior. These transition systems are derived from the adaptation rules and a Context Kripke Structure, which is a context evolution model. Furthermore, we formally define five properties that can be used to identify existing design faults in DSPL design. Aiming to assess the feasibility of our approach, a feasibility study was conducted using two DSPLs, Mobile Visit Guides and Car. In both cases, design faults were automatically detected indicating that our formalism can help in the detection of design faults in the DSPLs adaptive behavior.},
booktitle = {Proceedings of the XXX Brazilian Symposium on Software Engineering},
pages = {113–122},
numpages = {10},
keywords = {Software Verification, Software Reliability, Model Checking, Dynamic Software Product Line},
location = {Maring\'{a}, Brazil},
series = {SBES '16}
}

@inproceedings{10.1145/3344948.3344964,
author = {Kerdoudi, Mohamed Lamine and Ziadi, Tewfik and Tibermacine, Chouki and Sadou, Salah},
title = {A bottom-up approach for reconstructing software architecture product lines},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344964},
doi = {10.1145/3344948.3344964},
abstract = {A large component and service-based software system exists in different forms, as different variants targeting different business needs and users. This kind of systems is provided as a set of "independent" products and not as a "single whole". The presence of a single model describing the architecture of the whole system may be of great interest for developers of future variants. Indeed, this enables them to see the invariant part of the whole, on top of which new functionality can be built, in addition to the different options they can use. We investigate in this work the use of software product line reverse engineering approaches, and in particular the framework named BUT4Reuse, for reconstructing an architecture model of a Software Architecture Product Line (SAPL), from a set of variants. We propose a generic process for reconstructing an architecture model of such a product line. We have instantiated this process for the OSGi Java framework and experimented it for building the architecture model of Eclipse IDE SPL.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {46–49},
numpages = {4},
location = {Paris, France},
series = {ECSA '19}
}

@inproceedings{10.1145/3639477.3639750,
author = {Wang, Zikuan and Liu, Bohan and Zhan, Zeye and Zhang, He and Li, Gongyuan},
title = {An Ethnographic Study on the CI of A Large Scale Project},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639750},
doi = {10.1145/3639477.3639750},
abstract = {Continuous Integration (CI) is the foundation for achieving rapid iteration and short-cycle delivery. To achieve CI, a series of best practices and solutions have been proposed, which are referred to as patterns. However, there is a natural contradiction between the speed and continuity pursued by CI and the ever-expanding project scale and complexity. Various factors such as project size, outdated system architecture, complex organizational structure, or limited server resources can all lead to deviations from patterns in CI practices, resulting in anti-patterns. We conducted an ethnographic research to investigate the current state, anti-patterns, and challenges in resolving anti-patterns of the CI process within a large communication project at a globally leading IT company. We conducted a deep observation and participation in the project for seven months and conducted multiple rounds of interviews with related developers in the company. The project adopts a CI pipeline that has a three-level hierarchical structure. We evaluated the company's software development practices based on the pattern list. We identified three anti-patterns that contradicted the patterns listed, and we also discovered three new anti-patterns that were not on the list. Further, we analyzed the challenges of solving these anti-patterns. Additionally, we found seven better practices and analyzed why they are better.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {287–297},
numpages = {11},
keywords = {continuous integration, ethnographic study, anti-patterns, best practice},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3183440.3183499,
author = {Mukelabai, Mukelabai and Behringer, Benjamin and Fey, Moritz and Palz, Jochen and Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {Multi-view editing of software product lines with PEoPL},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183499},
doi = {10.1145/3183440.3183499},
abstract = {A software product line is a portfolio of software variants in an application domain. It relies on a platform integrating common and variable features of the variants using variability mechanisms---typically classified into annotative and compositional mechanisms. Annotative mechanisms (e.g., using the C preprocessor) are easy to apply, but annotations clutter source code and feature code is often scattered across the platform, which hinders program comprehension and increases maintenance effort. Compositional mechanisms (e.g., using feature modules) support program comprehension and maintainability by modularizing feature code, but are difficult to adopt. Most importantly, engineers need to choose one mechanism and then stick to it for the whole life cycle of the platform. The PEoPL (Projectional Editing of Product Lines) approach combines the advantages of both kinds of mechanisms. In this paper, we demonstrate the PEoPL IDE, which supports the approach by providing various kinds of editable views, each of which represents the same software product line using annotative or compositional variability mechanisms, or subsets of concrete variants. Software engineers can seamlessly switch these views, or use multiple views side-by-side, based on the current engineering task. A demo video of PEoPL is available at Youtube: https://youtu.be/wByUxSPLoSY},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {81–84},
numpages = {4},
keywords = {annotative, modular, product lines, projectional editing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1145/3034827,
author = {Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
title = {CASE Tool Support for Variability Management in Software Product Lines},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3034827},
doi = {10.1145/3034827},
abstract = {Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools’ characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {14},
numpages = {45},
keywords = {software variability, computer-aided software engineering, Software engineering}
}

@inproceedings{10.1145/3650212.3680339,
author = {Huang, Kaifeng and Xia, Yingfeng and Chen, Bihuan and He, Siyang and Zeng, Huazheng and Zhou, Zhuotong and Guo, Jin and Peng, Xin},
title = {Your “Notice” Is Missing: Detecting and Fixing Violations of Modification Terms in Open Source Licenses during Forking},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680339},
doi = {10.1145/3650212.3680339},
abstract = {Open source software brings benefit to the software community but also introduces legal risks caused by license violations, which result in serious consequences such as lawsuits and financial losses. To mitigate legal risks, some approaches have been proposed to identify licenses, detect license incompatibilities and inconsistencies, and recommend licenses. As far as we know, however, there is no prior work to understand modification terms in open source licenses or to detect and fix violations of modification terms.
 
 
 
 
 
 
 

 
 
 
 
 
 
 
To bridge this gap, we first empirically characterize modification terms in 48 open source licenses. These licenses all require certain forms of “notice” to describe the modifications made to the original work. Inspired by our study, we then design LiVo to automatically detect and fix violations of modification terms in open source licenses during forking. Our evaluation has shown the effectiveness and efficiency of LiVo. 18 pull requests for fixing modification term violations have received positive responses. 8 have been merged.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1022–1034},
numpages = {13},
keywords = {license violation, open source software, software license, software modification},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1109/ICSE43902.2021.00028,
author = {Gao, Yanjie and Zhu, Yonghao and Zhang, Hongyu and Lin, Haoxiang and Yang, Mao},
title = {Resource-Guided Configuration Space Reduction for Deep Learning Models},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00028},
doi = {10.1109/ICSE43902.2021.00028},
abstract = {Deep learning models, like traditional software systems, provide a large number of configuration options. A deep learning model can be configured with different hyperparameters and neural architectures. Recently, AutoML (Automated Machine Learning) has been widely adopted to automate model training by systematically exploring diverse configurations. However, current AutoML approaches do not take into consideration the computational constraints imposed by various resources such as available memory, computing power of devices, or execution time. The training with non-conforming configurations could lead to many failed AutoML trial jobs or inappropriate models, which cause significant resource waste and severely slow down development productivity.In this paper, we propose DnnSAT, a resource-guided AutoML approach for deep learning models to help existing AutoML tools efficiently reduce the configuration space ahead of time. DnnSAT can speed up the search process and achieve equal or even better model learning performance because it excludes trial jobs not satisfying the constraints and saves resources for more trials. We formulate the resource-guided configuration space reduction as a constraint satisfaction problem. DnnSAT includes a unified analytic cost model to construct common constraints with respect to the model weight size, number of floating-point operations, model inference time, and GPU memory consumption. It then utilizes an SMT solver to obtain the satisfiable configurations of hyperparameters and neural architectures. Our evaluation results demonstrate the effectiveness of DnnSAT in accelerating state-of-the-art AutoML methods (Hyperparameter Optimization and Neural Architecture Search) with an average speedup from 1.19X to 3.95X on public benchmarks. We believe that DnnSAT can make AutoML more practical in a real-world environment with constrained resources.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {175–187},
numpages = {13},
keywords = {deep learning, constraint solving, configurable systems, AutoML},
location = {Madrid, Spain},
series = {ICSE '21}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3136040.3136054,
author = {Linsbauer, Lukas and Berger, Thorsten and Gr\"{u}nbacher, Paul},
title = {A classification of variation control systems},
year = {2017},
isbn = {9781450355247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136040.3136054},
doi = {10.1145/3136040.3136054},
abstract = {Version control systems are an integral part of today's software and systems development processes. They facilitate the management of revisions (sequential versions) and variants (concurrent versions) of a system under development and enable collaboration between developers. Revisions are commonly maintained either per file or for the whole system. Variants are supported via branching or forking mechanisms that conceptually clone the whole system under development. It is known that such cloning practices come with disadvantages. In fact, while short-lived branches for isolated development of new functionality (a.k.a. feature branches) are well supported, dealing with long-term and fine-grained system variants currently requires employing additional mechanisms, such as preprocessors, build systems or custom configuration tools. Interestingly, the literature describes a number of variation control systems, which provide a richer set of capabilities for handling fine-grained system variants compared to the version control systems widely used today. In this paper we present a classification and comparison of selected variation control systems to get an understanding of their capabilities and the advantages they can offer. We discuss problems of variation control systems, which may explain their comparably low popularity. We also propose research activities we regard as important to change this situation.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {49–62},
numpages = {14},
keywords = {software repositories, software product lines, configuration management, Variability management},
location = {Vancouver, BC, Canada},
series = {GPCE 2017}
}

@inproceedings{10.1145/1985793.1986047,
author = {Rubin, Julia and Botterweck, Goetz and Pleuss, Andreas and Weiss, David M.},
title = {Second international workshop on product line approaches in software engineering (PLEASE 2011)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1986047},
doi = {10.1145/1985793.1986047},
abstract = {PLEASE workshop series focuses on exploring the present and the future of Software Product Line Engineering techniques. The main goal of PLEASE 2011 is to bring together industrial practitioner and software product line researchers in order to couple real-life industrial problems with concrete solutions developed by the community.We plan for an interactive workshop, where participants can apply their expertise to current industrial problems, while those who face challenges in the area of product line engineering can benefit from the suggested solutions. We also intend to establish ongoing, long-lasting relationships between industrial and research participants to the mutual benefits of both.The second edition of PLEASE is held in conjunction with the 33rd International Conference in Software Engineering (May 21-28, 2011, Honolulu, Hawaii).},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {1204–1205},
numpages = {2},
keywords = {variability management, software product lines, product line engineering},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.5555/2050655.2050698,
author = {Cichos, Harald and Oster, Sebastian and Lochau, Malte and Sch\"{u}rr, Andy},
title = {Model-based coverage-driven test suite generation for software product lines},
year = {2011},
isbn = {9783642244841},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software Product Line (SPL) engineering is a popular approach for the systematic reuse of software artifacts across a large number of similar products. Unfortunately, testing each product of an SPL separately is often unfeasible. Consequently, SPL engineering is in conflict with standards like ISO 26262, which require each installed software configuration of safety-critical SPLs to be tested using a model-based approach with well-defined coverage criteria.In this paper we address this dilemma and present a new SPL test suite generation algorithm that uses model-based testing techniques to derive a small test suite from one variable 150% test model of the SPL such that a given coverage criterion is satisfied for the test model of every product. Furthermore, our algorithm simplifies the subsequent selection of a small, representative set of products (w.r.t. the given coverage criterion) on which the generated test suite can be executed.},
booktitle = {Proceedings of the 14th International Conference on Model Driven Engineering Languages and Systems},
pages = {425–439},
numpages = {15},
location = {Wellington, New Zealand},
series = {MODELS'11}
}

@inproceedings{10.1145/3540250.3549112,
author = {Ramkisoen, Poedjadevie Kadjel and Businge, John and van Bladel, Brent and Decan, Alexandre and Demeyer, Serge and De Roover, Coen and Khomh, Foutse},
title = {PaReco: patched clones and missed patches among the divergent variants of a software family},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549112},
doi = {10.1145/3540250.3549112},
abstract = {Re-using whole repositories as a starting point for new projects is often done by maintaining a variant fork parallel to the original. However, the common artifacts between both are not always kept up to date. As a result, patches are not optimally integrated across the two repositories, which may lead to sub-optimal maintenance between the variant and the original project. A bug existing in both repositories can be patched in one but not the other (we see this as a missed opportunity) or it can be manually patched in both probably by different developers (we see this as effort duplication). In this paper we present a tool (named PaReCo) which relies on clone detection to mine cases of missed opportunity and effort duplication from a pool of patches. We analyzed 364 (source to target) variant pairs with 8,323 patches resulting in a curated dataset containing 1,116 cases of effort duplication and 1,008 cases of missed opportunities. We achieve a precision of 91%, recall of 80%, accuracy of 88%, and F1-score of 85%. Furthermore, we investigated the time interval between patches and found out that, on average, missed patches in the target variants have been introduced in the source variants 52 weeks earlier. Consequently, PaReCo can be used to manage variability in “time” by automatically identifying interesting patches in later project releases to be backported to supported earlier releases.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {646–658},
numpages = {13},
keywords = {Variants, Software family, Social coding, Github, Forking, Effort duplication, Clone&amp;own, Clone detection, Bug-fixes},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3493244.3493250,
author = {Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Martinez, Jabier},
title = {Variability Debt: Characterization, Causes and Consequences},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493250},
doi = {10.1145/3493244.3493250},
abstract = {Variability is an inherent property of software systems to create families of products dealing with needs of different customers and environments. However, some practices to manage variability may incur technical debt. For example, the use of opportunistic reuse strategies, e.g., clone-and-own, harms maintenance and evolution activities; or deciding to abandon variability management and deriving a single product with all the features might threaten system usability. These examples are common problems found in practice but, to the best of or knowledge, not properly investigated from the perspective of technical debt. To expand the knowledge on the research and practice of technical debt in the perspective of variability management, we report results of this phenomenon, which we defined as variability debt. Our work is based on 52 industrial case studies that report problems observed in the use of opportunistic reuse. The results show that variability debt is caused by business, operational and technical aspects; leads to complex maintenance, creates difficulties to customize and create new products, misuse of human resources, usability problems; and impacts artifacts along the whole life-cycle. Although some of these issues are investigated in the field of systematic variability management, e.g., software product lines, our contribution is to present them from a technical debt perspective to enrich and create synergies between the two fields. As additional contribution, we present a catalog of variability debts in the light of technical debts found in the literature.},
booktitle = {Proceedings of the XX Brazilian Symposium on Software Quality},
articleno = {17},
numpages = {10},
keywords = {Variability management, Variability Debt, Technical Debt, Software Product Lines},
location = {Virtual Event, Brazil},
series = {SBQS '21}
}

@inproceedings{10.1145/2695664.2695743,
author = {Garcia, Cleiton and Paludo, Marco and Malucelli, Andreia and Reinehr, Sheila},
title = {A software process line for service-oriented applications},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695743},
doi = {10.1145/2695664.2695743},
abstract = {The management of processes and systems is a complex and time-consuming activity for organizations and also an ongoing Information Technology (IT) challenge. Among the different approaches for bringing flexibility to the business processes and systems are Service-Oriented Architecture (SOA) and Business Process Management (BPM). The SOA approach has become popular providing services and interfaces, enabling integration of heterogeneous and distributed platforms and BPM leverages the cycles of improvements, control and evaluation of business processes. BPM and SOA should work together aiming at improving business processes and evolving systems architecture. One main problem to apply BPM and SOA is the lack of established processes and this work proposes a software process line in order to simplify variability control and enable the instantiation of new development process applying BPM and SOA. It also aims at developing an environment to support the proposed software process line in order to automate the process, integrating industrial tools with one specifically developed to perform the transformation of UMA models into BPM notation. The main contribution of this work is the definition of the software process line for engineering service-oriented products. It is highly relevant to software industry since software process lines lacks experiments, practices and tools.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1680–1687},
numpages = {8},
keywords = {web-based services, software process lines, SPL, SOA, BPM},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1145/3023956.3023968,
author = {Mjeda, Anila and Wasala, Asanka and Botterweck, Goetz},
title = {Decision spaces in product lines, decision analysis, and design exploration: an interdisciplinary exploratory study},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023968},
doi = {10.1145/3023956.3023968},
abstract = {Context. From recent works on product properties resulting from configurations and the optimisation of these properties, one comes quickly to more complex challenges such as multi-objective optimisation, conflicting objectives, multiple stakeholders, and conflict resolution. The intuition is that Software Product Line Engineering (SPLE) can draw from other disciplines that deal with decision spaces and complex decision scenarios.Objectives. We aim to (1) explore links to such disciplines, (2) systematise and compare concepts, and (3) identify opportunities, where SPLE approaches can be enriched.Method. We undertake an exploratory study: Starting from common SPLE activities and artefacts, we identify aspects where we expect to find corresponding counterparts in other disciplines. We focus on Multiple Criteria Decision Analysis (MCDA), Multi-Objective Optimisation (MOO), and Design Space Exploration (DSE), and perform a comparison of the key concepts.Results. The resulting comparison relates SPLE activities and artefacts to concepts from MCDA, MOO, and DSE and identifies areas where SPLE approaches can be enriched. We also provide examples of existing work at the intersections of SPLE with the other fields. These findings are aimed to foster the conversation on research opportunities where SPLE can draw techniques from other disciplines dealing with complex decision scenarios.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {68–75},
numpages = {8},
keywords = {multi-objective optimisation, multi-criteria decision analysis, design-space exploration, decision modelling},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@article{10.1145/3428225,
author = {Shahin, Ramy and Chechik, Marsha},
title = {Automatic and efficient variability-aware lifting of functional programs},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428225},
doi = {10.1145/3428225},
abstract = {A software analysis is a computer program that takes some representation of a software product as input and produces some useful information about that product as output. A software product line encompasses many software product variants, and thus existing analyses can be applied to each of the product variations individually, but not to the entire product line as a whole. Enumerating all product variants and analyzing them one by one is usually intractable due to the combinatorial explosion of the number of product variants with respect to product line features. Several software analyses (e.g., type checkers, model checkers, data flow analyses) have been redesigned/re-implemented to support variability. This usually requires a lot of time and effort, and the variability-aware version of the analysis might have new errors/bugs that do not exist in the original one. Given an analysis program written in a functional language based on PCF, in this paper we present two approaches to transforming (lifting) it into a semantically equivalent variability-aware analysis. A light-weight approach (referred to as shallow lifting) wraps the analysis program into a variability-aware version, exploring all combinations of its input arguments. Deep lifting, on the other hand, is a program rewriting mechanism where the syntactic constructs of the input program are rewritten into their variability-aware counterparts. Compositionally this results in an efficient program semantically equivalent to the input program, modulo variability. We present the correctness criteria for functional program lifting, together with correctness proof sketches of shallow lifting. We evaluate our approach on a set of program analyses applied to the BusyBox C-language product line.},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {157},
numpages = {27},
keywords = {Variability-aware Programming, Software Product Lines, Program Rewriting, PCF, Lifting}
}

@inproceedings{10.1145/3510466.3510484,
author = {Ratzenb\"{o}ck, Michael and Gr\"{u}nbacher, Paul and Assun\c{c}ao, Wesley K. G. and Egyed, Alexander and Linsbauer, Lukas},
title = {Refactoring Product Lines by Replaying Version Histories},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3510484},
doi = {10.1145/3510466.3510484},
abstract = {When evolving software product lines, new features are added over time and existing features are revised. Engineers also decide to merge different features or split features in other cases. Such refactoring tasks are difficult when using manually maintained feature-to-code mappings. Intensional version control systems such as ECCO overcome this issue with automatically computed feature-to-code mappings. Furthermore, they allow creating variants that have not been explicitly committed before. However, such systems are still rarely used compared to extensional version control systems like Git, which keep track of the evolution history by assigning revisions to states of a system. This paper presents an approach combining both extensional and intensional version control systems, which relies on the extensional version control system Git to store versions. Developers selectively tag existing versions to describe the evolution at the level of features. Our approach then automatically replays the evolution history to create a repository of the intensional variation control system ECCO. The approach contributes to research on refactoring features of existing product lines and migrating existing systems to product lines. We provide an initial evaluation of the approach regarding correctness and performance based on an existing system.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {10},
keywords = {version control systems, refactoring, feature-level evolution},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/974044.974089,
author = {Wu, Xiuping and Woodside, Murray},
title = {Performance modeling from software components},
year = {2004},
isbn = {1581136730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974044.974089},
doi = {10.1145/974044.974089},
abstract = {When software products are assembled from pre-defined components, performance prediction should be based on the components also. This supports rapid model-building, using previously calibrated sub-models or "performance components", in sync with the construction of the product. The specification of a performance component must be tied closely to the software component specification, but it also includes performance related parameters (describing workload characteristics and demands), and it abstracts the behaviour of the component in various ways (for reasons related to practical factors in performance analysis). A useful set of abstractions and parameters are already defined for layered performance modeling. This work extends them to accommodate software components, using a new XML-based language called Component-Based Modeling Language (CBML). With CBML, compatible components can be inserted into slots provided in a hierarchical component specification based on the UML component model.},
booktitle = {Proceedings of the 4th International Workshop on Software and Performance},
pages = {290–301},
numpages = {12},
keywords = {submodel, software performance, software component, performance prediction, layered queue model, generative programming, LQN, CBML},
location = {Redwood Shores, California},
series = {WOSP '04}
}

@inproceedings{10.1145/3451471.3451478,
author = {Gunawan, Fandi and K. Budiardjo, Eko},
title = {&nbsp;A Quest of Software Process Improvements in DevOps and Kanban: A Case Study in Small Software Company},
year = {2021},
isbn = {9781450388955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3451471.3451478},
doi = {10.1145/3451471.3451478},
abstract = {A good software process improves software products. In the case of a small software company, software development is a matter of survivability due to its limited resources to develop software. XYZ Company is a very small software company that adopted Kanban and DevOps and faced software delivery delays. It is necessary to recommend the software process improvements to solve this problem. Software process improvements are the outcomes of measurement and analysis of maturity levels using the ISO 29110 framework in a qualitative study. They are then analyzed using the Lean Six Sigma tools, namely gap analysis, root cause analysis, and Pareto analysis. Delphi method validated them and resulted in 18 improvement recommendations within four domains, namely (a) product, (b) people, (c) technology, and (d) process. The improvements span across two main processes within software development, namely (a) Project Management (PM) and (b) Software Implementation (SI). The XYZ Company or any agile-based software company could adopt the 18 improvement recommendations to enhance the software process and quality.},
booktitle = {Proceedings of the 2021 4th International Conference on Software Engineering and Information Management},
pages = {39–45},
numpages = {7},
keywords = {small software company, agile, Software Process Improvement, SPI, Kanban, ISO 29110, DevOps},
location = {Yokohama, Japan},
series = {ICSIM '21}
}

@inproceedings{10.1145/3357765.3359525,
author = {Feichtinger, Kevin and Hinterreiter, Daniel and Linsbauer, Lukas and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {Supporting feature model evolution by suggesting constraints from code-level dependency analyses},
year = {2019},
isbn = {9781450369800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357765.3359525},
doi = {10.1145/3357765.3359525},
abstract = {Feature models are a de facto standard for representing the commonalities and variability of product lines and configurable software systems. Requirements-level features are commonly implemented in multiple source code artifacts, which results in complex dependencies at the code level. As developers change and evolve features frequently, it is challenging to keep feature models consistent with their implementation. We thus present an approach combining feature-to-code mappings and code dependency analyses to inform engineers about possible inconsistencies. Our focus is on code-level changes requiring updates in feature dependencies and constraints. Our approach uses static code analysis and a variation control system to lift complex code-level dependencies to feature models. We present the suggested dependencies to the engineer in two ways: directly as links between features in a feature model and as a heatmap visualizing the dependency changes of all features in a model. We present results of an evaluation on the Pick-and-Place Unit system, which demonstrates the utility and performance of our approach and the quality of the suggestions.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {129–142},
numpages = {14},
keywords = {variation control system, static code analysis, product lines, dependency analysis},
location = {Athens, Greece},
series = {GPCE 2019}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00122,
author = {Rosiak, Kamil},
title = {Extractive multi product-line engineering},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00122},
doi = {10.1109/ICSE-Companion52605.2021.00122},
abstract = {Cloning is a general approach to create new functionality within variants as well as new system variants. It is a fast, flexible, intuitive, and economical approach to evolve systems in the short run. However, in the long run, the maintenance effort increases. A common solution to this problem is the extraction of a product line from a set of cloned variants. This process requires a detailed analysis of variants to extract variability information. However, clones within a variant are usually not considered in the process, but are also a cause for unsustainable software. This thesis proposes an extractive multi product-line engineering approach to re-establish the sustainable development of software variants. We propose an approach to re-engineer intra-system and inter-system clones into reusable, configurable components stored in an integrated platform and synthesize a matching multilayer feature model.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {263–265},
numpages = {3},
keywords = {variability mining, refactoring, multi product-line, clone detection},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@proceedings{10.1145/3698062,
title = {WSSE '24: Proceedings of the 2024 The 6th World Symposium on Software Engineering (WSSE)},
year = {2024},
isbn = {9798400717086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3540250.3549108,
author = {Bittner, Paul Maximilian and Tinnes, Christof and Schulthei\ss{}, Alexander and Viegener, S\"{o}ren and Kehrer, Timo and Th\"{u}m, Thomas},
title = {Classifying edits to variability in source code},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549108},
doi = {10.1145/3540250.3549108},
abstract = {For highly configurable software systems, such as the Linux kernel, maintaining and evolving variability information along changes to source code poses a major challenge. While source code itself may be edited, also feature-to-code mappings may be introduced, removed, or changed. In practice, such edits are often conducted ad-hoc and without proper documentation. To support the maintenance and evolution of variability, it is desirable to understand the impact of each edit on the variability. We propose the first complete and unambiguous classification of edits to variability in source code by means of a catalog of edit classes. This catalog is based on a scheme that can be used to build classifications that are complete and unambiguous by construction. To this end, we introduce a complete and sound model for edits to variability. In about 21.5ms per commit, we validate the correctness and suitability of our classification by classifying each edit in 1.7 million commits in the change histories of 44 open-source software systems automatically. We are able to classify all edits with syntactically correct feature-to-code mappings and find that all our edit classes occur in practice.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {196–208},
numpages = {13},
keywords = {software variability, software product lines, software evolution, mining version histories, feature traceability},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3377024.3377047,
author = {Mahmood, Wardah and Chagama, Moses and Berger, Thorsten and Hebig, Regina},
title = {Causes of merge conflicts: a case study of ElasticSearch},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377047},
doi = {10.1145/3377024.3377047},
abstract = {Software branching and merging allows collaborative development and creating software variants, commonly referred to as clone &amp; own. While simple and cheap, a trade-off is the need to merge code and to resolve merge conflicts, which frequently occur in practice. When resolving conflicts, a key challenge for developer is to understand the changes that led to the conflict. While merge conflicts and their characteristics are reasonably well understood, that is not the case for the actual changes that cause them.We present a case study of the changes---on the code and on the project-level (e.g., feature addition, refactoring, feature improvement)---that lead to conflicts. We analyzed the development history of ElasticSearch, a large open-source project that heavily relies on branching (forking) and merging. We inspected 40 merge conflicts in detail, sampled from 534 conflicts not resolvable by a semi-structured merge tool. On a code (structural) level, we classified the semantics of changes made. On a project-level, we categorized the decisions that motivated these changes. We contribute a categorization of code- and project-level changes and a detailed dataset of 40 conflict resolutions with a description of both levels of changes. Similar to prior studies, most of our conflicts are also small; while our categorization of code-level changes surprisingly differs from that of prior work. Refactoring, feature additions and feature enhancements are the most common causes of merge conflicts, most of which could potentially be avoided with better development tooling.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {9},
numpages = {9},
keywords = {software merging, conflict resolution, case study},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1145/2814204.2814214,
author = {Font, Jaime and Arcega, Lorena and Haugen, \O{}ystein and Cetina, Carlos},
title = {Addressing metamodel revisions in model-based software product lines},
year = {2015},
isbn = {9781450336871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814204.2814214},
doi = {10.1145/2814204.2814214},
abstract = {Metamodels evolve over time, which can break the conformance between the models and the metamodel. Model migration strategies aim to co-evolve models and metamodels together, but their application is not fully automatizable and is thus cumbersome and error prone. We introduce the Variable MetaModel (VMM) strategy to address the evolution of the reusable model assets of a model-based Software Product Line. The VMM strategy applies variability modeling ideas to express the evolution of the metamodel in terms of commonalities and variabilities. When the metamodel evolves, the models continue to conform to the VMM, avoiding the need for migration. We have applied both the traditional migration strategy and the VMM strategy to a retrospective case study that includes 13 years of evolution of our industrial partner, an induction hobs manufacturer. The comparison between the two strategies shows better results for the VMM strategy in terms of model indirection, automation, and trust leak.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {161–170},
numpages = {10},
keywords = {Variability Modeling, Model-based Software Product Lines, Model and Metamodel Co-evolution},
location = {Pittsburgh, PA, USA},
series = {GPCE 2015}
}

@inproceedings{10.1145/2568225.2568267,
author = {Salay, Rick and Famelis, Michalis and Rubin, Julia and Di Sandro, Alessio and Chechik, Marsha},
title = {Lifting model transformations to product lines},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568267},
doi = {10.1145/2568225.2568267},
abstract = {Software product lines and model transformations are two techniques used in industry for managing the development of highly complex software. Product line approaches simplify the handling of software variants while model transformations automate software manipulations such as refactoring, optimization, code generation, etc. While these techniques are well understood independently, combining them to get the benefit of both poses a challenge because most model transformations apply to individual models while model-level product lines represent sets of models. In this paper, we address this challenge by providing an approach for automatically ``lifting'' model transformations so that they can be applied to product lines. We illustrate our approach using a case study and evaluate it through a set of experiments.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {117–128},
numpages = {12},
keywords = {Software Product Lines, Model Transformations, Model Driven Engineering},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/3084226.3084253,
author = {Abrah\~{a}o, Silvia and Insfran, Emilio},
title = {Evaluating Software Architecture Evaluation Methods: An Internal Replication},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084253},
doi = {10.1145/3084226.3084253},
abstract = {Context: The size and complexity of software systems along with the demand for ensuring quality requirements have fostered the interest in software architecture evaluation methods. Although several empirical studies have been reported, the actual body of knowledge is still insufficient. To address this concern, we presented a family of four controlled experiments that compares a recently proposed method, the Quality-Driven Architecture Derivation and Improvement (QuaDAI) method against the well-known Architecture Tradeoff Analysis Method (ATAM).Objective: To provide further evidence on the efficiency, effectiveness, and perceived satisfaction of participants using these two software architecture evaluation methods. We report the results of a differentiated internal replication study.Method: The same materials used in the baseline experiments were employed in this replication but the participants were sixteen practitioners. In addition, we used a simpler design to reduce the treatments' application sequences.Results: The participants obtained architectures with better quality when applying QuaDAI, and they found this method to be more useful and likely to be used than ATAM, but no difference in terms of efficiency and perceived ease of use were found.Conclusions: The results are in line with the baseline experiments and support the hypothesis that QuaDAI achieve better results than ATAM when performing architectural evaluations; however, further work is need to improve the methods usability.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {144–153},
numpages = {10},
keywords = {Software Architecture Evaluation, Experiment Replication},
location = {Karlskrona, Sweden},
series = {EASE '17}
}

@inproceedings{10.1145/2660190.2660191,
author = {Kolesnikov, Sergiy and Roth, Judith and Apel, Sven},
title = {On the relation between internal and external feature interactions in feature-oriented product lines: a case study},
year = {2014},
isbn = {9781450329804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660190.2660191},
doi = {10.1145/2660190.2660191},
abstract = {The feature-interaction problem has been explored for many years. Still, we lack sufficient knowledge about the interplay of different kinds of interactions in software product lines. Exploring the relations between different kinds of feature interactions will allow us to learn more about the nature of interactions and their causes. This knowledge can then be applied for improving existing approaches for detecting, managing, and resolving feature interactions. We present a framework for studying relations between different kinds of interactions. Furthermore, we report and discuss the results of a preliminary study in which we examined correlations between internal feature interactions (quantified by a set of software measures) and external feature interactions (represented by product-line-specific type errors). We performed the evaluation on a set of 15 feature-oriented, Java-based product lines. We observed moderate correlations between the interactions under discussion. This gives us confidence that we can apply our approach to studying other types of external feature interactions (e.g., performance interactions).},
booktitle = {Proceedings of the 6th International Workshop on Feature-Oriented Software Development},
pages = {1–8},
numpages = {8},
keywords = {software measures, feature-oriented software development, feature interactions},
location = {V\"{a}ster\r{a}s, Sweden},
series = {FOSD '14}
}

@article{10.1145/3571854,
author = {Zampetti, Fiorella and Tamburri, Damian and Panichella, Sebastiano and Panichella, Annibale and Canfora, Gerardo and Di Penta, Massimiliano},
title = {Continuous Integration and Delivery Practices for Cyber-Physical Systems: An Interview-Based Study},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3571854},
doi = {10.1145/3571854},
abstract = {Continuous Integration and Delivery (CI/CD) practices have shown several benefits for software development and operations, such as faster release cycles and early discovery of defects. For Cyber-Physical System (CPS) development, CI/CD can help achieving required goals, such as high dependability, yet it may be challenging to apply. This article empirically investigates challenges, barriers, and their mitigation occurring when applying CI/CD practices to develop CPSs in 10 organizations working in eight different domains. The study has been conducted through semi-structured interviews, by applying an open card sorting procedure together with a member-checking survey within the same organizations, and by validating the results through a further survey involving 55 professional developers. The study reveals several peculiarities in the application of CI/CD to CPSs. These include the need for (i) combining continuous and periodic builds while balancing the use of Hardware-in-the-Loop and simulators, (ii) coping with difficulties in software deployment (iii) accounting for simulators and Hardware-in-the-Loop differing in their behavior, and (vi) combining hardware/software expertise in the development team. Our findings open the road toward recommenders aimed at supporting the setting and evolution of CI/CD pipelines, as well as university curricula requiring interdisciplinarity, such as knowledge about hardware, software, and their interplay.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {73},
numpages = {44},
keywords = {empirical software engineering, Cyber-Physical Systems, Continuous Integration and Delivery}
}

@inproceedings{10.1145/3106237.3106273,
author = {Oh, Jeho and Batory, Don and Myers, Margaret and Siegmund, Norbert},
title = {Finding near-optimal configurations in product lines by random sampling},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106273},
doi = {10.1145/3106237.3106273},
abstract = {Software Product Lines (SPLs) are highly configurable systems. This raises the challenge to find optimal performing configurations for an anticipated workload. As SPL configuration spaces are huge, it is infeasible to benchmark all configurations to find an optimal one. Prior work focused on building performance models to predict and optimize SPL configurations. Instead, we randomly sample and recursively search a configuration space directly to find near-optimal configurations without constructing a prediction model. Our algorithms are simpler and have higher accuracy and efficiency.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {61–71},
numpages = {11},
keywords = {software product lines, searching configuration spaces, finding optimal configurations},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/2658761.2658767,
author = {Ruprecht, Andreas and Heinloth, Bernhard and Lohmann, Daniel},
title = {Automatic feature selection in large-scale system-software product lines},
year = {2014},
isbn = {9781450331616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658761.2658767},
doi = {10.1145/2658761.2658767},
abstract = {System software can typically be configured at compile time via a comfortable feature-based interface to tailor its functionality towards a specific use case. However, with the growing number of features, this tailoring process becomes increasingly difficult: As a prominent example, the Linux kernel in v3.14 provides nearly 14 000 configuration options to choose from. Even developers of embedded systems refrain from trying to build a minimized distinctive kernel configuration for their device – and thereby waste memory and money for unneeded functionality. In this paper, we present an approach for the automatic use-case specific tailoring of system software for special-purpose embedded systems. We evaluate the effectiveness of our approach on the example of Linux by generating tailored kernels for well-known applications of the Rasperry Pi and a Google Nexus 4 smartphone. Compared to the original configurations, our approach leads to memory savings of 15–70 percent and requires only very little manual intervention.},
booktitle = {Proceedings of the 2014 International Conference on Generative Programming: Concepts and Experiences},
pages = {39–48},
numpages = {10},
keywords = {Software Tailoring, Software Product Lines, Linux, Feature Selection},
location = {V\"{a}ster\r{a}s, Sweden},
series = {GPCE 2014}
}

@inproceedings{10.1145/3106237.3106283,
author = {Gazzillo, Paul},
title = {Kmax: finding all configurations of Kbuild makefiles statically},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106283},
doi = {10.1145/3106237.3106283},
abstract = {Feature-oriented software design is a useful paradigm for building and reasoning about highly-configurable software. By making variability explicit, feature-oriented tools and languages make program analysis tasks easier, such as bug-finding, maintenance, and more. But critical software, such as Linux, coreboot, and BusyBox rely instead on brittle tools, such as Makefiles, to encode variability, impeding variability-aware tool development. Summarizing Makefile behavior for all configurations is difficult, because Makefiles have unusual semantics, and exhaustive enumeration of all configurations is intractable in practice. Existing approaches use ad-hoc heuristics, missing much of the encoded variability in Makefiles. We present Kmax, a new static analysis algorithm and tool for Kbuild Makefiles. It is a family-based variability analysis algorithm, where paths are Boolean expressions of configuration options, called reaching configurations, and its abstract state enumerates string values for all configurations. Kmax localizes configuration explosion to the statement level, making precise analysis tractable. The implementation analyzes Makefiles from the Kbuild build system used by several low-level systems projects. Evaluation of Kmax on the Linux and BusyBox build systems shows it to be accurate, precise, and fast. It is the first tool to collect all source files and their configurations from Linux. Compared to previous approaches, Kmax is far more accurate and precise, performs with little overhead, and scales better.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {279–290},
numpages = {12},
keywords = {Variability, Static Analysis, Makefiles, Kmax, Kbuild, Configuration},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/1944892.1944899,
author = {Galster, Matthias and Avgeriou, Paris},
title = {The notion of variability in software architecture: results from a preliminary exploratory study},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944899},
doi = {10.1145/1944892.1944899},
abstract = {Context: In the software product line domain, the concept of variability is well recognized. However, variability in the context of software architecture still seems to be poorly understood. Objective: In this paper, we aim at contributing to the development of a basic understanding of the notion of variability in the software architecture domain, beyond the idea of product lines. Method: We perform a preliminary exploratory study which consists of two parts: an expert survey among 11 subjects, and a mini focus group with 4 participants. For both parts, we collect and analyze mostly qualitative data. Results: Our observations indicate that there seems to be no common understanding of "variability" in the context of software architecture. On the other hand, some challenges related to variability in software architecture are similar to challenges identified in the product line domain. Conclusions: Variability in software architecture might require more theoretical foundations in order to establish "variability" as an architectural key concept and first-class quality attribute.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {59–67},
numpages = {9},
keywords = {variability, software architecture, questionnaire, product lines, mini focus group},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@proceedings{10.1145/3634713,
title = {VaMoS '24: Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bern, Switzerland}
}

@inproceedings{10.1109/ICSE43902.2021.00076,
author = {Hata, Hideaki and Kula, Raula Gaikovina and Ishio, Takashi and Treude, Christoph},
title = {Same File, Different Changes: The Potential of Meta-Maintenance on GitHub},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00076},
doi = {10.1109/ICSE43902.2021.00076},
abstract = {Online collaboration platforms such as GitHub have provided software developers with the ability to easily reuse and share code between repositories. With clone-and-own and forking becoming prevalent, maintaining these shared files is important, especially for keeping the most up-to-date version of reused code. Different to related work, we propose the concept of meta-maintenance---i.e., tracking how the same files evolve in different repositories with the aim to provide useful maintenance opportunities to those files. We conduct an exploratory study by analyzing repositories from seven different programming languages to explore the potential of meta-maintenance. Our results indicate that a majority of active repositories on GitHub contains at least one file which is also present in another repository, and that a significant minority of these files are maintained differently in the different repositories which contain them. We manually analyzed a representative sample of shared files and their variants to understand which changes might be useful for meta-maintenance. Our findings support the potential of meta-maintenance and open up avenues for future work to capitalize on this potential.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {773–784},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.5555/2666719.2666730,
author = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
title = {Software feature model recommendations using data mining},
year = {2012},
isbn = {9781467317597},
publisher = {IEEE Press},
abstract = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation.},
booktitle = {Proceedings of the Third International Workshop on Recommendation Systems for Software Engineering},
pages = {47–51},
numpages = {5},
keywords = {range ranking, feature models, design decisions},
location = {Zurich, Switzerland},
series = {RSSE '12}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3422392.3422414,
author = {Marcondes, Arthur Roberto and Terra, Ricardo},
title = {An approach for updating forks against the original project},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422414},
doi = {10.1145/3422392.3422414},
abstract = {Several software projects start from an existing project. This practice, in the VCS ecosystem, is called fork. For instance, the Bootstrap project, initially developed on Twitter, today has more than 68,000 forks, which indicates that several projects started from the Bootstrap source code at a certain moment and are being customized. The problem occurs when customized projects want to obtain updates from the original project, i.e., new features, bug fixes, etc. The merge of the source code between the original and the customized projects usually generates conflicts that need human resolution. More important, the resolution of those conflicts might not be trivial and poses an arduous task for developers. This article, therefore, proposes an approach for updating forks against the original project where features are modularized, documented, traceable, and can be reused. We claim that the such task can no longer be carried out on an ad hoc basis. In a nutshell, instead of modify the method foo from the original project, the developer implements it locally and specifies, using one of the nine instructions of the proposed DSL, something like "replace the foo method with local implementation". We have developed a tool that automates our approach and conducted an evaluation on a large-scale real-world project that is regularly updated against your original project.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {213–222},
numpages = {10},
keywords = {Evolu\c{c}\~{a}o de software, conflitos de mesclagem, desenvolvimento colaborativo, fork, merge},
location = {Natal, Brazil},
series = {SBES '20}
}

@proceedings{10.1145/3571788,
title = {VaMoS '23: Proceedings of the 17th International Working Conference on Variability Modelling of Software-Intensive Systems},
year = {2023},
isbn = {9798400700019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Odense, Denmark}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@inproceedings{10.5555/2486788.2486853,
author = {Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
title = {On the value of user preferences in search-based software engineering: a case study in software product lines},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Software design is a process of trading off competing objectives. If the user objective space is rich, then we should use optimizers that can fully exploit that richness. For example, this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. As we increase the number of optimization objectives, we find that methods in widespread use (e.g. NSGA-II, SPEA2) perform much worse than IBEA (Indicator-Based Evolutionary Algorithm). IBEA works best since it makes most use of user preference knowledge. Hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0% violations of domain constraints. Our conclusion is that we need to change our methods for search-based software engineering, particularly when studying complex decision spaces.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {492–501},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.5555/381473.381482,
author = {Bosch, Jan},
title = {Software product lines: organizational alternatives},
year = {2001},
isbn = {0769510507},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software product lines enjoy increasingly wide adoption in the software industry. Most authors focus on the technical and process aspects and assume an organizational model consisting of a domain engineering unit and several application engineering units. In our cooperation with several software development organizations applying software product line principles, we have identified several other organizational models that are employed as well. In this article, we present a number of organizational alternatives, organized around four main models, i.e. development department, business units, domain engineering unit and hierarchical domain engineering units. For each model, its characteristics, applicability and advantages and disadvantages are discussed, as well as an example. Based on an analysis of these models, we present three factors that influence the choice of the organizational model, i.e. product-line assets, the responsibility levels and the type of organizational units.},
booktitle = {Proceedings of the 23rd International Conference on Software Engineering},
pages = {91–100},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {ICSE '01}
}

@article{10.1145/3660774,
author = {Lyu, Jun and Li, Shanshan and Zhang, He and Yang, Lanxin and Liu, Bohan and Rigger, Manuel},
title = {Towards Efficient Build Ordering for Incremental Builds with Multiple Configurations},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660774},
doi = {10.1145/3660774},
abstract = {Software products have many configurations to meet different environments and diverse needs. Building software with multiple software configurations typically incurs high costs in terms of build time and computing resources. Incremental builds could reuse intermediate artifacts if configuration settings affect only a portion of the build artifacts. The efficiency gains depend on the strategic ordering of the incremental builds as the order influences which build artifacts can be reused. Deriving an efficient order is challenging and an open problem, since it is infeasible to reliably determine the degree of re-use and time savings before an actual build. In this paper, we propose an approach, called BUDDI—BUild Declaration DIstance, for C-based and Make-based projects to derive an efficient order for incremental builds from the static information provided by the build scripts (i.e., Makefile). The core strategy of BUDDI is to measure the distance between the build declarations of configurations and predict the build size of a configuration from the build targets and build commands in each configuration. Since some artifacts could be reused in the subsequent builds if there is a close distance between the build scripts for different configurations. We implemented BUDDI as an automated tool called BuddiPlanner and evaluated it on 20 popular open-source projects, by comparing it to a baseline that randomly selects a build order. The experimental results show that the order created by BuddiPlanner outperforms 96.5% (193/200) of the random build orders in terms of build time and reduces the build time by an average of 305.94s (26%) compared to the random build orders, with a median saving of 64.88s (28%). BuddiPlanner demonstrates its potential to relieve practitioners of excessive build times and computational resource burdens caused by building multiple software configurations.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {67},
numpages = {24},
keywords = {Build Tool, Incremental Builds, Software Configurations}
}

@article{10.1145/3514233,
author = {Chen, Tao and Li, Miqing},
title = {The Weights Can Be Harmful: Pareto Search versus Weighted Search in Multi-objective Search-based Software Engineering},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3514233},
doi = {10.1145/3514233},
abstract = {In presence of multiple objectives to be optimized in Search-Based Software Engineering (SBSE), Pareto search has been commonly adopted. It searches for a good approximation of the problem’s Pareto-optimal solutions, from which the stakeholders choose the most preferred solution according to their preferences. However, when clear preferences of the stakeholders (e.g., a set of weights that reflect relative importance between objectives) are available prior to the search, weighted search is believed to be the first choice, since it simplifies the search via converting the original multi-objective problem into a single-objective one and enables the search to focus on what only the stakeholders are interested in.This article questions such a “weighted search first” belief. We show that the weights can, in fact, be harmful to the search process even in the presence of clear preferences. Specifically, we conduct a large-scale empirical study that consists of 38 systems/projects from three representative SBSE problems, together with two types of search budget and nine sets of weights, leading to 604 cases of comparisons. Our key finding is that weighted search reaches a certain level of solution quality by consuming relatively less resources at the early stage of the search; however, Pareto search is significantly better than its weighted counterpart the majority of the time (up to 77% of the cases), as long as we allow a sufficient, but not unrealistic search budget. This is a beneficial result, as it discovers a potentially new “rule-of-thumb” for the SBSE community: Even when clear preferences are available, it is recommended to always consider Pareto search by default for multi-objective SBSE problems, provided that solution quality is more important. Weighted search, in contrast, should only be preferred when the resource/search budget is limited, especially for expensive SBSE problems. This, together with other findings and actionable suggestions in the article, allows us to codify pragmatic and comprehensive guidance on choosing weighted and Pareto search for SBSE under the circumstance that clear preferences are available. All code and data can be accessed at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {5},
numpages = {40},
keywords = {self-adaptive systems, adaptive systems, configurable systems, user preference, quality indicator, quality evaluation, pareto optimization, multi-objective optimization, Search-based software engineering}
}

@article{10.1145/2581376,
author = {Behjati, Razieh and Nejati, Shiva and Briand, Lionel C.},
title = {Architecture-Level Configuration of Large-Scale Embedded Software Systems},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2581376},
doi = {10.1145/2581376},
abstract = {Configuration in the domain of Integrated Control Systems (ICS) is largely manual, laborious, and error prone. In this article, we propose a model-based configuration approach that provides automation support for reducing configuration effort and the likelihood of configuration errors in the ICS domain. We ground our approach on component-based specifications of ICS families. We then develop a configuration algorithm using constraint satisfaction techniques over finite domains to generate products that are consistent with respect to their ICS family specifications. We reason about the termination and consistency of our configuration algorithm analytically. We evaluate the effectiveness of our configuration approach by applying it to a real subsea oil production system. Specifically, we have rebuilt a number of existing verified product configurations of our industry partner. Our experience shows that our approach can automatically infer up to 50% of the configuration decisions, and reduces the complexity of making configuration decisions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {25},
numpages = {43},
keywords = {product configuration, formal specification, constraint satisfaction techniques, consistent configuration, UML/OCL, Model-based product-line engineering}
}

@inproceedings{10.1145/2491279.2491281,
author = {Schw\"{a}gerl, Felix and Uhrig, Sabrina and Westfechtel, Bernhard},
title = {Model-based tool support for consistent three-way merging of EMF models},
year = {2013},
isbn = {9781450320368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491279.2491281},
doi = {10.1145/2491279.2491281},
abstract = {Inadequate version control has been identified as a major obstacle to the application of model-driven software engineering. In particular, sophisticated support for merging model versions is urgently needed. We present a tool for merging of EMF models which may be applied to instances of arbitrary Ecore models. The tool advances the state of the art by guaranteeing a consistent merge result. Furthermore, it detects and resolves not only context-free, but also context-sensitive conflicts. Our merge tool is model-based; it relies on EMF for its implementation. Initial experiences gained from its application confirm that the merge tool operates both accurately and efficiently.},
booktitle = {Proceedings of the Workshop on ACadeMics Tooling with Eclipse},
articleno = {2},
numpages = {10},
keywords = {merging, EMF models},
location = {Montpellier, France},
series = {ACME '13}
}

@inproceedings{10.1145/3442391.3442409,
author = {G\"{o}ttmann, Hendrik and Bacher, Isabelle and Gottwald, Nicolas and Lochau, Malte},
title = {Static Analysis Techniques for Efficient Consistency Checking of Real-Time-Aware DSPL Specifications},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442409},
doi = {10.1145/3442391.3442409},
abstract = {Dynamic Software Product Lines (DSPL) have recently gained momentum as integrated engineering methodology for (self-)adaptive software. DSPL enhance statically configurable software by enabling run-time reconfiguration to facilitate continuous adaptations to changing environmental contexts. In a previous work, we presented a model-based methodology for specifying and automatically analyzing real-time constraints of reconfiguration decisions in a feature-oriented and compositional way. Internally, we translate real-time-aware DSPL specifications into timed automata serving as input for off-the-shelf model checkers like Uppaal for automatically checking semantic consistency properties. However, due to the very high computational complexity of model checking timed automata, those consistency checks suffer from scalability problems thus obstructing practical applications of the proposed approach. In this paper, we tackle this issue by investigating various kinds of static-analysis techniques that (1) aim to avoid expensive model checker calls by statically detecting certain classes of inconsistencies beforehand and otherwise (2) perform model reduction by detecting and merging equivalence states prior to model checker calls. The results of our experimental evaluation show very promising performance improvements achievable by those techniques, especially by the model-reduction approach.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {17},
numpages = {9},
keywords = {Timed Automata, Reconfiguration Decisions, Dynamic Software Product Lines},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.1145/1842752.1842769,
author = {Weyns, Danny and Capilla, Rafael},
title = {Current and emerging topics in software architecture (ECSA 2010 Workshops Summary)},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842769},
doi = {10.1145/1842752.1842769},
abstract = {Since 2004 in St. Andrews (Scotland, U.K.), ECSA the European Conference on Software Architecture (formerly EWSA, the European Workshop on Software Architecture) has been considered as an important meeting point for researchers and practitioners on the topic of software architecture. ECSA has matured from a workshop format to a full software engineering conference in the subfield of software architecture.This year, ECSA has become more ambitious and expanded its scope and schedule up to four full days. The program includes a series of tutorials, a doctoral mentoring program, and four full-day workshops. New and existing software challenges have led to a variety of trends in software architecture research, which makes the conference and workshops more attractive and promotes the discussion on current and emerging topics.Based on the scientific and technical interest of the topics, the innovativeness of workshop topics, and the capacity of the conference workshop program, the workshop co-chairs selected four workshops from the nine submitted proposals. We summarize the aims and goals of each workshop and the contributions accepted for the four workshops:• 2nd International Workshop on Software Ecosystems (EcoSys). Piers Campbell, Faheem Ahmed, Jan Bosch, Sliger Jansen.• 1st International Workshop on Measurability of Security in Software Architectures (MeSSa). Reijo Savola, Teemu Kranst\'{e}n, Antti Evesti.• 8th Nordic Workshop on Model Driven Software Engineering (NW-MODE). Andrzej Wasowski, Dragos Truscan, Ludwik Kuzniarz.• 1st International Workshop on Variability in Software Product Line Architectures (VARI-ARCH). Alexander Helleboogh, Paris Avgeriou, Nelis Boucke, Patryck Heymans.The ECSA 2010 Workshop co-chairs would like to thanks all workshop organizers for their effort and enthusiasm to attract submission in different software architecture research topics and make the ECSA 2010 workshops a success.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {59–62},
numpages = {4},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/1810295.1810302,
author = {Wang, Yi and Zhang, Min},
title = {Penalty policies in professional software development practice: a multi-method field study},
year = {2010},
isbn = {9781605587196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810295.1810302},
doi = {10.1145/1810295.1810302},
abstract = {Organizational Punishment/Penalty is a pervasive phenomenon in many professional organizations. In some software development organizations, punishment measures have been adopted in an attempt to improve software developers' performance, reduce the software defects, and hence ensure software quality. It is unclear whether these measures are effective. This article presents the results of a multi-method field study that analyzes software engineers' perception towards penalty policies in relation to software quality in a software development process. The results were generated via both qualitative and quantitative methods. Through interviews, we collected the individuals' perception towards the penalty policy. By extracting data in a software configuration management system, we identified several patterns of defects change. We found that while a penalty mechanism does help to reduce software defects in daily coding activity, it fails in achieving programmers' maximum work potential. Meanwhile, experienced software programmers require less time to adapt to penalty policies and benefit from exist of less experienced developers. Some additional findings and implications are also discussed.},
booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2},
pages = {39–47},
numpages = {9},
keywords = {software defects, perception and performance of software developers, penalty policies},
location = {Cape Town, South Africa},
series = {ICSE '10}
}

@inproceedings{10.1145/2600821.2600825,
author = {Nikitina, Natalja and Kajko-Mattsson, Mira},
title = {Guiding the adoption of software development methods},
year = {2014},
isbn = {9781450327541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600821.2600825},
doi = {10.1145/2600821.2600825},
abstract = {Literature shows that as many as 82% of the organizations that adopt agile methods experience problems in their agile adoptions. Despite this, very few reports have provided guidelines for how to conduct software method adoption. This paper suggests a process model of software method adoption and lists contextual factors for guiding the deployment of software development methods. The adoption model and the contextual factors have been evaluated in six industrial method adoption projects and they have proven to be useful for guiding organizations in their software method adoption efforts.},
booktitle = {Proceedings of the 2014 International Conference on Software and System Process},
pages = {109–118},
numpages = {10},
keywords = {Process change, SPI, agile adoption, agile method, deployment, method adoption, method engineering, process model},
location = {Nanjing, China},
series = {ICSSP '14}
}

@inproceedings{10.1145/1967486.1967572,
author = {Souer, Jurriaan and Joor, Dirk-Jan},
title = {An approach to identify commonalities in web application engineering for a web content management system},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967572},
doi = {10.1145/1967486.1967572},
abstract = {The process of Web applications engineering can be complex and time consuming. We argue that Web engineering based on a standardized platform with reusable components is a logical next step in the evolution of Web application development. One popular platform to create Web applications is called a Web Content Management Systems (WCMS) which allows organizations to develop Web applications in a time and resource efficient way. This paper presents a method to identify software commonalities in WCMS-based Web applications to improve the software product for future implementations based on feature modeling and e-business models. The resulting method provides insight in relevant e-business models and their corresponding functionalities. Moreover, this paper shows how these commonalities can be identified and how that could influence the software product line. The approach has been applied in a practical case study of a series of Web application engineering projects within the publishing vertical market. We have validated the approach with experts within the case study company and found that the approach is useful in aiding requirements engineers in the Web application engineering process and product managers in the software product management process.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {558–565},
numpages = {8},
keywords = {web engineering, web content management system, software product lines},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/2950290.2950311,
author = {Nguyen, ThanhVu and Koc, Ugur and Cheng, Javran and Foster, Jeffrey S. and Porter, Adam A.},
title = {iGen: dynamic interaction inference for configurable software},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950311},
doi = {10.1145/2950290.2950311},
abstract = {To develop, analyze, and evolve today's highly configurable software systems, developers need deep knowledge of a system's configuration options, e.g., how options need to be set to reach certain locations, what configurations to use for testing, etc. Today, acquiring this detailed information requires manual effort that is difficult, expensive, and error prone. In this paper, we propose iGen, a novel, lightweight dynamic analysis technique that automatically discovers a program's interactions---expressive logical formulae that give developers rich and detailed information about how a system's configuration option settings map to particular code coverage. iGen employs an iterative algorithm that runs a system under a small set of configurations, capturing coverage data; processes the coverage data to infer potential interactions; and then generates new configurations to further refine interactions in the next iteration. We evaluated iGen on 29 programs spanning five languages; the breadth of this study would be unachievable using prior interaction inference tools. Our results show that iGen finds precise interactions based on a very small fraction of the number of possible configurations. Moreover, iGen's results confirm several earlier hypotheses about typical interaction distributions and structures.},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {655–665},
numpages = {11},
keywords = {software testing, dynamic analysis, configurable systems, Program analysis},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/1858996.1859009,
author = {Vierhauser, Michael and Gr\"{u}nbacher, Paul and Egyed, Alexander and Rabiser, Rick and Heider, Wolfgang},
title = {Flexible and scalable consistency checking on product line variability models},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859009},
doi = {10.1145/1858996.1859009},
abstract = {The complexity of product line variability models makes it hard to maintain their consistency over time regardless of the modeling approach used. Engineers thus need support for detecting and resolving inconsistencies. We describe experiences of applying a tool-supported approach for incremental consistency checking on variability models. Our approach significantly improves the overall performance and scalability compared to batch-oriented techniques and allows providing immediate feedback to modelers. It is extensible as new consistency constraints can easily be added. Furthermore, the approach is flexible as it is not limited to variability models and it also checks the consistency of the models with the underlying code base of the product line. We report the results of a thorough evaluation based on real-world product line models and discuss lessons learned.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {variability models, software product lines, performance, model consistency, memory consumption, lessons learned, incremental consistency checking},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1145/2745802.2745831,
author = {Mahmood, Sajjad and Anwer, Sajid and Niazi, Mahmood and Alshayeb, Mohammad and Richardson, Ita},
title = {Identifying the factors that influence task allocation in global software development: preliminary results},
year = {2015},
isbn = {9781450333504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745802.2745831},
doi = {10.1145/2745802.2745831},
abstract = {Over the last decade, an increasing number of organizations have started software development in a globally distributed environment. One of the major challenges is that many organizations endorse the process of global software development without testing their management readiness for the globally distributed development activity. This includes work distribution through task allocation in the globally distributed development environment. The objective of this research paper is to identify factors that influence task allocation in global software development through carrying out a systematic literature review. We used customized search terms, derived from our research question, to identify literature on work distribution and task allocation in a global context. We identified criteria such as site technical expertise, time zone difference, resource cost, task dependency, vendor reliability, task size and vendor maturity level as key task allocation factors in globally distributed software projects. Based on the systematic literature review results, we suggest that there is a need to develop work distribution strategies and standards through global task allocation to help software development organizations in achieving the true potential of global software development at lower development costs and shorter time-to-market.},
booktitle = {Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {31},
numpages = {6},
keywords = {work distribution, task allocation, systematic literature review, global software development},
location = {Nanjing, China},
series = {EASE '15}
}

@inproceedings{10.1145/2593702.2593708,
author = {Kompella, Lakshminarayana},
title = {Agile methods, organizational culture and agility: some insights},
year = {2014},
isbn = {9781450328609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593702.2593708},
doi = {10.1145/2593702.2593708},
abstract = {Software development depends on various factors and organizational culture is one of them. Recently agile software development, with its emphasis on agility, has received much attention. Research so far has focused on the constructs that define agility and also identified the reasons that limit teams from exhibiting all the constructs of agile software development. This lead to re-defining agility by using economic, quality, simplicity and the relationship with the environment it operates on. One of the factors that contribute to relationship with environment is organizational culture. Though relationship of organizational culture and software methods is not new, analyzing the relationship further in the new defined definition of agility can provide deep insights into software development. In this paper a qualitative research method of multiple case-studies consisting of 3 releases of one product development team was selected. Data was collected using participant-observation method. Research findings have identified some useful insights that could provide researchers and practitioners to develop software development life-cycle that incorporates existing agile methods and uses diverse set of methods to resolve issues including organizational issues. Thereby the new software development life-cycle would not distinguish between agile and plan-driven development methods and could shape itself in the changing context.},
booktitle = {Proceedings of the 7th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {40–47},
numpages = {8},
keywords = {Qualitative Research, Probabilistic Neural Networks, Organizational culture, Bayesian, Agility as a prior characterization and emergent, Agile methods},
location = {Hyderabad, India},
series = {CHASE 2014}
}

@inproceedings{10.1145/1842752.1842812,
author = {Abbas, Nadeem and Andersson, Jesper and L\"{o}we, Welf},
title = {Autonomic Software Product Lines (ASPL)},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842812},
doi = {10.1145/1842752.1842812},
abstract = {We describe ongoing work on a variability mechanism for Autonomic Software Product Lines (ASPL). The autonomic software product lines have self-management characteristics that make product line instances more resilient to context changes and some aspects of product line evolution. Instances sense the context, selects and bind the best component variants to variation-points at run-time. The variability mechanism we describe is composed of a profile guided dispatch based on off-line and on-line training processes. Together they form a simple, yet powerful variability mechanism that continuously learns, which variants to bind given the current context and system goals.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {324–331},
numpages = {8},
keywords = {variation-points, variants, variability, on-line, off-line training, goals, context, autonomic elements, MAPE-K},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/3510466.3511274,
author = {Meixner, Kristof and Feichtinger, Kevin and Rabiser, Rick and Biffl, Stefan},
title = {Efficient Production Process Variability Exploration},
year = {2022},
isbn = {9781450396042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510466.3511274},
doi = {10.1145/3510466.3511274},
abstract = {Cyber-Physical Production Systems (CPPSs) manufacture highly-customizable products from a product family following a sequence of production steps. For a CPPS, basic planners design feasible production process sequences by arranging atomic production steps based on implicit domain knowledge. However, the manual design of production sequences is inefficient and hard to reproduce due to the large configuration space. In this paper, we introduce the Iterative Process Sequence Exploration (IPSE) approach that (i) elicits domain knowledge in an industrial variability artifact, using the Product-Process-Resource Domain-Specific Language (PPR–DSL); (ii) reduces configuration space size regarding structural product variability and behavioral process variability; and (iii) facilitates efficiently exploring the configuration space in a process decision model. For production process sequence design, IPSE is a first approach to combine structural and behavioral variability models. We investigated the feasibility of the IPSE in a study on a typical manufacturing work line in automotive production. We compare the IPSE to a traditional process sequence planning approach. Our study indicates IPSE to be more efficient than the traditional manual approach.},
booktitle = {Proceedings of the 16th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {14},
numpages = {9},
keywords = {Variability Modeling, Process Variability, Cyber-Physical Production System, Configuration Reduction.},
location = {Florence, Italy},
series = {VaMoS '22}
}

@inproceedings{10.1145/2641483.2641542,
author = {Alrashoud, Mubarak and Ahmed, Lubaid and Abhari, Abdolreza},
title = {Binary Linear Programming-based Release Planning for Multi-tenant Business SaaS},
year = {2014},
isbn = {9781450327121},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2641483.2641542},
doi = {10.1145/2641483.2641542},
abstract = {In multi-tenant Software as a Service (SaaS) business software, the degree of tenants' satisfaction is a significant indicator of the success of the SaaS system. Tenants' satisfaction can be achieved by continuously fulfilling their evolving needs. Usually, SaaS providers frequently deliver new releases of the application. Each release contains new or enhanced features. However, SaaS providers have limited resources, which makes it difficult to them to incorporate all of the tenants' requests in the next release. Therefore, some requirements shall be postponed to later releases. In order to achieve the highest possible level of tenets' satisfaction, SaaS providers shall include the most common requirements in the next release, which guarantee the satisfaction of highest possible number of tenants with less effort. Additionally, tenants' priorities and preferences about the requirements must be considered. Besides maximizing tenants' satisfaction, it is crucial to meet different types of constraints such as resource, technical, and contractual constraints. This paper identifies the factors that govern the release planning process for multi-tenant business software, which are contractual constraints, commonality of requirements, tenants' preferences and decision weights, risk, technical constraints. The first two factors are suggested by this paper, while the remaining factors are inherited from the traditional release planning process. Moreover, this paper proposes a framework that deals with the uniqueness of the release planning process in multi-tenant SaaS system. In this framework, Binary Linear Programming (BLP) is employed to optimize the selection process of the requirements that will be implemented in the next release. An experiments section is provided to illustrate the degree of satisfaction that can be achieved using the proposed framework.},
booktitle = {Proceedings of the 2014 International C* Conference on Computer Science &amp; Software Engineering},
articleno = {15},
numpages = {8},
keywords = {requirements prioritization, applications of binary linear programming, Software release planning, SaaS requirements engineering, SaaS development},
location = {Montreal, QC, Canada},
series = {C3S2E '14}
}

@proceedings{10.1145/3643667,
title = {Q-SE 2024: Proceedings of the 5th ACM/IEEE International Workshop on Quantum Software Engineering},
year = {2024},
isbn = {9798400705700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 5th International Workshop on Quantum Software Engineering (Q-SE 2024), co-located with ICSE 2024, provides a platform for researchers and practitioners to discuss challenges in developing quantum software in high-level quantum languages, novel solutions to build correct methods for testing quantum programs, executing quantum software, developing best practices, and creating a research roadmap of quantum software engineering.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2025113.2025177,
author = {Mori, Marco},
title = {A software lifecycle process for context-aware adaptive systems},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025177},
doi = {10.1145/2025113.2025177},
abstract = {It is increasingly important for computing systems to evolve their behavior at run-time because of resources uncertainty, system failures and emerging user needs. Our approach supports software engineers to analyze and develop context-aware adaptive applications. The software lifecycle process we propose supports static and dynamic decision making mechanisms, run-time consistent evolution and it is amenable to be automated.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {412–415},
numpages = {4},
keywords = {software lifecycle process, feature engineering, context-aware adaptive systems, consistent evolution},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}

@article{10.1145/2439976.2439982,
author = {Tiwari, Rajeev and Goel, Noopur},
title = {Reuse: reducing test effort},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2439976.2439982},
doi = {10.1145/2439976.2439982},
abstract = {Testing effort consumes more than half of all development effort and is one of the important factors, which obstruct quality assurance. Software reuse enhances quality and productivity and at the same time reduces the time-to-market of the software products. As reuse applies to the development process, so too, it applies to the testing process. In this paper, we discuss reuse-oriented test approaches, which are used to reduce the testing effort. Further, we present the state-of-the-art in reuse-oriented test approaches employed in reuseoriented development processes. At the end of the current paper, we argue that the current trend is towards built-in test and model based testing in the applications developed through reusable software.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {1–11},
numpages = {11},
keywords = {test effort, software product lines, reuse-oriented test approaches, reusable test cases}
}

@inproceedings{10.1145/2346536.2346547,
author = {Shang, Richard D. and Mohan, Kannan and Lang, Karl R. and Vragov, Roumen},
title = {A market mechanism for software component reuse: opportunities and barriers},
year = {2012},
isbn = {9781450311977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2346536.2346547},
doi = {10.1145/2346536.2346547},
abstract = {We propose a market based design for trading component-based software products bundled with reuse licenses that allows clients to customize software solutions onsite by reusing and reintegrating components across software systems using their own software development platforms. Using economic experiments in the laboratory with IT professionals we find that introducing reuse licenses has social welfare benefits in terms of both higher seller and higher buyer surplus as well as generating higher product variety in the market. We argue that as software development is increasingly using modularized and component-based approaches software vendor strategies based on flexible licenses permitting the reuse of software offer a viable and sustainable alternative to the traditional software business model build on monolithic user licenses.},
booktitle = {Proceedings of the 14th Annual International Conference on Electronic Commerce},
pages = {62–69},
numpages = {8},
location = {Singapore, Singapore},
series = {ICEC '12}
}

@inproceedings{10.1145/1083142.1083157,
author = {VanHilst, Michael and Garg, Pankaj K. and Lo, Christopher},
title = {Repository mining and Six Sigma for process improvement},
year = {2005},
isbn = {1595931236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083142.1083157},
doi = {10.1145/1083142.1083157},
abstract = {In this paper, we propose to apply artifact mining in a global development environment to support measurement based process management and improvement, such as SEI/CMMI's GQ(I)M and Six Sigma's DMAIC. CMM has its origins in managing large software projects for the government and emphasizes achieving expected outcomes. In GQM, organizational goals are identified. The appropriate questions with corresponding measurements are defined and collected. Six Sigma has its origins in manufacturing and emphasizes reducing cost and defects. In DMAIC, a major component of a Six Sigma approach, sources of waste are identified. Then changes are made in the process to reduce effort and increase the quality of the product produced. GQM and Six Sigma are complementary. Both approaches rely heavily on the measurement of input and output metrics. Mining development artifacts can provide usable metrics for the application of DMAIC and GQM in the software domain.},
booktitle = {Proceedings of the 2005 International Workshop on Mining Software Repositories},
pages = {1–4},
numpages = {4},
keywords = {six sigma, repositories, process improvement, GQM},
location = {St. Louis, Missouri},
series = {MSR '05}
}

@inproceedings{10.1145/2695664.2695875,
author = {Almeida, Andr\'{e} and Bencomo, Nelly and Batista, Thais and Cavalcante, Everton and Dantas, Francisco},
title = {Dynamic decision-making based on NFR for managing software variability and configuration selection},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695875},
doi = {10.1145/2695664.2695875},
abstract = {Due to dynamic variability, identifying the specific conditions under which non-functional requirements (NFRs) are satisfied may be only possible at runtime. Therefore, it is necessary to consider the dynamic treatment of relevant information during the requirements specifications. The associated data can be gathered by monitoring the execution of the application and its underlying environment to support reasoning about how the current application configuration is fulfilling the established requirements. This paper presents a dynamic decision-making infrastructure to support both NFRs representation and monitoring, and to reason about the degree of satisfaction of NFRs during runtime. The infrastructure is composed of: (i) an extended feature model aligned with a domain-specific language for representing NFRs to be monitored at runtime; (ii) a monitoring infrastructure to continuously assess NFRs at runtime; and (iii) a flexible decision-making process to select the best available configuration based on the satisfaction degree of the NRFs. The evaluation of the approach has shown that it is able to choose application configurations that well fit user NFRs based on runtime information. The evaluation also revealed that the proposed infrastructure provided consistent indicators regarding the best application configurations that fit user NFRs. Finally, a benefit of our approach is that it allows us to quantify the level of satisfaction with respect to NFRs specification.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1376–1382},
numpages = {7},
keywords = {variability, non-functional requirements, monitoring, SPLs},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1145/3319008.3319356,
author = {Neto, Amadeu Anderlin and Kalinowski, Marcos and Garcia, Alessandro and Winkler, Dietmar and Biffl, Stefan},
title = {A Preliminary Comparison of Using Variability Modeling Approaches to Represent Experiment Families},
year = {2019},
isbn = {9781450371452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319008.3319356},
doi = {10.1145/3319008.3319356},
abstract = {Background: Replication is essential to build knowledge in empirical science. Experiment replications reported in the software engineering context present variabilities on their design elements, e.g., variables, materials. The understanding of these variabilities is required to plan experimental replications within a research program. However, the lack of an explicit representation of experiments' variabilities and commonalities is likely to hamper their understanding and replication planning. Aims: The goal of this paper is to explore the use of Variability Modeling Approaches (VMAs) to represent experiment families (i.e., an original study and its replications) and to investigate the feasibility of using VMAs to support experiment replication planning. Method: We selected two experiment families, analyzed their commonalities and variabilities, and represented them using a set of well-known VMAs: Feature Model, Decision Model, and Orthogonal Variability Model. Based on the resulting models, we conducted a preliminary comparison of using such alternative VMAs to support replication planning. Results: Subjects were able to plan consistent experiment replications with the VMAs as support. Additionally, through a qualitative analysis, we identified and discuss advantages and limitations of using the VMAs. Conclusions: It is feasible to represent experiment families and to plan replications using VMAs. Based on our emerging results, we conclude that the Feature Model VMA provides the most suitable representation. Furthermore, we identified benefits in a potential merge between the Feature Model and Decision Model VMAs to provide more details to support replication planning.},
booktitle = {Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering},
pages = {333–338},
numpages = {6},
keywords = {experiment replication, experiment lines, Experiment planning},
location = {Copenhagen, Denmark},
series = {EASE '19}
}

@inproceedings{10.1145/2578128.2578237,
author = {de Andrade, Hugo Sica and Almeida, Eduardo and Crnkovic, Ivica},
title = {Architectural bad smells in software product lines: an exploratory study},
year = {2014},
isbn = {9781450325233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2578128.2578237},
doi = {10.1145/2578128.2578237},
abstract = {The Software Product Lines (SPL) paradigm has arisen for taking advantage of existing common aspects between different products, while also considering product-specific features. The architecture of a SPL comprises a model that will result in product architectures, and may include solutions leading to bad (architectural) design. One way to assess such design decisions is through the identification of architectural bad smells, which are properties that prejudice the overall software quality, but are not necessarily faulty or errant. In this paper, we conduct an exploratory study that aims at characterizing bad smells in the context of product line architectures. We analyzed an open source SPL project and extracted its architecture to investigate the occurrence or absence of four smells initially studied in single systems. In addition, we propose a smell specific to the SPL context and discuss possible causes and implications of having those smells in the architecture of a product line. The results indicate that the granularity of the SPL features may influence on the occurrence of smells.},
booktitle = {Proceedings of the WICSA 2014 Companion Volume},
articleno = {12},
numpages = {6},
keywords = {software product lines, exploratory study, evaluation, architecture, architectural bad smells},
location = {Sydney, Australia},
series = {WICSA '14 Companion}
}

@inproceedings{10.1145/1985394.1985397,
author = {Sengupta, Bikram and Roychoudhury, Abhik},
title = {Engineering multi-tenant software-as-a-service systems},
year = {2011},
isbn = {9781450305914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985394.1985397},
doi = {10.1145/1985394.1985397},
abstract = {Increasingly, Software-as-a-Service (SaaS) is becoming a dominant mechanism for the consumption of software by end users. From a vendor's perspective, the benefits of SaaS arise from leveraging economies of scale, by serving a large number of customers ("tenants") through a shared instance of a centrally hosted software service. Consequently, a SaaS provider would, in general, try to drive commonality amongst the requirements of different tenants, and at best, offer a fixed set of customization options. However, many tenants would also come with custom requirements, which may be a pre-requisite for them to adopt the SaaS system. These requirements should then be addressed by evolving the SaaS system in a controlled manner, while still supporting the needs of existing tenants. This need to balance tenant variability and commonality, and to optimize on development and testing effort, can make the evolution of multitenant SaaS systems an interesting engineering challenge; this has strong economic undertones as well, given the "pay-per-use" subscription model of SaaS, and the cost of incremental development and maintenance to cater to new tenant needs. In this paper, we outline a set of research issues in the design, testing and maintenance of multi-tenant SaaS systems, and highlight some of the interesting optimization questions that arise in the process. Presenting specific technical solutions is beyond the scope of this paper - instead, our goal is to help shape a research agenda for multi-tenant SaaS that can provide stimulus for further investigation into this area by the software and service engineering research community.},
booktitle = {Proceedings of the 3rd International Workshop on Principles of Engineering Service-Oriented Systems},
pages = {15–21},
numpages = {7},
keywords = {testing, software-as-a-service, semantics, refinement, multi-tenancy, cloud computing},
location = {Waikiki, Honolulu, HI, USA},
series = {PESOS '11}
}

@inproceedings{10.1145/2430502.2430526,
author = {Passos, Leonardo and Czarnecki, Krzysztof and Apel, Sven and W\k{a}sowski, Andrzej and K\"{a}stner, Christian and Guo, Jianmei},
title = {Feature-oriented software evolution},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430526},
doi = {10.1145/2430502.2430526},
abstract = {In this paper, we develop a vision of software evolution based on a feature-oriented perspective. From the fact that features provide a common ground to all stakeholders, we derive a hypothesis that changes can be effectively managed in a feature-oriented manner. Assuming that the hypothesis holds, we argue that feature-oriented software evolution relying on automatic traceability, analyses, and recommendations reduces existing challenges in understanding and managing evolution. We illustrate these ideas using an automotive example and raise research questions for the community.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {17},
numpages = {8},
keywords = {traceability, software evolution, recommendation, feature-oriented development, analysis},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@inproceedings{10.1145/1842752.1842777,
author = {Dhungana, Deepak and Groher, Iris and Schludermann, Elisabeth and Biffl, Stefan},
title = {Software ecosystems vs. natural ecosystems: learning from the ingenious mind of nature},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842777},
doi = {10.1145/1842752.1842777},
abstract = {The use of the term ecosystem in the context of extensible software platforms and third-party developers or user communities has made us ponder about the similarities between software ecosystems and natural ecosystems. We therefore compare software ecosystems and natural ecosystems to present an agenda for further research by analyzing some key characteristics of both types of ecosystems. We discuss the regulatory factors and mechanisms existing in nature, and then deduce key challenges that need to be dealt with, in order to achieve healthy operation of software ecosystems.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {96–102},
numpages = {7},
keywords = {software, nature, ecosystem},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/2642937.2642960,
author = {Hamidi, Saeideh and Andritsos, Periklis and Liaskos, Sotirios},
title = {Constructing adaptive configuration dialogs using crowd data},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2642960},
doi = {10.1145/2642937.2642960},
abstract = {As modern software systems grow in size and complexity so do their configuration possibilities. Users are easy to be confused and overwhelmed by the amount of choices they need to make in order to fit their systems to their exact needs. We propose a method to construct adaptive configuration elicitation dialogs through utilizing crowd wisdom. A set of configuration preferences in the form of association rules is first mined from a crowd configuration data set. Possible configuration elicitation dialogs are then modeled through a Markov Decision Process (MDP). Association rules are used to inform the model about configuration decisions that can be automatically inferred from knowledge already elicited earlier in the dialog. This way, an MDP solver can search for elicitation strategies which maximize the expected amount of automated decisions, reducing thereby elicitation effort and increasing user confidence of the result. The method is applied to the privacy configuration of Facebook.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {485–490},
numpages = {6},
keywords = {software customization, markov decision processes, facebook, crowdsourcing, association rules mining},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@inproceedings{10.1109/EA.2009.5071583,
author = {Khan. Simon Lock, Safoora Shakil},
title = {Concern tracing and change impact analysis: An exploratory study},
year = {2009},
isbn = {9781424437191},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/EA.2009.5071583},
doi = {10.1109/EA.2009.5071583},
abstract = {A few AO Requirement Engineering approaches support traceability by providing mapping and influence of requirements-level concerns on subsequent phase artefacts. This is not sufficient to ensure that the architecture actually meets the specified requirements (as some requirements lead to architectural decisions, establish trade-offs, etc). Equally, without knowledge of such traceability relationships it becomes very difficult to predict change impact and thus understand the causes of system instability. In order to improve this situation, we have developed a concern-oriented dependency taxonomy that enables us to capture the dependency relationships between requirements-level concerns and their manifestation at the architectural level. We have applied the dependency taxonomy on a real-world case study to explore and identify unstable architectural components, which are most likely to be impacted by change.},
booktitle = {Proceedings of the 2009 ICSE Workshop on Aspect-Oriented Requirements Engineering and Architecture Design},
pages = {44–48},
numpages = {5},
series = {EA '09}
}

@inproceedings{10.1145/2031759.2031771,
author = {Dobrica, Liliana and Ovaska, Eila},
title = {Analysis of a cross-domain reference architecture using change scenarios},
year = {2011},
isbn = {9781450306188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2031759.2031771},
doi = {10.1145/2031759.2031771},
abstract = {The content of this paper addresses the issue of how to perform analysis of a cross domain reference architecture. The cross domain reference architecture is designed based on the domains requirements and features modeling. The definition of a cross domain reference architecture is based on well known concepts from software architecture description, service orientation and product line. We apply a method based on change scenarios to analyze variability at the architectural level. In order to handle complexity in analysis we propose categories of change scenarios to be derived from each problem domain and we provide informal guidelines for each step of the analysis method.},
booktitle = {Proceedings of the 5th European Conference on Software Architecture: Companion Volume},
articleno = {10},
numpages = {9},
keywords = {variability, service, scenarios, quality, cross domain reference architecture, analysis methods},
location = {Essen, Germany},
series = {ECSA '11}
}

@article{10.1145/1081992.1082007,
author = {Armour, Phillip G.},
title = {To plan, two plans},
year = {2005},
issue_date = {September 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/1081992.1082007},
doi = {10.1145/1081992.1082007},
abstract = {A planning approach to managing risk.},
journal = {Commun. ACM},
month = sep,
pages = {15–19},
numpages = {5}
}

@inproceedings{10.1145/1944892.1944898,
author = {Cavalcanti, Yguarat\~{a} Cerqueira and do Carmo Machado, Ivan and da Mota, Paulo Anselmo and Neto, Silveira and Lobato, Luanna Lopes and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero},
title = {Towards metamodel support for variability and traceability in software product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944898},
doi = {10.1145/1944892.1944898},
abstract = {In Software Product Lines (SPL), where a greater variety of products are derived from a common platform and constantly changed and evolved, it is important to manage the SPL variability and the traceability among its artifacts. This paper presents a metamodel which aims to coordinate SPL activities, by managing different SPL phases and their responsibles, and to maintain the traceability and variability among different artifacts. The metamodel was built for a SPL project in a private company working in the medical information management domain, which includes four products encompassing 102 different modules and 840 features. The metamodel is divided into five sub-models: project and risk management, scoping, requirements and testing. It is represented in the UML notation. Organizations using this metamodel as basis for their approaches, can easily understand the relationships between the SPL assets, communicate to the stakeholders, and facilitate the evolution and maintenance of the SPL. The metamodel can also be adapted to the single system development context.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {49–57},
numpages = {9},
keywords = {variability, software product lines, software engineering, metamodel, design},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/2039239.2039242,
author = {Tartler, Reinhard and Lohmann, Daniel and Dietrich, Christian and Egger, Christoph and Sincero, Julio},
title = {Configuration coverage in the analysis of large-scale system software},
year = {2011},
isbn = {9781450309790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2039239.2039242},
doi = {10.1145/2039239.2039242},
abstract = {System software, especially operating systems, tends to be highly configurable. Like every complex piece of software, a considerable amount of bugs in the implementation has to be expected. In order to improve the general code quality, tools for static analysis provide means to check for source code defects without having to run actual test cases on real hardware. Still, for proper type checking a specific configuration is required so that all header include paths are available and all types are properly resolved.In order to find as many bugs as possible, usually a "full configuration" is used for the check. However, mainly because of alternative blocks in form of #else-blocks, a single configuration is insufficient to achieve full coverage. In this paper, we present a metric for configuration coverage (CC) and explain the challenges for (properly) calculating it. Furthermore, we present an efficient approach for determining a sufficiently small set of configurations that achieve (nearly) full coverage and evaluate it on a recent Linux kernel version.},
booktitle = {Proceedings of the 6th Workshop on Programming Languages and Operating Systems},
articleno = {2},
numpages = {5},
location = {Cascais, Portugal},
series = {PLOS '11}
}

@proceedings{10.1145/3564719,
title = {GPCE 2022: Proceedings of the 21st ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2022},
isbn = {9781450399203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 21st ACM SIGPLAN International Conference on Generative Programming: Concept &amp; Experiences (GPCE 2022) held on December 6th and 7th, 2022 in Auckland, New Zealand. GPCE is the premiere venue for researchers and practitioners interested in techniques that use program generation, domain-specific languages, and component deployment to increase programmer productivity, improve software quality, and shorten the time-to-market of software products. In addition to exploring cutting-edge techniques of generative software, GPCE seeks to foster cross-fertilization between software engineering and programming language.},
location = {Auckland, New Zealand}
}

@article{10.1145/590806.590810,
author = {Hevner, Alan R. and Collins, Rosann W. and Garfield, Monica J.},
title = {Product and project challenges in electronic commerce software development},
year = {2002},
issue_date = {Fall 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {0095-0033},
url = {https://doi.org/10.1145/590806.590810},
doi = {10.1145/590806.590810},
abstract = {Electronic commerce (E-commerce) software development organizations face unique challenges based on rapidly changing markets, demanding customers with ill-defined requirements, and resulting priority conflicts between product line development and customer projects. A model of this unique development environment is identified with important linkages among the product function, the project function, and the underlying software development function within an organization. Guided by this model of the E-commerce development environment, a case study of a medium-sized E-commerce company was conducted. Based on this study, eight critical challenges to the successful development of top quality software systems are identified. From these challenges a research model and propositions are presented. As each challenge is discussed unique impacts of the E-commerce environment are reinforced by direct quotes from in-depth interviews. On-going research will draw upon the research model and propositions to provide insights on how best to develop software products and deliver customer projects in E-commerce environments.},
journal = {SIGMIS Database},
month = dec,
pages = {10–22},
numpages = {13},
keywords = {software engineering, software development process, software development metrics, project management, product-lines, electronic commerce}
}

@inproceedings{10.1145/3439961.3439975,
author = {Pald\^{e}s, Roberto Avila and Canedo, Edna Dias and Guimar\~{a}es, Fernando de Albuquerque and Calazans, Ang\'{e}lica Toffano Seidel},
title = {Functional Requirements Elicitation in IoT Systems: a follow-up study},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439975},
doi = {10.1145/3439961.3439975},
abstract = {As the Internet of Things (IoT) advances, specific views have been proposed for the entire software development cycle and also for Requirements Engineering (RE). The analysis of the use of RE techniques, tools, and models can contribute to obtain better results in this field. This paper presents a Systematic Mapping Study (SMS) to investigate techniques for Functional Requirements (FR) elicitation in IoT software systems, as well as gaps and limitations of current solutions. During the SMS, seventeen articles focused on FR in the IoT were found. The analysis was complemented with an input from the experience of practitioners who have dedicated to this topic, obtained through structured and semi-structured interviews. The results show that FR elicitation has started from the use of traditional techniques, but that these do not fully meet the specificities of the IoT. The majority of the models found are based on UML (Unified Modeling Language) and the most important techniques are based on scenarios. The tools that support these proposals are maturing or under development. In the conclusion, the study shows the advancements already achieved, as well as the challenges and opportunities that are still present.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {14},
numpages = {10},
keywords = {Systematic Mapping Study., Software System, Internet of Things, Functional Requirements Elicitation},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.1145/352515.352519,
author = {Blackburn, Joseph and Scudder, Gary and Van Wassenhove, Luk N.},
title = {Concurrent software development},
year = {2000},
issue_date = {Nov. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {11es},
issn = {0001-0782},
url = {https://doi.org/10.1145/352515.352519},
doi = {10.1145/352515.352519},
journal = {Commun. ACM},
month = nov,
pages = {4–es},
numpages = {15}
}

@inproceedings{10.1145/581339.581415,
author = {Schmid, Klaus},
title = {A comprehensive product line scoping approach and its validation},
year = {2002},
isbn = {158113472X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/581339.581415},
doi = {10.1145/581339.581415},
abstract = {Product Line Engineering is a recent approach to software development that specifically aims at exploiting commonalities and systematic variabilities among functionally overlapping systems in terms of large scale reuse. Taking full advantage of this potential requires adequate planning and management of the reuse approach as otherwise huge economic benefits will be missed due to an inappropriate alignment of the reuse infrastructure.Key in product line planning is the scoping activity, which aims at focussing the reuse investment where it pays. Scoping actually happens on several levels in the process: during the domain analysis step (analysis of product line requirements) a focusing needs to happen just like during the decision of what to implement for reuse. The latter decision has also important ramifications for the development of an appropriate reference architecture as it provides the reusability requirements for this step.In this paper, we describe an integrated approach that has been developed, improved, and validated over the last few years. The approach fully covers the scoping activities of domain scoping and reuse infrastructure scoping and was validated in several industrial case studies.},
booktitle = {Proceedings of the 24th International Conference on Software Engineering},
pages = {593–603},
numpages = {11},
location = {Orlando, Florida},
series = {ICSE '02}
}

@article{10.5555/1181901.1181950,
author = {Hunt, John M. and McGregor, John D.},
title = {Software product lines: a pedagogical application},
year = {2006},
issue_date = {December 2006},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {22},
number = {2},
issn = {1937-4771},
abstract = {This paper provides an overview of Software Product Lines and discusses issues involved in using Software Product Lines in courses. An SPL designs and produces common assets for a group of related products as a family; rather then building the products one at a time. SPL has been successful in delivering 80% to 100% reuse. SPL is moving out of an early adaptor phase and into mainstream reuse, which should increase industry demand for developers familiar with SPL. Understanding SPL is best done with a complete example. We discuss a complete set of publicly available SPL related assets that we developed, and discuss their use in the classroom.},
journal = {J. Comput. Sci. Coll.},
month = dec,
pages = {295–302},
numpages = {8}
}

@article{10.1145/3447580,
author = {Russo, Daniel and Stol, Klaas-Jan},
title = {PLS-SEM for Software Engineering Research: An Introduction and Survey},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447580},
doi = {10.1145/3447580},
abstract = {Software Engineering (SE) researchers are increasingly paying attention to organizational and human factors. Rather than focusing only on variables that can be directly measured, such as lines of code, SE research studies now also consider unobservable variables, such as organizational culture and trust. To measure such latent variables, SE scholars have adopted Partial Least Squares Structural Equation Modeling (PLS-SEM), which is one member of the larger SEM family of statistical analysis techniques. As the SE field is facing the introduction of new methods such as PLS-SEM, a key issue is that not much is known about how to evaluate such studies. To help SE researchers learn about PLS-SEM, we draw on the latest methodological literature on PLS-SEM to synthesize an introduction. Further, we conducted a survey of PLS-SEM studies in the SE literature and evaluated those based on recommended guidelines.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {78},
numpages = {38},
keywords = {structural equation modeling, research methodology, critical review, Partial least squares}
}

@inproceedings{10.5555/3351736.3351783,
author = {Lettner, Daniela and Eder, Klaus and Gr\"{u}nbacher, Paul and Pr\"{a}hofer, Herbert},
title = {Feature modeling of two large-scale industrial software systems: experiences and lessons learned},
year = {2015},
isbn = {9781467369084},
publisher = {IEEE Press},
abstract = {Feature models are frequently used to capture the knowledge about configurable software systems and product lines. However, feature modeling of large-scale systems is challenging as many models are needed for diverse purposes. For instance, feature models can be used to reflect the perspectives of product management, technical solution architecture, or product configuration. Furthermore, models are required at different levels of granularity. Although numerous approaches and tools are available, it remains hard to define the purpose, scope, and granularity of feature models. In this paper we thus present experiences of developing feature models for two large-scale industrial automation software systems. Specifically, we extended an existing feature modeling tool to support models for different purposes and at multiple levels. We report results on the characteristics and modularity of the feature models, including metrics about model dependencies. We further discuss lessons learned during the modeling process.},
booktitle = {Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems},
pages = {386–395},
numpages = {10},
keywords = {industrial software systems, feature modeling, experience report},
location = {Ottawa, Ontario, Canada},
series = {MODELS '15}
}

@article{10.1145/966789.966803,
author = {Cheng, Li-Te and de Souza, Cleidson R.B. and Hupfer, Susanne and Patterson, John and Ross, Steven},
title = {Building Collaboration into IDEs: Edit&gt;Compile&gt;Run&gt;Debug&gt;Collaborate?},
year = {2003},
issue_date = {December/January 2003-2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {9},
issn = {1542-7730},
url = {https://doi.org/10.1145/966789.966803},
doi = {10.1145/966789.966803},
abstract = {Software development is rarely a solo coding effort. More often, it is a collaborative process, with teams of developers working together to design solutions and produce quality code. The members of these close-knit teams often look at one another’s code, collectively make plans about how to proceed, and even fix each other’s bugs when necessary. Teamwork does not stop there, however. An extended team may include project managers, testers, architects, designers, writers, and other specialists, as well as other programming teams. Programmers also interact with the community of developers outside their organization to obtain advice, code snippets, and a general understanding of what works and what doesn’t.},
journal = {Queue},
month = dec,
pages = {40–50},
numpages = {11}
}

@inproceedings{10.1145/1842752.1842811,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Categorizing and modeling variation in families of systems: a position paper},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842811},
doi = {10.1145/1842752.1842811},
abstract = {This paper presents an approach that considers variation in systems and system architectures according to the kind of relation among the variants in the software family. The approach highlights why it is beneficial to consider such different variation relations separately and gives examples of what these relations may be.Two main categories of variation relations are presented, based on whether the system architecture remains constant (architecture-based variation), or whether the architecture itself is variable, i.e. the variants do not share a common architecture. The paper introduces several different kinds of variation families that seem to belong to these two categories, as well as yet other families comprising variants that do not neatly fit in either category, with only a subset of the variants sharing a common architecture. Each kind of variation relation is illustrated with an example software family from different domains, including operating systems (OS).},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {316–323},
numpages = {8},
keywords = {variation, variability, system architectures, software product lines, software families},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1109/ASE.2009.70,
author = {Nistor, Eugen C. and Hoek, Andr\'{e} van der},
title = {Explicit Concern-Driven Development with ArchEvol},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.70},
doi = {10.1109/ASE.2009.70},
abstract = {Supporting developers in examining and evolving a software system in terms of concerns is considered a critical capability in the face of the scale and complexity of today’s software. A number of existing approaches make an inroad to providing this support, but they fall short in key ways. This paper introduces ArchEvol, a new programming environment that embodies a new kind of approach, one we term explicit concern-driven development. The vision is threefold: (1) a fine-grained concern model maps concerns to code, (2) concerns are visualized at both the code level, to assist in the actual act of making changes, and the architectural level, to assist in gauging levels of scattering and tangling, and (3) automated support assists developers in maintaining the concern mapping over time. Developers, then, continuously examine, structure, and modify the software they produce in terms of concerns. We introduce our approach, discuss how we have realized it in ArchEvol, and present the results of a first set of evaluations that demonstrate its potential.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {185–196},
numpages = {12},
keywords = {software evolution, software concerns, development environments},
series = {ASE '09}
}

@article{10.1145/3229048,
author = {Zheng, Yongjie and Cu, Cuong and Taylor, Richard N.},
title = {Maintaining Architecture-Implementation Conformance to Support Architecture Centrality: From Single System to Product Line Development},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3229048},
doi = {10.1145/3229048},
abstract = {Architecture-centric development addresses the increasing complexity and variability of software systems by focusing on architectural models, which are generally easier to understand and manipulate than source code. It requires a mechanism that can maintain architecture-implementation conformance during architectural development and evolution. The challenge is twofold. There is an abstraction gap between software architecture and implementation, and both may evolve. Existing approaches are deficient in support for both change mapping and product line architecture. This article presents a novel approach named 1.x-way mapping and its extension, 1.x-line mapping to support architecture-implementation mapping in single system development and in product line development, respectively. They specifically address mapping architecture changes to code, maintaining variability conformance between product line architecture and code, and tracing architectural implementation. We built software tools named xMapper and xLineMapper to realize the two approaches, and conducted case studies with two existing open-source systems to evaluate the approaches. The result shows that our approaches are applicable to the implementation of a real software system and are capable of maintaining architecture-implementation conformance during system evolution.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {8},
numpages = {52},
keywords = {variability conformance, architecture-centric feature traceability, architecture-centric development, architectural evolution, Architecture-implementation mapping}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/581339.581369,
author = {Weiss, David M. and Bennett, David and Payseur, John Y. and Tendick, Pat and Zhang, Ping},
title = {Goal-oriented software assessment},
year = {2002},
isbn = {158113472X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/581339.581369},
doi = {10.1145/581339.581369},
abstract = {Companies that engage in multi-site, multi-project software development continually face the problem of how to understand and improve their software development capabilities. We have defined and applied a goal-oriented process that enables such a company to assess the strengths and weaknesses of those capabilities. Our goals are to help a) to decrease the time and cost to develop software, b)to decrease the time needed to make changes to existing software, c) to improve software quality, d) to attract and retain a talented engineering staff, and e) to facilitate more predictable management of software projects. In response to the variety of product requirements, market needs, and development environments, we selected a goal-oriented process, rather than a criteria-oriented process, to advance our strategy and ensure relevance of the results. We describe the design of the process, discuss results achieved, and present vulnerabilities of the methodology. The process includes both interviews with projects' personnel and analysis of change data. Several common issues have emerged from the assessments across multiple projects, enabling strategic investments in software technology. Teams report satisfaction with the outcome in that they act on the recommendations, ask for additional future assessments, and recommend the process to sibling organizations.},
booktitle = {Proceedings of the 24th International Conference on Software Engineering},
pages = {221–231},
numpages = {11},
location = {Orlando, Florida},
series = {ICSE '02}
}

@inproceedings{10.1145/3196398.3196442,
author = {Nair, Vivek and Agrawal, Amritanshu and Chen, Jianfeng and Fu, Wei and Mathew, George and Menzies, Tim and Minku, Leandro and Wagner, Markus and Yu, Zhe},
title = {Data-driven search-based software engineering},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196442},
doi = {10.1145/3196398.3196442},
abstract = {This paper introduces Data-Driven Search-based Software Engineering (DSE), which combines insights from Mining Software Repositories (MSR) and Search-based Software Engineering (SBSE). While MSR formulates software engineering problems as data mining problems, SBSE reformulate Software Engineering (SE) problems as optimization problems and use meta-heuristic algorithms to solve them. Both MSR and SBSE share the common goal of providing insights to improve software engineering. The algorithms used in these two areas also have intrinsic relationships. We, therefore, argue that combining these two fields is useful for situations (a) which require learning from a large data source or (b) when optimizers need to know the lay of the land to find better solutions, faster.This paper aims to answer the following three questions: (1) What are the various topics addressed by DSE?, (2) What types of data are used by the researchers in this area?, and (3) What research approaches do researchers use? The paper briefly sets out to act as a practical guide to develop new DSE techniques and also to serve as a teaching resource.This paper also presents a resource (tiny.cc/data-se) for exploring DSE. The resource contains 89 artifacts which are related to DSE, divided into 13 groups such as requirements engineering, software product lines, software processes. All the materials in this repository have been used in recent software engineering papers; i.e., for all this material, there exist baseline results against which researchers can comparatively assess their new ideas.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {341–352},
numpages = {12},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/3297280.3297512,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {Test case selection using structural coverage in software product lines for time-budget constrained scenarios},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297512},
doi = {10.1145/3297280.3297512},
abstract = {Testing product lines is a challenging activity due to the large number of products to be tested. Many approaches focus on reducing the time for testing a product line by reducing the number of products to be tested, by employing, for instance, combinatorial approaches. However, even if the number of derived products by a combinatorial approach is limited, testing can still be time consuming. In this paper, we propose three different test case selection methods that consider a given time budget to test product lines in an efficient manner using structural coverage information. We analyze the three methods with three white-box coverage criteria (i.e., Decision Coverage, Condition Coverage and Modified Condition/Decision Coverage). We evaluate the different approaches with a case study from the automotive domain and mutation testing. The results suggest that considering coverage information at the domain engineering level helps on detecting more faults, particularly when time budgets are low.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2362–2371},
numpages = {10},
keywords = {product line testing, structural coverage, test case selection},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@article{10.1145/2967307.2967314,
author = {Doernhoefer, Mark},
title = {Surfing the Net for Software Engineering Notes},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/2967307.2967314},
doi = {10.1145/2967307.2967314},
journal = {SIGSOFT Softw. Eng. Notes},
month = aug,
pages = {9–17},
numpages = {9}
}

@inproceedings{10.1145/2745802.2745815,
author = {Zhou, You and Zhang, He and Huang, Xin and Yang, Song and Babar, Muhammad Ali and Tang, Hao},
title = {Quality assessment of systematic reviews in software engineering: a tertiary study},
year = {2015},
isbn = {9781450333504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745802.2745815},
doi = {10.1145/2745802.2745815},
abstract = {Context: The quality of an Systematic Literature Review (SLR) is as good as the quality of the reviewed papers. Hence, it is vital to rigorously assess the papers included in an SLR. There has been no tertiary study aimed at reporting the state of the practice of quality assessment used in SLRs in Software Engineering (SE).Objective: We aimed to study the practices of quality assessment of the papers included in SLRs in SE.Method: We conducted a tertiary study of the SLRs that have performed quality assessment of the reviewed papers.Results: We identified and analyzed different aspects of the quality assessment of the papers included in 127 SLRs.Conclusion: Researchers use a variety of strategies for quality assessment of the papers reviewed, but report little about the justification for the used criteria. The focus is creditability but not relevance aspect of the papers. Appropriate guidelines are required for devising quality assessment strategies.},
booktitle = {Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {14},
numpages = {14},
keywords = {systematic (literature) review, software engineering, quality assessment},
location = {Nanjing, China},
series = {EASE '15}
}

@inproceedings{10.1109/ASE.2013.6693104,
author = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
title = {Scalable product line configuration: a straw to break the camel's back},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693104},
doi = {10.1109/ASE.2013.6693104},
abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a "seed" in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {465–474},
numpages = {10},
keywords = {variability models, multiobjective optimization, evolutionary algorithms, automated configuration, SMT solvers},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1145/2866614.2866624,
author = {Rothberg, Valentin and Dintzner, Nicolas and Ziegler, Andreas and Lohmann, Daniel},
title = {Feature Models in Linux: From Symbols to Semantics},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866624},
doi = {10.1145/2866614.2866624},
abstract = {Linux is a highly configurable operating-system kernel which has been widely studied in the context of software product lines over the past years. Understanding the challenges and perils of evolving and maintaining feature models of the size of Linux is crucial to provide the right tools for development today and to direct future research. Unfortunately, previous studies show contradictory observations when analyzing the evolution of Linux feature models. We explain how peculiarities of the feature models of the Linux kernel lead to those differing observations, and show how the results can be re-aligned. Moreover, our findings also demonstrate that symbolic differencing on feature models used by researchers so far has limited value, depending on the use case. We show how the limitations can be addressed by means of semantic differencing, and ironically invalidate the results we sought to re-align.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {65–72},
numpages = {8},
keywords = {Linux, Kconfig, Feature Models, Configurability, CADOS},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@inproceedings{10.1145/508791.508986,
author = {Lee, Seok Won},
title = {Proxy Viewpoints Model-based Requirements engineering},
year = {2002},
isbn = {1581134452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/508791.508986},
doi = {10.1145/508791.508986},
abstract = {This paper addresses the problem of the "missing requirements" in software requirement specification (SRS) expressed in natural language. Due to rapid changes in technology and business frequently witnessed over time, the original SRS documents often experience the problems of missing, not available, and hard-to-locate requirements. One of the flaws in earlier solutions to this problem has no consideration for missing requirements from multiple viewpoints. Furthermore, since such SRS documents represent an incomplete domain model, manual discovery (identification and incorporation) of missing requirements is highly labor intensive and error-prone. Consequently, deriving and improving an efficient adaptation of SRS changes remain a complex problem. In this paper, we present a new methodology entitled "Proxy Viewpoints Model-based Requirements Discovery (PVRD)". Through the requirements discovery and analysis process, PVRD methodology provides ways to construct proxy viewpoints model from legacy status requirements. Requirements term expansion technique facilitates the retrieval process of requirements of interest based on the improved requirements representation space in proxy viewpoints model. The PVRD methodology provides an integrated environment that supports requirements discovery process as well as efficient management.},
booktitle = {Proceedings of the 2002 ACM Symposium on Applied Computing},
pages = {1004–1008},
numpages = {5},
keywords = {term expansion, requirements discovery, proxy viewpoints},
location = {Madrid, Spain},
series = {SAC '02}
}

@proceedings{10.1145/3669940,
title = {ASPLOS '25: Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to introduce the first volume of the ASPLOS proceedings for 2025. The conference is in its third year of an experiment with a three-deadline structure: authors can submit to any of three separate review cycles handled by a single year-long program committee. This volume includes papers from the first two review cycles, which had submission deadlines in the spring and summer of 2024. We combined the two cycles because submission volumes in the spring cycle were disproportionately small.This volume contains 72 of the 74 papers accepted to ASPLOS 2025 to date. This includes papers accepted in the spring and summer cycles and those invited to submit a revision in the spring cycle that was ultimately accepted. Two of these 74 accepted papers are still undergoing artifact evaluation and will be published in a subsequent volume. The spring and summer review cycles saw a combined 586 submissions. These submissions were reviewed by a 208-person Program Committee augmented by 57 External Review Committee members. On occasion, we solicited a small number of external expert reviews. On the PC, 129 members self-reported they were in an academic role and 77 self-reported they were in an industrial role. On the ERC it was 43 and 13 respectively. The median PhD year of the combined committees was 2014. In addition to these committees, we engaged ten vice chairs, experienced and trusted reviewers who helped us monitor the review process for each paper.These committees reviewed all of the submissions that were not desk rejected (11 papers) or withdrawn (4 papers). In keeping with recent norms, the technical review happened in two phases. Each paper received three reviews in the first round, with, in most cases, two additional reviews in the second round for the 54% of submissions that advanced. To assign reviews, we used the Toronto Paper Matching System (TPMS) to provide a preliminary review assignment that matched reviewer expertise. We then manually inspected and adjusted these assignments as needed: for example, to correct errors in TPMS's topic modeling or adjust to late-discovered conflicts. In addition, each paper was assigned a non-conflicted chair and a non-conflicted vice chair to provide two extra sets of eyes to monitor and facilitate the process. Due to the size and distribution of the PC, which spanned 14 time zones, the PC did not meet synchronously. Instead, each paper was discussed by the reviewers via comments in the HotCRP system. Ultimately, the discussion for each paper reached one of three outcomes: rejection, conditional acceptance, or major revision. All conditionally accepted papers were shepherded. Major revision papers were invited to revise and resubmit their paper for a second round of review by a subset of the original reviewers. All authors of papers that advanced to the second round of review were given the opportunity to see and respond to their reviewer questions prior to the reviewer discussion.},
location = {Rotterdam, Netherlands}
}

@inproceedings{10.1145/2491411.2491446,
author = {Rubin, Julia and Chechik, Marsha},
title = {N-way model merging},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491446},
doi = {10.1145/2491411.2491446},
abstract = {Model merging is widely recognized as an essential step in a variety of software development activities. During the process of combining a set of related products into a product line or consolidating model views of multiple stakeholders, we need to merge multiple input models into one; yet, most of the existing approaches are applicable to merging only two models. In this paper, we define the n-way merge problem. We show that it can be reduced to the known and widely studied NP-hard problem of weighted set packing. Yet, the approximation solutions for that problem do not scale for real-sized software models. We thus evaluate alternative approaches of merging models that incrementally process input models in small subsets and propose our own algorithm that considerably improves precision over such approaches without sacrificing performance.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {301–311},
numpages = {11},
keywords = {weighted set packing, combining multiple models, Model merging},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1145/2063239.2063245,
author = {Erwig, Martin and Walkingshaw, Eric},
title = {The Choice Calculus: A Representation for Software Variation},
year = {2011},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2063239.2063245},
doi = {10.1145/2063239.2063245},
abstract = {Many areas of computer science are concerned with some form of variation in software---from managing changes to software over time to supporting families of related artifacts. We present the choice calculus, a fundamental representation for software variation that can serve as a common language of discourse for variation research, filling a role similar to the lambda calculus in programming language research. We also develop an associated theory of software variation, including sound transformations of variation artifacts, the definition of strategic normal forms, and a design theory for variation structures, which will support the development of better algorithms and tools.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {6},
numpages = {27},
keywords = {representation, Variation}
}

@inproceedings{10.5555/2664398.2664422,
author = {Yoshimura, Kentaro and Mibe, Ryota},
title = {Visualizing code clone outbreak: an industrial case study},
year = {2012},
isbn = {9781467317955},
publisher = {IEEE Press},
abstract = {This paper describes an industrial experience on code clone visualization. Cloning source code fragments is a common practice in software development process. However, uncontrolled proliferation of code clones causes a serious problem in terms of software maintenance. In this paper, we briefly share our experience on code clone visualization especially for stakeholders who are not software experts. We describe our prototype tool for code clone visualization, and the feedback we have received with analyzing an enterprise business system.},
booktitle = {Proceedings of the 6th International Workshop on Software Clones},
pages = {96},
numpages = {1},
keywords = {software visualization, legacy system, code clone},
location = {Zurich, Switzerland},
series = {IWSC '12}
}

@proceedings{10.1145/2993236,
title = {GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/1944892.1944905,
author = {John, Isabel and Silva, Adeline},
title = {Evaluating variability instantiation strategies for product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944905},
doi = {10.1145/1944892.1944905},
abstract = {Explicit variability management is essential for large product lines and requires explicit strategies for instantiating the managed variabilities during application engineering. An instantiation strategy proposes a certain order for the resolution of variabilities during application engineering or for testing. If an alphabetical strategy is used, for instance, the variabilities are resolved in alphabetical order, from A to Z. In this paper, we motivate the necessity of strategies for large variability models, which help to identify starting points and guide the resolution of variability models.We sketch the application of the strategies in a tool and give the results of an experiment performed to compare the strategies in different situations. The experiment showed that the efficiency of instantiation differs by more than 35% between different strategies. Additionally, the meaningfulness of the instantiation was perceived differently for the various strategies and the strategies were all perceived as being easy to resolve. With the experiment, we managed to demonstrate that the effectiveness of instantiation strategies differs, which motivates the need for different variability instantiation strategies in different situations.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {105–113},
numpages = {9},
keywords = {variability, instantiation, decisions},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1109/ICSE.2019.00091,
author = {Heradio, Ruben and Fernandez-Amoros, David and Mayr-Dorn, Christoph and Egyed, Alexander},
title = {Supporting the statistical analysis of variability models},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00091},
doi = {10.1109/ICSE.2019.00091},
abstract = {Variability models are broadly used to specify the configurable features of highly customizable software. In practice, they can be large, defining thousands of features with their dependencies and conflicts. In such cases, visualization techniques and automated analysis support are crucial for understanding the models. This paper contributes to this line of research by presenting a novel, probabilistic foundation for statistical reasoning about variability models. Our approach not only provides a new way to visualize, describe and interpret variability models, but it also supports the improvement of additional state-of-the-art methods for software product lines; for instance, providing exact computations where only approximations were available before, and increasing the sensitivity of existing analysis operations for variability models. We demonstrate the benefits of our approach using real case studies with up to 17,365 features, and written in two different languages (KConfig and feature models).},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {843–853},
numpages = {11},
keywords = {variability modeling, software visualization, software product lines, feature modeling, binary decision diagrams},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2593743.2593746,
author = {Sierszecki, Krzysztof and Steffens, Michaela and Fogdal, Thomas and Savolainen, Juha and Mikkonen, Tommi},
title = {Towards green power electronics: software controllers and domain knowledge},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593743.2593746},
doi = {10.1145/2593743.2593746},
abstract = {One of the key challenges of green software is that various aspects have an impact to the overall energy consumption over the lifetime of a system operated by software. In particular, in the field of industrial applications, where embedded devices cooperate with many IT systems to make the industrial processes more efficient, to reduce waste or raw materials, and to save the environment, the concept of green software becomes unclear. In this paper, we address the green aspects of software in different phases – software construction, software execution, and software control in both inside an individual component and as a part of a complete industrial application. Furthermore, we demonstrate that the insight into system knowledge, not aspects related to software per se, is the key to create truly green software. Consequently, when considering truly software green, the focus is to be placed on the system level savings for embedded systems at the highest possible level where domain knowledge can be taken into account, not on software development or execution.},
booktitle = {Proceedings of the 3rd International Workshop on Green and Sustainable Software},
pages = {17–22},
numpages = {6},
keywords = {variable speed drives, software product lines, software development, green systems, embedded control systems, Green software},
location = {Hyderabad, India},
series = {GREENS 2014}
}

@inproceedings{10.1109/ASE.2015.47,
author = {Li, Yi and Rubin, Julia and Chechik, Marsha},
title = {Semantic slicing of software version histories},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.47},
doi = {10.1109/ASE.2015.47},
abstract = {Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a specific subset of the change history, "inheriting" additional, unwanted functionality.In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We refer to our approach, CSLICER, as semantic slicing of version histories. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and instantiate it in a specific implementation for Java projects managed in Git. We evaluate the correctness and effectiveness of our approach on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {686–696},
numpages = {11},
keywords = {version history, software changes, dependency},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@inproceedings{10.1145/2110147.2110162,
author = {Helvensteijn, Michiel},
title = {Delta modeling workflow},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110162},
doi = {10.1145/2110147.2110162},
abstract = {In previous work we show how abstract delta modeling can be used to model product lines. The formalism assigns a functional meaning to features from a feature model and provides a novel mechanism for resolving implementation conflicts without code duplication or overspecification. But in the vast expressive space of delta modeling, it may not be clear to a developer how to create a product line from scratch. The formalism was descriptive rather than prescriptive. To that end, we propose a development workflow based directly on Abstract Delta Modeling. We show preservation of global unambiguity and completeness in the product lines resulting from this workflow. We also show that the work-flow naturally supports concurrent development.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {129–137},
numpages = {9},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@inproceedings{10.1109/ICSE43902.2021.00142,
author = {Nguyen, KimHao and Nguyen, ThanhVu},
title = {GenTree: Using Decision Trees to Learn Interactions for Configurable Software},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00142},
doi = {10.1109/ICSE43902.2021.00142},
abstract = {Modern software systems are increasingly designed to be highly configurable, which increases flexibility but can make programs harder to develop, test, and analyze, e.g., how configuration options are set to reach certain locations, what characterizes the configuration space of an interesting or buggy program behavior? We introduce GenTree, a new dynamic analysis that automatically learns a program's interactions---logical formulae that describe how configuration option settings map to code coverage. GenTree uses an iterative refinement approach that runs the program under a small sample of configurations to obtain coverage data; uses a custom classifying algorithm on these data to build decision trees representing interaction candidates; and then analyzes the trees to generate new configurations to further refine the trees and interactions in the next iteration. Our experiments on 17 configurable systems spanning 4 languages show that GenTree efficiently finds precise interactions using a tiny fraction of the configuration space.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1598–1609},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1145/3176644,
author = {Xiang, Yi and Zhou, Yuren and Zheng, Zibin and Li, Miqing},
title = {Configuring Software Product Lines by Combining Many-Objective Optimization and SAT Solvers},
year = {2018},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3176644},
doi = {10.1145/3176644},
abstract = {A feature model (FM) is a compact representation of the information of all possible products from software product lines. The optimal feature selection involves the simultaneous optimization of multiple (usually more than three) objectives in a large and highly constrained search space. By combining our previous work on many-objective evolutionary algorithm (i.e., VaEA) with two different satisfiability (SAT) solvers, this article proposes a new approach named SATVaEA for handling the optimal feature selection problem. In SATVaEA, an FM is simplified with the number of both features and constraints being reduced greatly. We enhance the search of VaEA by using two SAT solvers: one is a stochastic local search--based SAT solver that can quickly repair infeasible configurations, whereas the other is a conflict-driven clause-learning SAT solver that is introduced to generate diversified products. We evaluate SATVaEA on 21 FMs with up to 62,482 features, including two models with realistic values for feature attributes. The experimental results are promising, with SATVaEA returning 100% valid products on almost all FMs. For models with more than 10,000 features, the search in SATVaEA takes only a few minutes. Concerning both effectiveness and efficiency, SATVaEA significantly outperforms other state-of-the-art algorithms.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {14},
numpages = {46},
keywords = {vector angle--based evolutionary algorithm (VaEA), satisfiability (SAT) solvers, many-objective optimization, Optimal feature selection}
}

@proceedings{10.1145/3001867,
title = {FOSD 2016: Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/2628136.2628155,
author = {Chen, Sheng and Erwig, Martin},
title = {Type-based parametric analysis of program families},
year = {2014},
isbn = {9781450328739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628136.2628155},
doi = {10.1145/2628136.2628155},
abstract = {Previous research on static analysis for program families has focused on lifting analyses for single, plain programs to program families by employing idiosyncratic representations. The lifting effort typically involves a significant amount of work for proving the correctness of the lifted algorithm and demonstrating its scalability. In this paper, we propose a parameterized static analysis framework for program families that can automatically lift a class of type-based static analyses for plain programs to program families. The framework consists of a parametric logical specification and a parametric variational constraint solver. We prove that a lifted algorithm is correct provided that the underlying analysis algorithm is correct. An evaluation of our framework has revealed an error in a previous manually lifted analysis. Moreover, performance tests indicate that the overhead incurred by the general framework is bounded by a factor of 2.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
pages = {39–51},
numpages = {13},
keywords = {variational types, static-analysis lifting, program families, constraint-based type system, choice calculus},
location = {Gothenburg, Sweden},
series = {ICFP '14}
}

@inproceedings{10.1145/2786805.2786809,
author = {Lo, David and Nagappan, Nachiappan and Zimmermann, Thomas},
title = {How practitioners perceive the relevance of software engineering research},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786809},
doi = {10.1145/2786805.2786809},
abstract = {The number of software engineering research papers over the last few years has grown significantly. An important question here is: how relevant is software engineering research to practitioners in the field? To address this question, we conducted a survey at Microsoft where we invited 3,000 industry practitioners to rate the relevance of research ideas contained in 571 ICSE, ESEC/FSE and FSE papers that were published over a five year period. We received 17,913 ratings by 512 practitioners who labelled ideas as essential, worthwhile, unimportant, or unwise. The results from the survey suggest that practitioners are positive towards studies done by the software engineering research community: 71% of all ratings were essential or worthwhile. We found no correlation between the citation counts and the relevance scores of the papers. Through a qualitative analysis of free text responses, we identify several reasons why practitioners considered certain research ideas to be unwise. The survey approach described in this paper is lightweight: on average, a participant spent only 22.5 minutes to respond to the survey. At the same time, the results can provide useful insight to conference organizers, authors, and participating practitioners.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {415–425},
numpages = {11},
keywords = {Survey, Software Engineering Research, Industry},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3468264.3468605,
author = {Wu, Xiuheng and Zhu, Chenguang and Li, Yi},
title = {DIFFBASE: a differential factbase for effective software evolution management},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468605},
doi = {10.1145/3468264.3468605},
abstract = {Numerous tools and techniques have been developed to extract and analyze information from software development artifacts. Yet, there is a lack of effective method to process, store, and exchange information among different analyses. In this paper, we propose differential factbase, a uniform exchangeable representation supporting efficient querying and manipulation, based on the existing concept of program facts. We consider program changes as first-class objects, which establish links between intra-version facts of single program snapshots and provide insights on how certain artifacts evolve over time via inter-version facts. We implement a series of differential fact extractors supporting different programming languages and platforms, and demonstrate with usage scenarios the benefits of adopting differential facts in supporting software evolution management.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {503–515},
numpages = {13},
keywords = {software maintenance, reverse engineering, program facts, Software evolution},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3239372.3239377,
author = {de Lara, Juan and Guerra, Esther and Chechik, Marsha and Salay, Rick},
title = {Model Transformation Product Lines},
year = {2018},
isbn = {9781450349499},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239372.3239377},
doi = {10.1145/3239372.3239377},
abstract = {Model transformations enable automation in Model-Driven Engineering (MDE) and are key to its success. The emphasis of MDE on using domain-specific languages has caused a proliferation of meta-models, many of them capturing variants of base languages. In this scenario, developing a transformation for a new meta-model is usually performed manually with no reuse, even if comparable transformations for similar meta-models exist. This is a suboptimal process that precludes a wider adoption of MDE in industry.To improve this situation, we propose applying ideas from software product lines to transformation engineering. Our proposal enables the definition of meta-model product lines to capture the variability within a domain, on top of which transformations can be defined in a modular way. We call this construction transformation product line (TPL), and propose mechanisms for their construction, extension and analysis. TPLs are supported by a tool, Merlin, which is agnostic to the transformation language and lifts analyses based on model finding to the TPL. Finally, we report on an evaluation showing the benefits of building and analysing TPLs compared to building and analysing each individual transformation.},
booktitle = {Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {67–77},
numpages = {11},
keywords = {Reusability, Product Lines, Model Transformations},
location = {Copenhagen, Denmark},
series = {MODELS '18}
}

@article{10.1145/3041957,
author = {Rosa, Marcello La and Aalst, Wil M. P. Van Der and Dumas, Marlon and Milani, Fredrik P.},
title = {Business Process Variability Modeling: A Survey},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3041957},
doi = {10.1145/3041957},
abstract = {It is common for organizations to maintain multiple variants of a given business process, such as multiple sales processes for different products or multiple bookkeeping processes for different countries. Conventional business process modeling languages do not explicitly support the representation of such families of process variants. This gap triggered significant research efforts over the past decade, leading to an array of approaches to business process variability modeling. In general, each of these approaches extends a conventional process modeling language with constructs to capture customizable process models. A customizable process model represents a family of process variants in a way that a model of each variant can be derived by adding or deleting fragments according to customization options or according to a domain model. This survey draws up a systematic inventory of approaches to customizable process modeling and provides a comparative evaluation with the aim of identifying common and differentiating modeling features, providing criteria for selecting among multiple approaches, and identifying gaps in the state of the art. The survey puts into evidence an abundance of customizable process-modeling languages, which contrasts with a relative scarcity of available tool support and empirical comparative evaluations.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {2},
numpages = {45},
keywords = {process model, customizable process model, Variability modeling}
}

@inproceedings{10.1145/1960502.1960508,
author = {Machado, Idarlan and Bonif\'{a}cio, Rodrigo and Alves, Vander and Turnes, Lucin\'{e}ia and Machado, Giselle},
title = {Managing variability in business processes: an aspect-oriented approach},
year = {2011},
isbn = {9781450306454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1960502.1960508},
doi = {10.1145/1960502.1960508},
abstract = {Business processes specify key activities in an organization, some of which can be automated. It is often the case that replication of activities across such processes occur and failure in identifying such replication results in organizational costs. To minimize this risk and optimize organizational resources, in this paper we characterize variability in business process and propose an approach to manage such a variability. The characterization of variability relies on the study of industrial-strength applications in the Human Resources domain. The management of variability is based on a compositional and parametric approach with Aspect-Orientation. It leverages and extends an existing tool to address variability in such domain},
booktitle = {Proceedings of the 2011 International Workshop on Early Aspects},
pages = {25–30},
numpages = {6},
keywords = {software product lines, composition, business processes, aspects},
location = {Porto de Galinhas, Brazil},
series = {EA '11}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@article{10.1145/2638550,
author = {Wu, Lisa and Polychroniou, Orestis and Barker, Raymond J. and Kim, Martha A. and Ross, Kenneth A.},
title = {Energy Analysis of Hardware and Software Range Partitioning},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0734-2071},
url = {https://doi.org/10.1145/2638550},
doi = {10.1145/2638550},
abstract = {Data partitioning is a critical operation for manipulating large datasets because it subdivides tasks into pieces that are more amenable to efficient processing. It is often the limiting factor in database performance and represents a significant fraction of the overall runtime of large data queries. This article measures the performance and energy of state-of-the-art software partitioners, and describes and evaluates a hardware range partitioner that further improves efficiency.The software implementation is broken into two phases, allowing separate analysis of the partition function computation and data shuffling costs. Although range partitioning is commonly thought to be more expensive than simpler strategies such as hash partitioning, our measurements indicate that careful data movement and optimization of the partition function can allow it to approach the throughput and energy consumption of hash or radix partitioning.For further acceleration, we describe a hardware range partitioner, or HARP, a streaming framework that offers a seamless execution environment for this and other streaming accelerators, and a detailed analysis of a 32nm physical design that matches the throughput of four to eight software threads while consuming just 6.9% of the area and 4.3% of the power of a Xeon core in the same technology generation.},
journal = {ACM Trans. Comput. Syst.},
month = aug,
articleno = {8},
numpages = {24},
keywords = {streaming data, specialized functional unit, microarchitecture, data partitioning, Accelerator}
}

@article{10.1145/2807593,
author = {Baudry, Benoit and Monperrus, Martin},
title = {The Multiple Facets of Software Diversity: Recent Developments in Year 2000 and Beyond},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2807593},
doi = {10.1145/2807593},
abstract = {Early experiments with software diversity in the mid 1970s investigated N-version programming and recovery blocks to increase the reliability of embedded systems. Four decades later, the literature about software diversity has expanded in multiple directions: goals (fault tolerance, security, software engineering), means (managed or automated diversity), and analytical studies (quantification of diversity and its impact). Our article contributes to the field of software diversity as the first work that adopts an inclusive vision of the area, with an emphasis on the most recent advances in the field. This survey includes classical work about design and data diversity for fault tolerance, as well as the cybersecurity literature that investigates randomization at different system levels. It broadens this standard scope of diversity to include the study and exploitation of natural diversity and the management of diverse software products. Our survey includes the most recent works, with an emphasis from 2000 to the present. The targeted audience is researchers and practitioners in one of the surveyed fields who miss the big picture of software diversity. Assembling the multiple facets of this fascinating topic sheds a new light on the field.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {16},
numpages = {26},
keywords = {program transformation, design principles, Software diversity}
}

@inproceedings{10.5555/2337223.2337260,
author = {Li, Jingyue and Ernst, Michael D.},
title = {CBCD: cloned buggy code detector},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Developers often copy, or clone, code in order to reuse or modify functionality. When they do so, they also clone any bugs in the original code. Or, different developers may independently make the same mistake. As one example of a bug, multiple products in a product line may use a component in a similar wrong way. This paper makes two contributions. First, it presents an empirical study of cloned buggy code. In a large industrial product line, about 4% of the bugs are duplicated across more than one product or file. In three open source projects (the Linux kernel, the Git version control system, and the PostgreSQL database) we found 282, 33, and 33 duplicated bugs, respectively. Second, this paper presents a tool, CBCD, that searches for code that is semantically identical to given buggy code. CBCD tests graph isomorphism over the Program Dependency Graph (PDG) representation and uses four optimizations. We evaluated CBCD by searching for known clones of buggy code segments in the three projects and compared the results with text-based, token-based, and AST-based code clone detectors, namely Simian, CCFinder, Deckard, and CloneDR. The evaluation shows that CBCD is fast when searching for possible clones of the buggy code in a large system, and it is more precise for this purpose than the other code clone detectors.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {310–320},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@article{10.1145/3239571,
author = {Yang, Peilin and Fang, Hui and Lin, Jimmy},
title = {Anserini: Reproducible Ranking Baselines Using Lucene},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1936-1955},
url = {https://doi.org/10.1145/3239571},
doi = {10.1145/3239571},
abstract = {This work tackles the perennial problem of reproducible baselines in information retrieval research, focusing on bag-of-words ranking models. Although academic information retrieval researchers have a long history of building and sharing systems, they are primarily designed to facilitate the publication of research papers. As such, these systems are often incomplete, inflexible, poorly documented, difficult to use, and slow, particularly in the context of modern web-scale collections. Furthermore, the growing complexity of modern software ecosystems and the resource constraints most academic research groups operate under make maintaining open-source systems a constant struggle. However, except for a small number of companies (mostly commercial web search engines) that deploy custom infrastructure, Lucene has become the de facto platform in industry for building search applications. Lucene has an active developer base, a large audience of users, and diverse capabilities to work with heterogeneous collections at scale. However, it lacks systematic support for ad hoc experimentation using standard test collections. We describe Anserini, an information retrieval toolkit built on Lucene that fills this gap. Our goal is to simplify ad hoc experimentation and allow researchers to easily reproduce results with modern bag-of-words ranking models on diverse test collections. With Anserini, we demonstrate that Lucene provides a suitable framework for supporting information retrieval research. Experiments show that our system efficiently indexes large web collections, provides modern ranking models that are on par with research implementations in terms of effectiveness, and supports low-latency query evaluation to facilitate rapid experimentation},
journal = {J. Data and Information Quality},
month = oct,
articleno = {16},
numpages = {20},
keywords = {TREC, Ad hoc retrieval}
}

@inproceedings{10.5555/2667025.2667028,
author = {Boss, Birgit},
title = {Architectural aspects of software sharing and standardization: AUTOSAR for automotive domain},
year = {2012},
isbn = {9781467318532},
publisher = {IEEE Press},
abstract = {Business and cooperation models in the automotive domain are becoming more and more complex and flexible. The following two models and their impact on software architecture will be discussed in more detail: 1) delivery of code relevant artifacts from the OEM (original automobile equipment manufacturer) to the Tier1 (supplier of OEM) and the other way around: 2) delivery of Tier1 software to the OEM. Both use cases and all its derivations are subsumed under the term "Software Sharing". The discussion is based on the concrete experiences of BOSCH Powertrain (Diesel Gasoline Systems, DGS) in the area of software sharing. Improvements are seen in the strengthened use of standardized architecture and application interfaces. The most important software standard in the automotive domain is AUTOSAR (AUTomotive Open System ARchitecture).},
booktitle = {Proceedings of the Second International Workshop on Software Engineering for Embedded Systems},
pages = {9–15},
numpages = {7},
keywords = {supplier agreement management, standardization, software sharing, software architecture, software adapter, product line development, life cycle management, industrial practice and experience, embedded software, distributed software development, AUTOSAR},
location = {Zurich, Switzerland},
series = {SEES '12}
}

@proceedings{10.1145/3599691,
title = {HotStorage '23: Proceedings of the 15th ACM Workshop on Hot Topics in Storage and File Systems},
year = {2023},
isbn = {9798400702242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@inproceedings{10.1007/978-3-642-12261-3_9,
author = {Becker, Basil and Giese, Holger and Neumann, Stefan and Schenck, Martin and Treffer, Arian},
title = {Model-Based extension of AUTOSAR for architectural online reconfiguration},
year = {2009},
isbn = {3642122604},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12261-3_9},
doi = {10.1007/978-3-642-12261-3_9},
abstract = {In the last few years innovations in the automotive domain have been realized by software, leading to a dramatically increased complexity of such systems. Additionally, automotive systems have to be flexible and robust, e.g., to be able to deal with failures of sensors, actuators or other constituents of an automotive system. One possibility to achieve robustness and flexibility in automotive systems is the usage of reconfiguration capabilities. However, adding such capabilities introduces an even higher degree of complexity. To avoid this drawback we propose to integrate reconfiguration capabilities into AUTOSAR, an existing framework supporting the management of such a complex system at the architectural level. Elaborated and expensive tools and toolchains assist during the development of automotive systems. Hence, we present how our reconfiguration solution has been seamlessly integrated into such a toolchain.},
booktitle = {Proceedings of the 2009 International Conference on Models in Software Engineering},
pages = {83–97},
numpages = {15},
location = {Denver, CO},
series = {MODELS'09}
}

@article{10.1145/1118890.1118892,
author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
title = {When and how to develop domain-specific languages},
year = {2005},
issue_date = {December 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/1118890.1118892},
doi = {10.1145/1118890.1118892},
abstract = {Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage.Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, we identify patterns in the decision, analysis, design, and implementation phases of DSL development. Our patterns improve and extend earlier work on DSL design patterns. We also discuss domain analysis tools and language development systems that may help to speed up DSL development. Finally, we present a number of open problems.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {316–344},
numpages = {29},
keywords = {language development system, domain analysis, application language, Domain-specific language}
}

@article{10.1145/979743.979745,
author = {ACM SIGSOFT Software Engineering Notes staff},
title = {Back matter (abstracts and calendar)},
year = {2004},
issue_date = {March 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/979743.979745},
doi = {10.1145/979743.979745},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {27–62},
numpages = {36}
}

@inproceedings{10.1145/2970276.2970314,
author = {Maro, Salome and Anjorin, Anthony and Wohlrab, Rebekka and Stegh\"{o}fer, Jan-Philipp},
title = {Traceability maintenance: factors and guidelines},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970314},
doi = {10.1145/2970276.2970314},
abstract = {Traceability is an important concern for numerous software engineering activities. Establishing traceability links is a challenging and cost-intensive task, which is uneconomical without suitable strategies for maintaining high link quality. Current approaches to Traceability Management (TM), however, often make important assumptions and choices without ensuring that the consequences and implications for traceability maintenance are feasible and desirable in practice.  In this paper, therefore, we identify a set of core factors that influence how the quality of traceability links can be maintained. For each factor, we discuss relevant challenges and provide guidelines on how best to ensure viable traceability maintenance in a practical TM approach. Our guidelines are meant to be used by tool developers and users to select the most appropriate TM approach for their needs.  Our results are based on and supported by data collected from interviews conducted with: (i) 9 of our industrial and academic project partners to elicit requirements for a TM tool, and (ii) 24 software development stakeholders from 15 industrial cases to provide a broader overview of the current state of the practice on TM.  To evaluate the feasibility of our guidelines, we investigate a set of existing TM approaches used in industry with respect to our guidelines.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {414–425},
numpages = {12},
keywords = {Traceability quality, Traceability maintenance, Consistency},
location = {Singapore, Singapore},
series = {ASE '16}
}

@proceedings{10.1145/3634737,
title = {ASIA CCS '24: Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM AsiaCCS 2024, the 19th ACM Asia Conference on Computer and Communications Security. AsiaCCS 2024 takes place in Singapore from 1 July to 5 July.},
location = {Singapore, Singapore}
}

@article{10.1145/1095430.1095431,
title = {Frontmatter (TOC, Letters, Philosophy of computer science, Interviewers needed, Taking software requirements creation from folklore to analysis, SW components and product lines: from business to systems and technology, Software engineering survey)},
year = {2005},
issue_date = {September 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1095430.1095431},
doi = {10.1145/1095430.1095431},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {0},
numpages = {45}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3570361,
title = {ACM MobiCom '23: Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@inproceedings{10.1145/1944892.1944910,
author = {Merschen, Daniel and Polzer, Andreas and Botterweck, Goetz and Kowalewski, Stefan},
title = {Experiences of applying model-based analysis to support the development of automotive software product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944910},
doi = {10.1145/1944892.1944910},
abstract = {In embedded systems in general and in automotive systems in particular the systematic reuse of existing assets is crucial. Moreover, companies in these domains often offer whole families of similar products. Hence, the application of product line engineering seems to be an obvious option.However, current products have reached a complexity level where management of products within a product line cannot be handled with current techniques and tools (e.g. Matlab/Simulink) alone. To sustain an efficient engineering process and to reach the required quality levels of the products, additional techniques are required.In this paper we report on a prototypical framework for the analysis of embedded systems product lines. The techniques and tools offered by the framework were developed to support engineers in typical tasks, which occur during design, implementation, and maintenance of embedded software product lines. The techniques allow to analyse product line artefacts by transforming them into models, which are then used in an analysis process based on model transformation languages.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {141–150},
numpages = {10},
keywords = {embedded systems, eclipse modeling framework, Simulink, Matlab},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@proceedings{10.1145/3689031,
title = {EuroSys '25: Proceedings of the Twentieth European Conference on Computer Systems},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to EuroSys 2025, the 20th edition of the European Conference on Computer Systems! We are excited to host EuroSys 2025 in the modern and dynamic city of Rotterdam, Netherlands. This year's EuroSys is very special as it is co-located (for the first time) with the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2025). We hope you will enjoy an excellent technical program, engaging discussions, and networking opportunities in this vibrant city known for its innovative architecture, bustling port, and rich cultural scene.},
location = {Rotterdam, Netherlands}
}

@proceedings{10.1145/3581791,
title = {MobiSys '23: Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the entire organizing committee, it is with immense pleasure that we welcome you to the 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023) hosted in Helsinki, Finland on June 18 - 22, 2023. ACM MobiSys is the leading conference in research on mobile systems, applications and services, and a flagship conference of ACM SIGMOBILE.},
location = {Helsinki, Finland}
}

@proceedings{10.1145/3658644,
title = {CCS '24: Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great enthusiasm that we, on behalf of the Organizing Committee, invite you to join us for the 31st ACM SIGSAC Conference on Computer and Communications Security (CCS), a premier security and privacy conference where researchers, practitioners, and educators come together to present, learn, and debate research, innovation, and trends in the field of Computer and Communications Security and Privacy.This year, we are proud to introduce our conference theme to be "Inclusion, Mentorship, Community." These three pillars reflect our collective commitment to fostering a vibrant, supportive, and forwardthinking environment within the CCS community. Particularly, we host our inaugural Doctoral Symposium, which offers PhD students a unique platform to receive timely, constructive feedback on their dissertation research from leading experts in our community. Additionally, our first-ever Diversity, Equity, and Inclusion (DEI) Workshop is designed to cultivate a culture that embraces diversity and champions equity in our field. Moreover, understanding the importance of guidance and support, we have organized panels focusing on Student Mentoring, Faculty Mentoring, and Public Service. These panels are designed to facilitate mentorship connections, share valuable experiences, and encourage service that extends the impact of our work beyond academia. These new initiatives are also opportunities to strengthen the bonds within our CCS community.Regarding the main conference, this year's main conference is our largest ever, featuring 328 paper presentations that showcase the latest research and developments in our field. We are also honored to have two distinguished keynote speakers: Dr. Dan Boneh and Dr. Gene Tsudik, who will share their invaluable insights and perspectives on pressing topics in security and privacy. Additionally, 18 specialized workshops will take place on the pre-conference and post-conference days, providing platforms for focused discussions and collaborations on numerous specialized topics.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@proceedings{10.1145/3569966,
title = {CSSE '22: Proceedings of the 5th International Conference on Computer Science and Software Engineering},
year = {2022},
isbn = {9781450397780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@proceedings{10.1145/3607199,
title = {RAID '23: Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, China}
}

@inproceedings{10.1145/36206.36179,
author = {Beck, Bob and Kasten, Bob and Thakkar, Shreekant},
title = {VLSI assist for a multiprocessor},
year = {1987},
isbn = {0818608056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/36206.36179},
doi = {10.1145/36206.36179},
abstract = {Multiprocessors have long been of interest to computer community. They provide the potential for accelerating applications through parallelism and increased throughput for large multi-user system. Three factors have limited the commercial success of multiprocessor systems; entry cost, range of performance, and ease of application. Advances in very large scale integration (VLSI) and in computer aided design (CAD) have removed these limitations, making possible a new class of multiprocessor systems based on VLSI components. A set of requirements for building an efficient shared multiprocessor system are discussed, including: low-level mutual exclusion, interrupt distribution, inter-processor signaling, process dispatching, caching, and system configuration. A system that meets these requirements is described and evaluated.},
booktitle = {Proceedings of the Second International Conference on Architectual Support for Programming Languages and Operating Systems},
pages = {10–20},
numpages = {11},
location = {Palo Alto, California, USA},
series = {ASPLOS II}
}

@proceedings{10.1145/3603269,
title = {ACM SIGCOMM '23: Proceedings of the ACM SIGCOMM 2023 Conference},
year = {2023},
isbn = {9798400702365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New York, NY, USA}
}

@proceedings{10.1145/3626246,
title = {SIGMOD '24: Companion of the 2024 International Conference on Management of Data},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the SIGMOD 2024 organizing committee, it is our distinct honor, as General Chairs, to welcome you to the 2024 ACM International Conference on Management of Data - SIGMOD 2024. We are thrilled to be hosting this prestigious event for the very first time in Latin America, and specifically in Santiago de Chile, a recognized leader in data technology within the region. This marks a significant milestone for the SIGMOD community, and we are honored to have you join us for a fully in-person experience in this vibrant and innovative city.},
location = {Santiago AA, Chile}
}

@proceedings{10.1145/2984043,
title = {SPLASH Companion 2016: Companion Proceedings of the 2016 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity},
year = {2016},
isbn = {9781450344371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/1390630.1390640,
author = {Yoon, Il-Chul and Sussman, Alan and Memon, Atif and Porter, Adam},
title = {Effective and scalable software compatibility testing},
year = {2008},
isbn = {9781605580500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390630.1390640},
doi = {10.1145/1390630.1390640},
abstract = {Today's software systems are typically composed of multiple components, each with different versions. Software compatibility testing is a quality assurance task aimed at ensuring that multi-component based systems build and/or execute correctly across all their versions' combinations, or configurations. Because there are complex and changing interdependencies between components and their versions, and because there are such a large number of configurations, it is generally infeasible to test all potential configurations. Consequently, in practice, compatibility testing examines only a handful of default or popular configurations to detect problems; as a result costly errors can and do escape to the field.This paper presents a new approach to compatibility testing, called Rachet. We formally model the entire configuration space for software systems and use the model to generate test plans to sample a portion of the space. In this paper, we test all direct dependencies between components and execute the test plan efficiently in parallel. We present empirical results obtained by applying our approach to two large-scale scientific middleware systems. The results show that for these systems Rachet scaled well and discovered incompatibilities between components, and that testing only direct dependences did not compromise test quality.},
booktitle = {Proceedings of the 2008 International Symposium on Software Testing and Analysis},
pages = {63–74},
numpages = {12},
keywords = {software compatibility testing, component-based software system},
location = {Seattle, WA, USA},
series = {ISSTA '08}
}

@proceedings{10.1145/3653644,
title = {FAIML '24: Proceedings of the 2024 3rd International Conference on Frontiers of Artificial Intelligence and Machine Learning},
year = {2024},
isbn = {9798400709777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yichang, China}
}

@inproceedings{10.5555/2814058.3252438,
author = {Cappelli, Claudia and Ferreira, Arnaldo Alves},
title = {Session details: Special Track - Experience Reports in Industry and Case Studies},
year = {2015},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
booktitle = {Proceedings of the Annual Conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1},
location = {Goiania, Goias, Brazil},
series = {SBSI '15}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3669721,
title = {SIUSAI '24: Proceedings of the 2024 3rd International Symposium on Intelligent Unmanned Systems and Artificial Intelligence},
year = {2024},
isbn = {9798400710025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@article{10.1145/245882.245905,
author = {Atkinson, M. P. and Dayn\`{e}s, L. and Jordan, M. J. and Printezis, T. and Spence, S.},
title = {An orthogonally persistent Java},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/245882.245905},
doi = {10.1145/245882.245905},
abstract = {The language Java is enjoying a rapid rise in popularity as an application programming language. For many applications an effective provision of database facilities is required. Here we report on a particular approach to providing such facilities, called “orthogonal persistence”. Persistence allows data to have lifetimes that vary from transient to (the best approximation we can achieve to) indefinite. It is orthogonal persistence if the available lifetimes are the same for all kinds of data. We aim to show that the programmer productivity gains and possible performance gains make orthogonal persistence a valuable augmentation of Java.},
journal = {SIGMOD Rec.},
month = dec,
pages = {68–75},
numpages = {8}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3672758,
title = {CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi' an, China}
}

@book{10.1145/2534860,
author = {Joint Task Force on Computing Curricula, Association for Computing Machinery (ACM) and IEEE Computer Society},
title = {Computer Science Curricula 2013: Curriculum Guidelines for Undergraduate Degree Programs in Computer Science},
year = {2013},
isbn = {9781450323093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@article{10.1145/1218776.1218777,
author = {ACM SIGSOFT Software Engineering Notes staff},
title = {Frontmatter (TOC, Miscellaneous material)},
year = {2006},
issue_date = {November 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1218776.1218777},
doi = {10.1145/1218776.1218777},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {0},
numpages = {36}
}

@inproceedings{10.5555/800078.802512,
author = {Paster, Donald L.},
title = {Experience with application of modern software management controls},
year = {1981},
isbn = {0897911466},
publisher = {IEEE Press},
abstract = {This paper presents the experience of the Software Development Laboratory of Raytheon Company, Submarine Signal Division, in applying modern software management control techniques to the development of software for real-time embedded computer systems. The paper initially describes the characteristics of the software projects during the period 1969-1979, and the ultimate use of the systems. The software is developed for embedded computers of many types and for systems requiring from one to eleven racks of electronics, and it is programmed in many languages. The systems are installed in submarines, surface ships, aircraft, shore-based facilities and weapons. The paper then summarizes development methodologies and follows with a detailed description of the software management and control techniques, which include: manpower forecasting; tailored status reports for financial, module, and cost-milestone-schedule; cost estimating; support librarian and configuration management; policies and procedures; training; and staffing and organization.},
booktitle = {Proceedings of the 5th International Conference on Software Engineering},
pages = {18–26},
numpages = {9},
location = {San Diego, California, USA},
series = {ICSE '81}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3508352,
title = {ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Jointly sponsored by ACM and IEEE, ICCAD is the premier forum to explore new challenges, present leading-edge innovative solutions, and identify emerging technologies in the Electronic Design Automation (EDA) research areas. ICCAD covers the full range of Computer-Aided Design (CAD) topics - from device and circuit-level up through system-level, as well as post-CMOS design.},
location = {San Diego, California}
}

