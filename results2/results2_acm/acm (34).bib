@inproceedings{10.1145/2593882.2593888,
author = {Metzger, Andreas and Pohl, Klaus},
title = {Software product line engineering and variability management: achievements and challenges},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593888},
doi = {10.1145/2593882.2593888},
abstract = {Software product line engineering has proven to empower organizations to develop a diversity of similar software-intensive systems (applications) at lower cost, in shorter time, and with higher quality when compared with the development of single systems. Over the last decade the software product line engineering research community has grown significantly. It has produced impressive research results both in terms of quality as well as quantity. We identified over 600 relevant research and experience papers published within the last seven years in established conferences and journals. We briefly summarize the major research achievements of these past seven years. We structure this research summary along a standardized software product line framework. Further, we outline current and future research challenges anticipated from major trends in software engineering and technology.},
booktitle = {Future of Software Engineering Proceedings},
pages = {70–84},
numpages = {15},
keywords = {Software product lines, design, quality assurance, requirements engineering, variability management, variability modeling},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@article{10.1016/j.jss.2019.04.054,
author = {Acher, Mathieu and Cohen, Myra B.},
title = {Special issue on systems and software product line engineering},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.054},
doi = {10.1016/j.jss.2019.04.054},
journal = {J. Syst. Softw.},
month = aug,
pages = {110–111},
numpages = {2}
}

@inproceedings{10.1145/3233027.3233045,
author = {Becker, Martin and Zhang, Bo},
title = {How do our neighbours do product line engineering? a comparison of hardware and software product line engineering approaches from an industrial perspective},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233045},
doi = {10.1145/3233027.3233045},
abstract = {Product line engineering (PLE) approaches have been followed in industry for hardware and software solutions for more than three decades now. However, the different engineering disciplines (e.g. mechanics, electrics, software) have developed and evolved their approaches within their own realms, which is fine as long as there is no need for integrated approaches. Driven by the increasing complexity of systems, there is a rising need for interdisciplinary systems engineering these days. Companies engineering cyber-physical systems and their components have to integrate product line engineering approaches across the involved engineering disciplines to enable a global optimization of portfolio, solution structures, and assets along their lifecycle. From a bird's-eye view, there is noticeable commonality but also variety in the approaches followed for PLE in the different engineering disciplines, which renders the integration of approaches a non-trivial endeavour. In order to foster the development of integrated PLE approaches, this paper explores, maps, and compares PLE approaches in the field of hardware and software engineering. Furthermore, the paper identifies integration opportunities and challenges. As the paper targets industrial practitioners, it mainly provides references to respective industrial events and material and does not fully cover related work in the respective research communities.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {190–195},
numpages = {6},
keywords = {SPLC, academia, industry, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1016/j.infsof.2018.01.016,
author = {Soares, Larissa Rocha and Schobbens, Pierre-Yves and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Feature interaction in software product line engineering: A systematic mapping study},
year = {2018},
issue_date = {Jun 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {98},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.01.016},
doi = {10.1016/j.infsof.2018.01.016},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {44–58},
numpages = {15},
keywords = {Feature interaction, Software product lines, Systematic mapping}
}

@inproceedings{10.1145/3461001.3473060,
author = {Sch\"{a}fer, Andreas and Becker, Martin and Andres, Markus and Kistenfeger, Tim and Rohlf, Florian},
title = {Variability realization in model-based system engineering using software product line techniques: an industrial perspective},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473060},
doi = {10.1145/3461001.3473060},
abstract = {Efficiently handling system variants is rising of importance in industry and challenges the application of model-based systems engineering.This paper reveals the increasing industrial demand of guidance and decision support on how to handle variants and variability within SysML and UML models. While a substantial amount of variability realization approaches has already been published on source code level, there is little guidance for practitioners on system model level. Hence, there is major uncertainty in dealing with system changes or concurrent system modeling of related system. Due to a poor modularization and variability realization these model variants are ending up in interwoven and complex system models.In this paper, we aim to raise awareness of the need for appropriate guidance and decision support, identify important contextual factors of MBSE that influence variability realization, and derive well known variability mechanisms used in software coding for their applicability in system modeling.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {25–34},
numpages = {10},
keywords = {SysML, UML, decision support, model-based systems engineering, system and software product line engineering, variability mechanism, variability realization, variant management},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382025.3414942,
author = {Assun\c{c}\~{a}o, Wesley K. G. and Kr\"{u}ger, Jacob and Mendon\c{c}a, Willian D. F.},
title = {Variability management meets microservices: six challenges of re-engineering microservice-based webshops},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414942},
doi = {10.1145/3382025.3414942},
abstract = {A microservice implements a small unit of functionality that it provides through a network using lightweight protocols. So, microservices can be combined to fulfill tasks and implement features of a larger software system---resembling a variability mechanism in the context of a software product line (SPL). Microservices and SPLs have similar goals, namely facilitating reuse and customizing, but they are usually employed in different contexts. Any developer who has access to the network can provide a microservice for any task, while SPLs are usually intended to implement features of a specific domain. Due to their different concepts, using microservices to implement an SPL or adopting SPL practices (e.g., variability management) for microservices is a challenging cross-area research problem. However, both techniques can complement each other, and thus tackling this problem promises benefits for organizations that employ either technique. In this paper, we reason on the importance of advancing in this direction, and sketch six concrete challenges to initiate research, namely (1) feature identification, (2) variability modeling, (3) variable microservice architectures, (4) interchangeability, (5) deep customization, and (6) re-engineering an SPL. We intend these challenges to serve as a starting point for future research in this cross-area research direction---avoiding that the concepts of one area are reinvented in the other.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {22},
numpages = {6},
keywords = {cloud computing, microservices, re-engineering, software product line, variability management},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382025.3414971,
author = {Martinez, Jabier and Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley K. G. and Figueiredo, Eduardo},
title = {Insights on software product line extraction processes: ArgoUML to ArgoUML-SPL revisited},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414971},
doi = {10.1145/3382025.3414971},
abstract = {Software Product Lines (SPLs) are rarely developed from scratch. Commonly, they emerge from monolithic architectures when there is a need to create tailored variants, or from existing variants created in an ad-hoc way once their separated maintenance and evolution become challenging. Despite the vast literature about re-engineering systems into SPLs and related technical approaches, there is a lack of detailed analysis about the process itself and the effort that is involved. We provide and analyze empirical data of an existing SPL extraction process: the ArgoUML monolithic architecture transition to ArgoUML-SPL. The analysis relies on information mined from the version control history of the source-code repository and the discussion with developers that took part in the process. The contribution of this study is an in-depth characterization of the process compared to previous works that focused only on the structural results of the final SPL. We made publicly available the dataset and the analysis scripts to be used as baseline for extractive SPL adoption research and practice.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {6},
numpages = {6},
keywords = {ArgoUML, mining software repositories, re-engineering, software product line architecture},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3358960.3379137,
author = {Alves Pereira, Juliana and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc},
title = {Sampling Effect on Performance Prediction of Configurable Systems: A Case Study},
year = {2020},
isbn = {9781450369916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358960.3379137},
doi = {10.1145/3358960.3379137},
abstract = {Numerous software systems are highly configurable and provide a myriad of configuration options that users can tune to fit their functional and performance requirements (e.g., execution time). Measuring all configurations of a system is the most obvious way to understand the effect of options and their interactions, but is too costly or infeasible in practice. Numerous works thus propose to measure only a few configurations (a sample) to learn and predict the performance of any combination of options' values. A challenging issue is to sample a small and representative set of configurations that leads to a good accuracy of performance prediction models. A recent study devised a new algorithm, called distance-based sampling, that obtains state-of-the-art accurate performance predictions on different subject systems. In this paper, we replicate this study through an in-depth analysis of x264, a popular and configurable video encoder. We systematically measure all 1,152 configurations of x264 with 17 input videos and two quantitative properties (encoding time and encoding size). Our goal is to understand whether there is a dominant sampling strategy over the very same subject system (x264), i.e., whatever the workload and targeted performance properties. The findings from this study show that random sampling leads to more accurate performance models. However, without considering random, there is no single "dominant" sampling, instead different strategies perform best on different inputs and non-functional properties, further challenging practitioners and researchers.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {277–288},
numpages = {12},
keywords = {configurable systems, machine learning, performance prediction, software product lines},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1145/3023956.3023957,
author = {Wille, David and Runge, Tobias and Seidl, Christoph and Schulze, Sandro},
title = {Extractive software product line engineering using model-based delta module generation},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023957},
doi = {10.1145/3023956.3023957},
abstract = {To satisfy demand for customized products, companies commonly apply so-called clone-and-own strategies by copying functionality from existing products and modifying it to create product variants that have to be developed, maintained, and evolved in isolation. In previous work, we introduced a variability mining technique to identify variability information (commonalities and differences) in block-based model variants (e.g., MATLAB/Simulink models), which can be used to guide manual transition from clone-and-own to managed reuse of a software product line (SPL). In this paper, we present a procedure that uses the extracted variability information to generate a transformational delta-oriented SPL fully automatically. We generate a delta language specifically tailored to transforming models in the analyzed modeling language and utilize it to generate delta modules expressing variation of the SPL's implementation artifacts. The procedure seamlessly integrates with our variability mining technique and allows to fully adopt a managed reuse strategy (i.e., generation of products from a single code base) without manual overhead. We show the feasibility of the procedure by applying it to state chart and MATLAB/Simulink model variants from two industrial case studies.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {36–43},
numpages = {8},
keywords = {clone-and-own, delta modeling, extractive product line engineering, model-based, variability mining},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00122,
author = {Rosiak, Kamil},
title = {Extractive multi product-line engineering},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00122},
doi = {10.1109/ICSE-Companion52605.2021.00122},
abstract = {Cloning is a general approach to create new functionality within variants as well as new system variants. It is a fast, flexible, intuitive, and economical approach to evolve systems in the short run. However, in the long run, the maintenance effort increases. A common solution to this problem is the extraction of a product line from a set of cloned variants. This process requires a detailed analysis of variants to extract variability information. However, clones within a variant are usually not considered in the process, but are also a cause for unsustainable software. This thesis proposes an extractive multi product-line engineering approach to re-establish the sustainable development of software variants. We propose an approach to re-engineer intra-system and inter-system clones into reusable, configurable components stored in an integrated platform and synthesize a matching multilayer feature model.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {263–265},
numpages = {3},
keywords = {clone detection, multi product-line, refactoring, variability mining},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3382025.3414976,
author = {Pereira, Juliana Alves and Martin, Hugo and Temple, Paul and Acher, Mathieu},
title = {Machine learning and configurable systems: a gentle introduction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414976},
doi = {10.1145/3382025.3414976},
abstract = {The goal of this tutorial is to give a gentle introduction to how machine learning can be used to support software product line configuration. This is our second practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance and bug prediction) on real-world systems (Linux, VaryLaTeX, x264). The material is designed for academics and practitioners with basic knowledge in software product lines and machine learning.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {40},
numpages = {1},
keywords = {configurable systems, machine learning, software product lines},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3336294.3342383,
author = {Martin, Hugo and Pereira, Juliana Alves and Acher, Mathieu and Temple, Paul},
title = {Machine Learning and Configurable Systems: A Gentle Introduction},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342383},
doi = {10.1145/3336294.3342383},
abstract = {The goal of this tutorial is to give an introduction to how machine learning can be used to support activities related to the engineering of configurable systems and software product lines. To the best of our knowledge, this is the first practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance prediction) on real-world systems (VaryLaTeX, x264).},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {325–326},
numpages = {2},
keywords = {configurable systems, machine learning, software product lines},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3236405.3237200,
author = {Bilic, Damir and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter and Causevic, Adnan and Amlinger, Christoffer},
title = {Model-based product line engineering in an industrial automotive context: an exploratory case study},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237200},
doi = {10.1145/3236405.3237200},
abstract = {Product Line Engineering is an approach to reuse assets of complex systems by taking advantage of commonalities between product families. Reuse within complex systems usually means reuse of artifacts from different engineering domains such as mechanical, electronics and software engineering. Model-based systems engineering is becoming a standard for systems engineering and collaboration within different domains. This paper presents an exploratory case study on initial efforts of adopting Product Line Engineering practices within the model-based systems engineering process at Volvo Construction Equipment (Volvo CE), Sweden. We have used SysML to create overloaded models of the engine systems at Volvo CE. The variability within the engine systems was captured by using the Orthogonal Variability Modeling language. The case study has shown us that overloaded SysML models tend to become complex even on small scale systems, which in turn makes scalability of the approach a major challenge. For successful reuse and to, possibly, tackle scalability, it is necessary to have a database of reusable assets from which product variants can be derived.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {56–63},
numpages = {8},
keywords = {model-based systems engineering, orthogonal variability modeling, system product lines, variability management},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3336294.3342363,
author = {Acher, Mathieu and Rabiser, Rick and Lopez-Herrejon, Roberto E.},
title = {Fourth International Workshop on Software Product Line Teaching (SPLTea 2019)},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342363},
doi = {10.1145/3336294.3342363},
abstract = {Education has a key role to play for disseminating the constantly growing body of Software Product Line (SPL) knowledge. In a sense, every researcher in SPL should think about how to teach SPL. This workshop aims to explore and explain the current status and ongoing work on teaching SPLs at universities, colleges, and in industry (e.g., by consultants). This fourth edition will continue the effort made at SPLTea'14, SPLTea'15 and SPLTea'18. In particular we seek to better understand how to build a curriculum for teaching SPLs - a central issue as reported in surveys and as informally discussed at SPLTea'18. We expect several lightning talks that report on traditional questions like: what is the targeted audience? What is the place in the curriculum? What is the material (slides, tools, books, etc) used? As there is hardly a one-size-fits-all curriculum, the workshop aims to collectively identify commonality and variability when building SPL curriculums. As a concrete outcome, we expect to elaborate a variability model of SPL teaching that could be actuated to derive custom curriculum in various contexts.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {322},
numpages = {1},
keywords = {education, software product lines, teaching},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3233027.3233038,
author = {Martinez, Jabier and T\"{e}rnava, Xhevahire and Ziadi, Tewfik},
title = {Software product line extraction from variability-rich systems: the robocode case study},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233038},
doi = {10.1145/3233027.3233038},
abstract = {The engineering of a Software Product Line (SPL), either by creating it from scratch or through the re-engineering of existing variants, it uses to be a project that spans several years with a high investment. It is often hard to analyse and quantify this investment, especially in the context of extractive SPL adoption when the related software variants are independently created by different developers following different system architectures and implementation conventions. This paper reports an experience on the creation of an SPL by re-engineering system variants implemented around an educational game called Robocode. The objective of this game is to program a bot (a battle tank) that battles against the bots of other developers. The world-wide Robocode community creates and maintains a large base of knowledge and implementations that are mainly organized in terms of features, although not presented as an SPL. Therefore, a group of master students analysed this variability-rich domain and extracted a Robocode SPL. We present the results of such extraction augmented with an analysis and a quantification regarding the spent time and effort. We believe that the results and the a-posteriori analysis can provide insights on global challenges on SPL adoption. We also provide all the elements to SPL educators to reproduce the teaching activity, and we make available this SPL to be used for any research purpose.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {132–142},
numpages = {11},
keywords = {education, extractive software product line adoption, reverse-engineering, robocode, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s10664-020-09913-9,
author = {Lindohf, Robert and Kr\"{u}ger, Jacob and Herzog, Erik and Berger, Thorsten},
title = {Software product-line evaluation in the large},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09913-9},
doi = {10.1007/s10664-020-09913-9},
abstract = {Software product-line engineering is arguably one of the most successful methods for establishing large portfolios of software variants in an application domain. However, despite the benefits, establishing a product line requires substantial upfront investments into a software platform with a proper product-line architecture, into new software-engineering processes (domain engineering and application engineering), into business strategies with commercially successful product-line visions and financial planning, as well as into re-organization of development teams. Moreover, establishing a full-fledged product line is not always possible or desired, and thus organizations often adopt product-line engineering only to an extent that deemed necessary or was possible. However, understanding the current state of adoption, namely, the maturity or performance of product-line engineering in an organization, is challenging, while being crucial to steer investments. To this end, several measurement methods have been proposed in the literature, with the most prominent one being the Family Evaluation Framework (FEF), introduced almost two decades ago. Unfortunately, applying it is not straightforward, and the benefits of using it have not been assessed so far. We present an experience report of applying the FEF to nine medium- to large-scale product lines in the avionics domain. We discuss how we tailored and executed the FEF, together with the relevant adaptations and extensions we needed to perform. Specifically, we elicited the data for the FEF assessment with 27 interviews over a period of 11 months. We discuss experiences and assess the benefits of using the FEF, aiming at helping other organizations assessing their practices for engineering their portfolios of software variants.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {41},
keywords = {software product lines, process maturity, experience report, family evaluation framework}
}

@inproceedings{10.1145/3461001.3471155,
author = {Martin, Hugo and Acher, Mathieu and Pereira, Juliana Alves and J\'{e}z\'{e}quel, Jean-Marc},
title = {A comparison of performance specialization learning for configurable systems},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471155},
doi = {10.1145/3461001.3471155},
abstract = {The specialization of the configuration space of a software system has been considered for targeting specific configuration profiles, usages, deployment scenarios, or hardware settings. The challenge is to find constraints among options' values that only retain configurations meeting a performance objective. Since the exponential nature of configurable systems makes a manual specialization unpractical, several approaches have considered its automation using machine learning, i.e., measuring a sample of configurations and then learning what options' values should be constrained. Even focusing on learning techniques based on decision trees for their built-in explainability, there is still a wide range of possible approaches that need to be evaluated, i.e., how accurate is the specialization with regards to sampling size, performance thresholds, and kinds of configurable systems. In this paper, we compare six learning techniques: three variants of decision trees (including a novel algorithm) with and without the use of model-based feature selection. We first perform a study on 8 configurable systems considered in previous related works and show that the accuracy reaches more than 90% and that feature selection can improve the results in the majority of cases. We then perform a study on the Linux kernel and show that these techniques performs as well as on the other systems. Overall, our results show that there is no one-size-fits-all learning variant (though high accuracy can be achieved): we present guidelines and discuss tradeoffs.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {46–57},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1016/j.infsof.2013.05.006,
author = {Mohabbati, Bardia and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and M\"{u}ller, Hausi A.},
title = {Combining service-orientation and software product line engineering: A systematic mapping study},
year = {2013},
issue_date = {November, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.006},
doi = {10.1016/j.infsof.2013.05.006},
abstract = {Context: Service-Orientation (SO) is a rapidly emerging paradigm for the design and development of adaptive and dynamic software systems. Software Product Line Engineering (SPLE) has also gained attention as a promising and successful software reuse development paradigm over the last decade and proven to provide effective solutions to deal with managing the growing complexity of software systems. Objective: This study aims at characterizing and identifying the existing research on employing and leveraging SO and SPLE. Method: We conducted a systematic mapping study to identify and analyze related literature. We identified 81 primary studies, dated from 2000-2011 and classified them with respect to research focus, types of research and contribution. Result: The mapping synthesizes the available evidence about combining the synergy points and integration of SO and SPLE. The analysis shows that the majority of studies focus on service variability modeling and adaptive systems by employing SPLE principles and approaches. In particular, SPLE approaches, especially feature-oriented approaches for variability modeling, have been applied to the design and development of service-oriented systems. While SO is employed in software product line contexts for the realization of product lines to reconcile the flexibility, scalability and dynamism in product derivations thereby creating dynamic software product lines. Conclusion: Our study summarizes and characterizes the SO and SPLE topics researchers have investigated over the past decade and identifies promising research directions as due to the synergy generated by integrating methods and techniques from these two areas.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1845–1859},
numpages = {15},
keywords = {Service-oriented architecture, Software product lines, Systematic mapping}
}

@inproceedings{10.1145/3483899.3483902,
author = {Marchezan, Luciano and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Carbonell, Jo\~{a}o and Rodrigues, Elder and Bernardino, Maicon and Basso, F\'{a}bio},
title = {SPLReePlan - Automated Support for Software Product Line Reengineering Planning},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483902},
doi = {10.1145/3483899.3483902},
abstract = {The extractive adoption of Software Product Lines (SPL) relies on the reuse of the already developed systems, employing a reengineering process. However, due to the diversity of options found in the daily practice of SPL development, rigorous planning of scenarios is critical to perform SPL reengineering. This diversity is the result of different organizational aspects, such as team experience and product portfolio. Hence, a proper planning process must consider technical and organizational aspects, however, most existing studies in the field do not take into account organizational aspects of the companies. In this work, we present SPLReePlan, an automated framework to aid the SPL reengineering planning taking into account technical and organizational aspects. Our framework is supported by a web-based tool, ready to be used in the industry. To investigate how flexible is SPLReePlan to support the SPL reengineering planning in diverse situations, we extracted eight different scenarios from the SPL literature, which are used as input for the evaluation of SPLReePlan. The results indicate that SPLReePlan can be satisfactorily customized to a variety of scenarios with different artifacts, feature retrieval techniques, and reengineering activities. As a contribution, we discuss the lessons learned within the evaluation, and present challenges that were faced, being a source of information for tool builders or motivating new studies.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {automated support, reengineering process, software product lines, variability management},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/3382025.3414951,
author = {Heradio, Ruben and Fernandez-Amoros, David and Galindo, Jos\'{e} A. and Benavides, David},
title = {Uniform and scalable SAT-sampling for configurable systems},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414951},
doi = {10.1145/3382025.3414951},
abstract = {Several relevant analyses on configurable software systems remain intractable because they require examining vast and highly-constrained configuration spaces. Those analyses could be addressed through statistical inference, i.e., working with a much more tractable sample that later supports generalizing the results obtained to the entire configuration space. To make this possible, the laws of statistical inference impose an indispensable requirement: each member of the population must be equally likely to be included in the sample, i.e., the sampling process needs to be "uniform". Various SAT-samplers have been developed for generating uniform random samples at a reasonable computational cost. Unfortunately, there is a lack of experimental validation over large configuration models to show whether the samplers indeed produce genuine uniform samples or not. This paper (i) presents a new statistical test to verify to what extent samplers accomplish uniformity and (ii) reports the evaluation of four state-of-the-art samplers: Spur, QuickSampler, Unigen2, and Smarch. According to our experimental results, only Spur satisfies both scalability and uniformity.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {17},
numpages = {11},
keywords = {SAT, configurable systems, software product lines, uniform sampling, variability modeling},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/ASE.2015.45,
author = {Sarkar, Atri and Guo, Jianmei and Siegmund, Norbert and Apel, Sven and Czarnecki, Krzysztof},
title = {Cost-efficient sampling for performance prediction of configurable systems},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.45},
doi = {10.1109/ASE.2015.45},
abstract = {A key challenge of the development and maintenance of configurable systems is to predict the performance of individual system variants based on the features selected. It is usually infeasible to measure the performance of all possible variants, due to feature combinatorics. Previous approaches predict performance based on small samples of measured variants, but it is still open how to dynamically determine an ideal sample that balances prediction accuracy and measurement effort. In this paper, we adapt two widely-used sampling strategies for performance prediction to the domain of configurable systems and evaluate them in terms of sampling cost, which considers prediction accuracy and measurement effort simultaneously. To generate an initial sample, we introduce a new heuristic based on feature frequencies and compare it to a traditional method based on t-way feature coverage. We conduct experiments on six real-world systems and provide guidelines for stakeholders to predict performance by sampling.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {342–352},
numpages = {11},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {Software product lines, product-line analysis}
}

@inproceedings{10.1145/3425269.3425271,
author = {Nicolodi, Luciane Baldo and Colanzi, Thelma Elita and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Architectural Feature Re-Modularization for Software Product Line Evolution},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425271},
doi = {10.1145/3425269.3425271},
abstract = {Extensive maintenance leads to the Software Product Line Architecture (PLA) degradation over time. When there is the need of evolving the Software Product Line (SPL) to include new features, or move to a new platform, a degraded PLA requires considerable effort to understand and modify, demanding expensive refactoring activity. In the state of the art, search-based algorithms are used to improve PLA at package level. However, recent studies have shown that the most variability and implementation details of an SPL are described in the level of classes. There is a gap between existing approaches and existing practical needs. In this work, we extend the current state of the art to deal with feature modularization in the level of classes by introducing a new search operator and a set of objective functions to deal with feature modularization in a finer granularity of the architectural elements, namely at class level. We evaluated the proposal in an exploratory study with a PLA widely investigated and a real-world PLA. The results of quantitative and qualitative analysis point out that our proposal provides solutions to properly re-modularize features in a PLA, being preferred by practitioners, in order to support the evolution of SPLs.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {31–40},
numpages = {10},
keywords = {Architectural Degradation, Feature Modularization, Search-based Software Engineering, Software Evolution},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@inproceedings{10.1109/ICSE43902.2021.00147,
author = {Mahmood, Wardah and Str\"{u}ber, Daniel and Berger, Thorsten and L\"{a}mmel, Ralf and Mukelabai, Mukelabai},
title = {Seamless Variability Management With the Virtual Platform},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00147},
doi = {10.1109/ICSE43902.2021.00147},
abstract = {Customization is a general trend in software engineering, demanding systems that support variable stakeholder requirements. Two opposing strategies are commonly used to create variants: software clone&amp;own and software configuration with an integrated platform. Organizations often start with the former, which is cheap, agile, and supports quick innovation, but does not scale. The latter scales by establishing an integrated platform that shares software assets between variants, but requires high up-front investments or risky migration processes. So, could we have a method that allows an easy transition or even combine the benefits of both strategies? We propose a method and tool that supports a truly incremental development of variant-rich systems, exploiting a spectrum between both opposing strategies. We design, formalize, and prototype the variability-management framework virtual platform. It bridges clone&amp;own and platform-oriented development. Relying on programming-language-independent conceptual structures representing software assets, it offers operators for engineering and evolving a system, comprising: traditional, asset-oriented operators and novel, feature-oriented operators for incrementally adopting concepts of an integrated platform. The operators record meta-data that is exploited by other operators to support the transition. Among others, they eliminate expensive feature-location effort or the need to trace clones. Our evaluation simulates the evolution of a real-world, clone-based system, measuring its costs and benefits.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1658–1670},
numpages = {13},
keywords = {clone management, framework, re-engineering, software product lines, variability management},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/2791060.2791067,
author = {Yue, Tao and Ali, Shaukat and Selic, Bran},
title = {Cyber-physical system product line engineering: comprehensive domain analysis and experience report},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791067},
doi = {10.1145/2791060.2791067},
abstract = {Cyber-Physical Systems (CPSs) are the future generation of highly connected embedded systems having applications in diverse domains including Oil and Gas. Employing Product Line Engineering (PLE) is believed to bring potential benefits with respect to reduced cost, higher productivity, higher quality, and faster time-to-market. However, relatively few industrial field studies are reported regarding the application of PLE to develop large-scale systems, and more specifically CPSs. In this paper, we report about our experiences and insights gained from investigating the application of model-based PLE at a large international organization developing subsea production systems (typical CPSs) to manage the exploitation of oil and gas production fields. We report in this paper 1) how two systematic domain analyses (on requirements engineering and product configuration/derivation) were conducted to elicit CPS PLE requirements and challenges, 2) key results of the domain analysis (commonly observed in other domains), and 3) our initial experience of developing and applying two Model Based System Engineering (MBSE) PLE solution to address some of the requirements and challenges elicited during the domain analyses.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {338–347},
numpages = {10},
keywords = {cyber physical system (CPS), domain analysis, model based system engineering, product line engineering (PLE), requirements engineering},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3233027.3236404,
author = {Gazzillo, Paul and Koc, Ugur and Nguyen, ThanhVu and Wei, Shiyi},
title = {Localizing configurations in highly-configurable systems},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236404},
doi = {10.1145/3233027.3236404},
abstract = {The complexity of configurable systems has grown immensely, and it is only getting more complex. Such systems are a challenge for software testing and maintenance, because bugs and other defects can and do appear in any configuration. One common requirement for many development tasks is to identify the configurations that lead to a given defect or some other program behavior. We distill this requirement down to a challenge question: given a program location in a source file, what are valid configurations that include the location? The key obstacle is scalability. When there are thousands of configuration options, enumerating all combinations is exponential and infeasible. We provide a set of target programs of increasing difficulty and variations on the challenge question so that submitters of all experience levels can try out solutions. Our hope is to engage the community and stimulate new and interesting approaches to the problem of analyzing configurations.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {269–273},
numpages = {5},
keywords = {configurations, program analysis, testing, variability},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s10664-017-9573-6,
author = {Guo, Jianmei and Yang, Dingyu and Siegmund, Norbert and Apel, Sven and Sarkar, Atrisha and Valov, Pavel and Czarnecki, Krzysztof and Wasowski, Andrzej and Yu, Huiqun},
title = {Data-efficient performance learning for configurable systems},
year = {2018},
issue_date = {Jun 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9573-6},
doi = {10.1007/s10664-017-9573-6},
abstract = {Many software systems today are configurable, offering customization of functionality by feature selection. Understanding how performance varies in terms of feature selection is key for selecting appropriate configurations that meet a set of given requirements. Due to a huge configuration space and the possibly high cost of performance measurement, it is usually not feasible to explore the entire configuration space of a configurable system exhaustively. It is thus a major challenge to accurately predict performance based on a small sample of measured system variants. To address this challenge, we propose a data-efficient learning approach, called DECART, that combines several techniques of machine learning and statistics for performance prediction of configurable systems. DECART builds, validates, and determines a prediction model based on an available sample of measured system variants. Empirical results on 10 real-world configurable systems demonstrate the effectiveness and practicality of DECART. In particular, DECART achieves a prediction accuracy of 90% or higher based on a small sample, whose size is linear in the number of features. In addition, we propose a sample quality metric and introduce a quantitative analysis of the quality of a sample for performance prediction.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1826–1867},
numpages = {42},
keywords = {Performance prediction, Configurable systems, Regression, Model selection, Parameter tuning}
}

@inproceedings{10.1145/2647908.2655967,
author = {Assun\c{c}\~{a}o, Wesley Klewerton Guez and Vergilio, Silvia Regina},
title = {Feature location for software product line migration: a mapping study},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655967},
doi = {10.1145/2647908.2655967},
abstract = {Developing software from scratch is a high cost and error-prone activity. A possible solution to reduce time-to-market and produce high quality software is the reuse of existing software. But when the number of features in the system grows, the maintenance becomes more complex. In such cases, to adopt a systematic approach, such as Software Product Line Engineering, is necessary. Existing systems are generally migrated to a product line, allowing systematic reuse of artefacts and easing maintenance. To this end, some approaches have been proposed in the literature in the last years. A mapping of works on this subject and the identification of some research gaps can lead to an improvement of such approaches. This paper describes the main outcomes of a systematic mapping study on the evolution and migration of systems to SPL. The main works found are presented and classified according to adopted strategy, artefacts used, and evaluation conducted. Analysis of the evolution along the past years are also presented. At the end, we summarize some trends and open issues to serve as reference to new researches.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {52–59},
numpages = {8},
keywords = {evolution, reengineering, reuse, software product line},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3461001.3471147,
author = {Kenner, Andy and May, Richard and Kr\"{u}ger, Jacob and Saake, Gunter and Leich, Thomas},
title = {Safety, security, and configurable software systems: a systematic mapping study},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471147},
doi = {10.1145/3461001.3471147},
abstract = {Safety and security are important properties of any software system, particularly in safety-critical domains, such as embedded, automotive, or cyber-physical systems. Moreover, particularly those domains also employ highly-configurable systems to customize variants, for example, to different customer requirements or regulations. Unfortunately, we are missing an overview understanding of what research has been conducted on the intersection of safety and security with configurable systems. To address this gap, we conducted a systematic mapping study based on an automated search, covering ten years (2011--2020) and 65 relevant (out of 367) publications. We classified each publication based on established security and safety concerns (e.g., CIA triad) as well as the connection to configurable systems (e.g., ensuring security of such a system). In the end, we found that considerably more research has been conducted on safety concerns, but both properties seem under-explored in the context of configurable systems. Moreover, existing research focuses on two directions: Ensuring safety and security properties in product-line engineering; and applying product-line techniques to ensure safety and security properties. Our mapping study provides an overview of the current state-of-the-art as well as open issues, helping practitioners identify existing solutions and researchers define directions for future research.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {148–159},
numpages = {12},
keywords = {configurable systems, mapping study, safety, security, software product line engineering},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461001.3471149,
author = {Lesoil, Luc and Acher, Mathieu and T\'{e}rnava, Xhevahire and Blouin, Arnaud and J\'{e}z\'{e}quel, Jean-Marc},
title = {The interplay of compile-time and run-time options for performance prediction},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471149},
doi = {10.1145/3461001.3471149},
abstract = {Many software projects are configurable through compile-time options (e.g., using ./configure) and also through run-time options (e.g., command-line parameters, fed to the software at execution time). Several works have shown how to predict the effect of run-time options on performance. However it is yet to be studied how these prediction models behave when the software is built with different compile-time options. For instance, is the best run-time configuration always the best w.r.t. the chosen compilation options? In this paper, we investigate the effect of compile-time options on the performance distributions of 4 software systems. There are cases where the compiler layer effect is linear which is an opportunity to generalize performance models or to tune and measure runtime performance at lower cost. We also prove there can exist an interplay by exhibiting a case where compile-time options significantly alter the performance distributions of a configurable system.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {100–111},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1007/s10515-020-00273-8,
author = {Velez, Miguel and Jamshidi, Pooyan and Sattler, Florian and Siegmund, Norbert and Apel, Sven and K\"{a}stner, Christian},
title = {ConfigCrusher: towards white-box performance analysis for configurable systems},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00273-8},
doi = {10.1007/s10515-020-00273-8},
abstract = {Stakeholders of configurable systems are often interested in knowing how configuration options influence the performance of a system to facilitate, for example, the debugging and optimization processes of these systems. Several black-box approaches can be used to obtain this information, but they either sample a large number of configurations to make accurate predictions or miss important performance-influencing interactions when sampling few configurations. Furthermore, black-box approaches cannot pinpoint the parts of a system that are responsible for performance differences among configurations. This article proposes ConfigCrusher, a white-box performance analysis that inspects the implementation of a system to guide the performance analysis, exploiting several insights of configurable systems in the process. ConfigCrusher employs a static data-flow analysis to identify how configuration options may influence control-flow statements and instruments code regions, corresponding to these statements, to dynamically analyze the influence of configuration options on the regions’ performance. Our evaluation on 10 configurable systems shows the feasibility of our white-box approach to more efficiently build performance-influence models that are similar to or more accurate than current state of the art approaches. Overall, we showcase the benefits of white-box performance analyses and their potential to outperform black-box approaches and provide additional information for analyzing configurable systems.},
journal = {Automated Software Engg.},
month = dec,
pages = {265–300},
numpages = {36},
keywords = {Configurable systems, Performance analysis, Static analysis, Dynamic analysis}
}

@inproceedings{10.1145/2384716.2384733,
author = {Asaithambi, Suriya Priya R. and Jarzabek, Stan},
title = {Generic adaptable test cases for software product line testing: software product line},
year = {2012},
isbn = {9781450315630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2384716.2384733},
doi = {10.1145/2384716.2384733},
abstract = {This research study is about constructing "generic adaptable test cases" to counter test case libraries explosion problem. Our work focuses on effort reduction via systematic reuse of generic test assets by taking advantage of common aspects and predicted variability in test cases. We envision that the proposed approach to organizing test case libraries will be particularly useful in the context of Software Product Line Testing (SPLT). By exploring strategies for generic test cases, I hope to address problems of domain-level testing. Our work will investigate existing testing (SPLT) practices in variability management context by conducting empirical studies. We plan to synthesize principles for "generic test case" design, identify gaps between required and exiting techniques, and finally propose new approach for generic adaptive test case construction.},
booktitle = {Proceedings of the 3rd Annual Conference on Systems, Programming, and Applications: Software for Humanity},
pages = {33–36},
numpages = {4},
keywords = {software product line testing},
location = {Tucson, Arizona, USA},
series = {SPLASH '12}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {Clafer, ClaferIG, ClaferMOO, ClaferMOO visualizer, ClaferWiki, clafer configurator},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1007/978-3-030-64881-7_20,
author = {Jin, Hao and Kitamura, Takashi and Choi, Eun-Hye and Tsuchiya, Tatsuhiro},
title = {A Comparative Study on Combinatorial and Random Testing for Highly Configurable Systems},
year = {2020},
isbn = {978-3-030-64880-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64881-7_20},
doi = {10.1007/978-3-030-64881-7_20},
abstract = {Highly configurable systems (HCSs), such as software product lines, have complex configuration spaces. Combinatorial Testing and Random Testing are the main approaches to testing of HCSs. In this paper, we empirically compare their strengths with respect to scalability and diversity of sampled configurations (i.e., tests). We choose Icpl&nbsp;and QuickSampler&nbsp;to respectively represent Combinatorial Testing and Random Testing. Experiments are conducted to evaluate the t-way coverage criterion of generated test suites for HCS benchmarks.},
booktitle = {Testing Software and Systems: 32nd IFIP WG 6.1 International Conference, ICTSS 2020, Naples, Italy, December 9–11, 2020, Proceedings},
pages = {302–309},
numpages = {8},
keywords = {Combinatorial testing, Random testing, Software product line},
location = {Naples, Italy}
}

@inproceedings{10.1145/3233027.3241370,
author = {Acher, Mathieu and Rabiser, Rick and Lopez-Herrejon, Roberto E.},
title = {SPLtea 2018: third international workshop on software product line teaching},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3241370},
doi = {10.1145/3233027.3241370},
abstract = {Education has a key role to play for disseminating the constantly growing body of Software Product Line (SPL) knowledge. In a sense, every researcher in SPL should think about how to teach SPL. This workshop aims to explore and explain the current status and ongoing work on teaching SPLs at universities, colleges, and in industry (e.g., by consultants). This third edition will continue the effort made at SPLTea'14 and SPLTea'15. In particular we seek to attract experience reports of teaching SPLs. We expect several lightning talks that report on traditional questions like: what is the targeted audience? What is the place in the curriculum? What is the material (slides, tools, books, etc) used? What are the benefits of teaching SPLs? What are the difficulties and barriers? We also welcome opinionated and provocative talks that encourage discussions about the topic. Another goal of the workshop is to populate an open repository of resources dedicated to SPL teaching: http://teaching.variability.io},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {297},
numpages = {1},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1016/j.cl.2016.07.007,
author = {Karimpour, Reza and Ruhe, Guenther},
title = {Evolutionary robust optimization for software product line scoping},
year = {2017},
issue_date = {January 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {47},
number = {P2},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2016.07.007},
doi = {10.1016/j.cl.2016.07.007},
abstract = {Background: Software product line (SPL) scoping is an important phase when planning for product line adoption. An SPL scope specifies: (1) the extent of the domain supported by the product line, (2) portfolio of products in the product line and (3) list of assets to be developed for reuse across the family of products.Issue: SPL scope planning is usually based on estimates about the state of the market and the engineering capabilities of the development team. One challenge with these estimates is that there are inaccuracies due to uncertainty in the environment or accuracy of measurement. This may result in issues ranging from suboptimal plans to infeasible plans.Objective: To address the above, we propose to include uncertainty as part of the SPL scoping model. Plans developed in consideration of uncertainty would be more robust against possible fluctuations in estimates.Approach: In this paper, a method to incorporate uncertainty in scoping optimization and its application to generate robust solutions is proposed. We capture uncertainty as part of the formulation and model scoping optimization as a multi-objective problem with profit and stability as fitness functions. Profit stability and feasibility stability are considered to represent stability concerns.Results: Results show that, compared to other scope optimization approaches, both performance stability and feasibility stability are improved while maintaining near optimal performance for profit objective. Also, generated results consist of solutions with trade-offs between profit and stability, providing the decision maker with enhanced decision support.Conclusion: Multi-objective optimization with stability consideration for SPL scoping provides project managers with a robust and flexible way to address uncertainty in the process of SPL scoping. HighlightsA robust multi-objective optimization approach for SPL scoping is proposed.Two types of stability are considered: performance stability and feasibility stability.Approach was able to find plans with higher stability.},
journal = {Comput. Lang. Syst. Struct.},
month = jan,
pages = {189–210},
numpages = {22},
keywords = {Evolutionary optimization, Robust optimization, Search-based software engineering, Software product line scoping}
}

@inproceedings{10.1145/2648511.2648527,
author = {Villela, Karina and Silva, Adeline and Vale, Tassio and de Almeida, Eduardo Santana},
title = {A survey on software variability management approaches},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648527},
doi = {10.1145/2648511.2648527},
abstract = {Variability Management (VM) is a key practice in the development of variant-rich systems. Over the years, attention has been paid to VM approaches adopted by traditional software product lines. The increasing demand for dynamic and highly configurable systems, however, calls for a closer look at the approaches used to develop these systems. We therefore conducted a survey with practitioners from organizations developing variant-rich systems in order to characterize the state of the practice. We also wanted to identify factors that might influence the adoption of specific VM approaches as well as the perception of problems/difficulties posed by those. We analyzed the answers of 31 respondents from thirteen countries and found that there is a correlation between the business domain and the adopted VM approaches. With regard to the problems/difficulties, the difficulty of assuring the quality of maintenance due to the explosion of dependencies was a major issue. This paper reports on relevant findings that could help companies to better understand their problems and researchers to design new/improved solutions.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {147–156},
numpages = {10},
keywords = {product line, state-of-the-practice, survey, variability, variability management},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3404835.3463039,
author = {Zendel, Oleg and Culpepper, J. Shane and Scholer, Falk},
title = {Is Query Performance Prediction With Multiple Query Variations Harder Than Topic Performance Prediction?},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463039},
doi = {10.1145/3404835.3463039},
abstract = {Accurately estimating the retrieval effectiveness of different queries representing distinct information needs is a problem in Information Retrieval (IR) that has been studied for over 20 years. Recent work showed that the problem can be significantly harder when multiple queries representing the same information need are used in prediction. By generalizing the existing evaluation framework of Query Performance Prediction (QPP) we explore the causes of these differences in prediction quality in the two scenarios. Our empirical analysis demonstrates that for most predictors, this difference is solely an artifact of the underlying differences in the query effectiveness distributions. Our detailed analysis also demonstrates key performance distribution properties under which (QPP) is most and least reliable.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1713–1717},
numpages = {5},
keywords = {evaluation, query performance prediction, query variations},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@article{10.1016/j.jss.2019.110419,
author = {Jung, Pilsu and Kang, Sungwon and Lee, Jihyun},
title = {Automated code-based test selection for software product line regression testing},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110419},
doi = {10.1016/j.jss.2019.110419},
journal = {J. Syst. Softw.},
month = dec,
numpages = {19},
keywords = {Product lines testing, Regression test selection, Software maintenance, Software evolution}
}

@inproceedings{10.1145/2364412.2364428,
author = {Zhang, Bo and Becker, Martin},
title = {Code-based variability model extraction for software product line improvement},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364428},
doi = {10.1145/2364412.2364428},
abstract = {Successful Software Product Lines (SPLs) evolve over time. However, one practical problem is that during SPL evolution the core assets, especially the code, tend to become complicated and difficult to understand, use, and maintain. Typically, more and more problems arise over time with implicit or already lost adaptation knowledge about the interdependencies of the different system variants and the supported variability. In this paper, we present a model-based SPL improvement process that analyzes existing large-scale SPL reuse infrastructure to identify improvement potential with respective metrics. Since Conditional Compilation (CC) is one of the most widely used mechanisms to implement variability, we parse variability-related facts from preprocessor code. Then we automatically extract an implementation variability model, including product configuration and variation points that are structured in a hierarchical variability tree. The extraction process is presented with concrete measurement results from an industrial case study.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {91–98},
numpages = {8},
keywords = {conditional compilation, software product line maintenance, variability model},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s10664-021-09964-6,
author = {Duchien, Laurence and Gr\"{u}nbacher, Paul and Th\"{u}m, Thomas},
title = {Foreword to the Special Issue on Configurable Systems},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09964-6},
doi = {10.1007/s10664-021-09964-6},
journal = {Empirical Softw. Engg.},
month = jul,
numpages = {3}
}

@inproceedings{10.1145/3377024.3377045,
author = {Ferreira, Fischer and Vale, Gustavo and Diniz, Jo\~{a}o P. and Figueiredo, Eduardo},
title = {On the proposal and evaluation of a test-enriched dataset for configurable systems},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377045},
doi = {10.1145/3377024.3377045},
abstract = {Configurable systems offer advantages compared to single systems since developers should maintain a unique platform to address a diversity of deployment contexts and usages. To ensure that all configurations correctly execute, developers spend considerable effort testing different system configurations. This testing process is essential because configurations that fail may potentially hurt user experience and degrade the reputation of a project. Previous studies have reported and created repositories of open-source configurable systems, although they neglected their test suites. Considering the importance of testing configurable systems, we reviewed the literature to find test suites of open-source configurable systems. As we found only 10 configurable systems with test suite available and considering that a test suite for configurable systems may be useful for different research topics, we created test suites for 20 additional configurable systems and evaluated the test suites coverage of all 30 configurable systems. Surprisingly, our test suites were able to find several failures in existing systems, mainly because of feature interactions, which enforces the need of test suites available for open source configurable systems. Aiming at finding common characteristics for fault-prone components (e.g., classes) on configurable systems, we group them based on software quality metrics (e.g., coupling between objects and lines of code). As result, we found that 44% of the configurable systems of our dataset have failures and these failures are concentrated in few classes.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {16},
numpages = {10},
keywords = {dataset of open-source configurable systems, feature interactions, software failures, testing configurable systems},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1007/978-3-030-41418-4_17,
author = {Chen, Yuntianyi and Gu, Yongfeng and He, Lulu and Xuan, Jifeng},
title = {Regression Models for Performance Ranking of Configurable Systems: A Comparative Study},
year = {2019},
isbn = {978-3-030-41417-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41418-4_17},
doi = {10.1007/978-3-030-41418-4_17},
abstract = {Finding the best configurations for a highly configurable system is challenging. Existing studies learned regression models to predict the performance of potential configurations. Such learning suffers from the low accuracy and the high effort of examining the actual performance for data labeling. A recent approach uses an iterative strategy to sample a small number of configurations from the training pool to reduce the number of sampled ones. In this paper, we conducted a comparative study on the rank-based approach of configurable systems with four regression methods. These methods are compared on 21 evaluation scenarios of 16 real-world configurable systems. We designed three research questions to check the impacts of different methods on the rank-based approach. We find out that the decision tree method of Classification And Regression Tree (CART) and the ensemble learning method of Gradient Boosted Regression Trees (GBRT) can achieve better ranks among four regression methods under evaluation; the sampling strategy in the rank-based approach is useful to save the cost of sampling configurations; the measurement, i.e., rank difference correlates with the relative error in several evaluation scenarios.},
booktitle = {Structured Object-Oriented Formal Language and Method: 9th International Workshop, SOFL+MSVL 2019, Shenzhen, China, November 5, 2019, Revised Selected Papers},
pages = {243–258},
numpages = {16},
keywords = {Regression methods, Performance prediction, Sampling, Software configurations},
location = {Shenzhen, China}
}

@inproceedings{10.1145/3357765.3359515,
author = {Hinterreiter, Daniel and Nieke, Michael and Linsbauer, Lukas and Seidl, Christoph and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {Harmonized temporal feature modeling to uniformly perform, track, analyze, and replay software product line evolution},
year = {2019},
isbn = {9781450369800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357765.3359515},
doi = {10.1145/3357765.3359515},
abstract = {A feature model (FM) describes commonalities and variability within a software product line (SPL) and represents the configuration options at one point in time. A temporal feature model (TFM) additionally represents FM evolution, e.g., the change history or the planning of future releases. The increasing number of different TFM notations hampers research collaborations due to a lack of interoperability regarding notations, editors, and analyses. We present a common API for TFMs, which provides the core of a TFM ecosystem, to harmonize notations. We identified the requirements for the API based on systematically classifying and comparing the capabilities of existing TFM approaches. Our approach allows to work seamlessly with different TFM notations to perform, track, analyze and replay evolution. Our evaluation investigates two research questions on the expressiveness (RQ1) and utility (RQ2) of our approach by presenting implementations for several existing FM and TFM notations and replaying evolution histories from two case study systems.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {115–128},
numpages = {14},
keywords = {evolution, software product lines},
location = {Athens, Greece},
series = {GPCE 2019}
}

@article{10.1016/j.cl.2018.01.002,
author = {Braz, Larissa and Gheyi, Rohit and Mongiovi, Melina and Ribeiro, M\'{a}rcio and Medeiros, Fl\'{a}vio and Teixeira, Leopoldo and Souto, Sabrina},
title = {A change-aware per-file analysis to compile configurable systems with #ifdefs      },
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {54},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2018.01.002},
doi = {10.1016/j.cl.2018.01.002},
journal = {Comput. Lang. Syst. Struct.},
month = dec,
pages = {427–450},
numpages = {24},
keywords = {Compilation, #ifdef, Configurable systems, Impact analysis}
}

@inproceedings{10.1145/2491627.2491643,
author = {Fantechi, Alessandro},
title = {Topologically configurable systems as product families},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491643},
doi = {10.1145/2491627.2491643},
abstract = {We address a category of systems whose deployment requires a configuration according to topological information. Although inspired by the case of railway interlocking systems, we give a general definition of topologically configurable control systems. We consider the application of product line engineering principles to the development of these systems, by discussing the adoption of different approaches to achieve a flexible configuration of products, able to factorise most of the design effort, as typical in a product line approach.Verifying the behaviour of such systems, either by testing or by formal verification is actually a challenge: the intricate relations between the actual topology controlled by a product and its functional requirements may prevent any attempt to factorise analysis activities. We will discuss how the application of product line engineering principles can help, with special focus on formal verification, pointing to several open research issues.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {151–156},
numpages = {6},
keywords = {topological configuration, variability modelling},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@article{10.1002/smr.2202,
author = {de Oliveira, Andr\'{e} Luiz and Braga, Rosana and Masiero, Paulo and Parker, David and Papadopoulos, Yiannis and Habli, Ibrahim and Kelly, Tim},
title = {Variability management in safety‐critical systems design and dependability analysis},
year = {2019},
issue_date = {August 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {8},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2202},
doi = {10.1002/smr.2202},
abstract = {Safety‐critical systems are of paramount importance for many application domains, where safety properties are a key driver to engineer critical aspects and avoid system failures. For the benefits of large‐scale reuse, software product lines (SPL) have been adopted in critical systems industry. However, the integration of safety analysis in the SPL development process is nontrivial. Also, the different usage contexts of safety‐critical systems complicates component fault modeling tasks and the identification of potential hazards. In this light, better methods become necessary to estimate the impact of dependability properties during Hazard Analysis and Risk Assessment. Existing methods incorporating the analysis of safety properties in SPL are limited as they do not include hazard analysis and component fault modeling. In this paper, we present the novel DEPendable Software Product Line Engineering (DEPendable‐SPLE) approach, which extends traditional SPL processes to support the reuse of safety assets. We also present a detailed analysis of the impact of product and context features on the SPL design, safety analysis, and safety requirements. We applied DEPendable‐SPLE to a realistic case study from the aerospace domain to illustrate how to model and reuse safety properties. DEPendable‐SPLE reduced the effort of safety analysis for certifying system variants.


image
image
 Extending traditional software product line processes with the support for variability management on dependability analysis enables the systematic reuse of both design and dependability information, and generation of dependability assets. It contributes to reduce the effort and costs of achieving certification of safety‐critical systems. Understanding the impact of variation in product and usage context features on the system design and dependability analysis may contribute to increase the accuracy of the reused dependability assets.},
journal = {J. Softw. Evol. Process},
month = aug,
numpages = {27},
keywords = {dependability analysis, reuse, safety certification, safety‐critical systems, software product lines}
}

@inproceedings{10.1145/3474995.3475020,
author = {Ma, Xiao and Qu, Jian-Hua and Xu, Hui-Min and Ling, Yu-Ting},
title = {E-Learning Performance Prediction Based on Attention Mechanism},
year = {2021},
isbn = {9781450390033},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474995.3475020},
doi = {10.1145/3474995.3475020},
abstract = {One of the current research hotspots in educational data mining is to predict their online academic performance. The prediction results can provide personalized guidance for learners and teaching strategies. At present, performance prediction methods often ignore the fact that different behavior characteristics have different effects on performance. Therefore, this paper proposed an e-Learning performance prediction method based on attention mechanism. This method calculated the attention score of each behavior feature, then assigned the corresponding attention weight to each behavior feature. So, by this way, different behavior features have different influence on academic performance. The experimental results show that this method can predict e-Learning performance more accurately than other methods.},
booktitle = {Proceedings of the 2021 6th International Conference on Distance Education and Learning},
pages = {152–156},
numpages = {5},
keywords = {Behavior Characteristics, Performance Prediction, Attention Mechanism, E-Learning},
location = {Shanghai, China},
series = {ICDEL '21}
}

@inproceedings{10.1145/3461001.3472731,
author = {Becker, Martin and Sch\"{a}fer, Andreas},
title = {Variability realization in UML/SysML models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3472731},
doi = {10.1145/3461001.3472731},
abstract = {Motivated by experiences from different industrial settings, the tutorial reveals the increasing need for guidance and decision support on how to handle variants and variability in SysML and UML models. While a substantial amount of variability realization approaches has already been discussed on the level of source code, there is little guidance for practitioners on the model level. With this, there is major uncertainty in dealing with concurrent changes and parallel modeling of similar system variants},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {212–213},
numpages = {2},
keywords = {SysML, UML, decision support, model-based systems engineering, system and software product line engineering, variability mechanism, variability realization, variant management},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3474085.3475688,
author = {Khan, Md Fahim Faysal and Troncoso Aldas, Nelson Daniel and Kumar, Abhishek and Advani, Siddharth and Narayanan, Vijaykrishnan},
title = {Sparse to Dense Depth Completion using a Generative Adversarial Network with Intelligent Sampling Strategies},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475688},
doi = {10.1145/3474085.3475688},
abstract = {Predicting dense depth accurately is essential for 3D scene understanding applications such as autonomous driving and robotics. However, the depth obtained from commercially available LiDAR and Time-of-Flight sensors is very sparse. With RGB color guidance, modern convolutional neural network (CNN) based approaches can recover the missing depth information. However, there could be scenarios such as low-light environments where it might be difficult to get an associated RGB image with the sparse depth. In this work, we propose a Generative Adversarial Network (GAN) that can accurately predict the dense depth using only sparse samples without any RGB inputs. Generally, the sparsity in the depth samples is uniformly distributed and cannot guarantee capturing all intricate details. In this study, we also explore different variants of sparse sampling strategies from uniform to feature based directed sampling. We find that feature based intelligent sampling enjoys better compression ratio without sacrificing intricate details, saving data communication bandwidth. Compared to uniform sampling, depending on how aggressively the directed sampling is done, we observe about 3% to 25% reduction in size. We can easily reduce the size by 8% with directed sampling without sacrificing the reconstruction accuracy. Although such directed sampling strategies are not readily available with commercially viable depth sensors, we believe that our study paves the way for future intelligent sensing and sampling strategies. To further investigate data reduction and reconstruction accuracy trade-offs we deploy our GAN to generate higher resolution dense depth from 4 times smaller sparse samples. With slight decrease in accuracy, our GAN is able to recover the depth successfully which shows great promise in edge Internet of Things (IoT) applications where we have very tight constraint on data transmission bandwidth. Our source code along with examples is available at: https://github.com/kocchop/depth-completion-gan},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {5528–5536},
numpages = {9},
keywords = {depth completion, gan, image compression, sensor sampling},
location = {Virtual Event, China},
series = {MM '21}
}

@article{10.1007/s00521-020-05460-y,
author = {Margaris, Dionisis and Spiliotopoulos, Dimitris and Vassilakis, Costas and Vasilopoulos, Dionysios},
title = {Improving collaborative filtering’s rating prediction accuracy by introducing the experiencing period criterion},
year = {2020},
issue_date = {Jan 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05460-y},
doi = {10.1007/s00521-020-05460-y},
abstract = {Collaborative filtering algorithms take into account users’ tastes and interests, expressed as ratings, in order to formulate personalized recommendations. These algorithms initially identify each user’s “near neighbors,” i.e., users having highly similar tastes and likings. Then, their already entered ratings are used, in order to formulate rating predictions, and predictions are typically used thereafter to drive the recommendation formulation process, e.g., by selecting the items with the top-K rating predictions; henceforth, the quality of the rating predictions significantly affects the quality of the generated recommendations. However, certain types of users prefer to experience (purchase, listen to, watch, play) items the moment they become available in the stores, or even preorder, while other types of users prefer to wait for a period of time before experiencing, until a satisfactory amount of feedback (reviews and/or evaluations) becomes available for the item of interest. Notably, a user may apply varying practices on different item categories, i.e., be keen to experience new items in some categories while being uneager in other categories. To formulate successful recommendations, a recommender system should align with users’ patterns of practice and avoid recommending a newly released item to users that delay to experience new items in the particular category, and vice versa. Insofar, however, no algorithm that takes into account this aspect has been proposed. In this work, we (1) present the Experiencing Period Criterion rating prediction algorithm (CFEPC) which modifies the rating prediction value based on the combination of the users’ experiencing wait period in a certain item category and the period the rating to be predicted belongs to, so as to enhance the prediction accuracy of recommender systems and (2) evaluate the accuracy of the proposed algorithm using seven widely used datasets, considering two widely employed user similarity metrics, as well as four accuracy metrics. The results show that the CFEPC algorithm, presented in this paper, achieves a considerable rating prediction quality improvement, in all the datasets tested, indicating that the CFEPC algorithm can provide a basis for formulating more successful recommendations.},
journal = {Neural Comput. Appl.},
month = nov,
pages = {193–210},
numpages = {18},
keywords = {Recommender systems, Rating prediction accuracy, Collaborative filtering, Experiencing period criterion, Ratings’ timestamps, Pearson correlation coefficient, Cosine similarity, Evaluation}
}

@inproceedings{10.1007/978-3-030-91387-8_26,
author = {Huynh-Ly, Thanh-Nhan and Le, Huy-Thap and Thai-Nghe, Nguyen},
title = {Integrating Deep Learning Architecture into Matrix Factorization for Student Performance Prediction},
year = {2021},
isbn = {978-3-030-91386-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91387-8_26},
doi = {10.1007/978-3-030-91387-8_26},
abstract = {In universities using the academic credit system, choosing elective courses is a crucial task that significantly affects student performance. Because of poor performances, numerous students have been receiving formal warnings and expulsions from universities. Certainly, a good study plan from course recommendation methods plays an important role in obtaining a good study performance. In addition, early warnings that release on challenging courses enable students to prepare better for such courses. Predicting student learning performance is a vital factor in the courses recommendation system and is an essential task of an academic advisor. Many research methods solved this problem with diverse approaches such as association rules, deep learning, and recommender systems (RS). It recently built the courses recommendation system, which is used for personalized recommendation, especially the matrix factorization (MF) technique; But, the prediction accuracy of the MF still need to be improved. So, many studies try to integrate more information (e.g., social networks, course relationships) into the model. Besides, deep learning addresses the student performance prediction, which currently is state of the art, but it usually is general rules (not a personalized prediction). Indeed, deep learning and matrix factorization have advantages and disadvantages, so they need to compound together to get better. This paper proposes an approach to predict student performance that utilizes the deep learning architecture to carry out the MF method to enhance prediction accuracy, called deep matrix factorization. Experimental results of the proposed approach are positive when we perform on the published educational dataset.},
booktitle = {Future Data and Security Engineering: 8th International Conference, FDSE 2021, Virtual Event, November 24–26, 2021, Proceedings},
pages = {408–423},
numpages = {16},
keywords = {Educational data mining, Deep learning, Matrix factorization, Courses recommendation, Student performance prediction}
}

@inproceedings{10.1145/2791060.2791069,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Empirical comparison of regression methods for variability-aware performance prediction},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791069},
doi = {10.1145/2791060.2791069},
abstract = {Product line engineering derives product variants by selecting features. Understanding the correlation between feature selection and performance is important for stakeholders to acquire a desirable product variant. We infer such a correlation using four regression methods based on small samples of measured configurations, without additional effort to detect feature interactions. We conduct experiments on six real-world case studies to evaluate the prediction accuracy of the regression methods. A key finding in our empirical study is that one regression method, called Bagging, is identified as the best to make accurate and robust predictions for the studied systems.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {186–190},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s11265-020-01563-w,
author = {Arndt, Oliver Jakob and L\"{u}ders, Matthias and Riggers, Christoph and Blume, Holger},
title = {Multicore Performance Prediction with MPET: Using Scalability Characteristics for Statistical Cross-Architecture Prediction},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {92},
number = {9},
issn = {1939-8018},
url = {https://doi.org/10.1007/s11265-020-01563-w},
doi = {10.1007/s11265-020-01563-w},
abstract = {Multicore processors serve as target platforms in a broad variety of applications ranging from high-performance computing to embedded mobile computing and automotive applications. But, the required parallel programming opens up a huge design space of parallelization strategies each with potential bottlenecks. Therefore, an early estimation of an application’s performance is a desirable development tool. However, out-of-order execution, superscalar instruction pipelines, as well as communication costs and (shared-) cache effects essentially influence the performance of parallel programs. While offering low modeling effort and good simulation speed, current approximate analytic models provide moderate prediction results so far. Virtual prototyping requires a time-consuming simulation, but produces better accuracy. Furthermore, even existing statistical methods often require detailed knowledge of the hardware for characterization. In this work, we present a concept called Multicore Performance Evaluation Tool (MPET) and its evaluation for a statistical approach for performance prediction based on abstract runtime parameters, which describe an application’s scalability behavior and can be extracted from profiles without user input. These scalability parameters not only include information on the interference of software demands and hardware capabilities, but indicate bottlenecks as well. Depending on the database setup, we achieve a competitive accuracy of 20% mean prediction error (11% median), which we also demonstrate in a case study.},
journal = {J. Signal Process. Syst.},
month = sep,
pages = {981–998},
numpages = {18},
keywords = {Parallelization, Performance Prediction, Scalability, Multicore Software Migration}
}

@inproceedings{10.1145/3001867.3001872,
author = {Lity, Sascha and Kowal, Matthias and Schaefer, Ina},
title = {Higher-order delta modeling for software product line evolution},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001872},
doi = {10.1145/3001867.3001872},
abstract = {In software product lines (SPL), i.e., a family of similar software systems sharing common and variable artifacts, modeling evolution and reasoning about it is challenging, as not only a single system, but rather a set of system variants as well as their interdependencies change. An integrated modeling formalism for variability and evolution is required to allow the capturing of evolution operations that are applied to SPL artifacts, and to facilitate the impact analysis of evolution on the artifact level. Delta modeling is a flexible transformational variability modeling approach, where the variability and commonality between variants are explicitly documented and analyzable by means of transformations modeled as deltas. In this paper, we lift the notion of delta modeling to capture both, variability and evolution, by deltas. We evolve a delta model specifying a set of variants by applying higher-order deltas. A higher-order delta encapsulates evolution operations, i.e., additions, removals, or modifications of deltas, and transforms a delta model in its new version. In this way, we capture the complete evolution history of delta-oriented SPLs by higher-order delta models. By analyzing each higher-order delta application, we are further able to reason about the impact and, thus, the changes to the specified set of variants. We prototypically implement our formalism and show its applicability using a system from the automation engineering domain.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {39–48},
numpages = {10},
keywords = {Delta Modeling, Software Evolution, Software Product Lines},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@phdthesis{10.5555/AAI28490906,
author = {Pan, Zhenyu and Chen, Cindy and Chen, Guanling},
advisor = {Tingjian, Ge,},
title = {Student Behavior Pattern Learning for Course Performance Prediction},
year = {2021},
isbn = {9798515200282},
publisher = {University of Massachusetts Lowell},
abstract = {Massive Online Open Courses (MOOCs) have become increasingly popular among students, partly because they make learning resources much easier to spread and share. However, MOOC's unfinished rate or failure rate can be extremely high. To improve the current state of affairs, were sort to learning and discovering students' online study behavior. By using the learning behavior features that we collect, we first build a statistical model that predicts a student's examination scores. Furthermore, at a deeper level, we extract language features from students' reading notes. Through analyzing the topics in the reading notes, we obtain latent but robust and reliable features that indicate a student's performance in the course.Specifically, we use a Topic-based Latent Variable Model to predict the midterm and final scores with students' textbook reading notes, and compare with both the Two-step LDA model and the knowledge graph embedding. Our novel study brings insights into understanding the the connection between online course study behaviors and end performance, which will not only benefit the conscientious students who want to improve their study, but also shed light on educators for identifying the under-performing students earlier for intervention, and for improving the design of online courses. Last but not least, we study the theoretical problem and prove the convergence of prediction accuracy for a generic discriminative model.},
note = {AAI28490906}
}

@inproceedings{10.1145/3459637.3482063,
author = {Arabzadeh, Negar and Khodabakhsh, Maryam and Bagheri, Ebrahim},
title = {BERT-QPP: Contextualized Pre-trained transformers for Query Performance Prediction},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482063},
doi = {10.1145/3459637.3482063},
abstract = {Query Performance Prediction (QPP) is focused on estimating the difficulty of satisfying a user query for a certain retrieval method. While most state of the art QPP methods are based on term frequency and corpus statistics, more recent work in this area have started to explore the utility of pretrained neural embeddings, neural architectures and contextual embeddings. Such approaches extract features from pretrained or contextual embeddings for the sake of training a supervised performance predictor. In this paper, we adopt contextual embeddings to perform performance prediction, but distinguish ourselves from the state of the art by proposing to directly fine-tune a contextual embedding, i.e., BERT, specifically for the task of query performance prediction. As such, our work allows the fine-tuned contextual representations to estimate the performance of a query based on the association between the representation of the query and the retrieved documents. We compare the performance of our approach with the state-of-the-art based on the MS MARCO passage retrieval corpus and its three associated query sets: (1) MS MARCO development set, (2) TREC DL 2019, and (3) TREC DL 2020. We show that our approach not only shows significant improved prediction performance compared to all the state-of-the-art methods, but also, unlike past neural predictors, it shows significantly lower latency, making it possible to use in practice.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {2857–2861},
numpages = {5},
keywords = {bi-encoder, contextualized pre-trained transformers, cross-encoder, query performance prediction},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@inproceedings{10.5555/1753235.1753274,
author = {Pech, Daniel and Knodel, Jens and Carbon, Ralf and Schitter, Clemens and Hein, Dirk},
title = {Variability management in small development organizations: experiences and lessons learned from a case study},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Product line practices promise to reduce development and maintenance efforts, to improve the productivity and to reduce the time to market by systematic reuse of commonalities and variabilities. However, in order to reap the fruits of exploiting those, an upfront investment is required. This paper presents a case study, which analyzes the cost-benefit ratio for one product line discipline -- variability management. Wikon GmbH -- a small German development organization evolving a product line of remote monitoring and controlling devices -- switched from manual, file-based conditional compilation to tool-supported decision models. We discuss experiences made and show that the break-even was reached with the 4th product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {285–294},
numpages = {10},
keywords = {decision model, evolution, product line engineering, software architecture, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.5555/2819009.2819208,
author = {Klewerton, Wesley and Assun\c{c}\~{a}o, Guez},
title = {Search-based migration of model variants to software product line architectures},
year = {2015},
publisher = {IEEE Press},
abstract = {Software Product Lines (SPLs) are families of related software systems developed for specific market segments or domains. Commonly, SPLs emerge from sets of existing variants when their individual maintenance becomes infeasible. However, current approaches for SPL migration do not support design models, are partially automated, or do not reflect constraints from SPL domains. To tackle these limitations, the goal of this doctoral research plan is to propose an automated approach to the SPL migration process at the design level. This approach consists of three phases: detection, analysis and transformation. It uses as input the class diagrams and lists of features for each system variant, and relies on search-based algorithms to create a product line architecture that best captures the variability present in the variants. Our expected contribution is to support the adoption of SPL practices in companies that face the scenario of migrating variants to SPLs.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {895–898},
numpages = {4},
keywords = {migration, re-engineering, reuse, search-based software engineering, software product line},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3382025.3414725,
author = {Ferreira, Fischer and Viggiato, Markos and Souza, Maur\'{\i}cio and Figueiredo, Eduardo},
title = {Testing configurable software systems: the failure observation challenge},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414725},
doi = {10.1145/3382025.3414725},
abstract = {Configurable software systems can be adapted or configured according to a set of features to increase reuse and productivity. The testing process is essential because configurations that fail may potentially hurt user experience and degrade the reputation of a project. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. To encourage the research area on testing configurable systems, researchers and practitioners should be able to try out their solutions in common datasets. In this paper, we propose a dataset with 22 configurable software systems and an extensive test suite. Moreover, we report failures found in these systems and source code metrics to allow evaluating candidate solutions. We hope to engage the community and stimulate new and existing approaches to the problem of testing configurable systems.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {28},
numpages = {6},
keywords = {software product line, testing configurable systems},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1007/s10922-020-09547-8,
author = {Van Rossem, Steven and Tavernier, Wouter and Colle, Didier and Pickavet, Mario and Demeester, Piet},
title = {Optimized Sampling Strategies to Model the Performance of Virtualized Network Functions},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09547-8},
doi = {10.1007/s10922-020-09547-8},
abstract = {Modern network services make increasing use of virtualized compute and network resources. This is enabled by the growing availability of softwarized network functions, which take on major roles in the total traffic flow (such as caching, routing or as firewall). To ensure reliable operation of its services, the service provider needs a good understanding of the performance of the deployed softwarized network functions. Ideally, the service performance should be predictable, given a certain input workload and a set of allocated (virtualized) resources (such as vCPUs and bandwidth). This helps to estimate more accurately how much resources are needed to operate the service within its performance specifications. To predict its performance, the network function should be profiled in the whole range of possible input workloads and resource configurations. However, this input can span a large space of multiple parameters and many combinations to test, resulting in an expensive and overextended measurement period. To mitigate this, we present a profiling framework and a sampling heuristic to help select both workload and resource configurations to test. Additionally, we compare several machine-learning based methods for the best prediction accuracy, in combination with the sampling heuristic. As a result, we obtain a reduced dataset which can still model the performance of the network functions with adequate accuracy, while requiring less profiling time. Compared to uniform sampling, our tests show that the heuristic achieves the same modeling accuracy with up to five times less samples.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {1482–1521},
numpages = {40},
keywords = {Sampling heuristic, Network Function Virtualization, Performance profiling, Machine learning, Regression}
}

@inproceedings{10.1145/2993236.2993250,
author = {Braz, Larissa and Gheyi, Rohit and Mongiovi, Melina and Ribeiro, M\'{a}rcio and Medeiros, Fl\'{a}vio and Teixeira, Leopoldo},
title = {A change-centric approach to compile configurable systems with #ifdefs},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993250},
doi = {10.1145/2993236.2993250},
abstract = {Configurable systems typically use #ifdefs to denote variability. Generating and compiling all configurations may be time-consuming. An alternative consists of using variability-aware parsers, such as TypeChef. However, they may not scale. In practice, compiling the complete systems may be costly. Therefore, developers can use sampling strategies to compile only a subset of the configurations. We propose a change-centric approach to compile configurable systems with #ifdefs by analyzing only configurations impacted by a code change (transformation). We implement it in a tool called CHECKCONFIGMX, which reports the new compilation errors introduced by the transformation. We perform an empirical study to evaluate 3,913 transformations applied to the 14 largest files of BusyBox, Apache HTTPD, and Expat configurable systems. CHECKCONFIGMX finds 595 compilation errors of 20 types introduced by 41 developers in 214 commits (5.46% of the analyzed transformations). In our study, it reduces by at least 50% (an average of 99%) the effort of evaluating the analyzed transformations by comparing with the exhaustive approach without considering a feature model. CHECKCONFIGMX may help developers to reduce compilation effort to evaluate fine-grained transformations applied to configurable systems with #ifdefs.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {109–119},
numpages = {11},
keywords = {#ifdefs, Configurable Systems, compilation errors},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@article{10.1007/s10009-015-0386-x,
author = {Gnesi, Stefania and Jarzabek, Stan},
title = {Special section on the 17th International Software Product Line Conference},
year = {2015},
issue_date = {October   2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-015-0386-x},
doi = {10.1007/s10009-015-0386-x},
abstract = {Today, companies develop, maintain and deploy families of similar software products (e.g., games for different models of smartphones) rather than a single product. Software product lines engineering refers to software engineering methods, tools and techniques for creating a collection of similar software systems from a shared set of software assets using a common means of production. Software Product Line Conferences started in 1996, as the premier forum for practitioners, researchers and educators to present and discuss the most recent ideas, innovations, trends, experiences, and concerns in the area of software product lines, software product family engineering and, more recently, systems family engineering, managing families of software products as a whole rather than each family member individually. This special section stems from the 17th SPL Conference held in Tokyo, Japan, in August 2013. The contributions to this special section are further elaborations of the papers presented at the conference.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {555–557},
numpages = {3},
keywords = {Software Engineering, Software Product Lines}
}

@inproceedings{10.1145/3236024.3236074,
author = {Jamshidi, Pooyan and Velez, Miguel and K\"{a}stner, Christian and Siegmund, Norbert},
title = {Learning to sample: exploiting similarities across environments to learn performance models for configurable systems},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236074},
doi = {10.1145/3236024.3236074},
abstract = {Most software systems provide options that allow users to tailor the system in terms of functionality and qualities. The increased flexibility raises challenges for understanding the configuration space and the effects of options and their interactions on performance and other non-functional properties. To identify how options and interactions affect the performance of a system, several sampling and learning strategies have been recently proposed. However, existing approaches usually assume a fixed environment (hardware, workload, software release) such that learning has to be repeated once the environment changes. Repeating learning and measurement for each environment is expensive and often practically infeasible. Instead, we pursue a strategy that transfers knowledge across environments but sidesteps heavyweight and expensive transfer-learning strategies. Based on empirical insights about common relationships regarding (i) influential options, (ii) their interactions, and (iii) their performance distributions, our approach, L2S (Learning to Sample), selects better samples in the target environment based on information from the source environment. It progressively shrinks and adaptively concentrates on interesting regions of the configuration space. With both synthetic benchmarks and several real systems, we demonstrate that L2S outperforms state of the art performance learning and transfer-learning approaches in terms of measurement effort and learning accuracy.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {71–82},
numpages = {12},
keywords = {Software performance, configurable systems, transfer learning},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1007/978-3-030-60636-7_11,
author = {Li, Jianian and Yu, Yanwei and Lu, Yunhong and Song, Peng},
title = {Student Performance Prediction Based on Multi-view Network Embedding},
year = {2020},
isbn = {978-3-030-60635-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60636-7_11},
doi = {10.1007/978-3-030-60636-7_11},
abstract = {Predicting student performance is a very important but yet challenging task in education. In this paper, we propose a Multi-View Network Embedding (MVNE) method for student performance prediction, which effectively fuses multiple data sources. We first construct three networks to model three different types of data sources correlated with student performance, ranging from class performance data, historical grades, to students’ campus social relationships. Then we use joint network embedding to learn the embedding representation of students and questions based on the proposed separated random walk sampling. Student performance is predicted based on both student and question similarities in the low-dimensional representation. Experimental results on the real-world datasets demonstrate the effectiveness of the proposed method.},
booktitle = {Pattern Recognition and Computer Vision: Third Chinese Conference, PRCV 2020, Nanjing, China, October 16–18, 2020, Proceedings, Part III},
pages = {125–136},
numpages = {12},
keywords = {Student performance prediction, Network embedding, Heterogeneous networks, Multi-source data},
location = {Nanjing, China}
}

@article{10.1002/spe.2428,
author = {Santos, Andr\'{e} L.},
title = {Variability management of plugin-based systems using feature models},
year = {2017},
issue_date = {July 2017},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {47},
number = {7},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.2428},
doi = {10.1002/spe.2428},
abstract = {Plugin-based systems are typically realized with resort to a component framework that offers an infrastructure for assembling plugin components, which can be composed to form system variants. Feature models have been proposed as an abstraction to manage software variability, where feature configurations describe variants of a software system. In this paper, we propose an automated approach to map the artifacts of plugin-based component frameworks to feature models. We describe a methodology for structuring the architecture of a plugin-based system, so that the variability space and variants are reflected in a feature model and its configurations. We materialized the proposed approach for the Eclipse Equinox component framework in a tool to visualize the variability of plugin-based systems in feature diagrams, which can be used to generate system variants. We carried out an experiment where we developed a small plugin-based product line on top of Equinox in the context of an advanced software development course. Copyright © 2016 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Pract. Exper.},
month = jul,
pages = {959–970},
numpages = {12},
keywords = {Equinox, components, feature models, plugin-based systems, variability management}
}

@inproceedings{10.1145/3238147.3238201,
author = {Mukelabai, Mukelabai and Ne\v{s}i\'{c}, Damir and Maro, Salome and Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp},
title = {Tackling combinatorial explosion: a study of industrial needs and practices for analyzing highly configurable systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238201},
doi = {10.1145/3238147.3238201},
abstract = {Highly configurable systems are complex pieces of software. To tackle this complexity, hundreds of dedicated analysis techniques have been conceived, many of which able to analyze system properties for all possible system configurations, as opposed to traditional, single-system analyses. Unfortunately, it is largely unknown whether these techniques are adopted in practice, whether they address actual needs, or what strategies practitioners actually apply to analyze highly configurable systems. We present a study of analysis practices and needs in industry. It relied on a survey with 27 practitioners engineering highly configurable systems and follow-up interviews with 15 of them, covering 18 different companies from eight countries. We confirm that typical properties considered in the literature (e.g., reliability) are relevant, that consistency between variability models and artifacts is critical, but that the majority of analyses for specifications of configuration options (a.k.a., variability model analysis) is not perceived as needed. We identified rather pragmatic analysis strategies, including practices to avoid the need for analysis. For instance, testing with experience-based sampling is the most commonly applied strategy, while systematic sampling is rarely applicable. We discuss analyses that are missing and synthesize our insights into suggestions for future research.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {155–166},
numpages = {12},
keywords = {Analysis, Highly Configurable Systems, Product Lines},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.4018/ijkss.2014100104,
author = {Ripon, Shamim H and Hossain, Sk. Jahir and Piash, Moshiur Mahamud},
title = {Logic-Based Analysis and Verification of Software Product Line Variant Requirement Model},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100104},
doi = {10.4018/ijkss.2014100104},
abstract = {Software Product Line SPL provides the facility to systematically reuse of software improving the efficiency of software development regarding time, cost and quality. The main idea of SPL is to identify the common core functionality that can be implemented once and reused afterwards. A variant model has also to be developed to manage the variants of the SPL. Usually, a domain model consisting of the common and variant requirements is developed during domain engineering phase to alleviate the reuse opportunity. The authors present a product line model comprising of a variant part for the management of variant and a decision table to depict the customization of decision regarding each variant. Feature diagrams are widely used to model SPL variants. Both feature diagram and our variant model, which is based on tabular method, lacks logically sound formal representation and hence, not amenable to formal verification. Formal representation and verification of SPL has gained much interest in recent years. This chapter presents a logical representation of the variant model by using first order logic. With this representation, the table based variant model as well as the graphical feature diagram can now be verified logically. Besides applying first-order-logic to model the features, the authors also present an approach to model and analyze SPL model by using semantic web approach using OWL-DL. The OWL-DL representation also facilitates the search and maintenance of feature models and support knowledge sharing within a reusable engineering context. Reasoning tools are used to verify the consistency of the feature configuration for both logic-based and semantic web-based approaches.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {52–76},
numpages = {25},
keywords = {Domain Model, Feature Diagrams, OWL-DL, Software Product Line SPL, Web-Based Approaches}
}

@inproceedings{10.1145/2791060.2791063,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {SPLTea 2015: Second International Workshop on Software Product Line Teaching},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791063},
doi = {10.1145/2791060.2791063},
abstract = {Education has a key role to play for disseminating the constantly growing body of Software Product Line (SPL) knowledge. Teaching SPLs is challenging; it is unclear, for example, how SPLs can be taught and what is the material available. This workshop aims to explore and explain the current status and ongoing work on teaching SPLs at universities, colleges, and in industry (e.g., by consultants). This second edition will continue the effort made at SPLTea'14. In particular we seek to design and populate an open repository of resources dedicated to SPL teaching.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {396},
numpages = {1},
keywords = {software engineering teaching, software product lines},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3382025.3414975,
author = {Becker, Martin and Sch\"{a}fer, Andreas},
title = {Variability realization in UML/SysML models},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414975},
doi = {10.1145/3382025.3414975},
abstract = {Motivated by experiences from different industrial settings, the tutorial reveals the increasing need for guidance and decision support on how to handle variants and variability in SysML and UML models. While a substantial amount of variability realization approaches has already been discussed on the level of source code, there is little guidance for practitioners on the model level. With this, there is major uncertainty in dealing with concurrent changes and parallel modeling of similar system variants.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {39},
numpages = {1},
keywords = {SysML, UML, decision support, model-based systems engineering, system and software product line engineering, variability mechanism, variability realization, variant management},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {Software performance prediction, adversarial learning, configurable systems, regularization},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1145/3395035.3425964,
author = {Kubasova, Uliyana and Murray, Gabriel},
title = {Group Performance Prediction with Limited Context},
year = {2021},
isbn = {9781450380027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395035.3425964},
doi = {10.1145/3395035.3425964},
abstract = {Automated prediction of group task performance normally proceeds by extracting linguistic, acoustic, or multimodal features from an entire conversation in order to predict an objective task measure. In this work, we investigate whether we can maintain robust prediction performance when using only limited context from the beginning of the meeting. Graph-based conversation features as well as more traditional linguistic features are extracted from the first minute of the meeting and from the entire meeting. We find that models trained only on the first minute are competitive with models trained on the full conversation. In particular, deriving features from graph-based models of conversational interaction in the first minute of discussion is particularly effective for predicting group performance, and outperforms models using more traditional linguistic features. This work also uses a much larger amount of data than previous work, by combining three similar survival task datasets.},
booktitle = {Companion Publication of the 2020 International Conference on Multimodal Interaction},
pages = {191–195},
numpages = {5},
keywords = {graph models, group interaction, meetings, multimodal interaction, social network analysis, social signal processing, task performance},
location = {Virtual Event, Netherlands},
series = {ICMI '20 Companion}
}

@inproceedings{10.1007/978-3-030-14799-0_31,
author = {Nguyen, Ngoc Thang and Phan, Van Thanh and Malara, Zbigniew},
title = {Using Fourier Series to Improve the Prediction Accuracy of Nonlinear Grey Bernoulli Model},
year = {2019},
isbn = {978-3-030-14798-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-14799-0_31},
doi = {10.1007/978-3-030-14799-0_31},
abstract = {In recent decades, the Nonlinear Grey Bernoulli model “NGBM (1, 1)” has been applied in various fields and achieved positive results. However, its prediction results may be inaccurate in different scenario. In order to expand the field of application and to improve the predict quality of NGBM (1, 1) model, this paper proposes an effective model (named as Fourier-NGBM (1, 1)). This model includes two main stages; first, we get the error values based on the actual data and predicted value of NGBM (1, 1). Then, we used Fourier series to filter out and to select the low- frequency their error values. To test the superior ability of the proposed model, the historical data of annual water consumption in Wuhan from 2005 to 2012 in He et al.’ paper is used. Forecasted results proved that the performance of Fourier-NGBM (1, 1) model is better than three forecasting models which are GM (1, 1), NGBM (1, 1) and improved Grey-Regression model. In subsequent research, more methodologies can be used to reduce the residual error of NGBM (1, 1) model, such as Markov chain or different kinds of Fourier functions. Additionally, the proposed model can be applied in different industries with the fluctuation data and uncertain information.},
booktitle = {Intelligent Information and Database Systems: 11th Asian Conference, ACIIDS 2019, Yogyakarta, Indonesia, April 8–11, 2019, Proceedings, Part I},
pages = {363–372},
numpages = {10},
keywords = {Fourier series, Nonlinear grey Bernoulli model, Modeling, Prediction accuracy},
location = {Yogyakarta, Indonesia}
}

@article{10.1007/s10489-020-02039-x,
author = {Xue, Xia and Gao, Yi and Liu, Meng and Sun, Xia and Zhang, Wenyu and Feng, Jun},
title = {GRU-based capsule network with an improved loss for personnel performance prediction},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {7},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02039-x},
doi = {10.1007/s10489-020-02039-x},
abstract = {Personnel performance is a key factor to maintain core competitive advantages. Thus, predicting personnel future performance is a significant research domain in human resource management (HRM). In this paper, to improve the performance, we propose a novel method for personnel performance prediction which helps decision-makers select high-potential talents. Specifically, for modeling the personnel performance, we first devise a GRU model to learn sequential information from personnel performance data without any expertise. Then, to better cluster the features, we exploit capsule network. Finally, to precisely make predictions, we further design one strategy, i.e., an improved loss function, and embed it into the capsule network. In addition, by introducing this strategy, our proposed model can well deal with the imbalanced data problem. Extensive experiments on real-world data clearly demonstrate the effectiveness of the proposed approach.},
journal = {Applied Intelligence},
month = jul,
pages = {4730–4743},
numpages = {14},
keywords = {Personnel performance prediction, Capsule network, Improved loss function, Gated recurrent unit}
}

@inproceedings{10.1145/2701319.2701330,
author = {Rabiser, Rick and Vierhauser, Michael and Gr\"{u}nbacher, Paul},
title = {Variability Management for a Runtime Monitoring Infrastructure},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701330},
doi = {10.1145/2701319.2701330},
abstract = {Many software systems today are systems of systems (SoS), which are difficult to analyze due to their size, complexity, heterogeneity, and variability. For instance, unexpected behavior of SoS is often caused by the complex interactions between the involved systems and their environment at runtime. Monitoring infrastructures (MIs) provide support for engineers and support staff analyzing the behavior of SoS during development and operation. Variability plays an important role in MIs, however, while some approaches exist, managing variability of MIs remains challenging. In this paper, we describe how we applied a variability management approach to support the reconfiguration of a SoS monitoring infrastructure (MI) at runtime. Our approach provides configuration support for setting up the MI to reflect system variability. It also supports runtime reconfiguration of the MI to reflect the different monitoring tasks of users and to support evolution. We motivate our work using the case of monitoring a real-world SoS from the domain of industrial automation and discuss variability-related challenges in four monitoring scenarios. We evaluate the feasibility of our approach by applying it to these scenarios. We also demonstrate that our approach reduces manual reconfiguration effort and helps to reduce the overhead of the MI.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {35–42},
numpages = {8},
keywords = {Software monitoring, large-scale systems, reconfiguration, variability management},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@inproceedings{10.1145/3461001.3471148,
author = {Krieter, Sebastian and Arens, Rahel and Nieke, Michael and Sundermann, Chico and He\ss{}, Tobias and Th\"{u}m, Thomas and Seidl, Christoph},
title = {Incremental construction of modal implication graphs for evolving feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471148},
doi = {10.1145/3461001.3471148},
abstract = {A feature model represents a set of variants as configurable features and dependencies between them. During variant configuration, (de)selection of a feature may entail that other features must or cannot be selected. A Modal Implication Graph (MIG) enables efficient decision propagation to perform automatic (de)selection of subsequent features. In addition, it facilitates other configuration-related activities such as t-wise sampling. Evolution of a feature model may change its configuration logic, thereby invalidating an existing MIG and forcing a full recomputation. However, repeated recomputation of a MIG is expensive, and thus hampers the overall usefulness of MIGs for frequently evolving feature models. In this paper, we devise a method to incrementally compute updated MIGs after feature model evolution. We identify expensive steps in the MIG construction algorithm, enable them for incremental computation, and measure performance compared to a full rebuild of a complete MIG within the evolution histories of four real-world feature models. Results show that our incremental method can increase the speed of MIG construction by orders of magnitude, depending on the given scenario and extent of evolutionary changes.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {64–74},
numpages = {11},
keywords = {configurable system, evolution, software product line},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-030-95391-1_16,
author = {Yuan, Tianyi and Ou, Dongyang and Wang, Jiwei and Jiang, Congfeng and C\'{e}rin, Christophe and Yan, Longchuan},
title = {PPCTS: Performance Prediction-Based Co-located Task Scheduling in Clouds},
year = {2021},
isbn = {978-3-030-95390-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-95391-1_16},
doi = {10.1007/978-3-030-95391-1_16},
abstract = {With increasing market competition among commercial cloud computing infrastructures, major cloud service providers are building co-located data centers to deploy online services and offline jobs in the same cluster to improve resource utilization. However, at present, related researches on the characteristics of co-location are still immature. Therefore, stable solutions for resource collaborative scheduling are still essentially absent, which restricts the further optimization of co-location technology. In this paper, we present performance prediction-based co-located task scheduling (PPCTS) model to perform fine-grained resource allocation under Quality of Service (QoS) constraints. PPCTS improves the overall cluster CPU resource utilization to 56.211%, which is competitive to the current related works. Besides, this paper fully implements a co-located system prototype. Compared with the traditional simulator-based scheduling research work, the prototype proposed in this paper is easier to be migrated to the real production environment.},
booktitle = {Algorithms and Architectures for Parallel Processing: 21st International Conference, ICA3PP 2021, Virtual Event, December 3–5, 2021, Proceedings, Part III},
pages = {245–257},
numpages = {13},
keywords = {Data center, Co-located deployment, Container scheduling, Quality of Service}
}

@article{10.1186/s13673-018-0163-4,
author = {Gautam, Bhaskar and Basava, Annappa},
title = {Performance prediction of data streams on high-performance architecture},
year = {2019},
issue_date = {Dec 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {9},
number = {1},
issn = {2192-1962},
url = {https://doi.org/10.1186/s13673-018-0163-4},
doi = {10.1186/s13673-018-0163-4},
abstract = {Worldwide sensor streams are expanding continuously with unbounded velocity in volume, and for this acceleration, there is an adaptation of large stream data processing system from the homogeneous to rack-scale architecture which makes serious concern in the domain of workload optimization, scheduling, and resource management algorithms. Our proposed framework is based on providing architecture independent performance prediction model to enable resource adaptive distributed stream data processing platform. It is comprised of seven pre-defined domain for dynamic data stream metrics including a self-driven model which tries to fit these metrics using ridge regularization regression algorithm. Another significant contribution lies in fully-automated performance prediction model inherited from the state-of-the-art distributed data management system for distributed stream processing systems using Gaussian processes regression that cluster metrics with the help of dimensionality reduction algorithm. We implemented its base on Apache Heron and evaluated with proposed Benchmark Suite comprising of five domain-specific topologies. To assess the proposed methodologies, we forcefully ingest tuple skewness among the benchmarking topologies to set up the ground truth for predictions and found that accuracy of predicting the performance of data streams increased up to 80.62% from 66.36% along with the reduction of error from 37.14 to 16.06%.},
journal = {Hum.-Centric Comput. Inf. Sci.},
month = dec,
articleno = {163},
numpages = {23},
keywords = {Apache Heron, Clustering, Data streams, High performance computing, Performance behavior, Performance prediction, Regression, Stream benchmark suite}
}

@inproceedings{10.1145/3387902.3392625,
author = {Zacarias, Felippe Vieira and Nishtala, Rajiv and Carpenter, Paul},
title = {Contention-aware application performance prediction for disaggregated memory systems},
year = {2020},
isbn = {9781450379564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387902.3392625},
doi = {10.1145/3387902.3392625},
abstract = {Disaggregated memory has recently been proposed as a way to allow flexible and fine-grained allocation of memory capacity to compute jobs. This paper makes an important step towards effective resource allocation on disaggregated memory systems. Specifically, we propose a generic approach to predict the performance degradation due to sharing of disaggregated memory. In contrast to prior work, cache capacity is not shared among multiple applications, which removes a major contributor to application performance. For this reason, our analysis is driven by the demand for memory bandwidth, which has been shown to have an important effect on application performance. We show that profiling the application slowdown often involves significant experimental error and noise, and to this end, we improve the accuracy by linear smoothing of the sensitivity curves. We also show that contention is sensitive to the ratio between read and write memory accesses, and we address this sensitivity by building a family of sensitivity curves according to the read/write ratios.Our results show that the methodology predicts the slowdown in application performance subject to memory contention with an average error of 1.19% and max error of 14.6%. Compared with state-of-the-art, the relative improvements are almost 24% on average and 33% for the worst case.},
booktitle = {Proceedings of the 17th ACM International Conference on Computing Frontiers},
pages = {49–59},
numpages = {11},
keywords = {memory bandwidth, memory subsystem, performance counters, performance degradation, performance prediction},
location = {Catania, Sicily, Italy},
series = {CF '20}
}

@inproceedings{10.1145/3457388.3458666,
author = {Bouzidi, Halima and Ouarnoughi, Hamza and Niar, Smail and Cadi, Abdessamad Ait El},
title = {Performance prediction for convolutional neural networks on edge GPUs},
year = {2021},
isbn = {9781450384049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457388.3458666},
doi = {10.1145/3457388.3458666},
abstract = {Edge computing is increasingly used for Artificial Intelligence (AI) purposes to meet latency, privacy, and energy challenges. Convolutional Neural networks (CNN) are more frequently deployed on Edge devices for several applications. However, due to their constrained computing resources and energy budget, Edge devices struggle to meet CNN's latency requirements while maintaining good accuracy. It is, therefore, crucial to choose the CNN with the best accuracy and latency trade-off while respecting hardware constraints. This paper presents and compares five of the widely used Machine Learning (ML) based approaches to predict CNN's inference execution time on Edge GPUs. For these 5 methods, in addition to their prediction accuracy, we also explore the time needed for their training and their hyperparameters' tuning. Finally, we compare times to run the prediction models on different platforms. The use of these methods will highly facilitate design space exploration by quickly providing the best CNN on a target Edge GPU. Experimental results show that XGBoost provides an interesting average prediction error even for unexplored and unseen CNN architectures. Random Forest depicts comparable accuracy but needs more effort and time to be trained. The other 3 approaches (OLS, MLP, and SVR) are less accurate for CNN performance estimation.},
booktitle = {Proceedings of the 18th ACM International Conference on Computing Frontiers},
pages = {54–62},
numpages = {9},
keywords = {CNN, XGBoost, edge GPU, multi-layer perceptrons, multiple linear regression, performance modeling, random forest, support vector machine},
location = {Virtual Event, Italy},
series = {CF '21}
}

@article{10.1155/2021/5578871,
author = {Yang, Sitong and Luo, Lina and Tan, Baohua and Kung, Hsu-Yang},
title = {Research on Sports Performance Prediction Based on BP Neural Network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/5578871},
doi = {10.1155/2021/5578871},
abstract = {Artificial neural network has the advantages of self-training and fault tolerance, while BP neural network has simple learning algorithms and powerful learning capabilities. The BP neural network algorithm has been widely used in practice. This paper conducts research on sports performance prediction based on 5G and artificial neural network algorithms. This paper uses the BP neural network algorithm as a pretest modelling method to predict the results of the 30th Olympic Men’s 100m Track and Field Championships and is supported by the MATLAB neural network toolbox. According to the experimental results, the scheme proposed in this paper has better performance than the other prediction strategies. In order to explore the feasibility and application of the BP neural network in this kind of prediction, there is a lot of work to be done. The model has a high prediction accuracy and provides a new method for the prediction of sports performance. The results show that the BP neural network algorithm can be used to predict sports performance, with high prediction accuracy and strong generalization ability.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {8}
}

@article{10.1007/s11704-019-9062-8,
author = {Ma, Yuling and Cui, Chaoran and Yu, Jun and Guo, Jie and Yang, Gongping and Yin, Yilong},
title = {Multi-task MIML learning for pre-course student performance prediction},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-019-9062-8},
doi = {10.1007/s11704-019-9062-8},
abstract = {In higher education, the initial studying period of each course plays a crucial role for students, and seriously influences the subsequent learning activities. However, given the large size of a course’s students at universities, it has become impossible for teachers to keep track of the performance of individual students. In this circumstance, an academic early warning system is desirable, which automatically detects students with difficulties in learning (i.e., at-risk students) prior to a course starting. However, previous studies are not well suited to this purpose for two reasons: 1) they have mainly concentrated on e-learning platforms, e.g., massive open online courses (MOOCs), and relied on the data about students’ online activities, which is hardly accessed in traditional teaching scenarios; and 2) they have only made performance prediction when a course is in progress or even close to the end. In this paper, for traditional classroom-teaching scenarios, we investigate the task of pre-course student performance prediction, which refers to detecting at-risk students for each course before its commencement. To better represent a student sample and utilize the correlations among courses, we cast the problem as a multi-instance multi-label (MIML) problem. Besides, given the problem of data scarcity, we propose a novel multi-task learning method, i.e., MIML-Circle, to predict the performance of students from different specialties in a unified framework. Extensive experiments are conducted on five real-world datasets, and the results demonstrate the superiority of our approach over the state-of-the-art methods.},
journal = {Front. Comput. Sci.},
month = oct,
numpages = {10},
keywords = {educational data mining, academic early warning system, student performance prediction, multi-instance multi-label learning, multi-task learning}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {machine learning, quality assurance, software product line, software testing, software variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461001.3461660,
author = {Michelon, Gabriela Karoline and Obermann, David and Assun\c{c}\~{a}o, Wesley K. G. and Linsbauer, Lukas and Gr\"{u}nbacher, Paul and Egyed, Alexander},
title = {Managing systems evolving in space and time: four challenges for maintenance, evolution and composition of variants},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3461660},
doi = {10.1145/3461001.3461660},
abstract = {Software companies need to provide a large set of features satisfying functional and non-functional requirements of diverse customers, thereby leading to variability in space. Feature location techniques have been proposed to support software maintenance and evolution in space. However, so far only one feature location technique also analyses the evolution in time of system variants, which is required for feature enhancements and bug fixing. Specifically, existing tools for managing a set of systems over time do not offer proper support for keeping track of feature revisions, updating existing variants, and creating new product configurations based on feature revisions. This paper presents four challenges concerning such capabilities for feature (revision) location and composition of new product configurations based on feature/s (revisions). We also provide a benchmark containing a ground truth and support for computing metrics. We hope that this will motivate researchers to provide and evaluate tool-supported approaches aiming at managing systems evolving in space and time. Further, we do not limit the evaluation of techniques to only this benchmark: we introduce and provide instructions on how to use a benchmark extractor for generating ground truth data for other systems. We expect that the feature (revision) location techniques maximize information retrieval in terms of precision, recall, and F-score, while keeping execution time and memory consumption low.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {75–80},
numpages = {6},
keywords = {benchmark extractor, feature location, feature revision, repository mining, software product line},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1016/j.jss.2016.09.045,
author = {Parejo, Jos\'{e} A. and S\'{a}nchez, Ana B. and Segura, Sergio and Ruiz-Cort\'{e}s, Antonio and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
title = {Multi-objective test case prioritization in highly configurable systems},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.09.045},
doi = {10.1016/j.jss.2016.09.045},
abstract = {A multi-objective test case prioritization real-world case study is presented.Seven objective functions based on functional and non-functional data are proposed.Comparison of the effectiveness of 63 combinations of up to three objectives.NSGA-II evolutionary algorithm to solve the multi-objective prioritization problem.Multi-objective prioritization is more effective than mono-objective approaches. Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non-functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization.},
journal = {J. Syst. Softw.},
month = dec,
pages = {287–310},
numpages = {24},
keywords = {Automated software testing, Highly-configurable systems, Test case prioritization, Variability}
}

@inproceedings{10.1145/3322798.3329254,
author = {Jin, Mengtian and Homma, Youkow and Sim, Alex and Kroeger, Wilko and Wu, Kesheng},
title = {Performance Prediction for Data Transfers in LCLS Workflow},
year = {2019},
isbn = {9781450367615},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322798.3329254},
doi = {10.1145/3322798.3329254},
abstract = {In this work, we study the use of decision tree-based models to predict the transfer rates in different parts of the data pipeline that sends experiment data from Linac Coherent Light Source (LCLS) at SLAC National Accelerator Laboratory (SLAC) to National Energy Research Scientific Computing Center (NERSC). The system monitoring the data pipeline collects a number of characteristics such as the file size, source file system, start time and so on, all of which are known at the start of the file transfer. However, these static variables do not capture the dynamic information such as current state of the networking system. In this work, we explore a number of different ways to capture the state of the network and other dynamic information. We find that in addition to using static features, using these dynamic features can improve the transfer performance predictions by up to 10-15%. We additionally study a couple of different well-known decision-tree based models and find that Gradient-Tree Boosting algorithm performs better overall.},
booktitle = {Proceedings of the ACM Workshop on Systems and Network Telemetry and Analytics},
pages = {37–44},
numpages = {8},
keywords = {LCLS, network performance, performance prediction},
location = {Phoenix, AZ, USA},
series = {SNTA '19}
}

@article{10.1016/j.eswa.2019.01.086,
author = {Chang, Xiaohui and Li, Jiexun},
title = {Business performance prediction in location-based social commerce},
year = {2019},
issue_date = {Jul 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {126},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.01.086},
doi = {10.1016/j.eswa.2019.01.086},
journal = {Expert Syst. Appl.},
month = jul,
pages = {112–123},
numpages = {12},
keywords = {Social commerce, Location-based services, Site selection, Business performance prediction}
}

@inproceedings{10.1145/3391812.3396272,
author = {Nakashima, Makiya and Sim, Alex and Kim, Jinoh},
title = {Evaluation of Deep Learning Models for Network Performance Prediction for Scientific Facilities},
year = {2020},
isbn = {9781450379809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3391812.3396272},
doi = {10.1145/3391812.3396272},
abstract = {Large data transfers are getting more critical with the increasing volume of data in scientific computing. While scientific facilities manage dedicated infrastructures to support large data transfers, predicting network performance based on the historical measurement would be essential for workflow scheduling and resource allocation in the facility. In this study, we empirically evaluate deep learning (DL) models with respect to the prediction accuracy of network performance for scientific facilities, using a two-month network communication log. This paper compares a set of DL models based on Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Gated Recurrent Unit (GRU), and Long Short-Term Memory (LSTM), to predict average throughput as a means to estimate network performance, and shares the observations made from the extensive experiments with the results of prediction accuracy and timing complexity.},
booktitle = {Proceedings of the 3rd International Workshop on Systems and Network Telemetry and Analytics},
pages = {53–56},
numpages = {4},
keywords = {deep learning, network performance prediction, regression, scientific computing},
location = {Stockholm, Sweden},
series = {SNTA '20}
}

@inproceedings{10.1145/3461002.3473070,
author = {Acher, Mathieu and Perrouin, Gilles and Cordy, Maxime},
title = {BURST: a benchmarking platform for uniform random sampling techniques},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473070},
doi = {10.1145/3461002.3473070},
abstract = {We present BURST, a benchmarking platform for uniform random sampling techniques. With BURST, researchers have a flexible, controlled environment in which they can evaluate the scalability and uniformity of their sampling. BURST comes with an extensive --- and extensible --- benchmark dataset comprising 128 feature models, including challenging, real-world models of the Linux kernel. BURST takes as inputs a sampling tool, a set of feature models and a sampling budget. It automatically translates any feature model of the set in DIMACS and invokes the sampling tool to generate the budgeted number of samples. To evaluate the scalability of the sampling tool, BURST measures the time the tool needs to produce the requested sample. To evaluate the uniformity of the produced sample, BURST integrates the state-of-the-art and proven statistical test Barbarik. We envision BURST to become the starting point of a standardisation initiative of sampling tool evaluation. Given the huge interest of research for sampling algorithms and tools, this initiative would have the potential to reach and crosscut multiple research communities including AI, ML, SAT and SPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {36–40},
numpages = {5},
keywords = {SAT, benchmark, configurable systems, sampling, software product lines, variability model},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3387514.3405868,
author = {Manousis, Antonis and Sharma, Rahul Anand and Sekar, Vyas and Sherry, Justine},
title = {Contention-Aware Performance Prediction For Virtualized Network Functions},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405868},
doi = {10.1145/3387514.3405868},
abstract = {At the core of Network Functions Virtualization lie Network Functions (NFs) that run co-resident on the same server, contend over its hardware resources and, thus, might suffer from reduced performance relative to running alone on the same hardware. Therefore, to efficiently manage resources and meet performance SLAs, NFV orchestrators need mechanisms to predict contention-induced performance degradation. In this work, we find that prior performance prediction frameworks suffer from poor accuracy on modern architectures and NFs because they treat memory as a monolithic whole. In addition, we show that, in practice, there exist multiple components of the memory subsystem that can separately induce contention. By precisely characterizing (1) the pressure each NF applies on the server's shared hardware resources (contentiousness) and (2) how susceptible each NF is to performance drop due to competing contentiousness (sensitivity), we develop SLOMO, a multivariable performance prediction framework for Network Functions. We show that relative to prior work SLOMO reduces prediction error by 2-5x and enables 6-14% more efficient cluster utilization. SLOMO's codebase can be found at https://github.com/cmu-snap/SLOMO.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {270–282},
numpages = {13},
keywords = {Network Functions Performance, Packet Processing Software},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1007/978-3-642-34059-8_10,
author = {Haber, Arne and Rendel, Holger and Rumpe, Bernhard and Schaefer, Ina},
title = {Evolving delta-oriented software product line architectures},
year = {2012},
isbn = {9783642340581},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34059-8_10},
doi = {10.1007/978-3-642-34059-8_10},
abstract = {Diversity is prevalent in modern software systems. Several system variants exist at the same time in order to adapt to changing user requirements. Additionally, software systems evolve over time in order to adjust to unanticipated changes in their application environment. In modern software development, software architecture modeling is an important means to deal with system complexity by architectural decomposition. This leads to the need of architectural description languages that can represent spatial and temporal variability. In this paper, we present delta modeling of software architectures as a uniform modeling formalism for architectural variability in space and in time. In order to avoid degeneration of the product line model under system evolution, we present refactoring techniques to maintain and improve the quality of the variability model. Using a running example from the automotive domain, we evaluate our approach by carrying out a case study that compares delta modeling with annotative variability modeling.},
booktitle = {Proceedings of the 17th Monterey Conference on Large-Scale Complex IT Systems: Development, Operation and Management},
pages = {183–208},
numpages = {26},
location = {Oxford, UK}
}

@inproceedings{10.1145/3341105.3373904,
author = {D\'{e}jean, S\'{e}bastien and Ionescu, Radu Tudor and Mothe, Josiane and Ullah, Md Zia},
title = {Forward and backward feature selection for query performance prediction},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373904},
doi = {10.1145/3341105.3373904},
abstract = {The goal of query performance prediction (QPP) is to automatically estimate the effectiveness of a search result for any given query, without relevance judgements. Post-retrieval features have been shown to be more effective for this task while being more expensive to compute than pre-retrieval features. Combining multiple post-retrieval features is even more effective, but state-of-the-art QPP methods are impossible to interpret because of the black-box nature of the employed machine learning models. However, interpretation is useful for understanding the predictive model and providing more answers about its behavior. Moreover, combining many post-retrieval features is not applicable to real-world cases, since the query running time is of utter importance. In this paper, we investigate a new framework for feature selection in which the trained model explains well the prediction. We introduce a step-wise (forward and backward) model selection approach where different subsets of query features are used to fit different models from which the system selects the best one. We evaluate our approach on four TREC collections using standard QPP features. We also develop two QPP features to address the issue of query-drift in the query feedback setting. We found that: (1) our model based on a limited number of selected features is as good as more complex models for QPP and better than non-selective models; (2) our model is more efficient than complex models during inference time since it requires fewer features; (3) the predictive model is readable and understandable; and (4) one of our new QPP features is consistently selected across different collections, proving its usefulness.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {690–697},
numpages = {8},
keywords = {AIC criterion, QPP, feature selection, information retrieval, linear regression, predictive model, query performance prediction, selective model},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3369583.3392678,
author = {Kim, Sunggon and Sim, Alex and Wu, Kesheng and Byna, Suren and Son, Yongseok and Eom, Hyeonsang},
title = {Towards HPC I/O Performance Prediction through Large-scale Log Analysis},
year = {2020},
isbn = {9781450370523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369583.3392678},
doi = {10.1145/3369583.3392678},
abstract = {Large-scale high performance computing (HPC) systems typically consist of many thousands of CPUs and storage units, while used by hundreds to thousands of users at the same time. Applications from these large numbers of users have diverse characteristics, such as varying compute, communication, memory, and I/O intensiveness. A good understanding of the performance characteristics of each user application is important for job scheduling and resource provisioning. Among these performance characteristics, the I/O performance is difficult to predict because the I/O system software is complex, the I/O system is shared among all users, and the I/O operations also heavily rely on networking systems. To improve the prediction of the I/O performance on HPC systems, we propose to integrate information from a number of different system logs and develop a regression-based approach that dynamically selects the most relevant features from the most recent log entries, and automatically select the best regression algorithm for the prediction task. Evaluation results show that our proposed scheme can predict the I/O performance with up to 84% prediction accuracy in the case of the I/O-intensive applications using the logs from CORI supercomputer at NERSC.},
booktitle = {Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {77–88},
numpages = {12},
keywords = {I/O performance prediction, distributed file system, high performance computing, log analysis},
location = {Stockholm, Sweden},
series = {HPDC '20}
}

@inproceedings{10.1145/3233027.3236402,
author = {Martinez, Jabier and Ordo\~{n}ez, Nicolas and T\"{e}rnava, Xhevahire and Ziadi, Tewfik and Aponte, Jairo and Figueiredo, Eduardo and Valente, Marco Tulio},
title = {Feature location benchmark with argoUML SPL},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236402},
doi = {10.1145/3233027.3236402},
abstract = {Feature location is a traceability recovery activity to identify the implementation elements associated to a characteristic of a system. Besides its relevance for software maintenance of a single system, feature location in a collection of systems received a lot of attention as a first step to re-engineer system variants (created through clone-and-own) into a Software Product Line (SPL). In this context, the objective is to unambiguously identify the boundaries of a feature inside a family of systems to later create reusable assets from these implementation elements. Among all the case studies in the SPL literature, variants derived from ArgoUML SPL stands out as the most used one. However, the use of different settings, or the omission of relevant information (e.g., the exact configurations of the variants or the way the metrics are calculated), makes it difficult to reproduce or benchmark the different feature location techniques even if the same ArgoUML SPL is used. With the objective to foster the research area on feature location, we provide a set of common scenarios using ArgoUML SPL and a set of utils to obtain metrics based on the results of existing and novel feature location techniques.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {257–263},
numpages = {7},
keywords = {argoUML, benchmark, extractive software product line adoption, feature location, reverse-engineering, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.5555/1753235.1753272,
author = {Dordowsky, Frank and Hipp, Walter},
title = {Adopting software product line principles to manage software variants in a complex avionics system},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Eurocopter is the majority partner in NH Industries, the international consortium that develops and produces the medium weight multi-role helicopter NH90. AgustaWestland and Stork Fokker are additional partners. The NH90 has been successfully sold to 14 nations and their armed forces. The software division at Eurocopter Germany develops the on-board software for three computers of the NH90 avionics CORE and MISSION Systems. The growing number of customers and their specific application domains for the NH90 has led to an increasing number of functionally different helicopter variants. Moreover, during the long development time that is typical for complex military avionics projects, the computing technology has changed considerably over time so that the current operational software has to fit to several processor architectures. In order to cope with the high number of software variants and technology variations, the NH90 software team developed concepts and strategies for SW architecture and tool modifications based on Software Product Line (SPL) principles.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {265–274},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3340531.3412733,
author = {Li, Haotian and Wei, Huan and Wang, Yong and Song, Yangqiu and Qu, Huamin},
title = {Peer-inspired Student Performance Prediction in Interactive Online Question Pools with Graph Neural Network},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412733},
doi = {10.1145/3340531.3412733},
abstract = {Student performance prediction is critical to online education. It can benefit many downstream tasks on online learning platforms, such as estimating dropout rates, facilitating strategic intervention, and enabling adaptive online learning. Interactive online question pools provide students with interesting interactive questions to practice their knowledge in online education. However, little research has been done on student performance prediction in interactive online question pools. Existing work on student performance prediction targets at online learning platforms with predefined course curriculum and accurate knowledge labels like MOOC platforms, but they are not able to fully model knowledge evolution of students in interactive online question pools. In this paper, we propose a novel approach using Graph Neural Networks (GNNs) to achieve better student performance prediction in interactive online question pools. Specifically, we model the relationship between students and questions using student interactions to construct the student-interaction-question network and further present a new GNN model, called R2GCN, which intrinsically works for the heterogeneous networks, to achieve generalizable student performance prediction in interactive online question pools. We evaluate the effectiveness of our approach on a real-world dataset consisting of 104,113 mouse trajectories generated in the problem-solving process of over 4,000 students on 1,631 questions. The experiment results show that our approach can achieve a much higher accuracy of student performance prediction than both traditional machine learning approaches and GNN models.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {2589–2596},
numpages = {8},
keywords = {graph neural networks, online question pools, student performance prediction},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@inproceedings{10.1145/3461001.3471146,
author = {Horcas, Jose-Miguel and Galindo, Jos\'{e} A. and Heradio, Ruben and Fernandez-Amoros, David and Benavides, David},
title = {Monte Carlo tree search for feature model analyses: a general framework for decision-making},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471146},
doi = {10.1145/3461001.3471146},
abstract = {The colossal solution spaces of most configurable systems make intractable their exhaustive exploration. Accordingly, relevant analyses remain open research problems. There exist analyses alternatives such as SAT solving or constraint programming. However, none of them have explored simulation-based methods. Monte Carlo-based decision making is a simulation-based method for dealing with colossal solution spaces using randomness. This paper proposes a conceptual framework that tackles various of those analyses using Monte Carlo methods, which have proven to succeed in vast search spaces (e.g., game theory). Our general framework is described formally, and its flexibility to cope with a diversity of analysis problems is discussed (e.g., finding defective configurations, feature model reverse engineering or getting optimal performance configurations). Additionally, we present a Python implementation of the framework that shows the feasibility of our proposal. With this contribution, we envision that different problems can be addressed using Monte Carlo simulations and that our framework can be used to advance the state of the art a step forward.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {190–201},
numpages = {12},
keywords = {configurable systems, feature models, monte carlo tree search, software product lines, variability modeling},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1016/j.jss.2013.12.038,
author = {Capilla, Rafael and Bosch, Jan and Trinidad, Pablo and Ruiz-Cort\'{e}s, Antonio and Hinchey, Mike},
title = {An overview of Dynamic Software Product Line architectures and techniques: Observations from research and industry},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.12.038},
doi = {10.1016/j.jss.2013.12.038},
abstract = {Over the last two decades, software product lines have been used successfully in industry for building families of systems of related products, maximizing reuse, and exploiting their variable and configurable options. In a changing world, modern software demands more and more adaptive features, many of them performed dynamically, and the requirements on the software architecture to support adaptation capabilities of systems are increasing in importance. Today, many embedded system families and application domains such as ecosystems, service-based applications, and self-adaptive systems demand runtime capabilities for flexible adaptation, reconfiguration, and post-deployment activities. However, as traditional software product line architectures fail to provide mechanisms for runtime adaptation and behavior of products, there is a shift toward designing more dynamic software architectures and building more adaptable software able to handle autonomous decision-making, according to varying conditions. Recent development approaches such as Dynamic Software Product Lines (DSPLs) attempt to face the challenges of the dynamic conditions of such systems but the state of these solution architectures is still immature. In order to provide a more comprehensive treatment of DSPL models and their solution architectures, in this research work we provide an overview of the state of the art and current techniques that, partially, attempt to face the many challenges of runtime variability mechanisms in the context of Dynamic Software Product Lines. We also provide an integrated view of the challenges and solutions that are necessary to support runtime variability mechanisms in DSPL models and software architectures.},
journal = {J. Syst. Softw.},
month = may,
pages = {3–23},
numpages = {21},
keywords = {Dynamic Software Product Lines, Dynamic variability, Feature models, Software architecture}
}

@inproceedings{10.1145/3341981.3344219,
author = {Roitman, Haggai and Erera, Shai and Feigenblat, Guy},
title = {A Study of Query Performance Prediction for Answer Quality Determination},
year = {2019},
isbn = {9781450368810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341981.3344219},
doi = {10.1145/3341981.3344219},
abstract = {We study a constrained retrieval setting in which either a single qualitative answer is provided as a response to a user-query or none. Given a user-query and the "best" answer that was retrieved from the underlying search engine, we wish to determine whether or not to accept it. To address this challenge, we propose an answer quality determination approach which leverages a novel set of answer-level query performance prediction (QPP) features, derived from a couple of recent discriminative QPP frameworks. Using various search benchmarks with both ad-hoc retrieval and non-factoid question answering (QA) tasks, we demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {43–46},
numpages = {4},
keywords = {answer quality determination, classification, query performance prediction},
location = {Santa Clara, CA, USA},
series = {ICTIR '19}
}

@inproceedings{10.1007/978-3-030-48340-1_22,
author = {L\"{u}ders, Matthias and Arndt, Oliver Jakob and Blume, Holger},
title = {Multicore Performance Prediction – Comparing Three Recent Approaches in a Case Study},
year = {2019},
isbn = {978-3-030-48339-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-48340-1_22},
doi = {10.1007/978-3-030-48340-1_22},
abstract = {Even though parallel programs, written in high-level languages, are portable across different architectures, their parallelism does not necessarily scale after migration. Predicting a multicore-application’s performance on the target platform in an early development phase can prevent developers from unpromising optimizations and thus significantly reduce development time. However, the vast diversity and heterogeneity of system-design decisions of processor types from HPC and desktop PCs to embedded MPSoCs complicate the modeling due to varying capabilities. Concurrency effects (caching, locks, or bandwidth bottlenecks) influence parallel runtime behavior as well. Complex performance prediction approaches emerged, which can be grouped into: virtual prototyping, analytical models, and statistical methods. In this work, we predict the performance of two algorithms from the field of advanced driver-assistance systems in a case study. With the following three methods, we provide a comparative overview of state-of-the-art predictions: GEM5 (virtual prototype), IBM Exabounds (analytical model), and an in-house developed statistical method. We first describe the theoretical background, describe the experimental- and model-setup, and give a detailed evaluation of the prediction. In addition, we discuss the applicability of all three methods for predicting parallel and heterogeneous systems.},
booktitle = {Euro-Par 2019: Parallel Processing Workshops: Euro-Par 2019 International Workshops, G\"{o}ttingen, Germany, August 26–30, 2019, Revised Selected Papers},
pages = {282–294},
numpages = {13},
keywords = {Performance prediction, Virtual prototyping, Parallelization, Advanced driver-assistance systems, Scalability, MPSoC},
location = {G\"{o}ttingen, Germany}
}

@inproceedings{10.1145/2786805.2786845,
author = {Siegmund, Norbert and Grebhahn, Alexander and Apel, Sven and K\"{a}stner, Christian},
title = {Performance-influence models for highly configurable systems},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786845},
doi = {10.1145/2786805.2786845},
abstract = {Almost every complex software system today is configurable. While configurability has many benefits, it challenges performance prediction, optimization, and debugging. Often, the influences of individual configuration options on performance are unknown. Worse, configuration options may interact, giving rise to a configuration space of possibly exponential size. Addressing this challenge, we propose an approach that derives a performance-influence model for a given configurable system, describing all relevant influences of configuration options and their interactions. Our approach combines machine-learning and sampling heuristics in a novel way. It improves over standard techniques in that it (1) represents influences of options and their interactions explicitly (which eases debugging), (2) smoothly integrates binary and numeric configuration options for the first time, (3) incorporates domain knowledge, if available (which eases learning and increases accuracy), (4) considers complex constraints among options, and (5) systematically reduces the solution space to a tractable size. A series of experiments demonstrates the feasibility of our approach in terms of the accuracy of the models learned as well as the accuracy of the performance predictions one can make with them.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {284–294},
numpages = {11},
keywords = {Performance-influence models, machine learning, sampling},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1109/ICSE43902.2021.00100,
author = {Velez, Miguel and Jamshidi, Pooyan and Siegmund, Norbert and Apel, Sven and K\"{a}stner, Christian},
title = {White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00100},
doi = {10.1109/ICSE43902.2021.00100},
abstract = {Performance-influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system. With this understanding, stakeholders can debug performance behavior and make deliberate configuration decisions. Current black-box techniques to build such models combine various sampling and learning strategies, resulting in tradeoffs between measurement effort, accuracy, and interpretability. We present Comprex, a white-box approach to build performance-influence models for configurable systems, combining insights of local measurements, dynamic taint analysis to track options in the implementation, compositionality, and compression of the configuration space, without relying on machine learning to extrapolate incomplete samples. Our evaluation on 4 widely-used, open-source projects demonstrates that Comprex builds similarly accurate performance-influence models to the most accurate and expensive black-box approach, but at a reduced cost and with additional benefits from interpretable and local models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1072–1084},
numpages = {13},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3461001.3471151,
author = {Mortara, Johann and Collet, Philippe},
title = {Capturing the diversity of analyses on the Linux kernel variability},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471151},
doi = {10.1145/3461001.3471151},
abstract = {As its variability management architecture is complex, the Linux kernel is a constant subject of study for analyzing different aspects of its variability. It relies on a configuration-aware build system, preprocessor directives in the code, and a configuration tool. While many studies have focused on detecting anomalies within these parts or between them, all concepts and denominations are different among contributions, with similar properties devised with varied formalisms, or with no easy relationship between them. This actually hampers the understanding of all variability issues and proposed analyses, as well as their application to other highly configurable systems. In this paper, we analyse the different properties that have been studied on the variability of the kernel and propose a formalism based on the generic concepts of configurator and derivator. We instantiate them to represent the Kconfig, the Kbuild, and CPP in a unified model that enables to represent all the consistency properties. With this model, we manage to categorize the main related studies, establishing their coverage on the defined properties, showing also overlapping and divergences between studies.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {160–171},
numpages = {12},
keywords = {Linux, build system, configuration, variability, variability anomalies},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-319-91452-7_19,
author = {Sasani, Keyvan and Namaki, Mohammad Hossein and Wu, Yinghui and Gebremedhin, Assefaw H.},
title = {Multi-metric Graph Query Performance Prediction},
year = {2018},
isbn = {978-3-319-91451-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-91452-7_19},
doi = {10.1007/978-3-319-91452-7_19},
abstract = {We propose a general framework for predicting graph query performance with respect to three performance metrics: execution time, query answer quality, and memory consumption. The learning framework generates and makes use of informative statistics from data and query structure and employs a multi-label regression model to predict the multi-metric query performance. We apply the framework to study two common graph query classes—reachability and graph pattern matching; the two classes differ significantly in their query complexity. For both query classes, we develop suitable performance models and learning algorithms to predict the performance. We demonstrate the efficacy of our framework via experiments on real-world information and social networks. Furthermore, by leveraging the framework, we propose a novel workload optimization algorithm and show that it improves the efficiency of workload management by 54% on average.},
booktitle = {Database Systems for Advanced Applications: 23rd International Conference, DASFAA 2018, Gold Coast, QLD, Australia, May 21-24, 2018, Proceedings, Part I},
pages = {289–306},
numpages = {18},
keywords = {Query Graph, Query Performance Prediction, Workload Optimization, Query Classes, Reachability Queries},
location = {Gold Coast, QLD, Australia}
}

@article{10.1007/s00521-019-04604-z,
author = {Xu, Lingwei and Wang, Jingjing and Wang, Han and Aaron Gulliver, T. and Le, Khoa N.},
title = {BP neural network-based ABEP performance prediction for mobile Internet of Things communication systems},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {20},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04604-z},
doi = {10.1007/s00521-019-04604-z},
abstract = {Wireless communications play an important role in the mobile Internet of Things (IoT). For practical mobile communication systems, N-Nakagami fading channels are a better characterization than N-Rayleigh and 2-Rayleigh fading channels. The average bit error probability (ABEP) is an important factor in the performance evaluation of mobile IoT systems. In this paper, cooperative communications is used to enhance the ABEP performance of mobile IoT systems using selection combining. To compute the ABEP, the signal-to-noise ratios (SNRs) of the direct link and end-to-end link are considered. The probability density function (PDF) of these SNRs is derived, and this is used to derive the cumulative distribution function, which is used to derive closed-form ABEP expressions. The theoretical results are confirmed by Monte-Carlo simulation. The impact of fading and other parameters on the ABEP performance is examined. These results can be used to evaluate the performance of complex environments such as mobile IoT and other communication systems. To support active complex event processing in mobile IoT, it is important to predict the ABEP performance. Thus, a back-propagation (BP) neural network-based ABEP performance prediction algorithm is proposed. We use the theoretical results to generate training data. We test the extreme learning machine (ELM), linear regression (LR), support vector machine (SVM), and BP neural network methods. Compared to LR, SVM, and ELM methods, the simulation results verify that our method can consistently achieve higher ABEP performance prediction results.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {16025–16041},
numpages = {17},
keywords = {Mobile Internet of Things, Mobile cooperative communication, Average bit error probability, Performance prediction, BP neural network}
}

@article{10.14778/3397230.3397238,
author = {Zhou, Xuanhe and Sun, Ji and Li, Guoliang and Feng, Jianhua},
title = {Query performance prediction for concurrent queries using graph embedding},
year = {2020},
issue_date = {May 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3397230.3397238},
doi = {10.14778/3397230.3397238},
abstract = {Query performance prediction is vital to many database tasks (e.g., database monitoring and query scheduling). Existing methods focus on predicting the performance for a single query but cannot effectively predict the performance for concurrent queries, because it is rather hard to capture the correlations between different queries, e.g., lock conflict and buffer sharing. To address this problem, we propose a performance prediction system for concurrent queries using a graph embedding based model. To the best of our knowledge, this is the first graph-embedding-based performance prediction model for concurrent queries. We first propose a graph model to encode query features, where each vertex is a node in the query plan of a query and each edge between two vertices denotes the correlations between them, e.g., sharing the same table/index or competing resources. We then propose a prediction model, in which we use a graph embedding network to encode the graph features and adopt a prediction network to predict query performance using deep learning. Since workloads may dynamically change, we propose a graph update and compaction algorithm to adapt to workload changes. We have conducted extensive experiments on real-world datasets, and experimental results showed that our method outperformed the state-of-the-art approaches.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {1416–1428},
numpages = {13}
}

@inproceedings{10.1145/3382026.3425767,
author = {Marchezan, Luciano and Carbonell, Jo\~{a}o and Rodrigues, Elder and Bernardino, Maicon and Basso, F\'{a}bio Paulo and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Enhancing the Feature Retrieval Process with Scoping and Tool Support: PAxSPL_v2},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425767},
doi = {10.1145/3382026.3425767},
abstract = {Software Product Lines (SPLs) are commonly adopted with an extractive approach, by performing a reengineering process in legacy systems, when dealing with variability and reuse became challenging. As a starting activity of the process, the legacy systems are analyzed to retrieve, categorize, and group their features in terms of commonality and variability. Due to the importance of this feature retrieving, we proposed the Prepare, Assemble, and Execute framework for SPL reengineering (PAxSPL). PAxSPL aims at guiding users to customize the feature retrieval for their scenario. In an initial evaluation of the PAxSPL in a real-world scenario, we could observe the need for including scoping activities and implementing a tool to make the framework more adoptable in practice. In this paper, we describe how we performed these improvements. We performed the evolution of PAxSPL by including SPL scoping concepts and activities into our framework as well as developing a supporting tool. We also conducted a pilot study to evaluate how PAxSPL allows instantiating a scenario where the SPL reengineering were conducted. The results show that all artifacts, activities, and techniques from the scenario could be properly represented. However, we also identified a potential limitation during the assembly of techniques regarding parallel activities. The main contribution is PAxSPL_v2 that makes the framework more adherent to industries performing the reengineering of legacy systems into SPLs.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {29–36},
numpages = {8},
keywords = {automated support, software product lines, variability management},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.5555/2818754.2818779,
author = {von Rhein, Alexander and Grebhahn, Alexander and Apel, Sven and Siegmund, Norbert and Beyer, Dirk and Berger, Thorsten},
title = {Presence-condition simplification in highly configurable systems},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {For the analysis of highly configurable systems, analysis approaches need to take the inherent variability of these systems into account. The notion of presence conditions is central to such approaches. A presence condition specifies a subset of system configurations in which a certain artifact or a concern of interest is present (e.g., a defect associated with this subset). In this paper, we introduce and analyze the problem of presence-condition simplification. A key observation is that presence conditions often contain redundant information, which can be safely removed in the interest of simplicity and efficiency. We present a formalization of the problem, discuss application scenarios, compare different algorithms for solving the problem, and empirically evaluate the algorithms by means of a set of substantial case studies.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {178–188},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1155/2021/9958203,
author = {Li, Shuping and Liu, Taotang and Uddin, M. Irfan},
title = {Performance Prediction for Higher Education Students Using Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/9958203},
doi = {10.1155/2021/9958203},
abstract = {Predicting students’ performance is very important in matters related to higher education as well as with regard to deep learning and its relationship to educational data. Prediction of students’ performance provides support in selecting courses and designing appropriate future study plans for students. In addition to predicting the performance of students, it helps teachers and managers to monitor students in order to provide support to them and to integrate the training programs to obtain the best results. One of the benefits of student’s prediction is that it reduces the official warning signs as well as expelling students because of their inefficiency. Prediction provides support to the students themselves through their choice of courses and study plans appropriate to their abilities. The proposed method used deep neural network in prediction by extracting informative data as a feature with corresponding weights. Multiple updated hidden layers are used to design neural network automatically; number of nodes and hidden layers controlled by feed forwarding and backpropagation data are produced by previous cases. The training mode is used to train the system with labeled data from dataset and the testing mode is used for evaluating the system. Mean absolute error (MAE) and root mean squared error (RMSE) with accuracy used for evolution of the proposed method. The proposed system has proven its worth in terms of efficiency through the achieved results in MAE (0.593) and RMSE (0.785) to get the best prediction.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@article{10.1007/s11633-021-1312-1,
author = {Baruah, Amlan Jyoti and Baruah, Siddhartha},
title = {Data Augmentation and Deep Neuro-fuzzy Network for Student Performance Prediction with MapReduce Framework},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1476-8186},
url = {https://doi.org/10.1007/s11633-021-1312-1},
doi = {10.1007/s11633-021-1312-1},
abstract = {The main aim of an educational institute is to offer high-quality education to students. The system to achieve better quality in the educational system is to find the knowledge from educational data and to discover the attributes that manipulate the performance of students. Student performance prediction is a major issue in education and training, specifically in the educational data mining system. This research presents the student performance prediction approach with the MapReduce framework based on the proposed fractional competitive multi-verse optimization-based deep neuro-fuzzy network. The proposed fractional competitive multi-verse optimization-based deep neuro-fuzzy network is derived by integrating fractional calculus with competitive multi-verse optimization. The MapReduce framework is designed with the mapper and the reducer phase to perform the student performance prediction mechanism with the deep learning classifier. The input data is partitioned at the mapper phase to perform the data transformation process, and thereby the features are selected using the distance measure. The selected unique features are employed for the data segmentation process, and thereafter the prediction strategy is accomplished at the reducer phase by the deep neuro-fuzzy network classifier. The proposed method obtained the performance in terms of mean square error, root mean square error and mean absolute error with the values of 0.338 3, 0.581 7, and 0.391 5, respectively.},
journal = {Int. J. Autom. Comput.},
month = dec,
pages = {981–992},
numpages = {12},
keywords = {Educational data mining (EDA), MapReduce framework, deep neuro-fuzzy network, student performance, data augmentation}
}

@article{10.1016/j.sysarc.2019.06.001,
author = {Gamati\'{e}, Abdoulaye and An, Xin and Zhang, Ying and Kang, An and Sassatelli, Gilles},
title = {Empirical model-based performance prediction for application mapping on multicore architectures},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2019.06.001},
doi = {10.1016/j.sysarc.2019.06.001},
journal = {J. Syst. Archit.},
month = sep,
pages = {1–16},
numpages = {16},
keywords = {Resource allocation, Application mapping, Model-based performance prediction, Machine learning}
}

@inproceedings{10.1145/3369255.3369277,
author = {Zhang, Wei and Zhou, Yilin and Yi, Baolin},
title = {An Interpretable Online Learner's Performance Prediction Model Based on Learning Analytics},
year = {2020},
isbn = {9781450372541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369255.3369277},
doi = {10.1145/3369255.3369277},
abstract = {Most of student performance prediction model only focused on the accuracy of prediction results, but achieving an interpretable prediction model may be as important as obtaining high accuracy in learning prediction research. This paper proposed a student performance prediction model based on online learning behavior analytics with 19 behavior indicators. This model consists of four steps: data collection and processing, correlation analysis, data analytics, student performance prediction algorithm, prediction and intervention. Moreover, a case have been taken to predict student performance according to the model with rule-based genetic programming algorithm. The experiment results show that the rule-based genetic programming algorithm has a stronger interpretation in ensuring competitive prediction accuracy. The model achieves a good prediction effect.},
booktitle = {Proceedings of the 11th International Conference on Education Technology and Computers},
pages = {148–154},
numpages = {7},
keywords = {Online learning platform, intervention, learning behavior analytics, prediction algorithm, student performance model},
location = {Amsterdam, Netherlands},
series = {ICETC '19}
}

@article{10.3103/S1060992X21020119,
author = {Surenthiran, S. and Rajalakshmi, R. and Sujatha, S. S.},
title = {Student Performance Prediction Using Atom Search Optimization Based Deep Belief Neural Network},
year = {2021},
issue_date = {Apr 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {2},
issn = {1060-992X},
url = {https://doi.org/10.3103/S1060992X21020119},
doi = {10.3103/S1060992X21020119},
journal = {Opt. Mem. Neural Netw.},
month = apr,
pages = {157–171},
numpages = {15},
keywords = {Student Performance, DBNN, ASO, RBM, Dataset, Learning rate}
}

@article{10.1155/2021/1682163,
author = {Liu, Huan and Zhang, Yuanpeng},
title = {Research on Performance Prediction of Technological Innovation Enterprises Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/1682163},
doi = {10.1155/2021/1682163},
abstract = {High-tech enterprises are the leaders in promoting economic development. The study of the relationship between their scientific and technological innovation capabilities and corporate performance is of far-reaching practical significance for guiding companies to formulate independent innovation strategies scientifically, improving their independent innovation capabilities, and promoting further transformation into an innovative country. In view of the large-scale technological innovation enterprise network, the traditional technological innovation enterprise performance prediction method cannot fully reflect the real-time technological innovation enterprise status. Aiming at the deficiencies of the existing short-term technology innovation enterprise forecasting methods, this paper proposes a technology innovation enterprise performance forecasting method based on deep learning. I analyze the temporal and spatial characteristics of the data of technological innovation enterprises and divide the data according to the temporal characteristics of technological innovation enterprises. According to the spatial relevance of technological innovation enterprises, grouping is carried out by setting different correlation coefficient thresholds. The method of spectral decomposition is used to divide the data of scientific and technological innovation enterprises into trend items and random fluctuation items, to decompose the matrix of scientific and technological innovation enterprises, and to construct a compressed matrix using correlation. Using the deep belief network model in deep learning combined with support vector regression to establish a prediction model for technological innovation enterprises, this paper proposes a convolutional neural network model for performance prediction of scientific and technological innovation enterprises. Through the convolution operation and subsampling operation based on the concept of local window, the feature learning from the local to the whole is completed. This article uses the Naive Bayes model, logistic regression model, support vector regression model, and other mainstream methods to predict and compare the performance of technological innovation enterprises. I use the dropout method to reduce the impact of overfitting during training. The experimental results show that the deep neural network model method used in this article can achieve better prediction results than mainstream methods under the same characteristics. The experimental results on the data set confirm that the method of performance prediction of technology innovation enterprises based on deep learning used in this paper can effectively improve the results of performance prediction of technology innovation enterprises.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/3233027.3236397,
author = {Mendon\c{c}a, Willian D. F. and Assun\c{c}\~{a}o, Wesley K. G. and Linsbauer, Lukas},
title = {Multi-objective optimization for reverse engineering of apo-games feature models},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236397},
doi = {10.1145/3233027.3236397},
abstract = {Software Product Lines Engineering (SPLE) is a software development approach intended for the development and maintenance of variable systems, i.e. systems that exist in many different variants. In the long run SPLE has many advantages. However, it requires a large upfront investment of time and money, which is why in practice Software Product Lines (SPLs) are rarely developed from scratch. Instead, they are often built using an extractive approach by which a set of existing system variants is consolidated (i.e. reverse engineered) into an SPL. A crucial part of this process is the construction of a variability model like a Feature Model (FM) that describes the common and variable parts of the system variants. In this paper we apply an approach for reverse engineering feature models based on a multi-objective optimization algorithm to the given challenge of constructing a feature model for a set of game variants and we present the results.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {279–283},
numpages = {5},
keywords = {feature model, reverse engineering, software product line},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3109729.3109748,
author = {Martinez, Jabier and Assun\c{c}\~{a}o, Wesley K. G. and Ziadi, Tewfik},
title = {ESPLA: A Catalog of Extractive SPL Adoption Case Studies},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109748},
doi = {10.1145/3109729.3109748},
abstract = {Building Software Product Lines (SPLs) from existing artefacts is known as the extractive approach for SPL adoption. The traditional case is that variants are created with ad-hoc reuse (e.g., copy-paste-modify to quickly respond to different customer needs) and practitioners want to reengineer them to an SPL. Several industrial cases have been presented in the literature to motivate the interest of the extraction and many case studies are used to validate methods and techniques for different activities during this adoption process.However, there is no catalog or repository that gather together case studies and artefacts related to extractive SPL adoption. In this paper we present ESPLA, a catalog of Extractive SPL Adoption case studies that aims to foster the advance of this field by providing comprehensive information about case studies that will be otherwise scattered in the literature. Researchers, practitioners and educators can use this catalog to find the case studies that better fit to their particular needs. Currently, ESPLA contains information about 123 case studies and it is intended to be a catalog that can be updated and extended by the community.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {38–41},
numpages = {4},
keywords = {Software product lines, extractive software product line adoption, reverse engineering, variability management},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1016/j.future.2018.03.015,
author = {Al-Faifi, Abdullah Mohammed and Song, Biao and Hassan, Mohammad Mehedi and Alamri, Atif and Gumaei, Abdu},
title = {Performance prediction model for cloud service selection from smart data},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {85},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.03.015},
doi = {10.1016/j.future.2018.03.015},
journal = {Future Gener. Comput. Syst.},
month = aug,
pages = {97–106},
numpages = {10},
keywords = {Cloud service selection, Smart data, Bayes classifier, Performance prediction}
}

@article{10.1155/2021/4091821,
author = {Wang, Jinjuan and Ahmed, Syed Hassan},
title = {Analysis of Sports Performance Prediction Model Based on GA-BP Neural Network Algorithm},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4091821},
doi = {10.1155/2021/4091821},
abstract = {There are many factors that affect athletes’ sports performance in sports competitions. The traditional sports performance prediction method is difficult to obtain more accurate sports performance prediction results and corresponding data analysis in a short time, which is not conducive for coaches to formulate targeted and scientific training sprint plans for athletes’ problems. Therefore, based on GA-BP neural network algorithm, this paper constructs a sports performance prediction model and carries out experiments and analysis. The experimental results show that GA-BP neural network algorithm has a faster convergence speed than BP neural network and can achieve the expected error accuracy in a shorter time, which overcomes the problems of the BP neural network. At the same time, different from the previous models, GA-BP neural network algorithm can get the athlete training model according to the relationship between quality training indicators and special sports training results, which can more intuitively show the advantages and disadvantages of athletes. In the final sports performance prediction results, GA-BP neural network prediction results have higher accuracy, better stability, better prediction effect, and higher application value than BP neural network.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/3234944.3234950,
author = {Roitman, Haggai},
title = {Enhanced Performance Prediction of Fusion-based Retrieval},
year = {2018},
isbn = {9781450356565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234944.3234950},
doi = {10.1145/3234944.3234950},
abstract = {We study the query performance prediction (QPP) task for fusion-based retrieval. Within such a retrieval setting, several ranked lists, each one retrieved by a different method, are combined into a single (fused) ranked list. A common prediction approach is to treat the (base) ranked lists as reference lists and combine those lists' QPP estimates according to their similarity with the fused-list. Yet, we identify a gap in the way that relevance-dependent aspects of inter-list relationships are modeled within such an approach. Aiming to address this gap, we derive an enhanced estimation approach which results in a more accurate prediction.},
booktitle = {Proceedings of the 2018 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {195–198},
numpages = {4},
keywords = {evaluation, fusion, qpp},
location = {Tianjin, China},
series = {ICTIR '18}
}

@inproceedings{10.1145/3382025.3414943,
author = {Th\"{u}m, Thomas},
title = {A BDD for Linux? the knowledge compilation challenge for variability},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414943},
doi = {10.1145/3382025.3414943},
abstract = {What is the number of valid configurations for Linux? How to generate uniform random samples for Linux? Can we create a binary decision diagram for Linux? It seems that the product-line community tries hard to answer such questions for Linux and other configurable systems. However, attempts are often not published due to the publication bias (i.e., unsuccessful attempts are not published). As a consequence, researchers keep trying by potentially spending redundant effort. The goal of this challenge is to guide research on these computationally complex problems and to foster the exchange between researchers and practitioners.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {16},
numpages = {6},
keywords = {artificial intelligence, binary decision diagrams, configurable system, decision models, feature models, knownledge compilation, product configuration, satisfiability solving, software configuration, software product line},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3307630.3342385,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {HADAS: Analysing Quality Attributes of Software Configurations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342385},
doi = {10.1145/3307630.3342385},
abstract = {Software Product Lines (SPLs) are highly configurable systems. Automatic analyses of SPLs rely on solvers to navigate complex dependencies among features and find legal solutions. Variability analysis tools are complex due to the diversity of products and domain-specific knowledge. On that, while there are experimental studies that analyse quality attributes, the knowledge is not easily accessible for developers, and its appliance is not trivial. Aiming to allow the industry to quality-explore SPL design spaces, we developed the HADAS assistant that: (1) models systems and collects quality attributes metrics in a cloud repository, and (2) reasons about it helping developers with quality attributes requirements.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {13–16},
numpages = {4},
keywords = {NFQA, attribute, model, numerical, software product line, variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2970276.2970322,
author = {Meinicke, Jens and Wong, Chu-Pan and K\"{a}stner, Christian and Th\"{u}m, Thomas and Saake, Gunter},
title = {On essential configuration complexity: measuring interactions in highly-configurable systems},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970322},
doi = {10.1145/2970276.2970322},
abstract = {Quality assurance for highly-configurable systems is challenging due to the exponentially growing configuration space. Interactions among multiple options can lead to surprising behaviors, bugs, and security vulnerabilities. Analyzing all configurations systematically might be possible though if most options do not interact or interactions follow specific patterns that can be exploited by analysis tools. To better understand interactions in practice, we analyze program traces to characterize and identify where interactions occur on control flow and data. To this end, we developed a dynamic analysis for Java based on variability-aware execution and monitor executions of multiple small to medium-sized programs. We find that the essential configuration complexity of these programs is indeed much lower than the combinatorial explosion of the configuration space indicates. However, we also discover that the interaction characteristics that allow scalable and complete analyses are more nuanced than what is exploited by existing state-of-the-art quality assurance strategies.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {483–494},
numpages = {12},
keywords = {Configurable Software, Feature Interaction, Variability-Aware Execution},
location = {Singapore, Singapore},
series = {ASE '16}
}

@article{10.1016/j.sysarc.2016.06.006,
author = {Cheng, Yuxia and Chen, Wenzhi and Wang, Zonghui and Xiang, Yang},
title = {Precise contention-aware performance prediction on virtualized multicore system},
year = {2017},
issue_date = {January 2017},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {72},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2016.06.006},
doi = {10.1016/j.sysarc.2016.06.006},
abstract = {Virtualized multicore contention - aware performance prediction model.Virtual machine contention sensitivity and intensity features collection.Quantify the precise levels of performance degradation between VMs. Multicore systems are widely deployed in both the embedded and the high end computing infrastructures. However, traditional virtualization systems can not effectively isolate shared micro architectural resources among virtual machines (VMs) running on multicore systems. CPU and memory intensive VMs contending for these resources will lead to serious performance interference, which makes virtualization systems less efficient and VM performance less stable. In this paper, we propose a contention-aware performance prediction model on the virtualized multicore systems to quantify the performance degradation of VMs. First, we identify the performance interference factors and design synthetic micro-benchmarks to obtain VM's contention sensitivity and intensity features that are correlated with VM performance degradation. Second, based on the contention features, we build VM performance prediction model using machine learning techniques to quantify the precise levels of performance degradation. The proposed model can be used to optimize VM performance on multicore systems. Our experimental results show that the performance prediction model achieves high accuracy and the mean absolute error is 2.83%.},
journal = {J. Syst. Archit.},
month = jan,
pages = {42–50},
numpages = {9},
keywords = {Multicore, Performance prediction, Resource contention, Virtual machine}
}

@inproceedings{10.1145/3068943.3068947,
author = {Namaki, Mohammad Hossein and Sasani, Keyvan and Wu, Yinghui and Gebremedhin, Assefaw H.},
title = {Performance Prediction for Graph Queries},
year = {2017},
isbn = {9781450349901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3068943.3068947},
doi = {10.1145/3068943.3068947},
abstract = {Query performance prediction has shown benefits to query optimization and resource allocation for relational databases. Emerging applications are leading to search scenarios where workloads with heterogeneous, structure-less analytical queries are processed over large-scale graph and network data. This calls for effective models to predict the performance of graph analytical queries, which are often more involved than their relational counterparts.In this paper, we study and evaluate predictive techniques for graph query performance prediction. We make several contributions. (1) We propose a general learning framework that makes use of practical and computationally efficient statistics from query scenarios and employs regression models. (2) We instantiate the framework with two routinely issued query classes, namely, reachability and graph pattern matching, that exhibit different query complexity. We develop modeling and learning algorithms for both query classes. (3) We show that our prediction models readily apply to resource-bounded querying, by providing a learning-based workload optimization strategy. Given a query workload and a time bound, the models select queries to be processed with a maximized query profit and a total cost within the bound. Using real-world graphs, we experimentally demonstrate the efficacy of our framework in terms of accuracy and the effectiveness of workload optimization.},
booktitle = {Proceedings of the 2nd International Workshop on Network Data Analytics},
articleno = {4},
numpages = {9},
location = {Chicago, IL, USA},
series = {NDA'17}
}

@inproceedings{10.1145/3150994.3150998,
author = {Singh, Alok and Rao, Arvind and Purawat, Shweta and Altintas, Ilkay},
title = {A machine learning approach for modular workflow performance prediction},
year = {2017},
isbn = {9781450351294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3150994.3150998},
doi = {10.1145/3150994.3150998},
abstract = {Scientific workflows provide an opportunity for declarative computational experiment design in an intuitive and efficient way. A distributed workflow is typically executed on a variety of resources and it uses a variety of computational algorithms or tools to achieve the desired outcomes. Such a variety imposes additional complexity in scheduling these workflows on large scale computers. As computation becomes more distributed, insights into expected workload that a workflow presents become critical for effective resource allocation. In this paper, we present a modular framework that leverages Machine Learning for creating precise performance predictions of a workflow. The central idea is to partition a workflow in such a way that makes the task of forecasting each atomic unit manageable and gives us a way to combine the individual predictions efficiently. We recognize a combination of an executable and a specific physical resource as a single module. This gives us a handle to characterize workload and machine power as a single unit of prediction. The modular approach of the presented framework allows it to adapt to highly complex nested workflows and scale to new scenarios. We present performance estimation results of independent workflow modules executed on the XSEDE SDSC Comet cluster using various Machine Learning algorithms. The results provide insights into the behavior and effectiveness of different algorithms in the context of scientific workflow performance prediction.},
booktitle = {Proceedings of the 12th Workshop on Workflows in Support of Large-Scale Science},
articleno = {7},
numpages = {11},
keywords = {distributed computing, exascale computing, machine learning, parallel computing, performance prediction, scientific workflows},
location = {Denver, Colorado},
series = {WORKS '17}
}

@inproceedings{10.5555/3155562.3155625,
author = {Jamshidi, Pooyan and Siegmund, Norbert and Velez, Miguel and K\"{a}stner, Christian and Patel, Akshay and Agarwal, Yuvraj},
title = {Transfer learning for performance modeling of configurable systems: an exploratory analysis},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = {Modern software systems provide many configuration options which significantly influence their non-functional properties. To understand and predict the effect of configuration options, several sampling and learning strategies have been proposed, albeit often with significant cost to cover the highly dimensional configuration space. Recently, transfer learning has been applied to reduce the effort of constructing performance models by transferring knowledge about performance behavior across environments. While this line of research is promising to learn more accurate models at a lower cost, it is unclear why and when transfer learning works for performance modeling. To shed light on when it is beneficial to apply transfer learning, we conducted an empirical study on four popular software systems, varying software configurations and environmental conditions, such as hardware, workload, and software versions, to identify the key knowledge pieces that can be exploited for transfer learning. Our results show that in small environmental changes (e.g., homogeneous workload change), by applying a linear transformation to the performance model, we can understand the performance behavior of the target environment, while for severe environmental changes (e.g., drastic workload change) we can transfer only knowledge that makes sampling more efficient, e.g., by reducing the dimensionality of the configuration space.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {497–508},
numpages = {12},
keywords = {Performance analysis, transfer learning},
location = {Urbana-Champaign, IL, USA},
series = {ASE '17}
}

@inproceedings{10.1145/3209978.3210041,
author = {Zamani, Hamed and Croft, W. Bruce and Culpepper, J. Shane},
title = {Neural Query Performance Prediction using Weak Supervision from Multiple Signals},
year = {2018},
isbn = {9781450356572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209978.3210041},
doi = {10.1145/3209978.3210041},
abstract = {Predicting the performance of a search engine for a given query is a fundamental and challenging task in information retrieval. Accurate performance predictors can be used in various ways, such as triggering an action, choosing the most effective ranking function per query, or selecting the best variant from multiple query formulations. In this paper, we propose a general end-to-end query performance prediction framework based on neural networks, called NeuralQPP. Our framework consists of multiple components, each learning a representation suitable for performance prediction. These representations are then aggregated and fed into a prediction sub-network. We train our models with multiple weak supervision signals, which is an unsupervised learning approach that uses the existing unsupervised performance predictors using weak labels. We also propose a simple yet effective component dropout technique to regularize our model. Our experiments on four newswire and web collections demonstrate that NeuralQPP significantly outperforms state-of-the-art baselines, in nearly every case. Furthermore, we thoroughly analyze the effectiveness of each component, each weak supervision signal, and all resulting combinations in our experiments.},
booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
pages = {105–114},
numpages = {10},
keywords = {deep learning, neural networks, quality estimation, query performance prediction, weak supervision},
location = {Ann Arbor, MI, USA},
series = {SIGIR '18}
}

@inproceedings{10.1007/978-3-030-93046-2_3,
author = {Liu, Mengfan and Shao, Pengyang and Zhang, Kun},
title = {Graph-Based Exercise- and&nbsp;Knowledge-Aware Learning Network for&nbsp;Student Performance Prediction},
year = {2021},
isbn = {978-3-030-93045-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-93046-2_3},
doi = {10.1007/978-3-030-93046-2_3},
abstract = {Predicting student performance is a fundamental task in Intelligent Tutoring Systems&nbsp;(ITSs), by which we can learn about students’ knowledge level and provide personalized teaching strategies for them. Researchers have made plenty of efforts on this task. They either leverage educational psychology methods to predict students’ scores according to the learned knowledge proficiency, or make full use of Collaborative Filtering (CF) models to represent latent factors of students and exercises. However, most of these methods either neglect the exercise-specific characteristics (e.g., exercise materials), or cannot fully explore the high-order interactions between students, exercises, as well as knowledge concepts. To this end, we propose a Graph-based Exercise- and Knowledge-Aware Learning Network&nbsp;for accurate student score prediction. Specifically, we learn students’ mastery of exercises and knowledge concepts respectively to model the two-fold effects of exercises and knowledge concepts. Then, to model the high-order interactions, we apply graph convolution techniques in the prediction process. Extensive experiments on two real-world datasets prove the effectiveness of our proposed Graph-EKLN.},
booktitle = {Artificial Intelligence: First CAAI International Conference, CICAI 2021, Hangzhou, China, June 5–6, 2021, Proceedings, Part I},
pages = {27–38},
numpages = {12},
keywords = {Education data mining, Intelligent tutoring system, Collaborative filtering, Graph neural network},
location = {Hangzhou, China}
}

@inproceedings{10.1145/3284497.3284509,
author = {Fan, Zhang},
title = {Modeling of Sports Performance Based on Nonlinear Screening Factors and Weighting to Improve Prediction Accuracy},
year = {2018},
isbn = {9781450365994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284497.3284509},
doi = {10.1145/3284497.3284509},
abstract = {In this paper, a weighted sports performance prediction model based on LSSVM is constructed for complex non-linear sports performance. The influencing factors of sports performance are selected and weighted by LSSVM, and the factors closely related to the predicted results are screened out, and appropriate weights are given to each factor. Firstly, the least square support vector machine (LS-SVM) was used to obtain the main influencing factors by nonlinear screening according to the principle of minimum cross-validation root mean square error. Then the main influencing factors are given different weights to reflect the extent of their impact on the results of sports performance prediction. Finally, the least squares support vector machine is used to build the optimal sports performance prediction model, and applied to the 1000-meter race performance prediction. The simulation results show that LSSVM-New improves the accuracy of sports performance prediction compared with other sports performance prediction models, and it is an effective sports performance prediction model.},
booktitle = {Proceedings of the 2nd International Conference on Digital Technology in Education},
pages = {86–90},
numpages = {5},
keywords = {Factors weighting, Model building, Nonlinear screening factor, Sports performances},
location = {Bangkok, Thailand},
series = {ICDTE '18}
}

@article{10.1007/s10055-020-00482-2,
author = {Lopez-Gordo, M. A. and Kohlmorgen, Nico and Morillas, C. and Pelayo, Francisco},
title = {Performance prediction at single-action level to a first-person shooter video game},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {3},
issn = {1359-4338},
url = {https://doi.org/10.1007/s10055-020-00482-2},
doi = {10.1007/s10055-020-00482-2},
abstract = {Serious games, professional entertainment (e.g. e-sport), or the immersive simulation of critical scenarios by means of virtual reality belong to the scope of the video game industry. With implications in economic (gambling) and professional careers (e-sports), researchers have focused on the high-level analysis of the win/lose chances and on the player’s profile (good/bad performers). At the low-level analysis, the prediction of player’s performance at single-action level, such as in the case of hits in a first-person shooter (FPS) video game, to the best of our knowledge, has not been undertaken yet. In this study we hypothesize that VR video games, embed enough contextual information to predict performance in an FPS game at single-action level. For this purpose, we developed an FPS video game and a single-shoot level prediction model based on virtual world contextual information. Eighteen students of the University of Granada without previous experience in the game played for 45–50&nbsp;min and generated 600–1200 events each. Every event, which was composed of twenty-contextual-player-centred components of the virtual scenario, were transmitted on-line to a remote server to perform predictions. Data from fifteen out of eighteen participants were used to train the model prediction model. After training, the model predicted “hit”/”miss” with a mean accuracy of 74.1%. In a broad vision, our results suggest that immersive virtual environments bear enough contextual information for accurate predictions even at single-action level. In a closed-loop design, this finding could be used (e.g. in defence, professional e-sports, etc.) to anticipate participant’s actions/decisions before they are taken, and modify the virtual scenario (e.g. abort mission, change environmental conditions) or drive the player (e. g. suggest options, relieve of command, etc.) according to the purpose of the mission.},
journal = {Virtual Real.},
month = sep,
pages = {681–693},
numpages = {13},
keywords = {Virtual reality, Performance, Prediction, Video game, First-person shooter}
}

@inproceedings{10.1145/3479242.3487327,
author = {Baert, Mathias and De Poorter, Eli and Hoebeke, Jeroen},
title = {A Digital Communication Twin for Performance Prediction and Management of Bluetooth Mesh Networks},
year = {2021},
isbn = {9781450390804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479242.3487327},
doi = {10.1145/3479242.3487327},
abstract = {Bluetooth Mesh technology can be used to realize heterogeneous IoT networks, consisting of a smart lighting backbone augmented with sensor-based applications. It offers many configuration options to adhere to the diverse application requirements and limit the overhead. Finding an optimal configuration of the network is a complex issue which leads to numerous performance-related questions. In this paper, Digital Twin technology is used to provide continuous and diverse insights into the network's behavior, under monitored or artificial network conditions. The twin is constantly connected to the physical network and combines selective simulation, graph algorithms and a data driven link model into a single toolbox. We evaluated its usage for smart lighting applications on a real-life testbed. The results indicate that the twin can produce end-to-end (E2E) latencies, E2E path distributions and a packet delivery ratio comparable to experiment outcomes in the physical network and in compliance with application requirements. Statistical validation of the similarity between measured and predicted E2E latency distributions indicates a Mean Absolute Error &lt; 10 % and a positive discrete Kolmogorov-Smirnov test for all results.},
booktitle = {Proceedings of the 17th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {1–10},
numpages = {10},
keywords = {bluetooth mesh, digital communication twin, graph algorithms, monitoring, network management, simulation},
location = {Alicante, Spain},
series = {Q2SWinet '21}
}

@article{10.14778/3342263.3342646,
author = {Marcus, Ryan and Papaemmanouil, Olga},
title = {Plan-structured deep neural network models for query performance prediction},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342646},
doi = {10.14778/3342263.3342646},
abstract = {Query performance prediction, the task of predicting a query's latency prior to execution, is a challenging problem in database management systems. Existing approaches rely on features and performance models engineered by human experts, but often fail to capture the complex interactions between query operators and input relations, and generally do not adapt naturally to workload characteristics and patterns in query execution plans. In this paper, we argue that deep learning can be applied to the query performance prediction problem, and we introduce a novel neural network architecture for the task: a plan-structured neural network. Our neural network architecture matches the structure of any optimizer-selected query execution plan and predict its latency with high accuracy, while eliminating the need for human-crafted input features. A number of optimizations are also proposed to reduce training overhead without sacrificing effectiveness. We evaluated our techniques on various workloads and we demonstrate that our approach can out-perform the state-of-the-art in query performance prediction.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1733–1746},
numpages = {14}
}

@inproceedings{10.1145/3461001.3473058,
author = {Ngo, Kien-Tuan and Nguyen, Thu-Trang and Nguyen, Son and Vo, Hieu Dinh},
title = {Variability fault localization: a benchmark},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473058},
doi = {10.1145/3461001.3473058},
abstract = {Software fault localization is one of the most expensive, tedious, and time-consuming activities in program debugging. This activity becomes even much more challenging in Software Product Line (SPL) systems due to the variability of failures in SPL systems. These unexpected behaviors are caused by variability faults which can only be exposed under some combinations of system features. Although localizing bugs in non-configurable code has been investigated in-depth, variability fault localization in SPL systems still remains mostly unexplored. To approach this challenge, we propose a benchmark for variability fault localization with a large set of 1,570 buggy versions of six SPL systems and baseline variability fault localization performance results. Our hope is to engage the community to propose new and better approaches to the problem of variability fault localization in SPL systems.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {120–125},
numpages = {6},
keywords = {benchmark, variability bug, variability fault localization},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2491411.2491459,
author = {Kim, Chang Hwan Peter and Marinov, Darko and Khurshid, Sarfraz and Batory, Don and Souto, Sabrina and Barros, Paulo and D'Amorim, Marcelo},
title = {SPLat: lightweight dynamic analysis for reducing combinatorics in testing configurable systems},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491459},
doi = {10.1145/2491411.2491459},
abstract = {Many programs can be configured through dynamic and/or static selection of configuration variables. A software product line (SPL), for example, specifies a family of programs where each program is defined by a unique combination of features. Systematically testing SPL programs is expensive as it can require running each test against a combinatorial number of configurations. Fortunately, a test is often independent of many configuration variables and need not be run against every combination. Configurations that are not required for a test can be pruned from execution. This paper presents SPLat, a new way to dynamically prune irrelevant configurations: the configurations to run for a test can be determined during test execution by monitoring accesses to configuration variables. SPLat achieves an optimal reduction in the number of configurations and is lightweight compared to prior work that used static analysis and heavyweight dynamic execution. Experimental results on 10 SPLs written in Java show that SPLat substantially reduces the total test execution time in many cases. Moreover, we demonstrate the scalability of SPLat by applying it to a large industrial code base written in Ruby on Rails.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {257–267},
numpages = {11},
keywords = {Automated testing, Configurable Systems, Efficiency, Software Product Lines},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/3233027.3233044,
author = {Al-Hajjaji, Mustafa and Schulze, Michael and Ryssel, Uwe},
title = {Similarity analysis of product-line variants},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233044},
doi = {10.1145/3233027.3233044},
abstract = {Many existing approaches have exploited the similarity notion to analyze software systems. In product-line engineering, similarity notion has been considered to fulfill analysis objectives, such as improving the testing effectiveness and reducing the testing efforts. However, most of the existing approaches consider in the similarity measurement only information of high level of abstraction, such as the feature selections of variants. In this paper, we present the notion of similarity in product-line engineering using different types of problem-space as well as solution-space information. In particular, we discuss different scenarios of measuring the similarity between variants and the possibility of combining different types of information to output the similarity between the compared variants. Moreover, we realized these scenarios in the industrial variant management tool pure::variants to fulfill analysis functionalities.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {226–235},
numpages = {10},
keywords = {highly configurable systems, similarity, software product lines, variants analysis},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2695664.2695694,
author = {Sidney, Christiane Faleiro and Mendes, Diego Sarmento and Ribeiro, Leonardo Andrade and H\"{a}rder, Theo},
title = {Performance prediction for set similarity joins},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695694},
doi = {10.1145/2695664.2695694},
abstract = {Query performance prediction is essential for many important tasks in cloud-based database management including resource provisioning, admission control, and pricing. Recently, there has been some work on building prediction models to estimate execution time of traditional SQL queries. While suitable for typical OLTP/OLAP workloads, these existing approaches are insufficient to model performance of complex data processing activities for deep analytics such as cleaning and integration of data. These activities are largely based on similarity operations---radically different from regular relational operators. In this paper, we consider prediction models for set similarity joins. We exploit knowledge of optimization techniques and design details popularly found in set similarity join algorithms to identify relevant features, which are then used to construct prediction models based on statistical machine learning. An extensive experimental evaluation confirms the accuracy of our approach.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {967–972},
numpages = {6},
keywords = {cloud databases, performance prediction, set similarity join},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1145/3461002.3473073,
author = {Pett, Tobias and Krieter, Sebastian and Th\"{u}m, Thomas and Lochau, Malte and Schaefer, Ina},
title = {AutoSMP: an evaluation platform for sampling algorithms},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473073},
doi = {10.1145/3461002.3473073},
abstract = {Testing configurable systems is a challenging task due to the combinatorial explosion problem. Sampling is a promising approach to reduce the testing effort for product-based systems by finding a small but still representative subset (i.e., a sample) of all configurations for testing. The quality of a generated sample wrt. evaluation criteria such as run time of sample generation, feature coverage, sample size, and sampling stability depends on the subject systems and the sampling algorithm. Choosing the right sampling algorithm for practical applications is challenging because each sampling algorithm fulfills the evaluation criteria to a different degree. Researchers keep developing new sampling algorithms with improved performance or unique properties to satisfy application-specific requirements. Comparing sampling algorithms is therefore a necessary task for researchers. However, this task needs a lot of effort because of missing accessibility of existing algorithm implementations and benchmarks. Our platform AutoSMP eases practitioners and researchers lifes by automatically executing sampling algorithms on predefined benchmarks and evaluating the sampling results wrt. specific user requirements. In this paper, we introduce the open-source application of AutoSMP and a set of predefined benchmarks as well as a set of T-wise sampling algorithms as examples.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {41–44},
numpages = {4},
keywords = {product lines, sampling, sampling evalutaion},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1007/s10515-017-0214-5,
author = {Tarvo, Alexander and Reiss, Steven P.},
title = {Automatic performance prediction of multithreaded programs: a simulation approach},
year = {2018},
issue_date = {March     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-017-0214-5},
doi = {10.1007/s10515-017-0214-5},
abstract = {The performance of multithreaded programs is often difficult to understand and predict. Multiple threads engage in synchronization operations and use hardware simultaneously. This results in a complex non-linear dependency between the configuration of a program and its performance. To better understand this dependency a performance prediction model is used. Such a model predicts the performance of a system for different configurations. Configurations reflect variations in the workload, different program options such as the number of threads, and characteristics of the hardware. Performance models are complex and require a solid understanding of the program's behavior. As a result, building models of large applications manually is extremely time-consuming and error-prone. In this paper we present an approach for building performance models of multithreaded programs automatically. We employ hierarchical discrete-event models. Different tiers of the model simulate different factors that affect performance of the program, while interaction between the model tiers simulates mutual influence of these factors on performance. Our framework uses a combination of static and dynamic analyses of a single representative run of a system to collect information required for building the performance model. This includes information about the structure of the program, the semantics of interaction between the program's threads, and resource demands of individual program's components. In our experiments we demonstrate that models accurately predict the performance of various multithreaded programs, including complex industrial applications.},
journal = {Automated Software Engg.},
month = mar,
pages = {101–155},
numpages = {55},
keywords = {Modeling, Performance, Program analysis, Simulation}
}

@inproceedings{10.1109/ICSE.2019.00113,
author = {Ha, Huong and Zhang, Hongyu},
title = {DeepPerf: performance prediction for configurable software with deep sparse neural network},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00113},
doi = {10.1109/ICSE.2019.00113},
abstract = {Many software systems provide users with a set of configuration options and different configurations may lead to different runtime performance of the system. As the combination of configurations could be exponential, it is difficult to exhaustively deploy and measure system performance under all possible configurations. Recently, several learning methods have been proposed to build a performance prediction model based on performance data collected from a small sample of configurations, and then use the model to predict system performance under a new configuration. In this paper, we propose a novel approach to model highly configurable software system using a deep feedforward neural network (FNN) combined with a sparsity regularization technique, e.g. the L1 regularization. Besides, we also design a practical search strategy for automatically tuning the network hyperparameters efficiently. Our method, called DeepPerf, can predict performance values of highly configurable software systems with binary and/or numeric configuration options at much higher prediction accuracy with less training data than the state-of-the art approaches. Experimental results on eleven public real-world datasets confirm the effectiveness of our approach.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {1095–1106},
numpages = {12},
keywords = {deep sparse feedforward neural network, highly configurable systems, software performance prediction, sparsity regularization},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1002/int.22603,
author = {Diao, Chenghao and Liu, Tianye and Yang, Zhen and Duan, Yuanyuan},
title = {Comparison between deep learning and fully connected neural network in performance prediction of power cycles: Taking supercritical CO2 Brayton cycle as an example},
year = {2021},
issue_date = {December 2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {36},
number = {12},
issn = {0884-8173},
url = {https://doi.org/10.1002/int.22603},
doi = {10.1002/int.22603},
abstract = {AI is becoming increasingly important in promoting the energy revolution of carbon‐neutral to achieve sustainable development. Induced by the large implementation of renewable energy, the more complexities and uncertainties in the future carbon‐neutral energy systems make their designs hard accessible to the conventional methods, so machine learning (ML) especially the neural network becomes under focus. Here, we design a deep learning architecture based on convolutional neural networks (DL‐CNN) known for its powerful predicting ability, and first utilize it in a case study of performance prediction of supercritical CO2 Brayton cycle. The design paradigm of DL‐CNN architecture for performance prediction of power cycle is proposed. We also summarize the commonly used fully connected neural network (FC‐NN) in related studies of power cycle design. Through systematically comparing the prediction performance of DL‐CNN and FC‐NN, their respective advantages and application scenarios in energy system design are discussed. In addition, a multiobjective design approach based on DL‐CNN combined with random search is proposed and proved to be feasible by comparing with genetic algorithm. The results show that our proposed DL‐CNN model is much more competitive than FC‐NN model when the training data is sufficient and the prediction condition is complex, in which the prediction accuracy can achieve 99.6%. In the future, our deep learning model may help solve the complex design problems of hybrid carbon‐neutral energy systems.},
journal = {Int. J. Intell. Syst.},
month = oct,
pages = {7682–7708},
numpages = {27},
keywords = {deep learning, fully connected neural network, optimization, power cycle design, supercritical CO2 Brayton cycles}
}

@inproceedings{10.1145/3200921.3200937,
author = {Obaida, Mohammad Abu and Liu, Jason and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
title = {Parallel Application Performance Prediction Using Analysis Based Models and HPC Simulations},
year = {2018},
isbn = {9781450350921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3200921.3200937},
doi = {10.1145/3200921.3200937},
abstract = {Parallel application performance models provide valuable insight about the performance in real systems. Capable tools providing fast, accurate, and comprehensive prediction and evaluation of high-performance computing (HPC) applications and system architectures have important value. This paper presents PyPassT, an analysis based modeling framework built on static program analysis and integrated simulation of the target HPC architectures. More specifically, the framework analyzes application source code written in C with OpenACC directives and transforms it into an application model describing its computation and communication behavior (including CPU and GPU workloads, memory accesses, and message-passing transactions). The application model is then executed on a simulated HPC architecture for performance analysis. Preliminary experiments demonstrate that the proposed framework can represent the runtime behavior of benchmark applications with good accuracy.},
booktitle = {Proceedings of the 2018 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {49–59},
numpages = {11},
keywords = {high-performance computing, performance modeling, performance prediction, program analysis, simulation},
location = {Rome, Italy},
series = {SIGSIM-PADS '18}
}

@inproceedings{10.1145/3184407.3184420,
author = {Ardagna, Danilo and Barbierato, Enrico and Evangelinou, Athanasia and Gianniti, Eugenio and Gribaudo, Marco and Pinto, T\'{u}lio B. M. and Guimar\~{a}es, Anna and Couto da Silva, Ana Paula and Almeida, Jussara M.},
title = {Performance Prediction of Cloud-Based Big Data Applications},
year = {2018},
isbn = {9781450350952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3184407.3184420},
doi = {10.1145/3184407.3184420},
abstract = {Data heterogeneity and irregularity are key characteristics of big data applications that often overwhelm the existing software and hardware infrastructures. In such context, the exibility and elasticity provided by the cloud computing paradigm over a natural approach to cost-effectively adapting the allocated resources to the application's current needs. Yet, the same characteristics impose extra challenges to predicting the performance of cloud-based big data applications, a central step in proper management and planning. This paper explores two modeling approaches for performance prediction of cloud-based big data applications. We evaluate a queuing-based analytical model and a novel fast ad-hoc simulator in various scenarios based on different applications and infrastructure setups. Our results show that our approaches can predict average application execution times with 26% relative error in the very worst case and about 12% on average. Moreover, our simulator provides performance estimates 70 times faster than state of the art simulation tools.},
booktitle = {Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {192–199},
numpages = {8},
keywords = {approximate methods, big data, performance modeling, simulation, spark},
location = {Berlin, Germany},
series = {ICPE '18}
}

@inproceedings{10.1145/3382025.3414955,
author = {Ananieva, Sofia and Greiner, Sandra and K\"{u}hn, Thomas and Kr\"{u}ger, Jacob and Linsbauer, Lukas and Gr\"{u}ner, Sten and Kehrer, Timo and Klare, Heiko and Koziolek, Anne and L\"{o}nn, Henrik and Krieter, Sebastian and Seidl, Christoph and Ramesh, S. and Reussner, Ralf and Westfechtel, Bernhard},
title = {A conceptual model for unifying variability in space and time},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414955},
doi = {10.1145/3382025.3414955},
abstract = {Software engineering faces the challenge of developing and maintaining systems that are highly variable in space (concurrent variations of the system at a single point in time) and time (sequential variations of the system due to its evolution). Recent research aims to address this need by managing variability in space and time simultaneously. However, such research often relies on nonuniform terminologies and a varying understanding of concepts, as it originates from different communities: software product-line engineering and software configuration management. These issues complicate the communication and comprehension of the concepts involved, impeding the development of techniques to unify variability in space and time. To tackle this problem, we performed an iterative, expert-driven analysis of existing tools to derive the first conceptual model that integrates and unifies terminologies and concepts of both dimensions of variability. In this paper, we present the unification process of concepts for variability in space and time, and the resulting conceptual model itself. We show that the conceptual model achieves high coverage and that its concepts are of appropriate granularity with respect to the tools for managing variability in space, time, or both that we considered. The conceptual model provides a well-defined, uniform terminology that empowers researchers and developers to compare their work, clarifies communication, and prevents redundant developments.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {15},
numpages = {12},
keywords = {product lines, revision management, variability, version control},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382025.3414967,
author = {Lima, Jackson A. Prado and Mendon\c{c}a, Willian D. F. and Vergilio, Silvia R. and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Learning-based prioritization of test cases in continuous integration of highly-configurable software},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414967},
doi = {10.1145/3382025.3414967},
abstract = {Continuous Integration (CI) is a practice widely adopted in the industry to allow frequent integration of code changes. During the CI process, many test cases are executed multiple times a day, subject to time constraints. In this scenario, a learning-based approach, named COLEMAN, has been successfully applied. COLEMAN allows earlier execution of the most promising test cases to reveal faults. This approach considers CI particularities such as time budget and volatility of test cases, related to the fact that test cases can be added/removed along the CI cycles. In the CI of Highly Configuration System (HCS), many product variants must be tested, each one with different configuration options, but having test cases that are common to or reused from other variants. In this context, we found, by analogy, another particularity, the volatility of variants, that is, some variants can be included/discontinued along CI cycles. Considering this context, this work introduces two strategies for the application of COLEMAN in the CI of HCS: the Variant Test Set Strategy (VTS) that relies on the test set specific for each variant, and the Whole Test Set Strategy (WST) that prioritizes the test set composed by the union of the test cases of all variants. Both strategies are evaluated in a real-world HCS, considering three test budgets. The results show that the proposed strategies are applicable regarding the time spent for prioritization. They perform similarly regarding early fault detection, but WTS better mitigates the problem of beginning without knowledge, and is more suitable when a new variant to be tested is added.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {31},
numpages = {11},
keywords = {continuous integration, family of products, software product line, test case prioritization},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/CCGrid.2016.89,
author = {Imai, Shigeru and Patterson, Stacy and Varela, Carlos A.},
title = {Cost-efficient elastic stream processing using application-agnostic performance prediction},
year = {2016},
isbn = {9781509024520},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2016.89},
doi = {10.1109/CCGrid.2016.89},
abstract = {Cloud computing adds great on-demand scalability to stream processing systems with its pay-per-use cost model. However, to promise service level agreements to users while keeping resource allocation cost low is a challenging task due to uncertainties coming from various sources, such as the target application's scalability, future computational demand, and the target cloud infrastructure's performance variability. To deal with these uncertainties, it is essential to create accurate application performance prediction models. In cloud computing, the current state of the art in performance modelling remains application-specific. We propose an application-agnostic performance modeling that is applicable to a wide range of applications. We also propose an extension to probabilistic performance prediction. This paper reports the progress we have made so far.},
booktitle = {Proceedings of the 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {604–607},
numpages = {4},
keywords = {cloud computing, performance prediction, resource allocation},
location = {Cartagena, Columbia},
series = {CCGRID '16}
}

@article{10.1007/s10732-017-9333-1,
author = {Herrmann, Sebastian and Ochoa, Gabriela and Rothlauf, Franz},
title = {PageRank centrality for performance prediction: the impact of the local optima network model},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1381-1231},
url = {https://doi.org/10.1007/s10732-017-9333-1},
doi = {10.1007/s10732-017-9333-1},
abstract = {A local optima network (LON) compresses relevant features of fitness landscapes in a complex network, where nodes are local optima and edges represent transition probabilities between different basins of attraction. Previous work has found that the PageRank centrality of local optima can be used to predict the success rate and average fitness achieved by local search based metaheuristics. Results are available for LONs where edges describe either basin transition probabilities or escape edges. This paper studies the interplay between the type of LON edges and the ability of the PageRank centrality for the resulting LON to predict the performance of local search based metaheuristics. It finds that LONs are stochastic models of the search heuristic. Thus, to achieve an accurate prediction, the definition of the LON edges must properly reflect the type of diversification steps used in the metaheuristic. LONs with edges representing basin transition probabilities capture well the diversification mechanism of simulated annealing which sometimes also accepts worse solutions that allow the search process to pass between basins. In contrast, LONs with escape edges capture well the diversification step of iterated local search, which escapes from local optima by applying a larger perturbation step.},
journal = {Journal of Heuristics},
month = jun,
pages = {243–264},
numpages = {22},
keywords = {Fitness landscape analysis, Local optima networks, NK landscapes, PageRank centrality, Search difficulty}
}

@inproceedings{10.1007/978-3-030-48340-1_46,
author = {Neumann, Philipp},
title = {Sparse Grid Regression for Performance Prediction Using High-Dimensional Run Time Data},
year = {2019},
isbn = {978-3-030-48339-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-48340-1_46},
doi = {10.1007/978-3-030-48340-1_46},
abstract = {We employ sparse grid regression to predict the run time in three types of numerical simulation: molecular dynamics (MD), weather and climate simulation. The impact of algorithmic, OpenMP/MPI and hardware-aware optimization parameters on performance is studied. We show that normalization of run time data via algorithmic complexity arguments significantly improves prediction accuracy. Mean relative prediction errors are in the range of few percent; in MD, a five-dimensional parameter space exploration results in mean relative prediction errors of ca. 15% using ca. 178 run time samples.},
booktitle = {Euro-Par 2019: Parallel Processing Workshops: Euro-Par 2019 International Workshops, G\"{o}ttingen, Germany, August 26–30, 2019, Revised Selected Papers},
pages = {601–612},
numpages = {12},
keywords = {Performance modeling, Sparse grids, Regression},
location = {G\"{o}ttingen, Germany}
}

@article{10.1016/j.jss.2021.111028,
author = {Cheng, Guoli and Ying, Shi and Wang, Bingming},
title = {Tuning configuration of apache spark on public clouds by combining multi-objective optimization and performance prediction model},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111028},
doi = {10.1016/j.jss.2021.111028},
journal = {J. Syst. Softw.},
month = oct,
numpages = {15},
keywords = {Spark, Configuration tuning, Multi-objective optimization}
}

@inproceedings{10.1145/3461002.3473940,
author = {Sundermann, Chico and He\ss{}, Tobias and Engelhardt, Dominik and Arens, Rahel and Herschel, Johannes and Jedelhauser, Kevin and Jutz, Benedikt and Krieter, Sebastian and Schaefer, Ina},
title = {Integration of UVL in FeatureIDE},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473940},
doi = {10.1145/3461002.3473940},
abstract = {Variability models are prevalent for specifying the commonalities and variabilities of configurable systems. A large variety of tools support using, editing, and analyzing variability models. However, the different tools often depend on distinct textual notations to store and read variability models which induces a large effort for researchers and practitioners. This additional effort could be reduced if the community adopted a single format. Following the goal of the MODEVAR initiative to develop a widely adopted variability language, we provided a first proposal with the Universal Variability language (UVL) in previous work. For a textual format to be adopted, an important aspect is an as small as possible effort when integrating the format in other tools. In this work, we discuss the integration of UVL in FeatureIDE. We use the integration to examine the applicability of UVL and our parser library to existing tools and gather further requirements for the language design. Furthermore, we provide a thorough documentation on the implementation to be used as reference and guidance for integration in other tools.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {73–79},
numpages = {7},
keywords = {exchange format, software product lines, unified language, variability language, variability modeling},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.advengsoft.2017.07.007,
author = {Deng, Hongying and Liu, Yi and Li, Ping and Zhang, Shengchang},
title = {Whole flow field performance prediction by impeller parameters of centrifugal pumps using support vector regression},
year = {2017},
issue_date = {December 2017},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {114},
number = {C},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2017.07.007},
doi = {10.1016/j.advengsoft.2017.07.007},
abstract = {A novel empirical model is proposed to predict the multiple performance indices of the whole flow field using related impeller parameters of centrifugal pumps.The complex nonlinearity relationship between multiple impeller parameters and performance indices can be described approximately.It is demonstrated by the performance prediction of the whole flow field for the D82-19-2 centrifugal mine pump.Compared with the computational fluid dynamics numerical simulation model, the higher prediction accuracy, more reliability prediction performance and less design time can be obtained. The relationship of multiple impeller parameters and performance indices is difficult to describe because of some unknown hydrodynamic phenomena. Modeling of performance indices of the whole flow field from impeller parameters often encounters some challenges, especially lower prediction accuracy in relatively small and large flow points, dependence on designers experience and time-consuming designing process. In this work, the least squares support vector regression (LSSVR) method is proposed to predict multiple pump performance indices of the whole flow field. To describe the performance more completely, the powder, the head, and the efficiency indices are chosen as the model outputs. Additionally, to improve the prediction accuracy and reduce the manufacture difficulty, nine impeller parameters and the flow rate are selected as the model inputs. With the LSSVR model, the complex nonlinearity relationship between multiple impeller parameters and performance indices can be described approximately. Moreover, the LSSVR model and the computational fluid dynamics numerical simulation model are applied to predict the powder, the head, and the efficiency of an actual centrifugal mine pump in the whole flow field. Compared with the performance test results, the superiority of the proposed method is demonstrated in terms of more accurate prediction performance and faster designing process.},
journal = {Adv. Eng. Softw.},
month = dec,
pages = {258–267},
numpages = {10},
keywords = {Centrifugal pump, Impeller parameter, Performance prediction, Support vector regression, Whole flow field}
}

@inproceedings{10.1145/3382026.3431252,
author = {Michelon, Gabriela Karoline},
title = {Evolving System Families in Space and Time},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431252},
doi = {10.1145/3382026.3431252},
abstract = {Managing the evolution of system families in space and time, i.e., system variants and their revisions is still an open challenge. The software product line (SPL) approach can support the management of product variants in space by reusing a common set of features. However, feature changes over time are often necessary due to adaptations and/or bug fixes, leading to different product versions. Such changes are commonly tracked in version control systems (VCSs). However, VCSs only deal with the change history of source code, and, even though their branching mechanisms allow to develop features in isolation, VCS does not allow propagating changes across variants. Variation control systems have been developed to support more fine-grained management of variants and to allow tracking of changes at the level of files or features. However, these systems are also limited regarding the types and granularity of artifacts. Also, they are cognitively very demanding with increasing numbers of revisions and variants. Furthermore, propagating specific changes over variants of a system is still a complex task that also depends on the variability-aware change impacts. Based on these existing limitations, the goal of this doctoral work is to investigate and define a flexible and unified approach to allow an easy and scalable evolution of SPLs in space and time. The expected contributions will aid the management of SPL products and support engineers to reason about the potential impact of changes during SPL evolution. To evaluate the approach, we plan to conduct case studies with real-world SPLs.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {104–111},
numpages = {8},
keywords = {feature-oriented software development, software evolution, software product lines, version control systems},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@article{10.1016/j.procs.2018.05.018,
author = {Ashraf, Mudasir and Zaman, Majid and Ahmed, Muheet},
title = {Using Ensemble StackingC Method and Base Classifiers to Ameliorate Prediction Accuracy of Pedagogical Data},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.018},
doi = {10.1016/j.procs.2018.05.018},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1021–1040},
numpages = {20},
keywords = {Ensemble, RandomForest, RandomTree, SMOTE, StackingC}
}

@inproceedings{10.1145/3461002.3473071,
author = {Beek, Maurice H. ter and Mazzanti, Franco and Damiani, Ferruccio and Paolini, Luca and Scarso, Giordano and Valfr\`{e}, Michele and Lienhardt, Michael},
title = {Static analysis and family-based model checking of featured transition systems with VMC},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473071},
doi = {10.1145/3461002.3473071},
abstract = {A Featured Transition System (FTS) is a formalism for modeling variability in configurable system behavior. The behavior of all variants (products) is modeled in a single compact FTS by associating the possibility to perform an action and transition from one state to another with feature expressions that condition the execution of an action in specific variants. We present a front-end for the research tool VMC. The resulting toolchain allows a modeler to analyze an FTS for ambiguities (dead or false optional transitions and hidden deadlock states), transform an ambiguous FTS into an unambiguous one, and perform an efficient kind of family-based verification of an FTS without hidden deadlock states. We use benchmarks from the literature to demonstrate the novelties offered by the toolchain.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {24–27},
numpages = {4},
keywords = {FTS, MTS, SPL, VMC, formal verification, static analysis, variability},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/2815782.2815799,
author = {Schaefer, Ina and Seidl, Christoph and Cleophas, Loek and Watson, Bruce W.},
title = {SPLicing TABASCO: Custom-Tailored Software Product Line Variants from Taxonomy-Based Toolkits},
year = {2015},
isbn = {9781450336833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815782.2815799},
doi = {10.1145/2815782.2815799},
abstract = {Taxonomy-Based Software Construction (TABASCO) applies extensive domain analyses to create conceptual hierarchies of algorithmic domains. Those are used as basis for the implementation of software toolkits. The monolithic structure of TABASCO-based toolkits restricts their adoption on resource-constrained or special-purpose devices. In this paper, we address this problem by applying Software Product Line (SPL) techniques to TABASCO-based toolkits: We use software taxonomies as input to creating a conceptual representation of variability as feature models of an SPL. We apply the variability realization mechanism delta modeling to transform realization artifacts, such as source code, to only contain elements for a particular selection of features. Our method is suitable for proactive, reactive and extractive SPL development so that it supports a seamless adoption and evolution of an SPL approach for TABASCO-based toolkits. We demonstrate the feasibility of the method with three case studies by proactively, reactively and extractively transforming TABASCO-based toolkits to SPLs, which allow derivation of variants with custom-tailored functionality.},
booktitle = {Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists},
articleno = {34},
numpages = {10},
keywords = {Software Product Line (SPL) adoption, Taxonomy-Based Software Construction (TABASCO) toolkit},
location = {Stellenbosch, South Africa},
series = {SAICSIT '15}
}

@inproceedings{10.5555/3504035.3504332,
author = {Su, Yu and Liu, Qingwen and Liu, Qi and Huang, Zhenya and Yin, Yu and Chen, Enhong and Ding, Chris and Wei, Si and Hu, Guoping},
title = {Exercise-enhanced sequential modeling for student performance prediction},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {In online education systems, for offering proactive services to students (e.g., personalized exercise recommendation), a crucial demand is to predict student performance (e.g., scores) on future exercising activities. Existing prediction methods mainly exploit the historical exercising records of students, where each exercise is usually represented as the manually labeled knowledge concepts, and the richer information contained in the text descriptions of exercises is still underex-plored. In this paper, we propose a novel Exercise-Enhanced Recurrent Neural Network (EERNN) framework for student performance prediction by taking full advantage of both student exercising records and the text of each exercise. Specifically, for modeling the student exercising process, we first design a bidirectional LSTM to learn each exercise representation from its text description without any expertise and information loss. Then, we propose a new LSTM architecture to trace student states (i.e., knowledge states) in their sequential exercising process with the combination of exercise representations. For making final predictions, we design two strategies under EERNN, i.e., EERNNM with Markov property and EERNNA with Attention mechanism. Extensive experiments on large-scale real-world data clearly demonstrate the effectiveness of EERNN framework. Moreover, by incorporating the exercise correlations, EERNN can well deal with the cold start problems from both student and exercise perspectives.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {297},
numpages = {9},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1109/CCGRID.2017.47,
author = {Wang, Jonathan and Yoo, Wucherl and Sim, Alex and Nugent, Peter and Wu, Kesheng},
title = {Parallel Variable Selection for Effective Performance Prediction},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.47},
doi = {10.1109/CCGRID.2017.47},
abstract = {Large data analysis problems often involve a large number of variables, and the corresponding analysis algorithms may examine all variable combinations to find the optimal solution. For example, to model the time required to complete a scientific workflow, we need to consider the impact of dozens of parameters. To reduce the model building time and reduce the likelihood of overfitting, we look to variable selection methods to identify the critical variables for the performance model. In this work, we create a combination of variable selection and performance prediction methods that is as effective as the exhaustive search approach when the exhaustive search could be completed in a reasonable amount of time. To handle the cases where the exhaustive search is too time consuming, we develop the parallelized variable selection algorithm. Additionally, we develop a parallel grouping mechanism that further reduces the variable selection time by 70%.As a case study, we exercise the variable selection technique with the performance measurement data from the Palomar Transient Factory (PTF) workflow. The application scientists have determined that about 50 variables and parameters are important to the performance of the workflows. Our tests show that the Sequential Backward Selection algorithm is able to approximate the optimal subset relatively quickly. By reducing the number of variables used to build the model from 50 to 4, we are able to maintain the prediction quality while reducing the model building time by a factor of 6. Using the parallelization and grouping techniques we developed in this work, the variable selection process was reduced from over 18 hours to 15 minutes while ending up with the same variable subset.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {208–217},
numpages = {10},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@article{10.1007/s00521-021-05962-3,
author = {Huang, Chenxi and Zhou, Junsheng and Chen, Jinling and Yang, Jane and Clawson, Kathy and Peng, Yonghong},
title = {A feature weighted support vector machine and artificial neural network algorithm for academic course performance prediction},
year = {2021},
issue_date = {Jun 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05962-3},
doi = {10.1007/s00521-021-05962-3},
abstract = {Academic performance, a globally understood metric, is utilized worldwide across disparate teaching and learning environments and is regarded as a quantifiable indicator of learning gain. The ability to reliably estimate student’s academic performance is important and can assist academic staff to improve the provision of support. However, it is recognized that academic performance estimation is non-trivial and affected by multiple factors, including a student’s engagement with learning activities and their social, geographic, and demographic characteristics. This paper investigates the opportunity to develop reliable models for predicting student performance using Artificial Intelligence. Specifically, we propose two-step academic performance prediction using feature weighted support vector machine and artificial neural network (ANN) learning. A feature weighted SVM, where the importance of different features to the outcome is calculated using information gain ratios, is employed to perform coarse-grained binary classification (pass, P1, or fail, P0). Subsequently, detailed score levels are divided from D to A+, and ANN learning is employed for fine-grained, multi-class training of the P1 and P0 classes separately. The experiments and our subsequent ablation study, which are conducted on the student datasets from two Portuguese secondary schools, have proved the effectiveness of this hybridized method.},
journal = {Neural Comput. Appl.},
month = apr,
pages = {11517–11529},
numpages = {13},
keywords = {Artificial intelligence, Academic performance analytics, Feature weighted SVM (FWSVM), Information gain ratio, ANN}
}

@article{10.1007/s00466-017-1448-6,
author = {Hu, Zhen and Mahadevan, Sankaran and Ao, Dan},
title = {Uncertainty aggregation and reduction in structure---material performance prediction},
year = {2018},
issue_date = {February  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {61},
number = {1–2},
issn = {0178-7675},
url = {https://doi.org/10.1007/s00466-017-1448-6},
doi = {10.1007/s00466-017-1448-6},
abstract = {An uncertainty aggregation and reduction framework is presented for structure---material performance prediction. Different types of uncertainty sources, structural analysis model, and material performance prediction model are connected through a Bayesian network for systematic uncertainty aggregation analysis. To reduce the uncertainty in the computational structure---material performance prediction model, Bayesian updating using experimental observation data is investigated based on the Bayesian network. It is observed that the Bayesian updating results will have large error if the model cannot accurately represent the actual physics, and that this error will be propagated to the predicted performance distribution. To address this issue, this paper proposes a novel uncertainty reduction method by integrating Bayesian calibration with model validation adaptively. The observation domain of the quantity of interest is first discretized into multiple segments. An adaptive algorithm is then developed to perform model validation and Bayesian updating over these observation segments sequentially. Only information from observation segments where the model prediction is highly reliable is used for Bayesian updating; this is found to increase the effectiveness and efficiency of uncertainty reduction. A composite rotorcraft hub component fatigue life prediction model, which combines a finite element structural analysis model and a material damage model, is used to demonstrate the proposed method.},
journal = {Comput. Mech.},
month = feb,
pages = {237–257},
numpages = {21},
keywords = {Bayesian calibration, Life prediction, Model validation, Uncertainty aggregation, Uncertainty reduction}
}

@inproceedings{10.1145/2934466.2962728,
author = {Santos, Alcemir Rodrigues and Machado, Ivan do Carmo and de Almeida, Eduardo Santana},
title = {RiPLE-HC: visual support for features scattering and interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2962728},
doi = {10.1145/2934466.2962728},
abstract = {With the ever increasing popularity of JavaScript in different domains to build bigger and more complex software systems, variability management may be deemed as an affordable strategy. In this sense, Software Product Lines (SPL) engineering is one of the most successful paradigms to accomplish the necessary modularity and systematic reuse of code artifacts for that purpose. In previous work, we present tool support to hybrid composition of JavaScript-based product lines, called RiPLE-HC, which we now extend to incorporate a means to deal with feature interactions and feature annotation scattering in a more smooth way. The proposed tool support may provide practitioners with an easy-to-use approach to implement crosscutting features by increasing the awareness of the developers about the features implementation.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {320–323},
numpages = {4},
keywords = {eclipse plugin, feature scattering visualization, featureide, javascript, software product line engineering},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382026.3425769,
author = {Nieke, Michael and Sampaio, Gabriela and Th\"{u}m, Thomas and Seidl, Christoph and Teixeira, Leopoldo and Schaefer, Ina},
title = {GuyDance: Guiding Configuration Updates for Product-Line Evolution},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425769},
doi = {10.1145/3382026.3425769},
abstract = {A product line is an approach for systematically managing configuration options of customizable systems, usually by means of features. Products are generated by utilizing configurations consisting of selected features. Product-line evolution can lead to unintended changes to product behavior. We illustrate that updating configurations after product-line evolution requires decisions of both, domain engineers responsible for product-line evolution as well as application engineers responsible for configurations. The challenge is that domain and application engineers might not be able to talk to each other. We propose a formal foundation and a methodology that enables domain engineers to guide application engineers through configuration evolution by sharing knowledge on product-line evolution and by defining configuration update operations. As an effect, we enable knowledge transfer between those engineers without the need to talk to each other. We evaluate our method by providing formal proofs that show product behavior of configurations can be preserved for typical evolution scenarios.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {56–64},
numpages = {9},
keywords = {configuration, evolution, software product line},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/CCNC.2019.8651839,
author = {Beye, Florian and Shinohara, Yusuke and Shimonishi, Hideyuki},
title = {Towards Accurate and Scalable Performance Prediction for Automated Service Design in NFV},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCNC.2019.8651839},
doi = {10.1109/CCNC.2019.8651839},
abstract = {Automatizing the process of designing communication services in network function virtualization (NFV) is important because it may reduce provisioning time and lead to more efficient designs. The design process involves solving performance constraints imposed by service level agreements (SLAs), which in turn requires accurate and fast performance prediction. However, effects such as resource contention make performance prediction in virtualized environments challenging when large numbers of possible combinations of software and hardware are considered. The key to scalability lies in finding a componentized approach that reduces the number of model degrees of freedom while still allowing high accuracy. In this work, we propose a componentized approach based on feed-forward networks that are composited from software and hardware models. Model parameter data is obtained from a machine learning technique which is fed using data generated from automatized offline performance measurements. An evaluation showed that our technology achieves a prediction accuracy close to 95% and prediction evaluation times of a few milliseconds.},
booktitle = {2019 16th IEEE Annual Consumer Communications &amp; Networking Conference (CCNC)},
pages = {1–7},
numpages = {7},
location = {Las Vegas, NV, USA}
}

@article{10.1007/s10664-016-9462-4,
author = {Assun\c{c}\~{a}o, Wesley K. and Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Vergilio, Silvia R. and Egyed, Alexander},
title = {Multi-objective reverse engineering of variability-safe feature models based on code dependencies of system variants},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9462-4},
doi = {10.1007/s10664-016-9462-4},
abstract = {Maintenance of many variants of a software system, developed to supply a wide range of customer-specific demands, is a complex endeavour. The consolidation of such variants into a Software Product Line is a way to effectively cope with this problem. A crucial step for this consolidation is to reverse engineer feature models that represent the desired combinations of features of all the available variants. Many approaches have been proposed for this reverse engineering task but they present two shortcomings. First, they use a single-objective perspective that does not allow software engineers to consider design trade-offs. Second, they do not exploit knowledge from implementation artifacts. To address these limitations, our work takes a multi-objective perspective and uses knowledge from source code dependencies to obtain feature models that not only represent the desired feature combinations but that also check that those combinations are indeed well-formed, i.e. variability safe. We performed an evaluation of our approach with twelve case studies using NSGA-II and SPEA2, and a single-objective algorithm. Our results indicate that the performance of the multi-objective algorithms is similar in most cases and that both clearly outperform the single-objective algorithm. Our work also unveils several avenues for further research.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1763–1794},
numpages = {32},
keywords = {Empirical evaluation, Feature models, Multi-objective evolutionary algorithms, Reverse engineering}
}

@inproceedings{10.1145/3337682.3337709,
author = {Zhang, Fan},
title = {Development of a Performance Prediction Model for College Athletes Based on Chaos Theory and Machine Learning Algorithms},
year = {2019},
isbn = {9781450372008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337682.3337709},
doi = {10.1145/3337682.3337709},
abstract = {In order to accurately predict college athlete's performance, a prediction model of college athlete's performance based on Chaos Theory and machine learning algorithm is designed according to the specific characteristics of college athlete's performance. Firstly, the current research status of college athlete performance modeling and prediction is analyzed, and the shortcomings of current college athlete performance prediction model are found. Then, the chaos theory is used to process the historical data of college athlete performance, and the hidden rules are found. Finally, the machine learning algorithm, extreme learning machine, is introduced to design the college athlete performance prediction model. The simulation results show that, compared with the current college athlete performance prediction model, the results of the designed model are more reliable, and the accuracy of college athlete performance prediction is higher, which can be applied to the formulation of sports scientific training plan.},
booktitle = {Proceedings of the 2019 5th International Conference on Education and Training Technologies},
pages = {146–150},
numpages = {5},
keywords = {chaos theory, college athletes performance, extreme learning machine, initial data, machine learning algorithm, performance prediction model},
location = {Seoul, Republic of Korea},
series = {ICETT '19}
}

@inproceedings{10.1145/3382025.3414973,
author = {Schlie, Alexander and Kn\"{u}ppel, Alexander and Seidl, Christoph and Schaefer, Ina},
title = {Incremental feature model synthesis for clone-and-own software systems in MATLAB/Simulink},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414973},
doi = {10.1145/3382025.3414973},
abstract = {Families of related MATLAB/Simulink systems commonly emerge ad hoc using clone-and-own practices. Extractively migrating systems towards a software product line (SPL) can be a remedy. A feature model (FM) represents all potential configurations of an SPL, ideally, in non-technical domain terms. However, yielding a sensible FM from automated synthesis remains a major challenge due to domain knowledge being a prerequisite for features to be adequate abstractions. In incremental reverse engineering, subsequent generation of FMs may further overwrite changes and design decisions made during previous manual FM refinement.In this paper, we propose an approach to largely automate the synthesis of a suitable FM from a set of cloned MATLAB/Simulink models as part of reverse engineering an SPL. We fully automate the extraction of an initial, i.e., a technical, FM that closely aligns with realization artifacts and their variability, and further provide operations to manually refine it to incorporate domain knowledge. Most importantly, we provide concepts to capture such operations and to replay them on a structurally different technical FM stemming from a subsequent reverse engineering increment that included further systems of the portfolio. We further provide an implementation and demonstrate the feasibility of our approach using two MATLAB/Simulink data sets from the automotive domain.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {7},
numpages = {12},
keywords = {150% model, MATLAB/Simulink, clone-and-own, feature model, incremental, individual, mapping, refinement, synthesis, variability},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2739480.2754720,
author = {Assun\c{c}\~{a}o, Wesley K.G. and Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Vergilio, Silvia R. and Egyed, Alexander},
title = {Extracting Variability-Safe Feature Models from Source Code Dependencies in System Variants},
year = {2015},
isbn = {9781450334723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739480.2754720},
doi = {10.1145/2739480.2754720},
abstract = {To effectively cope with increasing customization demands, companies that have developed variants of software systems are faced with the challenge of consolidating all the variants into a Software Product Line, a proven development paradigm capable of handling such demands. A crucial step in this challenge is to reverse engineer feature models that capture all the required feature combinations of each system variant. Current research has explored this task using propositional logic, natural language, and search-based techniques. However, using knowledge from the implementation artifacts for the reverse engineering task has not been studied. We propose a multi-objective approach that not only uses standard precision and recall metrics for the combinations of features but that also considers variability-safety, i.e. the property that, based on structural dependencies among elements of implementation artifacts, asserts whether all feature combinations of a feature model are in fact well-formed software systems. We evaluate our approach with five case studies and highlight its benefits for the software engineer.},
booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1303–1310},
numpages = {8},
keywords = {feature models, multi-objective evolutionary algorithms, reverse engineering},
location = {Madrid, Spain},
series = {GECCO '15}
}

@inproceedings{10.1145/3461002.3473066,
author = {Fortz, Sophie},
title = {LIFTS: learning featured transition systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473066},
doi = {10.1145/3461002.3473066},
abstract = {This PhD project aims to automatically learn transition systems capturing the behaviour of a whole family of software-based systems. Reasoning at the family level yields important economies of scale and quality improvements for a broad range of systems such as software product lines, adaptive and configurable systems. Yet, to fully benefit from the above advantages, a model of the system family's behaviour is necessary. Such a model is often prohibitively expensive to create manually due to the number of variants. For large long-lived systems with outdated specifications or for systems that continuously adapt, the modelling cost is even higher. Therefore, this PhD proposes to automate the learning of such models from existing artefacts. To advance research at a fundamental level, our learning target are Featured Transition Systems (FTS), an abstract formalism that can be used to provide a pivot semantics to a range of variability-aware state-based modelling languages. The main research questions addressed by this PhD project are: (1) Can we learn variability-aware models efficiently? (2) Can we learn FTS in a black-box fashion? (i.e., with access to execution logs but not to source code); (3) Can we learn FTS in a white/grey-box testing fashion? (i.e., with access to source code); and (4) How do the proposed techniques scale in practice?},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {1–6},
numpages = {6},
keywords = {active automata learning, featured transition systems, model learning, software product lines, variability mining},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3281375.3281403,
author = {Chanlekha, Hutchatai and Niramitranon, Jitti},
title = {Student performance prediction model for early-identification of at-risk students in traditional classroom settings},
year = {2018},
isbn = {9781450356220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281375.3281403},
doi = {10.1145/3281375.3281403},
abstract = {Student performance prediction is one of the educational data mining tasks that has received great deal of attentions. It enables the educators to improve the quality and effectiveness of classroom management and to help students achieve better academic performance. However, one of the major challenges in developing a prediction model in a traditional classroom setting is the limited amount of information available to be used as student attributes. In this research, we focus on developing a performance prediction models in information-lacking environment for identifying at-risk students who have tendency to receive low grades. To construct the models, five algorithms with different learning paradigms were investigated. The constructed models were evaluated on 5 different subjects. The results have shown that even though the prediction performances for the subjects that less depended on acquirable previous performance information were quite low, the performances for the subjects offered during higher year of the educational program were quite promising.},
booktitle = {Proceedings of the 10th International Conference on Management of Digital EcoSystems},
pages = {239–245},
numpages = {7},
keywords = {data analytics, educational data mining, student performance prediction, traditional classroom},
location = {Tokyo, Japan},
series = {MEDES '18}
}

@inproceedings{10.1109/HPCC-CSS-ICESS.2015.243,
author = {Flores-Contreras, Jesus and Ruiz, Carlos and Salazar, Pablo and Duran-Limon, Hector A. and Mezura-Montes, Efren and Cruz-Ramirez, Nicandro and Acosta-Mesa, H\'{e}ctor-Gabriel},
title = {A Performance Prediction Model for Database Environments: A Preliminary Analysis},
year = {2015},
isbn = {9781479989379},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HPCC-CSS-ICESS.2015.243},
doi = {10.1109/HPCC-CSS-ICESS.2015.243},
abstract = {Properly addressing the performance issues presented in database systems is and has been a significant technological challenge, this due to the uncontrolled fluctuation of user requests. Being able to predict the behaviour of such systems can greatly improve their performance. Several prediction methods, such as linear regression and autoregressive moving average, among others, have extensively been used to predict performance in shared environments where a workload is involved. However, not all them produce accurate predictions when the system is working under different workloads. In this paper, we present our preliminary results on exploring the accuracy of two different approaches (exact and approximate methods) used to predict the response time of a database system subject to different workloads in a controlled environment. Our results show that approximate methods present better prediction accuracy when compared to exact methods. Hence, we consider the main contributions of this work the following: a) the results obtained from comparing exact and approximate methods, since they can be used as a basis for further works addressing similar problems, and b) a preliminary prediction model also based on our findings.},
booktitle = {Proceedings of the 2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conf on Embedded Software and Systems},
pages = {1707–1712},
numpages = {6},
keywords = {Approximate methods, Databases, Exact methods, Performance prediction, System workload},
series = {HPCC-CSS-ICESS '15}
}

@inproceedings{10.1007/978-3-030-38778-5_29,
author = {Shen, Yingshan and Liu, Weiwei and Wu, Qiumei and Chen, Ruiyang and Liu, Kui},
title = {Leveraging Neural Network for Online Learning Performance Prediction and Learning Suggestion},
year = {2019},
isbn = {978-3-030-38777-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38778-5_29},
doi = {10.1007/978-3-030-38778-5_29},
abstract = {Learning performance analysis is such a research field that draws much attention from researchers though it has just been emerged in recent years. On the one hand, analyzing learning behaviors can help learners to choose their learning methods and allocate their study time in a more appropriate way. On the other hand, learning analysis can provide valuable feedbacks for teachers and administrators to improve teaching efficiency and quality. This paper studies and analyzes more than 640,000 learning data from the MOOC platform edX. A tree-based model along with an information gain measure is applied to identify the usefulness of data features. A back-propagation neural network model is further adopted to train data and achieve a prediction model of learning performance. In addition, a genetic algorithm calculates learning score conditions and return feedbacks as suggestions to learners. Experiment results demonstrate the effectiveness of the utilization of the methods in the predication of online learning performance.},
booktitle = {Emerging Technologies for Education: 4th International Symposium, SETE 2019, Held in Conjunction with ICWL 2019, Magdeburg, Germany, September 23–25, 2019, Revised Selected Papers},
pages = {267–279},
numpages = {13},
keywords = {Neural network, Genetic algorithm, Learning prediction, Suggestion},
location = {Magdeburg, Germany}
}

@inproceedings{10.1145/3030207.3030216,
author = {Valov, Pavel and Petkovich, Jean-Christophe and Guo, Jianmei and Fischmeister, Sebastian and Czarnecki, Krzysztof},
title = {Transferring Performance Prediction Models Across Different Hardware Platforms},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3030216},
doi = {10.1145/3030207.3030216},
abstract = {Many software systems provide configuration options relevant to users, which are often called features. Features influence functional properties of software systems as well as non-functional ones, such as performance and memory consumption. Researchers have successfully demonstrated the correlation between feature selection and performance. However, the generality of these performance models across different hardware platforms has not yet been evaluated.We propose a technique for enhancing generality of performance models across different hardware environments using linear transformation. Empirical studies on three real-world software systems show that our approach is computationally efficient and can achieve high accuracy (less than 10% mean relative error) when predicting system performance across 23 different hardware platforms. Moreover, we investigate why the approach works by comparing performance distributions of systems and structure of performance models across different platforms.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {39–50},
numpages = {12},
keywords = {linear transformation, model transfer, performance modelling, regression trees},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@article{10.1155/2021/2157343,
author = {Liu, Jinyang and Yin, Chuantao and Li, Yuhang and Sun, Honglu and Zhou, Hong and Ye, Yinghui},
title = {Deep Learning and Collaborative Filtering-Based Methods for Students’ Performance Prediction and Course Recommendation},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/2157343},
doi = {10.1155/2021/2157343},
abstract = {At the beginning of a new semester, due to the limited understanding of the new courses, it is difficult for students to make predictive choices about the courses of the current semester. In order to help students solve this problem, this paper proposed a hybrid prediction model based on deep learning and collaborative filtering. The proposed model can automatically generate personalized suggestions about courses in the next semester to assist students in course selection. The two important tasks of this study are course recommendation and student ranking prediction. First, we use a user-based collaborative filtering model to give a list of recommended courses by calculating the similarity between users. Then, for the courses in the list, we use a hybrid prediction model to predict the student’s performance in each course, that is, ranking prediction. Finally, we will give a list of courses that the student is good at or not good at according to the predicted ranking of the courses. Our method is evaluated on students’ data from two departments of our university. Through experiments, we compared the hybrid prediction model with other nonhybrid models and confirmed the good effect of our model. By using our model, students can refer to the different recommendation lists given and choose courses that they may be interested in and good at. The proposed method can be widely applied in Internet of Things and industrial vocational learning systems.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {13}
}

@inproceedings{10.1109/ASE.2013.6693089,
author = {Guo, Jianmei and Czarnecki, Krzysztof and Apely, Sven and Siegmundy, Norbert and Wasowski, Andrzej},
title = {Variability-aware performance prediction: a statistical learning approach},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693089},
doi = {10.1109/ASE.2013.6693089},
abstract = {Configurable software systems allow stakeholders to derive program variants by selecting features. Understanding the correlation between feature selections and performance is important for stakeholders to be able to derive a program variant that meets their requirements. A major challenge in practice is to accurately predict performance based on a small sample of measured variants, especially when features interact. We propose a variability-aware approach to performance prediction via statistical learning. The approach works progressively with random samples, without additional effort to detect feature interactions. Empirical results on six real-world case studies demonstrate an average of 94% prediction accuracy based on small random samples. Furthermore, we investigate why the approach works by a comparative analysis of performance distributions. Finally, we compare our approach to an existing technique and guide users to choose one or the other in practice.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {301–311},
numpages = {11},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1145/2966986.2966997,
author = {Gupta, Ujjwal and Campbell, Joseph and Ogras, Umit Y. and Ayoub, Raid and Kishinevsky, Michael and Paterna, Francesco and Gumussoy, Suat},
title = {Adaptive performance prediction for integrated GPUs},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1145/2966986.2966997},
doi = {10.1145/2966986.2966997},
abstract = {Integrated GPUs have become an indispensable component of mobile processors due to the increasing popularity of graphics applications. The GPU frequency is a key factor both in application throughput and mobile processor power consumption under graphics workloads. Therefore, dynamic power management algorithms have to assess the performance sensitivity to the GPU frequency accurately. Since the impact of the GPU frequency on performance varies rapidly over time, there is a need for online performance models that can adapt to varying workloads. This paper presents a light-weight adaptive runtime performance model that predicts the frame processing time. We use this model to estimate the frame time sensitivity to the GPU frequency. Our experiments on a mobile platform running common GPU benchmarks show that the mean absolute percentage error in frame time and frame time sensitivity prediction are 3.8% and 3.9%, respectively.},
booktitle = {2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
pages = {1–8},
numpages = {8},
location = {Austin, TX, USA}
}

@inproceedings{10.1145/2866614.2866621,
author = {Capilla, Rafael and Bosch, Jan},
title = {Dynamic Variability Management Supporting Operational Modes of a Power Plant Product Line},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866621},
doi = {10.1145/2866614.2866621},
abstract = {Runtime variability is becoming an attractive technique to support those runtime scenarios for systems that demand some kind of autonomous reconfiguration or adaptive behavior. Nowadays, the challenge of many critical systems that need to handle different operational modes, often in an unattended mode, require specific solutions for which runtime variability mechanisms become relevant. This research describes the challenges of runtime variability to support multiple binding modes for handling the diversity of different operational modes and runtime reconfiguration needs. We validate our approach in a power plant control product line at Toshiba which advances previous work making the transition between the power plant operational modes more automatic and dynamic.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {49–56},
numpages = {8},
keywords = {Runtime variability, dynamic software product lines, multiple binding times, runtime reconfiguration},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@inproceedings{10.1145/3461001.3474452,
author = {He\ss{}, Tobias and Sundermann, Chico and Th\"{u}m, Thomas},
title = {On the scalability of building binary decision diagrams for current feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3474452},
doi = {10.1145/3461001.3474452},
abstract = {Binary decision diagrams (BDD) have been proposed for numerous product-line analyses. These analyses typically exploit properties unique to decision diagrams, such as negation in constant time and space. Furthermore, the existence of a BDD representing the configuration space of a product line removes the need to employ SAT or #SAT solvers for their analysis. Recent work has shown that the performance of state-of-the-art BDD libraries is significantly lower than previously reported and hypothesized. In this work, we provide an assessment of the state-of-the-art of BDD scalability in this domain and explain why previous results on the scalability of BDDs do not apply to more recent product-line instances.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {131–135},
numpages = {5},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1109/INFOCOM.2019.8737447,
author = {Li, Jian and Qian, Jianmin and Guan, Haibing},
title = {A Holistic Model for Performance Prediction and Optimization on NUMA-based Virtualized Systems},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/INFOCOM.2019.8737447},
doi = {10.1109/INFOCOM.2019.8737447},
abstract = {The non-uniform memory access (NUMA) architecture has become the dominant server architecture due to its scalable bandwidth performance. However, the NUMA architecture also introduces the complicated performance influences to the applications, because of the differentiated remote devices access latency and shared resource access contention. Secondly, quick developments of high speed networking devices make I/O resource be another important performance affecting element for I/O-intensive cloud applications on NUMA server. Thirdly, it is more critical in virtualized environment since all resources are managed uniformly and transparently to the VM, and the application behaviors in the VM are shielded from the Virtual Machine Manager (VMM). In this paper, we first give an analytic evaluation for performance influence from the various resource affinity. Motivated by the observations, we then build an accurate performance prediction model, named Resource Affinity performance Influence Estimation (RAIE). RAIE provides a novel performance prediction model with the holistic resource affinity parameters that are measured with the platform independent quantification approaches that need be executed in one-off manner. Moreover, RAIE model takes into account the actual influence of resource affinity according to the VM behaviours that can be monitored online without VM modification. Comprehensive evaluations prove that the RAIE model for a VM’s performance prediction can increase the average prediction accuracy by 3.27x on a 4node NUMA server with high speed Network Interface Cards (NIC). The RAIE guided scheduling case validates that it can achieve 2.1x performance improvement for actual VMM resource management servicing a VM running the dynamic applications.},
booktitle = {IEEE INFOCOM 2019 - IEEE Conference on Computer Communications},
pages = {352–360},
numpages = {9},
location = {Paris, France}
}

@article{10.1155/2021/5284457,
author = {Xu, Wei and Xiong, Wenying and Shao, Zhe and Li, Yun and Huang, Chenxi},
title = {Analysis of Effectiveness and Performance Prediction of Sports Flipped Classroom Teaching Based on Neural Networks},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/5284457},
doi = {10.1155/2021/5284457},
abstract = {Traditional physical education methods are unable to meet this requirement due to the practical nature of sports skill teaching. As a result, as the times demanded, the flipped classroom based on neural network technology arose. It has the potential to not only promote the modernization of physical education but also to ensure that it has a positive educational impact. This is a mode of instruction. Furthermore, colleges and universities are increasingly focusing on college students’ overall quality development. A method for predicting college students’ sports performance using a particle swarm optimization neural network is proposed to accurately predict sports performance and provide a reliable analysis basis for the establishment of sports teaching goals. Neural networks are used in the model. The particle swarm optimization algorithm optimizes the variance and weights of the neural network to improve the accuracy of college students’ sports performance predicted by the neural network by updating the particle position and speed through the two extreme values of individual extreme values and global extreme values. Teachers always play the role of the facilitator and helper in the teaching process, which realizes the transformation of teachers’ and students’ self-positioning, allows students to better play the lead role, and stimulates students’ interest in learning.},
journal = {Sci. Program.},
month = jan,
numpages = {7}
}

@inproceedings{10.1145/3336294.3336313,
author = {Fernandez-Amoros, David and Heradio, Ruben and Mayr-Dorn, Christoph and Egyed, Alexander},
title = {A Kconfig Translation to Logic with One-Way Validation System},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336313},
doi = {10.1145/3336294.3336313},
abstract = {Automated analysis of variability models is crucial for managing software system variants, customized for different market segments or contexts of use. As most approaches for automated analysis are built upon logic engines, they require having a Boolean logic translation of the variability models. However, the translation of some significant languages to Boolean logic is remarkably non-trivial. The contribution of this paper is twofold: first, a translation of the Kconfig language is presented; second, an approach to test the translation for any given model is provided. The proposed translation has been empirically tested with the introduced validation procedure on five open-source projects.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {303–308},
numpages = {6},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2396761.2398692,
author = {Kustarev, Andrey and Ustinovskiy, Yury and Mazur, Anna and Serdyukov, Pavel},
title = {Session-based query performance prediction},
year = {2012},
isbn = {9781450311564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396761.2398692},
doi = {10.1145/2396761.2398692},
abstract = {Search sessions are known to be a rich source of diverse valuable information for individual query analysis. In this paper, we address the problem of query performance prediction by utilizing the entire logical search sessions containing the given query. Guided by the intuitions based on the observations made after the analysis of the search sessions' properties and performance of the queries they contain, we propose a number of features that significantly advance the existing query performance prediction models. Some of them specifically allow to focus on tail queries with sparse click-through statistics.},
booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
pages = {2563–2566},
numpages = {4},
keywords = {query flow graph, query performance prediction, user sessions},
location = {Maui, Hawaii, USA},
series = {CIKM '12}
}

@article{10.1016/j.aei.2016.12.009,
author = {Zhang, Zi-jian and Gong, Lin and Jin, Yan and Xie, Jian and Hao, Jia},
title = {A quantitative approach to design alternative evaluation based on data-driven performance prediction},
year = {2017},
issue_date = {April 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {32},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2016.12.009},
doi = {10.1016/j.aei.2016.12.009},
abstract = {A systematic approach is proposed to quantitatively evaluate design alternatives.The judgments of designers are quantified in the vague and subjective environment.Obtains the optimal alternative based on the data-driven performance prediction.Strengthens efficiency and objectivity by reducing vagueness and human involvement. Design alternative evaluation in the early stages of engineering design plays an important role in determining the success of new product development, as it influences considerably the subsequent design activities. However, existing approaches to design alternative evaluation are overly reliant on experts ambiguous and subjective judgments and qualitative descriptions. To reduce subjectivity and improve efficiency of the evaluation process, this paper proposes a quantitative evaluation approach through data-driven performance predictions. In this approach, the weights of performance characteristics are determined based on quantitative assessment of expert judgments, and the ranking of design alternatives is achieved by predicting performance values based on historical product design data. The experts subjective and often vague judgments are captured quantitatively through a rough number based Decision-Making Trial and Evaluation Laboratory (DEMATEL) method. In order to facilitate performance based quantitative ranking of alternatives at the early stages of design where no performance calculation is possible, a particle swarm optimization based support vector machine (PSO-SVM) is applied for historical data based performance prediction. The final ranking of alternatives given the predicted values of multiple performance characteristics is achieved through Viekriterijumska Optimizacija I kompromisno Reenje (VIKOR). A case study is carried out to demonstrate the validity of the proposed approach.},
journal = {Adv. Eng. Inform.},
month = apr,
pages = {52–65},
numpages = {14},
keywords = {Data-driven, Design alternative evaluation, Performance prediction, Quantitative evaluation, Rough DEMATEL}
}

@inproceedings{10.1145/2491627.2491637,
author = {Kanda, Tetsuya and Ishio, Takashi and Inoue, Katsuro},
title = {Extraction of product evolution tree from source code of product variants},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491637},
doi = {10.1145/2491627.2491637},
abstract = {A large number of software products may be derived from an original single product. Although software product line engineering is advocated as an effective approach to maintaining such a family of products, re-engineering existing products requires developers to understand the evolution history of the products. This can be challenging because developers typically only have access to product source code. In this research, we propose to extract a Product Evolution Tree that approximates the evolution history from source code of products. Our key idea is that two successive products are the most similar to one another in the evolution history. We construct a Product Evolution Tree as a minimum spanning tree whose cost function is defined by the number of similar files between products. As an experiment, we extracted Product Evolution Trees from 6 datasets of open-source projects. The result showed that 53% to 92% of edges in the extracted trees were consistent with the actual evolution history of the projects.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {141–150},
numpages = {10},
keywords = {software evolution, software product line, visualization},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3461002.3473944,
author = {Ballesteros, Joaqu\'{\i}n and Fuentes, Lidia},
title = {Transfer learning for multiobjective optimization algorithms supporting dynamic software product lines},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473944},
doi = {10.1145/3461002.3473944},
abstract = {Dynamic Software Product Lines (DSPLs) are a well-accepted approach for self-adapting Cyber-Physical Systems (CPSs) at run-time. The DSPL approaches make decisions supported by performance models, which capture system features' contribution to one or more optimization goals. Combining performance models with Multi-Objectives Evolutionary Algorithms (MOEAs) as decision-making mechanisms is common in DSPLs. However, MOEAs algorithms start solving the optimization problem from a randomly selected population, not finding good configurations fast enough after a context change, requiring too many resources so scarce in CPSs. Also, the DSPL engineer must deal with the hardware and software particularities of the target platform in each CPS deployment. And although each system instantiation has to solve a similar optimization problem of the DSPL, it does not take advantage of experiences gained in similar CPS. Transfer learning aims at improving the efficiency of systems by sharing the previously acquired knowledge and applying it to similar systems. In this work, we analyze the benefits of transfer learning in the context of DSPL and MOEAs testing on 8 feature models with synthetic performance models. Results are good enough, showing that transfer learning solutions dominate up to 71% of the non-transfer learning ones for similar DSPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {51–59},
numpages = {9},
keywords = {cyber-physical systems, dynamic software product lines, multiobjective optimization algorithms, self-adaptation, transfer learning},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461002.3473946,
author = {Meixner, Kristof and Feichtinger, Kevin and Rabiser, Rick and Biffl, Stefan},
title = {A reusable set of real-world product line case studies for comparing variability models in research and practice},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473946},
doi = {10.1145/3461002.3473946},
abstract = {Real-world cases describing (product) variability in production systems are rare and often not accessible. Thus, researchers often use toy examples or develop fictitious case studies. These are designed to demonstrate their approach but rarely to compare multiple approaches. In this paper, we aim at making variability modeling evaluations comparable. We present and provide a reusable set of four real-world case studies that are easy to access, with artifacts represented in a universal, variability-model-agnostic way, the industrial Product-Process-Resource Domain-Specific Language (PPR DSL). We report how researchers can use the case studies, automatically transforming the Domain-Specific Language (DSL) artifacts to well-known variability models, e.g., product feature models, using the Variability Evolution Roundtrip Transformation (VERT) process. We compare the expressiveness and complexity of the transformed feature models. We argue that the case studies with the DSL and the flexible transformation capabilities build a valuable contribution to making future research results more comparable and facilitating evaluations with real-world product lines.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {105–112},
numpages = {8},
keywords = {case studies, cyber-physical production system, feature extraction, variability modeling},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3358528.3358558,
author = {Miao, Yuanyang and Lv, Shengli and Bao, Feihu},
title = {Long-Storage Performance Prediction Method for Complex Systems Based On Data Fusion},
year = {2019},
isbn = {9781450371926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358528.3358558},
doi = {10.1145/3358528.3358558},
abstract = {For a long time, the protection and maintenance of complex equipment system mainly adopts periodic inspection, maintenance and fault diagnosis and emergency repair during service. However, it can't evaluate and forecast the overall quality and long-storage performance of the system, which has many inconveniences for regular inspection and maintenance, and may affect the reliability of mechanical equipment. According to the structure and use characteristics of complex equipment system, the application software engineering idea and object-oriented programming method, a complex system data fusion software and method were developed using data fusion technology. The method can analyze the data of the material layer, the component layer and the system layer, and respectively fuse the data of each layer to realize the corrosion analysis and prediction of various complex mechanical systems. Using the missile tank system as an example, the feasibility and accuracy of the data fusion method are verified.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Technologies},
pages = {6–10},
numpages = {5},
keywords = {complex system, corrosion prediction, data fusion, missile tank},
location = {Jinan, China},
series = {ICBDT '19}
}

@inproceedings{10.1145/3336294.3336305,
author = {Fischer, Stefan and Ramler, Rudolf and Linsbauer, Lukas and Egyed, Alexander},
title = {Automating Test Reuse for Highly Configurable Software},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336305},
doi = {10.1145/3336294.3336305},
abstract = {Dealing with highly configurable systems is generally very complex. Hundreds of different analysis techniques have been conceived to deal with different aspects of configurable systems. One large focal point is the testing of configurable software. This is challenging due to the large number of possible configurations and because tests themselves are rarely configurable and instead built for specific configurations. Existing tests can usually not be reused on other configurations. Therefore, tests need to be adapted for the specific configuration they are supposed to test. In this paper we report on an experiment about reusing tests in a configurable system. We used manually developed tests for specific configurations of Bugzilla and investigated which of them could be reused for other configurations. Moreover, we automatically generated new test variants (by automatically reusing from existing ones) for combinations of previous configurations. Our results showed that we can directly reuse some tests for configurations which they were not intended for. Nonetheless, our automatically generated test variants generally yielded better results. When applying original tests to new configurations we found an average success rate for the tests of 81,84%. In contrast, our generated test variants achieved an average success rate of 98,72%. This is an increase of 16,88%.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {1–11},
numpages = {11},
keywords = {clone-and-own, configurable software, reuse, testing, variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342408,
author = {Schlie, Alexander and Rosiak, Kamil and Urbaniak, Oliver and Schaefer, Ina and Vogel-Heuser, Birgit},
title = {Analyzing Variability in Automation Software with the Variability Analysis Toolkit},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342408},
doi = {10.1145/3307630.3342408},
abstract = {Control software for automated production systems (aPs) becomes increasingly complex as it evolves due to changing requirements. To address varying customer demands or altered regulatory guidelines, it is common practice to create a new system variant by copying and subsequently modifying existing control software. Referred to as clone-and-own, proper documentation is typically not cherished, thereby entailing severe maintenance issues in the long-run. To mitigate such problems and to reinstate sustainable development, respective software systems need to be compared and their variability information needs to be reverse-engineered. However, recent work identified variability management in the domain of aPs to remain a challenging endevour and appropriate tool support to be missing.We bridge this gap and introduce the Variability Analysis Toolkit (VAT), an extensible platform that allows for the customizable definition of metrics to compare IEC61131-3 control software variants as well as providing means to visualize results. The VAT facilitates a working environment that allows for the exchange of produced results between users. By that, we aim to support engineers in re-engineering control software systems by providing them with means to define metrics based on their individual demands. We demonstrate the feasibility of the VAT using 24 software system variants implemented in accordance to the IEC61131-3 standard.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {191–198},
numpages = {8},
keywords = {automation software, legacy systems, software product lines, tooling, variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3336294.3336306,
author = {Ghamizi, Salah and Cordy, Maxime and Papadakis, Mike and Traon, Yves Le},
title = {Automated Search for Configurations of Convolutional Neural Network Architectures},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336306},
doi = {10.1145/3336294.3336306},
abstract = {Convolutional Neural Networks (CNNs) are intensively used to solve a wide variety of complex problems. Although powerful, such systems require manual configuration and tuning. To this end, we view CNNs as configurable systems and propose an end-to-end framework that allows the configuration, evaluation and automated search for CNN architectures. Therefore, our contribution is threefold. First, we model the variability of CNN architectures with a Feature Model (FM) that generalizes over existing architectures. Each valid configuration of the FM corresponds to a valid CNN model that can be built and trained. Second, we implement, on top of Tensorflow, an automated procedure to deploy, train and evaluate the performance of a configured model. Third, we propose a method to search for configurations and demonstrate that it leads to good CNN models. We evaluate our method by applying it on image classification tasks (MNIST, CIFAR-10) and show that, with limited amount of computation and training, our method can identify high-performing architectures (with high accuracy). We also demonstrate that we outperform existing state-of-the-art architectures handcrafted by ML researchers. Our FM and framework have been released to support replication and future research.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {119–130},
numpages = {12},
keywords = {AutoML, NAS, configuration search, feature model, neural architecture search},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1109/HPCC-CSS-ICESS.2015.246,
author = {Wang, Kewen and Khan, Mohammad Maifi Hasan},
title = {Performance Prediction for Apache Spark Platform},
year = {2015},
isbn = {9781479989379},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HPCC-CSS-ICESS.2015.246},
doi = {10.1109/HPCC-CSS-ICESS.2015.246},
abstract = {Apache Spark is an open source distributed data processing platform that uses distributed memory abstraction to process large volume of data efficiently. However, performance of a particular job on Apache Spark platform can vary significantly depending on the input data type and size, design and implementation of the algorithm, and computing capability, making it extremely difficult to predict the performance metric of a job such as execution time, memory footprint, and I/O cost. To address this challenge, in this paper, we present a simulation driven prediction model that can predict job performance with high accuracy for Apache Spark platform. Specifically, as Apache spark jobs are often consist of multiple sequential stages, the presented prediction model simulates the execution of the actual job by using only a fraction of the input data, and collect execution traces (e.g., I/O overhead, memory consumption, execution time) to predict job performance for each execution stage individually. We evaluated our prediction framework using four real-life applications on a 13 node cluster, and experimental results show that the model can achieve high prediction accuracy.},
booktitle = {Proceedings of the 2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conf on Embedded Software and Systems},
pages = {166–173},
numpages = {8},
keywords = {Apache Spark, Execution Time Prediction, Performance Modeling},
series = {HPCC-CSS-ICESS '15}
}

@inproceedings{10.1109/ASE.2015.15,
author = {Zhang, Yi and Guo, Jianmei and Blais, Eric and Czarnecki, Krzysztof},
title = {Performance prediction of configurable software systems by fourier learning},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.15},
doi = {10.1109/ASE.2015.15},
abstract = {Understanding how performance varies across a large number of variants of a configurable software system is important for helping stakeholders to choose a desirable variant. Given a software system with n optional features, measuring all its 2n possible configurations to determine their performances is usually infeasible. Thus, various techniques have been proposed to predict software performances based on a small sample of measured configurations. We propose a novel algorithm based on Fourier transform that is able to make predictions of any configurable software system with theoretical guarantees of accuracy and confidence level specified by the user, while using minimum number of samples up to a constant factor. Empirical results on the case studies constructed from real-world configurable systems demonstrate the effectiveness of our algorithm.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {365–373},
numpages = {9},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1016/j.scico.2012.04.009,
author = {Marinho, Fabiana G. and Andrade, Rossana M. C. and Werner, Cl\'{a}udia and Viana, Windson and Maia, Marcio E. F. and Rocha, Lincoln S. and Teixeira, Eld\'{\i}nae and Filho, Jo\~{a}o B. Ferreira and Dantas, Val\'{e}ria L. L. and Lima, Fabr\'{\i}cio and Aguiar, Saulo},
title = {MobiLine: A Nested Software Product Line for the domain of mobile and context-aware applications},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.04.009},
doi = {10.1016/j.scico.2012.04.009},
abstract = {Mobile devices are multipurpose and multi-sensor equipments supporting applications able to adapt their behavior according to changes in the user's context (device, location, time, etc.). Meanwhile, the development of mobile and context-aware software is not a simple task, mostly due to the peculiar characteristics of these devices. Although several solutions have been proposed to facilitate their development, reuse is not systematically used throughout the software development life-cycle. In this paper, we discuss an approach for the development of mobile and context-aware software using the Software Product Line (SPL) paradigm. Furthermore, a Nested SPL for the domain of mobile and context-aware applications is presented, lessons learned in the SPL development are discussed and a product for a context-aware visit guide is shown.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2381–2398},
numpages = {18},
keywords = {Context-awareness, Mobility, Software product line}
}

@inproceedings{10.1145/3461002.3473072,
author = {Martinson, Johan and Jansson, Herman and Mukelabai, Mukelabai and Berger, Thorsten and Bergel, Alexandre and Ho-Quang, Truong},
title = {HAnS: IDE-based editing support for embedded feature annotations},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473072},
doi = {10.1145/3461002.3473072},
abstract = {When developers maintain or evolve software, they often need to know the locations of features. This proves challenging when the feature locations are not documented, when the code was written by different developers who may have left the organization, or when the developer's memory of the implementation has faded. Automated feature location techniques are hard to adopt in practice, especially since they boast too many false positives. To address these challenges, embedded feature annotations have been proposed to allow developers to trace features in code during development with minimal effort. However, tool support is needed for developers to effectively record and use these annotations. We propose HAnS as a tool to meet this need; it is implemented as an IntelliJ IDE plugin to support developers seamlessly record feature locations while they write their code. HAnS supports developers when mapping features to software assets, such as files and code fragments, with code completion and syntax highlighting. It also provides functionality to browse feature definitions and locations, as well as refactor features. A demo video is available at https://youtu.be/cx_-ZshHLgA.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {28–31},
numpages = {4},
keywords = {IDE, embedded feature annotations, feature location, tool support},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.micpro.2016.05.006,
author = {Guo, Jun and Ma, Anxiang and Yan, Yongming and Zhang, Bin},
title = {Application performance prediction method based on cross-core performance interference on multi-core processor},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {47},
number = {PA},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2016.05.006},
doi = {10.1016/j.micpro.2016.05.006},
abstract = {Due to the contention for shared resource, applications deployed on different cores would suffer from the performance interference. Therefore, how to predict applications performance reasonably has become the hotspot in current studies. A challenges of the existing application performance prediction methods are hard to determine the pressure indicators and assess the pressure of the multi-interference application forcing, this paper proposes an application performance prediction method which is based on the cross-core performance interference on multi-core processors. In particular, we firstly analyze the relationship between the cross-core shared resource usage and the performance degradation of applications. Then, we- select the appropriate indicators to represent the pressure on shared resources using the correlation analysis, and establish the correlation model between the degree of the performance degradation and the pressure level by using the stepwise regression analysis method. Meanwhile, we consider the mutual of the interference and employ a K-means clustering algorithm to decrease the prediction cost. Experimental results show that the pressure indicators could measure the competition to the resource and the performance model could predict the performance degradation accurately.},
journal = {Microprocess. Microsyst.},
month = nov,
pages = {112–120},
numpages = {9},
keywords = {Application performance prediction, Data center, Interference, Multi-core}
}

@inproceedings{10.1145/3461002.3473950,
author = {Kuiter, Elias and Kr\"{u}ger, Jacob and Saake, Gunter},
title = {Iterative development and changing requirements: drivers of variability in an industrial system for veterinary anesthesia},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473950},
doi = {10.1145/3461002.3473950},
abstract = {Developing a safety-critical embedded system poses a high risk, since such systems must usually comply with (potentially changing) rigorous standards set by customers and legal authorities. To reduce risk and cope with changing requirements, manufacturers of embedded devices increasingly use iterative development processes and prototyping both for hard- and firmware. However, hard- and firmware development are difficult to align in a common process, because hardware development cycles are typically longer and more expensive. Thus, seamlessly transitioning software to new hardware revisions and reusing old hardware revisions can be problematic. In this paper, we describe an industrial case study for veterinary anesthesia in which we also faced this problem. To solve it, we introduced preprocessor-based variability to create a small configurable system that could flexibly adapt to our needs. We discuss our solution, alternative solutions for hardware evolution, as well as their pros and cons. Our experiences generalize an interesting evolution scenario for systems that are planned and delivered as a single system, but exhibited variability to cope with problems during agile development processes.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {113–122},
numpages = {10},
keywords = {case study, configurable system, driver of variability, evolution},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1007/s00766-015-0232-4,
author = {Dargan, John L. and Wasek, James S. and Campos-Nanez, Enrique},
title = {Systems performance prediction using requirements quality attributes classification},
year = {2016},
issue_date = {November  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-015-0232-4},
doi = {10.1007/s00766-015-0232-4},
abstract = {Poor requirements definition can adversely impact system cost and performance for government acquisition programs. This can be mitigated by ensuring requirements statements are written in a clear and unambiguous manner with high linguistic quality. This paper introduces a statistical model that uses requirements quality factors to predict system operational performance. This work explores four classification techniques (Logistic Regression, Na\"{\i}ve Bayes Classifier, Support Vector Machine, and K-Nearest Neighbor) to develop the predictive model. This model is created using empirical data from current major acquisition programs within the federal government. Operational Requirements Documents and Operational Test Reports are the data sources, respectively, for the system requirements statements and the accompanying operational test results used for model development. A commercial-off-the-shelf requirements quality analysis tool is used to determine the requirements linguistic quality metrics used in the model. Subsequent to model construction, the predictive value of the model is confirmed through execution of a sensitivity analysis, cross-validation of the data, and an overfitting analysis. Lastly, Receiver Operating Characteristics are examined to determine the best performing model. In all, the results establish that requirements quality is indeed a predictive factor for end-system operational performance, and the resulting statistical model can influence requirements development based on likelihood of successful operational performance.},
journal = {Requir. Eng.},
month = nov,
pages = {553–572},
numpages = {20},
keywords = {Natural language requirements, Poor requirements, Requirements definition, Requirements engineering, Requirements quality attributes}
}

@inproceedings{10.1145/3150928.3150943,
author = {Llwaah, Faris and Ca\l{}a, Jacek and Thomas, Nigel},
title = {Runtime Performance Prediction of Big Data Workflows with I/O-aware Simulation},
year = {2017},
isbn = {9781450363464},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3150928.3150943},
doi = {10.1145/3150928.3150943},
abstract = {Modelling and simulation of Big Data analytics processes running in the cloud is a difficult problem which introduces many challenges. The major one is the collection of training data which is scarce and costly to obtain, due to large scale and long runtime of those processes. In our previous work, we proposed a methodology to model, simulate and predict the runtime of Big Data processes such as complex Next Generation Sequencing (NGS) pipelines. The major contribution of our simulation methodology is that it provides a reasonable prediction of runtime for testing data much larger than the training inputs. To further improve the accuracy of prediction we present now an extension of our previous work that can model cloud data storage. Our simulation framework is based on CloudSim and WorkflowSim, to which we have added a shared storage component. We present the design and implementation of the storage extension together with an evaluation performed on selected scientific workflows: the Pegasus Montage workflow and NGS pipeline implemented in e-Science Central. The evaluation shows that the proposed extension works correctly and can improve prediction accuracy for our largest 390 GB input dataset by about 16% when compared to previous results.},
booktitle = {Proceedings of the 11th EAI International Conference on Performance Evaluation Methodologies and Tools},
pages = {74–81},
numpages = {8},
keywords = {Big data, Data-intensive simulation, Next generation sequencing pipeline, WorkflowSim},
location = {Venice, Italy},
series = {VALUETOOLS 2017}
}

@inproceedings{10.1145/2351676.2351703,
author = {Westermann, Dennis and Happe, Jens and Krebs, Rouven and Farahbod, Roozbeh},
title = {Automated inference of goal-oriented performance prediction functions},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351703},
doi = {10.1145/2351676.2351703},
abstract = {Understanding the dependency between performance metrics (such as response time) and software configuration or usage parameters is crucial in improving software quality. However, the size of most modern systems makes it nearly impossible to provide a complete performance model. Hence, we focus on scenario-specific problems where software engineers require practical and efficient approaches to draw conclusions, and we propose an automated, measurement-based model inference method to derive goal-oriented performance prediction functions. For the practicability of the approach it is essential to derive functional dependencies with the least possible amount of data. In this paper, we present different strategies for automated improvement of the prediction model through an adaptive selection of new measurement points based on the accuracy of the prediction model. In order to derive the prediction models, we apply and compare different statistical methods. Finally, we evaluate the different combinations based on case studies using SAP and SPEC benchmarks.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {190–199},
numpages = {10},
keywords = {Model Inference, Performance Prediction},
location = {Essen, Germany},
series = {ASE '12}
}

@inproceedings{10.1609/aaai.v33i01.33012395,
author = {Weise, Thomas and Wu, Zijun and Wagner, Markus},
title = {An improved generic bet-and-run strategy with performance prediction for stochastic local search},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33012395},
doi = {10.1609/aaai.v33i01.33012395},
abstract = {A commonly used strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space. Building on the recent success of BET-AND-RUN approaches for restarted local search solvers, we introduce a more generic version that makes use of performance prediction. It is our goal to obtain the best possible results within a given time budget t using a given black-box optimization algorithm. If no prior knowledge about problem features and algorithm behavior is available, the question about how to use the time budget most efficiently arises. We first start k ≥ 1 independent runs of the algorithm during an initialization budget t1 &lt; t, pause these runs, then apply a decision maker D to choose 1 ≤ m &lt; k runs from them (consuming t2 ≥ 0 time units in doing so), and then continue these runs for the remaining t3 = t-t1-t2 time units. In previous BET-AND-RUN strategies, the decision maker D = currentBest would simply select the run with the best-so-far results at negligible time. We propose using more advanced methods to discriminate between "good" and "bad" sample runs with the goal of increasing the correlation of the chosen run with the a-posteriori best one. In over 157 million experiments, we test different approaches to predict which run may yield the best results if granted the remaining budget. We show (1) that the currentBest method is indeed a very reliable and robust baseline approach, and (2) that our approach can yield better results than the previous methods.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {296},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1145/3109729.3109745,
author = {Markiegi, Urtzi},
title = {Test optimisation for Highly-Configurable Cyber-Physical Systems},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109745},
doi = {10.1145/3109729.3109745},
abstract = {Cyber-Physical Systems (CPS) have become one of the core-enabling technologies for multiple domains, such as manufacturing, healthcare, energy and transportation. Furthermore, these domains are demanding CPS to be highly-configurable in order to respond to multiple and changing market requirements. Testing these Highly-Configurable Cyber-Physical Systems (HCCPS) is challenging. First, when working with CPSs, considerable time is required in order to tackle physical processes during testing. And secondly, in highly-configurable systems, a large number of system variants need to be tested. Consequently, reducing HCCPS testing time is essential.In this context, a research work is presented to reduce the overall testing time of HCCPS, focusing on a merged strategy of product and test cases optimisation. In particular, two approaches are proposed in order to achieve the testing time reduction. The first approach aims to reduce the HCCPS testing time by an iterative allocation of products and test cases. The second approach aims to reduce the HCCPS testing time by a feedback driven dynamic and iterative allocation of products and test cases.A preliminary experiment has been undertaken to test the iterative allocation approach. In this experiment, products to be tested are selected and prioritised. Next, multiple testing iterations are perform until the time-budget is consumed. In each iteration a small number of test cases are allocated for each of the products to be tested. The experiment was evaluated with an academic HCCPS and preliminary results suggest that the proposed approach reduces the fault detection time when compared with traditional approaches.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {139–144},
numpages = {6},
keywords = {Cyber-Physical Systems, Fault Detection, Highly-Configurable Systems, Product Line Testing, Search-Based Software Engineering, Software Engineering},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1504/IJNVO.2018.093649,
title = {A novel virtual machine scheduling policy based on performance prediction model},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {4},
issn = {1470-9503},
url = {https://doi.org/10.1504/IJNVO.2018.093649},
doi = {10.1504/IJNVO.2018.093649},
abstract = {In cloud platforms, virtual machine scheduling policy plays an important role for providing desirable service quality for users. In many existing scheduling policies, the task execution time is often assumed to be constant or defined by users. However, either unpredictable workload or resource unreliability may significantly affect task execution time, which in turn results in inefficient scheduling decisions. In this paper, we first present a task execution time model by applying queue theory; then we use this model to predict the performance of application at runtime and propose a novel virtual machine scheduling policy. By conducting extensive experiments, we investigate the effectiveness and efficiency of the proposed scheduling policy. The experimental results indicate that it can significantly reduce the response time of cloud application comparing with other existing scheduling policies.},
journal = {Int. J. Netw. Virtual Organ.},
month = jan,
pages = {279–293},
numpages = {15}
}

@inproceedings{10.1145/3307630.3342398,
author = {Beek, Maurice H. ter and Schmid, Klaus and Eichelberger, Holger},
title = {Textual Variability Modeling Languages: An Overview and Considerations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342398},
doi = {10.1145/3307630.3342398},
abstract = {During the three decades since the invention of the first variability modeling approach [28], there have been multiple attempts to introduce advanced variability modeling capabilities. More recently, we have seen increased attention on textual variability modeling languages. In this paper, we summarize the main capabilities of state of the art textual variability modeling languages, based on [23], including updates regarding more recent work. Based on this integrated characterization, we provide a discussion of additional concerns, opportunities and challenges that are relevant for designing future (textual) variability modeling languages. The paper also summarizes relevant contributions by the authors as input to further discussions on future (textual) variability modeling languages.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {151–157},
numpages = {7},
keywords = {software product lines, textual specification languages, variability modeling},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10270-015-0457-1,
author = {Heinrich, Robert and Merkle, Philipp and Henss, J\"{o}rg and Paech, Barbara},
title = {Integrating business process simulation and information system simulation for performance prediction},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0457-1},
doi = {10.1007/s10270-015-0457-1},
abstract = {Business process (BP) designs and enterprise information system (IS) designs are often not well aligned. Missing alignment may result in performance problems at run-time, such as large process execution time or overloaded IS resources. The complex interrelations between BPs and ISs are not adequately understood and considered in development so far. Simulation is a promising approach to predict performance of both BP and IS designs. Based on prediction results, design alternatives can be compared and verified against requirements. Thus, BP and IS designs can be aligned to improve performance. In current simulation approaches, BP simulation and IS simulation are not adequately integrated. This results in limited prediction accuracy due to neglected interrelations between the BP and the IS in simulation. In this paper, we present the novel approach Integrated Business IT Impact Simulation (IntBIIS) to adequately reflect the mutual impact between BPs and ISs in simulation. Three types of mutual impact between BPs and ISs in terms of performance are specified. We discuss several solution alternatives to predict the impact of a BP on the performance of ISs and vice versa. It is argued that an integrated simulation of BPs and ISs is best suited to reflect their interrelations. We propose novel concepts for continuous modeling and integrated simulation. IntBIIS is implemented by extending the Palladio tool chain with BP simulation concepts. In a real-life case study with a BP and IS from practice, we validate the feasibility of IntBIIS and discuss the practicability of the corresponding tool support.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {257–277},
numpages = {21},
keywords = {Alignment, Business process, Information system, Performance}
}

@inproceedings{10.1109/SOSE.2015.11,
author = {Karim, Raed and Ding, Chen and Miri, Ali},
title = {End-to-End Performance Prediction for Selecting Cloud Services Solutions},
year = {2015},
isbn = {9781479983568},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SOSE.2015.11},
doi = {10.1109/SOSE.2015.11},
abstract = {In cloud computing, in order to select or recommend the best service solutions to end users, the end-to-end QoS requirements (e.g. response time and throughput) have to be computed. A typical cloud solution is a combination of multiple component services such as IaaS, SaaS, PaaS, etc. In a simplified case, there could be two components- software services and infrastructure services. The software service alone can satisfy end user's functional requirements (e.g. business objectives); however, the end-to-end QoS requirements require a collaboration of the multiple components at multiple cloud layers. In this paper, we consider the multilayered cloud architecture for computing the end-to-end performance values for cloud solutions. We propose a new method for measuring cloud component services similarity and predicting the end-to-end performance values of cloud solutions. In this method, the historical performance data of cloud component services is used based on users' past invocations. To evaluate our method and show its effectiveness, series of experiments are conducted. The experimental results demonstrate that our cloud multi-layers based method produces better prediction accuracy than other prediction approaches that consider one cloud layer.},
booktitle = {Proceedings of the 2015 IEEE Symposium on Service-Oriented System Engineering},
pages = {69–77},
numpages = {9},
keywords = {Cloud Computing, End-to-End Cloud Performance Prediction, IaaS, QoS, SaaS},
series = {SOSE '15}
}

@inproceedings{10.1145/2934466.2934469,
author = {Zhang, Yi and Guo, Jianmei and Blais, Eric and Czarnecki, Krzysztof and Yu, Huiqun},
title = {A mathematical model of performance-relevant feature interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934469},
doi = {10.1145/2934466.2934469},
abstract = {Modern software systems have grown significantly in their size and complexity, therefore understanding how software systems behave when there are many configuration options, also called features, is no longer a trivial task. This is primarily due to the potentially complex interactions among the features. In this paper, we propose a novel mathematical model for performance-relevant, or quantitative in general, feature interactions, based on the theory of Boolean functions. Moreover, we provide two algorithms for detecting all such interactions with little measurement effort and potentially guaranteed accuracy and confidence level. Empirical results on real-world configurable systems demonstrated the feasibility and effectiveness of our approach.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {25–34},
numpages = {10},
keywords = {boolean functions, feature interactions, fourier transform, performance},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382025.3414954,
author = {Michelon, Gabriela Karoline and Obermann, David and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley Klewerton G. and Gr\"{u}nbacher, Paul and Egyed, Alexander},
title = {Locating feature revisions in software systems evolving in space and time},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414954},
doi = {10.1145/3382025.3414954},
abstract = {Software companies encounter variability in space as variants of software systems need to be produced for different customers. At the same time, companies need to handle evolution in time because the customized variants need to be revised and kept up-to-date. This leads to a predicament in practice with many system variants significantly diverging from each other. Maintaining these variants consistently is difficult, as they diverge across space, i.e., different feature combinations, and over time, i.e., revisions of features. This work presents an automated feature revision location technique that traces feature revisions to their implementation. To assess the correctness of our technique, we used variants and revisions from three open source highly configurable software systems. In particular, we compared the original artifacts of the variants with the composed artifacts that were located by our technique. The results show that our technique can properly trace feature revisions to their implementation, reaching traces with 100% precision and 98% recall on average for the three analyzed subject systems, taking on average around 50 seconds for locating feature revisions per variant used as input.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {14},
numpages = {11},
keywords = {feature location, feature revisions, repository mining, variants},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382026.3425776,
author = {Michelon, Gabriela Karoline and Obermann, David and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Linsbauer, Lukas and Gr\"{u}nbacher, Paul and Egyed, Alexander},
title = {Mining Feature Revisions in Highly-Configurable Software Systems},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425776},
doi = {10.1145/3382026.3425776},
abstract = {Highly-Configurable Software Systems (HCSSs) support the systematic evolution of systems in space, i.e., the inclusion of new features, which then allow users to configure software products according to their needs. However, HCSSs also change over time, e.g., when adapting existing features to new hardware or platforms. In practice, HCSSs are thus developed using both version control systems (VCSs) and preprocessor directives (#ifdefs). However, the use of a preprocessor as variability mechanism has been criticized regarding the separation of concerns and code obfuscation, which complicates the analysis of HCSS evolution in VCSs. For instance, a single commit may contain changes of totally unrelated features, which may be scattered over many variation points (#ifdefs), thus making the evolution history hard to understand. This complexity often leads to error-prone changes and high costs for maintenance and evolution. In this paper, we propose an automated approach to mine HCSS features taking into account evolution in space and time. Our approach uses constraint satisfaction problem solving to mine newly introduced, removed and changed features. It finds a configuration containing the feature revisions which are needed to activate a specific program location. Furthermore, it increments the revision number of each changed feature. Thus, our approach enables to analyze when and which features often change over time, as well as their interactions, for every single commit of a HCSS. Our approach can contribute to future research on understanding the characteristics of HCSS and supporting developers during maintenance and evolution tasks.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {74–78},
numpages = {5},
keywords = {feature evolution, preprocessors, repository mining, software product lines, system evolution, version control systems},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@article{10.1007/s10586-007-0039-2,
author = {Sodhi, Sukhdeep and Subhlok, Jaspal and Xu, Qiang},
title = {Performance prediction with skeletons},
year = {2008},
issue_date = {June      2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {11},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-007-0039-2},
doi = {10.1007/s10586-007-0039-2},
abstract = {The performance skeleton of an application is a short running program whose performance in any scenario reflects the performance of the application it represents. Specifically, the execution time of the performance skeleton is a small fixed fraction of the execution time of the corresponding application in any execution environment. Such a skeleton can be employed to quickly estimate the performance of a large application under existing network and node sharing. This paper presents a framework for automatic construction of performance skeletons of a specified execution time and evaluates their use in performance prediction with CPU and network sharing. The approach is based on capturing the execution behavior of an application and automatically generating a synthetic skeleton program that reflects that execution behavior. The paper demonstrates that performance skeletons running for a few seconds can predict the application execution time fairly accurately. Relationship of skeleton execution time, application characteristics, and nature of resource sharing, to accuracy of skeleton based performance prediction, is analyzed in detail. The goal of this research is accurate performance estimation in heterogeneous and shared computational grids.},
journal = {Cluster Computing},
month = jun,
pages = {151–165},
numpages = {15},
keywords = {Grid computing, Performance modeling, Performance prediction, Perfromance skeletons, Resource management, Scheduling}
}

@inproceedings{10.1145/2934466.2934478,
author = {Galindo, Jos\'{e} A. and Acher, Mathieu and Tirado, Juan Manuel and Vidal, Cristian and Baudry, Benoit and Benavides, David},
title = {Exploiting the enumeration of all feature model configurations: a new perspective with distributed computing},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934478},
doi = {10.1145/2934466.2934478},
abstract = {Feature models are widely used to encode the configurations of a software product line in terms of mandatory, optional and exclusive features as well as propositional constraints over the features. Numerous computationally expensive procedures have been developed to model check, test, configure, debug, or compute relevant information of feature models. In this paper we explore the possible improvement of relying on the enumeration of all configurations when performing automated analysis operations. We tackle the challenge of how to scale the existing enumeration techniques by relying on distributed computing. We show that the use of distributed computing techniques might offer practical solutions to previously unsolvable problems and opens new perspectives for the automated analysis of software product lines.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {74–78},
numpages = {5},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382025.3414989,
author = {Krieter, Sebastian},
title = {Large-scale T-wise interaction sampling using YASA},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414989},
doi = {10.1145/3382025.3414989},
abstract = {Testing highly-configurable software systems (i.e., software product lines) is challenging due to their large configuration space. T-wise sampling is one method of finding a representative subset of configurations for a system, which can then be tested. However, for large-scale systems, such as Linux, existing t-wise sampling algorithms do not scale well. To this end, Pett et al. proposed the sampling challenge for large-scale systems at SPLC 2019. In this paper, we attempt to solve the proposed challenge using our sampling algorithm YASA. We report our experience for all three of the given systems FinancialServices01, Automotive02, and Linux. In addition, we present the results for computing samples for all versions of the system FinancialServices01.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {29},
numpages = {4},
keywords = {T-wise sampling, configurable system, software product lines},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/1989323.1989359,
author = {Duggan, Jennie and Cetintemel, Ugur and Papaemmanouil, Olga and Upfal, Eli},
title = {Performance prediction for concurrent database workloads},
year = {2011},
isbn = {9781450306614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1989323.1989359},
doi = {10.1145/1989323.1989359},
abstract = {Current trends in data management systems, such as cloud and multi-tenant databases, are leading to data processing environments that concurrently execute heterogeneous query workloads. At the same time, these systems need to satisfy diverse performance expectations. In these newly-emerging settings, avoiding potential Quality-of-Service (QoS) violations heavily relies on performance predictability, i.e., the ability to estimate the impact of concurrent query execution on the performance of individual queries in a continuously evolving workload.This paper presents a modeling approach to estimate the impact of concurrency on query performance for analytical workloads. Our solution relies on the analysis of query behavior in isolation, pairwise query interactions and sampling techniques to predict resource contention under various query mixes and concurrency levels. We introduce a simple yet powerful metric that accurately captures the joint effects of disk and memory contention on query performance in a single value. We also discuss predicting the execution behavior of a time-varying query workload through query-interaction timelines, i.e., a fine-grained estimation of the time segments during which discrete mixes will be executed concurrently. Our experimental evaluation on top of PostgreSQL/TPC-H demonstrates that our models can provide query latency predictions within approximately 20% of the actual values in the average case.},
booktitle = {Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data},
pages = {337–348},
numpages = {12},
keywords = {concurrency, query performance prediction},
location = {Athens, Greece},
series = {SIGMOD '11}
}

@inproceedings{10.1145/2668930.2688823,
author = {Didona, Diego and Romano, Paolo},
title = {Hybrid Machine Learning/Analytical Models for Performance Prediction: A Tutorial},
year = {2015},
isbn = {9781450332484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668930.2688823},
doi = {10.1145/2668930.2688823},
abstract = {Classical approaches to performance prediction of computer systems rely on two, typically antithetic, techniques: Machine Learning (ML) and Analytical Modeling (AM).ML undertakes a black-box approach, which typically achieves very good accuracy in regions of the features' space that have been sufficiently explored during the training process, but that has very weak extrapolation power (i.e., poor accuracy in regions for which none, or too few samples are known).Conversely, AM relies on a white-box approach, whose key advantage is that it requires no or minimal training, hence supporting prompt instantiation of the target system's performance model. However, to ensure their tractability, AM-based performance predictors typically rely on simplifying assumptions. Consequently, AM's accuracy is challenged in scenarios not matching such assumptions.This tutorial describes techniques that exploit AM and ML in synergy in order to get the best of the two worlds. It surveys several such hybrid techniques and presents use cases spanning a wide range of application domains.},
booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
pages = {341–344},
numpages = {4},
keywords = {analytical modeling, gray box modeling, machine learning},
location = {Austin, Texas, USA},
series = {ICPE '15}
}

@inproceedings{10.1145/3106195.3106204,
author = {Luthmann, Lars and Stephan, Andreas and B\"{u}rdek, Johannes and Lochau, Malte},
title = {Modeling and Testing Product Lines with Unbounded Parametric Real-Time Constraints},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106204},
doi = {10.1145/3106195.3106204},
abstract = {Real-time requirements are crucial for embedded software in many modern application domains of software product lines. Hence, techniques for modeling and analyzing time-critical software have to be lifted to software product line engineering, too. Existing approaches extend timed automata (TA) by feature constraints to so-called featured timed automata (FTA) facilitating efficient verification of real-time properties for entire product lines in a single run. In this paper, we propose a novel modeling formalism, called configurable parametric timed automata (CoPTA), extending expressiveness of FTA by supporting freely configurable and therefore a-priori unbounded timing intervals for real-time constraints, which are defined as feature attributes in extended feature models with potentially infinite configuration spaces. We further describe an efficient test-suite generation methodology for CoPTA models, achieving location coverage on every possible model configuration. Finally, we present evaluation results gained from applying our tool implementation to a collection of case studies, demonstrating efficiency improvements compared to a variant-by-variant analysis.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {104–113},
numpages = {10},
keywords = {Model-based Testing, Real-Time Systems, Software Product Lines, Timed Automata},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3307630.3342396,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {White-Box and Black-Box Test Quality Metrics for Configurable Simulation Models},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342396},
doi = {10.1145/3307630.3342396},
abstract = {Simulation models are widely employed to model and simulate complex systems from different domains, such as automotive. These systems are becoming highly configurable to support different users' demands. Testing all of them is impracticable, and thus, cost-effective techniques are mandatory. Costs are usually attributed either to the time it takes to test a configurable system or to its monetary value. Nevertheless, for the case of test effectiveness several quality metrics can be found in the literature. This paper aims at proposing both black-box and white-box test quality metrics for configurable simulation models relying on 150% variability modeling approaches.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {211–214},
numpages = {4},
keywords = {product lines, simulation models, test quality metrics},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342410,
author = {Rosiak, Kamil and Urbaniak, Oliver and Schlie, Alexander and Seidl, Christoph and Schaefer, Ina},
title = {Analyzing Variability in 25 Years of Industrial Legacy Software: An Experience Report},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342410},
doi = {10.1145/3307630.3342410},
abstract = {In certain domains, safety-critical software systems may remain operational for decades. To comply with changing requirements, new system variants are commonly created by copying and modifying existing ones. Typically denoted clone-and-own, software quality and overall maintainability are adversely affected in the long-run. With safety being pivotal, a fault in one variant may require the entire portfolio to be assessed. Thus, engineers need to maintain legacy systems dating back decades, implemented in programming languages such as Pascal. Software product lines (SPLs) can be a remedy but migrating legacy systems requires their prior analysis and comparison. For industrial software systems, this remains a challenge.In this paper, we introduce a comparison procedure and customizable metrics to allow for a fine-grained comparison of Pascal modules to the level of individual expressions. By that, we identify common parts of while also capturing different parts between modules as a basis for a transition towards anSPLs practice. Moreover, we demonstrate the feasibility of our approach using a case study with seven Pascal modules totaling 13,271 lines of code with an evolution-history of 25 years and show our procedure to be fast and precise. Furthermore, we elaborate on the case study and detail peculiarities of the Pascal modules, which are characteristic for an evolution-history of a quarter century.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {65–72},
numpages = {8},
keywords = {clone-and-own, legacy software, software prodct line, variability},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10586-017-1553-5,
author = {VeeraManickam, M. R. M. and Mohanapriya, M. and Pandey, Bishwajeet K. and Akhade, Sushma and Kale, S. A. and Patil, Reshma and Vigneshwar, M.},
title = {Map-Reduce framework based cluster architecture for academic student’s performance prediction using cumulative dragonfly based neural network},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-017-1553-5},
doi = {10.1007/s10586-017-1553-5},
abstract = {The major aim of the education institute is to provide the high-quality education to students. The way to attain the high quality in the education system is to determine the knowledge from the educational data and learn the attributes which influence the performance of the students. The extracted knowledge is used to predict the academic performance of the students. This paper presents the student performance prediction model by proposing the Map-reduce architecture based cumulative dragonfly based neural network (CDF-NN). The CDF-NN is proposed by training the neural network by the cumulative dragonfly algorithm (DA). Initially, the marks of the students from semester 1 to semester 7 are collected from different colleges. In the training phase, the features are selected from the student’s information and the intermediate data is generated by the mapper. Then, the intermediate data is provided to the reducer function which is built with the CDF-NN to provide the estimated marks of the students in a forthcoming semester. The proposed method is compared with the existing methods, such as Dragonfly- NN and Back prorogation algorithm for the evaluation metrics, MSE and RMSE. The proposed prediction model obtains the MSE of 16.944 and RMSE of 4.665.},
journal = {Cluster Computing},
month = jan,
pages = {1259–1275},
numpages = {17},
keywords = {Educational data mining, Map-Reduce framework, Cluster, Neural network, Dragonfly algorithm, Smart E-learning}
}

@article{10.1504/IJLT.2017.088407,
title = {An empirical study on attribute selection of student performance prediction model},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {3},
issn = {1477-8386},
url = {https://doi.org/10.1504/IJLT.2017.088407},
doi = {10.1504/IJLT.2017.088407},
abstract = {Despite improvement in the standard of education globally, students' failure rates have risen. Data mining has been implemented in several domains, including education, for extracting valuable information from raw data. The aim of this study was to develop a model for predicting student performance and thereby identifying the students who might under perform in examinations. Student data used for the study consisted of demographic and academic information of students. Systematic analysis of different attributes of the student data was done using feature subset selection algorithms. The model was tested using classification algorithms. Based on these results a small attribute set, namely student data feature set SDFS was proposed. The experimental results demonstrate that the learning model using SDFS gives the best results and also minimises the errors. This model can be utilised to identify the academically weaker students so that appropriate preventive action can be taken to avoid failures. Adoption of data analytics in education can help create a smart education system beneficial for society.},
journal = {Int. J. Learn. Technol.},
month = jan,
pages = {241–252},
numpages = {12}
}

@inproceedings{10.1007/978-3-642-31095-9_39,
author = {Sch\"{a}ler, Martin and Leich, Thomas and Rosenm\"{u}ller, Marko and Saake, Gunter},
title = {Building information system variants with tailored database schemas using features},
year = {2012},
isbn = {9783642310942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31095-9_39},
doi = {10.1007/978-3-642-31095-9_39},
abstract = {Database schemas are an integral part of many information systems (IS). New software-engineering methods, such as software product lines, allow engineers to create a high number of different programs tailored to the customer needs from a common code base. Unfortunately, these engineering methods usually do not take the database schema into account. Particularly, a tailored client program requires a tailored database schema as well to form a consistent IS. In this paper, we show the challenges of tailoring relational database schemas in software product lines. Furthermore, we present an approach to treat the client and database part of an IS in the same way using a variable database schema. Additionally, we show the benefits and discuss disadvantages of the approach during the evolution of an industrial case study, covering a time span of more than a year.},
booktitle = {Proceedings of the 24th International Conference on Advanced Information Systems Engineering},
pages = {597–612},
numpages = {16},
keywords = {feasibility study, software product lines, tailoring DB schemas},
location = {Gda\'{n}sk, Poland},
series = {CAiSE'12}
}

@inproceedings{10.1109/MASCOTS.2013.61,
author = {Brosig, Fabian and Gorsler, Fabian and Huber, Nikolaus and Kounev, Samuel},
title = {Evaluating Approaches for Performance Prediction in Virtualized Environments},
year = {2013},
isbn = {9780769551029},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MASCOTS.2013.61},
doi = {10.1109/MASCOTS.2013.61},
abstract = {Performance management and performance prediction of services deployed in virtualized environments is a challenging task. On the one hand, the virtualization layer makes the estimation of performance model parameters difficult and inaccurate. On the other hand, it is difficult to model the hyper visor scheduler in a representative and practically feasible manner. In this paper, we describe how to obtain relevant parameters, such as the virtualization overhead, depending on the amount and type of available monitoring data. We adapt classical queueing-theory-based modeling techniques to make them usable for different configurations of virtualized environments. We provide answers how to include the virtualization overhead into queueing network models, and how to take the contention between different VMs into account. Finally, we evaluate our approach in representative scenarios based on the SPECjEnterprise2010 standard benchmark and XenServer 5.5, showing significant improvements in the prediction accuracy and discussing further open issues for performance prediction in virtualized environments.},
booktitle = {Proceedings of the 2013 IEEE 21st International Symposium on Modelling, Analysis &amp; Simulation of Computer and Telecommunication Systems},
pages = {404–408},
numpages = {5},
series = {MASCOTS '13}
}

@inproceedings{10.1145/3336294.3336295,
author = {Beek, Maurice H. ter and Damiani, Ferruccio and Lienhardt, Michael and Mazzanti, Franco and Paolini, Luca},
title = {Static Analysis of Featured Transition Systems},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336295},
doi = {10.1145/3336294.3336295},
abstract = {A Featured Transition System (FTS) is a formal behavioural model for software product lines, which represents the behaviour of all the products of an SPL in a single compact structure by associating transitions with features that condition their existence in products. In general, an FTS may contain featured transitions that are unreachable in any product (so called dead transitions) or, on the contrary, mandatorily present in all products for which their source state is reachable (so called false optional transitions), as well as states from which only for certain products progress is possible (so called hidden deadlocks). In this paper, we provide algorithms to analyse an FTS for such ambiguities and to transform an ambiguous FTS into an unambiguous FTS. The scope of our approach is twofold. First and foremost, an ambiguous model is typically undesired as it gives an unclear idea of the SPL. Second, an unambiguous FTS paves the way for efficient family-based model checking. We apply our approach to illustrative examples from the literature.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {39–51},
numpages = {13},
keywords = {behavioural model, featured transition systems, formal specification, software product lines, static analysis},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {classification, defect, feature, prediction},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2791060.2791095,
author = {Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire},
title = {Test control algorithms for the validation of cyber-physical systems product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791095},
doi = {10.1145/2791060.2791095},
abstract = {Cyber-Physical Systems (CPSs) product lines appear in a wide range of applications of different domains (e.g., car's doors' windows, doors of a lift, etc.). The variability of these systems is large and as a result they can be configured into plenty of configurations. Testing each of the configurations can be time consuming as not only software has to be simulated, but also the hardware and the physical layer of the CPS, which is often modelled with complex mathematical models. Choosing the adequate test control strategy is critical when testing CPSs product lines. This paper presents a set of test control algorithms organized in an architecture of three layers (domain, application and simulation) for testing CPSs product lines. An illustrative example of a CPS product line is presented and three experiments are conducted to measure the performance of the proposed test control algorithms. We conclude that test scheduling and test suite minimization significantly help to reduce the overall test costs while preserving the test quality in CPSs product lines. In addition, we conclude that knowing the results of the previously tested configurations permits reducing the time for the detection of anomalous designs.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {273–282},
numpages = {10},
keywords = {cyber-physical systems product lines, product line engineering, testing, validation},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.5555/3351736.3351773,
author = {Ketata, Aymen and Moreno, Carlos and Fischmeister, Sebastian and Liang, Jia and Czarnecki, Krzysztof},
title = {Performance prediction upon toolchain migration in model-based software},
year = {2015},
isbn = {9781467369084},
publisher = {IEEE Press},
abstract = {Changing the development environment can have severe impacts on the system behavior such as the execution-time performance. Since it can be costly to migrate a software application, engineers would like to predict the performance parameters of the application under the new environment with as little effort as possible.In this paper, we concentrate on model-driven development and provide a methodology to estimate the execution-time performance of application models under different toolchains. Our approach has low cost compared to the migration effort of an entire application. As part of the approach, we provide methods for characterizing model-driven applications, an algorithm for generating application-specific microbenchmarks, and results on using different methods for estimating the performance. In the work, we focus on SCADE as the development toolchain and use a Cruise Control and a Water Level application as case studies to confirm the technical feasibility and viability of our technique.},
booktitle = {Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems},
pages = {302–311},
numpages = {10},
keywords = {automated code generation, estimation, migration, model-based development, prediction},
location = {Ottawa, Ontario, Canada},
series = {MODELS '15}
}

@article{10.1155/2017/7323681,
author = {Nguyen, Thoa and Vu, Thang and Ngoc, Nam Pham and Thang, Truong Cong and Shyu, Mei-Ling},
title = {SDP-Based Quality Adaptation and Performance Prediction in Adaptive Streaming of VBR Videos},
year = {2017},
issue_date = {2017},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2017},
issn = {1687-5680},
url = {https://doi.org/10.1155/2017/7323681},
doi = {10.1155/2017/7323681},
abstract = {Recently, various adaptation methods have been proposed to cope with throughput fluctuations in HTTP adaptive streaming (HAS). However, these methods have mostly focused on constant bitrate (CBR) videos. Moreover, most of them are qualitative in the sense that performance metrics could only be obtained after a streaming session. In this paper, we propose a new adaptation method for streaming variable bitrate (VBR) videos using stochastic dynamic programming (SDP). With this approach, the system should have a probabilistic characterization along with the definition of a cost function that is minimized by a control strategy. Our solution is based on a new statistical model where the future streaming performance is directly related to the past bandwidth statistics. We develop mathematical models to predict and develop simulation models to measure the average performance of the adaptation policy. The experimental results show that the prediction models can provide accurate performance prediction which is useful in planning adaptation policy and that our proposed adaptation method outperforms the existing ones in terms of average quality and average quality switch.},
journal = {Adv. MultiMedia},
month = jan,
numpages = {12}
}

@inproceedings{10.1007/978-3-642-24749-1_19,
author = {Babka, Vlastimil and T\r{u}ma, Petr},
title = {Can linear approximation improve performance prediction ?},
year = {2011},
isbn = {9783642247484},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-24749-1_19},
doi = {10.1007/978-3-642-24749-1_19},
abstract = {Software performance evaluation relies on the ability of simple models to predict the performance of complex systems. Often, however, the models are not capturing potentially relevant effects in system behavior, such as sharing of memory caches or sharing of cores by hardware threads. The goal of this paper is to investigate whether and to what degree a simple linear adjustment of service demands in software performance models captures these effects and thus improves accuracy. Outlined experiments explore the limits of the approach on two hardware platforms that include shared caches and hardware threads, with results indicating that the approach can improve throughput prediction accuracy significantly, but can also lead to loss of accuracy when the performance models are otherwise defective.},
booktitle = {Proceedings of the 8th European Conference on Computer Performance Engineering},
pages = {250–264},
numpages = {15},
keywords = {linear models, performance modeling, resource sharing},
location = {Borrowdale, UK},
series = {EPEW'11}
}

@inproceedings{10.1145/2884781.2884823,
author = {Schr\"{o}ter, Reimar and Krieter, Sebastian and Th\"{u}m, Thomas and Benduhn, Fabian and Saake, Gunter},
title = {Feature-model interfaces: the highway to compositional analyses of highly-configurable systems},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884823},
doi = {10.1145/2884781.2884823},
abstract = {Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satisfiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {667–678},
numpages = {12},
keywords = {compositionality, configurable software, feature model, modularity, software product line, variability modeling},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.4108/eai.24-8-2015.2260961,
author = {Rygielski, Piotr and Kounev, Samuel and Tran-Gia, Phuoc},
title = {Flexible performance prediction of data center networks using automatically generated simulation models},
year = {2015},
isbn = {9781631900792},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/eai.24-8-2015.2260961},
doi = {10.4108/eai.24-8-2015.2260961},
abstract = {Using different modeling and simulation approaches for predicting network performance requires extensive experience and involves a number of time consuming manual steps regarding each of the modeling formalisms. In this paper, we propose a generic approach to modeling the performance of data center networks. The approach offers multiple performance models but requires to use only a single modeling language. We propose a two-step modeling methodology, in which a high-level descriptive model of the network is built in the first step, and in the second step model-to-model transformations are used to automatically transform the descriptive model to different network simulation models. We automatically generate three performance models defined at different levels of abstraction to analyze network throughput. By offering multiple simulation models in parallel, we provide flexibility in trading-off between the modeling accuracy and the simulation overhead. We analyze the simulation models by comparing the prediction accuracy with respect to the simulation duration. We observe, that in the investigated scenarios the solution duration of coarser simulation models is up to 300 times shorter, whereas the average prediction accuracy decreases only by 4 percent.},
booktitle = {Proceedings of the 8th International Conference on Simulation Tools and Techniques},
pages = {119–128},
numpages = {10},
keywords = {data center networks, meta-modeling, performance modeling},
location = {Athens, Greece},
series = {SIMUTools '15}
}

@article{10.1145/2000832.2000839,
author = {Holland, Brian and George, Alan D. and Lam, Herman and Smith, Melissa C.},
title = {An analytical model for multilevel performance prediction of Multi-FPGA systems},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1936-7406},
url = {https://doi.org/10.1145/2000832.2000839},
doi = {10.1145/2000832.2000839},
abstract = {Power limitations in semiconductors have made explicitly parallel device architectures such as Field-Programmable Gate Arrays (FPGAs) increasingly attractive for use in scalable systems. However, mitigating the significant cost of FPGA development requires efficient design-space exploration to plan and evaluate a range of potential algorithm and platform choices prior to implementation. The authors propose the RC Amenability Test for Scalable Systems (RATSS), an analytical model which enables straightforward, fast, and reasonably accurate performance prediction prior to implementation by extending current modeling concepts to multi-FPGA designs. RATSS provides a comprehensive strategic model to evaluate applications based on the computation and communication requirements of the algorithm and capabilities of the FPGA platform. The RATSS model targets data-parallel applications on current scalable FPGA systems. Three case studies with RATSS demonstrate nearly 90% prediction accuracy as compared to corresponding implementations.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = aug,
articleno = {27},
numpages = {28},
keywords = {FPGA, formulation methodology, performance prediction, reconfigurable computing, strategic design space exploration}
}

@inproceedings{10.5555/1882011.1882025,
author = {Zhang, Lei and Liu, Guiquan and Zhang, Xuechen and Jiang, Song and Chen, Enhong},
title = {Storage device performance prediction with selective bagging classification and regression tree},
year = {2010},
isbn = {3642156711},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Storage device performance prediction is a key element of self-managed storage systems and application planning tasks, such as data assignment and configuration. Based on bagging ensemble, we proposed an algorithm named selective bagging classification and regression tree (SBCART) to model storage device performance. In addition, we consider the caching effect as a feature in workload characterization. Experiments indicate that caching effect added in feature vector can substantially improve prediction accuracy and SBCART is more precise and more stable compared to CART.},
booktitle = {Proceedings of the 2010 IFIP International Conference on Network and Parallel Computing},
pages = {121–133},
numpages = {13},
keywords = {CART, bagging, ensemble learning, performance prediction, storage device modeling},
location = {Zhengzhou, China},
series = {NPC'10}
}

@article{10.1145/1968587.1968607,
author = {Geetha, D. Evangelin and Kumar, T.V. Suresh and Kanth, K. Rajani},
title = {Framework for hybrid performance prediction process model: use case performance engineering approach},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/1968587.1968607},
doi = {10.1145/1968587.1968607},
abstract = {The dynamic behavior of distributed systems requires that their performance characteristics be determined rigorously, preferably in the early stages of software engineering process. Evaluation of the performance at the end of software development leads to increase in the cost of design change. To compare design alternatives or to identify system bottlenecks, quantitative system analysis must be carried out from the early stages of the software development life cycle. In this paper we describe a process model, Hybrid Performance Prediction Process Model that allows modeling and evaluating distributed systems with the explicit goal of assessing performance of the software system during feasibility study. The use case performance engineering approach proposed in this paper exploits use case model and provides flexibility to integrate the software performance prediction process with software engineering process. We use an e-parking application to demonstrate various elements in our framework. The performance metrics are obtained and analyzed by considering two software architectures. Sensitivity analysis on the behavior of resources is carried out. This analysis helps to determine the capacity of the execution environment to obtain the defined performance objectives.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–15},
numpages = {15},
keywords = {4+1 view model, hybrid performance prediction process model, multitier architecture, simulation model, software performance prediction, unified modeling language, use case performance engineering}
}

@inproceedings{10.1145/3336294.3342360,
author = {Michelon, Gabriela Karoline and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley K. G. and Egyed, Alexander},
title = {Comparison-Based Feature Location in ArgoUML Variants},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342360},
doi = {10.1145/3336294.3342360},
abstract = {Identifying and extracting parts of a system's implementation for reuse is an important task for re-engineering system variants into Software Product Lines (SPLs). An SPL is an approach that enables systematic reuse of existing assets across related product variants. The re-engineering process to adopt an SPL from a set of individual variants starts with the location of features and their implementation, to be extracted and migrated into an SPL and reused in new variants. Therefore, feature location is of fundamental importance to the success in the adoption of SPLs. Despite its importance, existing feature location techniques struggle with huge, complex, and numerous system artifacts. This is the scenario of ArgoUML-SPL, which stands out as the most used case study for the validation of feature location approaches. In this paper we use an automated feature location technique and apply it to the ArgoUML feature location challenge posed.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {93–97},
numpages = {5},
keywords = {clones, feature location, reuse, software product lines, traceability, variants},
location = {Paris, France},
series = {SPLC '19}
}

@phdthesis{10.5555/AAI30263556,
author = {Guo, Xiaolong and E., Turochy, Rod and Nam, Tran,},
advisor = {H., Timm, David and Randy, West,},
title = {Evaluation, Local Calibration, and Validation of Performance Prediction Models in AASHTOWare Pavement ME Design Software Using NCAT Test Track Data},
year = {2017},
isbn = {9798371902924},
publisher = {Auburn University},
address = {USA},
abstract = {The AASHTOWareTM Pavement ME Design software was adopted by the American Association of State Highway and Transportation Officials (AASHTO) for structural pavement designs. The performance prediction models in the software were only calibrated based on a national database of pavement sections in the U.S. and Canada. These models may not apply to local pavement designs due to insufficient adequacy. The National Center for Asphalt Technology (NCAT), equipped with a full-scale accelerated pavement Test Track and asphalt materials laboratory, supported this study on evaluation, local calibration, and validation of the rutting, bottom-up fatigue cracking, and IRI models. The NCAT database was developed with research-grade detail and accuracy and was locally-based regarding the information of materials, traffic, and climate, and field performance. In the process of local calibration, automation was used during software runs and data compiling to minimize human interaction with the computer. Considerable labor savings (100% reduction) and time savings (nearly 35% reduction) were gained. As for evaluation results, over-predictions by the nationally-calibrated rutting and bottom-up fatigue cracking model were seen for a majority of experimental sections, and local calibration reduced bias and standard error of the estimate. The IRI prediction by the nationally-calibrated model was only accurate between 35 in./mile to 65 in./mile, and local calibration insignificantly improved the IRI prediction accuracy. The improvement of model accuracy was adequately validated for the locally-calibrated rutting and bottom-up fatigue cracking model, but not for the locally-calibrated IRI model, using independent local datasets. The recommended calibration coefficients should be evaluated based on a local database if they are intended for other design conditions. The automation method is recommended for future calibration studies since benefits in saving time and labor cost.},
note = {AAI30263556}
}

@inproceedings{10.1145/3233027.3233035,
author = {Varshosaz, Mahsa and Al-Hajjaji, Mustafa and Th\"{u}m, Thomas and Runge, Tobias and Mousavi, Mohammad Reza and Schaefer, Ina},
title = {A classification of product sampling for software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233035},
doi = {10.1145/3233027.3233035},
abstract = {The analysis of software product lines is challenging due to the potentially large number of products, which grow exponentially in terms of the number of features. Product sampling is a technique used to avoid exhaustive testing, which is often infeasible. In this paper, we propose a classification for product sampling techniques and classify the existing literature accordingly. We distinguish the important characteristics of such approaches based on the information used for sampling, the kind of algorithm, and the achieved coverage criteria. Furthermore, we give an overview on existing tools and evaluations of product sampling techniques. We share our insights on the state-of-the-art of product sampling and discuss potential future work.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {1–13},
numpages = {13},
keywords = {domain models, feature interaction, sampling algorithms, software product lines, testing},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3014812.3014857,
author = {Zhang, Wenbin and Shi, Yuliang and Zheng, Yongqing and Liu, Lei and Cui, Lizhen},
title = {Resource and performance prediction at high utilization for N-Tier cloud-based service systems},
year = {2017},
isbn = {9781450347686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3014812.3014857},
doi = {10.1145/3014812.3014857},
abstract = {One of the key objectives of cloud computing systems is to meet the service level agreements (SLAs) under conditions of high resource utilization. Cloud service providers often need to design policies for resource sharing and performance optimization. As a result, being able to predict the performance and resource utilizations prior to implementing these policies is important to the dynamic provisioning of services by cloud providers. It is a significant and difficult challenge due to the fact that requests for resources often interact with each other in complex ways. Moreover, the dynamics of the cloud environment bring more problems to predicting the performance of a running query or workload. Hence, an accurate situation-aware model which can capture the complex interactions among resource requests is useful for addressing this challenge. To this end, we propose an efficient and highly accurate resource and performance prediction framework which takes into account the interactions among concurrently running resource requests for n-tier service systems. The proposed framework extends the Gaussian process and kernel canonical correlation analysis techniques and is able to dynamically adapt to variations in workload and physical resource usage. The proposed framework has been trained and evaluated extensively with a realistic multi-tier cloud application benchmark - the RUBiS benchmark system. The results demonstrate that the framework yields highly accurate performance and resource usage predictions, especially under high resource utilization conditions.},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {43},
numpages = {9},
keywords = {benchmark, cloud, performance, prediction, resource},
location = {Geelong, Australia},
series = {ACSW '17}
}

@inproceedings{10.1145/2830772.2830780,
author = {Ardalani, Newsha and Lestourgeon, Clint and Sankaralingam, Karthikeyan and Zhu, Xiaojin},
title = {Cross-architecture performance prediction (XAPP) using CPU code to predict GPU performance},
year = {2015},
isbn = {9781450340342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2830772.2830780},
doi = {10.1145/2830772.2830780},
abstract = {GPUs have become prevalent and more general purpose, but GPU programming remains challenging and time consuming for the majority of programmers. In addition, it is not always clear which codes will benefit from getting ported to GPU. Therefore, having a tool to estimate GPU performance for a piece of code before writing a GPU implementation is highly desirable. To this end, we propose Cross-Architecture Performance Prediction (XAPP), a machine-learning based technique that uses only single-threaded CPU implementation to predict GPU performance.Our paper is built on the two following insights: i) Execution time on GPU is a function of program properties and hardware characteristics. ii) By examining a vast array of previously implemented GPU codes along with their CPU counterparts, we can use established machine learning techniques to learn this correlation between program properties, hardware characteristics and GPU execution time. We use an adaptive two-level machine learning solution. Our results show that our tool is robust and accurate: we achieve 26.9% average error on a set of 24 real-world kernels. We also discuss practical usage scenarios for XAPP.},
booktitle = {Proceedings of the 48th International Symposium on Microarchitecture},
pages = {725–737},
numpages = {13},
keywords = {GPU, cross-platform prediction, machine learning, performance modeling},
location = {Waikiki, Hawaii},
series = {MICRO-48}
}

@inproceedings{10.1145/3382025.3414962,
author = {Chrszon, Philipp and Baier, Christel and Dubslaff, Clemens and Kl\"{u}ppelholz, Sascha},
title = {From features to roles},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414962},
doi = {10.1145/3382025.3414962},
abstract = {The detection of interactions is a challenging task present in almost all stages of software development. In feature-oriented system design, this task is mainly investigated for interactions of features within a single system, detected by their emergent behaviors. We propose a formalism to describe interactions in hierarchies of feature-oriented systems (hierarchical interactions) and the actual situations where features interact (active interplays). Based on the observation that such interactions are also crucial in role-based systems, we introduce a compositional modeling framework based on concepts and notions of roles, comprising role-based automata (RBAs). To describe RBAs, we present a modeling language that is close to the input language of the probabilistic model checker Prism. To exemplify the use of RBAs, we implemented a tool that translates RBA models into Prism and thus enables the formal analysis of functional and non-functional properties including system dynamics, contextual changes, and interactions. We carry out two case studies as a proof of concept of such analyses: First, a peer-to-peer protocol case study illustrates how undesired hierarchical interactions can be discovered automatically. Second, a case study on a self-adaptive production cell demonstrates how undesired interactions influence quality-of-service measures such as reliability and throughput.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {19},
numpages = {11},
keywords = {feature-oriented systems, formal methods, roles, verification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1007/978-3-642-25725-4_21,
author = {Rai, Jitendra Kumar and Negi, Atul and Wankar, Rajeev},
title = {Machine learning based performance prediction for multi-core simulation},
year = {2011},
isbn = {9783642257247},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25725-4_21},
doi = {10.1007/978-3-642-25725-4_21},
abstract = {Programs co-running on cores share resources on multi-core processor systems. It is now well known that interference between the programs arising from the sharing may result in severe performance degradations. It is the objective of recent research in system scheduling to be aware of shared resource requirements of the running programs (threads). To this end AKULA is a toolset recently developed that provides a platform for experiments and developing thread scheduling algorithms on multi-core processors. In AKULA a bootstrapping module works on the basis of previously collected performance data of programs to simulate program execution on multi-cores. In this paper we describe a different approach where that augments such a bootstrapping module with a model built using machine learning techniques. The proposed model will extend the bootstrapping module's ability to predict degradation in performance due to sharing where previous performance data is not available for pairing /co-scheduling of applications. Also the proposed approach allows greater scalability for variable number of processor cores sharing the resources.},
booktitle = {Proceedings of the 5th International Conference on Multi-Disciplinary Trends in Artificial Intelligence},
pages = {236–247},
numpages = {12},
keywords = {AKULA toolset, CPU scheduling, co-runner interference, machine learning techniques, multi-core simulation, performance prediction},
location = {Hyderabad, India},
series = {MIWAI'11}
}

@inproceedings{10.1145/2791060.2791099,
author = {Filho, Jo\~{a}o Bosco Ferreira and Allier, Simon and Barais, Olivier and Acher, Mathieu and Baudry, Benoit},
title = {Assessing product line derivation operators applied to Java source code: an empirical study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791099},
doi = {10.1145/2791060.2791099},
abstract = {Product Derivation is a key activity in Software Product Line Engineering. During this process, derivation operators modify or create core assets (e.g., model elements, source code instructions, components) by adding, removing or substituting them according to a given configuration. The result is a derived product that generally needs to conform to a programming or modeling language. Some operators lead to invalid products when applied to certain assets, some others do not; knowing this in advance can help to better use them, however this is challenging, specially if we consider assets expressed in extensive and complex languages such as Java. In this paper, we empirically answer the following question: which product line operators, applied to which program elements, can synthesize variants of programs that are incorrect, correct or perhaps even conforming to test suites? We implement source code transformations, based on the derivation operators of the Common Variability Language. We automatically synthesize more than 370,000 program variants from a set of 8 real large Java projects (up to 85,000 lines of code), obtaining an extensive panorama of the sanity of the operations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {36–45},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.neucom.2013.09.074,
author = {Wong, Ka In and Vong, Chi Man and Wong, Pak Kin and Luo, Jiahua},
title = {Sparse Bayesian extreme learning machine and its application to biofuel engine performance prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {149},
number = {PA},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2013.09.074},
doi = {10.1016/j.neucom.2013.09.074},
abstract = {Biofuels are important for the reduction of engine exhaust emissions and fossil fuel consumption. To use different blends of biofuels, the electronic control unit (ECU) of the engine must be modified and calibrated. However, the calibration process of ECU is very costly and time-consuming. Therefore, most of the engines can only use one specific biofuel blend; otherwise the engines cannot run properly. To alleviate this problem, a mathematical engine model can be used for predicting the engine performance at different ECU settings and biofuel blends so that the ECU can be re-calibrated in real-time via some controllers. The prediction of the engine model must be very fast and accurate for such online control purpose. It must also be very compact due to the limited memory size of the ECU. As a result, a new method called sparse Bayesian extreme learning machine (SBELM) is proposed in this paper to fulfill these requirements of the mathematical engine model for fast engine performance prediction and ECU online re-calibration. Experiments were conducted to compare SBELM with conventional ELM, Bayesian ELM (BELM) and back-propagated neural network (BPNN). Evaluation results show that SBELM can perform at least similar to, but mostly better than, ELM, BELM and BPNN, in terms of prediction accuracy. In terms of execution time, model size, and insensitivity to hidden neuron number, SBELM completely outperforms the other three methods. By these results, SBELM is verified to better fulfill the practical requirements of mathematical engine model for online engine performance prediction.},
journal = {Neurocomput.},
month = feb,
pages = {397–404},
numpages = {8},
keywords = {Biofuel, Dual-fuel engine, Engine performance, Extreme learning machine, Sparse Bayesian}
}

@inproceedings{10.1145/3423211.3425685,
author = {Damaskinos, Georgios and Guerraoui, Rachid and Kermarrec, Anne-Marie and Nitu, Vlad and Patra, Rhicheek and Taiani, Francois},
title = {FLeet: Online Federated Learning via Staleness Awareness and Performance Prediction},
year = {2020},
isbn = {9781450381536},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423211.3425685},
doi = {10.1145/3423211.3425685},
abstract = {Federated Learning (FL) is very appealing for its privacy benefits: essentially, a global model is trained with updates computed on mobile devices while keeping the data of users local. Standard FL infrastructures are however designed to have no energy or performance impact on mobile devices, and are therefore not suitable for applications that require frequent (online) model updates, such as news recommenders.This paper presents FLeet, the first Online FL system, acting as a middleware between the Android OS and the machine learning application. FLeet combines the privacy of Standard FL with the precision of online learning thanks to two core components: (i) I-Prof, a new lightweight profiler that predicts and controls the impact of learning tasks on mobile devices, and (ii) AdaSGD, a new adaptive learning algorithm that is resilient to delayed updates.Our extensive evaluation shows that Online FL, as implemented by FLeet, can deliver a 2.3\texttimes{} quality boost compared to Standard FL, while only consuming 0.036% of the battery per day. I-Prof can accurately control the impact of learning tasks by improving the prediction accuracy up to 3.6\texttimes{} (computation time) and up to 19\texttimes{} (energy). AdaSGD outperforms alternative FL approaches by 18.4% in terms of convergence speed on heterogeneous data.},
booktitle = {Proceedings of the 21st International Middleware Conference},
pages = {163–177},
numpages = {15},
keywords = {asynchronous gradient descent, federated learning, mobile Android devices, online learning, profiling},
location = {Delft, Netherlands},
series = {Middleware '20}
}

@inproceedings{10.1145/2668930.2688047,
author = {Didona, Diego and Quaglia, Francesco and Romano, Paolo and Torre, Ennio},
title = {Enhancing Performance Prediction Robustness by Combining Analytical Modeling and Machine Learning},
year = {2015},
isbn = {9781450332484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668930.2688047},
doi = {10.1145/2668930.2688047},
abstract = {Classical approaches to performance prediction rely on two, typically antithetic, techniques: Machine Learning (ML) and Analytical Modeling (AM). ML takes a black box approach, whose accuracy strongly depends on the representativeness of the dataset used during the initial training phase. Specifically, it can achieve very good accuracy in areas of the features' space that have been sufficiently explored during the training process. Conversely, AM techniques require no or minimal training, hence exhibiting the potential for supporting prompt instantiation of the performance model of the target system. However, in order to ensure their tractability, they typically rely on a set of simplifying assumptions. Consequently, AM's accuracy can be seriously challenged in scenarios (e.g., workload conditions) in which such assumptions are not matched.In this paper we explore several hybrid/gray box techniques that exploit AM and ML in synergy in order to get the best of the two worlds. We evaluate the proposed techniques in case studies targeting two complex and widely adopted middleware systems: a NoSQL distributed key-value store and a Total Order Broadcast (TOB) service.},
booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
pages = {145–156},
numpages = {12},
keywords = {analytical modeling, gray box modeling, machine learning},
location = {Austin, Texas, USA},
series = {ICPE '15}
}

@inproceedings{10.1145/3240302.3270315,
author = {Arafa, Yehia and Badawy, Abdel-Hameed A. and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
title = {PPT-GPU: performance prediction toolkit for GPUs identifying the impact of caches: extended abstract},
year = {2018},
isbn = {9781450364751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240302.3270315},
doi = {10.1145/3240302.3270315},
abstract = {In the early days, computers only had central processing units or CPUs. High performance computing capabilities are now in high demand. Emerging applications such as deep learning, augmented and virtual reality, and video processing require accelerators especially graphics processing units (GPUs). GPUs became an integral component in any HPC system.Memory access and management are important parts of any high-performance system. Therefore, identifying the impact of the memory subsystem on modern accelerators used in high-performance computing is very important.In this paper, we identify the impact of GPUs on-chip memory on different workloads and introduce our ongoing work, PPT-GPU, a performance prediction tool that enables GPU code developers and architects to test new algorithms in a fast, scalable, and accurate-enough way by predicting the performance of different workloads under different GPU architectures.},
booktitle = {Proceedings of the International Symposium on Memory Systems},
pages = {301–302},
numpages = {2},
keywords = {CUDA, GPGPU architecture, cache memory, performance prediction},
location = {Alexandria, Virginia, USA},
series = {MEMSYS '18}
}

@inproceedings{10.1145/3493244.3493274,
author = {Silva, Leandro F. and OliveiraJr, Edson},
title = {SMartyModeling: an instance of VMTools-RA for Engineering UML-based Software Product Lines},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493274},
doi = {10.1145/3493244.3493274},
abstract = {Software Product Line (SPL) life cycle comprises a set of essential activities. Variability Management (VM) is one of its most important activities to the success of an SPL, especially those based on UML, as the solution space encompasses different diagrams and perspectives on variability. However, the lack of tools to support UML-based SPLs reflects difficulties in adopting this approach. This scenario motivated the development of SMartyModeling, an environment for engineering UML-based SPL. The SMartyModeling architecture was instantiated based on VMTools-RA, an existing reference architecture for software variability tools. VMTools-RA describes architectural requirements, elements and views on software variability, which aid one to instantiate variability tool architectures. The instantiation process started from the identification of requirements, selection of elements, modules, and visions of VMTools-RA, planning and design of the architectural solutions, implementation of modules and organization of features. We then analyzed the feasibility of adopting VMTools-RA for instantiating an specific tool architecture. In this sense, such instantiation is part of the development process of SMartyModeling, which includes the main activities related to VM. We also empirically evaluated SMartyModeling in three ways: (i) a field study to analyze the instantiation process and the decisions taken; (ii) a comparative experiment analyzing efficiency and effectiveness of SMartyModeling in relation to a general purpose UML tool; and (iii) an evaluation of aspects related to perceived ease of use and perceived usability. The results of such evaluations provide initial evidence VMTools-RA is feasible to instantiate specific architectures and SMartyModeling is feasible to support to VM for UML-based SPLs.},
booktitle = {Proceedings of the XX Brazilian Symposium on Software Quality},
articleno = {33},
numpages = {10},
keywords = {Software Product Line. SMartyModeling. Environment for Modeling Software Product Line. VMTools-RA. UML. Empirical studies.},
location = {Virtual Event, Brazil},
series = {SBQS '21}
}

@inproceedings{10.1145/3106195.3106202,
author = {Wille, David and Wehling, Kenny and Seidl, Christoph and Pluchator, Martin and Schaefer, Ina},
title = {Variability Mining of Technical Architectures},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106202},
doi = {10.1145/3106195.3106202},
abstract = {Technical architectures (TAs) represent the computing infrastructure of a company with all its hardware and software components. Over the course of time, the number of TAs grows with the companies' requirements and usually a large variety of TAs has to be maintained. Core challenge is the missing information on relations between the existing variants of TAs, which complicates reuse of solutions across systems. However, identifying these relations is an expensive task as architects have to manually analyze each TA individually. Restructuring the existing TAs poses severe risks as often sufficient information is not available (e.g., due to time constraints). To avoid failures in productive systems and resulting loss of profit, companies continue to create new solutions without restructuring existing ones. This increased variability in TAs represents technical debt. In this paper, we adapt the idea of variability mining from the software product line domain and present an efficient and automatic mining algorithm to identify the common and varying parts of TAs by analyzing a potentially arbitrary number of TAs in parallel. Using the identified variability information, architects are capable of analyzing the relations of TAs, identifying reuse potential, and making well-founded maintenance decisions. We show the feasibility and scalability of our approach by applying it to a real-world industrial case study with large sets of TAs.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {39–48},
numpages = {10},
keywords = {enterprise architecture, technical architecture, variability mining},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1007/s00500-015-1841-z,
author = {Kim, Kyung-Joong and Cho, Sung-Bae},
title = {Ensemble bayesian networks evolved with speciation for high-performance prediction in data mining},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {4},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-015-1841-z},
doi = {10.1007/s00500-015-1841-z},
abstract = {Bayesian networks (BNs) can be easily refined (or learn) using data given prior knowledge about a changing environment. Furthermore, by exploring multiple diverse BNs in parallel, it is expected that an intelligent system may adapt quickly to changes in the environment, resulting in robust prediction. Recently, there have been attempts to design BN structures using evolutionary algorithms; however, most of these have used only the fittest solution from the final generation. Because it is difficult to combine all of the important factors into a single evaluation function, the solution is often biased and of limited adaptability. Here we describe a method of generating diverse BN structures via speciation and selective combination for adaptive prediction. Experiments using the seven benchmark networks show that the proposed method can result in improved accuracy in handling uncertainty by exploiting ensembles of BNs evolved by speciation.},
journal = {Soft Comput.},
month = feb,
pages = {1065–1080},
numpages = {16},
keywords = {Bayesian networks, Ensemble, Evolution, Prediction, Speciation, Uncertainty}
}

@inproceedings{10.1007/978-3-642-12275-0_34,
author = {Bellog\'{\i}n, Alejandro and Castells, Pablo},
title = {A performance prediction approach to enhance collaborative filtering performance},
year = {2010},
isbn = {3642122744},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12275-0_34},
doi = {10.1007/978-3-642-12275-0_34},
abstract = {Performance prediction has gained increasing attention in the IR field since the half of the past decade and has become an established research topic in the field. The present work restates the problem in the area of Collaborative Filtering (CF), where it has barely been researched so far. We investigate the adaptation of clarity-based query performance predictors to predict neighbor performance in CF. A predictor is proposed and introduced in a kNN CF algorithm to produce a dynamic variant where neighbor ratings are weighted based on their predicted performance. The properties of the predictor are empirically studied by, first, checking the correlation of the predictor output with a proposed measure of neighbor performance. Then, the performance of the dynamic kNN variant is examined on different sparsity and neighborhood size conditions, where the variant consistently outperforms the baseline algorithm, with increasing difference on small neighborhoods.},
booktitle = {Proceedings of the 32nd European Conference on Advances in Information Retrieval},
pages = {382–393},
numpages = {12},
keywords = {collaborative filtering, neighbor selection, performance prediction, query clarity, recommender systems},
location = {Milton Keynes, UK},
series = {ECIR'2010}
}

@inproceedings{10.1109/CCGrid.2013.72,
author = {Kim, Daihee and Larson, J. Walter and Chiu, Kenneth},
title = {Automatic performance prediction for load-balancing coupled models},
year = {2013},
isbn = {9780768549965},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2013.72},
doi = {10.1109/CCGrid.2013.72},
abstract = {Computationally-demanding, parallel coupled models are crucial to understanding many important multi-physics/multiscale phenomena. Load-balancing such simulations on large clusters is often done through off-line, static means that often require significant manual input. Dynamic, runtime load-balancing has been shown in our previous work to be effective, but we still used a manually generated performance predictor to guide the load-balancing decisions. In this paper, we show how timing and interaction information obtained by instrumenting the middleware can be used to automatically generate a performance predictor that relates the overall execution time to the execution time of each individual submodel. The performance predictor is evaluated through the new coupled model benchmark employing five constituent submodels that simulates the CCSM coupled climate model.},
booktitle = {Proceedings of the 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {410–417},
numpages = {8},
keywords = {MPI, dynamic load balance, model coupling, multiphysics modeling, multiscale modeling},
location = {Delft, Netherlands},
series = {CCGRID '13}
}

@article{10.1016/j.eswa.2011.02.007,
author = {Pan, Nang-Fei and Ko, Chien-Ho and Yang, Ming-Der and Hsu, Kai-Chun},
title = {Pavement performance prediction through fuzzy regression},
year = {2011},
issue_date = {August, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {8},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.02.007},
doi = {10.1016/j.eswa.2011.02.007},
abstract = {Accurate predictions of future pavement conditions are essential for determining the most cost-effective maintenance strategy. The current methods for assessing pavement conditions involve either equipment measures or visual inspections. Equipment measures are not extensively implemented because of high cost; thus, subjective evaluations by road inspectors are often used as a replacement. Nevertheless, visual inspections could draw in errors and variations due to subjectivity and uncertainty. The present serviceability index (PSI), one of the most common indicators used to evaluate pavement performance, is incapable of transforming one's imprecise judgment into an exact number between 0 (the worst) and 5 (the best). Conventional regression cannot deal with visual inspection data that are linguistic or non-crisp. In contrast, fuzzy regression is capable of handling such fuzzy data. In this paper, pavement conditions are exemplified by five membership functions and estimated by using fuzzy regression to better account the uncertainties of the traditional method. Also, a similarity indicator is applied to measure the goodness of fit. A case study using pavement inspection data is presented to establish estimated fuzzy regression equations. The results demonstrate the capability of the model, which is able to assist road administration units to determine desirable repair actions regarding the predicted pavement conditions.},
journal = {Expert Syst. Appl.},
month = aug,
pages = {10010–10017},
numpages = {8},
keywords = {Fuzzy regression analysis, Fuzzy sets, Pavement maintenance, Pavement performance, Predictions}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using machine learning to infer constraints for product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {constraints and variability mining, machine learning, software product lines, software testing, variability modeling},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Systematic literature review, Software product lines, Machine learning, Configurable systems}
}

@inproceedings{10.1145/1272996.1273002,
author = {Stewart, Christopher and Kelly, Terence and Zhang, Alex},
title = {Exploiting nonstationarity for performance prediction},
year = {2007},
isbn = {9781595936363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1272996.1273002},
doi = {10.1145/1272996.1273002},
abstract = {Real production applications ranging from enterprise applications to large e-commerce sites share a crucial but seldom-noted characteristic: The relative frequencies of transaction types in their workloads are nonstationary, i.e., the transaction mix changes over time. Accurately predicting application-level performance in business-critical production applications is an increasingly important problem. However, transaction mix nonstationarity casts doubt on the practical usefulness of prediction methods that ignore this phenomenon.This paper demonstrates that transaction mix nonstationarity enables a new approach to predicting application-level performance as a function of transaction mix. We exploit nonstationarity to circumvent the need for invasive instrumentation and controlled benchmarking during model calibration; our approach relies solely on lightweight passive measurements that are routinely collected in today's production environments. We evaluate predictive accuracy on two real business-critical production applications. The accuracy of our response time predictions ranges from 10% to 16% on these applications, and our models generalize well to workloads very different from those used for calibration.We apply our technique to the challenging problem of predicting the impact of application consolidation on transaction response times. We calibrate models of two testbed applications running on dedicated machines, then use the models to predict their performance when they run together on a shared machine and serve very different workloads. Our predictions are accurate to within 4% to 14%. Existing approaches to consolidation decision support predict post-consolidation resource utilizations. Our method allows application-level performance to guide consolidation decisions.},
booktitle = {Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007},
pages = {31–44},
numpages = {14},
keywords = {LAR regression, enterprise, internet services, mutli-tier, noninvasive, nonstationarity, performance prediction, realistic workloads},
location = {Lisbon, Portugal},
series = {EuroSys '07}
}

@inproceedings{10.5555/2512734.2512787,
author = {Henss, J\"{o}rg and Merkle, Philipp and Reussner, Ralf H.},
title = {The OMPCM simulator for model-based software performance prediction: poster abstract},
year = {2013},
isbn = {9781450324649},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {Software performance models play an important role in early stage quality evaluations. Performance models in particular allow for comparing architectural alternatives before unfavourable design decisions are made that need to be revised in a costly procedure. The Palladio component model (PCM) is a modelling language for component-based software architectures. Instances of the PCM can already be analysed for their performance using analytical or simulative approaches. It is, however, difficult to obtain accurate performance predictions for network-intensive distributed systems. This is mainly due to the simplistic network model used so far. In this paper, we present the OMPCM simulator, which integrates OMNeT++ network simulation with architecture-level software performance prediction. OMPCM models can be automatically created from PCM models using a chain of model transformations.},
booktitle = {Proceedings of the 6th International ICST Conference on Simulation Tools and Techniques},
pages = {354–357},
numpages = {4},
keywords = {component based software, palladio component model, simulation},
location = {Cannes, France},
series = {SimuTools '13}
}

@inproceedings{10.1145/3106195.3106213,
author = {Fu\ss{}berger, Nicolas and Zhang, Bo and Becker, Martin},
title = {A Deep Dive into Android's Variability Realizations},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106213},
doi = {10.1145/3106195.3106213},
abstract = {The open source Android operation system is widely used in both mobile consumer electronics as well as other industrial devices. It has actually become a variability-intensive system that can be highly customized to support different customers' requirements and hardware environments, which is a good inspiration for both practitioners and researchers. However, it is still unclear where and how variability is realized in its source code repository. In this paper, we conduct a systematic analysis on the variability realization of the Android operation system. The analysis focuses on the usage of different variability realization mechanisms (e.g., Conditional Compilation) in the Android source code and build environment. Finally, the study provides qualitative and quantitative results that help to understand i) what variability-specific artefacts exist in the Android source repository using which variability mechanisms and techniques; ii) how these artefacts express and instantiate variability along the layered Android realization architecture.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {69–78},
numpages = {10},
keywords = {Android, Variability Mechanisms, Variability Realization},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.5555/3199700.3199791,
author = {Kim, Yeseong and Mercati, Pietro and More, Ankit and Shriver, Emily and Rosing, Tajana},
title = {P4: phase-based power/performance prediction of heterogeneous systems via neural networks},
year = {2017},
publisher = {IEEE Press},
abstract = {The emergence of Internet of Things increases the complexity and the heterogeneity of computing platforms. Migrating workload between various platforms is one way to improve both energy efficiency and performance. Effective migration decisions require accurate estimates of its costs and benefits. To date, these estimates were done by either instrumenting the source code/binaries, thus causing high overhead, or by using power estimates from hardware performance counters, which work well for individual machines, but until now have not been accurate for predicting across different architectures. In this paper, we propose P4, a new Phase-based Power and Performance Prediction framework which identifies cross-platform application power and performance at runtime for heterogeneous computing systems. P4 analyzes and detects machine-independent application phases by characterizing computing platforms offline with a set of benchmarks, and then builds neural network-based models to automatically identify and generalize the complex cross-platform relationships for each benchmark phase. It then leverages these models along with performance counter measurements collected at runtime to estimate performance and power consumption if it were running on a completely different computing platform, including a different CPU architecture, without ever having to run it on there. We evaluate the proposed framework on four commercial heterogeneous platforms, ranging from X86 servers to mobile ARM-based architecture, with 129 industry-standard benchmarks. Our experimental results show that P4 can predict the power and performance changes with only 6.8% and 5.6% error, respectively, even for completely different architectures from the ones applications ran on.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {683–690},
numpages = {8},
keywords = {neural networks, performance prediction, phase recognition, power prediction},
location = {Irvine, California},
series = {ICCAD '17}
}

@inproceedings{10.1145/1277741.1277835,
author = {Zhou, Yun and Croft, W. Bruce},
title = {Query performance prediction in web search environments},
year = {2007},
isbn = {9781595935977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1277741.1277835},
doi = {10.1145/1277741.1277835},
abstract = {Current prediction techniques, which are generally designed for content-based queries and are typically evaluated on relatively homogenous test collections of small sizes, face serious challenges in web search environments where collections are significantly more heterogeneous and different types of retrieval tasks exist. In this paper, we present three techniques to address these challenges. We focus on performance prediction for two types of queries in web search environments: content-based and Named-Page finding. Our evaluation is mainly performed on the GOV2 collection. In addition to evaluating our models for the two types of queries separately, we consider a more challenging and realistic situation that the two types of queries are mixed together without prior information on query types. To assist prediction under the mixed-query situation, a novel query classifier is adopted. Results show that our prediction of web query performance is substantially more accurate than the current state-of-the-art prediction techniques. Consequently, our paper provides a practical approach to performance prediction in real-world web settings.},
booktitle = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {543–550},
numpages = {8},
keywords = {query classification, query performance prediction, web search},
location = {Amsterdam, The Netherlands},
series = {SIGIR '07}
}

@article{10.1016/j.jss.2008.03.066,
author = {Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
title = {The Palladio component model for model-driven performance prediction},
year = {2009},
issue_date = {January, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2008.03.066},
doi = {10.1016/j.jss.2008.03.066},
abstract = {One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independently from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influencing factors like the hardware platform or the usage profile into account. Our approach uses the Palladio component model (PCM) to specify component-based software architectures in a parametric way. This model offers direct support of the CBSE development process by dividing the model creation among the developer roles. This paper presents our model and a simulation tool based on it, which is capable of making performance predictions. Within a case study, we show that the resulting prediction accuracy is sufficient to support the evaluation of architectural design decisions.},
journal = {J. Syst. Softw.},
month = jan,
pages = {3–22},
numpages = {20},
keywords = {Component-based software engineering, Performance prediction, Software architecture}
}

@article{10.1504/ijitm.2019.103055,
author = {Peng, Xiao},
title = {CPPM: a lightweight performance prediction middleware for cloud platforms},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {4},
issn = {1461-4111},
url = {https://doi.org/10.1504/ijitm.2019.103055},
doi = {10.1504/ijitm.2019.103055},
abstract = {As more and more commercial clouds have been applied in various areas, how to evaluate the performance of a cloud platform has become an important issue that needs to be addressed. Furthermore, an effective performance prediction mechanism is of significant value for improving the current cloud services, such as resource allocation and task scheduling. In the paper, we present the design and prototype implementation of a performance prediction system, namely cloud performance prediction middleware (CPPM), which is aiming at providing a set of lightweight and flexible services on existing cloud infrastructure so as to allow cloud providers monitoring, estimating and predicting the runtime performance from various aspects. The CPPM enables cloud providers to make more efficient and fine-grained resource management and scheduling policies based on their short-term workload prediction mechanism; also it provides an application-level performance prediction service which uses skeleton approach to capture execution characteristics of the running applications so as to predict their actual runtime performance and efficiency. Extensive experiments are conducted to examine the effectiveness and efficiency of the CPPM.},
journal = {Int. J. Inf. Technol. Manage.},
month = jan,
pages = {419–434},
numpages = {15},
keywords = {cloud computing, performance evaluation, workload, quality of service}
}

@article{10.1016/j.peva.2009.07.006,
author = {Happe, Jens and Becker, Steffen and Rathfelder, Christoph and Friedrich, Holger and Reussner, Ralf H.},
title = {Parametric performance completions for model-driven performance prediction},
year = {2010},
issue_date = {August, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {67},
number = {8},
issn = {0166-5316},
url = {https://doi.org/10.1016/j.peva.2009.07.006},
doi = {10.1016/j.peva.2009.07.006},
abstract = {Performance prediction methods can help software architects to identify potential performance problems, such as bottlenecks, in their software systems during the design phase. In such early stages of the software life-cycle, only a little information is available about the system's implementation and execution environment. However, these details are crucial for accurate performance predictions. Performance completions close the gap between available high-level models and required low-level details. Using model-driven technologies, transformations can include details of the implementation and execution environment into abstract performance models. However, existing approaches do not consider the relation of actual implementations and performance models used for prediction. Furthermore, they neglect the broad variety of possible implementations and middleware platforms, possible configurations, and possible usage scenarios. In this paper, we (i) establish a formal relation between generated performance models and generated code, (ii) introduce a design and application process for parametric performance completions, and (iii) develop a parametric performance completion for Message-oriented Middleware according to our method. Parametric performance completions are independent of a specific platform, reflect performance-relevant software configurations, and capture the influence of different usage scenarios. To evaluate the prediction accuracy of the completion for Message-oriented Middleware, we conducted a real-world case study with the SPECjms2007 Benchmark [http://www.spec.org/jms2007/]. The observed deviation of measurements and predictions was below 10% to 15%.},
journal = {Perform. Eval.},
month = aug,
pages = {694–716},
numpages = {23},
keywords = {Message-oriented middleware, Model-driven performance engineering, Performance completion, Software architecture, Software performance engineering}
}

@inproceedings{10.1145/1958746.1958789,
author = {Kraft, Stephan and Casale, Giuliano and Krishnamurthy, Diwakar and Greer, Des and Kilpatrick, Peter},
title = {IO performance prediction in consolidated virtualized environments},
year = {2011},
isbn = {9781450305198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958746.1958789},
doi = {10.1145/1958746.1958789},
abstract = {We propose a trace-driven approach to predict the performance degradation of disk request response times due to storage device contention in consolidated virtualized environments. Our performance model evaluates a queueing network with fair share scheduling using trace-driven simulation. The model parameters can be deduced from measurements obtained inside Virtual Machines (VMs) from a system where a single VM accesses a remote storage server. The parameterized model can then be used to predict the effect of storage contention when multiple VMs are consolidated on the same virtualized server. The model parameter estimation relies on a search technique that tries to estimate the splitting and merging of blocks at the the Virtual Machine Monitor (VMM) level in the case of multiple competing VMs. Simulation experiments based on traces of the Postmark and FFSB disk benchmarks show that our model is able to accurately predict the impact of workload consolidation on VM disk IO response times.},
booktitle = {Proceedings of the 2nd ACM/SPEC International Conference on Performance Engineering},
pages = {295–306},
numpages = {12},
location = {Karlsruhe, Germany},
series = {ICPE '11}
}

@inproceedings{10.5555/1620754.1620820,
author = {Chen, Stanley F.},
title = {Performance prediction for exponential language models},
year = {2009},
isbn = {9781932432411},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We investigate the task of performance prediction for language models belonging to the exponential family. First, we attempt to empirically discover a formula for predicting test set cross-entropy for n-gram language models. We build models over varying domains, data set sizes, and n-gram orders, and perform linear regression to see whether we can model test set performance as a simple function of training set performance and various model statistics. Remarkably, we find a simple relationship that predicts test set performance with a correlation of 0.9997. We analyze why this relationship holds and show that it holds for other exponential language models as well, including class-based models and minimum discrimination information models. Finally, we discuss how this relationship can be applied to improve language model performance.},
booktitle = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
pages = {450–458},
numpages = {9},
location = {Boulder, Colorado},
series = {NAACL '09}
}

@inproceedings{10.1145/3109729.3109757,
author = {S\'{a}nchez, Ana B. and Segura, Sergio},
title = {SmarTest: A Test Case Prioritization Tool for Drupal},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109757},
doi = {10.1145/3109729.3109757},
abstract = {Test case prioritization techniques aim to identify the optimal ordering of tests to accelerate the detection of faults. The importance of these techniques has been recognized in the context of Software Product Lines (SPLs), where the potentially huge number of products makes testing extremely challenging. We found that the open source Drupal framework shares most of the principles and challenges of SPL development and it can be considered a real-world example of family of products. In a previous work, we represented the Drupal configuration space as a feature model and we collected extra functional information about its features from open repositories. Part of this data proved to be a good indicator of faults propensity in Drupal features. Thus, they become valuable assets to prioritize tests in individual Drupal products. In this paper, we present SmarTest, a test prioritization tool for accelerating the detection of faults in Drupal. SmarTest has been developed as an extension of the Drupal core testing system. SmarTest supports the prioritization of tests providing faster feedback and letting testers begin correcting critical faults earlier. Different test prioritization criteria can be selected in SmarTest, such as prioritization based on the number of commits made in the code, or based on the tests that failed in last executions. A customizable dashboard with significant system information to guide the testing is also provided by SmarTest at run-time. This work represents an interesting application of SPL-inspired testing techniques to real-world software systems, which could be applicable to other open-source SPLs.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {9–12},
numpages = {4},
keywords = {Prioritization, Software product lines, Testing, Tool, Variability},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1007/978-3-642-41398-8_19,
author = {Garland, Joshua and Bradley, Elizabeth},
title = {On the Importance of Nonlinear Modeling in Computer Performance Prediction},
year = {2013},
isbn = {9783642413971},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-41398-8_19},
doi = {10.1007/978-3-642-41398-8_19},
abstract = {Computers are nonlinear dynamical systems that exhibit complex and sometimes even chaotic behavior. The low-level performance models used in the computer systems community, however, are linear. This paper is an exploration of that disconnect: when linear models are adequate for predicting computer performance and when they are not. Specifically, we build linear and nonlinear models of the processor load of an Intel i7-based computer as it executes a range of different programs. We then use those models to predict the processor loads forward in time and compare those forecasts to the true continuations of the time series.},
booktitle = {Proceedings of the 12th International Symposium on Advances in Intelligent Data Analysis XII - Volume 8207},
pages = {210–222},
numpages = {13},
location = {London, UK},
series = {IDA 2013}
}

@inproceedings{10.1109/MODELS-C.2019.00045,
author = {Bilic, Damir and Brosse, Etienne and Sadovykh, Andrey and Truscan, Dragos and Bruneliere, Hugo and Ryssel, Uwe},
title = {An integrated model-based tool chain for managing variability in complex system design},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00045},
doi = {10.1109/MODELS-C.2019.00045},
abstract = {Software-intensive systems in the automotive domain are often built in different variants, notably in order to support different market segments and legislation regions. Model-based concepts are frequently applied to manage complexity in such variable systems. However, the considered approaches are often focused on single-product development. In order to support variable products in a model-based systems engineering environment, we describe a tool-supported approach that allows us to annotate SysML models with variability data. Such variability information is exchanged between the system modeling tool and variability management tools through the Variability Exchange Language. The contribution of the paper includes the introduction of the model-based product line engineering tool chain and its application on a practical case study at Volvo Construction Equipment. Initial results suggest an improved efficiency in developing such a variable system.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems Companion},
pages = {288–293},
numpages = {6},
keywords = {integrated tool chain, model-based systems engineering, product line engineering},
location = {Munich, Germany},
series = {MODELS '19 Companion}
}

@article{10.1155/2014/686130,
author = {Chen, Zhan-bo},
title = {Research on application of regression least squares support vector machine on performance prediction of hydraulic excavator},
year = {2014},
issue_date = {January 2014},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2014},
issn = {1687-5249},
url = {https://doi.org/10.1155/2014/686130},
doi = {10.1155/2014/686130},
abstract = {In order to improve the performance prediction accuracy of hydraulic excavator, the regression least squares support vector machine is applied. First, the mathematical model of the regression least squares support vector machine is studied, and then the algorithm of the regression least squares support vector machine is designed. Finally, the performance prediction simulation of hydraulic excavator based on regression least squares support vector machine is carried out, and simulation results show that this method can predict the performance changing rules of hydraulic excavator correctly.},
journal = {J. Control Sci. Eng.},
month = jan,
articleno = {25},
numpages = {1}
}

@inproceedings{10.1109/SASO.2010.41,
author = {Couceiro, Maria and Romano, Paolo and Rodrigues, Luis},
title = {A Machine Learning Approach to Performance Prediction of Total Order Broadcast Protocols},
year = {2010},
isbn = {9780769542324},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SASO.2010.41},
doi = {10.1109/SASO.2010.41},
abstract = {Total Order Broadcast (TOB) is a fundamental building block at the core of a number of strongly consistent, fault-tolerant replication schemes. While it is widely known that the performance of existing TOB algorithms varies greatly depending on the workload and deployment scenarios, the problem of how to forecast their performance in realistic settings is, at current date, still largely unexplored. In this paper we address this problem by exploring the possibility of leveraging on machine learning techniques for building, in a fully decentralized fashion, performance models of TOB protocols. Based on an extensive experimental study considering heterogeneous workloads and multiple TOB protocols, we assess the accuracy and efficiency of alternative machine learning methods including neural networks, support vector machines, and decision tree-based regression models. We propose two heuristics for the feature selection phase, that allow to reduce its execution time up to two orders of magnitude incurring in a very limited loss of prediction accuracy.},
booktitle = {Proceedings of the 2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems},
pages = {184–193},
numpages = {10},
keywords = {Machine Learning, Performance Prediction, Total Order Broadcast},
series = {SASO '10}
}

@inproceedings{10.1145/2791060.2791098,
author = {Becker, Martin and Zhang, Bo},
title = {Lean variation management: increasing business value with a diversified approach},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791098},
doi = {10.1145/2791060.2791098},
abstract = {Managing product variants and versions in an integrated way, e.g. to cope with the inherent complexity of product or solution portfolios, to reduce time to market, or to provide a coherent user experience to end users, is an ever increasing engineering challenge and competition factor in all business segments. Various engineering approaches including cloning, product or component platforms, product lines, production lines, and configurable systems are followed in practice to cope with the product variation in space and time. Unfortunately, there is no silver-bullet approach, and companies have to choose and adopt respective approaches in a deliberate way, but there is often only limited understanding of how to do so. Adoption problems, unexploited potential, wasted investments, frustration and disapproval are typical symptoms, which can be seen in consequence in the wild.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {385},
numpages = {1},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2791060.2791093,
author = {Souto, Sabrina and Gopinath, Divya and d'Amorim, Marcelo and Marinov, Darko and Khurshid, Sarfraz and Batory, Don},
title = {Faster bug detection for software product lines with incomplete feature models},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791093},
doi = {10.1145/2791060.2791093},
abstract = {A software product line (SPL) is a family of programs that are differentiated by features --- increments in functionality. Systematically testing an SPL is challenging because it requires running each test of a test suite against a combinatorial number of programs. Feature models capture dependencies among features and can (1) reduce the space of programs to test and (2) enable accurate categorization of failing tests as failures of programs or the tests themselves, not as failures due to illegal combinations of features. In practice, sadly, feature models are not always available.We introduce SPLif, the first approach for testing SPLs that does not require the a priori availability of feature models. Our insight is to use a profile of passing and failing test runs to quickly identify failures that are indicative of real problems in test or code rather than specious failures due to illegal feature combinations.Experimental results on five SPLs and one large configurable system (GCC) demonstrate the effectiveness of our approach. SPLif enabled the discovery of five news bugs in GCC, three of which have already been fixed.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {151–160},
numpages = {10},
keywords = {GCC, feature models, software testing},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.asoc.2007.02.001,
author = {Ravi, V. and Kurniawan, H. and Thai, Peter Nwee Kok and Kumar, P. Ravi},
title = {Soft computing system for bank performance prediction},
year = {2008},
issue_date = {January, 2008},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {8},
number = {1},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2007.02.001},
doi = {10.1016/j.asoc.2007.02.001},
abstract = {This paper presents a soft computing based bank performance prediction system. It is an ensemble system whose constituent models are a multi-layered feed forward neural network trained with backpropagation (MLFF-BP), a probabilistic neural network (PNN) and a radial basis function neural network (RBFN), support vector machine (SVM), classification and regression trees (CART) and a fuzzy rule based classifier. Further, principal component analysis (PCA) based hybrid neural networks, viz. PCA-MLFF-BP, PCA-PNN and PCA-RBF are also included as constituents of the ensemble. Moreover, GRNN and PNN were trained with a genetic algorithm to optimize the smoothing factors. Two ensembles (i) simple majority voting based and (ii) weightage based are implemented. This system predicts the performance of a bank in the coming financial year based on its previous 2-years' financial data. Ten-fold cross-validation is performed in the training sessions and results are validated with an independent production set. It is demonstrated that the ensemble is able to yield lower Type I and Type II errors compared to its constituent models. Further, the ensemble also outperformed an earlier study [P.G. Swicegood, Predicting poor bank profitability: a comparison of neural network, discriminant analysis and professional human judgement, Ph.D. Thesis, Department of Finance, Florida State University, 1998] that used multivariate discriminant analysis (MDA), MLFF-BP and human judgment.},
journal = {Appl. Soft Comput.},
month = jan,
pages = {305–315},
numpages = {11},
keywords = {Bank performance prediction, Classification and regression trees, Ensemble system, Financial ratios, Fuzzy classifier, Neural networks, Soft computing, Support vector machine}
}

@article{10.1007/s11227-014-1292-9,
author = {Pallipuram, Vivek K. and Smith, Melissa C. and Sarma, Nilim and Anand, Ranajeet and Weill, Edwin and Sapra, Karan},
title = {Subjective versus objective: classifying analytical models for productive heterogeneous performance prediction},
year = {2015},
issue_date = {January   2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {71},
number = {1},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-014-1292-9},
doi = {10.1007/s11227-014-1292-9},
abstract = {Heterogeneous analytical models are valuable tools that facilitate optimal application tuning via runtime prediction; however, they require several man-hours of effort to understand and employ for meaningful performance prediction. Consequently, developers face the challenge of selecting adequate performance models that best fit their design goals and level of system knowledge. In this research, we present a classification that enables users to select a set of easy-to-use and reliable analytical models for quality performance prediction. These models, which target the general-purpose graphical processing unit (GPGPU)-based systems, are categorized into two primary analytical classes: subjective-analytical and objective-analytical. The subjective-analytical models predict the computation and communication components of an application by describing the system using minimum qualitative relations among the system parameters; whereas the objective-analytical models predict these components by measuring pertinent hardware events using micro-benchmarks. We categorize, enhance, and characterize the existing analytical models for GPGPU computations, network-level, and inter-connect communications to facilitate fast and reliable application performance prediction. We also explore a suitable combination of the aforementioned analytical classes, the hybrid approach, for high-quality performance prediction and report prediction accuracy up to 95 % for several tested GPGPU cluster configurations. The research aims to ultimately provide a collection of easy-to-select analytical models that promote straightforward and accurate performance prediction prior to large-scale implementation.},
journal = {J. Supercomput.},
month = jan,
pages = {162–201},
numpages = {40},
keywords = {Analytical modeling, GPGPU clusters, High-level abstraction, Kepler K20, Performance prediction, Qualitative analysis, Quantitative analysis, Synchronous iterative algorithms}
}

@inproceedings{10.1145/2602458.2602475,
author = {Noorshams, Qais and Reeb, Roland and Rentschler, Andreas and Kounev, Samuel and Reussner, Ralf},
title = {Enriching software architecture models with statistical models for performance prediction in modern storage environments},
year = {2014},
isbn = {9781450325776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2602458.2602475},
doi = {10.1145/2602458.2602475},
abstract = {Model-based performance prediction approaches on the software architecture-level provide a powerful tool for capacity planning due to their high abstraction level. To process the increasing amount of data produced by today's applications, modern storage systems are becoming increasingly complex having multiple tiers and intricate optimization strategies. Current software architecture-level modeling approaches, however, struggle to account for this development and are not well-suited in complex storage environments due to overly simplistic storage assumptions, which consequently leads to inaccurate performance predictions. To address this problem, in this paper we present a novel approach to combine software architecture-level performance models with statistical models that capture the complex behavior of modern storage systems. More specifically, we first propose a general methodology for enriching software architecture modeling approaches with statistical I/O performance models. Then, we present how we realize the modeling concepts as well as model solving to obtain performance results. Finally, we evaluate our approach extensively in the context of three case studies with two state-of-the-art environments based on Sun Fire and IBM System z server hardware. Using our approach, we are able to successfully predict the application performance within 20 % prediction error in almost all cases.},
booktitle = {Proceedings of the 17th International ACM Sigsoft Symposium on Component-Based Software Engineering},
pages = {45–54},
numpages = {10},
keywords = {i/o, performance, prediction, software architecture, statistical model, storage},
location = {Marcq-en-Bareul, France},
series = {CBSE '14}
}

@inproceedings{10.1145/3493244.3493250,
author = {Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Martinez, Jabier},
title = {Variability Debt: Characterization, Causes and Consequences},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493250},
doi = {10.1145/3493244.3493250},
abstract = {Variability is an inherent property of software systems to create families of products dealing with needs of different customers and environments. However, some practices to manage variability may incur technical debt. For example, the use of opportunistic reuse strategies, e.g., clone-and-own, harms maintenance and evolution activities; or deciding to abandon variability management and deriving a single product with all the features might threaten system usability. These examples are common problems found in practice but, to the best of or knowledge, not properly investigated from the perspective of technical debt. To expand the knowledge on the research and practice of technical debt in the perspective of variability management, we report results of this phenomenon, which we defined as variability debt. Our work is based on 52 industrial case studies that report problems observed in the use of opportunistic reuse. The results show that variability debt is caused by business, operational and technical aspects; leads to complex maintenance, creates difficulties to customize and create new products, misuse of human resources, usability problems; and impacts artifacts along the whole life-cycle. Although some of these issues are investigated in the field of systematic variability management, e.g., software product lines, our contribution is to present them from a technical debt perspective to enrich and create synergies between the two fields. As additional contribution, we present a catalog of variability debts in the light of technical debts found in the literature.},
booktitle = {Proceedings of the XX Brazilian Symposium on Software Quality},
articleno = {17},
numpages = {10},
keywords = {Software Product Lines, Technical Debt, Variability Debt, Variability management},
location = {Virtual Event, Brazil},
series = {SBQS '21}
}

@inproceedings{10.1145/3233027.3233030,
author = {Weckesser, Markus and Kluge, Roland and Pfannem\"{u}ller, Martin and Matth\'{e}, Michael and Sch\"{u}rr, Andy and Becker, Christian},
title = {Optimal reconfiguration of dynamic software product lines based on performance-influence models},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233030},
doi = {10.1145/3233027.3233030},
abstract = {Today's adaptive software systems (i) are often highly configurable product lines, exhibiting hundreds of potentially conflicting configuration options; (ii) are context dependent, forcing the system to reconfigure to ever-changing contextual situations at runtime; (iii) need to fulfill context-dependent performance goals by optimizing measurable nonfunctional properties. Usually, a large number of consistent configurations exists for a given context, and each consistent configuration may perform differently with regard to the current context and performance goal(s). Therefore, it is crucial to consider nonfunctional properties for identifying an appropriate configuration. Existing black-box approaches for estimating the performance of configurations provide no means for determining context-sensitive reconfiguration decisions at runtime that are both consistent and optimal, and hardly allow for combining multiple context-dependent quality goals. In this paper, we propose a comprehensive approach based on Dynamic Software Product Lines (DSPL) for obtaining consistent and optimal reconfiguration decisions. We use training data obtained from simulations to learn performance-influence models. A novel integrated runtime representation captures both consistency properties and the learned performance-influence models. Our solution provides the flexibility to define multiple context-dependent performance goals. We have implemented our approach as a standalone component. Based on an Internet-of-Things case study using adaptive wireless sensor networks, we evaluate our approach with regard to effectiveness, efficiency, and applicability.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {98–109},
numpages = {12},
keywords = {dynamic software product lines, machine learning, performance-influence models},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106206,
author = {Arcaini, Paolo and Gargantini, Angelo and Vavassori, Paolo},
title = {Automated Repairing of Variability Models},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106206},
doi = {10.1145/3106195.3106206},
abstract = {Variability models are a common means for describing the commonalities and differences in Software Product Lines (SPL); configurations of the SPL that respect the constraints imposed by the variability model define the problem space. The same variability is usually also captured in the final implementation through implementation constraints, defined in terms of preprocessor directives, build files, build-time errors, etc. Configurations satisfying the implementation constraints and producing correct (compilable) programs define the solution space. Since sometimes the variability model is defined after the implementation exists, it could wrongly assess the validity of some system configurations, i.e., it could consider acceptable some configurations (not belonging to the solution space) that do not permit to obtain a correct program. We here propose an approach that automatically repairs variability models such that the configurations they consider valid are also part of the solution space. Experiments show that some existing variability models are indeed faulty and can be repaired by our approach.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {9–18},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/1619258.1619300,
author = {Rathfelder, Christoph and Kounev, Samuel},
title = {Model-based performance prediction for event-driven systems},
year = {2009},
isbn = {9781605586656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1619258.1619300},
doi = {10.1145/1619258.1619300},
abstract = {The event-driven communication paradigm provides a number of advantages for building loosely coupled distributed systems. However, the loose coupling of components in such systems makes it hard for developers to estimate their behavior and performance under load. Most existing performance prediction techniques for systems using event-driven communication require specialized knowledge to build the necessary prediction models. In this paper, we propose an extension of the Palladio Component Model (PCM) that provides natural support for modeling event-based communication and supports different performance prediction techniques.},
booktitle = {Proceedings of the Third ACM International Conference on Distributed Event-Based Systems},
articleno = {33},
numpages = {2},
location = {Nashville, Tennessee},
series = {DEBS '09}
}

@inproceedings{10.1145/1216993.1217006,
author = {Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
title = {Model-Based performance prediction with the palladio component model},
year = {2007},
isbn = {1595932976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1216993.1217006},
doi = {10.1145/1216993.1217006},
abstract = {One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independent from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influence factors like the hardware platform or the usage profile into account. In our approach, we use the Palladio Component Model (PCM) to specify component-based software architectures in a parametric way. This model offers direct support of the CBSE development process by dividing the model creation among the developer roles. In this paper, we present our model and a simulation tool based on it, which is capable of making performance predictions. Within a case study, we show that the resulting prediction accuracy can be sufficient to support the evaluation of architectural design decisions.},
booktitle = {Proceedings of the 6th International Workshop on Software and Performance},
pages = {54–65},
numpages = {12},
keywords = {component-based software engineering, performance prediction, software architecture},
location = {Buenes Aires, Argentina},
series = {WOSP '07}
}

@inproceedings{10.1145/3109729.3109753,
author = {Tenev, Vasil and Duszynski, Slawomir and Becker, Martin},
title = {Variant Analysis: Set-Based Similarity Visualization for Cloned Software Systems},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109753},
doi = {10.1145/3109729.3109753},
abstract = {Software product lines are frequently created using an extractive approach, in which a group of existing software products is reengineered to extract their reusable core. To direct that effort, it is necessary to analyze the reuse potential and the code similarity across the products. We present Variant Analysis, a tool visualizing code similarity across a group of software systems. We represent the systems as intersecting sets of content elements, and place the elements similar between any n systems into the intersection of the respective n sets. Using the resulting set model and the system structure hierarchy, we provide similarity visualizations scaling for tens of compared software systems and millions lines of code. The current Variant Analysis tool analyzes similarity of text files such as source code. However, the underlying models and visualizations can also be used for other types of data, even beyond the software domain.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {22–27},
numpages = {6},
keywords = {Similarity, set model, set visualization, software cloning, tools},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1007/11731139_15,
author = {Liu, Yang and An, Aijun and Huang, Xiangji},
title = {Boosting prediction accuracy on imbalanced datasets with SVM ensembles},
year = {2006},
isbn = {3540332065},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11731139_15},
doi = {10.1007/11731139_15},
abstract = {Learning from imbalanced datasets is inherently difficult due to lack of information about the minority class. In this paper, we study the performance of SVMs, which have gained great success in many real applications, in the imbalanced data context. Through empirical analysis, we show that SVMs suffer from biased decision boundaries, and that their prediction performance drops dramatically when the data is highly skewed. We propose to combine an integrated sampling technique with an ensemble of SVMs to improve the prediction performance. The integrated sampling technique combines both over-sampling and under-sampling techniques. Through empirical study, we show that our method outperforms individual SVMs as well as several other state-of-the-art classifiers.},
booktitle = {Proceedings of the 10th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining},
pages = {107–118},
numpages = {12},
location = {Singapore},
series = {PAKDD'06}
}

@inproceedings{10.1145/2648511.2648549,
author = {Berger, Thorsten and St\u{a}nciulescu, \c{S}tefan and \O{}g\r{a}rd, Ommund and Haugen, \O{}ystein and Larsen, Bo and W\k{a}sowski, Andrzej},
title = {To connect or not to connect: experiences from modeling topological variability},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648549},
doi = {10.1145/2648511.2648549},
abstract = {Variability management aims at taming variability in large and complex software product lines. To efficiently manage variability, it has to be modeled using formal representations, such as feature or decision models. Such models are efficient in many domains, where variability is about switching on and off features, or using parameters to customize products of the product line. However, variability can be represented in the form of a topology in domains where variability is about connecting components in a certain order, in specific interconnected hierarchies, or in different quantities.In this experience report, we explore topological variability within a case study of large-scale fire alarm systems. We identify core characteristics of the variability, derive modeling requirements, model the variability using UML2 class diagrams, and discuss the applicability of further variability modeling languages. We show that, although challenging, class diagrams can suffice to represent topological variability in order to generate a configurator tool. In contrast, modeling parallel and recursive structures, cycles, informal constraints, and orthogonal hierarchies were among the main experienced challenges that require further research.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {330–339},
numpages = {10},
keywords = {class diagrams, configuration, experience report, software product lines, topology, variability modeling},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1109/MASCOTS.2010.44,
author = {Hauck, Michael and Happe, Jens and Reussner, Ralf H.},
title = {Automatic Derivation of Performance Prediction Models for Load-balancing Properties Based on Goal-oriented Measurements},
year = {2010},
isbn = {9780769541976},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MASCOTS.2010.44},
doi = {10.1109/MASCOTS.2010.44},
abstract = {In symmetric multiprocessing environments, the performance of a software system heavily depends on the application's parallelism, the scheduling and load-balancing policies of the operating system, and the infrastructure it is running on. The scheduling of tasks can influence the response time of an application by several orders of magnitude. Thus, detailed models of the operating system scheduler are essential for accurate performance predictions. However, building such models for schedulers and including them into performance prediction models involves a lot of effort. For this reason, simplified scheduler models are used for the performance evaluation of business information systems in general. In this work, we present an approach to derive load-balancing properties of general-purpose operating system (GPOS) schedulers automatically. Our approach uses goal-oriented measurements to derive performance models based on observations. Furthermore, the derived performance model is plugged into the Palladio Component Model (PCM), a model-based performance prediction approach. We validated the applicability of the approach and its prediction accuracy in a case study on different operating systems.},
booktitle = {Proceedings of the 2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},
pages = {361–369},
numpages = {9},
keywords = {Performance Prediction, Load-balancing, Measurement, Modelling},
series = {MASCOTS '10}
}

@article{10.5555/3227237.3227507,
author = {Zhou, Yun and Croft, W. Bruce},
title = {Measuring ranked list robustness for query performance prediction},
year = {2008},
issue_date = {August    2008},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {2},
issn = {0219-1377},
abstract = {We introduce the notion of ranking robustness, which refers to a property of a ranked list of documents that indicates how stable the ranking is in the presence of uncertainty in the ranked documents. We propose a statistical measure called the robustness score to quantify this notion. Our initial motivation for measuring ranking robustness is to predict topic difficulty for content-based queries in the ad-hoc retrieval task. Our results demonstrate that the robustness score is positively and consistently correlation with average precision of content-based queries across a variety of TREC test collections. Though our focus is on prediction under the ad-hoc retrieval task, we observe an interesting negative correlation with query performance when our technique is applied to named-page finding queries, which are a fundamentally different kind of queries. A side effect of this different behavior of the robustness score between the two types of queries is that the robustness score is also found to be a good feature for query classification.},
journal = {Knowl. Inf. Syst.},
month = aug,
pages = {155–171},
numpages = {17},
keywords = {Ad-hoc retrieval, Algorithms, Experimentation, Named-page finding, Query classification, Query performance prediction, Ranking robustness, Theory}
}

@inproceedings{10.1007/978-3-540-87412-6_3,
author = {Martens, Anne and Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
title = {An Empirical Investigation of the Applicability of a Component-Based Performance Prediction Method},
year = {2008},
isbn = {9783540874119},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-87412-6_3},
doi = {10.1007/978-3-540-87412-6_3},
abstract = {Component-based software performance engineering (CBSPE) methods shall enable software architects to assess the expected response times, throughputs, and resource utilization of their systems already during design. This avoids the violation of performance requirements. Existing approaches for CBSPE either lack tool support or rely on prototypical tools, who have only been applied by their authors. Therefore, industrial applicability of these methods is unknown. On this behalf, we have conducted a controlled experiment involving 19 computer science students, who analysed the performance of two component-based designs using our Palladio performance prediction approach, as an example for a CBSPE method. Our study is the first of its type in this area and shall help to mature CBSPE to industrial applicability. In this paper, we report on results concerning the prediction accuracy achieved by the students and list several lessons learned, which are also relevant for other methods than Palladio.},
booktitle = {Proceedings of the 5th European Performance Engineering Workshop on Computer Performance Engineering},
pages = {17–31},
numpages = {15},
keywords = {Controlled Experiment, Empirical Study, Performance Prediction},
location = {Palma de Mallorca, Spain},
series = {EPEW '08}
}

@inproceedings{10.1145/1273463.1273482,
author = {Cohen, Myra B. and Dwyer, Matthew B. and Shi, Jiangfan},
title = {Interaction testing of highly-configurable systems in the presence of constraints},
year = {2007},
isbn = {9781595937346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1273463.1273482},
doi = {10.1145/1273463.1273482},
abstract = {Combinatorial interaction testing (CIT) is a method to sample configurations of a software system systematically for testing. Many algorithms have been developed that create CIT samples, however few have considered the practical concerns that arise when adding constraints between combinations of options. In this paper, we survey constraint handling techniques in existing algorithms and discuss the challenges that they present. We examine two highly-configurable software systems to quantify the nature of constraints in real systems. We then present a general constraint representation and solving technique that can be integrated with existing CIT algorithms and compare two constraint-enhanced algorithm implementations with existing CIT tools to demonstrate feasibility.},
booktitle = {Proceedings of the 2007 International Symposium on Software Testing and Analysis},
pages = {129–139},
numpages = {11},
keywords = {SAT, combinatorial interaction testing, constraints, covering arrays},
location = {London, United Kingdom},
series = {ISSTA '07}
}

@inproceedings{10.1145/3336294.3336319,
author = {Carvalho, Luiz and Garcia, Alessandro and Assun\c{c}\~{a}o, Wesley K. G. and Bonif\'{a}cio, Rodrigo and Tizzei, Leonardo P. and Colanzi, Thelma Elita},
title = {Extraction of Configurable and Reusable Microservices from Legacy Systems: An Exploratory Study},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336319},
doi = {10.1145/3336294.3336319},
abstract = {Microservices is an emerging industrial technique to promote better modularization and management of small and autonomous services. Microservice architecture is widely used to overcome the limitations of monolithic legacy systems, such as limited maintainability and reusability. Migration to a microservice architecture is increasingly becoming the focus of academic research. However, there is little knowledge on how microservices are extracted from legacy systems in practice. Among these limitations, there is a lack of understanding if variability is considered useful along the microservice extraction from a configurable system. In order to address this gap, we performed an exploratory study composed of two phases. Firstly, we conducted an online survey with 26 specialists that contributed to the migration of existing systems to a microservice architecture. Secondly, we performed individual interviews with seven survey participants. A subset of the participants (13 out of 26) dealt with systems with variability during the extraction, which stated that variability is a key criterion for structuring the microservices. Moreover, variability in the legacy system is usually implemented with simple mechanisms. Finally, initial evidence points out that microservices extraction can increase software customization.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {26–31},
numpages = {6},
keywords = {architecture migration, microservice architecture, microservice customization, software variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/1375457.1375510,
author = {Li, Bin and Peng, Lu and Ramadass, Balachandran},
title = {Efficient mart-aided modeling for microarchitecture design space exploration and performance prediction},
year = {2008},
isbn = {9781605580050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375457.1375510},
doi = {10.1145/1375457.1375510},
abstract = {Computer architects usually evaluate new designs by cycle-accurate processor simulation. This approach provides detailed insight into processor performance, power consumption and complexity. However, only configurations in a subspace can be simulated in practice due to long simulation time and limited resource, leading to suboptimal conclusions which might not be applied in a larger design space. In this paper, we propose an automated performance prediction approach which employs state-of-the-art techniques from experiment design, machine learning and data mining. Our method not only produces highly accurate estimations for unsampled points in the design space, but also provides interpretation tools that help investigators to understand performance bottlenecks. According to our experiments, by sampling only 0.02% of the full design space with about 15 millions points, the median percentage errors, based on 5000 independent test points, range from 0.32% to 3.12% in 12 benchmarks. Even for the worst-case performance, the percentage errors are within 7% for 10 out of 12 benchmarks. In addition, the proposed model can also help architects to find important design parameters and performance bottlenecks.},
booktitle = {Proceedings of the 2008 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {439–440},
numpages = {2},
keywords = {MART-aided models, design space exploration, performance prediction},
location = {Annapolis, MD, USA},
series = {SIGMETRICS '08}
}

@article{10.1007/s10270-016-0566-5,
author = {V\"{o}gele, Christian and Hoorn, Andr\'{e} and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
title = {WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction--a model-driven approach for session-based application systems},
year = {2018},
issue_date = {May       2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {2},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-016-0566-5},
doi = {10.1007/s10270-016-0566-5},
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.},
journal = {Softw. Syst. Model.},
month = may,
pages = {443–477},
numpages = {35},
keywords = {Load testing, Performance models, Performance prediction, Workload specifications}
}

@inproceedings{10.1109/ISWC.2005.52,
author = {Krause, Andreas and Ihmig, Matthias and Rankin, Edward and Leong, Derek and Gupta, Smriti and Siewiorek, Daniel and Smailagic, Asim and Deisher, Michael and Sengupta, Uttam},
title = {Trading off Prediction Accuracy and Power Consumption for Context-Aware Wearable Computing},
year = {2005},
isbn = {0769524192},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISWC.2005.52},
doi = {10.1109/ISWC.2005.52},
abstract = {Context-aware mobile computing requires wearable sensors to acquire information about the user. Continuous sensing rapidly depletes the wearable system's energy, which is a critically constrained resource. In this paper, we analyze the trade-off between power consumption and prediction accuracy of context classifiers working on dual-axis accelerometer data collected from the eWatch sensing and notification platform. We improve power consumption techniques by providing competitive classification performance even in the low frequency region of 1-10 Hz and for the highly erratic wrist based sensing location. Furthermore, we propose and analyze a collection of selective sampling strategies in order to reduce the number of required sensor readings and the computation cycles even further. Our results indicate that optimized sampling schemes can increase the deployment lifetime of a wearable computing platform by a factor of four without a significant loss in prediction accuracy.},
booktitle = {Proceedings of the Ninth IEEE International Symposium on Wearable Computers},
pages = {20–26},
numpages = {7},
series = {ISWC '05}
}

@inproceedings{10.1145/1005686.1005743,
author = {Wang, Mengzhi and Au, Kinman and Ailamaki, Anastassia and Brockwell, Anthony and Faloutsos, Christos and Ganger, Gregory R.},
title = {Storage device performance prediction with CART models},
year = {2004},
isbn = {1581138733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1005686.1005743},
doi = {10.1145/1005686.1005743},
abstract = {This work explores the application of a machine learning tool, CART modeling, to storage devices. We have developed approaches to predict a device's performance as a function of input workloads, requiring no knowledge of the device internals. Two uses of CART models are considered: one that predicts per-request response times (and then derives aggregate values) and one that predicts aggregate values directly from workload characteristics. After training on the device in question, both provide reasonably-accurate black box models across a range of test traces from real environments. An expanded version of this paper is available as a technical report [1].},
booktitle = {Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems},
pages = {412–413},
numpages = {2},
keywords = {performance prediction, storage device modeling},
location = {New York, NY, USA},
series = {SIGMETRICS '04/Performance '04}
}

@inproceedings{10.1145/1134285.1134449,
author = {Twala, Bhekisipho and Cartwright, Michelle and Shepperd, Martin},
title = {Ensemble of missing data techniques to improve software prediction accuracy},
year = {2006},
isbn = {1595933751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134285.1134449},
doi = {10.1145/1134285.1134449},
abstract = {Software engineers are commonly faced with the problem of incomplete data. Incomplete data can reduce system performance in terms of predictive accuracy. Unfortunately, rare research has been conducted to systematically explore the impact of missing values, especially from the missing data handling point of view. This has made various missing data techniques (MDTs) less significant. This paper describes a systematic comparison of seven MDTs using eight industrial datasets. Our findings from an empirical evaluation suggest listwise deletion as the least effective technique for handling incomplete data while multiple imputation achieves the highest accuracy rates. We further propose and show how a combination of MDTs by randomizing a decision tree building algorithm leads to a significant improvement in prediction performance for missing values up to 50%.},
booktitle = {Proceedings of the 28th International Conference on Software Engineering},
pages = {909–912},
numpages = {4},
keywords = {decision trees, ensemble, incomplete data, machine learning, software prediction},
location = {Shanghai, China},
series = {ICSE '06}
}

@inproceedings{10.1145/2791060.2791074,
author = {Reuling, Dennis and B\"{u}rdek, Johannes and Rot\"{a}rmel, Serge and Lochau, Malte and Kelter, Udo},
title = {Fault-based product-line testing: effective sample generation based on feature-diagram mutation},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791074},
doi = {10.1145/2791060.2791074},
abstract = {Testing every member of a product line individually is often impracticable due to large number of possible product configurations. Thus, feature models are frequently used to generate samples, i.e., subsets of product configurations under test. Besides the extensively studied combinatorial interaction testing (CIT) approach for coverage-driven sample generation, only few approaches exist so far adopting mutation testing to emulate faults in feature models to be detected by a sample. In this paper, we present a mutation-based sampling framework for fault-based product-line testing. We define a comprehensive catalog of atomic mutation operators on the graphical representation of feature models. This way, we are able (1) to also define complex mutation operators emulating more subtle faults, and (2) to classify operators semantically, e.g., to avoid redundant and equivalent mutants. We further introduce similarity-based mutant selection and higher order mutation strategies to reduce testing efforts. Our implementation is based on the graph transformation engine Henshin and is evaluated concerning effectiveness/efficiency trade-offs.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {131–140},
numpages = {10},
keywords = {combinatorial interaction testing, mutation testing},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1007/978-3-540-87891-9_2,
author = {Martens, Anne and Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
title = {An Empirical Investigation of the Effort of Creating Reusable, Component-Based Models for Performance Prediction},
year = {2008},
isbn = {9783540878902},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-87891-9_2},
doi = {10.1007/978-3-540-87891-9_2},
abstract = {Model-based performance prediction methods aim at evaluating the expected response time, throughput, and resource utilisation of a software system at design time, before implementation. Existing performance prediction methods use monolithic, throw-away prediction models or component-based, reusable prediction models. While it is intuitively clear that the development of reusable models requires more effort, the actual higher amount of effort has not been quantified or analysed systematically yet. To study the effort, we conducted a controlled experiment with 19 computer science students who predicted the performance of two example systems applying an established, monolithic method (Software Performance Engineering) as well as our own component-based method (Palladio). The results show that the effort of model creation with Palladio is approximately 1.25 times higher than with SPE in our experimental setting, with the resulting models having comparable prediction accuracy. Therefore, in some cases, the creation of reusable prediction models can already be justified, if they are reused at least once.},
booktitle = {Proceedings of the 11th International Symposium on Component-Based Software Engineering},
pages = {16–31},
numpages = {16},
keywords = {Controlled Experiment, Empirical Study, Performance Prediction},
location = {Karlsruhe, Germany},
series = {CBSE '08}
}

@inproceedings{10.1145/3233027.3233046,
author = {Beek, Maurice H. ter and Fantechi, Alessandro and Gnesi, Stefania},
title = {Product line models of large cyber-physical systems: the case of ERTMS/ETCS},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233046},
doi = {10.1145/3233027.3233046},
abstract = {A product line perspective may help to understand the possible variants in interactions between the subsystems of a large, cyber-physical system. This observation is exemplified in this paper by proposing a feature model of the family of ERTMS/ETCS train control systems and their foreseen extensions. This model not only shows the different components that have to be installed when deploying the system at the different levels established by the ERTMS/ETCS standards, but it also helps to identify and discuss specific issues, such as the borders between onboard and wayside equipment, different manufacturers of the subsystems, interoperability among systems developed at different levels, backward compatibility of trains equipped with higher level equipment running on lines equipped with lower level equipment, and evolution towards future trends of railway signalling. The feature model forms the basis for formal modelling of the behaviour of the critical components of the system and for evaluating the overall cost, effectiveness and sustainability, for example by adding cost and performance attributes to the feature model.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {208–214},
numpages = {7},
keywords = {ERTMS/ETCS train control systems, cyber-physical systems, feature models, product lines, variability},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2791060.2791107,
author = {Ji, Wenbin and Berger, Thorsten and Antkiewicz, Michal and Czarnecki, Krzysztof},
title = {Maintaining feature traceability with embedded annotations},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791107},
doi = {10.1145/2791060.2791107},
abstract = {Features are commonly used to describe functional and nonfunctional aspects of software. To effectively evolve and reuse features, their location in software assets has to be known. However, locating features is often difficult given their crosscutting nature. Once implemented, the knowledge about a feature's location quickly deteriorates, requiring expensive recovering of these locations. Manually recording and maintaining traceability information is generally considered expensive and error-prone. In this paper, we argue to the contrary and hypothesize that such information can be effectively embedded into software assets, and that arising costs will be amortized by the benefits of this information later during development. We test this hypothesis in a study where we simulate the development of a product line of cloned/forked projects using a lightweight code annotation approach. We identify annotation evolution patterns and measure the cost and benefit of these annotations. Our results show that not only the cost of adding annotations, but also that of maintaining them is small compared to the actual development cost. Embedding the annotations into assets significantly reduced the maintenance cost because they naturally co-evolve with the assets. Our results also show that a majority of these annotations provides a benefit for feature-related code maintenance tasks, such as feature propagation and migrating clones into a platform.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {61–70},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2491627.2491632,
author = {Haber, Arne and H\"{o}lldobler, Katrin and Kolassa, Carsten and Look, Markus and Rumpe, Bernhard and M\"{u}ller, Klaus and Schaefer, Ina},
title = {Engineering delta modeling languages},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491632},
doi = {10.1145/2491627.2491632},
abstract = {Delta modeling is a modular, yet flexible approach to capture spatial and temporal variability by explicitly representing the differences between system variants or versions. The conceptual idea of delta modeling is language-independent. But, in order to apply delta modeling for a concrete language, so far, a delta language had to be manually developed on top of the base language leading to a large variety of heterogeneous language concepts. In this paper, we present a process that allows deriving a delta language from the grammar of a given base language. Our approach relies on an automatically generated language extension that can be manually adapted to meet domain-specific needs. We illustrate our approach using delta modeling on a textual variant of statecharts.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {22–31},
numpages = {10},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@article{10.1007/s10664-017-9557-6,
author = {Dintzner, Nicolas and Deursen, Arie and Pinzger, Martin},
title = {FEVER: An approach to analyze feature-oriented changes and artefact co-evolution in highly configurable systems},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9557-6},
doi = {10.1007/s10664-017-9557-6},
abstract = {The evolution of highly configurable systems is known to be a challenging task. Thorough understanding of configuration options their relationships, and their implementation in various types of artefacts (variability model, mapping, and implementation) is required to avoid compilation errors, invalid products, or dead code. Recent studies focusing on co-evolution of artefacts detailed feature-oriented change scenarios, describing how related artefacts might change over time. However, relying on manual analysis of commits, such work do not provide the means to obtain quantitative information on the frequency of described scenarios nor information on the exhaustiveness of the presented scenarios for the evolution of a large scale system. In this work, we propose FEVER and its instantiation for the Linux kernel. FEVER extracts detailed information on changes in variability models (KConfig files), assets (preprocessor based C code), and mappings (Makefiles). We apply this methodology to the Linux kernel and build a dataset comprised of 15 releases of the kernel history. We performed an evaluation of the FEVER approach by manually inspecting the data and compared it with commits in the system's history. The evaluation shows that FEVER accurately captures feature related changes for more than 85% of the 810 manually inspected commits. We use the collected data to reflect on occurrences of co-evolution in practice. Our analysis shows that complex co-evolution scenarios occur in every studied release but are not among the most frequent change scenarios, as they only occur for 8 to 13% of the evolving features. Moreover, only a minority of developers working on a given release will make changes to all artefacts related to a feature (between 10% and 13% of authors). While our conclusions are derived from observations on the evolution of the Linux kernel, we believe that they may have implications for tool developers as well as guide further research in the field of co-evolution of artefacts.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {905–952},
numpages = {48},
keywords = {Co-evolution, Feature, Highly variable systems, Variability}
}

@inproceedings{10.1007/978-3-642-13672-6_8,
author = {Shim, Kyong Jin and Sharan, Richa and Srivastava, Jaideep},
title = {Player performance prediction in massively multiplayer online role-playing games (MMORPGs)},
year = {2010},
isbn = {3642136710},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13672-6_8},
doi = {10.1007/978-3-642-13672-6_8},
abstract = {In this study, we propose a comprehensive performance management tool for measuring and reporting operational activities of game players This study uses performance data of game players in EverQuest II, a popular MMORPG developed by Sony Online Entertainment, to build performance prediction models for game players The prediction models provide a projection of player's future performance based on his past performance, which is expected to be a useful addition to existing player performance monitoring tools First, we show that variations of PECOTA [2] and MARCEL [3], two most popular baseball home run prediction methods, can be used for game player performance prediction Second, we evaluate the effects of varying lengths of past performance and show that past performance can be a good predictor of future performance up to a certain degree Third, we show that game players do not regress towards the mean and that prediction models built on buckets using discretization based on binning and histograms lead to higher prediction coverage.},
booktitle = {Proceedings of the 14th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining - Volume Part II},
pages = {71–80},
numpages = {10},
location = {Hyderabad, India},
series = {PAKDD'10}
}

@article{10.1007/s10586-007-0041-8,
author = {Zhang, Jian and Figueiredo, Renato J.},
title = {Learning-aided predictor integration for system performance prediction},
year = {2007},
issue_date = {December  2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {4},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-007-0041-8},
doi = {10.1007/s10586-007-0041-8},
abstract = {The integration of multiple predictors promises higher prediction accuracy than the accuracy that can be obtained with a single predictor. The challenge is how to select the best predictor at any given moment. Traditionally, multiple predictors are run in parallel and the one that generates the best result is selected for prediction. In this paper, we propose a novel approach for predictor integration based on the learning of historical predictions. Compared with the traditional approach, it does not require running all the predictors simultaneously. Instead, it uses classification algorithms such as k-Nearest Neighbor (  k-NN ) and Bayesian classification and dimension reduction technique such as Principal Component Analysis (  PCA ) to forecast the best predictor for the workload under study based on the learning of historical predictions. Then only the forecasted best predictor is run for prediction. Our experimental results show that it achieved 20.18% higher best predictor forecasting accuracy than the cumulative MSE based predictor selection approach used in the popular Network Weather Service system. In addition, it outperformed the observed most accurate single predictor in the pool for 44.23% of the performance traces.},
journal = {Cluster Computing},
month = dec,
pages = {425–442},
numpages = {18},
keywords = {Bayesian classification, Principal component analysis (PCA), System performance, Time-series prediction, Virtual machine, Virtual machine monitor, k-Nearest Neighbor (kNN)}
}

@inproceedings{10.5555/1413370.1413391,
author = {Susukita, Ryutaro and Ando, Hisashige and Aoyagi, Mutsumi and Honda, Hiroaki and Inadomi, Yuichi and Inoue, Koji and Ishizuki, Shigeru and Kimura, Yasunori and Komatsu, Hidemi and Kurokawa, Motoyoshi and Murakami, Kazuaki J. and Shibamura, Hidetomo and Yamamura, Shuji and Yu, Yunqing},
title = {Performance prediction of large-scale parallell system and application using macro-level simulation},
year = {2008},
isbn = {9781424428359},
publisher = {IEEE Press},
abstract = {To predict application performance on an HPC system is an important technology for designing the computing system and developing applications. However, accurate prediction is a challenge, particularly, in the case of a future coming system with higher performance.In this paper, we present a new method for predicting application performance on HPC systems. This method combines modeling of sequential performance on a single processor and macro-level simulations of applications for parallel performance on the entire system. In the simulation, the execution flow is traced but kernel computations are omitted for reducing the execution time. Validation on a real terascale system showed that the predicted and measured performance agreed within 10% to 20 %. We employed the method in designing a hypothetical petascale system of 32768 SIMD-extended processor cores. For predicting application performance on the petascale system, the macro-level simulation required several hours.},
booktitle = {Proceedings of the 2008 ACM/IEEE Conference on Supercomputing},
articleno = {20},
numpages = {9},
keywords = {component, large-scale application, large-scale system, performance prediction},
location = {Austin, Texas},
series = {SC '08}
}

@inproceedings{10.1145/3316781.3317867,
author = {Singh, Gagandeep and G\'{o}mez-Luna, Juan and Mariani, Giovanni and Oliveira, Geraldo F. and Corda, Stefano and Stuijk, Sander and Mutlu, Onur and Corporaal, Henk},
title = {NAPEL: Near-Memory Computing Application Performance Prediction via Ensemble Learning},
year = {2019},
isbn = {9781450367257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316781.3317867},
doi = {10.1145/3316781.3317867},
abstract = {The cost of moving data between the memory/storage units and the compute units is a major contributor to the execution time and energy consumption of modern workloads in computing systems. A promising paradigm to alleviate this data movement bottleneck is near-memory computing (NMC), which consists of placing compute units close to the memory/storage units. There is substantial research effort that proposes NMC architectures and identifies workloads that can benefit from NMC. System architects typically use simulation techniques to evaluate the performance and energy consumption of their designs. However, simulation is extremely slow, imposing long times for design space exploration. In order to enable fast early-stage design space exploration of NMC architectures, we need high-level performance and energy models.We present NAPEL, a high-level performance and energy estimation framework for NMC architectures. NAPEL leverages ensemble learning to develop a model that is based on microarchitectural parameters and application characteristics. NAPEL training uses a statistical technique, called design of experiments, to collect representative training data efficiently. NAPEL provides early design space exploration 220\texttimes{} faster than a state-of-the-art NMC simulator, on average, with error rates of to 8.5% and 11.6% for performance and energy estimations, respectively, compared to the NMC simulator. NAPEL is also capable of making accurate predictions for previously-unseen applications.},
booktitle = {Proceedings of the 56th Annual Design Automation Conference 2019},
articleno = {27},
numpages = {6},
location = {Las Vegas, NV, USA},
series = {DAC '19}
}

@inproceedings{10.1145/1152154.1152174,
author = {Hoste, Kenneth and Phansalkar, Aashish and Eeckhout, Lieven and Georges, Andy and John, Lizy K. and De Bosschere, Koen},
title = {Performance prediction based on inherent program similarity},
year = {2006},
isbn = {159593264X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1152154.1152174},
doi = {10.1145/1152154.1152174},
abstract = {A key challenge in benchmarking is to predict the performance of an application of interest on a number of platforms in order to determine which platform yields the best performance. This paper proposes an approach for doing this. We measure a number of microarchitecture-independent characteristics from the application of interest, and relate these characteristics to the characteristics of the programs from a previously profiled benchmark suite. Based on the similarity of the application of interest with programs in the benchmark suite, we make a performance prediction of the application of interest. We propose and evaluate three approaches (normalization, principal components analysis and genetic algorithm) to transform the raw data set of microarchitecture-independent characteristics into a benchmark space in which the relative distance is a measure for the relative performance differences. We evaluate our approach using all of the SPEC CPU2000 benchmarks and real hardware performance numbers from the SPEC website. Our framework estimates per-benchmark machine ranks with a 0.89 average and a 0.80 worst case rank correlation coefficient.},
booktitle = {Proceedings of the 15th International Conference on Parallel Architectures and Compilation Techniques},
pages = {114–122},
numpages = {9},
keywords = {inherent program behavior, performance modeling, workload characterization},
location = {Seattle, Washington, USA},
series = {PACT '06}
}

@inproceedings{10.1145/2522848.2533788,
author = {Luz, Saturnino},
title = {Automatic identification of experts and performance prediction in the multimodal math data corpus through analysis of speech interaction},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2533788},
doi = {10.1145/2522848.2533788},
abstract = {An analysis of multiparty interaction in the problem solving sessions of the Multimodal Math Data Corpus is presented. The analysis focuses on non-verbal cues extracted from the audio tracks. Algorithms for expert identification and performance prediction (correctness of solution) are implemented based on patterns of speech activity among session participants. Both of these categorisation algorithms employ an underlying graph-based representation of dialogues for each individual problem solving activities. The proposed Bayesian approach to expert prediction proved quite effective, reaching accuracy levels of over 92% with as few as 6 dialogues of training data. Performance prediction was not quite as effective. Although the simple graph-matching strategy employed for predicting incorrect solutions improved considerably over a Monte Carlo simulated baseline (F1 score increased by a factor of 2.3), there is still much room for improvement in this task.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {575–582},
numpages = {8},
keywords = {collaborative problem solving, multimodal math data corpus, vocalisation graphs},
location = {Sydney, Australia},
series = {ICMI '13}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Software product line, Configurable system, Software variability, Software testing, Machine learning, Quality assurance}
}

@inproceedings{10.1145/2362536.2362551,
author = {Tischer, Christian and Boss, Birgit and M\"{u}ller, Andreas and Thums, Andreas and Acharya, Rajneesh and Schmid, Klaus},
title = {Developing long-term stable product line architectures},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362551},
doi = {10.1145/2362536.2362551},
abstract = {Product lines are usually built for the long term in order to repay the initial investment. While long-term stable software systems are already hard, if they are developed individually, it is even harder for complete product lines. At the time a new product line is created, the details of future product line characteristics are typically not known, no matter how well and detailed scoping and planning is done. Thus, any product line needs to evolve and adapt over time to incorporate new customer requirements as well as new technology constraints.Stability of the product line architecture is very important to the successful long-term evolution of a product line. In this paper, we discuss how a form of domain decomposition, which we call conceptual architecture, can be used to guide product line engineering towards long-term viability. We will illustrate this approach in the context of a large-scale product line development and analyze the evolution properties of the product line. Transferability of the approach is suggested to other embedded software systems that drive mature, well-understood physical control system.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {86–95},
numpages = {10},
keywords = {AUTOSAR, multi product lines, scoping, software architecture, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1016/j.sysarc.2009.09.004,
author = {Li, Bin and Peng, Lu and Ramadass, Balachandran},
title = {Accurate and efficient processor performance prediction via regression tree based modeling},
year = {2009},
issue_date = {October, 2009},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {55},
number = {10–12},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2009.09.004},
doi = {10.1016/j.sysarc.2009.09.004},
abstract = {Computer architects usually evaluate new designs using cycle-accurate processor simulation. This approach provides a detailed insight into processor performance, power consumption and complexity. However, only configurations in a subspace can be simulated in practice due to long simulation time and limited resource, leading to suboptimal conclusions which might not be applied to a larger design space. In this paper, we propose a performance prediction approach which employs state-of-the-art techniques from experiment design, machine learning and data mining. According to our experiments on single and multi-core processors, our prediction model generates highly accurate estimations for unsampled points in the design space and show the robustness for the worst-case prediction. Moreover, the model provides quantitative interpretation tools that help investigators to efficiently tune design parameters and remove performance bottlenecks.},
journal = {J. Syst. Archit.},
month = oct,
pages = {457–467},
numpages = {11},
keywords = {Evaluation, Measurement, Modeling, Modeling of computer architecture, Modeling techniques, Simulation of multiple-processor systems}
}

@inproceedings{10.5555/1365774.1365813,
author = {Mizutani, Yasuharu and Ino, Fumihiko and Hagihara, Kenichi},
title = {Fast performance prediction of master-slave programs by partial task execution},
year = {2005},
isbn = {9608457092},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {In this paper, it is proposed to rapidly and accurately predict performance of master-slave (MS) parallel programs. To provide rapid prediction with high accuracy, our method reduces direct execution of the target MS program and estimates execution time of tasks of the program from only some directly executed tasks. In this estimation, we use a linear interpolation in order to reproduce the original order of task assignment, which affects the prediction accuracy of a performance saturation point. The experimental result shows that our proposed method predicts the performance of MS programs 1.7 times faster, at least, than the measured execution time which corresponds to the minimum time taken to predict the performance by prediction methods based on direct execution. Furthermore, our method predicts the performance with 7% error being as good as that of existing prediction method.},
booktitle = {Proceedings of the 4th WSEAS International Conference on Software Engineering, Parallel &amp; Distributed Systems},
articleno = {39},
numpages = {7},
keywords = {master-slave, parallel computational model, performance prediction, simulation},
location = {Salzburg, Austria},
series = {SEPADS'05}
}

@article{10.1145/2579993,
author = {Bellog\'{\i}n, Alejandro and Castells, Pablo and Cantador, Iv\'{a}n},
title = {Neighbor Selection and Weighting in User-Based Collaborative Filtering: A Performance Prediction Approach},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1559-1131},
url = {https://doi.org/10.1145/2579993},
doi = {10.1145/2579993},
abstract = {User-based collaborative filtering systems suggest interesting items to a user relying on similar-minded people called neighbors. The selection and weighting of these neighbors characterize the different recommendation approaches. While standard strategies perform a neighbor selection based on user similarities, trust-aware recommendation algorithms rely on other aspects indicative of user trust and reliability. In this article we restate the trust-aware recommendation problem, generalizing it in terms of performance prediction techniques, whose goal is to predict the performance of an information retrieval system in response to a particular query. We investigate how to adopt the preceding generalization to define a unified framework where we conduct an objective analysis of the effectiveness (predictive power) of neighbor scoring functions. The proposed framework enables discriminating whether recommendation performance improvements are caused by the used neighbor scoring functions or by the ways these functions are used in the recommendation computation. We evaluated our approach with several state-of-the-art and novel neighbor scoring functions on three publicly available datasets. By empirically comparing four neighbor quality metrics and thirteen performance predictors, we found strong predictive power for some of the predictors with respect to certain metrics. This result was then validated by checking the final performance of recommendation strategies where predictors are used for selecting and/or weighting user neighbors. As a result, we have found that, by measuring the predictive power of neighbor performance predictors, we are able to anticipate which predictors are going to perform better in neighbor-scoring-powered versions of a user-based collaborative filtering algorithm.},
journal = {ACM Trans. Web},
month = mar,
articleno = {12},
numpages = {30},
keywords = {Recommender systems, neighbor selection, neighbor weighting, performance prediction, trust, user-based collaborative filtering}
}

@inproceedings{10.1145/3240765.3264635,
author = {O'Neal, Kenneth and Liu, Mitch and Tang, Hans and Kalantar, Amin and DeRenard, Kennen and Brisk, Philip},
title = {HLSPredict: cross platform performance prediction for FPGA high-level synthesis},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3264635},
doi = {10.1145/3240765.3264635},
abstract = {FPGA application developers must explore increasingly large design spaces to identify regions of code to accelerate. High-Level Synthesis (HLS) tools automatically derive FPGA-based designs from high-level language specifications, which improves designer productivity; however, HLS tool run-times are cost-prohibitive for design space exploration, preventing designers from adequately answering cost-value decisions without expert guidance. To address this concern, this paper introduces a machine learning framework to predict FPGA performance and power consumption without relying on analytical models or HLS tools in-the-loop. For workloads that were manually optimized by appropriately setting pragmas, the framework obtains a worst-case relative error of 9.08% while running 43.78x faster than HLS; for unoptimized workloads, the framework obtains a worst-case relative error of 9.79% while running 36.24x faster than HLS.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {104},
numpages = {8},
keywords = {FPGA, cross-platform predictive modeling, high-level synthesis},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.5555/2029686.2029733,
author = {Hegenbart, Sebastian and Uhl, Andreas and V\'{e}csei, Andreas},
title = {Systematic assessment of performance prediction techniques in medical image classification: a case study on celiac disease},
year = {2011},
isbn = {9783642220913},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In the context of automated classification of medical images, many authors report a lack of available test data. Therefore techniques such as the leave-one-out cross validation or k-fold validation are used to assess how well methods will perform in practice. In case of methods based on feature subset selection, cross validation might provide bad estimations of how well the optimized technique generalizes on an independent data set. In this work, we assess how well cross validation techniques are suited to predict the outcome of a preferred setup of distinct test- and training data sets. This is accomplished by creating two distinct sets of images, used separately as training- and test-data. The experiments are conducted using a set of Local Binary Pattern based operators for feature extraction which are using histogram subset selection to improve the feature discrimination. Common problems such as the effects of over fitting data during cross validation as well as using biased image sets due to multiple images from a single patient are considered.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Medical Imaging},
pages = {498–509},
numpages = {12},
keywords = {LOPO, celiac disease, classification, cross validation, over fitting},
location = {Kloster Irsee, Germany},
series = {IPMI'11}
}

@article{10.1016/j.micpro.2020.103322,
author = {Haiyun, Zhu and Yizhe, Xu},
title = {RETRACTED: Sports performance prediction model based on integrated learning algorithm and cloud computing Hadoop platform},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {79},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103322},
doi = {10.1016/j.micpro.2020.103322},
journal = {Microprocess. Microsyst.},
month = nov,
numpages = {7}
}

@inproceedings{10.1145/3297280.3297479,
author = {Ne\v{s}i\'{c}, Damir and Nyberg, Mattias and Gallina, Barbara},
title = {Constructing product-line safety cases from contract-based specifications},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297479},
doi = {10.1145/3297280.3297479},
abstract = {Safety cases are used to argue that safety-critical systems satisfy the requirements that are determined to mitigate the potential hazards in the systems operating environment. Although typically a manual task, safety cases have been successfully created for systems without many configuration options. However, in highly configurable systems, typically developed as a Product Line (PL), arguing about each possible configuration, and ensuring the completeness of the safety case are still open research problems. This paper presents a novel and general approach, based on Contract-Based Specification (CBS), for the construction of a safety case for an arbitrary PL. Starting from a general CBS framework, we present a PL extensions that allows expressing configurable systems and preserves the properties of the original CBS framework. Then, we define the transformation from arbitrary PL models, created using extended CBS framework, to a safety case argumentation-structure, expressed using the Goal Structuring Notation. Finally, the approach is exemplified on a simplified, but real, and currently produced system by Scania CV AB.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2022–2031},
numpages = {10},
keywords = {contract-based specification, product line engineering, safety case},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@article{10.1016/j.compind.2006.12.004,
author = {Liu, Jianbo and Djurdjanovic, Dragan and Ni, Jun and Casoetto, Nicolas and Lee, Jay},
title = {Similarity based method for manufacturing process performance prediction and diagnosis},
year = {2007},
issue_date = {August, 2007},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {58},
number = {6},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2006.12.004},
doi = {10.1016/j.compind.2006.12.004},
abstract = {Full realization of all the potentials of predictive maintenance highly depends on the accuracy of long-term predictions of the remaining useful life of manufacturing equipments. In this paper, we propose a new method that is capable of achieving high long-term prediction accuracy by comparing signatures from any two degradation processes using measures of similarity that form a match matrix (MM). Through this concept, we can effectively include large amounts of historical information into the prediction of the current degradation process. Similarities with historical records are used to generate possible future distributions of features indicative of process performance, which are then used to predict the probabilities of failure over time by evaluating overlaps between predicted feature distributions and feature distributions related to unacceptable equipment behavior. The analysis of experimental results shows that the proposed method can yield a noticeable improvement of long-term prediction accuracy in terms of mean prediction errors over the Elman Recurrent Neural Network (ERNN) based prediction, which was shown in the past literature to predict well behavior of highly non-linear and non-stationary time series.},
journal = {Comput. Ind.},
month = aug,
pages = {558–566},
numpages = {9},
keywords = {Failure prediction, Match matrix, Predictive maintenance, Time series prediction}
}

@inproceedings{10.5555/1688165.1688168,
author = {Dai, Denny C. and Wiese, Kay C.},
title = {Performance prediction for RNA design using parametric and non-parametric regression models},
year = {2009},
isbn = {9781424427567},
publisher = {IEEE Press},
abstract = {Empirical algorithm study involves tuning various parameter settings in order to achieve an optimal performance. It is also experimentally known that algorithm performance varies across problem instances. In stochastic local search (metaheuristics) paradigm, search efficiency is correlated to the empirical hardness of the underlying combinatorial optimization problem itself. Therefore, investigating these correlations are of crucial importance towards the design of robust algorithmic solutions. To achieve this goal, an accurate prediction of algorithm performance is a prerequisite, since it allows an automatic tuning of parameter settings on a perproblem base. In this work, we investigate using parametric &amp; non-parametric regression models for algorithm performance prediction for the RNA Secondary Structure Design problem (SSD). Empirical results show our non-parametric methods achieve a higher prediction accuracy on biologically existing data, where biological data exhibits a higher degree of local similarity among individual instances. We also found that using a non-parametric regression tree model (CART) provides insight into studying the empirical hardness of solving the SSD problem.},
booktitle = {Proceedings of the 6th Annual IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology},
pages = {16–23},
numpages = {8},
location = {Nashville, Tennessee, USA},
series = {CIBCB'09}
}

@inproceedings{10.1145/1066650.1066666,
author = {Toomula, Aditya and Subhlok, Jaspal},
title = {Replicating memory behavior for performance prediction},
year = {2004},
isbn = {9781450377997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1066650.1066666},
doi = {10.1145/1066650.1066666},
abstract = {This paper introduces a method to monitor an application and generate a short synthetic "memory skeleton" program whose memory access pattern is representative of the application. In particular, the application and its memory skeleton should have similar cache behavior on any memory hierarchy architecture. The objective is to quickly estimate the cache performance of an application on any memory architecture by running its memory skeleton. The paper presents and validates a framework for automatic construction of memory skeletons. The approach is based on sampling the address trace of an executing application, summarizing it, and then employing it to generate a synthetic memory skeleton program. The broad goal of this research is construction of "performance skeletons" designed to quickly estimate the performance of a large application in an unpredictable environment. A performance skeleton must also mimic the communication and execution behavior of the application. However, the memory behavior drives the performance of many scientific applications and hence memory skeletons are a critical component of this approach to performance estimation.},
booktitle = {Proceedings of the 7th Workshop on Workshop on Languages, Compilers, and Run-Time Support for Scalable Systems},
pages = {1–8},
numpages = {8},
location = {Houston, Texas, USA},
series = {LCR '04}
}

@inproceedings{10.1145/3474624.3474645,
author = {Camargo, Leomar and Fantin, Luisa and Lob\~{a}o, Gabriel and Figueiredo, Thiago and Bonifacio, Rodrigo and Gomes, Karine and Teixeira, Leopoldo},
title = {Evolving Delta-Oriented Product Lines: A Case Study on Feature Interaction, Safe and Partially Safe Evolution},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3474645},
doi = {10.1145/3474624.3474645},
abstract = {Software product line engineering is a well-known approach for building a set of configurable systems for a specific domain, and different techniques have been used to manage product line variability, including source-code preprocessing, aspect-oriented programming (AOP), and delta-oriented programming (DOP). Although existing studies have explored the design and evolution of product lines using techniques such as source-code preprocessing and AOP, little is known about the practical implications of using DOP to bootstrap and evolve software product lines. In this paper we address this issue, reporting our experience of using DeltaJ to implement two product lines (Reminder-PL and Iris-PL). This experience covers different scenarios of evolution (such as the inclusion of mandatory, optional, and alternative features) that indeed led to several feature interactions. Altogether, this work brings several contributions, including evidence that existing templates for safe and partially safe evolution of product lines can also help developers to evolve delta-oriented SPLs—although we revealed the need for two additional templates for safe evolution. Also, we present a description of the feature interactions that appeared during the evolution of both product lines and how we modularized these interactions using DOP constructs.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {95–104},
numpages = {10},
keywords = {Delta-Oriented Programming, Feature Interaction, Safe and Partially Safe Evolution of SPLs, Software Product Lines (SPLs)},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.1145/2647908.2655974,
author = {B\'{e}can, Guillaume and Ben Nasr, Sana and Acher, Mathieu and Baudry, Benoit},
title = {WebFML: synthesizing feature models everywhere},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655974},
doi = {10.1145/2647908.2655974},
abstract = {Feature Models (FMs) are the de-facto standard for documenting, model checking, and reasoning about the configurations of a software system. This paper introduces WebFML a comprehensive environment for synthesizing FMs from various kinds of artefacts (e.g. propositional formula, dependency graph, FMs or product comparison matrices). A key feature of WebFML is an interactive support (through ranking lists, clusters, and logical heuristics) for choosing a sound and meaningful hierarchy. WebFML opens avenues for numerous practical applications (e.g., merging multiple product lines, slicing a configuration process, reverse engineering configurable systems).},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {112–116},
numpages = {5},
keywords = {feature modeling environment, ontologic-aware synthesis, reverse engineering feature models},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5555/2930611.2930635,
author = {Venkataraman, Shivaram and Yang, Zongheng and Franklin, Michael and Recht, Benjamin and Stoica, Ion},
title = {Ernest: efficient performance prediction for large-scale advanced analytics},
year = {2016},
isbn = {9781931971294},
publisher = {USENIX Association},
address = {USA},
abstract = {Recent workload trends indicate rapid growth in the deployment of machine learning, genomics and scientific workloads on cloud computing infrastructure. However, efficiently running these applications on shared infrastructure is challenging and we find that choosing the right hardware configuration can significantly improve performance and cost. The key to address the above challenge is having the ability to predict performance of applications under various resource configurations so that we can automatically choose the optimal configuration.Our insight is that a number of jobs have predictable structure in terms of computation and communication. Thus we can build performance models based on the behavior of the job on small samples of data and then predict its performance on larger datasets and cluster sizes. To minimize the time and resources spent in building a model, we use optimal experiment design, a statistical technique that allows us to collect as few training points as required. We have built Ernest, a performance prediction framework for large scale analytics and our evaluation on Amazon EC2 using several workloads shows that our prediction error is low while having a training overhead of less than 5% for long-running jobs.},
booktitle = {Proceedings of the 13th Usenix Conference on Networked Systems Design and Implementation},
pages = {363–378},
numpages = {16},
location = {Santa Clara, CA},
series = {NSDI'16}
}

@article{10.1023/A:1026567408307,
author = {Girona, Sergi and Labarta, Jes\'{u}s},
title = {Sensitivity of Performance Prediction of Message Passing Programs},
year = {2000},
issue_date = {Nov. 2000},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {3},
issn = {0920-8542},
url = {https://doi.org/10.1023/A:1026567408307},
doi = {10.1023/A:1026567408307},
abstract = {This paper discusses the issues related to the accuracy of performance prediction tools for message passing programs. We present the results of two sets of experiments to quantify the effect of the instrumentation overhead and variance in the accuracy of Dimemas. The results show that this performance prediction tool can be used with a high level of confidence as the effect of instrumentation overhead on the predicted performance is minimal. We also show that it is possible to carry out instrumentation runs in highly loaded multi-user environments and still be able to accurately analyze the performance of the application as if it had run alone.},
journal = {J. Supercomput.},
month = nov,
pages = {291–298},
numpages = {8},
keywords = {MPI performance prediction, dimemas}
}

@inproceedings{10.5555/1793274.1793285,
author = {Zhao, Ying and Scholer, Falk and Tsegay, Yohannes},
title = {Effective pre-retrieval query performance prediction using similarity and variability evidence},
year = {2008},
isbn = {3540786457},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Query performance prediction aims to estimate the quality of answers that a search system will return in response to a particular query. In this paper we propose a new family of pre-retrieval predictors based on information at both the collection and document level. Pre-retrieval predictors are important because they can be calculated from information that is available at indexing time; they are therefore more efficient than predictors that incorporate information obtained from actual search results. Experimental evaluation of our approach shows that the new predictors give more consistent performance than previously proposed pre-retrieval methods across a variety of data types and search tasks.},
booktitle = {Proceedings of the IR Research, 30th European Conference on Advances in Information Retrieval},
pages = {52–64},
numpages = {13},
location = {Glasgow, UK},
series = {ECIR'08}
}

@inproceedings{10.1145/2647908.2655965,
author = {Holthusen, S\"{o}nke and Wille, David and Legat, Christoph and Beddig, Simon and Schaefer, Ina and Vogel-Heuser, Birgit},
title = {Family model mining for function block diagrams in automation software},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655965},
doi = {10.1145/2647908.2655965},
abstract = {Automation systems are mostly individual highly customized system variants, consisting both of hardware and software. In order to reduce development effort, it is a common practice to use a clone-and-own approach by modifying an existing variant to fit the changed requirements of a new variant. The information about the commonalities and differences between those variants is usually not well documented and leads to problems in maintenance, testing and evolution. To alleviate these problems, in this paper, we present an improved version of a family mining approach for automatically discovering commonality and variability between related system variants. We apply this approach to function block diagrams used to develop automation software and show its feasibility by a manufacturing case study.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {36–43},
numpages = {8},
keywords = {automation software, family mining, re-engineering, software engineering},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1007/s10009-015-0387-9,
author = {Haber, Arne and H\"{o}lldobler, Katrin and Kolassa, Carsten and Look, Markus and M\"{u}ller, Klaus and Rumpe, Bernhard and Schaefer, Ina and Schulze, Christoph},
title = {Systematic synthesis of delta modeling languages},
year = {2015},
issue_date = {October   2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-015-0387-9},
doi = {10.1007/s10009-015-0387-9},
abstract = {Delta modeling is a modular, yet flexible approach to capture variability by explicitly representing differences between system variants or versions. The conceptual idea of delta modeling is language-independent. But, to apply delta modeling to a concrete language, either a generic transformation language has to be used or the corresponding delta language has to be manually developed for each considered base language. Generic languages and their tool support often lack readability and specific context condition checking, since they are unrelated to the base language. In this paper, we present a process that allows synthesizing a delta language from the grammar of a given base language. Our method relies on an automatically generated language extension that can be manually adapted to meet domain-specific needs. We illustrate our method using delta modeling on a textual variant of architecture diagrams. Furthermore, we evaluate our method using a comparative case study. This case study covers an architectural, a structural, and a behavioral language and compares the preexisting handwritten grammars to the generated grammars as well as the manually tailored grammars. This paper is an extension of Haber et al. (Proceedings of the 17th international software product line conference (SPLC'13), pp 22---31, 2013).},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {601–626},
numpages = {26},
keywords = {Delta modeling, Domain specific languages, Generation, Language engineering, Modeling, Software product line engineering}
}

@inproceedings{10.1109/SC.2005.20,
author = {Yang, Leo T. and Ma, Xiaosong and Mueller, Frank},
title = {Cross-Platform Performance Prediction of Parallel Applications Using Partial Execution},
year = {2005},
isbn = {1595930612},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SC.2005.20},
doi = {10.1109/SC.2005.20},
abstract = {Performance prediction across platforms is increasingly important as developers can choose from a wide range of execution platforms. The main challenge remains to perform accurate predictions at a low-cost across different architectures. In this paper, we derive an affordable method approaching cross-platform performance translation based on relative performance between two platforms. We argue that relative performance can be observed without running a parallel application in full. We show that it suffices to observe very short partial executions of an application since most parallel codes are iterative and behave predictably manner after a minimal startup period. This novel prediction approach is observation-based. It does not require program modeling, code analysis, or architectural simulation. Our performance results using real platforms and production codes demonstrate that prediction derived from partial executions can yield high accuracy at a low cost. We also assess the limitations of our model and identify future research directions on observationbased performance prediction.},
booktitle = {Proceedings of the 2005 ACM/IEEE Conference on Supercomputing},
pages = {40},
series = {SC '05}
}

@inproceedings{10.1145/3417990.3421263,
author = {Pett, Tobias and Eichhorn, Domenik and Schaefer, Ina},
title = {Risk-based compatibility analysis in automotive systems engineering},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3421263},
doi = {10.1145/3417990.3421263},
abstract = {Software is the new leading factor for innovation in the automotive industry. With the increase of software in road vehicles new business models, such as after-sale updates (i.e., Function-on-Demand) and Over-the-Air-Updates come into focus of manufacturers. When updating a road vehicle in the field, it is required to ensure functional safety. An update shall not influence existing functionality and break its safety. Hence, it must be compatible with the existing software. The compatibility of an update is ensured by testing. However, testing all variants of a highly configurable system, such as a modern car's software, is infeasible, due to the combinatorial explosion. To address this problem, in this paper, we propose a risk-based change-impact analysis to identify system variants relevant for retesting after an update. We combine existing concepts from product sampling, risk-based testing, and configuration prioritization and apply them to automotive architectures. For validating our concept, we use the Body Comfort System case study from the automotive industry. Our evaluation reveals that the concept backed by tool support may reduce testing effort by identifying and prioritizing incompatible variants wrt to a system update.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {34},
numpages = {10},
keywords = {automotive engineering, configurable systems, risk-based analysis},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1007/11549468_24,
author = {Ipek, Engin and de Supinski, Bronis R. and Schulz, Martin and McKee, Sally A.},
title = {An approach to performance prediction for parallel applications},
year = {2005},
isbn = {3540287000},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11549468_24},
doi = {10.1007/11549468_24},
abstract = {Accurately modeling and predicting performance for large-scale applications becomes increasingly difficult as system complexity scales dramatically. Analytic predictive models are useful, but are difficult to construct, usually limited in scope, and often fail to capture subtle interactions between architecture and software. In contrast, we employ multilayer neural networks trained on input data from executions on the target platform. This approach is useful for predicting many aspects of performance, and it captures full system complexity. Our models are developed automatically from the training input set, avoiding the difficult and potentially error-prone process required to develop analytic models. This study focuses on the high-performance, parallel application SMG2000, a much studied code whose variations in execution times are still not well understood. Our model predicts performance on two large-scale parallel platforms within 5%-7% error across a large, multi-dimensional parameter space.},
booktitle = {Proceedings of the 11th International Euro-Par Conference on Parallel Processing},
pages = {196–205},
numpages = {10},
location = {Lisbon, Portugal},
series = {Euro-Par'05}
}

@article{10.1145/2180868.2180875,
author = {Nie, Liqiang and Wang, Meng and Zha, Zheng-Jun and Chua, Tat-Seng},
title = {Oracle in Image Search: A Content-Based Approach to Performance Prediction},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/2180868.2180875},
doi = {10.1145/2180868.2180875},
abstract = {This article studies a novel problem in image search. Given a text query and the image ranking list returned by an image search system, we propose an approach to automatically predict the search performance. We demonstrate that, in order to estimate the mathematical expectations of Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG), we only need to predict the relevance probability of each image. We accomplish the task with a query-adaptive graph-based learning based on the images’ ranking order and visual content. We validate our approach with a large-scale dataset that contains the image search results of 1,165 queries from 4 popular image search engines. Empirical studies demonstrate that our approach is able to generate predictions that are highly correlated with the real search performance. Based on the proposed image search performance prediction scheme, we introduce three applications: image metasearch, multilingual image search, and Boolean image search. Comprehensive experiments are conducted to validate our approach.},
journal = {ACM Trans. Inf. Syst.},
month = may,
articleno = {13},
numpages = {23},
keywords = {Image search, graph-based learning, search performance prediction}
}

@article{10.1007/s10664-021-09940-0,
author = {Cashman, Mikaela and Firestone, Justin and Cohen, Myra B. and Thianniwet, Thammasak and Niu, Wei},
title = {An empirical investigation of organic software product lines},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09940-0},
doi = {10.1007/s10664-021-09940-0},
abstract = {Software product line engineering is a best practice for managing reuse in families of software systems that is increasingly being applied to novel and emerging domains. In this work we investigate the use of software product line engineering in one of these new domains, synthetic biology. In synthetic biology living organisms are programmed to perform new functions or improve existing functions. These programs are designed and constructed using small building blocks made out of DNA. We conjecture that there are families of products that consist of common and variable DNA parts, and we can leverage product line engineering to help synthetic biologists build, evolve, and reuse DNA parts. In this paper we perform an investigation of domain engineering that leverages an open-source repository of more than 45,000 reusable DNA parts. We show the feasibility of these new types of product line models by identifying features and related artifacts in up to 93.5% of products, and that there is indeed both commonality and variability. We then construct feature models for four commonly engineered functions leading to product lines ranging from 10 to 7.5 \texttimes{} 1020 products. In a case study we demonstrate how we can use the feature models to help guide new experimentation in aspects of application engineering. Finally, in an empirical study we demonstrate the effectiveness and efficiency of automated reverse engineering on both complete and incomplete sets of products. In the process of these studies, we highlight key challenges and uncovered limitations of existing SPL techniques and tools which provide a roadmap for making SPL engineering applicable to new and emerging domains.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {43},
keywords = {Software product lines, Synthetic biology, Reverse engineering, BioBricks}
}

@inproceedings{10.1145/2019136.2019178,
author = {Brataas, Gunnar and Jiang, Shanshan and Reichle, Roland and Geihs, Kurt},
title = {Performance property prediction supporting variability for adaptive mobile systems},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019178},
doi = {10.1145/2019136.2019178},
abstract = {A performance property prediction (PPP) method for component-based self-adaptive applications is presented. Such performance properties are required by an adaptation middleware for reasoning about adaptation activities. Our PPP method is based on the Structure and Performance (SP) framework, a conceptually simple, yet powerful performance modelling framework based on matrices. The main contribution of this paper are the integration of SP-based PPP into a comprehensive model- and variability-based adaptation framework for context-aware mobile applications. A meta model for the SP method is described. The framework is demonstrated using a practical example.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {37},
numpages = {8},
keywords = {autonomic computing, mobile systems},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1016/j.rcim.2008.02.010,
author = {Johnston, A. B. and Maguire, L. P. and McGinnity, T. M.},
title = {Downstream performance prediction for a manufacturing system using neural networks and six-sigma improvement techniques},
year = {2009},
issue_date = {June, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {25},
number = {3},
issn = {0736-5845},
url = {https://doi.org/10.1016/j.rcim.2008.02.010},
doi = {10.1016/j.rcim.2008.02.010},
abstract = {Intelligent techniques have been applied in a range of industrial environments [Meziane F, Vadera S, Kobbacy K, Proudlove N. Intelligent systems in manufacturing: current developments and future prospects. Integrated Manuf Syst 2000;11(4):218-38; Stephanopoulos G, Han C. Intelligent systems in process engineering: a review. Comput Chem Eng, 1996;20 (6-7):743-91; Johnston AB, Maguire LP, McGinnity TM. Using business improvement techniques to inform the optimisation of production cycle time: an industrial case study. Proceedings of the IEEE SMC UK-RI Chapter conference 2004 on intelligent cybernetic systems. September 7-8, 2004 ISSN:1744-9189; Proudlove NC, Vadera S, Kobbacy KAH. Intelligent management systems in operations: A review. J Oper Res Soc, 1998;49(7):682-99] although their implementation is not the first choice of many process engineers. In contrast process engineers in a diverse range of manufacturing environments regularly deploy business improvement techniques, such as the six-sigma methodology. Such techniques aim to control and subsequently identify the relationship between the process inputs and outputs so that a process engineer can more accurately predict how the process output shall perform based on the system inputs. Factors such as cost reduction, automatic process control or simply process prediction may be the defining factors in establishing prediction models. In this paper the authors use as a case study the manufacture of hard disc drives, from the developing of the read-write head to the recording media and the overall construction of the hard disc drive with its controlling mechanisms. Each of these stages are separate and complex-processing elements and integral to the functionality of the end product. In addition each of these stages of manufacturing may take days or weeks to complete and be processed in separate facilities and/or countries. This paper reports on the application of intelligent system techniques to improve the downstream performance prediction within this manufacturing environment. The application is guided by a six-sigma methodology to obtain improved performance. The results highlight that significant downstream prediction accuracy can be obtained using this hybrid approach.},
journal = {Robot. Comput.-Integr. Manuf.},
month = jun,
pages = {513–521},
numpages = {9},
keywords = {Business improvements, Manufacturing, Neural networks, Six sigma}
}

@inproceedings{10.1007/11428848_100,
author = {Scaife, Norman and Michaelson, Greg and Horiguchi, Susumu},
title = {Empirical parallel performance prediction from semantics-based profiling},
year = {2005},
isbn = {3540260439},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11428848_100},
doi = {10.1007/11428848_100},
abstract = {The PMLS parallelizing compiler for Standard ML is based upon the automatic instantiation of algorithmic skeletons at sites of higher order function use. PMLS seeks to optimise run-time parallel be- haviour by combining skeleton cost models with Structural Operational Semantics rule counts for HOF argument functions. In this paper, the formulation of a general rule count cost model as a set of over-determined linear equations is discussed, and their solution by singular value decom- position, and by a genetic algorithm, are presented.},
booktitle = {Proceedings of the 5th International Conference on Computational Science - Volume Part II},
pages = {781–789},
numpages = {9},
location = {Atlanta, GA},
series = {ICCS'05}
}

@inproceedings{10.1145/302405.302409,
author = {DeBaud, Jean-Marc and Schmid, Klaus},
title = {A systematic approach to derive the scope of software product lines},
year = {1999},
isbn = {1581130740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302405.302409},
doi = {10.1145/302405.302409},
booktitle = {Proceedings of the 21st International Conference on Software Engineering},
pages = {34–43},
numpages = {10},
keywords = {domain engineering, product line scoping, reuse economic models, software product line},
location = {Los Angeles, California, USA},
series = {ICSE '99}
}

@article{10.1016/S0167-9236(03)00088-5,
author = {Lam, Monica},
title = {Neural network techniques for financial performance prediction: integrating fundamental and technical analysis},
year = {2004},
issue_date = {September 2004},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {37},
number = {4},
issn = {0167-9236},
url = {https://doi.org/10.1016/S0167-9236(03)00088-5},
doi = {10.1016/S0167-9236(03)00088-5},
abstract = {This research project investigates the ability of neural networks, specifically, the backpropagation algorithm, to integrate fundamental and technical analysis for financial performance prediction. The predictor attributes include 16 financial statement variables and 11 macroeconomic variables. The rate of return on common shareholders' equity is used as the to-be-predicted variable. Financial data of 364 S&amp;P companies are extracted from the CompuStat database, and macroeconomic variables are extracted from the Citibase database for the study period of 1985-1995. Used as predictors in Experiments 1, 2, and 3 are the 1 year's, the 2 years', and the 3 years' financial data, respectively. Experiment 4 has 3 years' financial data and macroeconomic data as predictors. Moreover, in order to compensate for data noise and parameter misspecification as well as to reveal prediction logic and procedure, we apply a rule extraction technique to convert the connection weights from trained neural networks to symbolic classification rules. The performance of neural networks is compared with the average return from the top one-third returns in the market (maximum benchmark) that approximates the return from perfect information as well as with the overall market average return (minimum benchmark) that approximates the return from highly diversified portfolios. Paired &lt;i&gt;t&lt;/i&gt; tests are carried out to calculate the statistical significance of mean differences. Experimental results indicate that neural networks using 1 year's or multiple years' financial data consistently and significantly outperform the minimum benchmark, but not the maximum benchmark. As for neural networks with both financial and macroeconomic predictors, they do not outperform the minimum or maximum benchmark in this study. The experimental results also show that the average return of 0.25398 from extracted rules is the only compatible result to the maximum benchmark of 0.2786. Consequentially, we demonstrate rule extraction as a postprocessing technique for improving prediction accuracy and for explaining the prediction logic to financial decision makers.},
journal = {Decis. Support Syst.},
month = sep,
pages = {567–581},
numpages = {15},
keywords = {data mining, financial performance, forecasting, fundamental analysis, neural networks, postprocessing techniques, rule extraction, technical analysis}
}

@inproceedings{10.1145/3422392.3422418,
author = {Rocha, Larissa and Machado, Ivan and Almeida, Eduardo and K\"{a}stner, Christian and Nadi, Sarah},
title = {A semi-automated iterative process for detecting feature interactions},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422418},
doi = {10.1145/3422392.3422418},
abstract = {For configurable systems, features developed and tested separately may present a different behavior when combined in a system. Since software products might be composed of thousands of features, developers should guarantee that all valid combinations work properly. However, features can interact in undesired ways, resulting in failures. A feature interaction is an unpredictable behavior that cannot be easily deduced from the individual features involved. We proposed VarXplorer to inspect feature interactions as they are detected and incrementally classify them as benign or problematic. Our approach provides an iterative analysis of feature interactions allowing developers to focus on suspicious cases. In this paper, we present an experimental study to evaluate our iterative process of tests execution. We aim to understand how VarXplorer could be used for a faster and more objective feature interaction analysis. Our results show that VarXplorer may reduce up to 50% the amount of interactions a developer needs to check during the testing process.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {778–787},
numpages = {10},
keywords = {Configurable Systems, Experimental Study, Feature interaction, Runtime Analysis},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.5555/1762418.1762520,
author = {Carrington, Laura and Snavely, Allan and Gao, Xiaofeng and Wolter, Nicole},
title = {A performance prediction framework for scientific applications},
year = {2003},
isbn = {3540401962},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This work presents a performance modeling framework, developed by the Performance Modeling and Characterization (PMaC) Lab at the San Diego Supercomputer Center, that is faster than traditional cycle-accurate simulation, more sophisticated than performance estimation based on system peakperformance metrics, and is shown to be effective on the LINPACK benchmark and a synthetic version of an ocean modeling application (NLOM). The LINPACK benchmark is further used to investigate methods to reduce the time required to make accurate performance predictions with the framework. These methods are applied to the predictions of the synthetic NLOM application.},
booktitle = {Proceedings of the 2003 International Conference on Computational Science: PartIII},
pages = {926–935},
numpages = {10},
location = {Melbourne, Australia},
series = {ICCS'03}
}

@inproceedings{10.1145/2647908.2655972,
author = {Meinicke, Jens and Th\"{u}m, Thomas and Schr\"{o}ter, Reimar and Benduhn, Fabian and Saake, Gunter},
title = {An overview on analysis tools for software product lines},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655972},
doi = {10.1145/2647908.2655972},
abstract = {A software product line is a set of different software products that share commonalities. For a selection of features, specialized products of one domain can be generated automatically from domain artifacts. However, analyses of software product lines need to handle a large number of products that can be exponential in the number of features. In the last decade, many approaches have been proposed to analyze software product lines efficiently. For some of these approaches tool support is available. Based on a recent survey on analysis for software product lines, we provide a first overview on such tools. While our discussion is limited to analysis tools, we provide an accompanying website covering further tools for product-line development. We compare tools according to their analysis and implementation strategy to identify underrepresented areas. In addition, we want to ease the reuse of existing tools for researchers and students, and to simplify research transfer to practice.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {94–101},
numpages = {8},
keywords = {code metrics, model checking, non-functional properties, sampling, software product lines, static analysis, testing, theorem proving, tool support, type checking},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1007/s11219-017-9400-8,
author = {Alf\'{e}rez, Mauricio and Acher, Mathieu and Galindo, Jos\'{e} A. and Baudry, Benoit and Benavides, David},
title = {Modeling variability in the video domain: language and experience report},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-017-9400-8},
doi = {10.1007/s11219-017-9400-8},
abstract = {In an industrial project, we addressed the challenge of developing a software-based video generator such that consumers and providers of video processing algorithms can benchmark them on a wide range of video variants. This article aims to report on our positive experience in modeling, controlling, and implementing software variability in the video domain. We describe how we have designed and developed a variability modeling language, called VM, resulting from the close collaboration with industrial partners during 2 years. We expose the specific requirements and advanced variability constructs; we developed and used to characterize and derive variations of video sequences. The results of our experiments and industrial experience show that our solution is effective to model complex variability information and supports the synthesis of hundreds of realistic video variants. From the software language perspective, we learned that basic variability mechanisms are useful but not enough; attributes and multi-features are of prior importance; meta-information and specific constructs are relevant for scalable and purposeful reasoning over variability models. From the video domain and software perspective, we report on the practical benefits of a variability approach. With more automation and control, practitioners can now envision benchmarking video algorithms over large, diverse, controlled, yet realistic datasets (videos that mimic real recorded videos)--something impossible at the beginning of the project.},
journal = {Software Quality Journal},
month = mar,
pages = {307–347},
numpages = {41},
keywords = {Automated reasoning, Configuration, Domain-specific languages, Feature modeling, Software product line engineering, Variability modeling, Video testing}
}

@inproceedings{10.1145/3180155.3180159,
author = {Krieter, Sebastian and Th\"{u}m, Thomas and Schulze, Sandro and Schr\"{o}ter, Reimar and Saake, Gunter},
title = {Propagating configuration decisions with modal implication graphs},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180159},
doi = {10.1145/3180155.3180159},
abstract = {Highly-configurable systems encompass thousands of interdependent configuration options, which require a non-trivial configuration process. Decision propagation enables a backtracking-free configuration process by computing values implied by user decisions. However, employing decision propagation for large-scale systems is a time-consuming task and, thus, can be a bottleneck in interactive configuration processes and analyses alike. We propose modal implication graphs to improve the performance of decision propagation by precomputing intermediate values used in the process. Our evaluation results show a significant improvement over state-of-the-art algorithms for 120 real-world systems.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {898–909},
numpages = {12},
keywords = {configuration, decision propagation, software product line},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2019136.2019185,
author = {Duszynski, Slawomir},
title = {A scalable goal-oriented approach to software variability recovery},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019185},
doi = {10.1145/2019136.2019185},
abstract = {Software reuse approaches, such as software product lines, can help to achieve considerable effort and cost savings in product development for sets of software systems with a significant overlap in functionality. However, in the practice many organizations at first develop a number of similar software products without explicitly planning for strategic reuse. In consequence, subsequent attempts to introduce reuse require a significant restructuring of the existing products. The restructuring is difficult because the precise information about the distribution of commonality and variability in the source code of the variants is often not available.The ongoing PhD thesis presented in this paper contributes to easing the task of extractive software reuse adoption: it proposes a reverse engineering approach for extracting the variability information from the source code of similar software products and outlines a method that guides the organization towards optimal use of this information in the process of planning and introducing software reuse.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {42},
numpages = {8},
keywords = {product lines, reverse engineering, software reuse, source code mining, variability, variant, visualization},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1016/j.jss.2019.05.001,
author = {Kicsi, Andr\'{a}s and Csuvik, Viktor and Vid\'{a}cs, L\'{a}szl\'{o} and Horv\'{a}th, Ferenc and Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy, Tibor and Kocsis, Ferenc},
title = {Feature analysis using information retrieval, community detection and structural analysis methods in product line adoption},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {155},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.05.001},
doi = {10.1016/j.jss.2019.05.001},
journal = {J. Syst. Softw.},
month = sep,
pages = {70–90},
numpages = {21},
keywords = {Software product line, Feature extraction, Information retrieval, Community detection}
}

@inproceedings{10.1007/11605300_3,
author = {Lafreniere, Benjamin J. and Sodan, Angela C.},
title = {ScoPred–scalable user-directed performance prediction using complexity modeling and historical data},
year = {2005},
isbn = {354031024X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11605300_3},
doi = {10.1007/11605300_3},
abstract = {Using historical information to predict future runs of parallel jobs has shown to be valuable in job scheduling. Trends toward more flexible job-scheduling techniques such as adaptive resource allocation, and toward the expansion of scheduling to grids, make runtime predictions even more important. We present a technique of employing both a user's knowledge of his/her parallel application and historical application-run data, synthesizing them to derive accurate and scalable predictions for future runs. These scalable predictions apply to runtime characteristics for different numbers of nodes (processor scalability) and different problem sizes (problem-size scalability). We employ multiple linear regression and show that for decently accurate complexity models, good prediction accuracy can be obtained.},
booktitle = {Proceedings of the 11th International Conference on Job Scheduling Strategies for Parallel Processing},
pages = {62–90},
numpages = {29},
location = {Cambridge, MA},
series = {JSSPP'05}
}

@inproceedings{10.1145/2491627.2491654,
author = {Schulze, Michael and Mauersberger, Jan and Beuche, Danilo},
title = {Functional safety and variability: can it be brought together?},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491654},
doi = {10.1145/2491627.2491654},
abstract = {Today's product development creates multiple products over time, often by using reuse strategies like "Clone and Own", leading to very inefficient reuse of artifacts in the long term since synergy effects between the products e.g. from testing cannot be utilized. Applying a product line approach with explicitly modeling the commonalities and variabilities of system artifacts and deriving products from that common base is a way to tackle the problem. High variant complexity can often be found in the development of embedded systems, which in turn often control safety critical functions. For these systems functional safety is a major concern not only since the ISO 26262 got relevant for the automotive industry. The arising question is: Can variability in functional safety related assets be treated in the same way as for other artifacts like requirements, models, and source code? In this paper we demonstrate on the example of two commercial tools and an automotive use case that from the technical/tool point of view safety related artifacts can be treated like other artifacts regarding variability. This means linking with variability information and visualizing as well as deriving of variants is feasible. This is a big step forward, because now not only ordinary artifacts but also functional safety related assets can be reused in the same way as other product line artifacts. However, we have identified and will discuss challenges with respect to variable safety analyses, regulations, and reuse of certifications, which need further research and elaboration, in this paper.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {236–243},
numpages = {8},
keywords = {functional-safety, tool support, variant management},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.5555/2401945.2401984,
author = {Nadeem, Farrukh and Prodan, Radu and Fahringer, Thomas},
title = {Optimizing performance of automatic training phase for application performance prediction in the grid},
year = {2007},
isbn = {3540754431},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Automatic execution time prediction of the Grid applications plays a critical role in making the pervasive Grid more reliable and predictable. However, automatic execution time prediction has not been addressed due to the diversity of the Grid applications, usability of an application in multiple contexts, dynamic nature of the Grid, and concerns about result accuracy and time expensive experimental training. We introduce an optimized, low-cost, and efficient yet automatic training phase for automatic execution time prediction of Grid applications. Our approach is supported by intra - and inter-platform performance sharing and translation mechanisms. We are able to reduce the total number of experiments from an polynomial complexity to a linear complexity.},
booktitle = {Proceedings of the Third International Conference on High Performance Computing and Communications},
pages = {309–321},
numpages = {13},
location = {Houston, TX},
series = {HPCC'07}
}

@inproceedings{10.5555/2535461.2535498,
author = {Kwon, Yongin and Lee, Sangmin and Yi, Hayoon and Kwon, Donghyun and Yang, Seungjun and Chun, Byung-Gon and Huang, Ling and Maniatis, Petros and Naik, Mayur and Paek, Yunheung},
title = {Mantis: automatic performance prediction for smartphone applications},
year = {2013},
publisher = {USENIX Association},
address = {USA},
abstract = {We present Mantis, a framework for predicting the performance of Android applications on given inputs automatically, accurately, and efficiently. A key insight underlying Mantis is that program execution runs often contain features that correlate with performance and are automatically computable efficiently. Mantis synergistically combines techniques from program analysis and machine learning. It constructs concise performance models by choosing from many program execution features only a handful that are most correlated with the program's execution time yet can be evaluated efficiently from the program's input. We apply program slicing to accurately estimate the evaluation cost of a feature and automatically generate executable code snippets for efficiently evaluating features. Our evaluation shows that Mantis predicts the execution time of six Android apps with estimation error in the range of 2.2-11.9% by executing predictor code costing at most 1.3% of their execution time on Galaxy Nexus.},
booktitle = {Proceedings of the 2013 USENIX Conference on Annual Technical Conference},
pages = {297–308},
numpages = {12},
location = {San Jose, CA},
series = {USENIX ATC'13}
}

@inproceedings{10.5555/882452.874331,
author = {Bontempi, G. and Kruijtzer, W.},
title = {A Data Analysis Method for Software Performance Prediction},
year = {2002},
isbn = {0769514715},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper explores the role of data analysis methodsto support system-level designers in characterising theperformance of embedded applications. In particular, weaddress the performance modelling of software applicationsrunning on an embedded microprocessor. Wepropose a data analysis method, which, on the basis of aparameterisation of the software functionality and thehardware architecture, is able to predict the number ofexecution cycles on an embedded processor. Experimentswith standard computational code (sorting, mathematicalcomputation) and with MPEG variable length decodingare presented to support this claim.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {971},
series = {DATE '02}
}

@inproceedings{10.5555/647810.738109,
author = {Gautama, Hasyim and Gemund, Arjan J. C. van},
title = {Symbolic Performance Prediction of Data-Dependent Parallel Programs},
year = {2002},
isbn = {3540435395},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Analytically predicting the performance of data-dependent programs is an extremely challenging problem. Even for a fixed problem size the variety of typical input data sets may cause a considerable execution time variance. Especially for time-critical applications, merely predicting the mean execution time does not suffice and knowledge of the execution time distribution is essential. In this paper we present a compositional analytic method to approximate the first four statistical moments of the program execution time in terms of the first four moments of the loop bounds, the branch conditions, and the execution time delays of the constituent tasks. The approach applies to sequential and parallel programs of which the associated DAG has a series-parallel structure. For each binary or  N -ary sequential, parallel, or conditional composition the solution complexity is merely  O (1). The method is exact for sequential and conditional composition. Furthermore, for  N -ary parallel compositions experimental results of synthetic and real workloads show that the actual prediction error of the moments method is in the percent range. The analytic method is implemented in terms of the performance modeling language PAMELA. Apart from the theory, in this paper we also present a symbolic PAMELA compiler. Provided with a PAMELA process model of the (parallel) program, the PAMELA compiler symbolically translates this source to closed-form expressions that express the first four moments of the program execution time.},
booktitle = {Proceedings of the 12th International Conference on Computer Performance Evaluation, Modelling Techniques and Tools},
pages = {259–278},
numpages = {20},
series = {TOOLS '02}
}

@article{10.1007/s10270-013-0336-6,
author = {Happe, Lucia and Buhnova, Barbora and Reussner, Ralf},
title = {Stateful component-based performance models},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0336-6},
doi = {10.1007/s10270-013-0336-6},
abstract = {The accuracy of performance-prediction models is crucial for widespread adoption of performance prediction in industry. One of the essential accuracy-influencing aspects of software systems is the dependence of system behaviour on a configuration, context or history related state of the system, typically reflected with a (persistent) system attribute. Even in the domain of component-based software engineering, the presence of state-reflecting attributes (the so-called internal states) is a natural ingredient of the systems, implying the existence of stateful services, stateful components and stateful systems as such. Currently, there is no consensus on the definition or method to include state-related information in component-based prediction models. Besides the task to identify and localise different types of stateful information across component-based software architecture, the issue is to balance the expressiveness and complexity of prediction models via an effective abstraction of state modelling. In this paper, we identify and classify stateful information in component-based software systems, study the performance impact of the individual state categories, and discuss the costs of their modelling in terms of the increased model size. The observations are formulated into a set of heuristics-guiding software engineers in state modelling. Finally, practical effect of state modelling on software performance is evaluated on a real-world case study, the SPECjms2007 Benchmark. The observed deviation of measurements and predictions was significantly decreased by more precise models of stateful dependencies.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1319–1343},
numpages = {25},
keywords = {Performance prediction, Prediction accuracy, Stateful components}
}

@article{10.1145/1462586.1462591,
author = {Holland, Brian and Nagarajan, Karthik and George, Alan D.},
title = {RAT: RC Amenability Test for Rapid Performance Prediction},
year = {2009},
issue_date = {January 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {1936-7406},
url = {https://doi.org/10.1145/1462586.1462591},
doi = {10.1145/1462586.1462591},
abstract = {While the promise of achieving speedup and additional benefits such as high performance per watt with FPGAs continues to expand, chief among the challenges with the emerging paradigm of reconfigurable computing is the complexity in application design and implementation. Before a lengthy development effort is undertaken to map a given application to hardware, it is important that a high-level parallel algorithm crafted for that application first be analyzed relative to the target platform, so as to ascertain the likelihood of success in terms of potential speedup. This article presents the RC Amenability Test, or RAT, a methodology and model developed for this purpose, supporting rapid exploration and prediction of strategic design tradeoffs during the formulation stage of application development.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = jan,
articleno = {22},
numpages = {31},
keywords = {FPGA, formulation methodology, performance prediction, reconfigurable computing, strategic design methodology}
}

@article{10.1145/3088440,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {Teaching Software Product Lines: A Snapshot of Current Practices and Challenges},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
url = {https://doi.org/10.1145/3088440},
doi = {10.1145/3088440},
abstract = {Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving, as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, and what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. In this article, we report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, that is, an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {31},
keywords = {Software product lines, software engineering teaching, software product line teaching, variability modeling}
}

@inproceedings{10.5555/838237.838459,
author = {Gautama, Hasyim and van Gemund, Arjan J. C.},
title = {A Statistical Approach to Branch Modeling in Static Program Performance Prediction},
year = {2003},
isbn = {0769519261},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Current static performance prediction methods have been less successful in statistically accounting for program workload distribution due to input data set variability, of which data-dependent branches are usually the most important contributors. While data-dependent basic block execution time is often characterized in terms of, e.g., mean and variance, branching conditions still are typically characterized by only one parameter, usually known as the truth probability. In this paper we propose and evaluate three statistical approaches to modeling branching behavior, to be used within a compositional method to predict program execution time distribution. The approaches are coined the Empirical, the Bernoulli, and the ARP (Alternating Renewal Processes) approach. While the Empirical approach is based on measuring branching behavior in terms of the surrounding loop construct, the other approaches aim at deriving a statistical model of the branch itself, which enables a higher level of compositionality. Our measurement results, based on synthetic as well as on real programs, show that the Empirical approach delivers the highest accuracy, whereas the alternative approaches trade accuracy for compositionality. For Markovian branches, thecompositional approaches deliver high prediction accuracy. In contrast to intuition and our synthetic experiments, in real programs the two-parameter ARP approach does not always outperform the one-parameter Bernoulli approach.},
booktitle = {Proceedings of the 17th International Symposium on Parallel and Distributed Processing},
pages = {280.1},
series = {IPDPS '03}
}

@inproceedings{10.1145/2791060.2791084,
author = {Teixeira, Leopoldo and Borba, Paulo and Gheyi, Rohit},
title = {Safe evolution of product populations and multi product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791084},
doi = {10.1145/2791060.2791084},
abstract = {A product line is often developed in the context of a set of related product lines. When supporting separate feature development, we might have product populations, with product line versions being simultaneously developed in different branches. Multi product lines involve a number of product lines that depend on each other. A product line refinement notion formalizes safe evolution, but this is not sufficient for reasoning over sets of product lines. We propose refinement notions and compositionality properties that help to explain how we can support modular development in these contexts. Thus, we formally define the foundations for safe and modular evolution of product populations and multi product lines, enabling developers to perform changes in a systematic manner.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {171–175},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2647908.2655961,
author = {Seidl, Christoph and Domachowska, Irena},
title = {Teaching variability engineering to cognitive psychologists},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655961},
doi = {10.1145/2647908.2655961},
abstract = {In research of cognitive psychology, experiments to measure cognitive processes may be run in many similar yet slightly different configurations. Variability engineering offers techniques to handle variable configurations both conceptually and technically. However, these techniques are largely unknown to cognitive psychologists so that experiment configurations are specified informally or too coarse grain. This is problematic, because it becomes difficult to get an overview of paradigm configurations used in the so far conducted experiments. Variability engineering techniques provide, i.a., concise notations for capturing variability in software and can also be used to express the configurable nature of a wide range of experiments in cognitive psychology. Furthermore, it enables cognitive psychologists to structure configuration knowledge, to identify suitably similar experiment setups and to more efficiently identify individual configuration options as relevant reasons for a particular effect in the outcome of an experiment. In this paper, we present experiences with teaching variability engineering to cognitive psychologists along with a suitable curriculum.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {16–23},
numpages = {8},
keywords = {cognitive psychology, feature model, teaching, variability engineering},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5555/1162708.1162772,
author = {Perumalla, Kalyan S. and Fujimoto, Richard M. and Thakare, Prashant J. and Pande, Santosh and Karimabadi, Homa and Omelchenko, Yuri and Driscoll, Jonathan},
title = {Performance prediction of large-scale parallel discrete event models of physical systems},
year = {2005},
isbn = {0780395190},
publisher = {Winter Simulation Conference},
abstract = {A virtualization system is presented that is designed to help predict the performance of parallel/distributed discrete event simulations on massively parallel (supercomputing) platforms. It is intended to be useful in experimenting with and understanding the effects of execution parameters, such as different load balancing schemes and mixtures of model fidelity. A case study of the virtualization system is presented in the context of plasma physics simulations, highlighting important virtualization challenges and issues, such as reentrancy and synchronization in the virtual plane, and our corresponding solution approaches. A trace-based prediction methodology is presented, and is evaluated with a 1-D hybrid collisionless shock model simulation, with the predicted performance being validated against one obtained in actual simulation. Predicted performance measurements show excellent agreement with actual performance measurements on parallel platforms containing up to 512 CPUs.},
booktitle = {Proceedings of the 37th Conference on Winter Simulation},
pages = {356–364},
numpages = {9},
location = {Orlando, Florida},
series = {WSC '05}
}

@inproceedings{10.5555/1753235.1753245,
author = {Cetina, Carlos and Haugen, \O{}ystein and Zhang, Xiaorui and Fleurey, Franck and Pelechano, Vicente},
title = {Strategies for variability transformation at run-time},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {More and more approaches propose to use Software Product Lines (SPLs) modelling techniques to implement dynamic adaptive systems. The resulting Dynamic Software Product Lines (DSPLs) present new challenges since the variability transformations used to derive alternative configurations have to be intensively used at runtime. This paper proposes to use the Common Variability Language (CVL) for modelling runtime variability and evaluates a set of alternative strategies for implementing the associated variability transformations. All the proposed strategies have been implemented and evaluated on the case-study of a smart-home system. Results show that the proposed strategies provide the same reconfiguration service with significant differences in quality-of-service.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {61–70},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1145/3280986,
author = {Rhein, Alexander Von and Liebig, J\"{o}RG and Janker, Andreas and K\"{a}stner, Christian and Apel, Sven},
title = {Variability-Aware Static Analysis at Scale: An Empirical Study},
year = {2018},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3280986},
doi = {10.1145/3280986},
abstract = {The advent of variability management and generator technology enables users to derive individual system variants from a configurable code base by selecting desired configuration options. This approach gives rise to the generation of possibly billions of variants, which, however, cannot be efficiently analyzed for bugs and other properties with classic analysis techniques. To address this issue, researchers and practitioners have developed sampling heuristics and, recently, variability-aware analysis techniques. While sampling reduces the analysis effort significantly, the information obtained is necessarily incomplete, and it is unknown whether state-of-the-art sampling techniques scale to billions of variants. Variability-aware analysis techniques process the configurable code base directly, exploiting similarities among individual variants with the goal of reducing analysis effort. However, while being promising, so far, variability-aware analysis techniques have been applied mostly only to small academic examples. To learn about the mutual strengths and weaknesses of variability-aware and sample-based static-analysis techniques, we compared the two by means of seven concrete control-flow and data-flow analyses, applied to five real-world subject systems: Busybox, OpenSSL, SQLite, the x86 Linux kernel, and uClibc. In particular, we compare the efficiency (analysis execution time) of the static analyses and their effectiveness (potential bugs found). Overall, we found that variability-aware analysis outperforms most sample-based static-analysis techniques with respect to efficiency and effectiveness. For example, checking all variants of OpenSSL with a variability-aware static analysis is faster than checking even only two variants with an analysis that does not exploit similarities among variants.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {18},
numpages = {33},
keywords = {Highly configurable systems, TypeChef, configuration sampling, variability-aware analysis}
}

@inproceedings{10.1145/3136040.3136054,
author = {Linsbauer, Lukas and Berger, Thorsten and Gr\"{u}nbacher, Paul},
title = {A classification of variation control systems},
year = {2017},
isbn = {9781450355247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136040.3136054},
doi = {10.1145/3136040.3136054},
abstract = {Version control systems are an integral part of today's software and systems development processes. They facilitate the management of revisions (sequential versions) and variants (concurrent versions) of a system under development and enable collaboration between developers. Revisions are commonly maintained either per file or for the whole system. Variants are supported via branching or forking mechanisms that conceptually clone the whole system under development. It is known that such cloning practices come with disadvantages. In fact, while short-lived branches for isolated development of new functionality (a.k.a. feature branches) are well supported, dealing with long-term and fine-grained system variants currently requires employing additional mechanisms, such as preprocessors, build systems or custom configuration tools. Interestingly, the literature describes a number of variation control systems, which provide a richer set of capabilities for handling fine-grained system variants compared to the version control systems widely used today. In this paper we present a classification and comparison of selected variation control systems to get an understanding of their capabilities and the advantages they can offer. We discuss problems of variation control systems, which may explain their comparably low popularity. We also propose research activities we regard as important to change this situation.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {49–62},
numpages = {14},
keywords = {Variability management, configuration management, software product lines, software repositories},
location = {Vancouver, BC, Canada},
series = {GPCE 2017}
}

@inproceedings{10.1007/978-3-030-95384-3_26,
author = {Liang, Zhongyu and Di, Xiaoqiang and Liu, Zhen and Liu, Xu and Zhang, Xingxu and Yu, Zhi},
title = {Predicting Students’ Academic Performance Based on Improved PSO-Xgboost: A Campus Behavior Perspective},
year = {2021},
isbn = {978-3-030-95383-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-95384-3_26},
doi = {10.1007/978-3-030-95384-3_26},
abstract = {Performance prediction research has become an important research task in the education field. Previous studies mainly used questionnaires and specific learning systems to collect data. Due to the richness of data sources and the diversity of features, the model’s low prediction accuracy is still challenging. Therefore, extracting features related to academic performance and improving the prediction accuracy of the model are the keys to advance research and development. In this paper, we use multi-source campus data to mine student behavior characteristics from different angles. The results of Pearson’s correlation coefficient show that there is a certain correlation between the features we extracted and academic performance. In particular, we designed a model based on the combination of XGBoost and an improved PSO algorithm to solve the multi-classification problem of academic performance. Finally, we verify on the real campus data set, and the results prove that the model can predict students’ academic performance with high accuracy.},
booktitle = {Algorithms and Architectures for Parallel Processing: 21st International Conference, ICA3PP 2021, Virtual Event, December 3–5, 2021, Proceedings, Part I},
pages = {402–421},
numpages = {20},
keywords = {Campus big data, Academic performance prediction, PSO-Xgboost, Particle swarm optimization}
}

@article{10.1007/s10270-018-0662-9,
author = {Kolesnikov, Sergiy and Siegmund, Norbert and K\"{a}stner, Christian and Grebhahn, Alexander and Apel, Sven},
title = {Tradeoffs in modeling performance of highly configurable software systems},
year = {2019},
issue_date = {June      2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-018-0662-9},
doi = {10.1007/s10270-018-0662-9},
abstract = {Modeling the performance of a highly configurable software system requires capturing the influences of its configuration options and their interactions on the system's performance. Performance-influence models quantify these influences, explaining this way the performance behavior of a configurable system as a whole. To be useful in practice, a performance-influence model should have a low prediction error, small model size, and reasonable computation time. Because of the inherent tradeoffs among these properties, optimizing for one property may negatively influence the others. It is unclear, though, to what extent these tradeoffs manifest themselves in practice, that is, whether a large configuration space can be described accurately only with large models and significant resource investment. By means of 10 real-world highly configurable systems from different domains, we have systematically studied the tradeoffs between the three properties. Surprisingly, we found that the tradeoffs between prediction error and model size and between prediction error and computation time are rather marginal. That is, we can learn accurate and small models in reasonable time, so that one performance-influence model can fit different use cases, such as program comprehension and performance prediction. We further investigated the reasons for why the tradeoffs are marginal. We found that interactions among four or more configuration options have only a minor influence on the prediction error and that ignoring them when learning a performance-influence model can save a substantial amount of computation time, while keeping the model small without considerably increasing the prediction error. This is an important insight for new sampling and learning techniques as they can focus on specific regions of the configuration space and find a sweet spot between accuracy and effort. We further analyzed the causes for the configuration options and their interactions having the observed influences on the systems' performance. We were able to identify several patterns across subject systems, such as dominant configuration options and data pipelines, that explain the influences of highly influential configuration options and interactions, and give further insights into the domain of highly configurable systems.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {2265–2283},
numpages = {19},
keywords = {Feature interactions, Highly configurable software systems, Machine learning, Performance prediction, Performance-influence models, Software product lines, Variability}
}

@inproceedings{10.1145/3302333.3302344,
author = {Ferreira, Fischer and Diniz, Jo\~{a}o P. and Silva, Cleiton and Figueiredo, Eduardo},
title = {Testing Tools for Configurable Software Systems: A Review-based Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302344},
doi = {10.1145/3302333.3302344},
abstract = {Configurable software systems are software systems that can be adapted or configured according to a set of features with the goal of increasing reuse and productivity. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. The lack of studies to explore the tools that apply those techniques motivated us to investigate the literature to find testing tools for configurable software systems and to understand how they work. In this paper, we conducted a systematic mapping and identified 34 testing tools for configurable software systems. We first summarized and discussed their main characteristics. We then designed and performed a comparative empirical study of the main sound testing tools found: VarexJ and SPLat. They are considered sound testing techniques because they explore all reachable configurations from a given test. Overall, we observed that VarexJ and SPLat presented distinct results for efficiency while testing the target systems and that, although VarexJ found more errors than SPLat for the majority of the target systems, such result deserves a more in-depth investigation because we expected a higher intersection of errors encountered by them.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {10},
keywords = {Software Product Line, Systematic Mapping Study, Testing Configurable Software Systems},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1109/WCRE.2011.45,
author = {Haslinger, Evelyn Nicole and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
title = {Reverse Engineering Feature Models from Programs' Feature Sets},
year = {2011},
isbn = {9780769545820},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WCRE.2011.45},
doi = {10.1109/WCRE.2011.45},
abstract = {Successful software is more and more rarely developed as a one-of-a-kind system. Instead, different system variants are built from a common set of assets and customized for catering to the different functionality or technology needs of the distinct clients and users. The Software Product Line Engineering (SPLE) paradigm has proven effective to cope with the variability described for this scenario. However, evolving a Software Product Line (SPL) from a family of systems is not a simple endeavor. A crucial requirement is accurately capturing the variability present in the family of systems and representing it with Feature Models (FMs), the de facto standard for variability modeling. Current research has focused on extracting FMs from configuration scripts, propositional logic expressions or natural language. In contrast, in this short paper we present an algorithm that reverse engineers a basic feature model from the feature sets which describe the features each system provides. We perform an evaluation of our approach using several case studies and outline the issues that still need to be addressed.},
booktitle = {Proceedings of the 2011 18th Working Conference on Reverse Engineering},
pages = {308–312},
numpages = {5},
keywords = {Feature, Feature Model, Feature Set, Software Product Line},
series = {WCRE '11}
}

@article{10.1145/2580950,
author = {Th\"{u}m, Thomas and Apel, Sven and K\"{a}stner, Christian and Schaefer, Ina and Saake, Gunter},
title = {A Classification and Survey of Analysis Strategies for Software Product Lines},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2580950},
doi = {10.1145/2580950},
abstract = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {6},
numpages = {45},
keywords = {Product-line analysis, model checking, program family, software analysis, software product line, static analysis, theorem proving, type checking}
}

@inproceedings{10.5555/1855711.1855721,
author = {Li, Zhichun and Zhang, Ming and Zhu, Zhaosheng and Chen, Yan and Greenberg, Albert and Wang, Yi-Min},
title = {WebProphet: automating performance prediction for web services},
year = {2010},
publisher = {USENIX Association},
address = {USA},
abstract = {Today, large-scale web services run on complex systems, spanning multiple data centers and content distribution networks, with performance depending on diverse factors in end systems, networks, and infrastructure servers. Web service providers have many options for improving service performance, varying greatly in feasibility, cost and benefit, but have few tools to predict the impact of these options.A key challenge is to precisely capture web object dependencies, as these are essential for predicting performance in an accurate and scalable manner. In this paper, we introduce WebProphet, a system that automates performance prediction for web services. WebProphet employs a novel technique based on timing perturbation to extract web object dependencies, and then uses these dependencies to predict the performance impact of changes to the handling of the objects. We have built, deployed, and evaluated the accuracy and efficiency of WebProphet. Applying WebProphet to the Search and Maps services of Google and Yahoo, we find WebProphet predicts the median and 95th percentiles of the page load time distribution with an error rate smaller than 16% in most cases. Using Yahoo Maps as an example, we find that WebProphet reduces the problem of performance optimization to a small number of web objects whose optimization would reduce the page load time by nearly 40%.},
booktitle = {Proceedings of the 7th USENIX Conference on Networked Systems Design and Implementation},
pages = {10},
numpages = {1},
location = {San Jose, California},
series = {NSDI'10}
}

@inproceedings{10.5555/1018411.1018886,
author = {Guo, Yutao and Muller, Jorg P. and Bauer, Bernhard},
title = {A Multiagent Approach for Logistics Performance Prediction Using Historical and Context Information},
year = {2004},
isbn = {1581138644},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper presents a multiagent architecture and methods for intelligent decision support in logistics processes. It extends current advanced prediction systems by providing the ability to combine history and situated reasoning. The contribution of the paper is threefold: first, a multi-agent architecture and learning algorithms are developed that enables us to combine background models learned from history data with context-related knowledge about the current situation; second, using a large real data set we show that adding situated knowledge actually improves the performance of a supply chain decision support system; and third, for our settings we evaluate the degree to which agent-assisted decision support is actually usable/sufficient to improve human decision-making and to support automated decision-making in dynamic supply network management scenarios.},
booktitle = {Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 3},
pages = {1164–1171},
numpages = {8},
location = {New York, New York},
series = {AAMAS '04}
}

@inproceedings{10.1145/2018436.2018502,
author = {Li, Ang and Zong, Xuanran and Kandula, Srikanth and Yang, Xiaowei and Zhang, Ming},
title = {CloudProphet: towards application performance prediction in cloud},
year = {2011},
isbn = {9781450307970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2018436.2018502},
doi = {10.1145/2018436.2018502},
abstract = {Choosing the best-performing cloud for one's application is a critical problem for potential cloud customers. We propose CloudProphet, a trace-and-replay tool to predict a legacy application's performance if migrated to a cloud infrastructure. CloudProphet traces the workload of the application when running locally, and replays the same workload in the cloud for prediction. We discuss two key technical challenges in designing CloudProphet, and some preliminary results using a prototype implementation.},
booktitle = {Proceedings of the ACM SIGCOMM 2011 Conference},
pages = {426–427},
numpages = {2},
keywords = {cloud computing, performance, prediction},
location = {Toronto, Ontario, Canada},
series = {SIGCOMM '11}
}

@inproceedings{10.1145/331532.331568,
author = {Faerman, Marcio and Su, Alan and Wolski, Richard and Berman, Francine},
title = {Adaptive performance prediction for distributed data-intensive applications},
year = {1999},
isbn = {1581130910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331532.331568},
doi = {10.1145/331532.331568},
booktitle = {Proceedings of the 1999 ACM/IEEE Conference on Supercomputing},
pages = {36–es},
location = {Portland, Oregon, USA},
series = {SC '99}
}

@article{10.1007/s11042-021-10771-w,
author = {Kumari, Ruchika and Dev, Amita and Kumar, Ashwani},
title = {An efficient adaptive artificial neural network based text to speech synthesizer for Hindi language},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {16},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-10771-w},
doi = {10.1007/s11042-021-10771-w},
abstract = {Speech recognition is one of the major research regions these days under speech processing. This paper depends on developing a whole process that takes the input as the text file from the user and provides the output in speech form. This paper proposes a text to speech synthesizer for the Hindi language depends on the coefficients of Mel-frequency cepstral (MFCC) features are extracted to the production and linguistic constraints proposed for modeling the parameters such as intonation, duration, and syllable intensities. The features extracted from the MFCC features are phrasing, fundamental frequency, duration, etc. Neural network models are discovered to confine the features as mentioned earlier, employing MFCC. The performance of the proposed ALO-ANN is computed utilizing objective measures such as prediction error (η), standard deviation (σ), and linear correlation coefficient (χ). The accuracy predicted of the proposed ALO-ANN models is high when compared with other models such as DNN and ANN. The prediction accuracy is high for ALO-ANN models when compared with other models.},
journal = {Multimedia Tools Appl.},
month = jul,
pages = {24669–24695},
numpages = {27},
keywords = {Hindi TTS synthesis, Prediction accuracy, ANN, ALO, Fundamental frequency, Text to speech and MFCC}
}

@article{10.1016/j.bdr.2021.100270,
author = {Bai, Xiaomei and Zhang, Fuli and Li, Jinzhou and Guo, Teng and Aziz, Abdul and Jin, Aijing and Xia, Feng},
title = {Educational Big Data: Predictions, Applications and Challenges},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {26},
number = {C},
issn = {2214-5796},
url = {https://doi.org/10.1016/j.bdr.2021.100270},
doi = {10.1016/j.bdr.2021.100270},
journal = {Big Data Res.},
month = nov,
numpages = {12},
keywords = {Educational big data, Predictive models, Performance prediction, Educational data mining}
}

@inproceedings{10.1109/ASONAM49781.2020.9381481,
author = {M\"{u}ller, Siegfried and Ghawi, Raji and Pfeffer, J\"{u}rgen},
title = {Using communication networks to predict team performance in massively multiplayer online games},
year = {2021},
isbn = {9781728110561},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASONAM49781.2020.9381481},
doi = {10.1109/ASONAM49781.2020.9381481},
abstract = {Virtual teams are becoming increasingly important. Since they are digital in nature, their "trace data" enable a broad set of new research opportunities. Online Games are especially useful for studying social behavior patterns of collaborative teams. In our study we used longitudinal data from the Massively Multiplayer Online Game (MMOG) Travian collected over a 12-month period that included 4,753 teams with 18,056 individuals and their communication networks. For predicting team performance, we selected 13 SNA-based attributes frequently used in team and leadership research. Using machine learning algorithms, the added explanatory power derived from the patterns of the communication networks enabled us to achieve an adjusted R2 = 0.67 in the best fitting performance prediction model and a prediction accuracy of up to 95.3% in the classification of top performing teams.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {353–360},
numpages = {8},
keywords = {communication network, machine learning, massively multiplayer online game, performance prediction, social network analysis, virtual teams},
location = {Virtual Event, Netherlands},
series = {ASONAM '20}
}

@inproceedings{10.1145/3358960.3379127,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Transferring Pareto Frontiers across Heterogeneous Hardware Environments},
year = {2020},
isbn = {9781450369916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358960.3379127},
doi = {10.1145/3358960.3379127},
abstract = {Software systems provide user-relevant configuration options called features. Features affect functional and non-functional system properties, whereas selections of features represent system configurations. A subset of configuration space forms a Pareto frontier of optimal configurations in terms of multiple properties, from which a user can choose the best configuration for a particular scenario. However, when a well-studied system is redeployed on a different hardware, information about property value and the Pareto frontier might not apply. We investigate whether it is possible to transfer this information across heterogeneous hardware environments. We propose a methodology for approximating and transferring Pareto frontiers of configurable systems across different hardware environments. We approximate a Pareto frontier by training an individual predictor model for each system property, and by aggregating predictions of each property into an approximated frontier. We transfer the approximated frontier across hardware by training a transfer model for each property, by applying it to a respective predictor, and by combining transferred properties into a frontier. We evaluate our approach by modeling Pareto frontiers as binary classifiers that separate all system configurations into optimal and non-optimal ones. Thus we can assess quality of approximated and transferred frontiers using common statistical measures like sensitivity and specificity. We test our approach using five real-world software systems from the compression domain, while paying special attention to their performance. Evaluation results demonstrate that accuracy of approximated frontiers depends linearly on predictors' training sample sizes, whereas transferring introduces only minor additional error to a frontier even for small training sizes.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {12–23},
numpages = {12},
keywords = {Pareto frontier, Pareto frontier transferring, configurable software, linear regression, performance prediction, regression trees},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}

@inproceedings{10.1007/978-3-030-45234-6_12,
author = {ter Beek, Maurice H. and van Loo, Sjef and de Vink, Erik P. and Willemse, Tim A. C.},
title = {Family-Based SPL Model Checking Using Parity Games with Variability},
year = {2020},
isbn = {978-3-030-45233-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-45234-6_12},
doi = {10.1007/978-3-030-45234-6_12},
abstract = {Family-based SPL model checking concerns the simultaneous verification of multiple product models, aiming to improve on enumerative product-based verification, by capitalising on the common features and behaviour of products in a software product line (SPL), typically modelled as a featured transition system (FTS). We propose efficient family-based SPL model checking of modal -calculus formulae on FTSs based on variability parity games, which extend parity games with conditional edges labelled with feature configurations, by reducing the SPL model checking problem for the modal -calculus on FTSs to the variability parity game solving problem, based on an encoding of FTSs as variability parity games. We validate our contribution by experiments on SPL benchmark models, which demonstrate that a novel family-based algorithm to collectively solve variability parity games, using symbolic representations of the configuration sets, outperforms the product-based method of solving the standard parity games obtained by projection with classical algorithms.},
booktitle = {Fundamental Approaches to Software Engineering: 23rd International Conference, FASE 2020, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2020, Dublin, Ireland, April 25–30, 2020, Proceedings},
pages = {245–265},
numpages = {21},
location = {Dublin, Ireland}
}

@inproceedings{10.1109/ICSE43902.2021.00028,
author = {Gao, Yanjie and Zhu, Yonghao and Zhang, Hongyu and Lin, Haoxiang and Yang, Mao},
title = {Resource-Guided Configuration Space Reduction for Deep Learning Models},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00028},
doi = {10.1109/ICSE43902.2021.00028},
abstract = {Deep learning models, like traditional software systems, provide a large number of configuration options. A deep learning model can be configured with different hyperparameters and neural architectures. Recently, AutoML (Automated Machine Learning) has been widely adopted to automate model training by systematically exploring diverse configurations. However, current AutoML approaches do not take into consideration the computational constraints imposed by various resources such as available memory, computing power of devices, or execution time. The training with non-conforming configurations could lead to many failed AutoML trial jobs or inappropriate models, which cause significant resource waste and severely slow down development productivity.In this paper, we propose DnnSAT, a resource-guided AutoML approach for deep learning models to help existing AutoML tools efficiently reduce the configuration space ahead of time. DnnSAT can speed up the search process and achieve equal or even better model learning performance because it excludes trial jobs not satisfying the constraints and saves resources for more trials. We formulate the resource-guided configuration space reduction as a constraint satisfaction problem. DnnSAT includes a unified analytic cost model to construct common constraints with respect to the model weight size, number of floating-point operations, model inference time, and GPU memory consumption. It then utilizes an SMT solver to obtain the satisfiable configurations of hyperparameters and neural architectures. Our evaluation results demonstrate the effectiveness of DnnSAT in accelerating state-of-the-art AutoML methods (Hyperparameter Optimization and Neural Architecture Search) with an average speedup from 1.19X to 3.95X on public benchmarks. We believe that DnnSAT can make AutoML more practical in a real-world environment with constrained resources.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {175–187},
numpages = {13},
keywords = {AutoML, configurable systems, constraint solving, deep learning},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3442391.3442411,
author = {Fischer, Stefan and Ramler, Rudolf and Klammer, Claus and Rabiser, Rick},
title = {Testing of Highly Configurable Cyber-Physical Systems – A Multiple Case Study},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442411},
doi = {10.1145/3442391.3442411},
abstract = {Cyber-physical systems, i.e., systems that seamlessly integrate computation and physical components, are typically highly-configurable systems. Testing such systems is particularly challenging because they comprise a large number of heterogeneous components that can be configured and combined in different ways. Despite a plethora of work investigating software testing in general and software product line testing in particular, variability in tests and how industry does actually manage testing highly configurable cyber-physical systems is not well understood. In this paper, we report the results of a multiple case study we conducted with three companies developing and maintaining highly-configurable cyber-physical systems focusing on their testing practices, with a particular focus on how they manage variability in tests. We conclude that experienced-based selection of configurations for testing is currently predominant. Variability modeling techniques are not utilized and the dependencies between configuration options are only partially modeled at best. However, the companies are aware of the situation and have the need and desire to cover more configuration combinations by automated tests. This in turn raises many questions, which might also be of interest to the scientific community and motivate future research.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {10},
keywords = {configuration testing, industry case, interview, variability testing},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.1145/3356317.3356318,
author = {Mendon\c{c}a, Willian D. F. and Assun\c{c}\~{a}o, Wesley K. G. and Vergilio, Silvia R.},
title = {Reusing Test Cases on Graph Product Line Variants: Results from a State-of-the-Practice Test Data Generation Tool},
year = {2019},
isbn = {9781450376488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3356317.3356318},
doi = {10.1145/3356317.3356318},
abstract = {Software testing is an essential activity for quality assurance, but, it is an error-prone and effort consuming task when conducted manually. Because of this, the use of automated tools is fundamental, as well as, the evaluation of these tools in practice. However, there is not so much evidence on how such tools perform on highly-configurable systems. Highly-configurable systems are commonly observed in industry as an approach to develop families of products, where products have different configuration options to meet customer needs. To fulfill such a gap, this paper reports results on the use of the tool Randoop, which is widely used in industry, to test variants of the Graph Product Line (GPL) family of products. Our goal is to evaluate reusability of a test data set generated by Randoop for one product when reused for testing other GPL products. Besides, we also investigate the impact of using different values of runtime, the main Randoop parameter, on the number of reused test data. The results show that the used value for runtime in general does not contribute to increase the coverage of test data reused in different products. Furthermore, similarity among products does not ensure a greater reusability.},
booktitle = {Proceedings of the IV Brazilian Symposium on Systematic and Automated Software Testing},
pages = {52–61},
numpages = {10},
keywords = {Family of Products, Highly-configurable systems, Software Reuse, Test Coverage, Test Data Generation},
location = {Salvador, Brazil},
series = {SAST '19}
}

@inproceedings{10.1145/3368089.3409684,
author = {Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {An empirical analysis of the costs of clone- and platform-oriented software reuse},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409684},
doi = {10.1145/3368089.3409684},
abstract = {Software reuse lowers development costs and improves the quality of software systems. Two strategies are common: clone &amp; own (copying and adapting a system) and platform-oriented reuse (building a configurable platform). The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs. The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility. As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures. Deciding for one strategy is a core decision with long-term impact on an organization’s software development. Unfortunately, the strategies’ costs are not well-understood - not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect. We present an empirical study of the development activities, costs, cost factors, and benefits associated with either reuse strategy. For this purpose, we combine quantitative and qualitative data that we triangulated from 26 interviews at a large organization and a systematic literature review covering 57 publications. Our study both confirms and refutes common hypotheses on software reuse. For instance, we confirm that developing for platform-oriented reuse is more expensive, but simultaneously reduces reuse costs; and that platform-orientation results in higher code quality compared to clone &amp; own. Surprisingly, refuting common hypotheses, we find that change propagation can be more expensive in a platform, that platforms can facilitate the advancement into innovative markets, and that there is no strict distinction of clone &amp; own and platform-oriented reuse in practice.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {432–444},
numpages = {13},
keywords = {clone &amp; own, economics, empirical study, platform engineering, software product line, software reuse},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1007/978-3-030-78270-2_74,
author = {Yun, Yue and Dai, Huan and Cao, Ruoqi and Zhang, Yupei and Shang, Xuequn},
title = {Self-paced Graph Memory Network for Student GPA Prediction and Abnormal Student Detection},
year = {2021},
isbn = {978-3-030-78269-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78270-2_74},
doi = {10.1007/978-3-030-78270-2_74},
abstract = {Student learning performance prediction (SLPP) is a crucial step in high school education. However, traditional methods fail to consider abnormal students. In this study, we organized every student’s learning data as a graph to use the schema of graph memory networks (GMNs). To distinguish the students and make GMNs learn robustly, we proposed to train GMNs in an “easy-to-hard” process, leading to self-paced graph memory network (SPGMN). SPGMN chooses the low-difficult samples as a batch to tune the model parameters in each training iteration. This approach not only improves the robustness but also rearranges the student sample from normal to abnormal. The experiment results show that SPGMN achieves a higher prediction accuracy and more robustness in comparison with traditional methods. The resulted student sequence reveals the abnormal student has a different pattern in course selection to normal students.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part II},
pages = {417–421},
numpages = {5},
keywords = {Student learning performance prediction, Self-paced learning, Graph memory networks, Abnormal student detection},
location = {Utrecht, The Netherlands}
}

@inproceedings{10.1145/3447545.3451182,
author = {Zhao, Yuxuan and Duplyakin, Dmitry and Ricci, Robert and Uta, Alexandru},
title = {Cloud Performance Variability Prediction},
year = {2021},
isbn = {9781450383318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447545.3451182},
doi = {10.1145/3447545.3451182},
abstract = {Cloud computing plays an essential role in our society nowadays. Many important services are highly dependant on the stable performance of the cloud. However, as prior work has shown, clouds exhibit large degrees of performance variability. Next to the stochastic variation induced by noisy neighbors, an important facet of cloud performance variability is given by changepoints---the instances where the non-stationary performance metrics exhibit persisting changes, which often last until subsequent changepoints occur. Such undesirable artifacts of the unstable application performance lead to problems with application performance evaluation and prediction efforts. Thus, characterization and understanding of performance changepoints become important elements of studying application performance in the cloud. In this paper, we showcase and tune two different changepoint detection methods, as well as demonstrate how the timing of the changepoints they identify can be predicted. We present a gradient-boosting-based prediction method, show that it can achieve good prediction accuracy, and give advice to practitioners on how to use our results.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {35–40},
numpages = {6},
keywords = {cloud computing, performance prediction, performance variability},
location = {Virtual Event, France},
series = {ICPE '21}
}

@article{10.1007/s00521-020-05441-1,
author = {Xu, Lingwei and Wang, Han and Li, Hui and Lin, Wenzhong and Gulliver, T. Aaron},
title = {QoS intelligent prediction for mobile video networks: a GR approach},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05441-1},
doi = {10.1007/s00521-020-05441-1},
abstract = {With the growth of mobile devices, consumer networks make the life more convenient and faster. Consumer networks consider mobile video as an important communication mode. Mobile video transmission faces complex environments, and the quality of service (QoS) of mobile video networks is very important for mobile entertainment applications. To evaluate the QoS of mobile video networks, outage probability (OP) is an important criterion. However, the mobile video networks gradually become complex, dynamic, and variable, which make it increasingly more difficult to predict the OP performance. In this paper, we investigate the OP performance analysis and prediction. The OP expressions are derived in exact closed-form. Then, based on the characteristics of mobile data, we have established a prediction model based on generalized regression (GR) neural network. A GR-based OP performance intelligent prediction algorithm is proposed. Compared with other methods, our proposed approach can obtain a better prediction effect. The prediction accuracy of the proposed approach can be increased by 64% and 58%, respectively. The running time is also the shortest.},
journal = {Neural Comput. Appl.},
month = may,
pages = {3891–3900},
numpages = {10},
keywords = {Mobile video networks, Quality of service, Performance analysis, Performance prediction}
}

@inproceedings{10.5555/602770.602870,
author = {Crovella, Mark E. and LeBlanc, Thomas J.},
title = {Parallel performance prediction using lost cycles analysis},
year = {1994},
isbn = {0818666056},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {Most performance debugging and tuning of parallel programs is based on the "measure-modify" approach, which is heavily dependent on detailed measurements of programs during execution. This approach is extremely time-consuming and does not lend itself to predicting performance under varying conditions. Analytic modeling and scalability analysis provide predictive power, but are not widely used in practice, due primarily to their emphasis on asymptotic behavior and the difficulty of developing accurate models that work for real-world programs. In this paper we describe a set of tools for performance tuning of parallel programs that bridges this gap between measurement and modeling.Our approach is based on lost cycles analysis, which involves measurement and modeling of all sources of overhead in a parallel program. We first describe a tool for measuring overheads in parallel programs that we have incorporated into the runtime environment for Fortran programs on the Kendall Square KSR1. We then describe a tool that fits these overhead measurements to analytic forms. We illustrate the use of these tools by analyzing the performance tradeoffs among parallel implementations of 2D FFT. These examples show how our tools enable programmers to develop accurate performance models of parallel applications without requiring extensive performance modeling expertise.},
booktitle = {Proceedings of the 1994 ACM/IEEE Conference on Supercomputing},
pages = {600–609},
numpages = {10},
location = {Washington, D.C.},
series = {Supercomputing '94}
}

@article{10.1177/0037549707084939,
author = {Grobelny, Eric and Bueno, David and Troxel, Ian and George, Alan D. and Vetter, Jeffrey S.},
title = {FASE: A Framework for Scalable Performance Prediction of HPC Systems and Applications},
year = {2007},
issue_date = {October   2007},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
volume = {83},
number = {10},
issn = {0037-5497},
url = {https://doi.org/10.1177/0037549707084939},
doi = {10.1177/0037549707084939},
abstract = {As systems of computers become more compleX in terms of their architecture,                interconnect and heterogeneity, the optimum configuration and utilization of these                machines becomes a major challenge. To reduce the penalties caused by poorly                configured systems, simulation is often used to predict the performance of key                applications to be eXecuted on the new systems. Simulation provides the capability                to observe component and system characteristics (e.g. performance and power) in                order to make vital design decisions. However, simulating high-fidelity models can                be very time consuming and even prohibitive when evaluating large-scale systems. The                Fast and Accurate Simulation Environment (FASE) framework seeks to support                large-scale system simulation by using high-fidelity models to capture the behavior                of only the performance-critical components while employing abstraction techniques                to capture the effects of those components with little impact on the system. In                order to achieve this balance of accuracy and simulation speed, FASE provides a                methodology and associated toolset to evaluate numerous architectural options. This                approach allows users to make system design decisions based on quantifiable demands                of their key applications rather than using manual analysis which can be error prone                and impractical for large systems. The framework accomplishes this evaluation                through a novel approach of combining discrete-event simulation with an application                characterization scheme in order to remove unnecessary details while focusing on                components critical to the performance of the application. In this paper, we present                the methodology and techniques behind FASE and include several case studies                validating systems constructed using various applications and interconnects.},
journal = {Simulation},
month = oct,
pages = {721–745},
numpages = {25},
keywords = {Performance prediction, application characterization, discrete-event simulation, high-performance computing}
}

@inproceedings{10.1145/1835449.1835659,
author = {Liu, Yang and Yu, Xiaohui and Huang, Xiangji and An, Aijun},
title = {S-PLASA+: adaptive sentiment analysis with application to sales performance prediction},
year = {2010},
isbn = {9781450301534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835449.1835659},
doi = {10.1145/1835449.1835659},
abstract = {Analyzing the large volume of online reviews would produce useful knowledge that could be of economic values to vendors and other interested parties. In particular, the sentiments expressed in the online reviews have been shown to be strongly correlated with the sales performance of products. In this paper, we present an adaptive sentiment analysis model called S-PLSA+, which aims to capture the hidden sentiment factors in the reviews with the capability to be incrementally updated as more data become available. We show how S-PLSA+ can be applied to sales performance prediction using an ARSA model developed in previous literature. A case study is conducted in the movie domain, and results from preliminary experiments confirm the effectiveness of the proposed model.},
booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {873–874},
numpages = {2},
keywords = {prediction, review mining, sentiment analysis},
location = {Geneva, Switzerland},
series = {SIGIR '10}
}

@article{10.1007/s11219-013-9197-z,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Quality attribute modeling and quality aware product configuration in software product lines},
year = {2014},
issue_date = {September 2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-013-9197-z},
doi = {10.1007/s11219-013-9197-z},
abstract = {In software product line engineering, the customers mostly concentrate on the functionalities of the target product during product configuration. The quality attributes of a target product, such as security and performance, are often assessed until the final product is generated. However, it might be very costly to fix the problem if it is found that the generated product cannot satisfy the customers' quality requirements. Although the quality of a generated product will be affected by all the life cycles of product development, feature-based product configuration is the first stage where the estimation or prediction of the quality attributes should be considered. As we know, the key issue of predicting the quality attributes for a product configured from feature models is to measure the interdependencies between functional features and quality attributes. The current existing approaches have several limitations on this issue, such as requiring real products for the measurement or involving domain experts' efforts. To overcome these limitations, we propose a systematic approach of modeling quality attributes in feature models based on domain experts' judgments using the analytic hierarchical process (AHP) and conducting quality aware product configuration based on the captured quality knowledge. Domain experts' judgments are adapted to avoid generating the real products for quality evaluation, and AHP is used to reduce domain experts' efforts involved in the judgments. A prototype tool is developed to implement the concepts of the proposed approach, and a formal evaluation is carried out based on a large-scale case study.},
journal = {Software Quality Journal},
month = sep,
pages = {365–401},
numpages = {37},
keywords = {Analytic hierarchical process (AHP), Feature model, Non-functional requirement (NFR) framework, Product configuration, Quality attributes assessment, Software product line}
}

@article{10.1016/j.future.2016.11.022,
author = {Cheng, Yuxia and Chen, Wenzhi and Wang, Zonghui and Tang, Zhongxian and Xiang, Yang},
title = {Smart VM co-scheduling with the precise prediction of performance characteristics},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {105},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2016.11.022},
doi = {10.1016/j.future.2016.11.022},
journal = {Future Gener. Comput. Syst.},
month = apr,
pages = {1016–1027},
numpages = {12},
keywords = {Virtual machine, Shared resource contention, Performance prediction, VM co-location}
}

@inproceedings{10.1145/3458817.3476221,
author = {Arafa, Yehia and Badawy, Abdel-Hameed and ElWazir, Ammar and Barai, Atanu and Eker, Ali and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
title = {Hybrid, scalable, trace-driven performance modeling of GPGPUs},
year = {2021},
isbn = {9781450384421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458817.3476221},
doi = {10.1145/3458817.3476221},
abstract = {In this paper, we present PPT-GPU, a scalable performance prediction toolkit for GPUs. PPT-GPU achieves scalability through a hybrid high-level modeling approach where some computations are extrapolated and multiple parts of the model are parallelized. The tool primary prediction models use pre-collected memory and instructions traces of the workloads to accurately capture the dynamic behavior of the kernels.PPT-GPU reports an extensive array of GPU performance metrics accurately while being easily extensible. We use a broad set of benchmarks to verify predictions accuracy. We compare the results against hardware metrics collected using vendor profiling tools and cycle-accurate simulators. The results show that the performance predictions are highly correlated to the actual hardware (MAPE: &lt; 16% and Correlation: &gt; 0.98). Moreover, PPT-GPU is orders of magnitude faster than cycle-accurate simulators. This comprehensiveness of the collected metrics can guide architects and developers to perform design space explorations. Moreover, the scalability of the tool enables conducting efficient and fast sensitivity analyses for performance-critical applications.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {53},
numpages = {15},
keywords = {NVIDIA GPUs, PTX, SASS, design space exploration, modeling and simulation, performance prediction},
location = {St. Louis, Missouri},
series = {SC '21}
}

@article{10.1016/j.procs.2018.04.193,
author = {Chen, Jing and Wang, Yinglong},
title = {A Resource Demand Prediction Method Based on EEMD in Cloud Computing},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {131},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.04.193},
doi = {10.1016/j.procs.2018.04.193},
abstract = {A large number of resources are integrated into a data center to provide various resource services in cloud computing. A major challenge is how to provide resources timely and accurately to satisfy users demands. However, users resource demands change constantly and sometimes fluctuate very strong. The resource provision may be not performed in time. And even, sometimes the active physical resources may be too insufficient to satisfy users demands because some of them are shut down in order to reduce energy. So it is important to provide a proactive resource provision to guarantee good users experiences in cloud computing. The key is to predict the future resource demands accurately to support resource provision in advance. In this paper, we propose a resource demand prediction method EEMD-ARIMA based on ensemble empirical mode decomposition (EEMD) in cloud computing. This method decomposes the non-stationary users resource demands into a plurality of intrinsic mode function components (IMFs) and residual component (RES) through EEMD method to improve the prediction accuracy. The experimental results show that our method has a higher prediction accuracy compared with the existing ARIMA prediction model in the short-term prediction of cloud resource demands.},
journal = {Procedia Comput. Sci.},
month = may,
pages = {116–123},
numpages = {8},
keywords = {ARIMA, Cloud computing, EEMD, prediction accuracy, resource demand}
}

@inproceedings{10.1145/3377024.3377041,
author = {Beek, Maurice H. ter and Legay, Axel and Lafuente, Alberto Lluch and Vandin, Andrea},
title = {Variability meets security: qantitative security modeling and analysis of highly customizable attack scenarios},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377041},
doi = {10.1145/3377024.3377041},
abstract = {We present a framework for quantitative security modeling and analysis of highly customizable attack scenarios, which resulted as a spin-off from our research in software product line engineering. The graphical security models are based on attributed attack-defense diagrams to capture the structure and properties of vulnerabilities, defenses and countermeasures---with notable similarities to feature diagrams---and on probabilistic models of attack behavior, capable of capturing resource constraints and attack effectiveness. In this paper, we provide an overview of the framework that is described in full technical detail in twin papers, which present the formal syntax and semantics of the domain-specific language and showcase the associated tool with advanced IDE support for performing analyses based on statistical model checking. The properties of interest range from average cost and success probability of attacks to the effectiveness of defenses and countermeasures. Here we illustrate the capabilities of the DSL and the tool by applying them to an example scenario from the security domain. This shows how techniques from variability modeling can be applied to security. We conclude with a vision and roadmap for future research.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {11},
numpages = {9},
keywords = {attack-defense trees, formal analysis tools, graphical security models, quantitative security, statistical model checking, variability models},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1145/2391229.2391250,
author = {Park, Nohhyun and Ahmad, Irfan and Lilja, David J.},
title = {Romano: autonomous storage management using performance prediction in multi-tenant datacenters},
year = {2012},
isbn = {9781450317610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2391229.2391250},
doi = {10.1145/2391229.2391250},
abstract = {Workload consolidation is a key technique in reducing costs in virtualized datacenters. When considering storage consolidation, a key problem is the unpredictable performance behavior of consolidated workloads on a given storage system. In practice, this often forces system administrators to grossly overprovision storage to meet application demands. In this paper, we show that existing modeling techniques are inaccurate and ineffective in the face of heterogenous devices. We introduce Romano, a storage performance management system designed to optimize truly heterogeneous virtualized datacenters. At its core, Romano constructs and adapts approximate workload-specific performance models of storage devices automatically, along with prediction intervals. It then applies these models to allow highly efficient IO load balancing.End-to-end experiments demonstrate that Romano reduces prediction error by 80% on average compared with existing techniques. The result is improved load balancing with lowered variance by 82% and reduced average and maximum latency observed across the storage systems by 52% and 78%, respectively.},
booktitle = {Proceedings of the Third ACM Symposium on Cloud Computing},
articleno = {21},
numpages = {14},
keywords = {QoS, VM, device, modeling, storage, virtualization},
location = {San Jose, California},
series = {SoCC '12}
}

@article{10.1177/109434200001400306,
author = {Nudd, G. R. and Kerbyson, D. J. and Papaefstathiou, E. and Perry, S. C. and Harper, J. S. and Wilcox, D. V.},
title = {Pace--A Toolset for the Performance Prediction of Parallel and Distributed Systems},
year = {2000},
issue_date = {August    2000},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {14},
number = {3},
issn = {1094-3420},
url = {https://doi.org/10.1177/109434200001400306},
doi = {10.1177/109434200001400306},
abstract = {This paper describes a methodology that provides detailed predictive performance information throughout the software design and implementation cycles. It is structured around a hierarchy of performance models that describe the computing system in terms of its software, parallelization, and hardware components. The methodology is illustrated with an implementation, the performance analysis and characterization environment (PACE) system, which provides information concerning execution time, scalability, and resource use. A principal aim of the work is to provide a capability for rapid calculation of relevant performance numbers without sacrificing accuracy. The predictive nature of the approach provides both pre and post implementation analyses and allows implementation alternatives to be explored prior to the commitment of an application to a system. Because of the relatively fast analysis times, these techniques can be used at runtime to assist in application steering and scheduling with reference to dynamically changing systems and metacomputing.},
journal = {Int. J. High Perform. Comput. Appl.},
month = aug,
pages = {228–251},
numpages = {24}
}

@article{10.1007/s10664-020-09892-x,
author = {Kuiter, Elias and Krieter, Sebastian and Kr\"{u}ger, Jacob and Saake, Gunter and Leich, Thomas},
title = {variED: an editor for collaborative, real-time feature modeling},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09892-x},
doi = {10.1007/s10664-020-09892-x},
abstract = {Feature models are a helpful means to document, manage, maintain, and configure the variability of a software system, and thus are a core artifact in software product-line engineering. Due to the various purposes of feature models, they can be a cross-cutting concern in an organization, integrating technical and business aspects. For this reason, various stakeholders (e.g., developers and consultants) may get involved into modeling the features of a software product line. Currently, collaboration in such a scenario can only be done with face-to-face meetings or by combining single-user feature-model editors with additional communication and version-control systems. While face-to-face meetings are often costly and impractical, using version-control systems can cause merge conflicts and inconsistency within a model, due to the different intentions of the involved stakeholders. Advanced tools that solve these problems by enabling collaborative, real-time feature modeling, analogous to Google Docs or Overleaf for text editing, are missing. In this article, we build on a previous paper and describe (1) the extended formal foundations of collaborative, real-time feature modeling, (2) our conflict resolution algorithm in more detail, (3) proofs that our formalization converges and preserves causality as well as user intentions, (4) the implementation of our prototype, and (5) the results of an empirical evaluation to assess the prototype’s usability. Our contributions provide the basis for advancing existing feature-modeling tools and practices to support collaborative feature modeling. The results of our evaluation show that our prototype is considered helpful and valuable by 17 users, also indicating potential for extending our tool and opportunities for new research directions.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {47},
keywords = {Software product lines, Groupware, Feature modeling, Variability, Consistency maintenance, Collaboration}
}

@article{10.1016/j.jss.2019.04.026,
author = {Gacit\'{u}a, Ricardo and Sep\'{u}lveda, Samuel and Mazo, Ra\'{u}l},
title = {FM-CF: A framework for classifying feature model building approaches},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.026},
doi = {10.1016/j.jss.2019.04.026},
journal = {J. Syst. Softw.},
month = aug,
pages = {1–21},
numpages = {21},
keywords = {Feature model, Software product lines, Framework, Classification, Models}
}

@article{10.1007/s10664-015-9360-1,
author = {Hunsen, Claus and Zhang, Bo and Siegmund, Janet and K\"{a}stner, Christian and Leβenich, Olaf and Becker, Martin and Apel, Sven},
title = {Preprocessor-based variability in open-source and industrial software systems: An empirical study},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9360-1},
doi = {10.1007/s10664-015-9360-1},
abstract = {Almost every sufficiently complex software system today is configurable. Conditional compilation is a simple variability-implementation mechanism that is widely used in open-source projects and industry. Especially, the C preprocessor (CPP) is very popular in practice, but it is also gaining (again) interest in academia. Although there have been several attempts to understand and improve CPP, there is a lack of understanding of how it is used in open-source and industrial systems and whether different usage patterns have emerged. The background is that much research on configurable systems and product lines concentrates on open-source systems, simply because they are available for study in the first place. This leads to the potentially problematic situation that it is unclear whether the results obtained from these studies are transferable to industrial systems. We aim at lowering this gap by comparing the use of CPP in open-source projects and industry--especially from the embedded-systems domain--based on a substantial set of subject systems and well-known variability metrics, including size, scattering, and tangling metrics. A key result of our empirical study is that, regarding almost all aspects we studied, the analyzed open-source systems and the considered embedded systems from industry are similar regarding most metrics, including systems that have been developed in industry and made open source at some point. So, our study indicates that, regarding CPP as variability-implementation mechanism, insights, methods, and tools developed based on studies of open-source systems are transferable to industrial systems--at least, with respect to the metrics we considered.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {449–482},
numpages = {34},
keywords = {C preprocessor, Configurable systems, Industrial systems, Open-source systems, Software product lines, Variability, cppstats}
}

@article{10.1007/s10639-020-10230-3,
author = {Khan, Anupam and Ghosh, Soumya K.},
title = {Student performance analysis and prediction in classroom learning: A review of educational data mining studies},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1360-2357},
url = {https://doi.org/10.1007/s10639-020-10230-3},
doi = {10.1007/s10639-020-10230-3},
abstract = {Student performance modelling is one of the challenging and popular research topics in educational data mining (EDM). Multiple factors influence the performance in non-linear ways; thus making this field more attractive to the researchers. The widespread availability of e ducational datasets further catalyse this interestingness, especially in online learning. Although several EDM surveys are available in the literature, we could find only a few specific surveys on student performance analysis and prediction. These specific surveys are limited in nature and primarily focus on studies that try to identify possible predictor or model student performance. However, the previous works do not address the temporal aspect of prediction. Moreover, we could not find any such specific survey which focuses only on classroom-based education. In this paper, we present a systematic review of EDM studies on student performance in classroom learning. It focuses on identifying the predictors, methods used for such identification, time and aim of prediction. It is significantly the first systematic survey of EDM studies that consider only classroom learning and focuses on the temporal aspect as well. This paper presents a review of 140 studies in this area. The meta-analysis indicates that the researchers achieve significant prediction efficiency during the tenure of the course. However, performance prediction before course commencement needs special attention.},
journal = {Education and Information Technologies},
month = jan,
pages = {205–240},
numpages = {36},
keywords = {Student performance, Classroom learning, Performance prediction, Literature review, Educational data mining}
}

@inproceedings{10.1145/3458817.3476215,
author = {Zhao, Laiping and Yang, Yanan and Li, Yiming and Zhou, Xian and Li, Keqiu},
title = {Understanding, predicting and scheduling serverless workloads under partial interference},
year = {2021},
isbn = {9781450384421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458817.3476215},
doi = {10.1145/3458817.3476215},
abstract = {Interference among distributed cloud applications can be classified into three types: full, partial and zero. While prior research merely focused on full interference, the partial interference that occurs at parts of applications is far more common yet still lacks in-depth study. Serverless computing that structures applications into small-sized, short-lived functions further exacerbate partial interference. We characterize the features of partial interference in serverless as exhibiting high volatility, spatial-temporal variation, and propagation. Given these observations, we propose an incremental learning predictor, named Gsight, which can achieve high precision by harnessing the spatial-temporal overlap codes and profiles of functions via an end-to-end call path. Experimental results show that Gsight can achieve an average error of 1.71%. Its convergence speed is at least 3X faster than that in a serverful system. A scheduling case study shows that the proposed method can improve function density by ≥ 18.79% while guaranteeing the quality of service (QoS).},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {22},
numpages = {15},
keywords = {partial interference, performance prediction, resource utilization, serverless},
location = {St. Louis, Missouri},
series = {SC '21}
}

@inproceedings{10.1145/3427921.3450248,
author = {Grohmann, Johannes and Straesser, Martin and Chalbani, Avi and Eismann, Simon and Arian, Yair and Herbst, Nikolas and Peretz, Noam and Kounev, Samuel},
title = {SuanMing: Explainable Prediction of Performance Degradations in Microservice Applications},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450248},
doi = {10.1145/3427921.3450248},
abstract = {Application performance management (APM) tools are useful to observe the performance properties of an application during production. However, APM is normally purely reactive, that is, it can only report about current or past performance degradation. Although some approaches capable of predictive application monitoring have been proposed, they can only report a predicted degradation but cannot explain its root-cause, making it hard to prevent the expected degradation.In this paper, we present SuanMing---a framework for predicting performance degradation of microservice applications running in cloud environments. SuanMing is able to predict future root causes for anticipated performance degradations and therefore aims at preventing performance degradations before they actually occur. We evaluate SuanMing on two realistic microservice applications, TeaStore and TrainTicket, and we show that our approach is able to predict and pinpoint performance degradations with an accuracy of over 90%.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {165–176},
numpages = {12},
keywords = {explainability, forecasting, microservices, performance prediction},
location = {Virtual Event, France},
series = {ICPE '21}
}

@inproceedings{10.1007/978-3-642-33119-0_13,
author = {Lopez-Herrejon, Roberto Erick and Galindo, Jos\'{e} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
title = {Reverse engineering feature models with evolutionary algorithms: an exploratory study},
year = {2012},
isbn = {9783642331183},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33119-0_13},
doi = {10.1007/978-3-642-33119-0_13},
abstract = {Successful software evolves, more and more commonly, from a single system to a set of system variants tailored to meet the similiar and yet different functionality required by the distinct clients and users. Software Product Line Engineering (SPLE) is a software development paradigm that has proven effective for coping with this scenario. At the core of SPLE is variability modeling which employs Feature Models (FMs) as the de facto standard to represent the combinations of features that distinguish the systems variants. Reverse engineering FMs consist in constructing a feature model from a set of products descriptions. This research area is becoming increasingly active within the SPLE community, where the problem has been addressed with different perspectives and approaches ranging from analysis of configuration scripts, use of propositional logic or natural language techniques, to ad hoc algorithms. In this paper, we explore the feasibility of using Evolutionary Algorithms (EAs) to synthesize FMs from the feature sets that describe the system variants. We analyzed 59 representative case studies of different characteristics and complexity. Our exploratory study found that FMs that denote proper supersets of the desired feature sets can be obtained with a small number of generations. However, reducing the differences between these two sets with an effective and scalable fitness function remains an open question. We believe that this work is a first step towards leveraging the extensive wealth of Search-Based Software Engineering techniques to address this and other variability management challenges.},
booktitle = {Proceedings of the 4th International Conference on Search Based Software Engineering},
pages = {168–182},
numpages = {15},
location = {Riva del Garda, Italy},
series = {SSBSE'12}
}

@inproceedings{10.1145/3168365.3168377,
author = {Ananieva, Sofia and Klare, Heiko and Burger, Erik and Reussner, Ralf},
title = {Variants and Versions Management for Models with Integrated Consistency Preservation},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168377},
doi = {10.1145/3168365.3168377},
abstract = {Modern software systems are often developed and maintained by describing them in several modeling and programming languages. To reduce complexity and improve understandability of such systems, models represent specific views on the system. These views have semantic interrelations (e.g., by sharing common or dependent information) that need to be kept consistent during evolution of the system. Apart from that, modern systems need to run in many different contexts and be highly configurable to satisfy the demand for fully customizable products. Such variable systems often comprise various dependencies from which inconsistencies may arise. Combining solutions for consistency management with variants and versions management, however, comes with many challenges.In this research-in-progress paper, we introduce the VaVe approach which makes variants and versions management aware of automated consistency preservation in the context of multi-view modeling. We explain core features of the approach and reason about its benefits and limitations.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {3–10},
numpages = {8},
keywords = {Delta-Based Consistency Preservation, Software Product Lines, Variability Management},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.5555/3172795.3172831,
author = {Masri, Samer Al and Bhuiyan, Nazim Uddin and Nadi, Sarah and Gaudet, Matthew},
title = {Software variability through C++ static polymorphism: a case study of challenges and open problems in eclipse OMR},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software Product Line Engineering (SPLE) creates configurable platforms that can be used to efficiently produce similar, and yet different, product variants. SPLs are typically modular such that it is easy to connect different blocks of code together, creating different variations of the product. There are many variability implementation mechanisms to achieve an SPL. This paper shows how static polymorphism can be used to implement variability, through a case study of IBM's open-source Eclipse OMR project. We discuss the current open problems and challenges this variability implementation mechanism raises and highlight technology gaps for reasoning about variability in OMR. We then suggest steps to close these gaps.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {285–291},
numpages = {7},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.5555/1158337.1158711,
author = {Czarnecki, Krzysztof},
title = {Tutorial on Generative Software Development},
year = {2006},
isbn = {0769525997},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software product line engineering (SPLE) [5] seeks to exploit the commonalities among systems from a given problem domain while managing the variabilities among them in a systematic way. In SPLE, new system variants can be rapidly created based on a set of reusable assets, such as a common architecture, components, and models. Generative software development [6] aims at modeling and implementing product lines in such a way that a given system can be automatically generated from a specification written in one or more textual or graphical domain-specific languages (DSLs) [13, 4, 15, 8, 3, 1, 12, 14].},
booktitle = {Proceedings of the 10th International on Software Product Line Conference},
pages = {227},
series = {SPLC '06}
}

@article{10.1145/3477133.3477137,
author = {Wang, Chuan-Chi and Liao, Ying-Chiao and Kao, Ming-Chang and Liang, Wen-Yew and Hung, Shih-Hao},
title = {Toward accurate platform-aware performance modeling for deep neural networks},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1559-6915},
url = {https://doi.org/10.1145/3477133.3477137},
doi = {10.1145/3477133.3477137},
abstract = {In this paper, we provide a fine-grain machine learning-based method, PerfNetV2, which improves the accuracy of our previous work for modeling the neural network performance on a variety of GPU accelerators. Given an application, the proposed method can be used to predict the inference time and training time of the convolutional neural networks used in the application, which enables the system developer to optimize the performance by choosing the neural networks and/or incorporating the hardware accelerators to deliver satisfactory results in time. Furthermore, the proposed method is capable of predicting the performance of an unseen or non-existing device, e.g. a new GPU which has a higher operating frequency with less processor cores, but more memory capacity. This allows a system developer to quickly search the hardware design space and/or fine-tune the system configuration. Compared to the previous works, PerfNetV2 delivers more accurate results by modeling detailed host-accelerator interactions in executing the full neural networks and improving the architecture of the machine learning model used in the predictor. Our case studies show that PerfNetV2 yields a mean absolute percentage error within 13.1% on LeNet, AlexNet, and VGG16 on NVIDIA GTX-1080Ti, while the error rate on a previous work published in ICBD 2018 could be as large as 200%.},
journal = {SIGAPP Appl. Comput. Rev.},
month = jul,
pages = {50–61},
numpages = {12},
keywords = {benchmark, heterogeneous systems, machine learning, performance prediction}
}

@inproceedings{10.1145/2517208.2517209,
author = {Siegmund, Norbert and von Rhein, Alexander and Apel, Sven},
title = {Family-based performance measurement},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517209},
doi = {10.1145/2517208.2517209},
abstract = {Most contemporary programs are customizable. They provide many features that give rise to millions of program variants. Determining which feature selection yields an optimal performance is challenging, because of the exponential number of variants. Predicting the performance of a variant based on previous measurements proved successful, but induces a trade-off between the measurement effort and prediction accuracy. We propose the alternative approach of family-based performance measurement, to reduce the number of measurements required for identifying feature interactions and for obtaining accurate predictions. The key idea is to create a variant simulator (by translating compile-time variability to run-time variability) that can simulate the behavior of all program variants. We use it to measure performance of individual methods, trace methods to features, and infer feature interactions based on the call graph. We evaluate our approach by means of five feature-oriented programs. On average, we achieve accuracy of 98%, with only a single measurement per customizable program. Observations show that our approach opens avenues of future research in different domains, such an feature-interaction detection and testing.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {95–104},
numpages = {10},
keywords = {family-based analysis, featurehouse, performance prediction},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@article{10.1016/j.future.2017.10.048,
author = {Mariani, Giovanni and Anghel, Andreea and Jongerius, Rik and Dittmann, Gero},
title = {Predicting cloud performance for HPC applications before deployment},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {87},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2017.10.048},
doi = {10.1016/j.future.2017.10.048},
journal = {Future Gener. Comput. Syst.},
month = oct,
pages = {618–628},
numpages = {11},
keywords = {Cloud computing, Performance prediction, Random forest}
}

@inproceedings{10.1145/3458744.3474049,
author = {Dhandhania, Sunidhi and Deodhar, Akshay and Pogorelov, Konstantin and Biswas, Swarnendu and Langguth, Johannes},
title = {Explaining the Performance of Supervised and Semi-Supervised Methods for Automated Sparse Matrix Format Selection},
year = {2021},
isbn = {9781450384414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458744.3474049},
doi = {10.1145/3458744.3474049},
abstract = {The performance of sparse matrix-vector multiplication kernels (SpMV) depends on the sparse matrix storage format and the architecture and the memory hierarchy of the target processor. Many sparse matrix storage formats along with corresponding SpMV algorithms have been proposed for improved SpMV performance. Given a sparse matrix and a target architecture, supervised Machine Learning techniques automate selecting the best formats. However, existing supervised approaches suffer from several drawbacks. They depend on large representative datasets and are expensive to train. In addition, retraining to incorporate new classes of matrices or different processor architectures is just as costly since new training data must be generated by benchmarking many instances. Furthermore, it is hard to understand the results of many supervised systems. We propose using semi-supervised machine learning techniques for format selection. We highlight the challenges in using the K-Means clustering for the sparse format selection problem and show how to adapt the algorithm to improve its performance. An empirical evaluation of our technique shows that the performance of our proposed semi-supervised learning approach is competitive with supervised methods, in addition to providing flexibility and explainability.},
booktitle = {50th International Conference on Parallel Processing Workshop},
articleno = {6},
numpages = {10},
keywords = {ML, SpMV, Sparse matrices, clustering, performance prediction},
location = {Lemont, IL, USA},
series = {ICPP Workshops '21}
}

@article{10.1007/s10664-020-09911-x,
author = {Ramos-Guti\'{e}rrez, Bel\'{e}n and Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Discovering configuration workflows from existing logs using process mining},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09911-x},
doi = {10.1007/s10664-020-09911-x},
abstract = {Variability models are used to build configurators, for guiding users through the configuration process to reach the desired setting that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the design options that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suits stakeholders according to previous configurations. For example, when configuring a Linux distribution the configuration process starts by choosing the network or the graphic card and then, other packages concerning a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), a framework that can automatically assist determining the configuration workflow that better fits the configuration logs generated by user activities given a set of logs of previous configurations and a variability model. COLOSSI is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Derived from the possible complexity of both logs and the discovered processes, often, it is necessary to divide the traces into small ones. This provides an easier configuration workflow to be understood and followed by the user during the configuration process. In this paper, we apply and compare four different techniques for the traces clustering: greedy, backtracking, genetic and hierarchical algorithms. Our proposal is validated in three different scenarios, to show its feasibility, an ERP configuration, a Smart Farming, and a Computer Configuration. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering along with the necessity to apply clustering techniques for the trace preparation in the context of configuration workflows.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {41},
keywords = {Variability, Configuration workflow, Process mining, Process discovery, Clustering}
}

@inproceedings{10.1145/3422604.3425929,
author = {Qiu, Yiming and Kang, Qiao and Liu, Ming and Chen, Ang},
title = {Clara: Performance Clarity for SmartNIC Offloading},
year = {2020},
isbn = {9781450381451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422604.3425929},
doi = {10.1145/3422604.3425929},
abstract = {The gap between CPU and networking speeds has motivated the development of SmartNICs for near-network processing. Recent work has shown that many network functions can benefit from SmartNIC offloading, but identifying the best porting strategy requires hand-tuning and workload-specific optimizations. The developer has no easy way to understand the ported performance beforehandWe are developing a tool called Clara, whose goal is to provide performance clarity for SmartNIC offloading. Clara can analyze an unported NF in its original form, and predict its performance when ported to a SmartNIC target. This automated workflow enables the developer to easily customize offloading strategies, obtain performance insights, and identify suitable SmartNIC models for her workloads. Clara's key technical roadmap is to emulate a compiler, lowering an unported program to a SmartNIC target logically, without performing code generation. This results in a mapping from core NF logic to SmartNIC hardware resources, and Clara then plugs in NIC parameters to predict the performance for specific workloads. We describe our progress so far, and report initial validation results with Netronome hardware.},
booktitle = {Proceedings of the 19th ACM Workshop on Hot Topics in Networks},
pages = {16–22},
numpages = {7},
keywords = {network functions, performance prediction, smartnics},
location = {Virtual Event, USA},
series = {HotNets '20}
}

@article{10.1007/s10664-019-09705-w,
author = {Kolesnikov, Sergiy and Siegmund, Norbert and K\"{a}stner, Christian and Apel, Sven},
title = {On the relation of control-flow and performance feature interactions: a case study},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09705-w},
doi = {10.1007/s10664-019-09705-w},
abstract = {Detecting feature interactions is imperative for accurately predicting performance of highly-configurable systems. State-of-the-art performance prediction techniques rely on supervised machine learning for detecting feature interactions, which, in turn, relies on time-consuming performance measurements to obtain training data. By providing information about potentially interacting features, we can reduce the number of required performance measurements and make the overall performance prediction process more time efficient. We expect that information about potentially interacting features can be obtained by analyzing the source code of a highly-configurable system, which is computationally cheaper than performing multiple performance measurements. To this end, we conducted an in-depth qualitative case study on two real-world systems (mbedTLS and SQLite), in which we explored the relation between internal (precisely control-flow) feature interactions, detected through static program analysis, and external (precisely performance) feature interactions, detected by performance-prediction techniques using performance measurements. We found that a relation exists that can potentially be exploited to predict performance interactions.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {2410–2437},
numpages = {28},
keywords = {Control-flow feature interaction, Feature, Feature interaction, Feature-interaction prediction, Highly configurable software system, Performance feature interaction, Variability}
}

@inproceedings{10.1007/978-3-030-65310-1_20,
author = {Metzger, Andreas and Quinton, Cl\'{e}ment and Mann, Zolt\'{a}n \'{A}d\'{a}m and Baresi, Luciano and Pohl, Klaus},
title = {Feature Model-Guided Online Reinforcement Learning for Self-Adaptive Services},
year = {2020},
isbn = {978-3-030-65309-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-65310-1_20},
doi = {10.1007/978-3-030-65310-1_20},
abstract = {A self-adaptive service can maintain its QoS requirements in the presence of dynamic environment changes. To develop a self-adaptive service, service engineers have to create self-adaptation logic encoding when the service should execute which adaptation actions. However, developing self-adaptation logic may be difficult due to design time uncertainty; e.g., anticipating all potential environment changes at design time is in most cases infeasible. Online reinforcement learning addresses design time uncertainty by learning suitable adaptation actions through interactions with the environment at runtime. To learn more about its environment, reinforcement learning has to select actions that were not selected before, which is known as exploration. How exploration happens has an impact on the performance of the learning process. We focus on two problems related to how a service’s adaptation actions are explored: (1) Existing solutions randomly explore adaptation actions and thus may exhibit slow learning if there are many possible adaptation actions to choose from. (2) Existing solutions are unaware of service evolution, and thus may explore new adaptation actions introduced during such evolution rather late. We propose novel exploration strategies that use feature models (from software product line engineering) to guide exploration in the presence of many adaptation actions and in the presence of service evolution. Experimental results for a self-adaptive cloud management service indicate an average speed-up of the learning process of 58.8% in the presence of many adaptation actions, and of 61.3% in the presence of service evolution. The improved learning performance in turn led to an average QoS improvement of 7.8% and 23.7% respectively
.},
booktitle = {Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {269–286},
numpages = {18},
keywords = {Adaptation, Reinforcement learning, Feature model, Cloud service},
location = {Dubai, United Arab Emirates}
}

@article{10.1016/j.infsof.2015.01.008,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
title = {A systematic mapping study of search-based software engineering for software product lines},
year = {2015},
issue_date = {May 2015},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {61},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.01.008},
doi = {10.1016/j.infsof.2015.01.008},
abstract = {ContextSearch-Based Software Engineering (SBSE) is an emerging discipline that focuses on the application of search-based optimization techniques to software engineering problems. Software Product Lines (SPLs) are families of related software systems whose members are distinguished by the set of features each one provides. SPL development practices have proven benefits such as improved software reuse, better customization, and faster time to market. A typical SPL usually involves a large number of systems and features, a fact that makes them attractive for the application of SBSE techniques which are able to tackle problems that involve large search spaces. ObjectiveThe main objective of our work is to identify the quantity and the type of research on the application of SBSE techniques to SPL problems. More concretely, the SBSE techniques that have been used and at what stage of the SPL life cycle, the type of case studies employed and their empirical analysis, and the fora where the research has been published. MethodA systematic mapping study was conducted with five research questions and assessed 77 publications from 2001, when the term SBSE was coined, until 2014. ResultsThe most common application of SBSE techniques found was testing followed by product configuration, with genetic algorithms and multi-objective evolutionary algorithms being the two most commonly used techniques. Our study identified the need to improve the robustness of the empirical evaluation of existing research, a lack of extensive and robust tool support, and multiple avenues worthy of further investigation. ConclusionsOur study attested the great synergy existing between both fields, corroborated the increasing and ongoing interest in research on the subject, and revealed challenging open research questions.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {33–51},
numpages = {19},
keywords = {Evolutionary algorithm, Metaheuristics, Search based software engineering, Software product line, Systematic mapping study}
}

@inproceedings{10.1145/3400286.3418245,
author = {Wang, Chuan-Chi and Liao, Ying-Chiao and Kao, Ming-Chang and Liang, Wen-Yew and Hung, Shih-Hao},
title = {PerfNet: Platform-Aware Performance Modeling for Deep Neural Networks},
year = {2020},
isbn = {9781450380256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3400286.3418245},
doi = {10.1145/3400286.3418245},
abstract = {The technology of deep learning has grown rapidly and been widely used in the industry. In addition to the accuracy of the deep learning (DL) models, system developers are also interested in comprehending their performance aspects to make sure that the hardware design and the systems deployed to meet the application demands. However, developing a performance model to serve the aforementioned purpose needs to take many issues into account, e.g. the DL model, the runtime software, and the system architecture, which is quite complex. In this work, we propose a multi-layer regression network, called PerfNet, to predict the performance of DL models on heterogeneous systems. To train the PerfNet, we develop a tool to collect the performance features and characteristics of DL models on a set of heterogeneous systems, including key hyper-parameters such as loss functions, network shapes, and dataset size, as well as the hardware specifications. Our experiments show that the results of our approach are more accurate than previously published methods. In the case of VGG16 on GTX1080Ti, PerfNet yields a mean absolute percentage error of 20%, while the referenced work constantly overestimates with errors larger than 200%.},
booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},
pages = {90–95},
numpages = {6},
keywords = {Performance Prediction, Machine Learning, Heterogeneous Systems, Benchmark},
location = {Gwangju, Republic of Korea},
series = {RACS '20}
}

@article{10.1006/jpdc.1996.0129,
author = {Yang, Yong and Zhang, Xiaodong and Song, Yongsheng},
title = {An Effective and Practical Performance Prediction Model for Parallel Computing on Nondedicated Heterogeneous NOW},
year = {1996},
issue_date = {Oct. 10, 1996},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {38},
number = {1},
issn = {0743-7315},
url = {https://doi.org/10.1006/jpdc.1996.0129},
doi = {10.1006/jpdc.1996.0129},
abstract = {Networks of workstations (NOW) are receiving increased attention as a viable platform for high performance parallel computations. Heterogeneity and time-sharing are two characteristics that distinguish the NOW systems from conventional multiprocessor/multicomputer systems which are homogeneous and dedicated. It is important to have a practical model for users to predict the execution times of large-scale parallel applications on nondedicated heterogeneous NOW. Another objective of this study is to provide insight into the dynamic performance of parallel computing and into the effects of program structures and system factors on such a platform. In this paper, we study performance predictions for parallel computing on nondedicated heterogeneous networks of workstations. Our approach is based on a two-level model. On the top level, a semideterministic task graph is used to capture the parallel execution behavior including the variances of communication and synchronization. On the bottom level, a discrete time model is used to quantify effects from NOW systems. An iterative process is used to determine the interactive effects between network contention and task execution. We validate the prediction model using experiments on a nondedicated heterogeneous NOW. The maximum differences between predicted results and measured results were less than 10% in most cases and 15% in the worst cases.},
journal = {J. Parallel Distrib. Comput.},
month = oct,
pages = {63–80},
numpages = {18}
}

@inproceedings{10.1007/978-3-030-57675-2_33,
author = {Ahmad, Najeeb and Yilmaz, Buse and Unat, Didem},
title = {A Prediction Framework for Fast Sparse Triangular Solves},
year = {2020},
isbn = {978-3-030-57674-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-57675-2_33},
doi = {10.1007/978-3-030-57675-2_33},
abstract = {Sparse triangular solve (SpTRSV) is an important linear algebra kernel, finding extensive uses in numerical and scientific computing. The parallel implementation of SpTRSV is a challenging task due to the sequential nature of the steps involved. This makes it, in many cases, one of the most time-consuming operations in an application. Many approaches for efficient SpTRSV on CPU and GPU systems have been proposed in the literature. However, no single implementation or platform (CPU or GPU) gives the fastest solution for all input sparse matrices. In this work, we propose a machine learning-based framework to predict the SpTRSV implementation giving the fastest execution time for a given sparse matrix based on its structural features. The framework is tested with six SpTRSV implementations on a state-of-the-art CPU-GPU machine (Intel Xeon Gold CPU, NVIDIA V100 GPU). Experimental results, with 998 matrices taken from the SuiteSparse Matrix Collection, show the classifier prediction accuracy of 87% for the fastest SpTRSV algorithm for a given input matrix. Predicted SpTRSV implementations achieve average speedups (harmonic mean) in the range of 1.4–2.7 against the six SpTRSV implementations used in the evaluation.},
booktitle = {Euro-Par 2020: Parallel Processing: 26th International Conference on Parallel and Distributed Computing, Warsaw, Poland, August 24–28, 2020, Proceedings},
pages = {529–545},
numpages = {17},
keywords = {Performance prediction, Sparse triangular solve, Heterogeneous systems, Performance autotuning},
location = {Warsaw, Poland}
}

@inproceedings{10.1145/3267183.3267187,
author = {Lima, Crescencio and Assun\c{c}\~{a}o, Wesley K. G. and Martinez, Jabier and do Carmo Machado, Ivan and von Flach G. Chavez, Christina and Mendon\c{c}a, Willian D. F.},
title = {Towards an Automated Product Line Architecture Recovery: The Apo-Games Case Study},
year = {2018},
isbn = {9781450365543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267183.3267187},
doi = {10.1145/3267183.3267187},
abstract = {Software Product Line Engineering (SPLE) has been widely adopted for applying systematic reuse in families of systems. Given the high upfront investment required for SPLE adoption, organizations commonly start with more opportunistic reuse approaches (e.g., a single system that they clone and modify). However, maintenance problems appear when managing a large number of similar systems where each of them implements and evolves particular characteristics. One viable solution to solve this issue is to migrate to SPLs using an extractive approach. This initiative, in its early phases, includes the definition of a Product Line Architecture (PLA) supporting the variants derivation and also allowing the customization according to customers' needs. Our objective is to provide automatic support in PLA recovery to reduce the time and effort in this process. One of the main issues in the extractive approach is the explosion of the variability in the PLA representation. Our approach is based on identifying the minimum subset of cross-product architectural information for an effective PLA recovery. To evaluate our approach, we applied it in the case of the Apo-Games projects. The experimentation in this real family of systems showed that our automatic approach is able to identify variant outliers and help domain experts to take informed decisions to support PLA recovery.},
booktitle = {Proceedings of the VII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {33–42},
numpages = {10},
keywords = {Variability, Software Product Lines, Product Line Architecture Recovery, Product Line Architecture},
location = {Sao Carlos, Brazil},
series = {SBCARS '18}
}

@inproceedings{10.1145/3494885.3494916,
author = {Aruna, P. and Priya, N.},
title = {Analysis of Machine Learning techniques for Predicting Student Success in an Educational Institution},
year = {2021},
isbn = {9781450390675},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494885.3494916},
doi = {10.1145/3494885.3494916},
abstract = {The student success is one of the essential components to assess the quality of the educational institutions. Monitoring student performance is of no use unless or otherwise it is done from the early stage. This research work will definitely consider two factors in mind about student success, firstly, Academic success. Secondly, Placement success. The goal of the proposed system is to predict the student's success using machine learning techniques and give feedback to the educational institutions. In this work , discussion of factors which affect the prediction, finding out the data sources and discussion about the various techniques used in prediction have been done.},
booktitle = {Proceedings of the 4th International Conference on Computer Science and Software Engineering},
pages = {168–173},
numpages = {6},
keywords = {Success Factors, Student Success, Performance Prediction, Machine Learning Algorithms},
location = {Singapore, Singapore},
series = {CSSE '21}
}

@article{10.4018/IJSWIS.2018010101,
author = {Li, Yuan-Fang and Pan, Jeff Z. and Bobed, Carlos and Guclu, Isa and Bobillo, Fernando and Kollingbaum, Martin J. and Mena, Eduardo},
title = {Predicting Reasoner Performance on ABox Intensive OWL 2 EL Ontologies},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {14},
number = {1},
issn = {1552-6283},
url = {https://doi.org/10.4018/IJSWIS.2018010101},
doi = {10.4018/IJSWIS.2018010101},
abstract = {In this article, the authors introduce the notion of ABox intensity in the context of predicting reasoner performance to improve the representativeness of ontology metrics, and they develop new metrics that focus on ABox features of OWL 2 EL ontologies. Their experiments show that taking into account the intensity through the proposed metrics contributes to overall prediction accuracy for ABox intensive ontologies.},
journal = {Int. J. Semant. Web Inf. Syst.},
month = jan,
pages = {1–30},
numpages = {30},
keywords = {Semantic Web, Performance Prediction, Ontology, Machine Learning, ABox Reasoning}
}

@inproceedings{10.1145/3375462.3375521,
author = {Wei, Huan and Li, Haotian and Xia, Meng and Wang, Yong and Qu, Huamin},
title = {Predicting student performance in interactive online question pools using mouse interaction features},
year = {2020},
isbn = {9781450377126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375462.3375521},
doi = {10.1145/3375462.3375521},
abstract = {Modeling student learning and further predicting the performance is a well-established task in online learning and is crucial to personalized education by recommending different learning resources to different students based on their needs. Interactive online question pools (e.g., educational game platforms), an important component of online education, have become increasingly popular in recent years. However, most existing work on student performance prediction targets at online learning platforms with a well-structured curriculum, predefined question order and accurate knowledge tags provided by domain experts. It remains unclear how to conduct student performance prediction in interactive online question pools without such well-organized question orders or knowledge tags by experts. In this paper, we propose a novel approach to boost student performance prediction in interactive online question pools by further considering student interaction features and the similarity between questions. Specifically, we introduce new features (e.g., think time, first attempt, and first drag-and-drop) based on student mouse movement trajectories to delineate students' problem-solving details. In addition, heterogeneous information network is applied to integrating students' historical problem-solving information on similar questions, enhancing student performance predictions on a new question. We evaluate the proposed approach on the dataset from a real-world interactive question pool using four typical machine learning models. The result shows that our approach can achieve a much higher accuracy for student performance prediction in interactive online question pools than the traditional way of only using the statistical features (e.g., students' historical question scores) in various models. We further discuss the performance consistency of our approach across different prediction models and question classes, as well as the importance of the proposed interaction features in detail.},
booktitle = {Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge},
pages = {645–654},
numpages = {10},
keywords = {student performance prediction, question pool, mouse movement trajectory, heterogeneous information network},
location = {Frankfurt, Germany},
series = {LAK '20}
}

@article{10.1007/s10639-021-10512-4,
author = {El Aouifi, Houssam and El Hajji, Mohamed and Es-Saady, Youssef and Douzi, Hassan},
title = {Predicting learner’s performance through video sequences viewing behavior analysis using educational data-mining},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1360-2357},
url = {https://doi.org/10.1007/s10639-021-10512-4},
doi = {10.1007/s10639-021-10512-4},
abstract = {This paper analyzes how learners interact with the pedagogical sequences of educational videos, and its effect on their performance. In this study, the suggested video courses are segmented on several pedagogical sequences. In fact, we’re not focusing on the type of clicks made by learners, but we’re concentrating on the pedagogical sequences in which those clicks were made. We focalize on the interpretation of the path followed by a learner watching an educational video, and the way they navigate the pedagogical sequences of that video, in order to predict whether a learner can pass or fail the video course. Learner’s video clicks are collected and classified. We applied educational data mining technique using K-nearest Neighbours and Multilayer Perceptron algorithms to predict learner’s performance. The classification results are acceptable, the kNN classifier achieves the best results with an average accuracy of 65.07%. The experimental result indicates that learners’ performance could be predicted, we notice a correlation between video sequence viewing behavior and learning performances. This method may help instructors understand the way learners watch educational videos. It can be used for early detection of learners’ video viewing behavior deviation and allow the instructor to provide well-timed, effective guidance.},
journal = {Education and Information Technologies},
month = sep,
pages = {5799–5814},
numpages = {16},
keywords = {Educational video, Video viewing behavior, Pedagogical sequences, Performance prediction, Educational data mining}
}

@inproceedings{10.1145/3464971.3468420,
author = {Orton, Indigo and Mycroft, Alan},
title = {Refactoring traces to identify concurrency improvements},
year = {2021},
isbn = {9781450385435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3464971.3468420},
doi = {10.1145/3464971.3468420},
abstract = {It is often difficult to analyse why a program executes more slowly than intended. This is particularly true for concurrent programs. We describe and evaluate a system, Rehype, which takes Java programs, performs low-overhead tracing of method calls, analyses the resulting trace-logs to detect inefficient uses of concurrency constructs, and suggests source-code-oriented improvements. Rehype deals with task-based concurrency, specifically a future-based model of tasks. Implementing the suggested improvements on an industrial API server more than doubled request-processing throughput.},
booktitle = {Proceedings of the 23rd ACM International Workshop on Formal Techniques for Java-like Programs},
pages = {16–23},
numpages = {8},
keywords = {Trace refactoring, Task-based concurrency, Performance prediction, Concurrent improvements},
location = {Virtual, Denmark},
series = {FTfJP '21}
}

@article{10.1016/j.jss.2014.10.037,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Galindo, Jos\'{e} A. and Parejo, Jos\'{e} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
title = {An assessment of search-based techniques for reverse engineering feature models},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {103},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.10.037},
doi = {10.1016/j.jss.2014.10.037},
abstract = {HighlightsSearch based techniques perform well for reverse engineering feature models.Different algorithms and objectives favour precision and recall differently.The F1 objective function provides a trade-off between precision and recall. Successful software evolves from a single system by adding and changing functionality to keep up with users' demands and to cater to their similar and different requirements. Nowadays it is a common practice to offer a system in many variants such as community, professional, or academic editions. Each variant provides different functionality described in terms of features. Software Product Line Engineering (SPLE) is an effective software development paradigm for this scenario. At the core of SPLE is variability modelling whose goal is to represent the combinations of features that distinguish the system variants using feature models, the de facto standard for such task. As SPLE practices are becoming more pervasive, reverse engineering feature models from the feature descriptions of each individual variant has become an active research subject. In this paper we evaluated, for this reverse engineering task, three standard search based techniques (evolutionary algorithms, hill climbing, and random search) with two objective functions on 74 SPLs. We compared their performance using precision and recall, and found a clear trade-off between these two metrics which we further reified into a third objective function based on Fβ, an information retrieval measure, that showed a clear performance improvement. We believe that this work sheds light on the great potential of search-based techniques for SPLE tasks.},
journal = {J. Syst. Softw.},
month = may,
pages = {353–369},
numpages = {17},
keywords = {Search Based Software Engineering, Reverse engineering, Feature model}
}

@phdthesis{10.5555/AAI28544034,
author = {Khoshmanesh, Seyedehzahra and Samik, Basu, and Andrew, Miner, and Hridesh, Rajan, and Karin, Dorman,},
advisor = {R, Lutz, Robyn},
title = {Learning Feature Interactions with and without Specifications},
year = {2021},
isbn = {9798544278207},
publisher = {Iowa State University},
address = {USA},
abstract = {Developers of software product lines and highly configurable systems reuse and combine features (units of functionality) to build new or customize existing products. However, features can interact in ways that are contrary to developers' intent. Predicting whether a new combination of features will produce an unwanted or even hazardous feature interaction is a continuing challenge. Current techniques to detect unwanted feature interactions are costly, slow, and inadequate. In this thesis, we investigate how to detect unwanted feature interactions early in development and that are scalable to large software product lines or highly configurable systems. First, we propose a similarity-based method to identify unwanted feature interactions much earlier in the development process for early detection. It uses knowledge of prior feature interactions stored with the software product line's feature model to help find unwanted interactions between a new feature and existing features. Results show that the approach performs well, with 83% accuracy and 60% to 100% coverage of feature interactions in experiments, and scales to a large number of features.Moreover, to learn and automate the detection, we show how detecting unwanted feature interactions can be effectively represented as a link prediction problem. We investigate six link-based similarity metrics and evaluate our approach on a software product line benchmark. Results show that the best machine learning algorithms achieve an accuracy of 0.75 to 1 for classifying feature interactions.Finally, we develop a new approach based on program analysis that extracts feature-relevant learning models from the source code to obtain more semantic details of unwanted feature interactions. The method is capable of learning feature interactions whether constraints on feature combinations are specified or not. If specifications of feature constraints are unavailable, as is common in real-world systems, our approach infers the constraints using feature-related data-flow dependency information. Experimental evaluation on three software product line benchmarks and a highly configurable system shows that this approach is fast and effective.The contribution is to support developers by automatically detecting those feature combinations in a new product or version that can interact in unwanted or unrecognized ways. This enables a better understanding of hidden interactions and identifies software components that should be tested together because their features interact in some configurations.},
note = {AAI28544034}
}

@article{10.1007/s10916-019-1295-4,
author = {Francis, Bindhia K. and Babu, Suvanam Sasidhar},
title = {Predicting Academic Performance of Students Using a Hybrid Data Mining Approach},
year = {2019},
issue_date = {Jun 2019},
publisher = {Plenum Press},
address = {USA},
volume = {43},
number = {6},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-019-1295-4},
doi = {10.1007/s10916-019-1295-4},
abstract = {Data mining offers strong techniques for different sectors involving education. In the education field the research is developing rapidly increasing due to huge number of student's information which can be used to invent valuable pattern pertaining learning behavior of students. The institutions of education can utilize educational data mining to examine the performance of students which can support the institution in recognizing the student's performance. In data mining classification is a familiar technique that has been implemented widely to find the performance of students. In this study a new prediction algorithm for evaluating student's performance in academia has been developed based on both classification and clustering techniques and been ested on a real time basis with student dataset of various academic disciplines of higher educational institutions in Kerala, India. The result proves that the hybrid algorithm combining clustering and classification approaches yields results that are far superior in terms of achieving accuracy in prediction of academic performance of the students.},
journal = {J. Med. Syst.},
month = jun,
pages = {1–15},
numpages = {15},
keywords = {Student academic performance, Prediction accuracy, K-means clustering, Educational data mining}
}

@inproceedings{10.1145/3368089.3409721,
author = {Liu, Liu and Isaacman, Sibren and Kremer, Ulrich},
title = {Global cost/quality management across multiple applications},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409721},
doi = {10.1145/3368089.3409721},
abstract = {Approximation is a technique that optimizes the balance between application outcome quality and its resource usage. Trading quality for performance has been investigated for single application scenarios, but not for environments where multiple approximate applications may run concurrently on the same machine, interfering with each other by sharing machine resources. Applying existing, single application techniques to this multi-programming environment may lead to configuration space size explosion, or result in poor overall application quality outcomes.  Our new RAPID-M system is the first cross-application con-figuration management framework. It reduces the problem size by clustering configurations of individual applications into local"similarity buckets". The global cross-applications configuration selection is based on these local bucket spaces. RAPID-M dynamically assigns buckets to applications such that overall quality is maximized while respecting individual application cost budgets.Once assigned a bucket, reconfigurations within buckets may be performed locally with minimal impact on global selections. Experimental results using six configurable applications show that even large configuration spaces of complex applications can be clustered into a small number of buckets, resulting in search space size reductions of up to 9 orders of magnitude for our six applications. RAPID-M constructs performance cost models with an average prediction error of ≤3%. For our application execution traces, RAPID-M dynamically selects configurations that lower the budget violation rate by 33.9% with an average budget exceeding rate of 6.6% as compared to other possible approaches. RAPID-M successfully finishes 22.75% more executions which translates to a 1.52X global output quality increase under high system loads. Theo verhead ofRAPID-Mis within≤1% of application execution times.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {350–361},
numpages = {12},
keywords = {Performance Prediction, Multi-Programming, Global Configuration Management, Approximate Computing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1007/978-3-030-52240-7_55,
author = {Ahuja, Rohan and Khan, Daniyal and Tahir, Sara and Wang, Magdalene and Symonette, Danilo and Pan, Shimei and Stacey, Simon and Engel, Don},
title = {Machine Learning and Student Performance in Teams},
year = {2020},
isbn = {978-3-030-52239-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-52240-7_55},
doi = {10.1007/978-3-030-52240-7_55},
abstract = {This project applies a variety of machine learning algorithms to the interactions of first year college students using the GroupMe messaging platform to collaborate online on a team project. The project assesses the efficacy of these techniques in predicting existing measures of team member performance, generated by self- and peer assessment through the Comprehensive Assessment of Team Member Effectiveness (CATME) tool. We employed a wide range of machine learning classifiers (SVM, KNN, Random Forests, Logistic Regression, Bernoulli Naive Bayes) and a range of features (generated by a socio-linguistic text analysis program, Doc2Vec, and TF-IDF) to predict individual team member performance. Our results suggest machine learning models hold out the possibility of providing accurate, real-time information about team and team member behaviors that instructors can use to support students engaged in team-based work, though challenges remain.},
booktitle = {Artificial Intelligence in Education: 21st International Conference, AIED 2020, Ifrane, Morocco, July 6–10, 2020, Proceedings, Part II},
pages = {301–305},
numpages = {5},
keywords = {Text mining, Performance prediction, Teamwork, Machine learning},
location = {Ifrane, Morocco}
}

@article{10.1016/j.asoc.2021.107355,
author = {Giannakas, F. and Troussas, C. and Voyiatzis, I. and Sgouropoulou, C.},
title = {A deep learning classification framework for early prediction of team-based academic performance},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107355},
doi = {10.1016/j.asoc.2021.107355},
journal = {Appl. Soft Comput.},
month = jul,
numpages = {17},
keywords = {Computer-assisted learning, Machine learning, Collaboration, Team performance prediction, Deep neural network}
}

@article{10.1016/j.jpdc.2019.02.005,
author = {Lee, Seyong and Gounley, John and Randles, Amanda and Vetter, Jeffrey S.},
title = {Performance portability study for massively parallel computational fluid dynamics application on scalable heterogeneous architectures},
year = {2019},
issue_date = {Jul 2019},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {129},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2019.02.005},
doi = {10.1016/j.jpdc.2019.02.005},
journal = {J. Parallel Distrib. Comput.},
month = jul,
pages = {1–13},
numpages = {13},
keywords = {Performance prediction, Heterogeneous architectures, OpenACC, Performance portability, Computational fluid dynamics, Patient-specific hemodynamics, Lattice Boltzmann method}
}

@inproceedings{10.1145/3302333.3302346,
author = {Gomes, Karine and Teixeira, Leopoldo and Alves, Thayonara and Ribeiro, M\'{a}rcio and Gheyi, Rohit},
title = {Characterizing safe and partially safe evolution scenarios in product lines: An Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302346},
doi = {10.1145/3302333.3302346},
abstract = {Evolving software product lines is often error-prone. Previous works have proposed classifying product line evolution into safe or partially safe, depending on the number of products that have their behavior preserved after evolution. Based on these notions, it is possible to derive transformation templates that abstract common evolution scenarios, such as adding an optional feature. However, existing works are focused on evaluating either safe or partially safe templates. Hence, in this work we aim to characterize product line evolution as a whole, measuring to what extent the evolution history is safe compared to partially safe, to better understand how product lines evolve. We measure how often existing templates happen using 2,300 commits from an open-source product line. According to our study, 91.7% of the commits represent partially safe evolution scenarios. Our results also show that 1,800 of these commits can automatically be classified as instances of existing templates. Among these, commits that do not modify other variability-aware models, are the most frequent, accounting for 72.3% out of the total of commits. For the remaining 500 commits, we identify that 24.4% are related to changes in the configuration knowledge, that is, the file responsible for the mapping between features and code.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {9},
keywords = {Software Product Lines, Safe Evolution, Product Line Evolution, Partially Safe Evolution, Empirical Study, Configurable Systems},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1145/3126908.3126967,
author = {Jain, Nikhil and Bhatele, Abhinav and Howell, Louis H. and B\"{o}hme, David and Karlin, Ian and Le\'{o}n, Edgar A. and Mubarak, Misbah and Wolfe, Noah and Gamblin, Todd and Leininger, Matthew L.},
title = {Predicting the performance impact of different fat-tree configurations},
year = {2017},
isbn = {9781450351140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126908.3126967},
doi = {10.1145/3126908.3126967},
abstract = {The fat-tree topology is one of the most commonly used network topologies in HPC systems. Vendors support several options that can be configured when deploying fat-tree networks on production systems, such as link bandwidth, number of rails, number of planes, and tapering. This paper showcases the use of simulations to compare the impact of these design options on representative production HPC applications, libraries, and multi-job workloads. We present advances in the TraceR-CODES simulation framework that enable this analysis and evaluate its prediction accuracy against experiments on a production fat-tree network. In order to understand the impact of different network configurations on various anticipated scenarios, we study workloads with different communication patterns, computation-to-communication ratios, and scaling characteristics. Using multi-job workloads, we also study the impact of inter-job interference on performance and compare the cost-performance tradeoffs.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {50},
numpages = {13},
keywords = {procurement, performance prediction, network simulation, fat-tree topology},
location = {Denver, Colorado},
series = {SC '17}
}

@inproceedings{10.1145/3331184.3331334,
author = {Roitman, Haggai},
title = {Normalized Query Commitment Revisited},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331334},
doi = {10.1145/3331184.3331334},
abstract = {We revisit the Normalized Query Commitment (NQC) query performance prediction (QPP) method. To this end, we suggest a scaled extension to a discriminative QPP framework and use it to analyze NQC. Using this analysis allows us to redesign NQC and suggest several options for improvement.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1085–1088},
numpages = {4},
keywords = {weighted product model (WPM), query performance prediction, normalized query commitment (NQC)},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/2430502.2430513,
author = {Berger, Thorsten and Rublack, Ralf and Nair, Divya and Atlee, Joanne M. and Becker, Martin and Czarnecki, Krzysztof and W\k{a}sowski, Andrzej},
title = {A survey of variability modeling in industrial practice},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430513},
doi = {10.1145/2430502.2430513},
abstract = {Over more than two decades, numerous variability modeling techniques have been introduced in academia and industry. However, little is known about the actual use of these techniques. While dozens of experience reports on software product line engineering exist, only very few focus on variability modeling. This lack of empirical data threatens the validity of existing techniques, and hinders their improvement. As part of our effort to improve empirical understanding of variability modeling, we present the results of a survey questionnaire distributed to industrial practitioners. These results provide insights into application scenarios and perceived benefits of variability modeling, the notations and tools used, the scale of industrial models, and experienced challenges and mitigation strategies.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {7},
numpages = {8},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1145/2950290.2950311,
author = {Nguyen, ThanhVu and Koc, Ugur and Cheng, Javran and Foster, Jeffrey S. and Porter, Adam A.},
title = {iGen: dynamic interaction inference for configurable software},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950311},
doi = {10.1145/2950290.2950311},
abstract = {To develop, analyze, and evolve today's highly configurable software systems, developers need deep knowledge of a system's configuration options, e.g., how options need to be set to reach certain locations, what configurations to use for testing, etc. Today, acquiring this detailed information requires manual effort that is difficult, expensive, and error prone. In this paper, we propose iGen, a novel, lightweight dynamic analysis technique that automatically discovers a program's interactions---expressive logical formulae that give developers rich and detailed information about how a system's configuration option settings map to particular code coverage. iGen employs an iterative algorithm that runs a system under a small set of configurations, capturing coverage data; processes the coverage data to infer potential interactions; and then generates new configurations to further refine interactions in the next iteration. We evaluated iGen on 29 programs spanning five languages; the breadth of this study would be unachievable using prior interaction inference tools. Our results show that iGen finds precise interactions based on a very small fraction of the number of possible configurations. Moreover, iGen's results confirm several earlier hypotheses about typical interaction distributions and structures.},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {655–665},
numpages = {11},
keywords = {software testing, dynamic analysis, configurable systems, Program analysis},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1007/978-3-030-63882-5_13,
author = {Teixeira, Leopoldo and Gheyi, Rohit and Borba, Paulo},
title = {Safe Evolution of Product Lines Using Configuration Knowledge Laws},
year = {2020},
isbn = {978-3-030-63881-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63882-5_13},
doi = {10.1007/978-3-030-63882-5_13},
abstract = {When evolving a software product line, it is often important to ensure that we do it in a safe way, ensuring that the resulting product line remains well-formed and that the behavior of existing products is not affected. To ensure this, one usually has to analyze the different artifacts that constitute a product line, like feature models, configuration knowledge and assets. Manually analyzing these artifacts can be time-consuming and error prone, since a product line might consist of thousands of products. Existing works show that a non-negligible number of changes performed in commits deal only with the configuration knowledge, that is, the mapping between features and assets. This way, in this paper, we propose a set of algebraic laws, which correspond to bi-directional transformations for configuration knowledge models, that we can use to justify safe evolution of product lines, when only the configuration knowledge model changes. Using a theorem prover, we proved all laws sound with respect to a formal semantics. We also present a case study, where we use these laws to justify safe evolution scenarios of a non trivial industrial software product line.},
booktitle = {Formal Methods: Foundations and Applications: 23rd Brazilian Symposium, SBMF 2020, Ouro Preto, Brazil, November 25–27, 2020, Proceedings},
pages = {210–227},
numpages = {18},
keywords = {Theorem proving, Software product lines, Safe evolution},
location = {Ouro Preto, Brazil}
}

@inproceedings{10.1145/2851553.2858665,
author = {Chahal, Dheeraj and Virk, Rupinder and Nambiar, Manoj},
title = {Performance Extrapolation of IO Intensive Workloads: Work in Progress},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851553.2858665},
doi = {10.1145/2851553.2858665},
abstract = {Performance prediction of an application before migrating from a source system and deploying on the target system is a challenging but important task. In this paper, we present a method for predicting the performance of an IO intensive multithreaded enterprise application workload on target systems connected to advanced storage devices. Our approach is an extension of well-known trace and replay method. We extract traces of IO intensive enterprise workloads representing temporal and spatial characteristics (e.g. read and write requests) on the source system where application is currently deployed. These traces are replayed on the system of interest called target system. The experimental results presented demonstrate the effectiveness and accuracy of this method.},
booktitle = {Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
pages = {105–108},
numpages = {4},
keywords = {performance prediction, extrapolation, IO traces},
location = {Delft, The Netherlands},
series = {ICPE '16}
}

@inproceedings{10.1145/3383313.3412264,
author = {Penha, Gustavo and Santos, Rodrygo L. T.},
title = {Exploiting Performance Estimates for Augmenting Recommendation Ensembles},
year = {2020},
isbn = {9781450375832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383313.3412264},
doi = {10.1145/3383313.3412264},
abstract = {Ensembling multiple recommender systems via stacking has shown to be effective at improving collaborative recommendation. Recent work extends stacking to use additional user performance predictors (e.g., the total number of ratings made by the user) to help determine how much each base recommender should contribute to the ensemble. Nonetheless, despite the cost of handcrafting discriminative predictors, which typically requires deep knowledge of the strengths and weaknesses of each recommender in the ensemble, only minor improvements have been observed. To overcome this limitation, instead of engineering complex features to predict the performance of different recommenders for a given user, we propose to directly estimate these performances by leveraging the user’s own historical ratings. Experiments on real-world datasets from multiple domains demonstrate that using performance estimates as additional features can significantly improve the accuracy of state-of-the-art ensemblers, achieving nDCG@20 improvements by an average of 23% over not using them.},
booktitle = {Proceedings of the 14th ACM Conference on Recommender Systems},
pages = {111–119},
numpages = {9},
keywords = {Recommender Systems, Performance Prediction, Performance Estimation, Learning to Rank, Ensembling},
location = {Virtual Event, Brazil},
series = {RecSys '20}
}

@article{10.1007/s10664-020-09884-x,
author = {Fischer, Stefan and Michelon, Gabriela Karoline and Ramler, Rudolf and Linsbauer, Lukas and Egyed, Alexander},
title = {Automated test reuse for highly configurable software},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09884-x},
doi = {10.1007/s10664-020-09884-x},
abstract = {Dealing with highly configurable systems is generally very complex. Researchers and practitioners have conceived hundreds of different analysis techniques to deal with different aspects of configurable systems. One large focal point is the testing of configurable software. This is challenging due to the large number of possible configurations. Moreover, tests themselves are rarely configurable and instead built for specific configurations. However, existing tests need to be adapted to run on a different configuration. In this paper, we report on an experiment about automatically reusing existing tests in configurable systems. We used manually developed tests for specific configurations of three configurable systems and investigated how changing the configuration affects the tests. Subsequently, we employed an approach for automated reuse to generate new test variants (by reusing from existing ones) for combinations of previous configurations and compared their results to the ones from existing tests. Our results showed that we could directly reuse some tests for different configurations. Nonetheless, our automatically generated test variants generally yielded better results. Our generated tests had a higher or equal success rate to the existing tests in most cases. Even in the cases the success rate was equal, our generated tests generally had higher code coverage.},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5295–5332},
numpages = {38},
keywords = {Testing, Reuse, Clone-and-own, Configurable software, Variability}
}

@article{10.1016/j.dss.2019.113191,
author = {Park, Gyunam and Song, Minseok},
title = {Predicting performances in business processes using deep neural networks},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {129},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2019.113191},
doi = {10.1016/j.dss.2019.113191},
journal = {Decis. Support Syst.},
month = feb,
numpages = {11},
keywords = {Deep neural networks, Process performance prediction, Online operational support, Process management, Process mining}
}

@article{10.1016/j.infsof.2014.04.002,
author = {Machado, Ivan Do Carmo and Mcgregor, John D. and Cavalcanti, Yguarat\~{a} Cerqueira and De Almeida, Eduardo Santana},
title = {On strategies for testing software product lines: A systematic literature review},
year = {2014},
issue_date = {October, 2014},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {56},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2014.04.002},
doi = {10.1016/j.infsof.2014.04.002},
abstract = {Context: Testing plays an important role in the quality assurance process for software product line engineering. There are many opportunities for economies of scope and scale in the testing activities, but techniques that can take advantage of these opportunities are still needed. Objective: The objective of this study is to identify testing strategies that have the potential to achieve these economies, and to provide a synthesis of available research on SPL testing strategies, to be applied towards reaching higher defect detection rates and reduced quality assurance effort. Method: We performed a literature review of two hundred seventy-six studies published from the year 1998 up to the 1st semester of 2013. We used several filters to focus the review on the most relevant studies and we give detailed analyses of the core set of studies. Results: The analysis of the reported strategies comprised two fundamental aspects for software product line testing: the selection of products for testing, and the actual test of products. Our findings indicate that the literature offers a large number of techniques to cope with such aspects. However, there is a lack of reports on realistic industrial experiences, which limits the inferences that can be drawn. Conclusion: This study showed a number of leveraged strategies that can support both the selection of products, and the actual testing of products. Future research should also benefit from the problems and advantages identified in this study.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1183–1199},
numpages = {17},
keywords = {Systematic literature review, Software testing, Software quality, Software product lines}
}

@inproceedings{10.1145/2556624.2556642,
author = {Heuer, Andr\'{e} and Pohl, Klaus},
title = {Structuring variability in the context of embedded systems during software engineering},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556642},
doi = {10.1145/2556624.2556642},
abstract = {During the development of embedded software, the system context (mechanical, electronical, business, etc.) has to be considered. Typically, this context is diverse and highly complex. Moreover, the context in which the system is embedded can vary. For example, the system can be used in different technical environments or in different countries. This variability in the context influences the software to be developed and typically leads to system variability. This paper systematically analyses the impact of context variability on the system development, more precisely, on the variability of the system. Related work is discussed and an example from the automotive domain is presented to identify open issues that need to be addressed.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {21},
numpages = {8},
keywords = {requirements engineering, context variability, context in product line engineering},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1145/3284127,
author = {Wang, Yu and Lee, Victor and Wei, Gu-Yeon and Brooks, David},
title = {Predicting New Workload or CPU Performance by Analyzing Public Datasets},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3284127},
doi = {10.1145/3284127},
abstract = {The marketplace for general-purpose microprocessors offers hundreds of functionally similar models, differing by traits like frequency, core count, cache size, memory bandwidth, and power consumption. Their performance depends not only on microarchitecture, but also on the nature of the workloads being executed. Given a set of intended workloads, the consumer needs both performance and price information to make rational buying decisions. Many benchmark suites have been developed to measure processor performance, and their results for large collections of CPUs are often publicly available. However, repositories of benchmark results are not always helpful when consumers need performance data for new processors or new workloads. Moreover, the aggregate scores for benchmark suites designed to cover a broad spectrum of workload types can be misleading. To address these problems, we have developed a deep neural network (DNN) model, and we have used it to learn the relationship between the specifications of Intel CPUs and their performance on the SPEC CPU2006 and Geekbench 3 benchmark suites. We show that we can generate useful predictions for new processors and new workloads. We also cross-predict the two benchmark suites and compare their performance scores. The results quantify the self-similarity of these suites for the first time in the literature. This work should discourage consumers from basing purchasing decisions exclusively on Geekbench 3, and it should encourage academics to evaluate research using more diverse workloads than the SPEC CPU suites alone.},
journal = {ACM Trans. Archit. Code Optim.},
month = jan,
articleno = {53},
numpages = {21},
keywords = {performance comparison, data mining, benchmarking, Performance prediction}
}

@inproceedings{10.1007/978-3-030-32047-8_26,
author = {Khoshmanesh, Seyedehzahra and Lutz, Robyn R.},
title = {Leveraging Feature Similarity for Earlier Detection of Unwanted Feature Interactions in Evolving Software Product Lines},
year = {2019},
isbn = {978-3-030-32046-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32047-8_26},
doi = {10.1007/978-3-030-32047-8_26},
abstract = {Software product lines enable reuse of shared software across a family of products. As new products are built in the product line, new features are added. The features are units of functionality that provide services to users. Unwanted feature interactions, wherein one feature interferes with another feature’s operation, is a significant problem, especially as large software product lines evolve. Detecting feature interactions is a time-consuming and difficult task for developers. Moreover, feature interactions are often only discovered during testing, at which point costly re-work is needed. This paper proposes a similarity-based method to identify unwanted feature interactions much earlier in the development process. It uses knowledge of prior feature interactions stored with the software product line’s feature model to help find unwanted interactions between a new feature and existing features. The paper describes the framework and algorithms used to detect the feature interactions using three path similarity measures and evaluates the approach on a real-world, evolving software product line. Results show that the approach performs well, with 83% accuracy and 60% to 100% coverage of feature interactions in experiments, and scales to a large number of features.},
booktitle = {Similarity Search and Applications: 12th International Conference, SISAP 2019, Newark, NJ, USA, October 2–4, 2019, Proceedings},
pages = {293–307},
numpages = {15},
keywords = {Feature interaction, Similarity measures, Software product lines},
location = {Newark, NJ, USA}
}

@article{10.1016/j.future.2018.06.032,
author = {Chao, Zemin and Shi, Shengfei and Gao, Hong and Luo, Jizhou and Wang, Hongzhi},
title = {A gray-box performance model for Apache Spark},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {89},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.06.032},
doi = {10.1016/j.future.2018.06.032},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {58–67},
numpages = {10},
keywords = {Machine learning, Performance prediction model, Apache Spark, Gray-box method}
}

@inproceedings{10.1145/3344341.3368821,
author = {Tariq, Hassan and Al-Sahaf, Harith and Welch, Ian},
title = {Modelling and Prediction of Resource Utilization of Hadoop Clusters: A Machine Learning Approach},
year = {2019},
isbn = {9781450368940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344341.3368821},
doi = {10.1145/3344341.3368821},
abstract = {Hadoop is a distributed computing framework that has a large number of configurable parameters. These parameters have impact on system resources and execution time. Optimizing the performance of a Hadoop cluster by tuning such a large number of parameters is a tedious task. Most current big data modeling approaches does not include complex interaction between configuration parameters and the cluster environment changes such as different datasets or query. This makes it difficult to predict the performance or resource utilization of a cluster when we use real-world datasets because of their size and content. This paper presents the modeling of resource utilization of Hadoop cluster on the basis of Hadoop configuration parameters and dataset structure. Our approach builds a machine learning based-model using Hive-based Hadoop query and then predict the outcome for a particular parameter setting and query type. We used decision trees to build models for each of our performance metric measures. Decision rules were extracted from these tree-based models and evaluated for their ability to generalize to unseen data. Our experiments predicted that the percentage of columns selected, mappers and replica has a statistically significant impact over the utilization of different resources in Hadoop cluster.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
pages = {93–100},
numpages = {8},
keywords = {performance prediction, decision trees, data modeling, big data},
location = {Auckland, New Zealand},
series = {UCC'19}
}

@article{10.1504/ijnvo.2020.108856,
author = {Xiao, Peng},
title = {An extensible and scalable cloud information monitoring middleware},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {23},
number = {2},
issn = {1470-9503},
url = {https://doi.org/10.1504/ijnvo.2020.108856},
doi = {10.1504/ijnvo.2020.108856},
abstract = {With the increasing complexity of cloud systems, how to efficiently manage cloud infrastructures has become a challenging task, while an effective monitoring service plays a crucial role to achieve this goal. In this paper, we present an extensible and scalable cloud monitoring middleware called extensible cloud monitoring service (ECMS), which is designed for offering online monitoring service to different monitoring requests from either cloud users or resource providers. In ECMS, a layered monitoring framework is introduced with aiming to cover different aspects of cloud monitoring requests. The implementation of ECMS is evaluated in a real-world cloud test-bed and the results indicate that it can efficiently provide online monitoring services to different kinds of clients and exhibits better scalability and robustness comparing with other monitoring systems.},
journal = {Int. J. Netw. Virtual Organ.},
month = jan,
pages = {97–111},
numpages = {14},
keywords = {data filter, performance prediction, resource allocation, monitoring service, cloud computing}
}

@inproceedings{10.1145/1835449.1835615,
author = {Balasubramanian, Niranjan and Kumaran, Giridhar and Carvalho, Vitor R.},
title = {Predicting query performance on the web},
year = {2010},
isbn = {9781450301534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835449.1835615},
doi = {10.1145/1835449.1835615},
abstract = {Predicting the performance of web queries is useful for several applications such as automatic query reformulation and automatic spell correction. In the web environment, accurate performance prediction is challenging because measures such as clarity that work well on homogeneous TREC-like collections, are not as effective and are often expensive to compute. We present Rank-time Performance Prediction (RAPP), an effective and efficient approach for online performance prediction on the web. RAPP uses retrieval scores, and aggregates of the rank-time features used by the document- ranking algorithm to train regressors for query performance prediction. On a set of over 12,000 queries sampled from the query logs of a major search engine, RAPP achieves a linear correlation of 0.78 with DCG@5, and 0.52 with NDCG@5. Analysis of prediction accuracy shows that hard queries are easier to identify while easy queries are harder to identify.},
booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {785–786},
numpages = {2},
keywords = {web search, query difficulty, performance prediction},
location = {Geneva, Switzerland},
series = {SIGIR '10}
}

@inproceedings{10.1145/3293320.3293321,
author = {Cardwell, David and Song, Fengguang},
title = {An Extended Roofline Model with Communication-Awareness for Distributed-Memory HPC Systems},
year = {2019},
isbn = {9781450366328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293320.3293321},
doi = {10.1145/3293320.3293321},
abstract = {Performance modeling of parallel applications on distributed memory systems is a challenging task due to the effects of CPU speed, memory access time, and communication cost. In this paper, we propose a simple and intuitive graphical model, which extends the widely used Roofline performance model to include the communication cost in addition to the memory access time and the peak CPU performance. This new performance model inherits the simplicity of the original Roofline model and enables performance evaluation on a third dimension of communication performance. Such a model will greatly facilitate and expedite the analysis, development and optimization of parallel programs on high-end computer systems. We empirically validate the extended new Roofline model usingfl oating-point-computation-bound, memory-bound, and communication-bound applications. Three distinct high-end computing platforms have been tested: 1) high performance computing (HPC) systems, 2) high throughput computing systems, and 3) cloud computing systems. Our experimental results with four different parallel applications show that the new model can approximately evaluate the performance of different programs on various distributed-memory systems. Furthermore, the extended new model is able to provide insight into how the problem size can affect the upper bound performance of parallel applications, which is a special property revealed by the new dimension of communication cost analysis.},
booktitle = {Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region},
pages = {26–35},
numpages = {10},
keywords = {visualization, performance prediction, Roofline model},
location = {Guangzhou, China},
series = {HPCAsia '19}
}

@article{10.1287/isre.2019.0876,
author = {Zhang, Jingjing and Adomavicius, Gediminas and Gupta, Alok and Ketter, Wolfgang},
title = {Consumption and Performance: Understanding Longitudinal Dynamics of Recommender Systems via an Agent-Based Simulation Framework},
year = {2020},
issue_date = {March 2020},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {31},
number = {1},
issn = {1526-5536},
url = {https://doi.org/10.1287/isre.2019.0876},
doi = {10.1287/isre.2019.0876},
abstract = {We develop a general-purpose agent-based simulation and modeling approach to analyze how user–recommender interactions affect recommender systems in the long run. Our explorations show that, over time, user–recommender interactions consistently lead to the longitudinal performance paradox of recommender systems. In particular, users’ reliance on recommendations, while helping users discover relevant items, actually hurts the future diversity of items that are recommended and consumed as well as slows down the system’s learning pace (i.e., the rate of predictive accuracy improvement). We also demonstrate unique benefits of certain hybrid consumption strategies—that is, that take advantage of both popularity- and personalization-based recommendations—in facilitating improvements in consumption relevance over time. Because users’ consumption strategies can significantly influence the longitudinal performance of recommender systems, it is important for designers to analyze the histories of a system’s recommendations and users’ choices to infer and understand users’ consumption strategies. This would enable the system to anticipate users’ consumption behavior and strategically adjust the system’s parameters according to its long-term performance objectives.We develop a general agent-based modeling and computational simulation approach to study the impact of various factors on the temporal dynamics of recommender systems’ performance. The proposed agent-based simulation approach allows for comprehensive analysis of longitudinal recommender systems performance under a variety of diverse conditions, which typically is not feasible with live real-world systems. We specifically focus on exploring the product consumption strategies and show that, over time, user–recommender interactions consistently lead to the longitudinal performance paradox of recommender systems. In particular, users’ reliance on the system’s recommendations to make item choices generally tends to make the recommender system less useful in the long run or, more specifically, negatively impacts the longitudinal dynamics of several important dimensions of recommendation performance. Furthermore, we explore the nuances of the performance paradox via additional explorations of longitudinal dynamics of recommender systems for a variety of user populations and consumption strategies, as well as personalized and nonpersonalized recommendation approaches. One interesting discovery from our exploration is that a certain hybrid consumption strategy—that is, where users rely on a combination of both personalized- and popularity-based recommendations, offers a unique ability to substantially improve consumption relevance over time. In other words, for such hybrid consumption settings, recommendation algorithms facilitate the general “quality-rises-to-the-top” phenomenon, which is not present in the pure popularity-based consumption. In addition to discussing a number of interesting performance patterns, the paper also analyzes and provides insights into the underlying factors that drive such patterns. Our findings have significant implications for the design and implementation of recommender systems.},
journal = {Info. Sys. Research},
month = mar,
pages = {76–101},
numpages = {26},
keywords = {consumption relevance, consumption diversity, prediction accuracy, consumption strategies, simulation, agent-based modeling, dynamics of recommender systems}
}

@inproceedings{10.1007/978-3-030-23204-7_3,
author = {Al-Luhaybi, Mashael and Yousefi, Leila and Swift, Stephen and Counsell, Steve and Tucker, Allan},
title = {Predicting Academic Performance: A Bootstrapping Approach for Learning Dynamic Bayesian Networks},
year = {2019},
isbn = {978-3-030-23203-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-23204-7_3},
doi = {10.1007/978-3-030-23204-7_3},
abstract = {Predicting academic performance requires utilization of student related data and the accurate identification of the key issues regarding such data can enhance the prediction process. In this paper, we proposed a bootstrapped resampling approach for predicting the academic performance of university students using probabilistic modeling taking into consideration the bias issue of educational datasets. We include in this investigation students’ data at admission level, Year 1 and Year 2, respectively. For the purpose of modeling academic performance, we first address the imbalanced time series of educational datasets with a resampling method using bootstrap aggregating (bagging). We then ascertain the Bayesian network structure from the resampled dataset to compare the efficiency of our proposed approach with the original data approach. Hence, one interesting outcome was that of learning and testing the Bayesian model from the bootstrapped time series data. The prediction results were improved dramatically, especially for the minority class, which was for identifying the high risk of failing students.},
booktitle = {Artificial Intelligence in Education: 20th International Conference, AIED 2019, Chicago, IL, USA, June 25-29, 2019, Proceedings, Part I},
pages = {26–36},
numpages = {11},
keywords = {Performance prediction, Bayesian networks, Resampling, Bootstrapping, EDM},
location = {Chicago, IL, USA}
}

@inproceedings{10.1145/3344948.3344958,
author = {Frank, Markus and Klinaku, Floriment and Hilbrich, Marcus and Becker, Steffen},
title = {Towards a parallel template catalogue for software performance predictions},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344958},
doi = {10.1145/3344948.3344958},
abstract = {Software Performance Engineers evaluate quality attributes (like response time) of software rich systems based on architectural models during early design time. Thereby, they use model-based approaches to analyze the software's behaviour and resource consumption. One prominent approach is the Palladio Component Model (PCM) which has been researched for over a decade. However, when it comes to multicore support or massive parallel execution the approaches still suffer from major drawbacks. Drawbacks include inaccurate prediction models, insufficient modelling languages, and missing tool support, to name just some of them.In this paper, we focus on overcoming the last two drawbacks, namely improving the modelling language and the tool support. We present a template catalogue for parallel performance patterns in software performance predictions. We use the example of a parallel-loop in the Palladio Component Model to exemplify our idea.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {18–21},
numpages = {4},
keywords = {software performance engineering, performance prediction, parallel template, parallel pattern, multicore},
location = {Paris, France},
series = {ECSA '19}
}

@article{10.1007/s10515-017-0225-2,
author = {Nair, Vivek and Menzies, Tim and Siegmund, Norbert and Apel, Sven},
title = {Faster discovery of faster system configurations with spectral learning},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-017-0225-2},
doi = {10.1007/s10515-017-0225-2},
abstract = {Despite the huge spread and economical importance of configurable software systems, there is unsatisfactory support in utilizing the full potential of these systems with respect to finding performance-optimal configurations. Prior work on predicting the performance of software configurations suffered from either (a) requiring far too many sample configurations or (b) large variances in their predictions. Both these problems can be avoided using the WHAT spectral learner. WHAT's innovation is the use of the spectrum (eigenvalues) of the distance matrix between the configurations of a configurable software system, to perform dimensionality reduction. Within that reduced configuration space, many closely associated configurations can be studied by executing only a few sample configurations. For the subject systems studied here, a few dozen samples yield accurate and stable predictors--less than 10% prediction error, with a standard deviation of less than 2%. When compared to the state of the art, WHAT (a) requires 2---10 times fewer samples to achieve similar prediction accuracies, and (b) its predictions are more stable (i.e., have lower standard deviation). Furthermore, we demonstrate that predictive models generated by WHAT can be used by optimizers to discover system configurations that closely approach the optimal performance.},
journal = {Automated Software Engg.},
month = jun,
pages = {247–277},
numpages = {31},
keywords = {Spectral learning, Search-based software engineering, Sampling, Performance prediction, Decision trees}
}

@article{10.1007/s10586-019-03011-2,
author = {Shafiabadi, Mohammad Hossein and Pedram, Hossein and Reshadi, Midia and Reza, Akram},
title = {Comprehensive regression-based model to predict performance of general-purpose graphics processing unit},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-03011-2},
doi = {10.1007/s10586-019-03011-2},
abstract = {Recently, the use of graphics processors has been significantly increased in fast and accurate scientific calculations. These processors provide a heterogeneous design space, and make designers capable of performing more accurate designs with higher efficiency. In this paper, a regression model is proposed to predict the performance of various applications on general-purpose graphics processors units. We present the main challenges for predicting the efficiency of graphics processing units (GPUs) based on simulation experiments. Also, we build the regression statistical inference from the result of the simulation, which predicts the efficiency of GPUs in various performances with approximately 7% of error of measurement. We have used AMD Southern Island and SDK 2.5, OpenCL which are both based on OpenCL. The first version of the design is built by very large design space, approximately about 17 billion points, from which 8000 points were randomly chosen, and the performance of graphic processors was calculated based on the results of the simulation. The model of non-linear regression is capable of predicting the performance of graphics process with the average error rate of 7%.},
journal = {Cluster Computing},
month = jun,
pages = {1505–1516},
numpages = {12},
keywords = {Validation, Performance prediction, Non-linear regression model, General-purpose graphics processors unit}
}

@inproceedings{10.1007/978-3-662-49224-6_22,
author = {Beek, Maurice H. and Gnesi, Stefania and Latella, Diego and Massink, Mieke},
title = {Towards Automatic Decision Support for Bike-Sharing System Design},
year = {2015},
isbn = {9783662492239},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-49224-6_22},
doi = {10.1007/978-3-662-49224-6_22},
abstract = {Public bike-sharing systems are a popular means of sustainable urban mobility, but their successful introduction in a city stands or falls with their specific designs. What kind of bikes and docking stations are needed, how many and where to install them? How to avoid as much as possible that stations are completely empty or full for some period? Hence, a bike-sharing system can be seen both as a highly reconfigurable system and as a collective adaptive system. In this paper, we present two complementary strategies for the evaluation of bike-sharing system designs by means of automated tool support. We use the Clafer toolset to perform multi-objective optimisation of attributed feature models known from software product line engineering and the recently developed mean field model checker FlyFast to assess performance and user satisfaction aspects of variants of large-scale bike-sharing systems. The combined use of these analysis approaches is a preliminary step in the direction of automatic decision support for the initial design of a bike-sharing system as well as its successive adaptations and reconfigurations that considers both qualitative and performance aspects.},
booktitle = {Revised Selected Papers of the SEFM 2015 Collocated Workshops on Software Engineering and Formal Methods - Volume 9509},
pages = {266–280},
numpages = {15}
}

@inproceedings{10.1145/3173574.3174019,
author = {Goguey, Alix and Casiez, G\'{e}ry and Cockburn, Andy and Gutwin, Carl},
title = {Storyboard-Based Empirical Modeling of Touch Interface Performance},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174019},
doi = {10.1145/3173574.3174019},
abstract = {Touch interactions are now ubiquitous, but few tools are available to help designers quickly prototype touch interfaces and predict their performance. For rapid prototyping, most applications only support visual design. For predictive modelling, tools such as CogTool generate performance predictions but do not represent touch actions natively and do not allow exploration of different usage contexts. To combine the benefits of rapid visual design tools with underlying predictive models, we developed the Storyboard Empirical Modelling tool (StEM) for exploring and predicting user performance with touch interfaces. StEM provides performance models for mainstream touch actions, based on a large corpus of realistic data. We evaluated StEM in an experiment and compared its predictions to empirical times for several scenarios. The study showed that our predictions are accurate (within 7% of empirical values on average), and that StEM correctly predicted differences between alternative designs. Our tool provides new capabilities for exploring and predicting touch performance, even in the early stages of design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch interaction, performance prediction, modelling},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@article{10.1007/s10844-018-0498-3,
author = {Vicente-L\'{o}pez, Eduardo and Campos, Luis M. and Fern\'{a}ndez-Luna, Juan M. and Huete, Juan F.},
title = {Predicting IR personalization performance using pre-retrieval query predictors},
year = {2018},
issue_date = {December  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {3},
issn = {0925-9902},
url = {https://doi.org/10.1007/s10844-018-0498-3},
doi = {10.1007/s10844-018-0498-3},
abstract = {Although personalization generally improves query performance, it may also occasionally harm how queries perform. If we are able to predict and therefore disable personalization for such situations, overall performance will be higher and users will be more satisfied with personalized systems. We use various state-of-the-art, pre-retrieval query performance predictors and propose several others including user profile information for this purpose. We study the correlations between these predictors and the difference between personalized and original queries. We also use classification and regression techniques to improve the results and finally achieve slightly more than one third of maximum ideal performance. We consider this to be a good starting point within this research line, which will undoubtedly result in further work and improvements.},
journal = {J. Intell. Inf. Syst.},
month = dec,
pages = {597–620},
numpages = {24},
keywords = {Query difficulty, Personalization, Performance prediction, Information retrieval}
}

@inproceedings{10.1145/3307681.3325409,
author = {Li, Yusen and Shan, Chuxu and Chen, Ruobing and Tang, Xueyan and Cai, Wentong and Tang, Shanjiang and Liu, Xiaoguang and Wang, Gang and Gong, Xiaoli and Zhang, Ying},
title = {GAugur: Quantifying Performance Interference of Colocated Games for Improving Resource Utilization in Cloud Gaming},
year = {2019},
isbn = {9781450366700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307681.3325409},
doi = {10.1145/3307681.3325409},
abstract = {Cloud gaming has been very popular recently, but providing satisfactory gaming experiences to players at a modest cost is still challenging. Colocating several games onto one server could improve server utilization. To enable efficient colocations while providing Quality of Service (QoS) guarantees, a precise quantification of performance interference among colocated games is required. However, achieving such precise interference prediction is very challenging for games due to the complexity introduced by the contention on many shared resources across CPU and GPU. Moreover, the distinctive properties of cloud gaming require that the prediction model should be constructed beforehand and the prediction should be made instantaneously at request arrivals, which further increases the difficulty. The existing solutions are either not applicable or not effective due to many limitations. In this paper, we present GAugur, a novel methodology that enables highly accurate prediction of the performance interference among games arbitrarily colocated. By leveraging machine learning technologies, GAugur is able to capture the complex relationship between the interference and the contention features of colocated games. We evaluate GAugur through extensive experiments using a large number of real popular games. The results show that GAugur is able to identify whether a colocated game satisfies QoS requirement within an average error of 5%, and is able to quantify the performance degradation of a colocated game within an average error of 7.9%, which significantly outperforms the alternatives. Moreover, GAugur incurs an offline profiling cost linear to the number of games, and negligible overhead for online prediction. We apply GAugur to guiding efficient game colocations for cloud gaming. Experimental results show that GAugur is able to increase the resource utilization by 20% to 60%, and improve the overall performance by up to 15%, compared to the state-of-the-art solutions.},
booktitle = {Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {231–242},
numpages = {12},
keywords = {performance prediction, performance interference, machine learning, game co-location, cloud gaming},
location = {Phoenix, AZ, USA},
series = {HPDC '19}
}

@inproceedings{10.1145/3404835.3462932,
author = {Gao, Weibo and Liu, Qi and Huang, Zhenya and Yin, Yu and Bi, Haoyang and Wang, Mu-Chun and Ma, Jianhui and Wang, Shijin and Su, Yu},
title = {RCD: Relation Map Driven Cognitive Diagnosis for Intelligent Education Systems},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3462932},
doi = {10.1145/3404835.3462932},
abstract = {Cognitive diagnosis (CD) is a fundamental issue in intelligent educational settings, which aims to discover the mastery levels of students on different knowledge concepts. In general, most previous works consider it as an inter-layer interaction modeling problem, e.g., student-exercise interactions in IRT or student-concept interactions in DINA, while the inner-layer structural relations, such as educational interdependencies among concepts, are still underexplored. Furthermore, there is a lack of comprehensive modeling for the student-exercise-concept hierarchical relations in CD systems. To this end, in this paper, we present a novel Relation map driven Cognitive Diagnosis (RCD) framework, uniformly modeling the interactive and structural relations via a multi-layer student-exercise-concept relation map. Specifically, we first represent students, exercises and concepts as individual nodes in a hierarchical layout, and construct three well-defined local relation maps to incorporate inter- and inner-layer relations, including a student-exercise interaction map, a concept-exercise correlation map and a concept dependency map. Then, we leverage a multi-level attention network to integrate node-level relation aggregation inside each local map and balance map-level aggregation across different maps. Finally, we design an extendable diagnosis function to predict students' performance and jointly train the networks. Extensive experimental results on real-world datasets clearly show the effectiveness and extendibility of our RCD in both diagnosis accuracy improvement and relation-aware representation learning.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {501–510},
numpages = {10},
keywords = {cognitive diagnosis, graph neural network, student performance prediction},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@inproceedings{10.1007/978-3-642-30829-1_6,
author = {Khosravi, Ramtin and Sabouri, Hamideh},
title = {Using coordinated actors to model families of distributed systems},
year = {2012},
isbn = {9783642308284},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-30829-1_6},
doi = {10.1007/978-3-642-30829-1_6},
abstract = {Software product line engineering enables strategic reuse in development of families of related products. In a component-based approach to product line development, components capture functionalities appearing in one or more products in the family and different assemblies of components yield to various products or configurations. In this approach, an interaction model which effectively factors out the logic handling variability from the functionality of the system greatly enhances the reusability of components. We study the problem of variability modeling for a family of distributed systems expressed in actor model. We define a special type of actors called coordinators whose behavior is described as Reo circuits with the aim of encapsulating the variability logic. We have the benefits of Reo language for expressing coordination logic, while modeling the entire system as an actor-based distributed model. We have applied this model to a case study extracted from an industrial software family in the domain of interactive TV.},
booktitle = {Proceedings of the 14th International Conference on Coordination Models and Languages},
pages = {74–88},
numpages = {15},
location = {Stockholm, Sweden},
series = {COORDINATION'12}
}

@inproceedings{10.1007/978-3-030-79382-1_24,
author = {Munoz, Daniel-Jesus and Gurov, Dilian and Pinto, Monica and Fuentes, Lidia},
title = {Category Theory Framework for Variability Models with Non-functional Requirements},
year = {2021},
isbn = {978-3-030-79381-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79382-1_24},
doi = {10.1007/978-3-030-79382-1_24},
abstract = {In Software Product Line (SPL) engineering one uses Variability Models (VMs) as input to automated reasoners to generate optimal products according to certain Quality Attributes (QAs). Variability models, however, and more specifically those including numerical features (i.e., NVMs), do not natively support QAs, and consequently, neither do automated reasoners commonly used for variability resolution. However, those satisfiability and optimisation problems have been covered and refined in other relational models such as databases.Category Theory (CT) is an abstract mathematical theory typically used to capture the common aspects of seemingly dissimilar algebraic structures. We propose a unified relational modelling framework subsuming the structured objects of VMs and QAs and their relationships into algebraic categories. This abstraction allows a combination of automated reasoners over different domains to analyse SPLs. The solutions’ optimisation can now be natively performed by a combination of automated theorem proving, hashing, balanced-trees and chasing algorithms. We validate this approach by means of the edge computing SPL tool HADAS.},
booktitle = {Advanced Information Systems Engineering: 33rd International Conference, CAiSE 2021, Melbourne, VIC, Australia, June 28 – July 2, 2021, Proceedings},
pages = {397–413},
numpages = {17},
keywords = {Category theory, Quality attribute, Non-functional requirement, Feature, Numerical variability model},
location = {Melbourne, VIC, Australia}
}

@article{10.1016/j.jvcir.2019.02.019,
author = {Oliveira, Alberto and Oakley, Eric and da Silva Torres, Ricardo and Rocha, Anderson},
title = {Relevance prediction in similarity-search systems using extreme value theory},
year = {2019},
issue_date = {Apr 2019},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {60},
number = {C},
issn = {1047-3203},
url = {https://doi.org/10.1016/j.jvcir.2019.02.019},
doi = {10.1016/j.jvcir.2019.02.019},
journal = {J. Vis. Comun. Image Represent.},
month = apr,
pages = {236–249},
numpages = {14},
keywords = {Information retrieval, Weibull distribution, Extreme value theory, Performance prediction, Relevance prediction}
}

@inproceedings{10.1007/978-3-319-23781-7_21,
author = {Kostopoulos, Georgios and Kotsiantis, Sotiris and Pintelas, Panagiotis},
title = {Predicting Student Performance in Distance Higher Education Using Semi-supervised Techniques},
year = {2015},
isbn = {9783319237800},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-23781-7_21},
doi = {10.1007/978-3-319-23781-7_21},
abstract = {Students' performance prediction in distance higher education has been widely researched over the past decades. Machine learning techniques and especially supervised learning have been used in numerous studies to identify in time students that are possible to fail in final exams. The identification of in case failure as soon as possible, could lead the academic staff to develop learning strategies aiming to improve students' overall performance. In this paper, we investigate the effectiveness of semi-supervised techniques in predicting students' performance in distance higher education. Several experiments take place in our research comparing to the accuracy measures of familiar semi-supervised algorithms. As far as, we are aware various researches deal with students' performance prediction in distance learning by using machine learning techniques and especially supervised methods, but none of them investigate the effectiveness of semi-supervised algorithms. Our results confirm the advantage of semi-supervised methods and especially the satisfactory performance of Tri-Training algorithm.},
booktitle = {Proceedings of the 5th International Conference on Model and Data Engineering - Volume 9344},
pages = {259–270},
numpages = {12},
keywords = {Tri-training, Semi-supervised learning, Performance prediction, Distance higher education, C4.5 decision tree},
location = {Rhodes, Greece},
series = {MEDI 2015}
}

@article{10.1016/j.is.2019.07.002,
author = {Kang, Yong-Bin and Krishnaswamy, Shonali and Sawangphol, Wudhichart and Gao, Lianli and Li, Yuan-Fang},
title = {Understanding and improving ontology reasoning efficiency through learning and ranking},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {87},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2019.07.002},
doi = {10.1016/j.is.2019.07.002},
journal = {Inf. Syst.},
month = jan,
numpages = {17},
keywords = {Semantic web, Meta-reasoning, Learning, Metrics, Ontology, Performance prediction, Reasoning, OWL}
}

@article{10.1007/s10009-012-0250-1,
author = {Wong, Peter Y. and Albert, Elvira and Muschevici, Radu and Proen\c{c}a, Jos\'{e} and Sch\"{a}fer, Jan and Schlatte, Rudolf},
title = {The ABS tool suite: modelling, executing and analysing distributed adaptable object-oriented systems},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0250-1},
doi = {10.1007/s10009-012-0250-1},
abstract = {Modern software systems must support a high degree of variability to accommodate a wide range of requirements and operating conditions. This paper introduces the Abstract Behavioural Specification (ABS) language and tool suite, a comprehensive platform for developing and analysing highly adaptable distributed concurrent software systems. The ABS language has a hybrid functional and object- oriented core, and comes with extensions that support the development of systems that are adaptable to diversified requirements, yet capable to maintain a high level of trustworthiness. Using ABS, system variability is consistently traceable from the level of requirements engineering down to object behaviour. This facilitates temporal evolution, as changes to the required set of features of a system are automatically reflected by functional adaptation of the system's behaviour. The analysis capabilities of ABS stretch from debugging, observing and simulating to resource analysis of ABS models and help ensure that a system will remain dependable throughout its evolutionary lifetime. We report on the experience of using the ABS language and the ABS tool suite in an industrial case study.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {567–588},
numpages = {22},
keywords = {Variability, Tool support, Software product line, Formal modelling and analysis, Feature modelling, Concurrency}
}

@article{10.1016/j.future.2018.06.041,
author = {Hussain, Walayat and Hussain, Farookh Khadeer and Saberi, Morteza and Hussain, Omar Khadeer and Chang, Elizabeth},
title = {Comparing time series with machine learning-based prediction approaches for violation management in cloud SLAs},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {89},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.06.041},
doi = {10.1016/j.future.2018.06.041},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {464–477},
numpages = {14},
keywords = {Cloud service provider, Prediction accuracy, SLA management, Time series prediction approaches, Machine learning prediction algorithms, QoS prediction methods, SLA monitoring, Cloud computing}
}

@article{10.1016/j.eswa.2021.115421,
author = {Lan Phuong Nguyen, Kieu and Hsun Chuang, Yen and Yu, Ruey-Fang and Chen, Ho-Wen},
title = {Developing an ANN-based early warning model for airborne particulate matters in river banks areas},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {183},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115421},
doi = {10.1016/j.eswa.2021.115421},
journal = {Expert Syst. Appl.},
month = nov,
numpages = {8},
keywords = {Estuary dust, Prediction model, Early-warning system, Artificial neural network}
}

@article{10.1007/s10639-019-10053-x,
author = {Aydo\u{g}du, \c{S}eyhmus},
title = {Predicting student final performance using artificial neural networks in online learning environments},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1360-2357},
url = {https://doi.org/10.1007/s10639-019-10053-x},
doi = {10.1007/s10639-019-10053-x},
abstract = {Prediction of student performance is one of the most important subjects of educational data mining. Artificial neural networks are seen to be an effective tool in predicting student performance in e-learning environments. In the studies carried out with artificial neural networks, performance predictions based on student scores are generally made, but students’ use of learning management system is not focused. In this study, performances of 3518 university students, who studying and actively participating in a learning management system, were tried to be predicted by artificial neural networks in terms of gender, content score, time spent on the content, number of entries to content, homework score, number of attendance to live sessions, total time spent in live sessions, number of attendance to archived courses and total time spent in archived courses variables. Since it is difficult to interpret how much input variables in artificial neural networks contribute to predicting output variables, these networks are called black boxes. Also, in this study the amount of contribution of input variables on the prediction of output variable was also examined. The artificial neural network created as a result of the study makes a prediction with an accuracy of 80.47%. Finally, it was found that the variables of number of attendance to the live classes, the number of attendance to archived courses and the time spent in the content contributed most to the prediction of the output variable.},
journal = {Education and Information Technologies},
month = may,
pages = {1913–1927},
numpages = {15},
keywords = {Deep learning, Distance education, Online learning environments, Artificial neural networks, Educational data mining, Performance prediction}
}

@article{10.1007/s10489-018-1262-7,
author = {Son, Le Hoang and Fujita, Hamido},
title = {Neural-fuzzy with representative sets for prediction of student performance},
year = {2019},
issue_date = {January   2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-018-1262-7},
doi = {10.1007/s10489-018-1262-7},
abstract = {In this paper, a new method for handling the Multi-Input Multi-Output Student Academic Performance Prediction (MIMO SAPP) problem is proposed. The MIMO SAPP aims to predict the future performance of a student after being enrolled into a university. The existing methods have limitations of using a parameter set and an unsuitable training strategy. Thus, the new method called MANFIS-S (Multi Adaptive Neuro-Fuzzy Inference System with Representative Sets) uses multiple parameter sets and a special learning strategy to resolve those weaknesses. Specifically, the idea of multiple parameter sets is to approximate the MANFIS-S model with many meaningful parameters to ensure the performance of system. This is regarded as the representative problem, which is mathematically formulated and theoretically validated. The idea for the special learning strategy is to use global and local training. In global training, a random parameter set is trained from the first to the last record of the database. Each time of training results in a set of parameters. Global training will rectify and achieve a meaningful subset of parameters by the last training process. In local training, there are 2 types of parameters in MANFIS-S namely premise and consequent that are trained by the gradient descent and Particle Swarm Optimization in a hybrid way. Lastly, for a new record in the testing set, Fuzzy K-Nearest Neighbor is used to find which group it belongs to. The proposed MANFIS-S model is experimentally validated against ANFIS, MANFIS, OneR and Random Tree in a benchmark student performance dataset from UCI, a real student performance dataset from VNU University of Science, Vietnam, and 3 educational datasets taken from KDD Cup. The experiments demonstrated the superiority of MANFIS-S over the related algorithms in term of accuracy.},
journal = {Applied Intelligence},
month = jan,
pages = {172–187},
numpages = {16},
keywords = {Student performance prediction, Representative sets, MIMO processing, MANFIS-S}
}

@inproceedings{10.1145/3183440.3183499,
author = {Mukelabai, Mukelabai and Behringer, Benjamin and Fey, Moritz and Palz, Jochen and Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {Multi-view editing of software product lines with PEoPL},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183499},
doi = {10.1145/3183440.3183499},
abstract = {A software product line is a portfolio of software variants in an application domain. It relies on a platform integrating common and variable features of the variants using variability mechanisms---typically classified into annotative and compositional mechanisms. Annotative mechanisms (e.g., using the C preprocessor) are easy to apply, but annotations clutter source code and feature code is often scattered across the platform, which hinders program comprehension and increases maintenance effort. Compositional mechanisms (e.g., using feature modules) support program comprehension and maintainability by modularizing feature code, but are difficult to adopt. Most importantly, engineers need to choose one mechanism and then stick to it for the whole life cycle of the platform. The PEoPL (Projectional Editing of Product Lines) approach combines the advantages of both kinds of mechanisms. In this paper, we demonstrate the PEoPL IDE, which supports the approach by providing various kinds of editable views, each of which represents the same software product line using annotative or compositional variability mechanisms, or subsets of concrete variants. Software engineers can seamlessly switch these views, or use multiple views side-by-side, based on the current engineering task. A demo video of PEoPL is available at Youtube: https://youtu.be/wByUxSPLoSY},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {81–84},
numpages = {4},
keywords = {annotative, modular, product lines, projectional editing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3106237.3119880,
author = {Tang, Chong},
title = {System performance optimization via design and configuration space exploration},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3119880},
doi = {10.1145/3106237.3119880},
abstract = {The runtime performance of a software system often depends on a large number of static parameters, which usually interact in complex ways to carry out system functionality and influence system performance. It's hard to understand such configuration spaces and find good combinations of parameter values to gain available levels of performance. Engineers in practice often just accept the default settings, leading such systems to significantly underperform relative to their potential. This problem, in turn, has impacts on cost, revenue, customer satisfaction, business reputation, and mission effectiveness. To improve the overall performance of the end-to-end systems, we propose to systematically explore (i) how to design new systems towards good performance through design space synthesis and evaluation, and (ii) how to auto-configure an existing system to obtain better performance through heuristic configuration space search. In addition, this research further studies execution traces of a system to predict runtime performance under new configurations.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {1046–1049},
numpages = {4},
keywords = {Performance Prediction, Performance Optimization, Design Space, Configuration Space},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1109/CCGRID.2017.105,
author = {Imai, Shigeru and Patterson, Stacy and Varela, Carlos A.},
title = {Maximum Sustainable Throughput Prediction for Data Stream Processing over Public Clouds},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.105},
doi = {10.1109/CCGRID.2017.105},
abstract = {In cloud-based stream processing services, the maximum sustainable throughput (MST) is defined as the maximum throughput that a system composed of a fixed number of virtual machines (VMs) can ingest indefinitely. If the incoming data rate exceeds the system's MST, unprocessed data accumulates, eventually making the system inoperable. Thus, it is important for the service provider to keep the MST always larger than the incoming data rate by dynamically changing the number of VMs used by the system. In this paper, we identify a common data processing environment used by modern data stream processing systems, and we propose MST prediction models for this environment. We train the models using linear regression with samples obtained from a few VMs and predict MST for a larger number of VMs. To minimize the time and cost for model training, we statistically determine a set of training samples using Intel's Storm benchmarks with representative resource usage patterns. Using typical use-case benchmarks on Amazon's EC2 public cloud, our experiments show that, training with up to 8 VMs, we can predict MST for streaming applications with less than 4% average prediction error for 12 VMs, 9% for 16 VMs, and 32% for 24 VMs. Further, we evaluate our prediction models with simulation-based elastic VM scheduling on a realistic workload. These simulation results show that with 10% over-provisioning, our proposed models' cost efficiency is on par with the cost of an optimal scaling policy without incurring any service level agreement violations.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {504–513},
numpages = {10},
keywords = {resource management, performance prediction, cloud computing, auto-scaling},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1109/ICMTMA.2011.378,
author = {Liang-yong, Huang and Sheng-zhong, Huang},
title = {Immune evolutionary algorithm of wavelet neural network to predict the performance in the centrifugal compressor and Research},
year = {2011},
isbn = {9780769542966},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMTMA.2011.378},
doi = {10.1109/ICMTMA.2011.378},
abstract = {Centrifugal compressor performance prediction method mainly uses the traditional BP neural network problem is not high enough accuracy, convergence, easily falling into local optimal solution. In order to more accurately predict the performance of centrifugal compressors, find problems early implicit commit. Is the algorithm, wavelet theory, artificial neural networks, established immune algorithm of wavelet neural network model of a centrifugal compressor performance prediction. First, the initial antibody produced by the immune algorithm group, through iteration, obtain the corresponding coefficient for each antibody WNN, and then use back-propagation algorithm to train WNN approach any nonlinear function. Simulation results show that application of the prediction model, which enables the accurate prediction of centrifugal compressor performance and monitoring. The prediction model algorithm is simple, stable structure, computational convergence speed, generalization ability of the advantages of prediction accuracy of 99%. Than the traditional method of prediction accuracy of 13%. Has some theoretical research value and practical value.},
booktitle = {Proceedings of the 2011 Third International Conference on Measuring Technology and Mechatronics Automation - Volume 02},
pages = {366–369},
numpages = {4},
keywords = {Wavelet neural network, Performance prediction, Immune algorithm, Centrifugal compressor},
series = {ICMTMA '11}
}

@inproceedings{10.1145/2568088.2576760,
author = {Ghaith, Shadi and Wang, Miao and Perry, Philip and Murphy, Liam},
title = {Software contention aware queueing network model of three-tier web systems},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2576760},
doi = {10.1145/2568088.2576760},
abstract = {Using modelling to predict the performance characteristics of software applications typically uses Queueing Network Models representing the various system hardware resources. Leaving out the software resources, such as the limited number of threads, in such models leads to a reduced prediction accuracy. Accounting for Software Contention is a challenging task as existing techniques to model software components are complex and require deep knowledge of the software architecture. Furthermore, they also require complex measurement processes to obtain the model's service demands. In addition, solving the resultant model usually require simulation solvers which are often time consuming.In this work, we aim to provide a simpler model for three-tier web software systems which accounts for Software Contention that can be solved by time efficient analytical solvers. We achieve this by expanding the existing "Two-Level Iterative Queuing Modelling of Software Contention" method to handle the number of threads at the Application Server tier and the number of Data Sources at the Database Server tier. This is done in a generic manner to allow for extending the solution to other software components like memory and critical sections. Initial results show that our technique clearly outperforms existing techniques.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {273–276},
numpages = {4},
keywords = {web applications, software contention, performance prediction, performance models},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@inproceedings{10.1145/2998476.2998483,
author = {Kattepur, Ajay and Nambiar, Manoj},
title = {Service Demand Modeling and Prediction with Single-user Performance Tests},
year = {2016},
isbn = {9781450348089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2998476.2998483},
doi = {10.1145/2998476.2998483},
abstract = {Performance load tests of online transaction processing (OLTP) applications are expensive in terms of manpower, time and costs. Alternative performance modeling and prediction tools are required to generate accurate outputs with minimal input sample points. Service Demands (time needed to serve 1 request at queuing stations) are typically needed as inputs by most performance models. However, as service demands vary as a function of workload, models that input singular service demands produce erroneous predictions. The alternative, which is to collect service demands at varying workloads, require time and resource intensive load tests to estimate multiple sample points -- this defeats the purpose of performance modeling for industrial use. In this paper, we propose a service demand model as a function of concurrency that can be estimated with a single-user performance test. Further, we analyze multiple CPU performance metrics (cache hits/misses, branch prediction, context switches and so on) using Principal Component Analysis (PCA) to extract a regression function of service demand with increasing workloads. We use the service demand models as input to performance prediction algorithms such as Mean Value Analysis (MVA), to accurately predict throughput at varying workloads. This service demand prediction model uses CPU hardware counters, which is used in conjunction with a modified version of MVA with single-user service demand inputs. The predicted throughput values are within 9% deviation with measurements procured for a variety of application/hardware configurations. Such a service demand model is a step towards reducing reliance on conventional load testing for performance assurance.},
booktitle = {Proceedings of the 9th Annual ACM India Conference},
pages = {31–41},
numpages = {11},
keywords = {Service Demand Modeling, Principal Component Analysis, Performance Prediction, Mean Value Analysis, CPU Performance Counters},
location = {Gandhinagar, India},
series = {COMPUTE '16}
}

@article{10.1007/s00158-021-02948-6,
author = {Wang, Zhixiang and Zhang, Dapeng and Lei, Yongjun and Wu, Zeping and Wang, Jie and OuYang, Xing and Wang, Jun},
title = {Constrained space-filling and non-collapsing sequential design of experiments and its application for the lightweight design of cylindrical stiffened shells},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {64},
number = {6},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-021-02948-6},
doi = {10.1007/s00158-021-02948-6},
abstract = {Constraints widely exist in the structural optimization problems, including not only expensive constraints but also inexpensive constraints with explicit or implicit analytical expressions. Simply omitting the infeasible sampling points generated by conventional design of experiments (DoE) techniques leads to fewer feasible points than desired and to the remaining points distributed sub-optimally. This paper presents a novel constrained space-filling and non-collapsing sequential sampling (CSFSS) method for the arbitrarily constrained design space. To this end, an improved local density is firstly proposed to measure the spatial distribution of the sampling points located in the feasible region. Then, a novel formulation based on the improved local density is proposed for the criterion of sequential sampling strategies, which can guarantee the space-filling and non-collapsing properties both preferably optimal. Afterwards, several methods are proposed to tackle the challenging multimodal optimization problem posed by sequential sampling strategies. Finally, a replacement-based strategy is proposed to further elevate the quality of the design. Extensive numerical results, including an application for the lightweight design of cylindrical stiffened shells in aerospace engineering, highlight the satisfying performance of the proposed method not only in obtaining a high quality of constrained experimental designs but also in competitive contributions to constrained optimization gains.},
journal = {Struct. Multidiscip. Optim.},
month = dec,
pages = {3265–3286},
numpages = {22},
keywords = {Constrained optimization gains, Constrained experimental designs, CSFSS, Non-collapsing, Space-filling, Cylindrical stiffened shells}
}

@inproceedings{10.1145/3331184.3331249,
author = {Chiang, Meng-Fen and Lim, Ee-Peng and Lee, Wang-Chien and Ashok, Xavier Jayaraj Siddarth and Prasetyo, Philips Kokoh},
title = {One-Class Order Embedding for Dependency Relation Prediction},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331249},
doi = {10.1145/3331184.3331249},
abstract = {Learning the dependency relations among entities and the hierarchy formed by these relations by mapping entities into some order embedding space can effectively enable several important applications, including knowledge base completion and prerequisite relations prediction. Nevertheless, it is very challenging to learn a good order embedding due to the existence of partial ordering and missing relations in the observed data. Moreover, most application scenarios do not provide non-trivial negative dependency relation instances. We therefore propose a framework that performs dependency relation prediction by exploring both rich semantic and hierarchical structure information in the data. In particular, we propose several negative sampling strategies based on graph-specific centrality properties, which supplement the positive dependency relations with appropriate negative samples to effectively learn order embeddings. This research not only addresses the needs of automatically recovering missing dependency relations, but also unravels dependencies among entities using several real-world datasets, such as course dependency hierarchy involving course prerequisite relations, job hierarchy in organizations, and paper citation hierarchy. Extensive experiments are conducted on both synthetic and real-world datasets to demonstrate the prediction accuracy as well as to gain insights using the learned order embedding.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {205–214},
numpages = {10},
keywords = {order embedding, one-class learning, dependency relation prediction},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3126908.3126969,
author = {Marathe, Aniruddha and Anirudh, Rushil and Jain, Nikhil and Bhatele, Abhinav and Thiagarajan, Jayaraman and Kailkhura, Bhavya and Yeom, Jae-Seung and Rountree, Barry and Gamblin, Todd},
title = {Performance modeling under resource constraints using deep transfer learning},
year = {2017},
isbn = {9781450351140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126908.3126969},
doi = {10.1145/3126908.3126969},
abstract = {Tuning application parameters for optimal performance is a challenging combinatorial problem. Hence, techniques for modeling the functional relationships between various input features in the parameter space and application performance are important. We show that simple statistical inference techniques are inadequate to capture these relationships. Even with more complex ensembles of models, the minimum coverage of the parameter space required via experimental observations is still quite large. We propose a deep learning based approach that can combine information from exhaustive observations collected at a smaller scale with limited observations collected at a larger target scale. The proposed approach is able to accurately predict performance in the regimes of interest to performance analysts while outperforming many traditional techniques. In particular, our approach can identify the best performing configurations even when trained using as few as 1% of observations at the target scale.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {31},
numpages = {12},
keywords = {transfer learning, performance prediction, parameter selection, deep learning},
location = {Denver, Colorado},
series = {SC '17}
}

@article{10.1145/2724717,
author = {Castro, Pablo De Oliveira and Akel, Chadi and Petit, Eric and Popov, Mihail and Jalby, William},
title = {CERE: LLVM-Based Codelet Extractor and REplayer for Piecewise Benchmarking and Optimization},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/2724717},
doi = {10.1145/2724717},
abstract = {This article presents Codelet Extractor and REplayer (CERE), an open-source framework for code isolation. CERE finds and extracts the hotspots of an application as isolated fragments of code, called codelets. Codelets can be modified, compiled, run, and measured independently from the original application. Code isolation reduces benchmarking cost and allows piecewise optimization of an application. Unlike previous approaches, CERE isolates codes at the compiler Intermediate Representation (IR) level. Therefore CERE is language agnostic and supports many input languages such as C, C++, Fortran, and D. CERE automatically detects codelets invocations that have the same performance behavior. Then, it selects a reduced set of representative codelets and invocations, much faster to replay, which still captures accurately the original application. In addition, CERE supports recompiling and retargeting the extracted codelets. Therefore, CERE can be used for cross-architecture performance prediction or piecewise code optimization. On the SPEC 2006 FP benchmarks, CERE codelets cover 90.9% and accurately replay 66.3% of the execution time. We use CERE codelets in a realistic study to evaluate three different architectures on the NAS benchmarks. CERE accurately estimates each architecture performance and is 7.3 \texttimes{} to 46.6 \texttimes{} cheaper than running the full benchmark.},
journal = {ACM Trans. Archit. Code Optim.},
month = apr,
articleno = {6},
numpages = {24},
keywords = {performance prediction, iterative optimization, checkpoint restart, Program replay}
}

@article{10.1007/s11042-017-4460-0,
author = {You, Jiali and Xue, Hanxing and Gao, Lixin and Zhang, Guoqiang and Zhuo, Yu and Wang, Jinlin},
title = {Predicting the online performance of video service providers on the internet},
year = {2017},
issue_date = {Sep 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {18},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-4460-0},
doi = {10.1007/s11042-017-4460-0},
abstract = {Video services on the Internet are not able to offer consistent and assured performance to users or third-party applications. Measuring levels of performance over time is difficult, and obtaining accurate measures in real time is problematic; thus, reactive measures to address loss of performance are also problematic. The ability to predict service performance can be viewed as an important added-value, one that can help users or third-part applications select the proper online service provider. With this aim in view, we have designed a measurement system and deployed it in eleven provinces and cities in China to monitor two popular websites, Youku and Tudou. The analysis indicates that the performance trend of these two service providers followed daily changing patterns, such as rush hour traffic and lower service workloads at midnight; this is consistent with user behaviors. It was also confirmed that the future performance was related to the historical records. Based on these findings, we have decided to investigate the use of modified time series models to forecast the performance of such video services. Meanwhile, some machine learning models are implemented and compared as baseline models, such as Artificial Neural Network, Support Vector Machine, and Decision Tree. In addition, a hybrid model, which is generated by combining different machine learning models, is also studied as the baseline. An investigation shows that time series models are much more suitable to this prediction problem than baseline models in most situations. To alleviate the data sparseness problem in training the predictor, a new predictor that combines different information sources is proposed, thus improving prediction precision. Furthermore, the predictor is quite stable, and we have discovered that the average performance estimation is more accurate if the model is updated within 2---3 days, which is useful in some applications, e.g., video source analysis and recommendation systems.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {19017–19038},
numpages = {22},
keywords = {Video service provider, Time-series models, Performance prediction, Performance analysis}
}

@inproceedings{10.1145/3366030.3366079,
author = {Sampaio, Vanderson S. de O. L. and Fileto, Renato and de Macedo, Douglas D. J.},
title = {A Method to Estimate Entity Performance from Mentions to Related Entities in Texts on the Web},
year = {2020},
isbn = {9781450371797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366030.3366079},
doi = {10.1145/3366030.3366079},
abstract = {Publications on the Web can influence the public opinion about certain entities (e.g., politicians, institutions). At the same time, a variety of indicators can be extracted from these publications and used to estimate entity performance (e.g., popularity, votes share). This work proposes an automatic method that employs state-of-the-art natural language processing tools to extract indicators about entities mentioned in texts, for estimating the performance of these entities or semantically related ones. Our method calculates performance metrics from performance indicators consolidated for semantically related entities, assess correlations of these consolidated metrics with ground true performance, and uses these metrics to predict certain fluctuations in entity performance. Experimental results in a case study on politics show that consolidated metrics for several interrelated entities are better correlated to observed real performance measures of some target entities and lead to better predictions, than metrics for just one entity.},
booktitle = {Proceedings of the 21st International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {267–276},
numpages = {10},
keywords = {semantic relatedness, entity performance prediction, Entity performance correlation},
location = {Munich, Germany},
series = {iiWAS2019}
}

@inproceedings{10.1145/3127479.3131614,
author = {Yadwadkar, Neeraja J. and Hariharan, Bharath and Gonzalez, Joseph E. and Smith, Burton and Katz, Randy H.},
title = {Selecting the best VM across multiple public clouds: a data-driven performance modeling approach},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3131614},
doi = {10.1145/3127479.3131614},
abstract = {Users of cloud services are presented with a bewildering choice of VM types and the choice of VM can have significant implications on performance and cost. In this paper we address the fundamental problem of accurately and economically choosing the best VM for a given workload and user goals. To address the problem of optimal VM selection, we present PARIS, a data-driven system that uses a novel hybrid offline and online data collection and modeling framework to provide accurate performance estimates with minimal data collection. PARIS is able to predict workload performance for different user-specified metrics, and resulting costs for a wide range of VM types and workloads across multiple cloud providers. When compared to sophisticated baselines, including collaborative filtering and a linear interpolation model using measured workload performance on two VM types, PARIS produces significantly better estimates of performance. For instance, it reduces runtime prediction error by a factor of 4 for some workloads on both AWS and Azure. The increased accuracy translates into a 45% reduction in user cost while maintaining performance.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {452–465},
numpages = {14},
keywords = {resource allocation, performance prediction, data-driven modeling, cloud computing},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/2534248.2534253,
author = {Malik, Muhammad Junaid and Fahringer, Thomas and Prodan, Radu},
title = {Execution time prediction for grid infrastructures based on runtime provenance data},
year = {2013},
isbn = {9781450325028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534248.2534253},
doi = {10.1145/2534248.2534253},
abstract = {An accurate performance prediction service can be very useful for resource management and the scheduler service and help them make better resource utilization decisions by providing better execution time estimates. In this paper we present a novel approach of predicting the execution time of computational tasks for Grid infrastructures using machine learning models based on multilayer perceptron combined with a principal feature selection algorithm for selecting the most important runtime features.Our technique uses runtime provenance information as input to multilayer perceptron (MLP) based neural network which trains a model that can predict the execution time of programs with reasonably good accuracy. For the development and training of our machine learning models, we used provenance data collected from three different computational Grids by executing real-world applications. By using our MLP based method we were able to minimise the prediction error to as low as 22% for real-world applications on various Grid infrastructures.},
booktitle = {Proceedings of the 8th Workshop on Workflows in Support of Large-Scale Science},
pages = {48–57},
numpages = {10},
keywords = {principal component analysis, performance prediction, neural networks, multilayer perceptron, grid},
location = {Denver, Colorado},
series = {WORKS '13}
}

@inproceedings{10.1145/3377024.3377042,
author = {Krieter, Sebastian and Th\"{u}m, Thomas and Schulze, Sandro and Saake, Gunter and Leich, Thomas},
title = {YASA: yet another sampling algorithm},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377042},
doi = {10.1145/3377024.3377042},
abstract = {Configurable systems allow users to derive customized software variants with behavior and functionalities tailored to individual needs. Developers of these configurable systems need to ensure that each configured software variant works as intended. Thus, software testing becomes highly relevant, but also highly expensive due to large configuration spaces that grow exponentially in the number of features. To this end, sampling techniques, such as t-wise interaction sampling, are used to generate a small yet representative subset of configurations, which can be tested even with a limited amount of resources. However, even state-of-the-art t-wise interaction sampling techniques do not scale well for systems with large configuration spaces. In this paper, we introduce the configurable technique YASA that aims to be more efficient than other existing techniques and enables control over trading-off sampling time and sample size. The general algorithm of YASA is based on the existing technique IPOG, but introduces several improvements and options to adapt the sampling procedure to a given configurable system. We evaluate our approach in terms of sampling time and sample size by comparing it to existing t-wise interaction sampling techniques. We find that YASA performs well even for large-scale system and is also able to produce smaller samples than existing techniques.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {4},
numpages = {10},
keywords = {software product lines, product-based testing, configurable system, T-wise sampling},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1145/3302333.3302337,
author = {Al-Hajjaji, Mustafa and Ryssel, Uwe and Schulze, Michael},
title = {Validating Partial Configurations of Product Lines},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302337},
doi = {10.1145/3302333.3302337},
abstract = {Configuring a new variant of a product line is not always a one-time task. In some cases, many stakeholders are involved in the configuration process. This is needed for example, if different stakeholders are responsible for different parts of the product line and they are not allowed to see specific parts of the product line already configured in previous steps. Thus, a partial derivation can be performed, where a part of the configuration process can be done by some stakeholders, while finishing the rest of the configuration process can be achieved by others.Validating partial configurations is a challenging task, since the selection state of some features can still be open. In addition to these open selection states of features, values of attributes, calculations of expressions, as well as constraints are needed to be handled, as they can use information, which is not defined yet. Thus, a validator that ables to address the aforementioned challenges is required. In this paper, we discuss how the partial configurations can be validated considering different cases. While these discussed cases can be applied in general, we focus in this paper on applying them with respect to the industrial variant management tool pure::variants.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {4},
numpages = {6},
keywords = {Software product lines, Product configuration, Partial derivation, Partial configuration, Multi-stage configuration, Highly configurable systems},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1109/ICSE.2019.00112,
author = {Kaltenecker, Christian and Grebhahn, Alexander and Siegmund, Norbert and Guo, Jianmei and Apel, Sven},
title = {Distance-based sampling of software configuration spaces},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00112},
doi = {10.1109/ICSE.2019.00112},
abstract = {Configurable software systems provide a multitude of configuration options to adjust and optimize their functional and non-functional properties. For instance, to find the fastest configuration for a given setting, a brute-force strategy measures the performance of all configurations, which is typically intractable. Addressing this challenge, state-of-the-art strategies rely on machine learning, analyzing only a few configurations (i.e., a sample set) to predict the performance of other configurations. However, to obtain accurate performance predictions, a representative sample set of configurations is required. Addressing this task, different sampling strategies have been proposed, which come with different advantages (e.g., covering the configuration space systematically) and disadvantages (e.g., the need to enumerate all configurations). In our experiments, we found that most sampling strategies do not achieve a good coverage of the configuration space with respect to covering relevant performance values. That is, they miss important configurations with distinct performance behavior. Based on this observation, we devise a new sampling strategy, called distance-based sampling, that is based on a distance metric and a probability distribution to spread the configurations of the sample set according to a given probability distribution across the configuration space. This way, we cover different kinds of interactions among configuration options in the sample set. To demonstrate the merits of distance-based sampling, we compare it to state-of-the-art sampling strategies, such as t-wise sampling, on 10 real-world configurable software systems. Our results show that distance-based sampling leads to more accurate performance models for medium to large sample sets.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {1084–1094},
numpages = {11},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1016/j.infsof.2021.106674,
author = {Domingo, \'{A}frica and Echeverr\'{\i}a, Jorge and Pastor, \'{O}scar and Cetina, Carlos},
title = {Evaluating the influence of scope on feature location},
year = {2021},
issue_date = {Dec 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {140},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106674},
doi = {10.1016/j.infsof.2021.106674},
journal = {Inf. Softw. Technol.},
month = dec,
numpages = {15},
keywords = {Model-driven engineering, Controlled experiment, Feature location}
}

@article{10.1016/j.pmcj.2015.10.001,
author = {Kwon, Yongin and Yi, Hayoon and Kwon, Donghyun and Yang, Seungjun and Cho, Yeongpil and Paek, Yunheung},
title = {Precise execution offloading for applications with dynamic behavior in mobile cloud computing},
year = {2016},
issue_date = {April 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {C},
issn = {1574-1192},
url = {https://doi.org/10.1016/j.pmcj.2015.10.001},
doi = {10.1016/j.pmcj.2015.10.001},
abstract = {In order to accommodate the high demand for performance in smartphones, mobile cloud computing techniques, which aim to enhance a smartphone's performance through utilizing powerful cloud servers, were suggested. Among such techniques, execution offloading, which migrates a thread between a mobile device and a server, is often employed. In such execution offloading techniques, it is typical to dynamically decide what code part is to be offloaded through decision making algorithms. In order to achieve optimal offloading performance, however, the gain and cost of offloading must be predicted accurately for such algorithms. Previous works did not try hard to do this because it is usually expensive to make an accurate prediction. Thus in this paper, we introduce novel techniques to automatically generate accurate and efficient method-wise performance predictors for mobile applications and empirically show they enhance the performance of offloading.},
journal = {Pervasive Mob. Comput.},
month = apr,
pages = {58–74},
numpages = {17},
keywords = {Performance prediction, Mobile cloud computing, Execution offloading}
}

@article{10.1016/j.bdr.2021.100207,
author = {Lan, Fangpeng and Zhang, Jinwen and Niu, Baoning},
title = {Predicting Response Time of Concurrent Queries with Similarity Models},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {25},
number = {C},
issn = {2214-5796},
url = {https://doi.org/10.1016/j.bdr.2021.100207},
doi = {10.1016/j.bdr.2021.100207},
journal = {Big Data Res.},
month = jul,
numpages = {13},
keywords = {OLAP, Query scheduler, Query rating, Query mix similarity, Query performance prediction}
}

@inproceedings{10.1145/3302333.3302349,
author = {ter Beek, Maurice H. and Legay, Axel},
title = {Quantitative Variability Modeling and Analysis},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302349},
doi = {10.1145/3302333.3302349},
abstract = {The explicit management of variability in the development cycle of software-intensive systems has led to a plethora of modeling and analysis techniques tailored to deal with behavioral validation of such configurable systems. Most of the work, however, focuses on qualitative (i.e. functional) requirements. Recently, there is growing interest in variability modeling and analysis techniques that do explicitly consider quantitative (i.e. non-functional) requirements, such as dependability, energy consumption, security, and cost.Today's software is embedded in a variety of smart and critical systems that run in environments where events occur randomly and affect the system, and to which it needs to adapt. Therefore, quantitative modeling and analysis is currently a hot topic. The panel on Quantitative Variability Modeling and Analysis (QSPL) discusses the latest quantitative techniques and how to apply them to variability modeling and analysis of software-intensive systems.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {13},
numpages = {2},
keywords = {Variability, Quantitative modeling, Quantitative analysis, QSPL},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1145/3357384.3357867,
author = {Dong, Yushun and Shao, Yingxia and Li, Xiaotong and Li, Sili and Quan, Lei and Zhang, Wei and Du, Junping},
title = {Forecasting Pavement Performance with a Feature Fusion LSTM-BPNN Model},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357867},
doi = {10.1145/3357384.3357867},
abstract = {In modern pavement management systems, pavement roughness is an important indicator of pavement performance, and it reflects the smoothness of pavement surface. International Roughness Index (IRI) is the de-facto metric to quantitatively analyze the roughness of pavement surface. The pavement with high IRI not only reduces the lifetime of vehicles, but also raises the risk of car accidents. Accurate prediction of IRI becomes a key task for the pavement management system, and it helps the transportation department refurbish the pavement in time. However, existing models are proposed on top of small datasets, and have poor performance. Besides, they only consider cross-sectional features of the pavements without any time-series information. In order to better capture the latent relationship between the cross-sectional and time-series features, we propose a novel feature fusion LSTM-BPNN model. LSTM-BPNN first learns the cross-sectional and time-series features with two neural networks separately, then it fuses both features via an attention mechanism. Experimental results on a high-quality real-world dataset clearly demonstrate that the new model outperforms existing considerable alternatives.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1953–1962},
numpages = {10},
keywords = {pavement performance prediction, neural network, feature fusion, attention},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1007/978-3-642-34026-0_11,
author = {Leucker, Martin and Thoma, Daniel},
title = {A formal approach to software product families},
year = {2012},
isbn = {9783642340253},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34026-0_11},
doi = {10.1007/978-3-642-34026-0_11},
abstract = {Software product line engineering deals with the combined development of a family of similar software systems. These systems provide a similar set of features and should therefore share a large number of common components. We study the user perspective of features and the engineering perspective of components and present a formal notion of features, component-based product families and their interaction. We then demonstrate using Milner's CCS how our formalism can be applied to extend an arbitrary modelling formalism with support for product lines. To verify that certain products indeed realize certain features, we propose μ-calculus model-checking for multi-valued Kripke-structures. The model checking result in that case no longer is a simple truth-value, but a set of products, conforming to a certain property.},
booktitle = {Proceedings of the 5th International Conference on Leveraging Applications of Formal Methods, Verification and Validation: Technologies for Mastering Change - Volume Part I},
pages = {131–145},
numpages = {15},
location = {Heraklion, Crete, Greece},
series = {ISoLA'12}
}

@article{10.1016/j.infsof.2019.106198,
author = {Assun\c{c}\~{a}o, Wesley K.G. and Vergilio, Silvia R. and Lopez-Herrejon, Roberto E.},
title = {Automatic extraction of product line architecture and feature models from UML class diagram variants},
year = {2020},
issue_date = {Jan 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {117},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106198},
doi = {10.1016/j.infsof.2019.106198},
journal = {Inf. Softw. Technol.},
month = jan,
numpages = {19},
keywords = {Search-based techniques, SPL architecture, Feature model, Model merging}
}

@inproceedings{10.1145/2568088.2568100,
author = {Gorsler, Fabian and Brosig, Fabian and Kounev, Samuel},
title = {Performance queries for architecture-level performance models},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2568100},
doi = {10.1145/2568088.2568100},
abstract = {Over the past few decades, many performance modeling formalisms and prediction techniques for software architectures have been developed in the performance engineering community. However, using a performance model to predict the performance of a software system normally requires extensive experience with the respective modeling formalism and involves a number of complex and time consuming manual steps. In this paper, we propose a generic declarative interface to performance prediction techniques to simplify and automate the process of using architecture-level software performance models for performance analysis. The proposed Descartes Query Language (DQL) is a language to express the demanded performance metrics for prediction as well as the goals and constraints of the specific prediction scenario. It reduces the manual effort and learning curve in working with performance models by a unified interface independent of the employed modeling formalism. We evaluate the applicability and benefits of the proposed approach in the context of several representative case studies.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {99–110},
numpages = {12},
keywords = {software performance engineering, query language, performance prediction, domain-specific language, automation},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@inproceedings{10.5555/2040317.2040324,
author = {Bellog\'{\i}n, Alejandro and Castells, Pablo and Cantador, Iv\'{a}n},
title = {Predicting the performance of recommender systems: an information theoretic approach},
year = {2011},
isbn = {9783642233173},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Performance prediction is an appealing problem in Recommender Systems, as it enables an array of strategies for deciding when to deliver or hold back recommendations based on their foreseen accuracy. The problem, however, has been barely addressed explicitly in the area. In this paper, we propose adaptations of query clarity techniques from ad-hoc Information Retrieval to define performance predictors in the context of Recommender Systems, which we refer to as user clarity. Our experiments show positive results with different user clarity models in terms of the correlation with single recommender's performance. Empiric results show significant dependency between this correlation and the recommendation method at hand, as well as competitive results in terms of average correlation.},
booktitle = {Proceedings of the Third International Conference on Advances in Information Retrieval Theory},
pages = {27–39},
numpages = {13},
keywords = {recommender systems, performance prediction, language models},
location = {Bertinoro, Italy},
series = {ICTIR'11}
}

@inproceedings{10.1145/1383559.1383573,
author = {Becker, Steffen},
title = {Coupled model transformations},
year = {2008},
isbn = {9781595938732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1383559.1383573},
doi = {10.1145/1383559.1383573},
abstract = {Model-driven performance prediction methods use abstract design models to predict the performance of the modelled system during early development stages. However, performance is an attribute of the running system and not its model. The system contains many implementation details not part of its model but still affecting the performance at run-time. Existing approaches neglect details of the implementation due to the abstraction underlying the design model. Completion components [26] deal with this problem, however, they have to be added manually to the prediction model. In this work, we assume that the system's implementation is generated by a chain of model transformations. In this scenario, the transformation rules determine the transformation result. By analysing these transformation rules, a second transformation can be derived which automatically adds details to the prediction model according to the encoded rules. We call this transformation a coupled transformation as it is coupled to an corresponding model-to-code transformation. It uses the knowledge on the output of the model-to-code transformation to increase performance prediction accuracy. The introduced coupled transformations method is validated in a case study in which a parametrised transformation maps abstract component connectors to realisations in different RPC calls. In this study, the corresponding coupled transformation captures the RPC's details with a prediction error of less than 5%.},
booktitle = {Proceedings of the 7th International Workshop on Software and Performance},
pages = {103–114},
numpages = {12},
keywords = {platform completions, performance prediction, model-driven software development, mda},
location = {Princeton, NJ, USA},
series = {WOSP '08}
}

@article{10.1145/1862648.1862655,
author = {Reardon, Casey and Grobelny, Eric and George, Alan D. and Wang, Gongyu},
title = {A Simulation Framework for Rapid Analysis of Reconfigurable Computing Systems},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1936-7406},
url = {https://doi.org/10.1145/1862648.1862655},
doi = {10.1145/1862648.1862655},
abstract = {Reconfigurable computing (RC) is rapidly emerging as a promising technology for the future of high-performance and embedded computing, enabling systems with the computational density and power of custom-logic hardware and the versatility of software-driven hardware in an optimal mix. Novel methods for rapid virtual prototyping, performance prediction, and evaluation are of critical importance in the engineering of complex reconfigurable systems and applications. These techniques can yield insightful tradeoff analyses while saving valuable time and resources for researchers and engineers alike. The research described herein provides a methodology for mapping arbitrary applications to targeted reconfigurable platforms in a simulation environment called RCSE. By splitting the process into two domains, the application and simulation domains, characterization of each element can occur independently and in parallel, leading to fast and accurate performance prediction results for large and complex systems. This article presents the design of a novel framework for system-level simulative performance prediction of RC systems and applications. The article also presents a set of case studies analyzing two applications, Hyperspectral Imaging (HSI) and Molecular Dynamics (MD), across three disparate RC platforms within the simulation framework. The validation results using each of these applications and systems show that our framework can quickly obtain performance prediction results with reasonable accuracy on a variety of platforms. Finally, a set of simulative case studies are presented to illustrate the various capabilities of the framework to quickly obtain a wide range of performance prediction results and power consumption estimates.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = nov,
articleno = {25},
numpages = {29},
keywords = {performance prediction, discrete-event simulation, Reconfigurable computing}
}

@inproceedings{10.1145/3344948.3344964,
author = {Kerdoudi, Mohamed Lamine and Ziadi, Tewfik and Tibermacine, Chouki and Sadou, Salah},
title = {A bottom-up approach for reconstructing software architecture product lines},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344964},
doi = {10.1145/3344948.3344964},
abstract = {A large component and service-based software system exists in different forms, as different variants targeting different business needs and users. This kind of systems is provided as a set of "independent" products and not as a "single whole". The presence of a single model describing the architecture of the whole system may be of great interest for developers of future variants. Indeed, this enables them to see the invariant part of the whole, on top of which new functionality can be built, in addition to the different options they can use. We investigate in this work the use of software product line reverse engineering approaches, and in particular the framework named BUT4Reuse, for reconstructing an architecture model of a Software Architecture Product Line (SAPL), from a set of variants. We propose a generic process for reconstructing an architecture model of such a product line. We have instantiated this process for the OSGi Java framework and experimented it for building the architecture model of Eclipse IDE SPL.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {46–49},
numpages = {4},
location = {Paris, France},
series = {ECSA '19}
}

@article{10.1016/j.asoc.2021.107110,
author = {Sun, Feng and Xie, Gongnan and Li, Shulei},
title = {An artificial-neural-network based prediction of heat transfer behaviors for in-tube supercritical CO2 flow},
year = {2021},
issue_date = {Apr 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107110},
doi = {10.1016/j.asoc.2021.107110},
journal = {Appl. Soft Comput.},
month = apr,
numpages = {14},
keywords = {Empirical correlation, Thermal behavior, Thermophysical property, Supercritical CO2, Artificial neural network}
}

@inproceedings{10.1145/3386392.3399309,
author = {Tokuda, Keita and Kaschub, David and Ota, Takuma and Hashimoto, Yasunobu and Fujiwara, Naoya and Sudo, Akihito},
title = {Prediction of Student Performance in Abacus-Based Calculation Using Matrix Factorization},
year = {2020},
isbn = {9781450379502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386392.3399309},
doi = {10.1145/3386392.3399309},
abstract = {We conducted modeling of student learning status and tasks in abacus-based calculation by utilizing matrix factorization on student-generated learning data. The matrix consisted of performance scores on student-task pairs. We decomposed the raw matrix into two matrices, yielding the distributed representations of each student and each task. Prediction of student performance using those decomposed matrices achieved better results than baseline models that use the student biases and task biases. This suggests matrix factorization successfully extracted the interaction of multiple latent features of each task and each student's learning status in abacus-based calculation.},
booktitle = {Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {114–118},
numpages = {5},
keywords = {stem education, performance prediction in education, evaluation methodologies, data accumulation in education, abacus},
location = {Genoa, Italy},
series = {UMAP '20 Adjunct}
}

@inproceedings{10.1145/3468264.3468531,
author = {Bittner, Paul Maximilian and Schulthei\ss{}, Alexander and Th\"{u}m, Thomas and Kehrer, Timo and Young, Jeffrey M. and Linsbauer, Lukas},
title = {Feature trace recording},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468531},
doi = {10.1145/3468264.3468531},
abstract = {Tracing requirements to their implementation is crucial to all stakeholders of a software development process. When managing software variability, requirements are typically expressed in terms of features, a feature being a user-visible characteristic of the software. While feature traces are fully documented in software product lines, ad-hoc branching and forking, known as clone-and-own, is still the dominant way for developing multi-variant software systems in practice. Retroactive migration to product lines suffers from uncertainties and high effort because knowledge of feature traces must be recovered but is scattered across teams or even lost. We propose a semi-automated methodology for recording feature traces proactively, during software development when the necessary knowledge is present. To support the ongoing development of previously unmanaged clone-and-own projects, we explicitly deal with the absence of domain knowledge for both existing and new source code. We evaluate feature trace recording by replaying code edit patterns from the history of two real-world product lines. Our results show that feature trace recording reduces the manual effort to specify traces. Recorded feature traces could improve automation in change-propagation among cloned system variants and could reduce effort if developers decide to migrate to a product line.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1007–1020},
numpages = {14},
keywords = {software product lines, feature traceability, feature location, disciplined annotations, clone-and-own},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3277104.3277109,
author = {Gao, Zhipeng and Wang, Ting and Wang, Qian and Yang, Yang},
title = {Execution Time Prediction for Apache Spark},
year = {2018},
isbn = {9781450365406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277104.3277109},
doi = {10.1145/3277104.3277109},
abstract = {Apache Spark is a framework that being increasingly used in distributed data processing. However, the performance of a Spark application can vary considerably depending on many factors, including the input data, implementation of the program, Spark configuration parameters and cluster resources, making performance prediction becomes an arduous work. To address this challenge, in this paper, we design a two-steps prediction framework with high prediction accuracy. The technical core is that each cluster of applications with similar performance behavior has a particular performance prediction model applying gradient boosting regression. The performance behavior is profiled using both CPU and memory utilization series. It adapts to ad-hoc applications by simulating the execution using limited amount of sample input data, matching the resource utilization signature with history applications, and predicting execution time using corresponding performance model. Experiment evaluates that the framework can predict execution time for ad-hoc applications with high accuracy and efficiency.},
booktitle = {Proceedings of the 2018 International Conference on Computing and Big Data},
pages = {47–51},
numpages = {5},
keywords = {Performance Modeling, Machine Learning, Execution Time Prediction, Apache Spark},
location = {Charleston, SC, USA},
series = {ICCBD '18}
}

@article{10.1016/j.cose.2021.102381,
author = {ter Beek, Maurice H. and Legay, Axel and Lluch Lafuente, Alberto and Vandin, Andrea},
title = {Quantitative Security Risk Modeling and Analysis with RisQFLan},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {109},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102381},
doi = {10.1016/j.cose.2021.102381},
journal = {Comput. Secur.},
month = oct,
numpages = {23},
keywords = {Formal analysis tools, Statistical model checking, Probabilistic model checking, Attack-defense trees, Graph-based security risk models}
}

@inproceedings{10.1145/1693453.1693493,
author = {Zhai, Jidong and Chen, Wenguang and Zheng, Weimin},
title = {PHANTOM: predicting performance of parallel applications on large-scale parallel machines using a single node},
year = {2010},
isbn = {9781605588773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1693453.1693493},
doi = {10.1145/1693453.1693493},
abstract = {For designers of large-scale parallel computers, it is greatly desired that performance of parallel applications can be predicted at the design phase. However, this is difficult because the execution time of parallel applications is determined by several factors, including sequential computation time in each process, communication time and their convolution. Despite previous efforts, it remains an open problem to estimate sequential computation time in each process accurately and efficiently for large-scale parallel applications on non-existing target machines.This paper proposes a novel approach to predict the sequential computation time accurately and efficiently. We assume that there is at least one node of the target platform but the whole target system need not be available. We make two main technical contributions. First, we employ deterministic replay techniques to execute any process of a parallel application on a single node at real speed. As a result, we can simply measure the real sequential computation time on a target node for each process one by one. Second, we observe that computation behavior of processes in parallel applications can be clustered into a few groups while processes in each group have similar computation behavior. This observation helps us reduce measurement time significantly because we only need to execute representative parallel processes instead of all of them.We have implemented a performance prediction framework, called PHANTOM, which integrates the above computation-time acquisition approach with a trace-driven network simulator. We validate our approach on several platforms. For ASCI Sweep3D, the error of our approach is less than 5% on 1024 processor cores. Compared to a recent regression-based prediction approach, PHANTOM presents better prediction accuracy across different platforms.},
booktitle = {Proceedings of the 15th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {305–314},
numpages = {10},
keywords = {trace-driven simulation, performance prediction, parallel application, deterministic replay},
location = {Bangalore, India},
series = {PPoPP '10}
}

@inproceedings{10.1109/COMPSACW.2014.116,
author = {Nikravesh, Ali Yadavar and Ajila, Samuel A. and Lung, Chung-Horng},
title = {Measuring Prediction Sensitivity of a Cloud Auto-scaling System},
year = {2014},
isbn = {9781479935789},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSACW.2014.116},
doi = {10.1109/COMPSACW.2014.116},
abstract = {Elasticity is one of the key benefits of cloud computing which helps customers reduce the cost. Although elasticity is beneficiary in terms of cost, obligation of maintaining Service Level Agreements leads to necessity in dealing with the cost-performance trade-off. Proactive auto-scaling is an efficient approach to overcome this problem. In this approach scaling actions are generated based on prediction results. Recently, several research studies have been focusing on improving prediction accuracy in order to improve the efficiency of auto-scaling mechanisms. However, the sensitivity of auto-scaling mechanisms to the prediction results is neglected in the domain. In this work we have investigated the sensitivity of auto-scaling mechanisms to the prediction results by evaluating the influence of performance predictions accuracy on the auto-scaling actions. Specifically, we have compared actions of threshold based scaling techniques which are generated based on Support Vector Machine (SVM) and Neural Networks (NN) predictions. Our experimental results show that although SVM is more accurate than NN, scaling decisions made by the two algorithms are identical in 91.5% of the time. Furthermore, we have shown that the optimal training duration for SVM and NN is about 60% of experiment duration.},
booktitle = {Proceedings of the 2014 IEEE 38th International Computer Software and Applications Conference Workshops},
pages = {690–695},
numpages = {6},
keywords = {Resource provisioning, Performance prediction, Machine learning, Cloud computing},
series = {COMPSACW '14}
}

@inproceedings{10.1145/2556624.2556625,
author = {Seidl, Christoph and Schaefer, Ina and A\ss{}mann, Uwe},
title = {Capturing variability in space and time with hyper feature models},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556625},
doi = {10.1145/2556624.2556625},
abstract = {Software product lines (SPLs) and software ecosystems (SECOs) are approaches to capturing families of closely related software systems in terms of common and variable functionality. SPLs and especially SECOs are subject to evolution to adapt to new or changed requirements resulting in different versions of the software family and its variable assets. These versions may have to be maintained and used for products even after they were superseded by newer versions. Variability models describing valid combinations of variable assets, such as feature models, capture variability in space (configuration), but not variability in time (evolution) making it impossible to respect versions of variable assets in product definitions on a conceptual level. In this paper, we propose Hyper Feature Models (HFMs) explicitly providing feature versions as configurable units for product definition. Furthermore, we provide a version-aware constraint language to specify dependencies between features and ranges of feature versions as well as a procedure to automatically select valid combinations of versions for a pre-configuration of features. We demonstrate our approach in a case study.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {8},
keywords = {version, variability in time, software product line (SPL), software ecosystem (SECO), hyper feature model (HFM), evolution, constraint},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/3106237.3106273,
author = {Oh, Jeho and Batory, Don and Myers, Margaret and Siegmund, Norbert},
title = {Finding near-optimal configurations in product lines by random sampling},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106273},
doi = {10.1145/3106237.3106273},
abstract = {Software Product Lines (SPLs) are highly configurable systems. This raises the challenge to find optimal performing configurations for an anticipated workload. As SPL configuration spaces are huge, it is infeasible to benchmark all configurations to find an optimal one. Prior work focused on building performance models to predict and optimize SPL configurations. Instead, we randomly sample and recursively search a configuration space directly to find near-optimal configurations without constructing a prediction model. Our algorithms are simpler and have higher accuracy and efficiency.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {61–71},
numpages = {11},
keywords = {software product lines, searching configuration spaces, finding optimal configurations},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/2597652.2597679,
author = {Costa, Lauro Beltr\~{a}o and Al-Kiswany, Samer and Yang, Hao and Ripeanu, Matei},
title = {Supporting storage configuration for I/O intensive workflows},
year = {2014},
isbn = {9781450326421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597652.2597679},
doi = {10.1145/2597652.2597679},
abstract = {System provisioning, resource allocation, and system configuration decisions for I/O-intensive workflow applications are complex even for expert users. Users face choices at multiple levels: allocating resources to individual sub-systems (e.g., the application layer, the storage layer) and configuring each of these optimally (e.g., replication level, chunk size, caching policies in case of storage) all having a large impact on overall application performance. This paper presents our progress on addressing the problem of supporting these provisioning, allocation and configuration decisions for workflow applications. To enable selecting a good choice in a reasonable time, we propose an approach that accelerates the exploration of the configuration space based on a low-cost performance predictor that estimates total execution time of a workflow application in a given setup. Our evaluation shows that: (i) the predictor is effective in identifying the desired system configuration, (ii) it can scale to model a workflow application run on an entire cluster, while (iii) using over 2000x less resources (machines x time) than running the actual application.},
booktitle = {Proceedings of the 28th ACM International Conference on Supercomputing},
pages = {191–200},
numpages = {10},
keywords = {performance prediction, distributed storage systems},
location = {Munich, Germany},
series = {ICS '14}
}

@article{10.1016/j.future.2010.09.004,
author = {Seneviratne, Sena and Levy, David C.},
title = {Task profiling model for load profile prediction},
year = {2011},
issue_date = {March, 2011},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {3},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2010.09.004},
doi = {10.1016/j.future.2010.09.004},
abstract = {The accurate prediction of load profiles of future job tasks on the nodes of a cluster or grid supplies vital information for the users to make CPU/Disk resource usage decisions. At present, the Unix five-second host load is collected and used to predict the host loads, but forecasting can be improved if CPU and Disk load data are collected separately for each user on each host. The Free Load Profile or footprint of a job task on a load free node is a necessary input to the proposed Performance Prediction Model. To this end, the Task Profiling Model for Load Profile Prediction is proposed, which forecasts the load profiles of job tasks of individual machines based on current and historical data. The data is collected by agents running on the nodes of the cluster/grid. The data so obtained aids in choosing the most suitable set of computers for the deployment of the tasks in time optimal manner. Also, accurately predicted load profiles are useful inputs to the cost prediction models. The Task Profiling Model has been implemented in a software framework and evaluated for its prediction accuracy.},
journal = {Future Gener. Comput. Syst.},
month = mar,
pages = {245–255},
numpages = {11},
keywords = {Task profiling model, Performance prediction, Load average, Grid computing, Free load profile, Division of load, Cluster computing}
}

@article{10.1007/s10489-020-01776-3,
author = {Injadat, MohammadNoor and Moubayed, Abdallah and Nassif, Ali Bou and Shami, Abdallah},
title = {Multi-split optimized bagging ensemble model selection for multi-class educational data mining},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {50},
number = {12},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01776-3},
doi = {10.1007/s10489-020-01776-3},
abstract = {Predicting students’ academic performance has been a research area of interest in recent years, with many institutions focusing on improving the students’ performance and the education quality. The analysis and prediction of students’ performance can be achieved using various data mining techniques. Moreover, such techniques allow instructors to determine possible factors that may affect the students’ final marks. To that end, this work analyzes two different undergraduate datasets at two different universities. Furthermore, this work aims to predict the students’ performance at two stages of course delivery (20% and 50% respectively). This analysis allows for properly choosing the appropriate machine learning algorithms to use as well as optimize the algorithms’ parameters. Furthermore, this work adopts a systematic multi-split approach based on Gini index and p-value. This is done by optimizing a suitable bagging ensemble learner that is built from any combination of six potential base machine learning algorithms. It is shown through experimental results that the posited bagging ensemble models achieve high accuracy for the target group for both datasets.},
journal = {Applied Intelligence},
month = dec,
pages = {4506–4528},
numpages = {23},
keywords = {Gini Index, Optimized Bagging Ensemble Learning Model Selection, Student Performance Prediction, e-Learning}
}

@inproceedings{10.1145/3275245.3275261,
author = {Campos, Denivan and Lima, Crescencio and do Carmo Machado, Ivan},
title = {MERCI: A Method to Evaluate Combinatorial Interaction Testing Tools for Software Product Lines},
year = {2018},
isbn = {9781450365659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275245.3275261},
doi = {10.1145/3275245.3275261},
abstract = {Testing a system is a routine activity, and it plays an important role in the software quality assurance process. However, testing highly-configurable systems, such as Software Product Lines (SPL), is a rather complex activity, due to the presence of variability in its engineering process, which increases the number of product configurations to test. The underlying idea to make testing feasible in SPL engineering is to select a small but representative subset of products to test, by employing techniques such as combinatorial interaction testing (CIT). This paper presents Method to Evaluate Combinatorial Interaction (MERCI), a novel method to evaluate the adequacy of existing CIT tools for SPL engineering, with respect to three measures: defect detection, test coverage, and test execution length. We carried out an empirical evaluation to compare four CIT tools: ACTS, CATS, PICTMaster and VPTag. The results show that the method may serve as an affordable strategy to evaluate how the CIT tools could behave in an SPL testing scenario.},
booktitle = {Proceedings of the XVII Brazilian Symposium on Software Quality},
pages = {151–159},
numpages = {9},
keywords = {Testing Tools, Software Testing Strategies, Software Product Lines, Combinatorial Interaction Testing},
location = {Curitiba, Brazil},
series = {SBQS '18}
}

@inproceedings{10.1109/ICSE-C.2017.154,
author = {Pereira, Juliana Alves},
title = {Runtime collaborative-based configuration of software product lines},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.154},
doi = {10.1109/ICSE-C.2017.154},
abstract = {Software Product Line (SPL) configuration practices have been employed by industries as a mass customization process. However, the inherent variability of large SPLs leads to configuration spaces of exponential sizes. Thus, scalability and performance concerns start to be an issue when facing runtime environments, since it is usually infeasible to explore the entire configuration space exhaustively. In this context, the aim of my research is therefore to propose an efficient collaborative-based runtime approach that relies on recommender techniques to provide accurate and scalable configurations to users. To demonstrate the efficiency of the proposed approach, I conduct series of experiments on real-world SPLs. In addition, I plan empirically verify through a user case study the usability of the proposed approach. My expected contribution is to support the adoption of SPL configuration practices in industrial scenarios.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {94–96},
numpages = {3},
keywords = {software product lines, recommender systems, configuration, collaborative-based recommendations},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@article{10.1177/1094342013507960,
author = {Che, Shuai and Skadron, Kevin},
title = {BenchFriend: Correlating the performance of GPU benchmarks},
year = {2014},
issue_date = {May       2014},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {28},
number = {2},
issn = {1094-3420},
url = {https://doi.org/10.1177/1094342013507960},
doi = {10.1177/1094342013507960},
abstract = {Graphics processing units GPUs have become an important platform for general-purpose computing, thanks to their high parallel throughput and high memory bandwidth. GPUs present significantly different architectures from CPUs and require specific mappings and optimizations to achieve high performance. This makes GPU workloads demonstrate application characteristics different from those of CPU workloads. It is critical for researchers to understand the first-order metrics that most influence GPU performance and scalability. Furthermore, methodologies and associated tools are needed to analyze and predict the performance of GPU applications and help guide users' purchasing decisions.In this work, we study the approach of predicting the performance of GPU applications by correlating them to existing workloads. One tenet of benchmark design, also a motivation of this paper, is that users should be given the capability to leverage standard workloads to infer the performance of applications of their interest. We first identify a set of important GPU application characteristics and then use them to predict performance of an arbitrary application by determining its most similar proxy benchmarks. We demonstrate the prediction methodology and conduct predictions with benchmarks from different suites to achieve better workload coverage. The experimental results show that we are able to achieve satisfactory performance predictions, although errors are higher for outlier applications. Finally, we discuss several considerations for systematically constructing future benchmark suites.},
journal = {Int. J. High Perform. Comput. Appl.},
month = may,
pages = {238–250},
numpages = {13},
keywords = {performance prediction, heterogeneous architectures., benchmarks, GPU, GPGPU}
}

@inproceedings{10.1109/ICSE43902.2021.00142,
author = {Nguyen, KimHao and Nguyen, ThanhVu},
title = {GenTree: Using Decision Trees to Learn Interactions for Configurable Software},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00142},
doi = {10.1109/ICSE43902.2021.00142},
abstract = {Modern software systems are increasingly designed to be highly configurable, which increases flexibility but can make programs harder to develop, test, and analyze, e.g., how configuration options are set to reach certain locations, what characterizes the configuration space of an interesting or buggy program behavior? We introduce GenTree, a new dynamic analysis that automatically learns a program's interactions---logical formulae that describe how configuration option settings map to code coverage. GenTree uses an iterative refinement approach that runs the program under a small sample of configurations to obtain coverage data; uses a custom classifying algorithm on these data to build decision trees representing interaction candidates; and then analyzes the trees to generate new configurations to further refine the trees and interactions in the next iteration. Our experiments on 17 configurable systems spanning 4 languages show that GenTree efficiently finds precise interactions using a tiny fraction of the configuration space.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1598–1609},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/2043932.2044009,
author = {Bellogin, Alejandro},
title = {Predicting performance in recommender systems},
year = {2011},
isbn = {9781450306836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2043932.2044009},
doi = {10.1145/2043932.2044009},
abstract = {Performance prediction has gained growing attention in the Information Retrieval field since the late nineties and has become an established research topic in the field. Our work restates the problem in the area of Recommender Systems, where it has barely been researched so far, despite being an appealing problem, as it enables an array of strategies for deciding when to deliver or hold back recommendations based on their foreseen accuracy. We investigate the adaptation and definition of different performance predictors based on the available user and item features. The properties of the predictor are empirically studied by checking the correlation of the predictor output with a performance measure. Then, we propose to introduce the performance predictor in a recommender system to produce a dynamic strategy. Depending on how the predictor is introduced we analyze two different problems: dynamic neighbor weighting in collaborative filtering and dynamic weighting of ensemble recommenders.},
booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
pages = {371–374},
numpages = {4},
keywords = {recommender systems, query clarity, performance prediction, hybrid recommender system},
location = {Chicago, Illinois, USA},
series = {RecSys '11}
}

@inproceedings{10.1109/ICWS.2013.19,
author = {Shen, Yuanhong and Zhu, Jianke and Wang, Xinyu and Cai, Liang and Yang, Xiaohu and Zhou, Bo},
title = {Geographic Location-Based Network-Aware QoS Prediction for Service Composition},
year = {2013},
isbn = {9780769550251},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICWS.2013.19},
doi = {10.1109/ICWS.2013.19},
abstract = {QoS-aware service composition intends to maximize the global QoS of a composite service while selecting candidate services from different providers with local and global QoS constraints. With more and more candidate services emerging from all over the world, the network delays often greatly impact the performance of the composite service, which are usually not easy to be collected before the composition. One remedy is to predict them for the composition. However, new issues occur in predicting network delay for the composition, including prediction accuracy and on-demand measures to new services, which affect the performance of network-aware composite services. To solve these critical challenges, in this paper, we take advantage of the geographic location information of candidate services. We propose a network-aware QoS (NQoS) model for the composite service. Based on that, we present a novel geographic location-based NQoS prediction approach before composition, and a NQoS re-prediction approach during the execution of the composite service. Extensive experiments are conducted on the real-world dataset collected from PlanetLab. Comparative experiment results reveal our approach facilitates to improve the prediction accuracy and predictability of the NQoS values, and increase global NQoS of the composite service while ensuring its reliability constraints.},
booktitle = {Proceedings of the 2013 IEEE 20th International Conference on Web Services},
pages = {66–74},
numpages = {9},
keywords = {re-selection, performance prediction, network, geographic location, QoS-aware service composition},
series = {ICWS '13}
}

@inproceedings{10.5555/3375069.3375078,
author = {Amannejad, Yasaman and Krishnamurthy, Diwakar and Far, Behrouz},
title = {Predicting Web Service Response Time Percentiles},
year = {2016},
isbn = {9783901882852},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Predicting Web service response time percentiles is often an important aspect of service level management exercises. Existing techniques can be very time consuming since they involve the manual construction of complex analytic or simulation models. To address this problem, we propose Prospective, a fully automated and data-driven approach for predicting Web service response time percentiles. Prospective relies on historical response time data collected from a Web service. Given a specification for workload expected at the Web service over a planning horizon, Prospective uses this historical data to offer predictions for response time percentiles of interest. At the core of Prospective is a lightweight simulator that uses collaborative filtering to estimate response time behaviour of the service based on behaviour observed historically. Results show that Prospective is able to predict various response time percentiles of interest with high accuracy for a wide variety of workloads.},
booktitle = {Proceedings of the 12th Conference on International Conference on Network and Service Management},
pages = {73–81},
numpages = {9},
keywords = {Software performance engineering, Response time percentile, Performance prediction, Machine learning},
location = {Montreal, Quebec, Canada},
series = {CNSM 2016}
}

@inproceedings{10.1109/ICSE.2017.58,
author = {Behringer, Benjamin and Palz, Jochen and Berger, Thorsten},
title = {PEoPL: projectional editing of product lines},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.58},
doi = {10.1109/ICSE.2017.58},
abstract = {The features of a software product line---a portfolio of system variants---can be realized using various implementation techniques (a.k.a., variability mechanisms). Each technique represents the software artifacts of features differently, typically classified into annotative (e.g., C preprocessor) and modular representations (e.g., feature modules), each with distinct advantages and disadvantages. Annotative representations are easy to realize, but annotations clutter source code and hinder program comprehension. Modular representations support comprehension, but are difficult to realize. Most importantly, to engineer feature artifacts, developers need to choose one representation and adhere to it for evolving and maintaining the same artifacts.We present PEoPL, an approach to combine the advantages of annotative and modular representations. When engineering a feature artifact, developers can choose the most-suited representation and even use different representations in parallel. PEoPL relies on separating a product line into an internal and external representation, the latter by providing editable projections used by the developers. We contribute a programming-language-independent internal representation of variability, five editable projections reflecting different variability representations, a supporting IDE, and a tailoring of PEoPL to Java. We evaluate PEoPL's expressiveness, scalability, and flexibility in eight Java-based product lines, finding that all can be realized, that projections are feasible, and that variant computation is fast (&lt;45ms on average for our largest subject Berkeley DB).},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {563–574},
numpages = {12},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@article{10.1145/3431731,
author = {Braun, Lorenz and Nikas, Sotirios and Song, Chen and Heuveline, Vincent and Fr\"{o}ning, Holger},
title = {A Simple Model for Portable and Fast Prediction of Execution Time and Power Consumption of GPU Kernels},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/3431731},
doi = {10.1145/3431731},
abstract = {Characterizing compute kernel execution behavior on GPUs for efficient task scheduling is a non-trivial task. We address this with a simple model enabling portable and fast predictions among different GPUs using only hardware-independent features. This model is built based on random forests using 189 individual compute kernels from benchmarks such as Parboil, Rodinia, Polybench-GPU, and SHOC. Evaluation of the model performance using cross-validation yields a median Mean Average Percentage Error (MAPE) of 8.86–52.0% for time and 1.84–2.94% for power prediction across five different GPUs, while latency for a single prediction varies between 15 and 108 ms.},
journal = {ACM Trans. Archit. Code Optim.},
month = dec,
articleno = {7},
numpages = {25},
keywords = {random forest, profiling, power prediction, portable performance prediction, cross-validation, GPU computing, GPGPU, Execution time prediction}
}

@article{10.1007/s10922-017-9426-z,
author = {Stadler, Rolf and Pasquini, Rafael and Fodor, Viktoria},
title = {Learning from Network Device Statistics},
year = {2017},
issue_date = {October   2017},
publisher = {Plenum Press},
address = {USA},
volume = {25},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-017-9426-z},
doi = {10.1007/s10922-017-9426-z},
abstract = {We estimate end-to-end service metrics from network device statistics. Our approach is based upon statistical, supervised learning, whereby the mapping from device-level to service-level metrics is learned from observations, i.e., through monitoring the system. The approach enables end-to-end performance prediction without requiring an explicit model of the system, which is different from traditional engineering techniques that use stochastic modeling and simulation. The fact that end-to-end service metrics can be estimated from local network statistics with good accuracy in the scenarios we consider suggests that service-level properties are "encoded" in network-level statistics. We show that the set of network statistics needed for estimation can be reduced to a set of measurements along the network path between client and service backend, with little loss in estimation accuracy. The reported work is largely experimental and its results have been obtained through testbed measurements from a video streaming service and a KV store over an OpenFlow network .},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {672–698},
numpages = {27},
keywords = {Statistical learning, OpenFlow, Network management, Network analytics, Machine learning, Feature selection, End-to-end performance Prediction}
}

@article{10.1016/j.knosys.2019.02.013,
author = {Yuan, Jin and Hou, Xingxing and Xiao, Yaoqiang and Cao, Da and Guan, Weili and Nie, Liqiang},
title = {Multi-criteria active deep learning for image classification},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {172},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.02.013},
doi = {10.1016/j.knosys.2019.02.013},
journal = {Know.-Based Syst.},
month = may,
pages = {86–94},
numpages = {9},
keywords = {Image classification, Multi-criteria, Active learning, Deep neural network}
}

@article{10.1007/s10270-013-0335-7,
author = {Hauck, Michael and Kuperberg, Michael and Huber, Nikolaus and Reussner, Ralf},
title = {Deriving performance-relevant infrastructure properties through model-based experiments with Ginpex},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0335-7},
doi = {10.1007/s10270-013-0335-7},
abstract = {To predict the performance of an application, it is crucial to consider the performance of the underlying infrastructure. Thus, to yield accurate prediction results, performance-relevant properties and behaviour of the infrastructure have to be integrated into performance models. However, capturing these properties is a cumbersome and error-prone task, as it requires carefully engineered measurements and experiments. Existing approaches for creating infrastructure performance models require manual coding of these experiments, or ignore the detailed properties in the models. The contribution of this paper is the Goal-oriented INfrastructure Performance EXperiments (Ginpex) approach, which introduces goal-oriented and model-based specification and generation of executable performance experiments for automatically detecting and quantifying performance-relevant infrastructure properties. Ginpex provides a metamodel for experiment specification and comes with predefined experiment templates that provide automated experiment execution on the target platform and also automate the evaluation of the experiment results. We evaluate Ginpex using three case studies, where experiments are executed to quantify various infrastructure properties.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1345–1365},
numpages = {21},
keywords = {Performance prediction, Metamodelling, Measurements, Infrastructure, Experiments, Deriving infrastructure properties}
}

@inproceedings{10.1145/1596473.1596482,
author = {Rathfelder, Christoph and Kounev, Samuel},
title = {Modeling event-driven service-oriented systems using the palladio component model},
year = {2009},
isbn = {9781605587097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1596473.1596482},
doi = {10.1145/1596473.1596482},
abstract = {The use of event-based communication within a Service-Oriented Architecture promises several benefits including more loosely-coupled services and better scalability. However, the loose coupling of services makes it difficult for system developers to estimate the behavior and performance of systems composed of multiple services. Most existing performance prediction techniques for systems using event-based communication require specialized knowledge to build the necessary prediction models. Furthermore, general purpose design-oriented performance models for component-based systems provide limited support for modeling event-based communication. In this paper, we propose an extension of the Palladio Component Model (PCM) that provides natural support for modeling event-based communication. We show how this extension can be exploited to model event-driven service-oriented systems with the aim to evaluate their performance and scalability.},
booktitle = {Proceedings of the 1st International Workshop on Quality of Service-Oriented Software Systems},
pages = {33–38},
numpages = {6},
keywords = {software architecture, performance prediction, event-driven communication},
location = {Amsterdam, The Netherlands},
series = {QUASOSS '09}
}

@article{10.5555/2592907.2592915,
author = {Bashir, Shariq},
title = {Combining pre-retrieval query quality predictors using genetic programming},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {40},
number = {3},
issn = {0924-669X},
abstract = {Predicting the effectiveness of queries plays an important role in information retrieval. In recent years, a number of methods are proposed for this task, however, there has been little work done on combining multiple predictors. Previous studies on combining multiple predictors rely on non-backtracking based machine learning methods. These studies show minor improvement over single predictors due to the limitation of non-backtracking. This paper discusses work on using machine learning to automatically generate an effective predictors' combination for query performance prediction. This task is referred to as--learning to predict for query performance prediction in the field. In this paper, a learning method, PredGP, is presented to address this task. PredGP employs genetic programming to learn a predictor by combining various pre-retrieval predictors. The proposed method is evaluated using the TREC Chemical Prior-Art Retrieval Task dataset and found to be significantly better than single predictors.},
journal = {Applied Intelligence},
month = apr,
pages = {525–535},
numpages = {11},
keywords = {Query performance prediction, Pre-retrieval predictors, Learning to rank, Intelligent information retrieval, Genetic programming}
}

@inproceedings{10.1007/978-3-642-13388-6_6,
author = {Cetintas, Suleyman and Si, Luo and Xin, Yan Ping and Hord, Casey},
title = {Predicting correctness of problem solving in ITS with a temporal collaborative filtering approach},
year = {2010},
isbn = {3642133878},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13388-6_6},
doi = {10.1007/978-3-642-13388-6_6},
abstract = {Collaborative filtering (CF) is a technique that utilizes how users are associated with items in a target application and predicts the utility of items for a particular user. Temporal collaborative filtering (temporal CF) is a time-sensitive CF approach that considers the change in user-item interactions over time. Despite its capability to deal with dynamic educational applications with rapidly changing user-item interactions, there is no prior research of temporal CF on educational tasks. This paper proposes a temporal CF approach to automatically predict the correctness of students' problem solving in an intelligent math tutoring system. Unlike traditional user-item interactions, a student may work on the same problem multiple times, and there are usually multiple interactions for a student-problem pair. The proposed temporal CF approach effectively utilizes information coming from multiple interactions and is compared to i) a traditional CF approach, ii) a temporal CF approach that uses a sliding-time-window but ignores old data and multiple interactions and iii) a combined temporal CF approach that uses a sliding-time-window together with multiple interactions. An extensive set of experiment results show that using multiple-interactions significantly improves the prediction accuracy while using sliding-time-windows doesn't make a significant difference.},
booktitle = {Proceedings of the 10th International Conference on Intelligent Tutoring Systems - Volume Part I},
pages = {15–24},
numpages = {10},
keywords = {temporal collaborative filtering, performance prediction, intelligent tutoring systems},
location = {Pittsburgh, PA},
series = {ITS'10}
}

@inproceedings{10.1007/978-3-030-72699-7_38,
author = {Jankovic, Anja and Eftimov, Tome and Doerr, Carola},
title = {Towards Feature-Based Performance Regression Using Trajectory Data},
year = {2021},
isbn = {978-3-030-72698-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-72699-7_38},
doi = {10.1007/978-3-030-72699-7_38},
abstract = {Black-box optimization is a very active area of research, with many new algorithms being developed every year. This variety is needed, on the one hand, since different algorithms are most suitable for different types of optimization problems. But the variety also poses a meta-problem: which algorithm to choose for a given problem at hand? Past research has shown that per-instance algorithm selection based on exploratory landscape analysis (ELA) can be an efficient mean to tackle this meta-problem. Existing approaches, however, require the approximation of problem features based on a significant number of samples, which are typically selected through uniform sampling or Latin Hypercube Designs. The evaluation of these points is costly, and the benefit of an ELA-based algorithm selection over a default algorithm must therefore be significant in order to pay off. One could hope to by-pass the evaluations for the feature approximations by using the samples that a default algorithm would anyway perform, i.e., by using the points of the default algorithm’s trajectory. We analyze in this paper how well such an approach can work. Concretely, we test how accurately trajectory-based ELA approaches can predict the final solution quality of the CMA-ES after a fixed budget of function evaluations. We observe that the loss of trajectory-based predictions can be surprisingly small compared to the classical global sampling approach, if the remaining budget for which solution quality shall be predicted is not too large. Feature selection, in contrast, did not show any advantage in our experiments and rather led to worsened prediction accuracy. The inclusion of state variables of CMA-ES only has a moderate effect on the prediction accuracy.},
booktitle = {Applications of Evolutionary Computation: 24th International Conference, EvoApplications 2021, Held as Part of EvoStar 2021, Virtual Event, April 7–9, 2021, Proceedings},
pages = {601–617},
numpages = {17},
keywords = {Feature selection, Performance regression, Black-box optimization, Automated algorithm selection, Exploratory landscape analysis}
}

@article{10.1007/s11235-014-9908-1,
author = {Varga, Mih\'{a}ly and Badiu, Mihai-Alin and Bota, Vasile},
title = {Link adaptation algorithm for distributed coded transmissions in cooperative OFDMA systems},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {59},
number = {4},
issn = {1018-4864},
url = {https://doi.org/10.1007/s11235-014-9908-1},
doi = {10.1007/s11235-014-9908-1},
abstract = {This paper proposes a link adaptation algorithm for cooperative transmissions in the down-link connection of an OFDMA-based wireless system. The algorithm aims at maximizing the spectral efficiency of a relay-aided communication link, while satisfying the block error rate constraints at both the relay and the destination nodes. The optimal solution would be to perform an exhaustive search over a high-dimensional space determined by all possible combinations of modulations, code rates and information block lengths on the individual channels of the cooperative link; clearly, such an approach has an intractable complexity. Our solution is to use a link performance prediction method and a trellis diagram representation such that the resulting algorithm outputs the link configuration that conveys as many information bits as possible and also fulfilling the block error rate constraints. The proposed link adaptation algorithm has linear complexity with the number of available resource blocks, while still provides a very good performance, as shown by simulation results.},
journal = {Telecommun. Syst.},
month = aug,
pages = {477–489},
numpages = {13},
keywords = {Link performance prediction, Link adaptation, Distributed channel coding, Cooperative wireless communications}
}

@inproceedings{10.1145/3422392.3422399,
author = {Lima, Crescencio and Machado, Ivan and Galster, Matthias and von Flach G. Chavez, Christina},
title = {Recovering Architectural Variability from Source Code},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422399},
doi = {10.1145/3422392.3422399},
abstract = {Context: Systematic variability management helps efficiently manage commonalities and differences in software systems (e.g., in software product lines and families). This enables the reuse of development artifacts in organizations and increases the quality of product variants. In software product lines, the product line architecture (PLA) is the core architecture for all product line variants. In practice, software architectures are often not documented in detail. Architecture recovery techniques can recover a system's architecture from development artifacts (e.g., source code). To recover the architecture of product lines, we need recovery techniques that are able to identify variability from different sources. Goal: We present SAVaR, an approach to recover architectural variability from the source code of product variants of a product line. SAVaR aims to help developers to (a) create architectural documentation for a product line, and (b) understand and improve the implementation of variability. SAVaR identifies the smallest subset of architectural information that is common across products of a product line. To limit the explosion of variability (and hence the complexity of architecture documentation) in the product line architecture, SAVaR allows architects to exclude architecture elements that appear in only a few product variants. Method: We performed an exploratory study with SAVaR to recover the architectures in ten academic product line projects. We verified how the elimination of exclusive optional modules improves the results of SAVaR. Results: The results showed that SAVaR is able to present improvements for the recovered PLAs and it helped to identify that some projects maintained the variability under control.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {808–817},
numpages = {10},
keywords = {Product Line Architecture, Product Line Architecture Recovery, Software Product Lines, Variability},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.5555/3021426.3021437,
author = {Rygielski, Piotr and Seliuchenko, Marian and Kounev, Samuel},
title = {Modeling and Prediction of Software-Defined Networks Performance using Queueing Petri Nets},
year = {2016},
isbn = {9781631901201},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {Using various modeling and simulation approaches for predicting network performance requires extensive experience and involves a number of time consuming manual steps regarding each of the modeling formalisms. Descartes Network Infrastructure (DNI) is a data center network performance modeling approach that addresses this challenge by offering multiple performance models but requiring to use only a single modeling language. In this paper, we thoroughly extend DNI to support new networking paradigms like, among others, Software-Defined Networking (SDN) and Network-Function Virtualization (NFV). Additionally, we demonstrate how SDN-based networks can be modeled using DNI and how are they transformed later into Queueing Petri Nets (QPN) using a model-to-model transformation. In the analysis of the performance prediction accuracy, we show that automatically generated QPN models represent the performance of heterogeneous SDN hardware with maximal prediction accuracy error of 12%.},
booktitle = {Proceedings of the 9th EAI International Conference on Simulation Tools and Techniques},
pages = {66–75},
numpages = {10},
keywords = {software-defined networking, performance modeling, meta-modeling, data center networks},
location = {Prague, Czech Republic},
series = {SIMUTOOLS'16}
}

@inproceedings{10.1145/3001867.3001874,
author = {Queiroz, Rodrigo and Berger, Thorsten and Czarnecki, Krzysztof},
title = {Towards predicting feature defects in software product lines},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001874},
doi = {10.1145/3001867.3001874},
abstract = {Defect-prediction techniques can enhance the quality assurance activities for software systems. For instance, they can be used to predict bugs in source files or functions. In the context of a software product line, such techniques could ideally be used for predicting defects in features or combinations of features, which would allow developers to focus quality assurance on the error-prone ones. In this preliminary case study, we investigate how defect prediction models can be used to identify defective features using machine-learning techniques. We adapt process metrics and evaluate and compare three classifiers using an open-source product line. Our results show that the technique can be effective. Our best scenario achieves an accuracy of 73 % for accurately predicting features as defective or clean using a Naive Bayes classifier. Based on the results we discuss directions for future work.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {58–62},
numpages = {5},
keywords = {software product lines, features, defect prediction},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@inproceedings{10.1145/2396716.2396725,
author = {Johansen, Martin F. and Haugen, \O{}ystein and Fleurey, Franck},
title = {Bow tie testing: a testing pattern for product lines},
year = {2011},
isbn = {9781450313025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396716.2396725},
doi = {10.1145/2396716.2396725},
abstract = {Verification of highly configurable systems poses a significant challenge, the challenge of knowing that every configuration works when there often are intractably many different configurations. When a homogeneous abstraction layer has many mutually exclusive alternative implementations, we might, according to the polymorphic server test pattern, test these implementations using one test suite targeted towards the abstraction layer which is then run for each concrete implementation of the abstraction layer. But, the pattern does not handle interaction testing. Combinatorial interaction testing is one of the more promising techniques for doing interaction testing of a software product line. The bow tie testing pattern describes how the configurations which differ only in the implementation layer require one test suite. In addition, comparing the execution results of one product with another provides for a test oracle. The pattern reduces the effort of testing a highly configurable system without reducing the error detection capabilities provided by ordinary combinatorial interaction testing. We present an example of a subset of the Eclipse IDE product line, and show that only 20 test suites is required to test 41 products, a significant reduction.},
booktitle = {Proceedings of the 16th European Conference on Pattern Languages of Programs},
articleno = {9},
numpages = {13},
keywords = {software product lines},
location = {Irsee, Germany},
series = {EuroPLoP '11}
}

@article{10.1007/s10664-010-9142-8,
author = {Martens, Anne and Koziolek, Heiko and Prechelt, Lutz and Reussner, Ralf},
title = {From monolithic to component-based performance evaluation of software architectures},
year = {2011},
issue_date = {October   2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-010-9142-8},
doi = {10.1007/s10664-010-9142-8},
abstract = {Model-based performance evaluation methods for software architectures can help architects to assess design alternatives and save costs for late life-cycle performance fixes. A recent trend is component-based performance modelling, which aims at creating reusable performance models; a number of such methods have been proposed during the last decade. Their accuracy and the needed effort for modelling are heavily influenced by human factors, which are so far hardly understood empirically. Do component-based methods allow to make performance predictions with a comparable accuracy while saving effort in a reuse scenario? We examined three monolithic methods (SPE, umlPSI, Capacity Planning (CP)) and one component-based performance evaluation method (PCM) with regard to their accuracy and effort from the viewpoint of method users. We conducted a series of three experiments (with different levels of control) involving 47 computer science students. In the first experiment, we compared the applicability of the monolithic methods in order to choose one of them for comparison. In the second experiment, we compared the accuracy and effort of this monolithic and the component-based method for the model creation case. In the third, we studied the effort reduction from reusing component-based models. Data were collected based on the resulting artefacts, questionnaires and screen recording. They were analysed using hypothesis testing, linear models, and analysis of variance. For the monolithic methods, we found that using SPE and CP resulted in accurate predictions, while umlPSI produced over-estimates. Comparing the component-based method PCM with SPE, we found that creating reusable models using PCM takes more (but not drastically more) time than using SPE and that participants can create accurate models with both techniques. Finally, we found that reusing PCM models can save time, because effort to reuse can be explained by a model that is independent of the inner complexity of a component. The tasks performed in our experiments reflect only a subset of the actual activities when applying model-based performance evaluation methods in a software development process. Our results indicate that sufficient prediction accuracy can be achieved with both monolithic and component-based methods, and that the higher effort for component-based performance modelling will indeed pay off when the component models incorporate and hide a sufficient amount of complexity.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {587–622},
numpages = {36},
keywords = {Software architecture, Performance prediction, Performance modelling, Performance evaluation, Empirical study}
}

@inproceedings{10.1145/2806777.2806843,
author = {Coppa, Emilio and Finocchi, Irene},
title = {On data skewness, stragglers, and MapReduce progress indicators},
year = {2015},
isbn = {9781450336512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806777.2806843},
doi = {10.1145/2806777.2806843},
abstract = {We tackle the problem of predicting the performance of MapReduce applications designing accurate progress indicators, which keep programmers informed on the percentage of completed computation time during the execution of a job. This is especially important in pay-as-you-go cloud environments, where slow jobs can be aborted in order to avoid excessive costs. Performance predictions can also serve as a building block for several profile-guided optimizations. By assuming that the running time depends linearly on the input size, state-of-the-art techniques can be seriously harmed by data skewness, load unbalancing, and straggling tasks. We thus design a novel profile-guided progress indicator, called NearestFit, that operates without the linear hypothesis assumption in a fully online way (i.e., without resorting to profile data collected from previous executions). NearestFit exploits a careful combination of nearest neighbor regression and statistical curve fitting techniques. Fine-grained profiles required by our theoretical progress model are approximated through space- and time-efficient data streaming algorithms. We implemented NearestFit on top of Hadoop 2.6.0. An extensive empirical assessment over the Amazon EC2 platform on a variety of benchmarks shows that its accuracy is very good, even when competitors incur non-negligible errors and wide prediction fluctuations.},
booktitle = {Proceedings of the Sixth ACM Symposium on Cloud Computing},
pages = {139–152},
numpages = {14},
keywords = {progress indicators, performance profiling, performance prediction, hadoop, data skewness, MapReduce},
location = {Kohala Coast, Hawaii},
series = {SoCC '15}
}

@article{10.5555/3447307.3447308,
author = {Amend, Jack J and Spurlock, Scott},
title = {Improving machine learning fairness with sampling and adversarial learning},
year = {2021},
issue_date = {January 2021},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {36},
number = {5},
issn = {1937-4771},
abstract = {Machine learning approaches learn models based on the statistical properties of training data. Learned models may be unfair due to bias inherent in the training data or because of spurious correlations based on sensitive attributes such as race or sex. This type of bias can lead to detrimental outcomes in important applications, including prison sentencing, credit scoring, and loan approvals. In this work, we perform a comparative study of techniques to increase the fairness of machine learning based classification with respect to a sensitive attribute. We assess the effectiveness of several data sampling strategies as well as of a variety of neural network architectures, including conventional and adversarial networks. Results are evaluated in terms of metrics measuring both classification accuracy and fairness. We find that model architecture and sampling strategy can both greatly affect metrics of fairness. We also find that there is no single best combination that should be used; the particular problem domain should drive the selection of neural network architecture and sampling strategy.},
journal = {J. Comput. Sci. Coll.},
month = jan,
pages = {14–23},
numpages = {10}
}

@inproceedings{10.1145/2245276.2245458,
author = {Griffith, Josephine and O'Riordan, Colm and Sorensen, Humphrey},
title = {Investigations into user rating information and predictive accuracy in a collaborative filtering domain},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2245458},
doi = {10.1145/2245276.2245458},
abstract = {The work described in this paper extracts user rating information from collaborative filtering datasets, and for each dataset uses a supervised machine learning approach to identify if there is an underlying relationship between rating information in the dataset and the expected accuracy of recommendations returned by the system. The underlying relationship is represented by decision tree rules. The rules can be used to indicate the predictive accuracy of the system for users of the system. Thus a user can know in advance of recommendation the level of accuracy to expect from the collaborative filtering system and may have more (or less) confidence in the recommendations produced. The experiment outlined in this paper aims to test the accuracy of the rules produced using three different datasets. Results show good accuracy can be found for all three datasets.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {937–942},
numpages = {6},
keywords = {performance prediction, machine learning, collaborative filtering},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/3141848.3141853,
author = {Schuster, Sven and Seidl, Christoph and Schaefer, Ina},
title = {Towards a development process for maturing Delta-oriented software product lines},
year = {2017},
isbn = {9781450355186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141848.3141853},
doi = {10.1145/3141848.3141853},
abstract = {A Software Product Line (SPL) exploits reuse-in-the-large to enable customization by explicitly modeling commonalities and variabilities of closely related software systems. Delta-Oriented Programming (DOP) is a flexible implementation approach to SPL engineering, which transforms an existing core product to another desired product by applying transformation operations. By capturing product alterations related to configurable functionality within delta modules, DOP closely resembles a natural process of software development, which proves beneficial in early stages of development. However, increasing complexity for a growing SPL in later development stages caused by the invasiveness of DOP drastically impairs maintenance and extensibility. Hence, a process utilizing the invasiveness of DOP in early development stages and restricting it in later stages would allow developers to mature growing delta-oriented SPLs. Moreover, ever-increasing complexity requires means to migrate into less invasive development approaches that are more suited for large-scale configurable applications. To this end, we propose a development process for delta-oriented SPLs including explicit variability points, metrics and refactorings as well as a semi-automatic reengineering of a delta-oriented SPL into a development approach based on blackbox-components. In this paper, we sketch this development process with its constituents and point out required research essential for successfully maturing a delta-oriented SPL.},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Workshop on Feature-Oriented Software Development},
pages = {41–50},
numpages = {10},
keywords = {Software Product Lines, Delta-Oriented Programming},
location = {Vancouver, BC, Canada},
series = {FOSD 2017}
}

@inproceedings{10.1145/3350768.3350774,
author = {Souza, Iuri Santos and Machado, Ivan and Seaman, Carolyn and Gomes, Gecynalda and Chavez, Christina and de Almeida, Eduardo Santana and Masiero, Paulo},
title = {Investigating Variability-aware Smells in SPLs: An Exploratory Study},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350774},
doi = {10.1145/3350768.3350774},
abstract = {Variability-aware smell is a concept referring to artifact shortcomings in the context of highly-configurable systems that can degrade aspects such as program comprehension, maintainability, and evolvability. To the best of our knowledge, there is very little evidence that variability-aware smells exist in Software Product Lines (SPLs). This work presents an exploratory study that investigated (I) evidence that variability-aware smells exist in SPLs and (II) new types of variability-aware smell not yet documented in the literature based on a quantitative study with open source SPL projects. We collected quantitative data to generate reliable research evidence, by performing feature model and source code inspections on eleven open-source SPL projects. Our findings revealed that (1) instances of variability-aware smells exist in open-source SPL projects and (2) feature information presented significant associations with variability-aware smells. Furthermore, (3) the study presented six new types of variability-aware smells.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {367–376},
numpages = {10},
keywords = {Variability-Aware Smells, Software Product Lines, Exploratory Study, Empirical Study},
location = {Salvador, Brazil},
series = {SBES '19}
}

@article{10.1007/s00607-013-0369-2,
author = {Kim, Shin-Gyu and Eom, Hyeonsang and Yeom, Heon Y. and Min, Sang Lyul},
title = {Energy-centric DVFS controlling method for multi-core platforms},
year = {2014},
issue_date = {December  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {96},
number = {12},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-013-0369-2},
doi = {10.1007/s00607-013-0369-2},
abstract = {Dynamic voltage and frequency scaling (DVFS) is a well-known and effective technique for reducing energy consumption in modern processors. However, accurately predicting the effect of frequency scaling on system performance is a challenging problem in real environments. In this paper, we propose a realistic DVFS performance prediction method, and a practical DVFS control policy (eDVFS) that aims to minimize total energy consumption in multi-core platforms. We also present power consumption estimation models for CPU and DRAM by exploiting a hardware energy monitoring unit. We implemented eDVFS in Linux, and our evaluation results show that eDVFS can save a substantial amount of energy compared with Linux "on-demand" CPU governor in diverse environments.},
journal = {Computing},
month = dec,
pages = {1163–1177},
numpages = {15},
keywords = {Multi-core processor, Energy saving, DVFS performance prediction, CPU and DRAM power prediction, 68M20}
}

@inproceedings{10.1145/3377024.3377036,
author = {Sprey, Joshua and Sundermann, Chico and Krieter, Sebastian and Nieke, Michael and Mauro, Jacopo and Th\"{u}m, Thomas and Schaefer, Ina},
title = {SMT-based variability analyses in FeatureIDE},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377036},
doi = {10.1145/3377024.3377036},
abstract = {Handling configurable systems with thousands of configuration options is a challenging problem in research and industry. One of the most common approaches to manage the configuration options of large systems is variability modelling. The verification and configuration process of large variability models is manually infeasible. Hence, they are usually assisted by automated analyses based on solving satisfiability problems (SAT). Recent advances in satisfiability modulo theories (SMT) could prove SMT solvers as a viable alternative to SAT solvers. However, SMT solvers are typically not utilized for variability analyses. A comparison for SAT and SMT could help to estimate SMT solvers potential for the automated analysis. We integrated two SMT solvers into FeatureIDE and compared them against a SAT solver on analyses for feature models, configurations, and realization artifacts. We give an overview of all variability analyses in FeatureIDE and present the results of our empirical evaluation for over 122 systems. We observed that SMT solvers are generally faster in generating explanations of unsatisfiable requests. However, the evaluated SAT solver outperformed SMT solvers for other analyses.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {9},
keywords = {variability analysis, preprocessor analysis, feature models, feature model analysis, feature attributes, configuration analysis, attribute optimization, SMT analysis, SMT, SAT vs SMT, SAT analysis, SAT},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1145/3323771.3323803,
author = {Guang-yu, Li and Geng, Han},
title = {The Behavior Analysis and Achievement Prediction Research of College Students Based on XGBoost Gradient Lifting Decision Tree Algorithm},
year = {2019},
isbn = {9781450366397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3323771.3323803},
doi = {10.1145/3323771.3323803},
abstract = {Student behavior data is a reflection of students' learning styles and habits in campus. Quantitative evaluation of various behavior indicators of students' college learning life can reflect students' learning status and laws, and the academic performance is the most important and basic index to evaluate a student's learning situation. Based on the data of students' behavior under the "Four PIN" education system of Beihang Shoue College, this paper adopts XGBoost gradient upgrade decision tree algorithm to fully mine and analyze the situation of college students' study life and participation in social work, and to study the potential behavior patterns with strong correlation between students' behavior data and students' performance. The performance prediction model is established through data mining technology and the prediction accuracy is 73%. The study finds that "Pinjian" program records the growth of students. Students' overall evaluation and student performance shows a positive correlation. "Pinxue" program promotes academic development. Academic guidance in college plays an important role in improving students' academic performance. "Pinzhi" program enhances comprehensive literacy. Cultural and artistic activities and serving as student cadre show a positive correlation with academic performance.},
booktitle = {Proceedings of the 2019 7th International Conference on Information and Education Technology},
pages = {289–294},
numpages = {6},
keywords = {XGBoost gradient lifting decision tree algorithm, Weight analysis, Data mining, Behavior analysis, Achievement prediction},
location = {Aizu-Wakamatsu, Japan},
series = {ICIET 2019}
}

@inproceedings{10.1145/2851553.2851578,
author = {Khoshkbarforoushha, Alireza and Ranjan, Rajiv},
title = {Resource and Performance Distribution Prediction for Large Scale Analytics Queries},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851553.2851578},
doi = {10.1145/2851553.2851578},
abstract = {Efficient resource consumption and performance estimation of data-intensive workloads is central to the design and development of workload management techniques. Recent work has explored the efficacy of using distribution-based estimation of workload performance as opposed to single point prediction for a number of workload management problems such as query scheduling, admission control, and the like. However, the proposed approaches lack an efficient workload performance distribution prediction in that they simply assume that the probability distribution function (pdf) of the target value is already available. This paper aims to address this problem for an inseparable portion of big data analytics workloads, Hive queries. To this end, we combine knowledge of Hive query executions with the novel usage of mixture density networks to predict the whole spectrum of resource and performance as probability density functions. We evaluate our technique using the TPC-H benchmark, showing that it not only produces accurate pdf predictions but outperforms the state of the art single point techniques in half of experiments.},
booktitle = {Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
pages = {49–54},
numpages = {6},
keywords = {query performance prediction, hive, distribution prediction},
location = {Delft, The Netherlands},
series = {ICPE '16}
}

@article{10.1145/1945023.1945032,
author = {Srinivasan, Sadagopan and Zhao, Li and Illikkal, Ramesh and Iyer, Ravishankar},
title = {Efficient interaction between OS and architecture in heterogeneous platforms},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1945023.1945032},
doi = {10.1145/1945023.1945032},
abstract = {Almost all hardware platforms to date have been homogeneous with one or more identical processors managed by the operating system (OS). However, recently, it has been recognized that power constraints and the need for domain-specific high performance computing may lead architects towards building heterogeneous architectures and platforms in the near future. In this paper, we consider the three types of heterogeneous core architectures: (a) Virtual asymmetric cores: multiple processors that have identical core micro-architectures and ISA but each running at a different frequency point or perhaps having a different cache size, (b) Physically asymmetric cores: heterogeneous cores, each with a fundamentally different microarchitecture (in-order vs. out-of-order for instance) running at similar or different frequencies, with identical ISA and (c) Hybrid cores: multiple cores, where some cores have tightly-coupled hardware accelerators or special functional units. We show case studies that highlight why existing OS and hardware interaction in such heterogeneous architectures is inefficient and causes loss in application performance, throughput efficiency and lack of quality of service. We then discuss hardware and software support needed to address these challenges in heterogeneous platforms and establish efficient heterogeneous environments for platforms in the next decade. In particular, we will outline a monitoring and prediction framework for heterogeneity along with software support to take advantage of this information. Based on measurements on real platforms, we will show that these proposed techniques can provide significant advantage in terms of performance and power efficiency in heterogeneous platforms.},
journal = {SIGOPS Oper. Syst. Rev.},
month = feb,
pages = {62–72},
numpages = {11},
keywords = {scheduling, performance prediction, heterogeneous platform}
}

@inproceedings{10.1145/2889160.2889262,
author = {Linsbauer, Lukas and Egyed, Alexander and Lopez-Herrejon, Roberto Erick},
title = {A variability aware configuration management and revision control platform},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889262},
doi = {10.1145/2889160.2889262},
abstract = {Modern systems need to run in many different contexts like hardware and software platforms or environmental conditions. Additionally different customers might have slightly different requirements towards systems. Therefore software systems need to be highly configurable and provide variable sets of features for different customers. There are various approaches to developing and managing such systems, like ad-hoc clone-and-own approaches or structured software product line approaches for each of which again several different techniques and tools exist to support them. While the different approaches come with advantages they also have several disadvantages and shortcomings. Some work only with specific implementation artifacts (e.g. source code but not models) and others exist only as plugins for specific IDEs which makes them intrusive or even unusable in some development environments. In our work we present a development process and tools for managing and engineering of highly configurable and variable systems that is generic, incremental, flexible and intuitive. We evaluated our approach on several case study systems from various different domains and origins like open source, academia or industry. The results so far showed promising results.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {803–806},
numpages = {4},
keywords = {versioning, variants, variability, features, configuration},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2486092.2486120,
author = {Andelfinger, Philipp and Hartenstein, Hannes},
title = {Towards performance evaluation of conservative distributed discrete-event network simulations using second-order simulation},
year = {2013},
isbn = {9781450319201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2486092.2486120},
doi = {10.1145/2486092.2486120},
abstract = {Whether a given simulation model of a computer network will benefit from parallelization is difficult to determine in advance, complicated by the fact that hardware properties of the simulation execution environment can substantially affect the execution time of a given simulation. We describe SONSim, an approach to predict the execution time based on a simulation of an envisioned distributed network simulation (second-order simulation). SONSim takes into account both network model characteristics and hardware properties of the simulation execution environment. To show that a SONSim prototype is able to predict distributed performance with acceptable accuracy, we study three reference network simulation models differing fundamentally in topology and levels of model detail - simple topologies comprised of interconnected subnetworks, peer-to-peer networks and wireless networks. We evaluate the performance predictions for multiple configurations by comparing predictions for the three reference network models to execution time measurements of distributed simulations on physical hardware using both Ethernet and InfiniBand interconnects. In addition, utilizing the freedom to vary simulation hardware and model parameters in the second-order simulation, we demonstrate how SONSim can be used to identify general model characteristics that determine distributed simulation performance.},
booktitle = {Proceedings of the 1st ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {221–230},
numpages = {10},
keywords = {simulation, performance prediction, parallel, network simulation, network models, distributed, discrete-event},
location = {Montr©al, Qu\'{e}bec, Canada},
series = {SIGSIM PADS '13}
}

@article{10.1007/s00158-020-02659-4,
author = {Chen, Xiaoqian and Chen, Xianqi and Zhou, Weien and Zhang, Jun and Yao, Wen},
title = {The heat source layout optimization using deep learning surrogate modeling},
year = {2020},
issue_date = {Dec 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {62},
number = {6},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-020-02659-4},
doi = {10.1007/s00158-020-02659-4},
abstract = {In practical engineering, the layout optimization technique driven by the thermal performance is faced with a severe computational burden when directly integrating the numerical analysis tool of temperature simulation into the optimization loop. To alleviate this difficulty, this paper presents a novel deep learning surrogate-assisted heat source layout optimization method. First, two sampling strategies, namely the random sampling strategy and the evolving sampling strategy, are proposed to produce diversified training data. Then, regarding mapping between the layout and the corresponding temperature field as an image-to-image regression task, the feature pyramid network (FPN), a kind of deep neural network, is trained to learn the inherent laws, which plays as a surrogate model to evaluate the thermal performance of the domain with respect to different input layouts accurately and efficiently. Finally, the neighborhood search-based layout optimization (NSLO) algorithm is proposed and combined with the FPN surrogate to solve discrete heat source layout optimization problems. A typical two-dimensional heat conduction optimization problem is investigated to demonstrate the feasibility and effectiveness of the proposed deep learning surrogate-assisted layout optimization framework.},
journal = {Struct. Multidiscip. Optim.},
month = dec,
pages = {3127–3148},
numpages = {22},
keywords = {Neighborhood search, Feature pyramid network, Deep learning surrogate, Heat source layout optimization}
}

@article{10.1016/j.compind.2013.02.013,
author = {Bleakie, Alexander and Djurdjanovic, Dragan},
title = {Analytical approach to similarity-based prediction of manufacturing system performance},
year = {2013},
issue_date = {August, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {64},
number = {6},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2013.02.013},
doi = {10.1016/j.compind.2013.02.013},
abstract = {In this paper, a new method is proposed that is capable of predicting system condition by comparing the similarity of the most recent performance signatures with the known degradation patterns available in the historical records. For predicting the future performance, the similarities of the current performance signatures to each known degradation pattern are utilized in an analytically tractable manner to slant the prediction distributions toward most similar past degradation patterns. The newly proposed method was applied to prediction of sensor signatures coming from an industrial plasma enhanced chemical vapor deposition (PECVD) tool operating in a major semiconductor manufacturing fab. Results showed that the proposed method significantly improves the long-term time series prediction accuracy in terms of mean squared errors over the traditional autoregressive moving average (ARMA) model and additionally showed comparable mean squared prediction errors to another recently introduced similarity-based algorithm for long-term prediction of non-linear and non-stationary time series. However, the analytical structure of the method proposed in this paper enables computation of the prediction distributions an order of magnitude faster.},
journal = {Comput. Ind.},
month = aug,
pages = {625–633},
numpages = {9},
keywords = {Weighted likelihood estimation, Time series modeling, Gaussian mixture model, Dynamic system performance prediction}
}

@inproceedings{10.1145/3449639.3459353,
author = {Liefooghe, Arnaud and Verel, S\'{e}bastien and Lacroix, Benjamin and Z\u{a}voianu, Alexandru-Ciprian and McCall, John},
title = {Landscape features and automated algorithm selection for multi-objective interpolated continuous optimisation problems},
year = {2021},
isbn = {9781450383509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449639.3459353},
doi = {10.1145/3449639.3459353},
abstract = {In this paper, we demonstrate the application of features from landscape analysis, initially proposed for multi-objective combinatorial optimisation, to a benchmark set of 1 200 randomly-generated multiobjective interpolated continuous optimisation problems (MO-ICOPs). We also explore the benefits of evaluating the considered landscape features on the basis of a fixed-size sampling of the search space. This allows fine control over cost when aiming for an efficient application of feature-based automated performance prediction and algorithm selection. While previous work shows that the parameters used to generate MO-ICOPs are able to discriminate the convergence behaviour of four state-of-the-art multi-objective evolutionary algorithms, our experiments reveal that the proposed (black-box) landscape features used as predictors deliver a similar accuracy when combined with a classification model. In addition, we analyse the relative importance of each feature for performance prediction and algorithm selection.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {421–429},
numpages = {9},
location = {Lille, France},
series = {GECCO '21}
}

@article{10.1109/TPDS.2009.137,
author = {Wu, Yongwei and Hwang, Kai and Yuan, Yulai and Zheng, Weiming},
title = {Adaptive Workload Prediction of Grid Performance in Confidence Windows},
year = {2010},
issue_date = {July 2010},
publisher = {IEEE Press},
volume = {21},
number = {7},
issn = {1045-9219},
url = {https://doi.org/10.1109/TPDS.2009.137},
doi = {10.1109/TPDS.2009.137},
abstract = {Predicting grid performance is a complex task because heterogeneous resource nodes are involved in a distributed environment. Long execution workload on a grid is even harder to predict due to heavy load fluctuations. In this paper, we use Kalman filter to minimize the prediction errors. We apply Savitzky-Golay filter to train a sequence of confidence windows. The purpose is to smooth the prediction process from being disturbed by load fluctuations. We present a new adaptive hybrid method (AHModel) for load prediction guided by trained confidence windows. We test the effectiveness of this new prediction scheme with real-life workload traces on the AuverGrid and Grid5000 in France. Both theoretical and experimental results are reported in this paper. As the lookahead span increases from 10 to 50 steps (5 minutes per step), the AHModel predicts the grid workload with a mean-square error (MSE) of 0.04-0.73 percent, compared with 2.54-30.2 percent in using the static point value autoregression (AR) prediction method. The significant gain in prediction accuracy makes the new model very attractive to predict Grid performance. The model was proved especially effective to predict large workload that demands very long execution time, such as exceeding 4 hours on the Grid5000 over 5,000 processors. With minor changes of some system parameters, the AHModel can apply to other computational grids as well. At the end, we discuss extended research issues and tool development for Grid performance prediction.},
journal = {IEEE Trans. Parallel Distrib. Syst.},
month = jul,
pages = {925–938},
numpages = {14},
keywords = {workload characterization, performance prediction, autoregression method, and parallel applications., Savitzky-Golay filter, Kalman filter, Grid computing, performance prediction, workload characterization, autoregression method, Kalman filter, Savitzky-Golay filter, and parallel applications., Grid computing}
}

@article{10.1007/s11219-016-9341-7,
author = {Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire and Zander, Justyna},
title = {Automatic generation of test system instances for configurable cyber-physical systems},
year = {2017},
issue_date = {September 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9341-7},
doi = {10.1007/s11219-016-9341-7},
abstract = {Cyber-physical systems (CPSs) are ubiquitous systems that integrate digital technologies with physical processes. These systems are becoming configurable to respond to the different needs that users demand. As a consequence, their variability is increasing, and they can be configured in many system variants. To ensure a systematic test execution of CPSs, a test system must be elaborated encapsulating several sources such as test cases or test oracles. Manually building a test system for each configuration is a non-systematic, time-consuming, and error-prone process. To overcome these problems, we designed a test system for testing CPSs and we analyzed the variability that it needed to test different configurations. Based on this analysis, we propose a methodology supported by a tool named ASTERYSCO that automatically generates simulation-based test system instances to test individual configurations of CPSs. To evaluate the proposed methodology, we selected different configurations of a configurable Unmanned Aerial Vehicle, and measured the time required to generate their test systems. On average, around 119 s were needed by our tool to generate the test system for 38 configurations. In addition, we compared the process of generating test system instances between the method we propose and a manual approach. Based on this comparison, we believe that the proposed tool allows a systematic method of generating test system instances. We believe that our approach permits an important step toward the full automation of testing in the field of configurable CPSs.},
journal = {Software Quality Journal},
month = sep,
pages = {1041–1083},
numpages = {43},
keywords = {Test system generation, Test automation, Configurable cyber-physical systems}
}

@inproceedings{10.1109/SEAMS.2017.11,
author = {Jamshidi, Pooyan and Velez, Miguel and K\"{a}stner, Christian and Siegmund, Norbert and Kawthekar, Prasad},
title = {Transfer learning for improving model predictions in highly configurable software},
year = {2017},
isbn = {9781538615508},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2017.11},
doi = {10.1109/SEAMS.2017.11},
abstract = {Modern software systems are built to be used in dynamic environments using configuration capabilities to adapt to changes and external uncertainties. In a self-adaptation context, we are often interested in reasoning about the performance of the systems under different configurations. Usually, we learn a black-box model based on real measurements to predict the performance of the system given a specific configuration. However, as modern systems become more complex, there are many configuration parameters that may interact and we end up learning an exponentially large configuration space. Naturally, this does not scale when relying on real measurements in the actual changing environment. We propose a different solution: Instead of taking the measurements from the real system, we learn the model using samples from other sources, such as simulators that approximate performance of the real system at low cost. We define a cost model that transform the traditional view of model learning into a multi-objective problem that not only takes into account model accuracy but also measurements effort as well. We evaluate our cost-aware transfer learning solution using real-world configurable software including (i) a robotic system, (ii) 3 different stream processing applications, and (iii) a NoSQL database system. The experimental results demonstrate that our approach can achieve (a) a high prediction accuracy, as well as (b) a high model reliability.},
booktitle = {Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {31–41},
numpages = {11},
keywords = {transfer learning, model prediction, model learning, machine learning, highly configurable software},
location = {Buenos Aires, Argentina},
series = {SEAMS '17}
}

@inproceedings{10.1007/978-3-030-50334-5_14,
author = {Alsayoud, Fatimah and Miri, Ali},
title = {Cross-Scenario Performance Modelling for Big Data Ecosystems},
year = {2020},
isbn = {978-3-030-50333-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50334-5_14},
doi = {10.1007/978-3-030-50334-5_14},
abstract = {Performance prediction is an essential aspect of several critical system design decisions, such as workload scheduling and resource planning. However, developing a model with higher prediction accuracy is a challenging task in big data systems due to the stack complexity and environmental heterogeneity. Workload modelling aims to simplify the connection between workloads factors and performance testing. Most of the workload models rely on a single scenario under test (SUT) method, where the trained and the evaluated data have the same distribution. However, a single SUT is not the ideal modelling method for big data workloads, as SUTs change frequently. Big data systems have a considerable amount of possible test scenarios that are generated from changing one or more elements in the testing environment, such as changing benchmarks, software versions, or cloud service types. To address this issue, we propose a cross-Scenario workload modelling method that aims to improve the workloads’ performance classification accuracy. The proposed approach adopts the Transfer Learning concept for reusing models cross different but related scenarios. In this work, we evaluate the proposed approach on multi real-world scenarios in Hadoop which is an example of big data system. The empirical results showed that the proposed approach is more accurate than SUT method.},
booktitle = {Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {211–228},
numpages = {18},
keywords = {Performance, Modelling, Transfer learning, Big data ecosystems},
location = {Copenhagen, Denmark}
}

@inproceedings{10.5555/2821357.2821367,
author = {Baresi, Luciano and Quinton, Cl\'{e}ment},
title = {Dynamically evolving the structural variability of dynamic software product lines},
year = {2015},
publisher = {IEEE Press},
abstract = {A Dynamic Software Product Line (dspl) is a widely used approach to handle variability at runtime, e.g., by activating or deactivating features to adapt the running configuration. With the emergence of highly configurable and evolvable systems, dspls have to cope with the evolution of their structural variability, i.e., the Feature Model (fm) used to derive the configuration. So far, little is known about the evolution of the fm while a configuration derived from this fm is running. In particular, such a dynamic evolution changes the dspl configuration space, which is thus unsynchronized with the running configuration and its adaptation capabilities. In this position paper, we propose and describe an initial architecture to manage the dynamic evolution of dspls and their synchronization. In particular, we explain how this architecture supports the evolution of dspls based on fms extended with cardinality and attributes, which, to the best of our knowledge, has never been addressed yet.},
booktitle = {Proceedings of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {57–63},
numpages = {7},
location = {Florence, Italy},
series = {SEAMS '15}
}

@article{10.1155/2007/734021,
author = {Prodan, Radu},
title = {Specification and runtime workflow support in the ASKALON Grid environment},
year = {2007},
issue_date = {December 2007},
publisher = {IOS Press},
address = {NLD},
volume = {15},
number = {4},
url = {https://doi.org/10.1155/2007/734021},
doi = {10.1155/2007/734021},
abstract = {We describe techniques to support the runtime execution of scientific workflows in the ASKALON Grid environment. We present a formal model and three middleware services that support in combination the effective execution in heterogeneous and dynamic Grid environments: performance prediction, scheduling, and enactment engine. We validate our techniques with concrete experimental results for two real-world applications executed in the Austrian Grid environment.},
journal = {Sci. Program.},
month = dec,
pages = {193–211},
numpages = {19},
keywords = {scientific workflows, scheduling, performance prediction, enactment engine, Grid computing}
}

@inproceedings{10.5555/318773.319262,
author = {Bayer, Joachim and Girard, Jean-Fran\c{c}ois and W\"{u}rthner, Martin and DeBaud, Jean-Marc and Apel, Martin},
title = {Transitioning legacy assets to a product line architecture},
year = {1999},
isbn = {3540665382},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A successful software system evolves over time, but this evolution often occurs in an ad-hoc fashion. One approach to structure system evolution is the concept of software product lines where a core architecture supports a variety of application contexts. However, in practice, the high cost and high risks of redevelopment as well as the substantial investments made to develop the existing systems most often mandate significant leverage of the legacy assets. Yet, there is little guidance in the literature on how to transition legacy assets into a product line set-up.In this paper, we present RE-PLACE, an approach developed to support the transition of existing software assets towards a product line architecture while taking into account anticipated new system variants. We illustrate this approach with its application in an industrial setting.},
booktitle = {Proceedings of the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {446–463},
numpages = {18},
keywords = {software product line, reuse, reengineering, domain-specific software architecture, architecture recovery},
location = {Toulouse, France},
series = {ESEC/FSE-7}
}

@article{10.1007/s10586-010-0145-4,
author = {Tao, Ming and Dong, Shoubin and Zhang, Liping},
title = {A multi-strategy collaborative prediction model for the runtime of online tasks in computing cluster/grid},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-010-0145-4},
doi = {10.1007/s10586-010-0145-4},
abstract = {An efficient function of a complicated or dynamic high performance computing environment requires the scheduler to dispatch the submitted tasks according to the identification of the idling resources. A derivative problem is to provide accurate forecasts of the tasks runtimes. This is usually needed to assist scheduling policies and fine tune scheduling decisions, and also used for future planning of resource allocation when conducting advance reservation. However, the characteristics of the existing prediction strategies determine that the sole strategy is not appropriate for all kinds of heterogeneous tasks. Aiming at this problem, a multi-strategy collaborative prediction model (MSCPM) for the runtime of online tasks is proposed, and a novel concept named Prediction Accuracy Assurance (PAA) as a criterion is introduced to quantitatively evaluate the precision of the prediction runtime provided by a specific prediction strategy.MSCPM uses the existing strategies of prediction runtime to generate multiple collaborative prediction schemes and takes the prediction result of the scheme which provides the optimal PAA. We evaluate the performance of the proposed model which recently integrates four simple yet widely used time series prediction strategies based on the gathered traces of three different tasks. The analysis results show that MSCPM can aggregate the superiority of the various existing prediction strategies and the evaluation criterion can pick out the near-optimal one within the prediction results provided by the integrated strategies. MSCPM provides an enhanced accuracy assurance for the prediction runtime of the online tasks in the computing environments.},
journal = {Cluster Computing},
month = jun,
pages = {199–210},
numpages = {12},
keywords = {Runtime, Prediction accuracy assurance, Online task, Multi-strategy collaborative prediction model, Cluster/grid}
}

@inproceedings{10.1145/3195970.3196122,
author = {Gupta, Ujjwal and Babu, Manoj and Ayoub, Raid and Kishinevsky, Michael and Paterna, Francesco and Ogras, Umit Y.},
title = {STAFF: online learning with stabilized adaptive forgetting factor and feature selection algorithm},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3196122},
doi = {10.1145/3195970.3196122},
abstract = {Dynamic resource management techniques rely on power consumption and performance models to optimize the operating frequency and utilization of processing elements, such as CPU and GPU. Despite the importance of these decisions, many existing approaches rely on fixed power and performance models that are learned offline. However, offline models cannot guarantee accuracy when workloads differ significantly from the training available at design time. This paper presents an online learning framework (STAFF) that constructs adaptive run-time models for stationary and non-stationary workloads. STAFF is the first framework that (1) guarantees stability while quickly adapting to workload changes, (2) performs online feature selection with linear complexity, and (3) adapts to new model coefficients by employing adaptively varying forgetting factor, all at the same time. Experiments on an Intel® Coreh™ i5 6th generation platform demonstrate up to 6\texttimes{} improvement in the performance prediction accuracy compared to existing techniques.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {177},
numpages = {6},
location = {San Francisco, California},
series = {DAC '18}
}

@inproceedings{10.1007/978-3-030-62008-0_36,
author = {Kang, Zongwei and Shang, Jiaxing and Feng, Yong and Zheng, Linjiang and Liu, Dajiang and Qiang, Baohua and Wei, Ran},
title = {A Deep Sequence-to-Sequence Method for Aircraft Landing Speed Prediction Based on QAR Data},
year = {2020},
isbn = {978-3-030-62007-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62008-0_36},
doi = {10.1007/978-3-030-62008-0_36},
abstract = {Runway overrun is one of the most typical landing incidents highly concerned by airlines in the aviation industry. Previous studies have shown that high landing speed is closely related to runway overrun risks, therefore the study of landing speed prediction based on flight data has drawn attention of many scholars in recent years. However, existing methods are mainly based on traditional machine learning models and handcrafted features, which not only rely heavily on flight experts’ priori knowledge, but also provide unsatisfactory prediction accuracy. To solve this problem, in this paper we propose an innovative deep encoder-decoder model for aircraft landing speed prediction based on Quick Access Recorder (QAR) data. Specifically, we first preprocess the QAR dataset through a data cleaning, Lagrange interpolation and normalization procedure. Second, based on the preprocessed QAR dataset, we use gradient boosting decision trees to select features which are most closely related to landing speed. Finally, we employ the LSTM encoder-decoder architecture where the encoder captures the pattern underlying in the past sequences while the decoder generates predictions for the future speed sequences. We evaluate our method on a dataset of 44,176 A321 flight samples. The experimental results show that the prediction accuracy of the proposed method is significantly higher than the conventional methods.},
booktitle = {Web Information Systems Engineering – WISE 2020: 21st International Conference, Amsterdam, The Netherlands, October 20–24, 2020, Proceedings, Part II},
pages = {516–530},
numpages = {15},
keywords = {GBDT, Long short-term memory, Encoder-Decoder, Landing speed prediction, QAR data},
location = {Amsterdam, The Netherlands}
}

@inproceedings{10.1145/2556624.2556629,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {A survey on teaching of software product lines},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556629},
doi = {10.1145/2556624.2556629},
abstract = {With around two decades of existence, the community of Software Product Line (SPL) researchers and practitioners is thriving as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of engineers to build highly complex SPLs. Yet, it is unclear how SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, or what is the material available. In this paper, we carry out a survey with over 30 respondents with the purpose of capturing a snapshot of the state of teaching in our community. We report and discuss quantitative as well as qualitative results of the survey. We build upon them and sketch six concrete actions to continue improving the state of practice of SPL teaching.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {3},
numpages = {8},
keywords = {software product lines, software engineering teaching},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1007/s00500-019-03795-w,
author = {Ramgouda, P. and Chandraprakash, V.},
title = {Constraints handling in combinatorial interaction testing using multi-objective crow search and fruitfly optimization},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {8},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-03795-w},
doi = {10.1007/s00500-019-03795-w},
abstract = {Combinatorial testing strategies are the recent interest of the researchers because of their wide variety of applications. The combinatorial testing strategy posses a great deal of minimizing the count of the input parameters of a system such that a small set of parameters is obtained depending on their interaction. Practically, the input models of the software system are subjected to the constraints mainly in highly configurable systems. There exist a number of issues while integrating the constraint in the testing strategy that is overcome using the proposed method. The proposed method aims at developing the combinatorial interaction test suites in the presence of constraints. The proposed strategy is multi-objective crow search and fruitfly optimization that is developed by the integration of the crow search algorithm and the chaotic fruitfly optimization algorithm. The proposed algorithm offers an optimal selection of the test suites at the better convergence. The experimentation based on the constraints and the analysis are carried out in terms of average size and average time with their values as 10 and 30 s, respectively.},
journal = {Soft Comput.},
month = apr,
pages = {2713–2726},
numpages = {14},
keywords = {Multi-objectives, Crow search algorithm (CSA), Constraints, Combinatorial interaction testing, Chaotic FOA}
}

@inproceedings{10.1145/2000259.2000269,
author = {Hauck, Michael and Kuperberg, Michael and Huber, Nikolaus and Reussner, Ralf},
title = {Ginpex: deriving performance-relevant infrastructure properties through goal-oriented experiments},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000269},
doi = {10.1145/2000259.2000269},
abstract = {In software performance engineering, the infrastructure on which an application is running plays a crucial role when predicting the performance of the application. Thus, to yield accurate prediction results, performance-relevant properties and behaviour of the infrastructure have to be integrated into performance models. However, capturing these properties is a cumbersome and error-prone task, as it requires carefully engineered measurements and experiments. Existing approaches for creating infrastructure performance models require manual coding of these experiments, or ignore the detailed properties in the models. The contribution of this paper is the Ginpex approach, which introduces goal-oriented and model-based specification and generation of executable performance experiments for detecting and quantifying performance relevant infrastructure properties. Ginpex provides a metamodel for experiment specification and comes with pre-defined experiment templates that provide automated experiment execution on the target platform and also automate the evaluation of the experiment results. We evaluate Ginpex using two case studies, where experiments are executed to detect the operating system scheduler timeslice length, and to quantify the CPU virtualization overhead for an application executed in a virtualized environment.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {53–62},
numpages = {10},
keywords = {performance prediction, metamodel, measurements, infrastructure, experiments},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@article{10.1145/3450289,
author = {Chen, Jiawei and Jiang, Chengquan and Wang, Can and Zhou, Sheng and Feng, Yan and Chen, Chun and Ester, Martin and He, Xiangnan},
title = {CoSam: An Efficient Collaborative Adaptive Sampler for Recommendation},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3450289},
doi = {10.1145/3450289},
abstract = {Sampling strategies have been widely applied in many recommendation systems to accelerate model learning from implicit feedback data. A typical strategy is to draw negative instances with uniform distribution, which, however, will severely affect a model’s convergence, stability, and even recommendation accuracy. A promising solution for this problem is to over-sample the “difficult” (a.k.a. informative) instances that contribute more on training. But this will increase the risk of biasing the model and leading to non-optimal results. Moreover, existing samplers are either heuristic, which require domain knowledge and often fail to capture real “difficult” instances, or rely on a sampler model that suffers from low efficiency. To deal with these problems, we propose CoSam, an efficient and effective collaborative sampling method that consists of (1) a collaborative sampler model that explicitly leverages user-item interaction information in sampling probability and exhibits good properties of normalization, adaption, interaction information awareness, and sampling efficiency, and (2) an integrated sampler-recommender framework, leveraging the sampler model in prediction to offset the bias caused by uneven sampling. Correspondingly, we derive a fast reinforced training algorithm of our framework to boost the sampler performance and sampler-recommender collaboration. Extensive experiments on four real-world datasets demonstrate the superiority of the proposed collaborative sampler model and integrated sampler-recommender framework.},
journal = {ACM Trans. Inf. Syst.},
month = may,
articleno = {34},
numpages = {24},
keywords = {adaption, efficiency, recommendation, Sampling}
}

@inproceedings{10.1145/2465498.2465505,
author = {Merkle, Philipp},
title = {Predicting transaction quality for balanced data consistency and performance},
year = {2013},
isbn = {9781450321259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465498.2465505},
doi = {10.1145/2465498.2465505},
abstract = {Data management is an overarching objective of enterprise information systems. Their operation is characterised by high quality requirements concerning performance and consistency of managed data items. To prevent inconsistencies among stored data items, semantically related data accesses are encapsulated in transactions, which are then guaranteed to be executed in an atomic, consistent, isolated and durable (ACID) fashion. High data consistency, however, comes often at the expense of performance. Software engineers influence this trade-off by their design decisions. Finding a proper balance is challenging and often relies on trial and error combined with experience and intuition. We believe that quantitative predictions of transaction performance and data consistency can help in finding a good balance. Therefore, we propose a novel approach that integrates simulation of transactions with software architecture simulation.},
booktitle = {Proceedings of the 18th International Doctoral Symposium on Components and Architecture},
pages = {13–18},
numpages = {6},
keywords = {transaction, performance simulation, performance prediction, palladio component model, data consistency prediction},
location = {Vancouver, British Columbia, Canada},
series = {WCOP '13}
}

@inproceedings{10.1109/ICSE-NIER.2019.00028,
author = {Trubiani, Catia and Apel, Sven},
title = {PLUS: performance learning for uncertainty of software},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00028},
doi = {10.1109/ICSE-NIER.2019.00028},
abstract = {Uncertainty is particularly critical in software performance engineering when it relates to the values of important parameters such as workload, operational profile, and resource demand, because such parameters inevitably affect the overall system performance. Prior work focused on monitoring the performance characteristics of software systems while considering influence of configuration options. The problem of incorporating uncertainty as a first-class concept in the software development process to identify performance issues is still challenging. The PLUS (Performance Learning for Uncertainty of Software) approach aims at addressing these limitations by investigating the specification of a new class of performance models capturing how the different uncertainties underlying a software system affect its performance characteristics. The main goal of PLUS is to answer a fundamental question in the software performance engineering domain: How to model the variable configuration options (i.e., software and hardware resources) and their intrinsic uncertainties (e.g., resource demand, processor speed) to represent the performance characteristics of software systems? This way, software engineers are exposed to a quantitative evaluation of their systems that supports them in the task of identifying performance critical configurations along with their uncertainties.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {77–80},
numpages = {4},
keywords = {uncertainty, machine learning},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.1007/978-3-030-30446-1_9,
author = {Dubslaff, Clemens},
title = {Compositional Feature-Oriented Systems},
year = {2019},
isbn = {978-3-030-30445-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30446-1_9},
doi = {10.1007/978-3-030-30446-1_9},
abstract = {Feature-oriented systems describe system variants through features as first-class abstractions of optional or incremental units of systems functionality. The choice how to treat modularity and composition in feature-oriented systems strongly influences their design and behavioral modeling. Popular paradigms for the composition of features are superimposition and parallel composition. We approach both in a unified formal way for programs in guarded command language by introducing compositional feature-oriented systems (CFOSs). We show how both compositions relate to each other by providing transformations that preserve the behaviors of system variants. Family models of feature-oriented systems encapsulate all behaviors of system variants in a single model, prominently used in family-based analysis approaches. We introduce family-ready CFOSs that admit a family model and show by an annotative approach that every CFOS can be transformed into a family-ready one that has the same modularity and behaviors.},
booktitle = {Software Engineering and Formal Methods: 17th International Conference, SEFM 2019, Oslo, Norway, September 18–20, 2019, Proceedings},
pages = {162–180},
numpages = {19},
location = {Oslo, Norway}
}

@inproceedings{10.5555/3437539.3437738,
author = {Zhong, Wei and Hu, Shuxiang and Ma, Yuzhe and Yang, Haoyu and Ma, Xiuyuan and Yu, Bei},
title = {Deep learning-driven simultaneous layout decomposition and mask optimization},
year = {2020},
isbn = {9781450367257},
publisher = {IEEE Press},
abstract = {Combining multiple pattern lithography (MPL) and optical proximity correlation (OPC) pushes the limit of 193nm wavelength lithography to go further. Considering that layout decomposition may generate plenty of solutions with diverse printabilities, relying on conventional mask optimization process to select the best candidates for manufacturing is computationally expensive. Therefore, an accurate and efficient printability estimation is crucial and can significantly accelerate the layout decomposition and mask optimization (LDMO) process. In this paper, we propose a CNN based prediction and integrate it into our new high performance LDMO framework. We also develop both the layout and the decomposition sampling strategies to facilitate the network training. The experimental results demonstrate the effectiveness and the efficiency of the proposed algorithms.},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
articleno = {199},
numpages = {6},
location = {Virtual Event, USA},
series = {DAC '20}
}

@inproceedings{10.1145/3404835.3463104,
author = {Zhou, Fan and Yu, Liu and Xu, Xovee and Trajcevski, Goce},
title = {Decoupling Representation and Regressor for Long-Tailed Information Cascade Prediction},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463104},
doi = {10.1145/3404835.3463104},
abstract = {Effectively predicting the size of information cascades is crucial for understanding the evolution of many social applications, such as influence maximization and fake news detection. Conventional methods face the challenge of data imbalance which, in turn, yields unsatisfactory prediction performance. To prevent the loss functions or metrics from being affected by extreme values and assure numerical stability, previous works reformulate the problem definitions or adopt other types of evaluation metrics. However, solving the regression prediction of information cascades from a long-tailed distribution perspective is under explored. In this paper, we propose a general decoupling prediction solution -- first extracting the representation, then fine-tuning the regressor, which combines the original prediction value and weighted bias generated by a sub-network (SUB) that we designed. Our experiments conducted on long-tailed benchmarks demonstrate that our method significantly improves the prediction accuracy over state-of-the-art methods and mitigates the long-tailed cascade prediction problem.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1875–1879},
numpages = {5},
keywords = {information cascade, information diffusion, long-tailed distribution},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@article{10.1007/s10470-012-9981-x,
author = {Liaperdos, John and Arapoyanni, Angela and Tsiatouhas, Yiorgos},
title = {A test and calibration strategy for adjustable RF circuits},
year = {2013},
issue_date = {January   2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {1},
issn = {0925-1030},
url = {https://doi.org/10.1007/s10470-012-9981-x},
doi = {10.1007/s10470-012-9981-x},
abstract = {A test and calibration strategy suitable for adjustable RF circuits is presented in this paper. Certain performance-affecting circuit elements are designed to be digitally controllable, providing the capability to adjust the performance characteristics of a circuit's instance around their post-fabrication values, throughout a set of discrete states of operation. The alternate test methodology is adopted for test and calibration and a set of optimally selected test observables is used to develop regression models for the prediction of the circuit's performance characteristics in every state of operation. In the test phase, measurements of the test observables are obtained from a subset of the circuit's states. The processing of these observables provides accurate prediction of the RF circuit's performance characteristics in all available states and enables the discrimination of defect-free from defective circuits. The latter is further accomplished by the exploitation of an extended superset of the test observables, the use of which intends to maximize fault coverage. Moreover, the predicted performance characteristics are also used to examine compliance with the specifications and to allow calibration of the RF circuit by identifying the appropriate state of operation at which all specifications are met and, consequently, by forcing the circuit to operate in this specific state. The efficiency of the proposed technique has been validated by its application to a typical differential RF Mixer designed in a 0.18 μm CMOS technology. Simulation results have been obtained and assessed.},
journal = {Analog Integr. Circuits Signal Process.},
month = jan,
pages = {175–192},
numpages = {18},
keywords = {RF mixer testing, RF alternate test, Performance prediction, Defect-oriented RF testing, Calibration}
}

@article{10.1145/3476037,
author = {Chung, Chaeyeon and Lee, Jungsoo and Park, Kyungmin and Lee, Junsoo and Kim, Minjae and Song, Mookyung and Kim, Yeonwoo and Choo, Jaegul and Hong, Sungsoo Ray},
title = {Understanding Human-side Impact of Sampling Image Batches in Subjective Attribute Labeling},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3476037},
doi = {10.1145/3476037},
abstract = {Capturing human annotators' subjective responses in image annotation has become crucial as vision-based classifiers expand the range of application areas. While there has been significant progress in image annotation interface design in general, relatively little research has been conducted to understand how to elicit reliable and cost-efficient human annotation when the nature of the task includes a certain level of subjectivity. To bridge this gap, we aim to understand how different sampling methods in image batch labeling, a design that allows human annotators to label a batch of images simultaneously, can impact human annotation performances. In particular, we developed three different strategies in forming image batches: (1) uncertainty-based labeling (UL) that prioritizes images that a classifier predicts with the highest uncertainty, (2) certainty-based labeling (CL), a reverse strategy of UL, and (3) random, a baseline approach that randomly selects images. Although UL and CL solely select images to be labeled from a classifier's point of view, we hypothesized that human-side perception and labeling performance may also vary depending on the different sampling strategies. In our study, we observed that participants were able to recognize a different level of perceived cognitive load across three conditions (CL the easiest while UL the most difficult). We also observed a trade-off between annotation task effectiveness (CL and UL more reliable than random) and task efficiency (UL the most efficient while CL the least efficient). Based on the results, we discuss the implications of design and possible future research directions of image batch labeling.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {296},
numpages = {26},
keywords = {active learning, annotation efficiency, annotation reliability, batch sampling, image batch labeling, subjective task}
}

@article{10.1007/s10270-016-0569-2,
author = {Al-Hajjaji, Mustafa and Th\"{u}m, Thomas and Lochau, Malte and Meinicke, Jens and Saake, Gunter},
title = {Effective product-line testing using similarity-based product prioritization},
year = {2019},
issue_date = {February  2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-016-0569-2},
doi = {10.1007/s10270-016-0569-2},
abstract = {A software product line comprises a family of software products that share a common set of features. Testing an entire product-line product-by-product is infeasible due to the potentially exponential number of products in the number of features. Accordingly, several sampling approaches have been proposed to select a presumably minimal, yet sufficient number of products to be tested. Since the time budget for testing is limited or even a priori unknown, the order in which products are tested is crucial for effective product-line testing. Prioritizing products is required to increase the probability of detecting faults faster. In this article, we propose similarity-based prioritization, which can be efficiently applied on product samples. In our approach, we incrementally select the most diverse product in terms of features to be tested next in order to increase feature interaction coverage as fast as possible during product-by-product testing. We evaluate the gain in the effectiveness of similarity-based prioritization on three product lines with real faults. Furthermore, we compare similarity-based prioritization to random orders, an interaction-based approach, and the default orders produced by existing sampling algorithms considering feature models of various sizes. The results show that our approach potentially increases effectiveness in terms of fault detection ratio concerning faults within real-world product-line implementations as well as synthetically seeded faults. Moreover, we show that the default orders of recent sampling algorithms already show promising results, which, however, can still be improved in many cases using similarity-based prioritization.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {499–521},
numpages = {23},
keywords = {Test-case prioritization, Software product lines, Product-line testing, Model-based testing, Combinatorial interaction testing}
}

@article{10.1145/3276487,
author = {Wong, Chu-Pan and Meinicke, Jens and Lazarek, Lukas and K\"{a}stner, Christian},
title = {Faster variational execution with transparent bytecode transformation},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {OOPSLA},
url = {https://doi.org/10.1145/3276487},
doi = {10.1145/3276487},
abstract = {Variational execution is a novel dynamic analysis technique for exploring highly configurable systems and accurately tracking information flow. It is able to efficiently analyze many configurations by aggressively sharing redundancies of program executions. The idea of variational execution has been demonstrated to be effective in exploring variations in the program, especially when the configuration space grows out of control. Existing implementations of variational execution often require heavy lifting of the runtime interpreter, which is painstaking and error-prone. Furthermore, the performance of this approach is suboptimal. For example, the state-of-the-art variational execution interpreter for Java, VarexJ, slows down executions by 100 to 800 times over a single execution for small to medium size Java programs. Instead of modifying existing JVMs, we propose to transform existing bytecode to make it variational, so it can be executed on an unmodified commodity JVM. Our evaluation shows a dramatic improvement on performance over the state-of-the-art, with a speedup of 2 to 46 times, and high efficiency in sharing computations.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {117},
numpages = {30},
keywords = {Variational Execution, Java Virtual Machine, Configurable System, Bytecode Transformation}
}

@inproceedings{10.1145/3328833.3328850,
author = {Gamie, Eslam Abou and El-Seoud, M. Samir Abou and Salama, Mostafa A.},
title = {A layered-analysis of the features in higher education data set},
year = {2019},
isbn = {9781450361057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328833.3328850},
doi = {10.1145/3328833.3328850},
abstract = {Machine learning is applied on high education for analyzing the interaction between the students and electronic learning systems. This type of analysis serves in predicting of the student scores, in alerting students-at-risk, and in managing the degree of student engagement to educational system. The approaches in this work implements the divide and conquer algorithm on feature set of an educational data set to enhance the analysis and prediction accuracy. It divides the feature set into a number of logical subgroups based on the problem domain. Each subgroup is analyzed separately and the final result is the combination of the results of the analysis of these subgroups. The classifier that shows the best prediction accuracy is dependent on the logical non-statistical nature of the features in each group. This approach provides the possibility to apply a brute force algorithm in the selection of the best feature subgroups with a low computational complexity. The experimental work shows a high prediction accuracy of the students-at-risk relative to the current research, and provides a list of new important features in the field of electronic learning systems.},
booktitle = {Proceedings of the 8th International Conference on Software and Information Engineering},
pages = {237–242},
numpages = {6},
keywords = {random forest, feature selection, XGBoost, Data mining},
location = {Cairo, Egypt},
series = {ICSIE '19}
}

@inproceedings{10.1145/2000259.2000268,
author = {Klatt, Benjamin and Rathfelder, Christoph and Kounev, Samuel},
title = {Integration of event-based communication in the palladio software quality prediction framework},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000268},
doi = {10.1145/2000259.2000268},
abstract = {Today, software engineering is challenged to handle more and more large-scale distributed systems with guaranteed quality-of-service. Component-based architectures have been established to build such systems in a more structured and manageable way. Modern architectures often utilize event-based communication which enables loosely-coupled interactions between components and leads to improved system scalability. However, the loose coupling of components makes it challenging to model such architectures in order to predict their quality properties, e.g., performance and reliability, at system design time. In this paper, we present an extension of the Palladio Component Model (PCM) and the Palladio software quality prediction framework, enabling the modeling of event-based communication in component-based architectures. The contributions include: i) a meta-model extension supporting events as first class entities, ii) a mode-to-model transformation from the extended to the original PCM, iii) an integration of the transformation into the Palladio tool chain allowing to use existing model solution techniques, and iv) a detailed evaluation of the reduction of the modeling effort enabled by the transformation in the context of a real-world case study.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {43–52},
numpages = {10},
keywords = {performance prediction, event-based communication, component-based architectures},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@inproceedings{10.1145/2658761.2658768,
author = {Ma, Lei and Artho, Cyrille and Zhang, Cheng and Sato, Hiroyuki},
title = {Efficient testing of software product lines via centralization (short paper)},
year = {2014},
isbn = {9781450331616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658761.2658768},
doi = {10.1145/2658761.2658768},
abstract = {Software product line~(SPL) engineering manages families of software products that share common features. However, cost-effective test case generation for an SPL is challenging. Applying existing test case generation techniques to each product variant separately may test common code in a redundant way. Moreover, it is difficult to share the test results among multiple product variants. In this paper, we propose the use of centralization, which combines multiple product variants from the same SPL and generates test cases for the entire system. By taking into account all variants, our technique generally avoids generating redundant test cases for common software components. Our case study on three SPLs shows that compared with testing each variant independently, our technique is more efficient and achieves higher test coverage.},
booktitle = {Proceedings of the 2014 International Conference on Generative Programming: Concepts and Experiences},
pages = {49–52},
numpages = {4},
keywords = {random testing, automatic test generation, Software Product Lines},
location = {V\"{a}ster\r{a}s, Sweden},
series = {GPCE 2014}
}

@inproceedings{10.5555/3466184.3466429,
author = {Vahdat, Kimia and Shashaani, Sara},
title = {Simulation optimization based feature selection, a study on data-driven optimization with input uncertainty},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {In machine learning, removing uninformative or redundant features from a dataset can significantly improve the construction, analysis, and interpretation of the prediction models, especially when the set of collected features is extensive. We approach this challenge with simulation optimization over a high dimensional binary space in place of the classic greedy search in forward or backward selection or regularization methods. We use genetic algorithms to generate scenarios, bootstrapping to estimate the contribution of the intrinsic and extrinsic noise and sampling strategies to expedite the procedure. By including the uncertainty from the input data in the measurement of the estimators' variability, the new framework obtains robustness and efficiency. Our results on a simulated dataset exhibit improvement over state-of-the-art accuracy, interpretability, and reliability. Our proposed framework provides insight for leveraging Monte Carlo methodology in probabilistic data-driven modeling and analysis.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2149–2160},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@article{10.1504/ijbic.2021.114089,
author = {Hemalatha, B. and Rajkumar, N.},
title = {A modified machine learning classification for dental age assessment with effectual ACM-JO based segmentation},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {2},
issn = {1758-0366},
url = {https://doi.org/10.1504/ijbic.2021.114089},
doi = {10.1504/ijbic.2021.114089},
abstract = {Estimation of dental age plays a vital role in anthropology, forensics, and bio archaeology. Specific age estimation is mandatory for living and dead individuals, especially in young adolescents and children. Diverse detection of dental age schemes is calculated though they have certain limitations, such as reliability and prediction accuracy. To resolve this, a modified extreme learning machine with sparse representation classification (MELM-SRC) is used with dental image in this work. Initially, input image is preprocessed for reducing noise and smoothing in image using an anisotropic diffusion filter (ADF). Subsequently, teeth images are segmented using active contour model (ACM) with Jaya optimisation (JO) and then morphological post processing has been applied on segmented result to progress classification accuracy. Next, certain features are extracted such as area, perimeter, solidity, diameter, major and minor axis length, and filled area to enhance prediction accuracy. Lastly, age has been classified with MELM-SRC. In this MELM, effectual features are classified using SRC to increase age classification accuracy. Simulation outcomes show anticipated MELM-SRC acquires superior performance than Demirjian method for dental age assessment and also other existing classification schemes such as radial basis function network (RBFN), and adaptive neuro fuzzy inference system (ANFIS) schemes.},
journal = {Int. J. Bio-Inspired Comput.},
month = jan,
pages = {95–104},
numpages = {9},
keywords = {ANFIS, adaptive neuro fuzzy inference system, RBFN, radial basis function network, SRC, sparse representation classification, MELM, modified extreme learning machine, Jaya optimisation algorithm, ACM, active contour model, ADF, anisotropic diffusion filter, dental age}
}

@article{10.1007/s10664-012-9213-0,
author = {Koziolek, Heiko and Schlich, Bastian and Becker, Steffen and Hauck, Michael},
title = {Performance and reliability prediction for evolving service-oriented software systems},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9213-0},
doi = {10.1007/s10664-012-9213-0},
abstract = {During software system evolution, software architects intuitively trade off the different architecture alternatives for their extra-functional properties, such as performance, maintainability, reliability, security, and usability. Researchers have proposed numerous model-driven prediction methods based on queuing networks or Petri nets, which claim to be more cost-effective and less error-prone than current practice. Practitioners are reluctant to apply these methods because of the unknown prediction accuracy and work effort. We have applied a novel model-driven prediction method called Q-ImPrESS on a large-scale process control system from ABB consisting of several million lines of code. This paper reports on the achieved performance prediction accuracy and reliability prediction sensitivity analyses as well as the effort in person hours for achieving these results.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {746–790},
numpages = {45},
keywords = {Software architecture, Reliablity prediction, Performance prediciton, Case study}
}

@inproceedings{10.1145/1458082.1458142,
author = {Hauff, Claudia and Murdock, Vanessa and Baeza-Yates, Ricardo},
title = {Improved query difficulty prediction for the web},
year = {2008},
isbn = {9781595939913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1458082.1458142},
doi = {10.1145/1458082.1458142},
abstract = {Query performance prediction aims to predict whether a query will have a high average precision given retrieval from a particular collection, or low average precision. An accurate estimator of the quality of search engine results can allow the search engine to decide to which queries to apply query expansion, for which queries to suggest alternative search terms, to adjust the sponsored results, or to return results from specialized collections. In this paper we present an evaluation of state of the art query prediction algorithms, both post-retrieval and pre-retrieval and we analyze their sensitivity towards the retrieval algorithm. We evaluate query difficulty predictors over three widely different collections and query sets and present an analysis of why prediction algorithms perform significantly worse on Web data. Finally we introduce Improved Clarity, and demonstrate that it outperforms state-of-the-art predictors on three standard collections, including two large Web collections.},
booktitle = {Proceedings of the 17th ACM Conference on Information and Knowledge Management},
pages = {439–448},
numpages = {10},
keywords = {query performance prediction, query clarity},
location = {Napa Valley, California, USA},
series = {CIKM '08}
}

@article{10.1145/2180887.2180901,
author = {Dubach, Christophe and Jones, Timothy M. and O'Boyle, Michael F. P.},
title = {Exploring and Predicting the Effects of Microarchitectural Parameters and Compiler Optimizations on Performance and Energy},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11S},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/2180887.2180901},
doi = {10.1145/2180887.2180901},
abstract = {Embedded processor performance is dependent on both the underlying architecture and the compiler optimizations applied. However, designing both simultaneously is extremely difficult to achieve due to the time constraints designers must work under. Therefore, current methodology involves designing compiler and architecture in isolation, leading to suboptimal performance of the final product.This article develops a novel approach to this codesign space problem. For our specific design space, we demonstrate that we can automatically predict the performance that an optimizing compiler would achieve without actually tuning it for any of the microarchitecture configurations considered. Once trained, a single run of the program compiled with the standard optimization setting is enough to make a prediction on the new microarchitecture with just a 3.2% error rate on average. This allows the designer to accurately choose an architectural configuration with knowledge of how an optimizing compiler will perform on it. We use this to find the best optimizing compiler/architectural configuration in our codesign space and demonstrate that it achieves an average 19% performance improvement and energy savings of 16% compared to the baseline, nearly doubling the energy-efficiency measured as the energy-delay-squared product (EDD).},
journal = {ACM Trans. Embed. Comput. Syst.},
month = jun,
articleno = {24},
numpages = {24},
keywords = {performance prediction, design-space exploration, Architecture/compiler codesign}
}

@article{10.1109/TPDS.2003.1178879,
author = {van Gemund, Arjan J. C.},
title = {Symbolic Performance Modeling of Parallel Systems},
year = {2003},
issue_date = {February 2003},
publisher = {IEEE Press},
volume = {14},
number = {2},
issn = {1045-9219},
url = {https://doi.org/10.1109/TPDS.2003.1178879},
doi = {10.1109/TPDS.2003.1178879},
abstract = {Performance prediction is an important engineering tool that provides valuable feedback on design choices in program synthesis and machine architecture development. We present an analytic performance modeling approach aimed to minimize prediction cost, while providing a prediction accuracy that is sufficient to enable major code and data mapping decisions. Our approach is based on a performance simulation language called Pamela. Apart from simulation, Pamela features a symbolic analysis technique that enables Pamela models to be compiled into symbolic performance models that trade prediction accuracy for the lowest possible solution cost. We demonstrate our approach through a large number of theoretical and practical modeling case studies, including six parallel programs and two distributed-memory machines. The average prediction error of our approach is less than 10 percent, while the average worst-case error is limited to 50 percent. It is shown that this accuracy is sufficient to correctly select the best coding or partitioning strategy. For programs expressed in a high-level, structured programming model, such as data-parallel programs, symbolic performance modeling can be entirely automated. We report on experiments with a Pamela model generator built within a data-parallel compiler for distributed-memory machines. Our results show that with negligible program annotation, symbolic performance models are automatically compiled in seconds, while their solution cost is in the order of milliseconds.},
journal = {IEEE Trans. Parallel Distrib. Syst.},
month = feb,
pages = {154–165},
numpages = {12},
keywords = {parallel processing, analytic performance modeling., Performance prediction}
}

@inproceedings{10.1145/2188286.2188304,
author = {Tawhid, Rasha and Petriu, Dorina},
title = {User-friendly approach for handling performance parameters during predictive software performance engineering},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188304},
doi = {10.1145/2188286.2188304},
abstract = {A Software Product Line (SPL) is a set of similar software systems that share a common set of features. Instead of building each product from scratch, SPL development takes advantage of the reusability of the core assets shared among the SPL members. In this work, we integrate performance analysis in the early phases of SPL development process, applying the same reusability concept to the performance annotations. Instead of annotating from scratch the UML model of every derived product, we propose to annotate the SPL model once with generic performance annotations. After deriving the model of a product from the family model by an automatic transformation, the generic performance annotations need to be bound to concrete product-specific values provided by the developer. Dealing manually with a large number of performance annotations, by asking the developer to inspect every diagram in the generated model and to extract these annotations is an error-prone process. In this paper we propose to automate the collection of all generic parameters from the product model and to present them to the developer in a user-friendly format (e.g., a spreadsheet per diagram, indicating each generic parameter together with guiding information that helps the user in providing concrete binding values). There are two kinds of generic parametric annotations handled by our approach: product-specific (corresponding to the set of features selected for the product) and platform-specific (such as device choices, network connections, middleware, and runtime environment). The following model transformations for (a) generating a product model with generic annotations from the SPL model, (b) building the spreadsheet with generic parameters and guiding information, and (c) performing the actual binding are all realized in the Atlas Transformation Language (ATL).},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {109–120},
numpages = {12},
keywords = {uml, spl, performance model, performance completion, model-driven development, marte, atl},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@article{10.1155/2021/4327896,
author = {Xie, Shu-Tong and He, Zong-Bao and Chen, Qiong and Chen, Rong-Xin and Kong, Qing-Zhao and Song, Cun-Ying and Huang, Jiwei},
title = {Predicting Learning Behavior Using Log Data in Blended Teaching},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/4327896},
doi = {10.1155/2021/4327896},
abstract = {Online and offline blended teaching mode, the future trend of higher education, has recently been widely used in colleges around the globe. In the article, we conducted a study on students’ learning behavior analysis and student performance prediction based on the data about students’ behavior logs in three consecutive years of blended teaching in a college’s “Java Language Programming” course. Firstly, the data from diverse platforms such as MOOC, Rain Classroom, PTA, and cnBlog are integrated and preprocessed. Secondly, a novel multiclass classification framework, combining the genetic algorithm (GA) and the error correcting output codes (ECOC) method, is developed to predict the grade levels of students. In the framework, GA is designed to realize both the feature selection and binary classifier selection to fit the ECOC models. Finally, key factors affecting grades are identified in line with the optimal subset of features selected by GA, which can be analyzed for teaching significance. The results show that the multiclass classification algorithm designed in this article can effectively predict grades compared with other algorithms. In addition, the selected subset of features corresponding to learning behaviors is pedagogically instructive.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@inproceedings{10.1145/3458817.3476197,
author = {Shu, Tong and Guo, Yanfei and Wozniak, Justin and Ding, Xiaoning and Foster, Ian and Kurc, Tahsin},
title = {Bootstrapping in-situ workflow auto-tuning via combining performance models of component applications},
year = {2021},
isbn = {9781450384421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458817.3476197},
doi = {10.1145/3458817.3476197},
abstract = {In an in-situ workflow, multiple components such as simulation and analysis applications are coupled with streaming data transfers. The multiplicity of possible configurations necessitates an auto-tuner for workflow optimization. Existing auto-tuning approaches are computationally expensive because many configurations must be sampled by running the whole workflow repeatedly in order to train the auto-tuner surrogate model or otherwise explore the configuration space. To reduce these costs, we instead combine the performance models of component applications by exploiting the analytical workflow structure, selectively generating test configurations to measure and guide the training of a machine learning workflow surrogate model. Because the training can focus on well-performing configurations, the resulting surrogate model can achieve high prediction accuracy for good configurations despite training with fewer total configurations. Experiments with real applications demonstrate that our approach can identify significantly better configurations than other approaches for a fixed computer time budget.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {28},
numpages = {15},
keywords = {in-situ workflow, component model combination, bootstrapping, auto-tuning},
location = {St. Louis, Missouri},
series = {SC '21}
}

@inproceedings{10.1145/2462456.2464453,
author = {Xu, Qiang and Mehrotra, Sanjeev and Mao, Zhuoqing and Li, Jin},
title = {PROTEUS: network performance forecast for real-time, interactive mobile applications},
year = {2013},
isbn = {9781450316729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462456.2464453},
doi = {10.1145/2462456.2464453},
abstract = {Real-time communication (RTC) applications such as VoIP, video conferencing, and online gaming are flourishing. To adapt and deliver good performance, these applications require accurate estimations of short-term network performance metrics, e.g., loss rate, one-way delay, and throughput. However, the wide variation in mobile cellular network performance makes running RTC applications on these networks problematic. To address this issue, various performance adaptation techniques have been proposed, but one common problem of such techniques is that they only adjust application behavior reactively after performance degradation is visible. Thus, proactive adaptation based on accurate short-term, fine-grained network performance prediction can be a preferred alternative that benefits RTC applications. In this study, we show that forecasting the short-term performance in cellular networks is possible in part due to the channel estimation scheme on the device and the radio resource scheduling algorithm at the base station. We develop a system interface called PROTEUS, which passively collects current network performance, such as throughput, loss, and one-way delay, and then uses regression trees to forecast future network performance. PROTEUS successfully predicts the occurrence of packet loss within a 0.5s time window for 98% of the time windows and the occurrence of long one-way delay for 97% of the time windows. We also demonstrate how PROTEUS can be integrated with RTC applications to significantly improve the perceptual quality. In particular, we increase the peak signal-to-noise ratio of a video conferencing application by up to 15dB and reduce the perceptual delay in a gaming application by up to 4s.},
booktitle = {Proceeding of the 11th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {347–360},
numpages = {14},
keywords = {real-time communication (RTC) applications, mobile applications, interactive applications, cellular network performance prediction},
location = {Taipei, Taiwan},
series = {MobiSys '13}
}

@inproceedings{10.1145/2556624.2556628,
author = {Lengauer, Philipp and Bitto, Verena and Angerer, Florian and Gr\"{u}nbacher, Paul and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Where has all my memory gone? determining memory characteristics of product variants using virtual-machine-level monitoring},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556628},
doi = {10.1145/2556624.2556628},
abstract = {Non-functional properties such as memory footprint have recently gained importance in software product line research. However, determining the memory characteristics of individual features and product variants is extremely challenging. We present an approach that supports the monitoring of memory characteristics of individual features at the level of Java virtual machines. Our approach provides extensions to Java virtual machines to track memory allocations and deal-locations of individual features based on a feature-to-code mapping. The approach enables continuous monitoring at the level of features to detect anomalies such as memory leaks, excessive memory consumption, or abnormal garbage collection times in product variants. We provide an evaluation of our approach based on different product variants of the DesktopSearcher product line. Our experiment with different program inputs demonstrates the feasibility of our technique.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {13},
numpages = {8},
keywords = {monitoring, memory footprint, feature-oriented software development, Java},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/3292500.3330789,
author = {Kitada, Shunsuke and Iyatomi, Hitoshi and Seki, Yoshifumi},
title = {Conversion Prediction Using Multi-task Conditional Attention Networks to Support the Creation of Effective Ad Creatives},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330789},
doi = {10.1145/3292500.3330789},
abstract = {Accurately predicting conversions in advertisements is generally a challenging task, because such conversions do not occur frequently. In this paper, we propose a new framework to support creating high-performing ad creatives, including the accurate prediction of ad creative text conversions before delivering to the consumer. The proposed framework includes three key ideas: multi-task learning, conditional attention, and attention highlighting. Multi-task learning is an idea for improving the prediction accuracy of conversion, which predicts clicks and conversions simultaneously, to solve the difficulty of data imbalance. Furthermore, conditional attention focuses attention of each ad creative with the consideration of its genre and target gender, thus improving conversion prediction accuracy. Attention highlighting visualizes important words and/or phrases based on conditional attention. We evaluated the proposed framework with actual delivery history data (14,000 creatives displayed more than a certain number of times from Gunosy Inc.), and confirmed that these ideas improve the prediction performance of conversions, and visualize noteworthy words according to the creatives' attributes.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2069–2077},
numpages = {9},
keywords = {supporting ad creative creation, recurrent neural network, online advertising, multi-task learning, attention mechanism},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1109/COASE.2019.8843001,
author = {Xu, Chuqiao and Liu, Xin and Wang, Junliang and Zhang, Jie and Cao, Jin and Qin, Wei},
title = {An Improved GA-KRR Nested Learning Approach for Refrigeration Compressor Performance Forecasting&lt;sup&gt;*&lt;/sup&gt;},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843001},
doi = {10.1109/COASE.2019.8843001},
abstract = {The long duration of refrigeration compressor performance tests is a key factor restricting the quality testing efficiency and the delivery times. To reduce the time of quality tests in the refrigeration compressor manufacturing systems, data-driven technology is used for forecasting the compressor performance using unsteady-state data in early test phase. The typical methods usually encapsulate two distinct blocks: input range selection and performance prediction. Such fixed and hand-crafted input range, which is crucial for the prediction accuracy and test time saving, may be a sub-optimal choice for diverse varieties of the compressors and prevent their usage for real-time applications. In this paper, we proposed a compressor performance forecasting approach using GA-KRR (genetic algorithm - kernel ridge regression algorithm) nested learning that has a heuristic design to automatically hunt the best input range and a nested learning design to fuse the automatic input range selection and performance prediction into a single learning body. The experimental results on real-world data show the outstanding performance of proposed approach compared with relative approaches, which indicates the test time can be reduced 75%.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {622–627},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1145/1183401.1183426,
author = {Curtis-Maury, Matthew and Dzierwa, James and Antonopoulos, Christos D. and Nikolopoulos, Dimitrios S.},
title = {Online power-performance adaptation of multithreaded programs using hardware event-based prediction},
year = {2006},
isbn = {1595932828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1183401.1183426},
doi = {10.1145/1183401.1183426},
abstract = {With high-end systems featuring multicore/multithreaded processors and high component density, power-aware high-performance multithreading libraries become a critical element of the system software stack. Online power and performance adaptation of multithreaded code from within user-level runtime libraries is a relatively new and unexplored area of research. We present a user-level library framework for nearly optimal online adaptation of multithreaded codes for low-power, high-performance execution. Our framework operates by regulating concurrency and changing the processors/threads configuration as the program executes. It is innovative in that it uses fast, runtime performance prediction derived from hardware event-driven profiling, to select thread granularities that achieve nearly optimal energy-efficiency points. The use of predictors substantially reduces the runtime cost of granularity control and program adaptation. Our framework achieves performance and ED2 (energy-delay-squared) levels which are: i) comparable to or better than those of oracle-derived offline predictors; ii) significantly better than those of online predictors using exhaustive or localized linear search. The complete prediction and adaptation framework is implemented on a real multi-SMT system with Intel Hyperthreaded processors and embeds adaptation capabilities in OpenMP programs.},
booktitle = {Proceedings of the 20th Annual International Conference on Supercomputing},
pages = {157–166},
numpages = {10},
keywords = {power-aware computing, performance prediction, online adaptation, hardware performance counters},
location = {Cairns, Queensland, Australia},
series = {ICS '06}
}

@article{10.1016/j.jcss.2007.07.003,
author = {Schaeli, Basile and Gerlach, Sebastian and Hersch, Roger D.},
title = {A simulator for adaptive parallel applications},
year = {2008},
issue_date = {September, 2008},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {74},
number = {6},
issn = {0022-0000},
url = {https://doi.org/10.1016/j.jcss.2007.07.003},
doi = {10.1016/j.jcss.2007.07.003},
abstract = {Dynamically allocating computing nodes to parallel applications is a promising technique for improving the utilization of cluster resources. Detailed simulations can help identify allocation strategies and problem decomposition parameters that increase the efficiency of parallel applications. We describe a simulation framework supporting dynamic node allocation which, given a simple cluster model, predicts the running time of parallel applications taking CPU and network sharing into account. Simulations can be carried out without needing to modify the application code. Thanks to partial direct execution, simulation times and memory requirements are reduced. In partial direct execution simulations, the application's parallel behavior is retrieved via direct execution, and the duration of individual operations is obtained from a performance prediction model or from prior measurements. Simulations may then vary cluster model parameters, operation durations and problem decomposition parameters to analyze their impact on the application performance and identify the limiting factors. We implemented the proposed techniques by adding direct execution simulation capabilities to the Dynamic Parallel Schedules parallelization framework. We introduce the concept of dynamic efficiency to express the resource utilization efficiency as a function of time. We verify the accuracy of our simulator by comparing the effective running time, respectively the dynamic efficiency, of parallel program executions with the running time, respectively the dynamic efficiency, predicted by the simulator under different parallelization and dynamic node allocation strategies.},
journal = {J. Comput. Syst. Sci.},
month = sep,
pages = {983–999},
numpages = {17},
keywords = {Sensitivity analysis, Performance prediction, Partial direct execution, Dynamic efficiency, Adaptive parallel application simulation}
}

@article{10.1007/s00521-016-2796-4,
author = {Yusoff, Yusliza and Mohd Zain, Azlan and Sharif, Safian and Sallehuddin, Roselina and Ngadiman, Mohd Salihin},
title = {Potential ANN prediction model for multiperformances WEDM on Inconel 718},
year = {2018},
issue_date = {October   2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {7},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2796-4},
doi = {10.1007/s00521-016-2796-4},
abstract = {This paper proposes a machining performance prediction approach on multiple performances of wire electrical discharge machining (WEDM) on Inconel 718. Artificial neural network (ANN) is emphasized to predict the machining performances. Many efforts have been made to model the performances of WEDM using ANN. However, to obtain the best ANN model, generally the network parameters are not consistent and so far, the selection has been made in a random manner and resulted in an excessive experimental trial. Taguchi design orthogonal array L256 is implemented in the process of network parameter selection to search for the potential machining model. This approach, prescribed as OrthoANN, is simplified to avoid as much as unnecessary experimentations. Material removal rate, surface roughness (Ra), cutting speed (Vc) and sparking gap (Sg) are the machining performances considered in this study. Five machining parameters considered; pulse on time, pulse off time, peak current, servo voltage and flushing pressure. Cascade forward back-propagation neural network (CFNN) is found to be the best network type of the selected data set. One hidden layer 5---14---4 CFNN showed the most precise and generalized network architecture with very good prediction accuracy. An average of 5.16% error is generated which seems to be in superior concurrence with the actual experimental results. Confirmation test is carried out to verify the machining performances suggested by this approach.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {2113–2127},
numpages = {15},
keywords = {Regression, Orthogonal array, Multiobjective, Modeling, Electrical discharge machining, Artificial neural network}
}

@inproceedings{10.1145/3394885.3431418,
author = {Vu, Hai-Dang and Nours, S. Le and Pillement, S. and Stemmer, Ralf and Gr\"{u}ttner, Kim},
title = {A Fast Yet Accurate Message-level Communication Bus Model for Timing Prediction of SDFGs on MPSoC},
year = {2021},
isbn = {9781450379991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394885.3431418},
doi = {10.1145/3394885.3431418},
abstract = {Fast yet accurate performance and timing prediction of complex parallel data flow applications on multi-processor systems remains a difficult discipline. The reason for it comes from the complexity of the data flow applications and the hardware platform with shared resources, like buses and memories. This combination may lead to complex timing interferences that are difficult to express in pure analytical or classical simulation-based approaches. In this work, we propose a message-level communication model for timing and performance prediction of Synchronous Data Flow (SDF) applications on MPSoCs with shared memories. We compare our work against measurement and TLM simulation-based performance prediction models on two case-studies from the computer vision domain. We show that the accuracy and execution time of our simulation outperforms existing approaches and is suitable for a fast yet accurate design space exploration.},
booktitle = {Proceedings of the 26th Asia and South Pacific Design Automation Conference},
pages = {17–22},
numpages = {6},
keywords = {Timing prediction, System-level modeling, Multi Processor},
location = {Tokyo, Japan},
series = {ASPDAC '21}
}

@inproceedings{10.1109/ICSE.2019.00092,
author = {Lazreg, Sami and Cordy, Maxime and Collet, Philippe and Heymans, Patrick and Mosser, S\'{e}bastien},
title = {Multifaceted automated analyses for variability-intensive embedded systems},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00092},
doi = {10.1109/ICSE.2019.00092},
abstract = {Embedded systems, like those found in the automotive domain, must comply with stringent functional and non-functional requirements. To fulfil these requirements, engineers are confronted with a plethora of design alternatives both at the software and hardware level, out of which they must select the optimal solution wrt. possibly-antagonistic quality attributes (e.g. cost of manufacturing vs. speed of execution). We propose a model-driven framework to assist engineers in this choice. It captures high-level specifications of the system in the form of variable dataflows and configurable hardware platforms. A mapping algorithm then derives the design space, i.e. the set of compatible pairs of application and platform variants, and a variability-aware executable model, which encodes the functional and non-functional behaviour of all viable system variants. Novel verification algorithms then pinpoint the optimal system variants efficiently. The benefits of our approach are evaluated through a real-world case study from the automotive industry.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {854–865},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2578128.2578236,
author = {Dhungana, Deepak and Schreiner, Herwig and Lehofer, Martin and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Modeling multiplicity and hierarchy in product line architectures: extending a decision-oriented approach},
year = {2014},
isbn = {9781450325233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2578128.2578236},
doi = {10.1145/2578128.2578236},
abstract = {Engineers developing large-scale industrial software systems need to instantiate, configure, and deploy many different types of reusable components. The number of component instances required is typically unknown when defining the systems' architecture and variability but depends on customer requirements only known during configuration. The hierarchy of dynamically created component instances further results in complex dependencies between configuration decisions. To deal with the multiplicity and hierarchy of components product line engineers thus need a modeling approach capable of expressing the dependencies among dynamically instantiated components and related configuration decisions. Decision-oriented variability modeling approaches are highly useful in product line engineering to support product derivation and to guide users through the configuration process. However, current approaches do not sufficiently support multiplicity and hierarchy. In this paper we report on extending an existing decision-oriented approach to support modeling component variability, multiplicity, and hierarchy in product line architectures.},
booktitle = {Proceedings of the WICSA 2014 Companion Volume},
articleno = {11},
numpages = {6},
keywords = {software product lines, multiplicity and hierarchy, decision models},
location = {Sydney, Australia},
series = {WICSA '14 Companion}
}

@article{10.1145/2670533,
author = {Bhardwaj, Amit and Chaudhuri, Subhasis and Dabeer, Onkar},
title = {Design and Analysis of Predictive Sampling of Haptic Signals},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1544-3558},
url = {https://doi.org/10.1145/2670533},
doi = {10.1145/2670533},
abstract = {In this article, we identify adaptive sampling strategies for haptic signals. Our approach relies on experiments wherein we record the response of several users to haptic stimuli. We then learn different classifiers to predict the user response based on a variety of causal signal features. The classifiers that have good prediction accuracy serve as candidates to be used in adaptive sampling. We compare the resultant adaptive samplers based on their rate-distortion tradeoff using synthetic as well as natural data. For our experiments, we use a haptic device with a maximum force level of 3 N and 10 users. Each user is subjected to several piecewise constant haptic signals and is required to click a button whenever he perceives a change in the signal. For classification, we not only use classifiers based on level crossings and Weber’s law but also random forests using a variety of causal signal features. The random forest typically yields the best prediction accuracy and a study of the importance of variables suggests that the level crossings and Weber’s classifier features are most dominant. The classifiers based on level crossings and Weber’s law have good accuracy (more than 90%) and are only marginally inferior to random forests. The level crossings classifier consistently outperforms the one based on Weber’s law even though the gap is small. Given their simple parametric form, the level crossings and Weber’s law--based classifiers are good candidates to be used for adaptive sampling. We study their rate-distortion performance and find that the level crossing sampler is superior. For example, for haptic signals obtained while exploring various rendered objects, for an average sampling rate of 10 samples per second, the level crossings adaptive sampler has a mean square error about 3dB less than the Weber sampler.},
journal = {ACM Trans. Appl. Percept.},
month = dec,
articleno = {16},
numpages = {20},
keywords = {rate-distortion curve, random forest, linear regression, level crossings, decision tree, Weber’s law, Adaptive sampling}
}

@inproceedings{10.1145/3340555.3353729,
author = {Miura, Go and Okada, Shogo},
title = {Task-independent Multimodal Prediction of Group Performance Based on Product Dimensions},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340555.3353729},
doi = {10.1145/3340555.3353729},
abstract = {This paper proposes an approach to develop models for predicting the performance for multiple group meeting tasks, where the model has no clear correct answer. This paper adopts ”product dimensions” [Hackman et al. 1967] (PD) which is proposed as a set of dimensions for describing the general properties of written passages that are generated by a group, as a metric measuring group output. This study enhanced the group discussion corpus called the MATRICS corpus including multiple discussion sessions by annotating the performance metric of PD. We extract group-level linguistic features including vocabulary level features using a word embedding technique, topic segmentation techniques, and functional features with dialog act and parts of speech on the word level. We also extracted nonverbal features from the speech turn, prosody, and head movement. With a corpus including multiple discussion data and an annotation of the group performance, we conduct two types of experiments thorough regression modeling to predict the PD. The first experiment is to evaluate the task-dependent prediction accuracy, in the situation that the samples obtained from the same discussion task are included in both the training and testing. The second experiments is to evaluate the task-independent prediction accuracy, in the situation that the type of discussion task is different between the training samples and testing samples. In this situation, regression models are developed to infer the performance in an unknown discussion task. The experimental results show that a support vector regression model archived a 0.76 correlation in the discussion-task-dependent setting and 0.55 in the task-independent setting.},
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {264–273},
numpages = {10},
keywords = {Multimodal, Group performance, Group Analysis},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.1145/2993236.2993252,
author = {Rothberg, Valentin and Dietrich, Christian and Ziegler, Andreas and Lohmann, Daniel},
title = {Towards scalable configuration testing in variable software},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993252},
doi = {10.1145/2993236.2993252},
abstract = {Testing a software product line such as Linux implies building the source with different configurations. Manual approaches to generate configurations that enable code of interest are doomed to fail due to the high amount of variation points distributed over the feature model, the build system and the source code. Research has proposed various approaches to generate covering configurations, but the algorithms show many drawbacks related to run-time, exhaustiveness and the amount of generated configurations. Hence, analyzing an entire Linux source can yield more than 30 thousand configurations and thereby exceeds the limited budget and resources for build testing.  In this paper, we present an approach to fill the gap between a systematic generation of configurations and the necessity to fully build software in order to test it. By merging previously generated configurations, we reduce the number of necessary builds and enable global variability-aware testing. We reduce the problem of merging configurations to finding maximum cliques in a graph. We evaluate the approach on the Linux kernel, compare the results to common practices in industry, and show that our implementation scales even when facing graphs with millions of edges.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {156–167},
numpages = {12},
keywords = {Software Testing, Software Product Lines, Sampling, Linux, Configurability},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@article{10.1007/s11257-020-09277-1,
author = {Ludewig, Malte and Mauro, Noemi and Latifi, Sara and Jannach, Dietmar},
title = {Empirical analysis of session-based recommendation algorithms: A comparison of neural and non-neural approaches},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {31},
number = {1},
issn = {0924-1868},
url = {https://doi.org/10.1007/s11257-020-09277-1},
doi = {10.1007/s11257-020-09277-1},
abstract = {Recommender systems are tools that support online users by pointing them to potential items of interest in situations of information overload. In recent years, the class of session-based recommendation algorithms received more attention in the research literature. These algorithms base their recommendations solely on the observed interactions with the user in an ongoing session and do not require the existence of long-term preference profiles. Most recently, a number of deep learning-based (“neural”) approaches to session-based recommendations have been proposed. However, previous research indicates that today’s complex neural recommendation methods are not always better than comparably simple algorithms in terms of prediction accuracy. With this work, our goal is to shed light on the state of the art in the area of session-based recommendation and on the progress that is made with neural approaches. For this purpose, we compare twelve algorithmic approaches, among them six recent neural methods, under identical conditions on various datasets. We find that the progress in terms of prediction accuracy that is achieved with neural methods is still limited. In most cases, our experiments show that simple heuristic methods based on nearest-neighbors schemes are preferable over conceptually and computationally more complex methods. Observations from a user study furthermore indicate that recommendations based on heuristic methods were also well accepted by the study participants. To support future progress and reproducibility in this area, we publicly share the session-rec evaluation framework that was used in our research.},
journal = {User Modeling and User-Adapted Interaction},
month = mar,
pages = {149–181},
numpages = {33},
keywords = {Reproducibility, Performance evaluation, Session-based recommendation}
}

@inproceedings{10.1145/1391469.1391712,
author = {Ozisikyilmaz, Berkin and Memik, Gokhan and Choudhary, Alok},
title = {Efficient system design space exploration using machine learning techniques},
year = {2008},
isbn = {9781605581156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1391469.1391712},
doi = {10.1145/1391469.1391712},
abstract = {Computer manufacturers spend a huge amount of time, resources, and money in designing new systems and newer configurations, and their ability to reduce costs, charge competitive prices and gain market share depends on how good these systems perform. In this work, we develop predictive models for estimating the performance of systems by using performance numbers from only a small fraction of the overall design space. Specifically, we first develop three models, two based on artificial neural networks and another based on linear regression. Using these models, we analyze the published Standard Performance Evaluation Corporation (SPEC) benchmark results and show that by using the performance numbers of only 2% and 5% of the machines in the design space, we can estimate the performance of all the systems within 9.1% and 4.6% on average, respectively. Then, we show that the performance of future systems can be estimated with less than 2.2% error rate on average by using the data of systems from a previous year. We believe that these tools can accelerate the design space exploration significantly and aid in reducing the corresponding research/development cost and time-to-market.},
booktitle = {Proceedings of the 45th Annual Design Automation Conference},
pages = {966–969},
numpages = {4},
keywords = {performance prediction, machine learning, design space},
location = {Anaheim, California},
series = {DAC '08}
}

@article{10.1016/j.mejo.2019.04.019,
author = {Huang, Libo and Yu, Qi and Zhou, Chaobing and Ma, Jianqiao and Li, Zhisheng and Dou, Qiang},
title = {Efficient architectural exploration of TAGE branch predictor for embedded processors},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {88},
number = {C},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2019.04.019},
doi = {10.1016/j.mejo.2019.04.019},
journal = {Microelectron. J.},
month = jun,
pages = {88–98},
numpages = {11},
keywords = {Embedded processor, TAGE, Design space exploration, Branch prediction}
}

@inproceedings{10.1145/1941553.1941569,
author = {Wu, Xing and Mueller, Frank},
title = {ScalaExtrap: trace-based communication extrapolation for spmd programs},
year = {2011},
isbn = {9781450301190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941553.1941569},
doi = {10.1145/1941553.1941569},
abstract = {Performance modeling for scientific applications is important for assessing potential application performance and systems procurement in high-performance computing (HPC). Recent progress on communication tracing opens up novel opportunities for communication modeling due to its lossless yet scalable trace collection. Estimating the impact of scaling on communication efficiency still remains non-trivial due to execution-time variations and exposure to hardware and software artifacts. This work contributes a fundamentally novel modeling scheme. We synthetically generate the application trace for large numbers of nodes by extrapolation from a set of smaller traces. We devise an innovative approach for topology extrapolation of single program, multiple data (SPMD) codes with stencil or mesh communication. The extrapolated trace can subsequently be (a) replayed to assess communication requirements before porting an application, (b) transformed to auto-generate communication benchmarks for various target platforms, and (c) analyzed to detect communication inefficiencies and scalability limitations. To the best of our knowledge, rapidly obtaining the communication behavior of parallel applications at arbitrary scale with the availability of timed replay, yet without actual execution of the application at this scale is without precedence and has the potential to enable otherwise infeasible system simulation at the exascale level.},
booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
pages = {113–122},
numpages = {10},
keywords = {tracing, performance prediction, message passing, high-performance computing},
location = {San Antonio, TX, USA},
series = {PPoPP '11}
}

@inproceedings{10.1145/3419604.3419786,
author = {El-Kassabi, Hadeel T. and Khalil, Khaled and Serhani, M. Adel},
title = {Deep Learning Approach for Forecasting Athletes' Performance in Sports Tournaments},
year = {2020},
isbn = {9781450377331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419604.3419786},
doi = {10.1145/3419604.3419786},
abstract = {Sports and international tournaments have gained world attention in the past decade. Enhancing sports activities and promoting sports to participate in international events, competitions, and tournaments play a substantial role in the development and advancement of nations around the globe. In this paper, we applied different deep learning models for predicting athletes' performance in tournaments to help them improve their results. We propose a deep learning selection algorithm to evaluate the effectiveness of the athletes' current training by predicting their race results upon completing each additional training, which potentially improves their performance. We gathered public training data for athletes who participated in the 2017 Boston Marathon within a five-month window prior to the race. Deep learning models were applied and evaluated to predict marathon finishing times. These include Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRU). Results show that Deep Learning models give improved race time prediction accuracy over the baseline machine learning model, such as standard Linear Regression (LR).},
booktitle = {Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications},
articleno = {33},
numpages = {6},
keywords = {sports training, prediction modeling, marathon, deep learning, Running},
location = {Rabat, Morocco},
series = {SITA'20}
}

@article{10.1145/3447814,
author = {Jia, Xiaowei and Willard, Jared and Karpatne, Anuj and Read, Jordan S. and Zwart, Jacob A. and Steinbach, Michael and Kumar, Vipin},
title = {Physics-Guided Machine Learning for Scientific Discovery: An Application in Simulating Lake Temperature Profiles},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2691-1922},
url = {https://doi.org/10.1145/3447814},
doi = {10.1145/3447814},
abstract = {Physics-based models are often used to study engineering and environmental systems. The ability to model these systems is the key to achieving our future environmental sustainability and improving the quality of human life. This article focuses on simulating lake water temperature, which is critical for understanding the impact of changing climate on aquatic ecosystems and assisting in aquatic resource management decisions. General Lake Model (GLM) is a state-of-the-art physics-based model used for addressing such problems. However, like other physics-based models used for studying scientific and engineering systems, it has several well-known limitations due to simplified representations of the physical processes being modeled or challenges in selecting appropriate parameters. While state-of-the-art machine learning models can sometimes outperform physics-based models given ample amount of training data, they can produce results that are physically inconsistent. This article proposes a physics-guided recurrent neural network model (PGRNN) that combines RNNs and physics-based models to leverage their complementary strengths and improves the modeling of physical processes. Specifically, we show that a PGRNN can improve prediction accuracy over that of physics-based models (by over 20% even with very little training data), while generating outputs consistent with physical laws. An important aspect of our PGRNN approach lies in its ability to incorporate the knowledge encoded in physics-based models. This allows training the PGRNN model using very few true observed data while also ensuring high prediction accuracy. Although we present and evaluate this methodology in the context of modeling the dynamics of temperature in lakes, it is applicable more widely to a range of scientific and engineering disciplines where physics-based (also known as mechanistic) models are used.},
journal = {ACM/IMS Trans. Data Sci.},
month = may,
articleno = {20},
numpages = {26},
keywords = {scientific discovery, deep learning, Physics-guided machine learning}
}

@article{10.1016/j.jcss.2014.04.018,
author = {Sallam, Ahmed and Li, Kenli and Ouyang, Aijia and Li, Zhiyong},
title = {Proactive workload management in dynamic virtualized environments},
year = {2014},
issue_date = {December, 2014},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {80},
number = {8},
issn = {0022-0000},
url = {https://doi.org/10.1016/j.jcss.2014.04.018},
doi = {10.1016/j.jcss.2014.04.018},
abstract = {Recently, with the improvement of Cloud systems technologies and the essential advantages they can provide such as availability, scalability, and costs saving; massive domains in the IT industry are directing their business to the Cloud. To fit the computing demands of this trend along with nowadays fluky applications (e.g. social networks, media contents), Cloud systems require rapid resource changes. As a result, the workload management in a virtualized environment becomes a complex task. In this paper we propose a new proactive workload management model for virtualized resources to inspect the workload behavior of the running Virtual Machines, and to assent an appropriate scheduling and resource consolidation schema in order to improve the system efficiency, utilization, and throughput. We have carried out our model by modifying Xen Cloud Platform, then we tested the model performance through different representative benchmarks. The results show that the Proactive model can decrease the average response time remarkably.},
journal = {J. Comput. Syst. Sci.},
month = dec,
pages = {1504–1517},
numpages = {14},
keywords = {Virtualization, Resource management, Performance prediction models, Cloud computing}
}

@inproceedings{10.5555/3437539.3437554,
author = {Chen, Pei-Wei and Huang, Yu-Ching and Lee, Cheng-Lin and Jiang, Jie-Hong Roland},
title = {Circuit learning for logic regression on high dimensional boolean space},
year = {2020},
isbn = {9781450367257},
publisher = {IEEE Press},
abstract = {Logic regression aims to find a Boolean model involving binary covariates that predicts the response of an unknown system. It has many important applications, e.g., in data analysis and system design. In the 2019 ICCAD CAD Contest, the challenge of learning a compact circuit representing a black-box input-output pattern generator in a high dimensional Boolean space is formulated as the logic regression problem. This paper presents our winning approach to the problem based on a decision-tree reasoning procedure assisted with a template based preprocessing. Our methods outperformed other contestants in the competition in both prediction accuracy and circuit size.},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
articleno = {15},
numpages = {6},
location = {Virtual Event, USA},
series = {DAC '20}
}

@article{10.1504/ijdats.2021.118024,
author = {Christy, A. Princy and Rama, N.},
title = {A methodical evaluation of classifiers in predicting academic performance for a multi-class approach},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {3},
issn = {1755-8050},
url = {https://doi.org/10.1504/ijdats.2021.118024},
doi = {10.1504/ijdats.2021.118024},
abstract = {Predictive analytics has gained importance in recent years as it helps to proactively identify factors that contribute to the success or failure of an event in the relevant field. Academic achievements of students can be predicted early by employing algorithms and analysing relevant data thereby devising solutions to improve performance. In this process choosing the right algorithm is very crucial since performance of algorithms vary depending on the distribution of data and the way it is tuned to handle the data. In order to enhance the performance of algorithms their hyper-parameters were tuned. Many multi-class classifiers were examined and the prediction accuracy of each model developed by employing them was compared. Depending on their classification accuracy the models developed were used to predict the performance of the students. This was done by using micro and macro averaging because of multi-class features. The results show that ensemble classifiers performed well than their individual counterparts.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = jan,
pages = {207–226},
numpages = {19},
keywords = {micro-average, macro-average, grid search, feature importance, random forest classifier, XGBoost, performance metrics, prediction, classification, multi-class}
}

@inproceedings{10.1145/2967938.2967960,
author = {Cho, Younghyun and Oh, Surim and Egger, Bernhard},
title = {Online Scalability Characterization of Data-Parallel Programs on Many Cores},
year = {2016},
isbn = {9781450341219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2967938.2967960},
doi = {10.1145/2967938.2967960},
abstract = {We present an accurate online scalability prediction model for data-parallel programs on NUMA many-core systems. Memory contention is considered to be the major limiting factor of program scalability as data parallelism limits the amount of synchronization or data dependencies between parallel work units. Reflecting the architecture of NUMA systems, contention is modeled at the last-level caches of the compute nodes and the memory nodes using a two-level queuing model to estimate the mean service time of the individual memory nodes. Scalability predictions for individual or co-located parallel applications are based solely on data obtained during a short sampling period at runtime; this allows the presented model to be employed in a variety of scenarios. The proposed model has been implemented into an open-source OpenCL and the GNU OpenMP runtime and evaluated on a 64-core AMD system. For a wide variety of parallel workloads and configurations, the evaluations show that the model is able to predict the scalability of data-parallel kernels with high accuracy.},
booktitle = {Proceedings of the 2016 International Conference on Parallel Architectures and Compilation},
pages = {191–205},
numpages = {15},
keywords = {space-shared scheduling, queuing models, performance scalability, performance prediction, performance modeling, parallel programming models, openmp, opencl, numa architectures, multi-socket multi-core architectures, memory contention, memory architectures, many-core resource management, last-level caches, data-parallelism},
location = {Haifa, Israel},
series = {PACT '16}
}

@inproceedings{10.1145/3442391.3442403,
author = {Michelon, Gabriela K. and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley K.G. and Fischer, Stefan and Egyed, Alexander},
title = {A Hybrid Feature Location Technique for Re-engineeringSingle Systems into Software Product Lines},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442403},
doi = {10.1145/3442391.3442403},
abstract = {Software product lines (SPLs) are known for improving productivity and reducing time-to-market through the systematic reuse of assets. SPLs are adopted mainly by re-engineering existing system variants. Feature location techniques (FLTs) support the re-engineering process by mapping the variants’ features to their implementation. However, such FLTs do not perform well when applied to single systems. In this way, there is a lack of FLTs to aid the re-engineering process of a single system into an SPL. In this work, we present a hybrid technique that consists of two complementary types of analysis: i) a dynamic analysis by runtime monitoring traces of scenarios in which features of the system are exercised individually, and ii) a static analysis for refining overlapping traces. We evaluate our technique on three subject systems by computing the common metrics used in FL research. We thus computed Precision, Recall, and F-Score at the line- and method-level of source code. In addition to that, one of the systems has a ground truth available, which we also used for comparing results. Results show that our FLT reached an average of 68-78% precision and 72-81% recall on two systems at the line-level, and 67-65% precision and 68-48% recall at the method-level. In these systems, most of the implementation can be covered by the exercise of the features. For the largest system, our technique reached a precision of up to 99% at the line-level, 94% at the method-level, and 44% when comparing to traces. However, due to its size, it was difficult to reach high code coverage during execution, and thus the recall obtained was on average of 28% at the line-level, 25% at the method-level, and 30% when comparing to traces. The main contribution of this work is a hybrid FLT, its publicly available implementation, and a replication package for comparisons and future studies.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {11},
numpages = {9},
keywords = {traceability, software reuse, runtime monitoring, feature location},
location = {Krems, Austria},
series = {VaMoS '21}
}

@article{10.2478/acss-2021-0015,
author = {Owusu-Boadu, Bridgitte and Nti, Isaac Kofi and Nyarko-Boateng, Owusu and Aning, Justice and Boafo, Victoria},
title = {Academic Performance Modelling with Machine Learning Based on Cognitive and Non-Cognitive Features},
year = {2021},
issue_date = {Dec 2021},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {26},
number = {2},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2021-0015},
doi = {10.2478/acss-2021-0015},
abstract = {The academic performance of students is essential for academic progression at all levels of education. However, the availability of several cognitive and non-cognitive factors that influence students’ academic performance makes it challenging for academic authorities to use conventional analytical tools to extract hidden knowledge in educational data. Therefore, Educational Data Mining (EDM) requires computational techniques to simplify planning and determining students who might be at risk of failing or dropping from school due to academic performance, thus helping resolve student retention. The paper studies several cognitive and non-cognitive factors such as academic, demographic, social and behavioural and their effect on student academic performance using machine learning algorithms. Heterogenous lazy and eager machine learning classifiers, including Decision Tree (DT), K-Nearest-Neighbour (KNN), Artificial Neural Network (ANN), Logistic Regression (LR), Random Forest (RF), AdaBoost and Support Vector Machine (SVM) were adopted and training was performed based on k-fold (k = 10) and leave-one-out cross-validation. We evaluated their predictive performance using well-known evaluation metrics like Area under Curve (AUC), F-1 score, Precision, Accuracy, Kappa, Matthew’s correlation coefficient (MCC) and Recall. The study outcome shows that Student Absence Days (SAD) are the most significant predictor of students’ academic performance. In terms of prediction accuracy and AUC, the RF (Acc = 0.771, AUC = 0.903), LR (Acc = 0.779, AUC = 0.90) and ANN (Acc = 0.760, AUC = 0.895) outperformed all other algorithms (KNN (Acc = 0.638, AUC = 0.826), SVM (Acc = 0.727, AUC = 0.80), DT (Acc = 0.733, AUC = 0.876) and AdaBoost (Acc = 0.748, AUC = 0.808)), making them more suitable for predicting students’ academic performance.},
journal = {Appl. Comput. Syst.},
month = dec,
pages = {122–131},
numpages = {10},
keywords = {support vector machine, random forest, na\"{\i}ve Bayes, machine learning, logistic regression, k-nearest neighbour, educational data mining, decision tree, artificial neural network, AdaBoost, Academic performance}
}

@inproceedings{10.1145/3338188.3338203,
author = {Zhang, Fan and Jiang, Qinhua and Zhou, Bo},
title = {Prediction and Analysis of College Students' Sports Achievements Based on Support Vector Machine and Particle Swarm Optimization},
year = {2019},
isbn = {9781450362931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338188.3338203},
doi = {10.1145/3338188.3338203},
abstract = {In order to scientifically evaluate college students' physical fitness, a prediction model of sports performance based on machine learning algorithm is proposed. This paper analyses the current situation of College Students' sports achievement prediction, points out the reasons that lead to the low prediction accuracy of the current model, establishes the prediction model of College Students' sports achievement by using machine learning algorithm-support vector machine, and uses particle swarm optimization algorithm to select model parameters. Finally, the model is applied to the sports achievement modeling and prediction of a university. The application results show that the machine learning algorithm can overcome the shortcomings of the traditional model and improve the prediction effect of College Students' sports performance.},
booktitle = {Proceedings of the 5th International Conference on Frontiers of Educational Technologies},
pages = {128–132},
numpages = {5},
keywords = {Support Vector Machines, Prediction Model, Physical Education, Particle Swarm Optimization, Machine Learning Algorithms},
location = {Beijing, China},
series = {ICFET '19}
}

@article{10.1155/2021/5519213,
author = {Gu, Cong and Wu, Wenqing},
title = {Research on Prediction of Investment Fund’s Performance before and after Investment Based on Improved Neural Network Algorithm},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5519213},
doi = {10.1155/2021/5519213},
abstract = {There are more and more popular investment fund projects in the continuous economic development; the prediction and performance continuity become hot topics in the financial field. Scholars’ enthusiasm for this also reflects the domestic fund primary stage progress, and there is a huge application demand in China. The prediction of fund performance can help investors to avoid risks and improve returns and help managers to learn more unknown information from the prediction for the sake of guide market well and manage the market orderly. In the past research, the traditional way is to use the advantages of neural network to build a model to predict the continuous trend foundation performance, but the author found that the traditional single neural network (NN) algorithm has a large error value in the research. With the discussion, the particle swarm optimization (PSO) algorithm is added to the radial basis function (BRF) neural network, and PSO is conditioned to optimize and improve the RBF NN combining the advantages of both sides; a new set of PSO-RBF neural network security fund performance prediction method is summed up, which optimizes the structure and workflow of the algorithm. In the research, the author takes the real data as the reference and compares the prediction results with the traditional method RBF and the improved PSO-RBF. In the prediction results of the continuous trend, the highest value, and the lowest value in the period of the security fund performance, the new PSO-RBF has a good prediction in the fund performance prediction, and its accuracy rate is greatly improved compared with the traditional method Sheng, with good application value, and is worth popularizing.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {9}
}

@inproceedings{10.1145/1183614.1183696,
author = {Zhou, Yun and Croft, W. Bruce},
title = {Ranking robustness: a novel framework to predict query performance},
year = {2006},
isbn = {1595934332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1183614.1183696},
doi = {10.1145/1183614.1183696},
abstract = {In this paper, we introduce the notion of ranking robustness, which refers to a property of a ranked list of documents that indicates how stable the ranking is in the presence of uncertainty in the ranked documents. We propose a statistical measure called the robustness score to quantify this notion. We demonstrate that the robustness score significantly and consistently correlates with query performance in a variety of TREC test collections including the GOV2 collection. We compare the robustness score with the clarity score method which is the state-of-the-art technique for query performance prediction. Our experimental results show that the robustness score performs better than or at least as good as the clarity score. We find that the clarity score is barely correlated with query performance on the GOV2 collection while the correlation between the robustness score and query performance remains significant. We also notice that a combination of the two usually results in more prediction power.},
booktitle = {Proceedings of the 15th ACM International Conference on Information and Knowledge Management},
pages = {567–574},
numpages = {8},
keywords = {ranking robustness, query performance prediction},
location = {Arlington, Virginia, USA},
series = {CIKM '06}
}

@inproceedings{10.1007/978-3-030-58342-2_8,
author = {Smyth, Barry and Willemsen, Martijn C.},
title = {Predicting the Personal-Best Times of Speed Skaters Using Case-Based Reasoning},
year = {2020},
isbn = {978-3-030-58341-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58342-2_8},
doi = {10.1007/978-3-030-58342-2_8},
abstract = {Speed skating is a form of ice skating in which the skaters race each other over a variety of standardised distances. Races take place on specialised ice-rinks and the type of track and ice conditions can have a significant impact on race-times. As race distances increase, pacing also plays an important role. In this paper we seek to extend recent work on the application of case-based reasoning to marathon-time prediction by predicting race-times for speed skaters. In particular, we propose and evaluate a number of case-based reasoning variants based on different case and feature representations to generate track-specific race predictions. We show it is possible to improve upon state-of-the-art prediction accuracy by harnessing richer case representations using shorter races and track-adjusted finish and lap-times.},
booktitle = {Case-Based Reasoning Research and Development: 28th International Conference, ICCBR 2020, Salamanca, Spain, June 8–12, 2020, Proceedings},
pages = {112–126},
numpages = {15},
keywords = {Case representation, Race-time prediction, Speed skating, CBR for health and exercise},
location = {Salamanca, Spain}
}

@article{10.1007/s10664-017-9499-z,
author = {Assun\c{c}\~{a}o, Wesley K. and Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Vergilio, Silvia R. and Egyed, Alexander},
title = {Reengineering legacy applications into software product lines: a systematic mapping},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9499-z},
doi = {10.1007/s10664-017-9499-z},
abstract = {Software Product Lines (SPLs) are families of systems that share common assets allowing a disciplined reuse. Rarely SPLs start from scratch, instead they usually start from a set of existing systems that undergo a reengineering process. Many approaches to conduct the reengineering process have been proposed and documented in research literature. This scenario is a clear testament to the interest in this research area. We conducted a systematic mapping study to provide an overview of the current research on reengineering of existing systems to SPLs, identify the community activity in regarding of venues and frequency of publications in this field, and point out trends and open issues that could serve as references for future research. This study identified 119 relevant publications. These primary sources were classified in six different dimensions related to reengineering phases, strategies applied, types of systems used in the evaluation, input artefacts, output artefacts, and tool support. The analysis of the results points out the existence of a consolidate community on this topic and a wide range of strategies to deal with different phases and tasks of the reengineering process, besides the availability of some tools. We identify some open issues and areas for future research such as the implementation of automation and tool support, the use of different sources of information, need for improvements in the feature management, the definition of ways to combine different strategies and methods, lack of sophisticated refactoring, need for new metrics and measures and more robust empirical evaluation. Reengineering of existing systems into SPLs is an active research topic with real benefits in practice. This mapping study motivates new research in this field as well as the adoption of systematic reuse in software companies.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {2972–3016},
numpages = {45},
keywords = {Systematic reuse, Reengineering, Product family, Legacy systems, Evolution}
}

@inproceedings{10.1145/3238147.3238175,
author = {Bao, Liang and Liu, Xin and Xu, Ziheng and Fang, Baoyin},
title = {AutoConfig: automatic configuration tuning for distributed message systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238175},
doi = {10.1145/3238147.3238175},
abstract = {Distributed message systems (DMSs) serve as the communication backbone for many real-time streaming data processing applications. To support the vast diversity of such applications, DMSs provide a large number of parameters to configure. However, It overwhelms for most users to configure these parameters well for better performance. Although many automatic configuration approaches have been proposed to address this issue, critical challenges still remain: 1) to train a better and robust performance prediction model using a limited number of samples, and 2) to search for a high-dimensional parameter space efficiently within a time constraint. In this paper, we propose AutoConfig -- an automatic configuration system that can optimize producer-side throughput on DMSs. AutoConfig constructs a novel comparison-based model (CBM) that is more robust that the prediction-based model (PBM) used by previous learning-based approaches. Furthermore, AutoConfig uses a weighted Latin hypercube sampling (wLHS) approach to select a set of samples that can provide a better coverage over the high-dimensional parameter space. wLHS allows AutoConfig to search for more promising configurations using the trained CBM. We have implemented AutoConfig on the Kafka platform, and evaluated it using eight different testing scenarios deployed on a public cloud. Experimental results show that our CBM can obtain better results than that of PBM under the same random forests based model. Furthermore, AutoConfig outperforms default configurations by 215.40% on average, and five state-of-the-art configuration algorithms by 7.21%-64.56%.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {29–40},
numpages = {12},
keywords = {weighted Latin hypercube sampling, distributed message system, comparison-based model, automatic configuration tuning},
location = {Montpellier, France},
series = {ASE '18}
}

@inproceedings{10.5555/2819009.2819203,
author = {Dintzner, Nicolas},
title = {Safe evolution patterns for software product lines},
year = {2015},
publisher = {IEEE Press},
abstract = {Despite a global recognition of the problem, and massive investment from researchers and practitioners, the evolution of complex software systems is still a major challenge for today's architects and developers. In the context of product lines, or highly configurable systems, variability in the implementation and design makes many of the pre-existing challenges even more difficult to tackle. Many approaches and tools have been designed, but developers still miss the tools and methods enabling safe evolution of complex, variable systems.In this paper, we present our research plans toward this goal: making the evolution of software product lines safer. We show, by use of two concrete examples of changes that occurred in Linux, that simple heuristics can be applied to facilitate change comprehension and avoid common mistakes, without relying on heavy tooling. Based on those observations, we present the steps we intend to take to build a framework to regroup and classify changes, run simple checks, and eventually increase the quality of code deliveries affecting the variability model, mapping and implementation of software product lines.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {875–878},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2337223.2337243,
author = {Siegmund, Norbert and Kolesnikov, Sergiy S. and K\"{a}stner, Christian and Apel, Sven and Batory, Don and Rosenm\"{u}ller, Marko and Saake, Gunter},
title = {Predicting performance via automated feature-interaction detection},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However, when features interact, accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end, we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g., databases, encoding libraries, and web servers) using different configuration techniques (e.g., configuration files and preprocessor flags). Results show an average prediction accuracy of 95%.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {167–177},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@article{10.1007/s00158-021-02915-1,
author = {Zhang, Yang and Wang, Shuo and Zhou, Chang’an and Lv, Liye and Song, Xueguan},
title = {A fast active learning method in design of experiments: multipeak parallel adaptive infilling strategy based on expected improvement},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {64},
number = {3},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-021-02915-1},
doi = {10.1007/s00158-021-02915-1},
abstract = {Surrogate models are widely used in simulation-based engineering design. The distribution of samples directly determines the quality and efficiency of surrogate models, which has a significant influence on follow-up work. This paper proposes a multipeak parallel adaptive infilling (MPEI) strategy based on expected improvement (EI), which can be divided into two stages: the construction of candidate peak areas and the selection of appropriate candidates at the candidate peak areas. In the first stage, the candidates are divided into the corresponding subspaces in sequence according to the value of EI and the position of each candidate to construct the candidate peak areas. In the second stage, the Gaussian function is used to extract the uncorrelated parent point and the corresponding offspring points in each candidate peak area. Based on these stages, the MPEI strategy selects multiple new samples in spaces with both local optima and areas of large uncertainty interest, which can fully balance global exploration and local exploitation. In addition, the samples selected in each candidate peak area are concise and locally uniform, which can effectively reduce the computational cost. Seven benchmark cases and one engineering problem are used to validate the performance of the MPEI strategy. The results show that the MPEI strategy can efficiently obtain the desired prediction accuracy of surrogate models at a small price of a few samples and confirm the feasibility and robustness of the presented methodology.},
journal = {Struct. Multidiscip. Optim.},
month = sep,
pages = {1259–1284},
numpages = {26},
keywords = {Surrogate model, Correlation analysis, Multipeak characteristics, Expected improvement, Parallel adaptive infilling strategy}
}

@article{10.1016/j.knosys.2009.11.014,
author = {Eichinger, Frank and Kramer, David and B\"{o}hm, Klemens and Karl, Wolfgang},
title = {From source code to runtime behaviour: Software metrics help to select the computer architecture},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {23},
number = {4},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2009.11.014},
doi = {10.1016/j.knosys.2009.11.014},
abstract = {The decision which hardware platform to use for a certain application is an important problem in computer architecture. This paper reports on a study where a data-mining approach is used for this decision. It relies purely on source-code characteristics, to avoid potentially expensive programme executions. One challenge in this context is that one cannot infer how often functions that are part of the application are typically executed. The main insight of this study is twofold: (a) Source-code characteristics are sufficient nevertheless. (b) Linking individual functions with the runtime behaviour of the programme as a whole yields good predictions. In other words, while individual data objects from the training set may be quite inaccurate, the resulting model is not.},
journal = {Know.-Based Syst.},
month = may,
pages = {343–349},
numpages = {7},
keywords = {Source-code metrics, Performance prediction, Data mining, Control-flow graphs, Computer architecture}
}

@inproceedings{10.1109/ICSE43902.2021.00099,
author = {Weber, Max and Apel, Sven and Siegmund, Norbert},
title = {White-Box Performance-Influence Models: A Profiling and Learning Approach},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00099},
doi = {10.1109/ICSE43902.2021.00099},
abstract = {Many modern software systems are highly configurable, allowing the user to tune them for performance and more. Current performance modeling approaches aim at finding performance-optimal configurations by building performance models in a black-box manner. While these models provide accurate estimates, they cannot pinpoint causes of observed performance behavior to specific code regions. This does not only hinder system understanding, but it also complicates tracing the influence of configuration options to individual methods.We propose a white-box approach that models configuration-dependent performance behavior at the method level. This allows us to predict the influence of configuration decisions on individual methods, supporting system understanding and performance debugging. The approach consists of two steps: First, we use a coarse-grained profiler and learn performance-influence models for all methods, potentially identifying some methods that are highly configuration- and performance-sensitive, causing inaccurate predictions. Second, we re-measure these methods with a fine-grained profiler and learn more accurate models, at higher cost, though. By means of 9 real-world Java software systems, we demonstrate that our approach can efficiently identify configuration-relevant methods and learn accurate performance-influence models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1059–1071},
numpages = {13},
keywords = {software variability, software product lines, performance, Configuration management},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1109/TEVC.2021.3055076,
author = {Sun, Yanan and Sun, Xian and Fang, Yuhan and Yen, Gary G. and Liu, Yuqiao},
title = {A Novel Training Protocol for Performance Predictors of Evolutionary Neural Architecture Search Algorithms},
year = {2021},
issue_date = {June 2021},
publisher = {IEEE Press},
volume = {25},
number = {3},
issn = {1089-778X},
url = {https://doi.org/10.1109/TEVC.2021.3055076},
doi = {10.1109/TEVC.2021.3055076},
abstract = {Evolutionary neural architecture search (ENAS) can automatically design the architectures of deep neural networks (DNNs) using evolutionary computation algorithms. However, most ENAS algorithms require an intensive computational resource, which is not necessarily available to the users interested. Performance predictors are a type of regression models which can assist to accomplish the search, while without exerting much computational resource. Despite various performance predictors have been designed, they employ the same training protocol to build the regression models: 1) sampling a set of DNNs with performance as the training dataset; 2) training the model with the mean square error criterion; and 3) predicting the performance of DNNs newly generated during the ENAS. In this article, we point out that the three steps constituting the training protocol are not well thought-out through intuitive and illustrative examples. Furthermore, we propose a new training protocol to address these issues, consisting of designing a pairwise ranking indicator to construct the training target, proposing to use the logistic regression to fit the training samples, and developing a differential method to build the training instances. To verify the effectiveness of the proposed training protocol, four widely used regression models in the field of machine learning have been chosen to perform the comparisons on two benchmark datasets. The experimental results of all the comparisons demonstrate that the proposed training protocol can significantly improve the performance prediction accuracy against the traditional training protocols.},
journal = {Trans. Evol. Comp},
month = jun,
pages = {524–536},
numpages = {13}
}

@inproceedings{10.1007/978-3-030-77873-6_8,
author = {Raj, Nisha S. and Prasad, Sreelakshmi and Harish, Parvathy and Boban, Maria and Cheriyedath, Nidhuna},
title = {Early Prediction of At-Risk Students in a Virtual Learning Environment Using Deep Learning Techniques},
year = {2021},
isbn = {978-3-030-77872-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77873-6_8},
doi = {10.1007/978-3-030-77873-6_8},
abstract = {With the advancement of the internet and communication technologies, online learning has gained acceleration. The largely-scaled open online courses run on specific virtual platforms, where learners can engage themselves in their own space and pace. The Virtual Learning Environments (VLE) have shown rapid development in recent years, allowing learners to access high-quality digital materials. This paper aims at exploring students' affinity towards early withdrawal from online courses. The work expands by finding learner-centric factors contributing to students' early prediction at-risk of withdrawal and developing a prediction model. The current work uses the free Open University Learning Analytics Dataset (OULAD). Here, the early identification of students at risk of withdrawal is predicted based on a Deep Learning Approach using CNN Algorithm. Time-series analysis is done using data from consecutive years. The work's significant contribution is a set of influential parameters predicting at-risk students at an early learning stage. The prediction accuracy falls in the range of 83% to 93%.},
booktitle = {Adaptive Instructional Systems. Adaptation Strategies and Methods: Third International Conference, AIS 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part II},
pages = {110–120},
numpages = {11},
keywords = {Deep learning, Student dropout, At-risk student prediction, Learning analytics}
}

@article{10.1007/s10766-021-00707-0,
author = {\"{O}z, I\c{s}\i{}l and Arslan, Sanem},
title = {Predicting the Soft Error Vulnerability of Parallel Applications Using Machine Learning},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-021-00707-0},
doi = {10.1007/s10766-021-00707-0},
abstract = {With the widespread use of the multicore systems having smaller transistor sizes, soft errors become an important issue for parallel program execution. Fault injection is a prevalent method to quantify the soft error rates of the applications. However, it is very time consuming to perform detailed fault injection experiments. Therefore, prediction-based techniques have been proposed to evaluate the soft error vulnerability in a faster way. In this work, we present a soft error vulnerability prediction approach for parallel applications using machine learning algorithms. We define a set of features including thread communication, data sharing, parallel programming, and performance characteristics; and train our models based on three ML algorithms. This study uses the parallel programming features, as well as the combination of all features for the first time in vulnerability prediction of parallel programs. We propose two models for the soft error vulnerability prediction: (1) A regression model with rigorous feature selection analysis that estimates correct execution rates, (2) A novel classification model that predicts the vulnerability level of the target programs. We get maximum prediction accuracy rate of 73.2% for the regression-based model, and achieve 89% F-score for our classification model.},
journal = {Int. J. Parallel Program.},
month = jun,
pages = {410–439},
numpages = {30},
keywords = {Machine Learning, Parallel programming, Fault injection, Soft error analysis}
}

@article{10.1007/s10660-019-09383-2,
author = {Dhote, Sunita and Vichoray, Chandan and Pais, Rupesh and Baskar, S. and Mohamed Shakeel, P.},
title = {Hybrid geometric sampling and AdaBoost based deep learning approach for data imbalance in E-commerce},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {1389-5753},
url = {https://doi.org/10.1007/s10660-019-09383-2},
doi = {10.1007/s10660-019-09383-2},
abstract = {Presently, significance of deep learning techniques starts to overlook the world of E-commerce with their endless customizable online shopping experience to the users. Though huge data is streaming constantly during online commerce, data imbalance problem is still unaddressed due to insufficient analytical algorithms to handle huge datasets for smooth outliers. This leads to high congestion in the network as well as the extraordinary cost problem during online commerce. The foremost objective of this work is to resolve the classification task of imbalance data and churn rate using hybrid geometric sampling and AdaBoost based deep learning classification approach that uses diverse solution to provide a balance among prediction, accuracy, precision, specificity, sensitivity, and usability of data in E-commerce. This proposed solution helps to reduce the data imbalance problem and prediction of churn as well as non-churn customers in E-commerce web links. The experimental analysis has been carried out for the proposed algorithm in accordance with conventional techniques to check the practicability of the algorithm in real time practice.},
journal = {Electronic Commerce Research},
month = jun,
pages = {259–274},
numpages = {16},
keywords = {Geometric analysis, Data imbalance, AdaBoost, Deep learning, E-commerce}
}

@inproceedings{10.1007/978-3-319-05843-6_7,
author = {Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {A Requirements Monitoring Infrastructure for Very-Large-Scale Software Systems},
year = {2014},
isbn = {9783319058429},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-05843-6_7},
doi = {10.1007/978-3-319-05843-6_7},
abstract = {[Context and motivation] Approaches for requirements monitoring check the compliance of systems with their requirements during operation. [Question/problem] Despite many advances, requirements monitoring remains challenging particularly for very-large-scale software systems VLSS with system-of-systems architectures. [Principal ideas/results] In this research preview we describe key characteristics of industrial VLSS and discuss implications for requirements monitoring. Furthermore, we report on our ongoing work of developing a requirements monitoring infrastructure addressing these characteristics. [Contribution] Our infrastructure supports runtime monitoring of requirements across systems; variability management of requirements-based monitors; and the integration of monitoring data from different sources in a VLSS.},
booktitle = {Proceedings of the 20th International Working Conference on Requirements Engineering: Foundation for Software Quality - Volume 8396},
pages = {88–94},
numpages = {7},
keywords = {very-large-scale software systems, Requirements monitoring},
location = {Essen, Germany},
series = {REFSQ 2014}
}

@inproceedings{10.1145/3303772.3303802,
author = {Hu, Qian and Rangwala, Huzefa},
title = {Reliable Deep Grade Prediction with Uncertainty Estimation},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303802},
doi = {10.1145/3303772.3303802},
abstract = {Currently, college-going students are taking longer to graduate than their parental generations. Further, in the United States, the six-year graduation rate has been 59% for decades. Improving the educational quality by training better-prepared students who can successfully graduate in a timely manner is critical. Accurately predicting students' grades in future courses has attracted much attention as it can help identify at-risk students early so that personalized feedback can be provided to them on time by advisors. Prior research on students' grade prediction include shallow linear models; however, students' learning is a highly complex process that involves the accumulation of knowledge across a sequence of courses that can not be sufficiently modeled by these linear models. In addition to that, prior approaches focus on prediction accuracy without considering prediction uncertainty, which is essential for advising and decision making. In this work, we present two types of Bayesian deep learning models for grade prediction under a course-specific framework: i)Multilayer Perceptron (MLP) and ii) Recurrent Neural Network (RNN). These course-specific models are based on the assumption that prior courses can provide students with knowledge for future courses so that grades of prior courses can be used to predict grades in a future course. The MLP ignores the temporal dynamics of students' knowledge evolution. Hence, we propose RNN for students' performance prediction. To evaluate the performance of the proposed models, we performed extensive experiments on data collected from a large public university. The experimental results show that the proposed models achieve better performance than prior state-of-the-art approaches. Besides more accurate results, Bayesian deep learning models estimate uncertainty associated with the predictions. We explore how uncertainty estimation can be applied towards developing a reliable educational early warning system. In addition to uncertainty, we also develop an approach to explain the prediction results, which is useful for advisors to provide personalized feedback to students.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {76–85},
numpages = {10},
keywords = {Uncertainty, Sequential Models, Grade Prediction, Educational Data Mining, Bayesian Deep Learning},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@inproceedings{10.1145/3453688.3461495,
author = {Wu, Nan and Xie, Yuan and Hao, Cong},
title = {IRONMAN: GNN-assisted Design Space Explo&lt;u&gt;r&lt;/u&gt;ati&lt;u&gt;o&lt;/u&gt;n in High-Level Sy&lt;u&gt;n&lt;/u&gt;thesis via Reinforce&lt;u&gt;m&lt;/u&gt;ent Le&lt;u&gt;a&lt;/u&gt;r&lt;u&gt;n&lt;/u&gt;ing},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453688.3461495},
doi = {10.1145/3453688.3461495},
abstract = {Despite the great success of High-Level Synthesis (HLS) tools, we observe several unresolved challenges: 1) the high-level abstraction of programming styles in HLS conceals optimization opportunities; 2) existing HLS tools do not provide flexible trade-offs among different objectives and constraints; 3) the actual quality of the resulting RTL designs is hard to predict. To this end, we propose an end-to-end framework, IRONMAN. The primary goal is to enable a flexible and automated design space exploration (DSE), which can provide either optimized solutions under user-specified constraints, or Pareto trade-offs among different objectives (e.g., resource types, area, and latency). IronMan consists of three components: GPP (a highly accurate graph-neural-network-based performance predictor), RLMD (a reinforcement-learning-based DSE engine that explores the optimized resource allocation strategy), and CT (a code transformer that assists RLMD and GPP by extracting data flow graphs from original HLS C/C++). Experimental results show that, 1) GPP achieves high prediction accuracy, reducing prediction errors of HLS tools by 10.9X in resource usage and 5.7X in timing; 2) RLMD obtains optimized or Pareto solutions outperforming genetic algorithm and simulated annealing by 12.7% and 12.9%, respectively; 3) IronMan can find optimized solutions perfectly matching various DSP constraints, with 2.54X fewer DSPs and up to 6X shorter latency than those of HLS tools. IronMan is also up to 400X faster than meta-heuristic techniques and HLS tools.},
booktitle = {Proceedings of the 2021 Great Lakes Symposium on VLSI},
pages = {39–44},
numpages = {6},
keywords = {design space exploration, graph neural network, high-level synthesis, reinforcement learning},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/1216993.1217020,
author = {Bondarev, Egor and Chaudron, Michel R. V. and de Kock, Erwin A.},
title = {Exploring performance trade-offs of a JPEG decoder using the deepcompass framework},
year = {2007},
isbn = {1595932976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1216993.1217020},
doi = {10.1145/1216993.1217020},
abstract = {Designing embedded systems for multiprocessor platforms requires early prediction and balancing of multiple system quality attributes. We present a design space exploration framework for component-based software systems that allows an architect to get insight into a space of possible design alternatives with further evaluation and comparison of these alternatives. The framework provides (a) tool-guided design of multiple alternatives of software and hardware architectures, (b) early design-time predictions of performance properties and identification of bottlenecks for each architectural alternative, and (c) evaluation of each alternative with respect to multi-objective trade-offs. The performance prediction technique employs modeling of individual components and composition of the models into a system model representing the system behaviour and resource usage. We illustrate the framework by a case study of a JPEG decoder application. For this system, we consider architectural alternatives, show their specification, and explore their trade-offs with respect to task latencies, resource utilization and system cost.},
booktitle = {Proceedings of the 6th International Workshop on Software and Performance},
pages = {153–163},
numpages = {11},
keywords = {system architecture, software, simulation, performance prediction, model synthesis, design trade-offs, component-based systems, component models, JPEG decoder},
location = {Buenes Aires, Argentina},
series = {WOSP '07}
}

@inproceedings{10.1145/3369412.3395060,
author = {Yang, Jianhua and Lu, Beiling and Xiao, Liang and Kang, Xiangui and Shi, Yun-Qing},
title = {Reinforcement Learning Aided Network Architecture Generation for JPEG Image Steganalysis},
year = {2020},
isbn = {9781450370509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369412.3395060},
doi = {10.1145/3369412.3395060},
abstract = {The architectures of convolutional neural networks used in steganalysis have been designed heuristically. In this paper, an automatic Network Architecture Generation algorithm based on reinforcement learning for JPEG image Steganalysis (JS-NAG) has been proposed. Different from the automatic neural network generation methods in computer vision which are based on the strong content signals, steganalysis is based on the weak embedded signals, thus needs specific design. In the proposed method, the agent is trained to sequentially select some high-performing blocks using Q-learning to generate networks. An early stop strategy and a well-designed performance prediction function have been utilized to reduce the search time. To generate the optimal networks, hundreds of networks have been searched and trained on 3 GPUs for 15 days. To further improve the detection accuracy, we make an ensemble classifier out of the generated convolutional neural networks. The experimental results have shown that the proposed method significantly outperforms the current state-of-the-art CNN based methods.},
booktitle = {Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security},
pages = {23–32},
numpages = {10},
keywords = {steganalysis, reinforcement learning, convolutional neural network, automatic network architecture generation},
location = {Denver, CO, USA},
series = {IH&amp;MMSec '20}
}

@inproceedings{10.1145/3426020.3426070,
author = {Jeong, Minseop and Park, Seongsoo and Han, Hwansoo},
title = {Caching Cost Model for In-memory Data Analytics Framework},
year = {2021},
isbn = {9781450389259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426020.3426070},
doi = {10.1145/3426020.3426070},
abstract = {In the era of data-parallel analytics, caching intermediate results is used as a key method to speed up the framework. Existing frameworks apply various caching policies depending on run-time context or programmer’s decision. Since caching still leave room for optimization, sophisticated caching which considering the benefit from caching is required. However, existing frameworks are limited to measure the performance benefit from caching because they only measure the computing time at the distributed task level. In this paper, we propose an operator-level computing time metric and a cost model to predict the performance benefit from caching, for in-memory data analytics frameworks. We implemented our scheme in Apache Spark and evaluated its prediction accuracy with Spark benchmark programs. The average error of the cost model measured from 10x input data was 7.3%, and the performance benefit predicted by the model and actual performance benefit showed a difference within 24%. The proposed cost model and performance benefit prediction method can be used to determine and optimize the caching of data analytics engines to maximize the performance benefit.},
booktitle = {The 9th International Conference on Smart Media and Applications},
pages = {187–189},
numpages = {3},
keywords = {Data Analytics, Cost Model, Caching},
location = {Jeju, Republic of Korea},
series = {SMA 2020}
}

@inproceedings{10.1145/3357384.3358090,
author = {Chen, Yuxing and Lu, Jiaheng and Chen, Chen and Hoque, Mohammad and Tarkoma, Sasu},
title = {Cost-effective Resource Provisioning for Spark Workloads},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3358090},
doi = {10.1145/3357384.3358090},
abstract = {Spark is one of the prevalent big data analytical platforms. Configuring proper resource provision for Spark jobs is challenging but essential for organizations to save time, achieve high resource utilization, and remain cost-effective. In this paper, we study the challenge of determining the proper parameter values that meet the performance requirements of workloads while minimizing both resource cost and resource utilization time. We propose a simulation-based cost model to predict the performance of jobs accurately. We achieve low-cost training by taking advantage of simulation framework, i.e., Monte Carlo (MC) simulation, which uses a small amount of data and resources to make a reliable prediction for larger datasets and clusters. The salient feature of our method is that it allows us to invest low training cost while obtaining an accurate prediction. Through experiments with six benchmark workloads, we demonstrate that the cost model yields less than 7% error on average prediction accuracy and the recommendation achieves up to 5x resource cost saving.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {2477–2480},
numpages = {4},
keywords = {spark executor parameter, simulation, resource provisioning, performance metrics, cost model},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1109/CCGRID.2009.77,
author = {Nadeem, Farrukh and Fahringer, Thomas},
title = {Using Templates to Predict Execution Time of Scientific Workflow Applications in the Grid},
year = {2009},
isbn = {9780769536224},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2009.77},
doi = {10.1109/CCGRID.2009.77},
abstract = {Workflow execution time predictions for Grid infrastructures is of critical importance for optimized workflow executions, advance reservations of resources, and overhead analysis. Predicting workflow execution time is complex due to multeity of workflow structures, involvement of several Grid resources in workflow execution, complex dependencies of workflow activities and dynamic behavior of the Grid. In this paper we present an online workflow execution time prediction system exploiting similarity templates. The workflows are characterized considering the attributes describing their performance at different Grid infrastructural levels. A “supervised exhaustive search” is employed to find suitable templates. We also make a provision of including expert user knowledge about the workflow performance in the procession of our methods. Results for three real world applications are presented to show the effectiveness of our approach.},
booktitle = {Proceedings of the 2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid},
pages = {316–323},
numpages = {8},
keywords = {Workflow Performance Prediction, Application Workflow},
series = {CCGRID '09}
}

@inproceedings{10.1145/2451617.2451619,
author = {Kowal, Matthias and Schulze, Sandro and Schaefer, Ina},
title = {Towards efficient SPL testing by variant reduction},
year = {2013},
isbn = {9781450318679},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451617.2451619},
doi = {10.1145/2451617.2451619},
abstract = {Testing software systems plays a pivotal role for quality, reliability, and safety of such systems. Several approaches exist that provide efficient algorithms to test one software system. However, in the context of variable software systems, called software product lines (SPLs), testing has to deal with potentially thousands of variants. Unfortunately, current approaches do not scale to this problem and thus testing SPLs efficiently is a challenging task. In this paper, we propose an approach to reduce the test set by explicitly modeling information about shared resources and communication in feature models. As a result, we can figure out features that interact with each other and thus are more likely to cause problems. We show with a small case study that our approach reduces both, the features under test as well as the time for computing all feature combinations to be tested.},
booktitle = {Proceedings of the 4th International Workshop on Variability &amp; Composition},
pages = {1–6},
numpages = {6},
keywords = {testing, software product lines, feature models},
location = {Fukuoka, Japan},
series = {VariComp '13}
}

@inproceedings{10.1007/978-3-030-60450-9_25,
author = {Hu, Fuyu and Ouyang, Chunping and Liu, Yongbin and Bu, Yi},
title = {MTNE: A Multitext Aware Network Embedding for Predicting Drug-Drug Interaction},
year = {2020},
isbn = {978-3-030-60449-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60450-9_25},
doi = {10.1007/978-3-030-60450-9_25},
abstract = {Identifying drug-drug interactions (DDIs) is an important research topic in drug discovery. Accurate predictions of DDIs reduce the unexpected interactions during the drug development process and play a significant role in drug safety surveillance. Many existing methods used drug properties to predict the unobserved interactions between drugs. However, semantic relations between drug features have seldom been considered and have resulted in low prediction accuracy. In addition, incomplete annotated data and sparse drug characteristics have greatly hindered the performance of DDI predictions. In this paper, we proposed a network embedding method named MTNE (MultiText Aware Network Embedding) that considers multiple external information sources. MTNE learns the dynamic representation of the drug description and the pharmacodynamics through a mutual attention mechanism. It effectively maps a high-dimension drug-drug interaction network to low dimension vector spaces by taking advantage of both the textual information of drugs and the topological information of the drug-drug interaction network. We conduct experiments based on the DrugBank dataset. The results show that MTNE improves the performance of DDI predictions with an AUC value of 76.1% and outperforms other state-of-the-art methods. Moreover, MTNE can also achieve high-quality prediction results on sparse datasets.},
booktitle = {Natural Language Processing and Chinese Computing: 9th CCF International Conference, NLPCC 2020, Zhengzhou, China, October 14–18, 2020, Proceedings, Part I},
pages = {306–318},
numpages = {13},
keywords = {Dynamic representation, Topological information, Text information, Network embedding, Drug-drug interaction},
location = {Zhengzhou, China}
}

@article{10.1016/j.infsof.2017.02.004,
author = {Ahmed, Bestoun S. and Gambardella, Luca M. and Afzal, Wasif and Zamli, Kamal Z.},
title = {Handling constraints in combinatorial interaction testing in the presence of multi objective particle swarm and multithreading},
year = {2017},
issue_date = {June 2017},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {86},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.02.004},
doi = {10.1016/j.infsof.2017.02.004},
abstract = {ContextCombinatorial testing strategies have lately received a lot of attention as a result of their diverse applications. In its simple form, a combinatorial strategy can reduce several input parameters (configurations) of a system into a small set based on their interaction (or combination). In practice, the input configurations of software systems are subjected to constraints, especially in case of highly configurable systems. To implement this feature within a strategy, many difficulties arise for construction. While there are many combinatorial interaction testing strategies nowadays, few of them support constraints. ObjectiveThis paper presents a new strategy, to construct combinatorial interaction test suites in the presence of constraints. MethodThe design and algorithms are provided in detail. To overcome the multi-judgement criteria for an optimal solution, the multi-objective particle swarm optimisation and multithreading are used. The strategy and its associated algorithms are evaluated extensively using different benchmarks and comparisons. ResultsOur results are promising as the evaluation results showed the efficiency and performance of each algorithm in the strategy. The benchmarking results also showed that the strategy can generate constrained test suites efficiently as compared to state-of-the-art strategies. ConclusionThe proposed strategy can form a new way for constructing of constrained combinatorial interaction test suites. The strategy can form a new and effective base for future implementations.},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {20–36},
numpages = {17},
keywords = {Test generation tools, Test case design techniques, Search-based software engineering, Multi-objective particle swarm optimisation, Constrained combinatorial interaction}
}

@inproceedings{10.1145/3341162.3343804,
author = {Zhan, Yuting and Haddadi, Hamed},
title = {Activity prediction for mapping contextual-temporal dynamics},
year = {2019},
isbn = {9781450368698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341162.3343804},
doi = {10.1145/3341162.3343804},
abstract = {Existing activity recognition technologies empower the smart home for perceiving the ambient environment. Efficient activity prediction, based on activity recognition, can enable the smart home to provide timely personalized services. However, predicting the next activity and its precise occurrence period are challenging due to the complexity of modelling human behaviour. In this work, we aim to understand whether the temporal information integrated into the deep learning networks can improve the prediction accuracy in both predicting the next activity and its timing. We develop two Long Short-Term Memory (LSTM) models, both with deep contextualized word representation on sensor labels, one with temporal information and one without. Our results highlight that if temporal information is used appropriately, the model with timestamp can outperform the model without this information. While modelling human activity prediction, comprehending the contextual-temporal dynamics is highly important.},
booktitle = {Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers},
pages = {246–249},
numpages = {4},
keywords = {time series data, recurrent neural networks, activity recognition, activity prediction},
location = {London, United Kingdom},
series = {UbiComp/ISWC '19 Adjunct}
}

@article{10.1016/j.future.2019.05.067,
author = {Li, Junnan and Lu, Zhihui and Tong, Yu and Wu, Jie and Huang, Shalin and Qiu, Meikang and Du, Wei},
title = {A general AI-defined attention network for predicting CDN performance},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {100},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.05.067},
doi = {10.1016/j.future.2019.05.067},
journal = {Future Gener. Comput. Syst.},
month = nov,
pages = {759–769},
numpages = {11},
keywords = {Deep neural network, Sequence learning, Content delivery network, Attention mechanism, Artificial intelligence}
}

@article{10.1007/s10766-017-0487-0,
author = {Zheng, Xinnian and John, Lizy K. and Gerstlauer, Andreas},
title = {LACross: Learning-Based Analytical Cross-Platform Performance and Power Prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {6},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-017-0487-0},
doi = {10.1007/s10766-017-0487-0},
abstract = {Fast and accurate performance and power prediction is a key challenge in pre-silicon design evaluations during the early phases of hardware and software co-development. Performance evaluation using full-system simulation is prohibitively slow, especially with real world applications. By contrast, analytical models are not sufficiently accurate or still require target-specific execution statistics that may be slow or difficult to obtain. In this paper, we present LACross, a learning-based cross-platform prediction technique aimed at predicting the time-varying performance and power of a benchmark on a target platform using hardware counter statistics obtained while running natively on a host platform. We employ a fine-grained phase-based approach, where the learning algorithm synthesizes analytical proxy models that predict the performance and power of the workload in each program phase from performance statistics obtained on the host. Our learning approach relies on a one-time training phase using a target reference model or real hardware. We train our models on less than 160 programs from the ACM ICPC database, and demonstrate prediction accuracy and speed on 35 programs from SPEC CPU2006, MiBench and SD-VBS benchmark suites. Results show that with careful choice of phase granularity, we can achieve on average over 97% performance and power prediction accuracy at simulation speeds of over 500 MIPS.},
journal = {Int. J. Parallel Program.},
month = dec,
pages = {1488–1514},
numpages = {27},
keywords = {System-level design, Performance and power prediction, Learning-based, Cross-platform}
}

@inproceedings{10.1145/3241815.3241875,
author = {Park, Young},
title = {Predicting Personalized Student Performance in Computing-Related Majors via Collaborative Filtering},
year = {2018},
isbn = {9781450359542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241815.3241875},
doi = {10.1145/3241815.3241875},
abstract = {The last decade has seen a significant enrollment surge in various computing-related majors. However, choosing the right computing major is vital to students' academic and career success. Personalized prediction of performance in closely related computing majors will help individual students better find the right major for them. This paper proposes a method of predicting student performance in computing majors. Our method is based on collaborative filtering using enhanced similarity and yields personalized predictions of student grades in courses required for each computing major. Prediction accuracy is enhanced by analyzing computing major-specific course characteristics, such as core courses, course prerequisites, and course levels.},
booktitle = {Proceedings of the 19th Annual SIG Conference on Information Technology Education},
pages = {151},
numpages = {1},
keywords = {recommender systems, personalized student performance, grade prediction, computing-related majors, collaborative filtering},
location = {Fort Lauderdale, Florida, USA},
series = {SIGITE '18}
}

@article{10.1016/j.procs.2021.08.083,
author = {Oeda, Shinichi and Shimizu, Daiki},
title = {Verification of Usefulness of Student Modeling with Real Educational Data using Convex Factorization Machines},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.08.083},
doi = {10.1016/j.procs.2021.08.083},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {804–811},
numpages = {8},
keywords = {Intelligent Tutoring Systems, Recommendation, Convex Optimization, Factorization Machines, Convex Factorization Machines, Student Modeling, Educational Data Mining}
}

@inproceedings{10.1145/3281375.3281396,
author = {Hentona, Asahi and Nonaka, Hirofumi and Nakai, Kensei and Sakumoto, Takeshi and Kataoka, Shotaro and Alem\'{a}n Carre\'{o}n, Elisa Claire and Mendoza Espa\~{n}a, Hugo Alberto and Hiraoka, Toru and Hirota, Masaharu},
title = {Community detection and growth potential prediction from patent citation networks},
year = {2018},
isbn = {9781450356220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281375.3281396},
doi = {10.1145/3281375.3281396},
abstract = {The scoring of patents is useful for technology management analysis. Therefore, a necessity of developing citation network clustering and prediction of future citations for practical patent scoring arises. In this paper, we propose a community detection method using the Node2vec. And in order to analyze growth potential we compare three "time series analysis methods", the Long Short-Term Memory (LSTM), ARIMA model, and Hawkes Process. The results of our experiments, we could find common technical points from those clusters by Node2vec. Furthermore, we found that the prediction accuracy of the ARIMA model was higher than that of other models.},
booktitle = {Proceedings of the 10th International Conference on Management of Digital EcoSystems},
pages = {204–211},
numpages = {8},
keywords = {patent analysis, hawkes process, growth prediction, community detection, Node2vec, LSTM, ARIMA},
location = {Tokyo, Japan},
series = {MEDES '18}
}

@article{10.1155/2021/6611885,
author = {Khalaf, Jamal Abdulrazzaq and Majeed, Abeer A. and Aldlemy, Mohammed Suleman and Ali, Zainab Hasan and Al Zand, Ahmed W. and Adarsh, S. and Bouaissi, Aissa and Hameed, Mohammed Majeed and Yaseen, Zaher Mundher and Al-Emran, Mostafa},
title = {Hybridized Deep Learning Model for Perfobond Rib Shear Strength Connector Prediction},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6611885},
doi = {10.1155/2021/6611885},
abstract = {Accurate and reliable prediction of Perfobond Rib Shear Strength Connector (PRSC) is considered as a major issue in the structural engineering sector. Besides, selecting the most significant variables that have a major influence on PRSC in every important step for attaining economic and more accurate predictive models, this study investigates the capacity of deep learning neural network (DLNN) for shear strength prediction of PRSC. The proposed DLNN model is validated against support vector regression (SVR), artificial neural network (ANN), and M5 tree model. In the second scenario, a comparable AI model hybridized with genetic algorithm (GA) as a robust bioinspired optimization approach for optimizing the related predictors for the PRSC is proposed. Hybridizing AI models with GA as a selector tool is an attempt to acquire the best accuracy of predictions with the fewest possible related parameters. In accordance with quantitative analysis, it can be observed that the GA-DLNN models required only 7 input parameters and yielded the best prediction accuracy with highest correlation coefficient (R = 0.96) and lowest value root mean square error (RMSE = 0.03936 KN). However, the other comparable models such as GA-M5Tree, GA-ANN, and GA-SVR required 10 input parameters to obtain a relatively acceptable level of accuracy. Employing GA as a feature parameter selection technique improves the precision of almost all hybrid models by optimally removing redundant variables which decrease the efficiency of the model.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@article{10.1007/s10664-014-9336-6,
author = {Sobernig, Stefan and Apel, Sven and Kolesnikov, Sergiy and Siegmund, Norbert},
title = {Quantifying structural attributes of system decompositions in 28 feature-oriented software product lines},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9336-6},
doi = {10.1007/s10664-014-9336-6},
abstract = {A key idea of feature orientation is to decompose a software product line along the features it provides. Feature decomposition is orthogonal to object-oriented decomposition--it crosscuts the underlying package and class structure. It has been argued often that feature decomposition improves system structure by reducing coupling and by increasing cohesion. However, recent empirical findings suggest that this is not necessarily the case. In this exploratory, observational study, we investigate the decompositions of 28 feature-oriented software product lines into classes, features, and feature-specific class fragments. The product lines under investigation are implemented using the feature-oriented programming language Fuji. In particular, we quantify and compare the internal attributes import coupling and cohesion of the different product-line decompositions in a systematic, reproducible manner. For this purpose, we adopt three established software measures (e.g., coupling between units, CBU; internal-ratio unit dependency, IUD) as well as standard concentration statistics (e.g., Gini coefficient). In our study, we found that feature decomposition can be associated with higher levels of structural coupling in a product line than a decomposition into classes. Although coupling can be concentrated in very few features in most feature decompositions, there are not necessarily hot-spot features  in all product lines. Interestingly, feature cohesion is not necessarily higher than class cohesion, whereas features are more equal in serving dependencies internally than classes of a product line. Our empirical study raises critical questions about alleged advantages of feature decomposition. At the same time, we demonstrate how our measurement approach of coupling and cohesion has potential to support static and dynamic analyses of software product lines (i.e., type checking and feature-interaction detection) by facilitating product sampling.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1670–1705},
numpages = {36},
keywords = {Structural coupling, Structural cohesion, Software product lines, Software measurement, Fuji, Feature-oriented programming}
}

@article{10.1007/s00500-020-05564-6,
author = {Xu, Longhua and Huang, Chuanzhen and Niu, Jiahui and Li, Chengwu and Wang, Jun and Liu, Hanlian and Wang, Xiaodan},
title = {An improved case-based reasoning method and its application to predict machining performance},
year = {2021},
issue_date = {Apr 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {7},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05564-6},
doi = {10.1007/s00500-020-05564-6},
abstract = {In the machining process, the machining performance which mainly refers to machined surface quality and cutting forces is hard to predict under different tool wear status. In this work, an improved case-based reasoning (ICBR) method is proposed to predict both the cutting force and machined surface roughness. With the emergence of new problem, ICBR method obtains solutions to new problem through case retrieval and reuse. In case retrieval stage, K similar cases to the new problem were retrieved using K nearest neighbor method. By means of the K similar cases, support vector regression machine (SVR) model was established to give the solution of the new problem in case of the reuse stage of ICBR method. Artificial neural network (ANN) was introduced to estimate the influence of machining parameters and tool wear on machining performance. As the ANN and SVR models contain unknown parameters, the novel particle swarm optimization algorithm was proposed to train these models for its capability of fast convergence and global optimum. The proposed ICBR method was used to predict the surface roughness and cutting force. The results showed the proposed ICBR method can give superior prediction accuracy and lower Mean square error than other popular intelligent models. Meantime, the ICBR method possesses good robustness and can be used for the actual machining process.},
journal = {Soft Comput.},
month = apr,
pages = {5683–5697},
numpages = {15},
keywords = {NPSO algorithm, ANN, SVR, Case-based reasoning, Machining performance}
}

@inproceedings{10.1007/978-3-030-22244-4_1,
author = {Zhai, Jiahe and Zhu, Zhengzhou and Li, Deqi and Huang, Nanxiong and Zhang, Kaiyue and Huang, Yuqi},
title = {A Learning Early-Warning Model Based on Knowledge Points},
year = {2019},
isbn = {978-3-030-22243-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-22244-4_1},
doi = {10.1007/978-3-030-22244-4_1},
abstract = {Learning early-warning is one of the important ways to realize adaptive learning. Aiming at the problem of too large prediction granularity in learning early-warning, we divide student’s characters into three dimensions (knowledge, behavior and emotion). Secondly, we predict the student’s master degree of knowledge, based on the knowledge point. And then we realized learning early-warning model. In the model, we take 60 points as the learning early-warning standard, and take RF and GDBT as base classifiers, and give the strategy of selecting the basic model. The experiment shows that the prediction of knowledge mastery of the model and the real data Pearson correlation coefficient can reach 0.904279, and the prediction accuracy of the model below the early-warning line can reach 76%.},
booktitle = {Intelligent Tutoring Systems: 15th International Conference, ITS 2019, Kingston, Jamaica, June 3–7, 2019, Proceedings},
pages = {1–6},
numpages = {6},
keywords = {Learning early-warning, Emotion, Type of question, Knowledge points},
location = {Kingston, Jamaica}
}

@inproceedings{10.1145/1178677.1178712,
author = {Kennedy, Lyndon S. and Chang, Shih-Fu and Kozintsev, Igor V.},
title = {To search or to label? predicting the performance of search-based automatic image classifiers},
year = {2006},
isbn = {1595934952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1178677.1178712},
doi = {10.1145/1178677.1178712},
abstract = {In this work we explore the trade-offs in acquiring training data for image classification models through automated web search as opposed to human annotation. Automated web search comes at no cost in human labor, but sometimes leads to decreased classification performance, while human annotations come at great expense in human labor but result in better performance. The primary contribution of this work is a system for predicting which visual concepts will show the greatest increase in performance from investing human effort in obtaining annotations. We propose to build this system as an estimation of the absolute gain in average precision (AP) experienced from using human annotations instead of web search. To estimate the AP gain, we rely on statistical classifiers built on top of a number of quality prediction features. We employ a feature selection algorithm to compare the quality of each of the predictors and find that cross-domain image similarity and cross-domain model generalization metrics are strong predictors, while concept frequency and within-domain model quality are weak predictors. In a test application, we find that the prediction scheme can result in a savings in annotation effort of up to 75%, while only incurring marginal damage (10% relative decrease in mean average precision) to the overall performance of the concept models.},
booktitle = {Proceedings of the 8th ACM International Workshop on Multimedia Information Retrieval},
pages = {249–258},
numpages = {10},
keywords = {search-based concept models, performance prediction},
location = {Santa Barbara, California, USA},
series = {MIR '06}
}

@inproceedings{10.5555/3540261.3541549,
author = {Sun, Xinwei and Wu, Botong and Zheng, Xiangyu and Liu, Chang and Chen, Wei and Qin, Tao and Liu, Tie-Yan},
title = {Recovering latent causal factor for generalization to distributional shifts},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Distributional shifts between training and target domains may degrade the prediction accuracy of learned models, mainly because these models often learn features that possess only correlation rather than causal relation with the output. Such a correlation, which is known as "spurious correlation" statistically, is domain-dependent hence may fail to generalize to unseen domains. To avoid such a spurious correlation, we propose Latent Causal Invariance Models (LaCIM) that specifies the underlying causal structure of the data and the source of distributional shifts, guiding us to pursue only causal factor for prediction. Specifically, the LaCIM introduces a pair of correlated latent factors: (a) causal factor and (b) others, while the extent of this correlation is governed by a domain variable that characterizes the distributional shifts. On the basis of this, we prove that the distribution of observed variables conditioning on latent variables is shift-invariant. Equipped with such an invariance, we prove that the causal factor can be recovered without mixing information from others, which induces the ground-truth predicting mechanism. We propose a Variational-Bayesian-based method to learn this invariance for prediction. The utility of our approach is verified by improved generalization to distributional shifts on various real-world data.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1288},
numpages = {14},
series = {NIPS '21}
}

@article{10.1109/TCBB.2019.2953908,
author = {Wang, Bing and Mei, Changqing and Wang, Yuanyuan and Zhou, Yuming and Cheng, Mu-Tian and Zheng, Chun-Hou and Wang, Lei and Zhang, Jun and Chen, Peng and Xiong, Yan},
title = {Imbalance Data Processing Strategy for Protein Interaction Sites Prediction},
year = {2019},
issue_date = {May-June 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {18},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2953908},
doi = {10.1109/TCBB.2019.2953908},
abstract = {Protein-protein interactions play essential roles in various biological progresses. Identifying protein interaction sites can facilitate researchers to understand life activities and therefore will be helpful for drug design. However, the number of experimental determined protein interaction sites is far less than that of protein sites in protein-protein interaction or protein complexes. Therefore, the negative and positive samples are usually imbalanced, which is common but bring result bias on the prediction of protein interaction sites by computational approaches. In this work, we presented three imbalance data processing strategies to reconstruct the original dataset, and then extracted protein features from the evolutionary conservation of amino acids to build a predictor for identification of protein interaction sites. On a dataset with 10,430 surface residues but only 2,299 interface residues, the imbalance dataset processing strategies can obviously reduce the prediction bias, and therefore improve the prediction performance of protein interaction sites. The experimental results show that our prediction models can achieve a better prediction performance, such as a prediction accuracy of 0.758, or a high F-measure of 0.737, which demonstrated the effectiveness of our method.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = nov,
pages = {985–994},
numpages = {10}
}

@inproceedings{10.1145/3324884.3416620,
author = {Dorn, Johannes and Apel, Sven and Siegmund, Norbert},
title = {Mastering uncertainty in performance estimations of configurable software systems},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416620},
doi = {10.1145/3324884.3416620},
abstract = {Understanding the influence of configuration options on performance is key for finding optimal system configurations, system understanding, and performance debugging. In prior research, a number of performance-influence modeling approaches have been proposed, which model a configuration option's influence and a configuration's performance as a scalar value. However, these point estimates falsely imply a certainty regarding an option's influence that neglects several sources of uncertainty within the assessment process, such as (1) measurement bias, (2) model representation and learning process, and (3) incomplete data. This leads to the situation that different approaches and even different learning runs assign different scalar performance values to options and interactions among them. The true influence is uncertain, though. There is no way to quantify this uncertainty with state-of-the-art performance modeling approaches. We propose a novel approach, P4, based on probabilistic programming that explicitly models uncertainty for option influences and consequently provides a confidence interval for each prediction of a configuration's performance alongside a scalar. This way, we can explain, for the first time, why predictions may cause errors and which option's influences may be unreliable. An evaluation on 12 real-world subject systems shows that P4's accuracy is in line with the state of the art while providing reliable confidence intervals, in addition to scalar predictions.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {684–696},
numpages = {13},
keywords = {P4, configurable software systems, performance-influence modeling, probabilistic programming},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/974044.974089,
author = {Wu, Xiuping and Woodside, Murray},
title = {Performance modeling from software components},
year = {2004},
isbn = {1581136730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974044.974089},
doi = {10.1145/974044.974089},
abstract = {When software products are assembled from pre-defined components, performance prediction should be based on the components also. This supports rapid model-building, using previously calibrated sub-models or "performance components", in sync with the construction of the product. The specification of a performance component must be tied closely to the software component specification, but it also includes performance related parameters (describing workload characteristics and demands), and it abstracts the behaviour of the component in various ways (for reasons related to practical factors in performance analysis). A useful set of abstractions and parameters are already defined for layered performance modeling. This work extends them to accommodate software components, using a new XML-based language called Component-Based Modeling Language (CBML). With CBML, compatible components can be inserted into slots provided in a hierarchical component specification based on the UML component model.},
booktitle = {Proceedings of the 4th International Workshop on Software and Performance},
pages = {290–301},
numpages = {12},
keywords = {submodel, software performance, software component, performance prediction, layered queue model, generative programming, LQN, CBML},
location = {Redwood Shores, California},
series = {WOSP '04}
}

@inproceedings{10.1145/1229428.1229479,
author = {Lee, Benjamin C. and Brooks, David M. and de Supinski, Bronis R. and Schulz, Martin and Singh, Karan and McKee, Sally A.},
title = {Methods of inference and learning for performance modeling of parallel applications},
year = {2007},
isbn = {9781595936028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1229428.1229479},
doi = {10.1145/1229428.1229479},
abstract = {Increasing system and algorithmic complexity combined with a growing number of tunable application parameters pose significant challenges for analytical performance modeling. We propose a series of robust techniques to address these challenges. In particular, we apply statistical techniques such as clustering, association, and correlation analysis, to understand the application parameter space better. We construct and compare two classes of effective predictive models: piecewise polynomial regression and artifical neural networks. We compare these techniques with theoretical analyses and experimental results. Overall, both regression and neural networks are accurate with median error rates ranging from 2.2 to 10.5 percent. The comparable accuracy of these models suggest differentiating features will arise from ease of use, transparency, and computational efficiency.},
booktitle = {Proceedings of the 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {249–258},
numpages = {10},
keywords = {statistics, regression, performance prediction, numerical methods, neural networks},
location = {San Jose, California, USA},
series = {PPoPP '07}
}

@inproceedings{10.1007/978-3-030-23502-4_14,
author = {Sondur, Sanjeev and Kant, Krishna},
title = {Towards Automated Configuration of Cloud Storage Gateways: A Data Driven Approach},
year = {2019},
isbn = {978-3-030-23501-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-23502-4_14},
doi = {10.1007/978-3-030-23502-4_14},
abstract = {Cloud storage gateways (CSGs) are an essential part of enterprises to take advantage of the scale and flexibility of cloud object store. A CSG provides clients the impression of a locally configured large size block-based storage device, which needs to be mapped to remote cloud storage which is invariably object based. Proper configuration of the cloud storage gateway is extremely challenging because of numerous parameters involved and interactions among them. In this paper, we study this problem for a commercial CSG product that is typical of offerings in the market. We explore how machine learning techniques can be exploited both for the forward problem (i.e. predicting performance from the configuration parameters) and backward problem (i.e. predicting configuration parameter values from the target performance). Based on extensive testing with real world customer workloads, we show that it is possible to achieve excellent prediction accuracy while ensuring that the model is not overfitted to the data.},
booktitle = {Cloud Computing – CLOUD 2019: 12th International Conference, Held as Part of the Services Conference Federation, SCF 2019, San Diego, CA, USA, June 25–30, 2019, Proceedings},
pages = {192–207},
numpages = {16},
keywords = {Machine learning, Configuration management, Performance, Object store, Cloud storage gateway},
location = {San Diego, CA, USA}
}

@article{10.1016/j.jbi.2019.103138,
author = {Li, Ziyi and Roberts, Kirk and Jiang, Xiaoqian and Long, Qi},
title = {Distributed learning from multiple EHR databases: Contextual embedding models for medical events},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {92},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2019.103138},
doi = {10.1016/j.jbi.2019.103138},
journal = {J. of Biomedical Informatics},
month = apr,
numpages = {10},
keywords = {Diagnoses prediction, Contextual embedding models, EHR data, Distributed computing}
}

@article{10.1007/s00521-020-05659-z,
author = {Meng, Xi and Zhang, Yin and Qiao, Junfei},
title = {An adaptive task-oriented RBF network for key water quality parameters prediction in wastewater treatment process},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {17},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05659-z},
doi = {10.1007/s00521-020-05659-z},
abstract = {The real-time availability of key water quality parameters is of great importance for an advanced and optimized process control in wastewater treatment plants (WWTPs). However, due to the complex environment conditions and costly measuring instruments, it is generally difficult and time-consuming to measure certain key water quality parameters online, such as the effluent biochemical oxygen demand (BOD) and the effluent total nitrogen (TN). Recently, artificial neural networks have powered the online prediction tasks in several WWTPs. Hence, in this paper, an adaptive task-oriented radial basis function (ATO-RBF) network is developed to design prediction models for accurate timely acquirements of the effluent BOD and the effluent TN. The advantage of ATO-RBF network is that the architecture is not designed by human engineers; it is adaptively generated from the data to be processed. First, to enhance the learning ability and generalization performance of prediction models, an error correction-based growing strategy and a second-order learning algorithm are combined to design the ATO-RBF network. Then, RFB nodes with low significance would be pruned without sacrificing the learning accuracy, making the prediction model more compact. Additionally, the convergence of the ATO-RBF network is analyzed based on the Lyapunov criterion, which can guarantee its feasibility in practical applications. Finally, the proposed methodology is verified by benchmark simulations and real industrial data, showing superior prediction accuracy in compared with conventional methods.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {11401–11414},
numpages = {14},
keywords = {Water quality parameters prediction, Second-order algorithm, Adaptive task-oriented, Radial basis function (RBF) networks}
}

@inproceedings{10.1145/1450095.1450103,
author = {Dubach, Christophe and Jones, Timothy M. and O'Boyle, Michael F.P.},
title = {Exploring and predicting the architecture/optimising compiler co-design space},
year = {2008},
isbn = {9781605584690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1450095.1450103},
doi = {10.1145/1450095.1450103},
abstract = {Embedded processor performance is dependent on both the underlying architecture and the compiler optimisations applied. However, designing both simultaneously is extremely difficult to achieve due to the time constraints designers must work under. Therefore, current methodology involves designing compiler and architecture in isolation, leading to sub-optimal performance of the final product.This paper develops a novel approach to this co-design space problem. For any microarchitectural configuration we automatically predict the performance that an optimising compiler would achieve without actually building it. Once trained, a single run of -O1 on the new architecture is enough to make a prediction with just a 1.6% error rate. This allows the designer to accurately choose an architectural configuration with knowledge of how an optimising compiler will perform on it. We use this to find the best optimising compiler/architectural configuration in our co-design space and demonstrate that it achieves an average 13% performance improvement and energy savings of 23% compared to the baseline, leading to an energy-delay (ED) value of 0.67.},
booktitle = {Proceedings of the 2008 International Conference on Compilers, Architectures and Synthesis for Embedded Systems},
pages = {31–40},
numpages = {10},
keywords = {performance prediction, design-space exploration, architecture/compiler co-design},
location = {Atlanta, GA, USA},
series = {CASES '08}
}

@inproceedings{10.1007/978-3-030-87571-8_11,
author = {Li, Shuang and Xu, Lei and Wang, Yuchen and Xu, Lizhen},
title = {Self-learning Tags and Hybrid Responses for Deep Knowledge Tracing},
year = {2021},
isbn = {978-3-030-87570-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87571-8_11},
doi = {10.1007/978-3-030-87571-8_11},
abstract = {Knowledge Tracing, as a classic task of evaluating student knowledge mastery and predicting performance by modeling student response sequences, has become one of the key motivations for stimulating the vigorous development of personalized online education. With the support of Recurrent Neural Network, Deep Knowledge Tracing (DKT) and its variants demonstrate remarkable KT performance on account of their excellent learning ability and knowledge state representation. However, the drawbacks of these models have gradually emerged with the surge in student interaction data scale and the variety of interaction forms, which include employing the pre-defined knowledge point tags and the single response feature input. In this paper, we advocate a brand-new LTDKT-HR model, which constructs exercise embedding mapped from exercise space to tag space by self-training and optimizes input by adding an effective feature of first response time to the original feature of whether answer is correct or not. Sufficient experiments on two open datasets prove that LTDKT-HR outperforms the general DKT in student performance prediction, that is, self-learning tags are superior to existing manual tags. In addition, the proposed model can dig out the influence between exercises, which provides the mathematical basis for further setting exercise relationship constraints.},
booktitle = {Web Information Systems and Applications: 18th International Conference, WISA 2021, Kaifeng, China, September 24–26, 2021, Proceedings},
pages = {121–132},
numpages = {12},
keywords = {Knowledge tracing, Deep learning, Student response sequences},
location = {Kaifeng, China}
}

@inproceedings{10.1145/3388440.3414863,
author = {Thapaliya, Naseeb and Goluguri, Lavanya and Suthaharan, Shan},
title = {Asymptotically Stable Privacy Protection Technique for fMRI Shared Data over Distributed Computer Networks},
year = {2020},
isbn = {9781450379649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388440.3414863},
doi = {10.1145/3388440.3414863},
abstract = {This paper presents a computational technique that leverages the asymptotic-stabilization behavior of transition probabilities that are characterized by two-state Markov chain. These asymptotic probabilities help the computational technique to protect the privacy of the functional magnetic resonance imaging (fMRI) data that is shared over a public distributed computer network. In general, the fMRI signals reveal a large number of correlated brain features that can be utilized in the development of predictive models for extracting brain networks and infer privacy information of an individual. These features make fMRI data highly vulnerable to privacy attacks. To conceal these features for privacy protection, we transform them to an asymptotic state of an fMRI signal using the concepts of asymptotic stabilization with two-sate Markov chain, and the compressed sensing and compressed learning techniques. The proposed predictive model is built using the asymptotically stabilized fMRI signals, rather than the original signals, which enhance the protection of privacy. Hence, the transformed signal, instead of the original signal, may be shared in public computer networks, such as the cloud computing network. The computer simulations show that the proposed predictive model provides very high prediction accuracy, while providing very strong privacy protection.},
booktitle = {Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {100},
numpages = {8},
keywords = {functional magnetic resonance imaging, feature space, distributed computing, dimensionality reduction, Markov chain, Machine learning},
location = {Virtual Event, USA},
series = {BCB '20}
}

@article{10.1016/j.artint.2013.10.003,
author = {Hutter, Frank and Xu, Lin and Hoos, Holger H. and Leyton-Brown, Kevin},
title = {Algorithm runtime prediction: Methods &amp; evaluation},
year = {2014},
issue_date = {January, 2014},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {206},
issn = {0004-3702},
url = {https://doi.org/10.1016/j.artint.2013.10.003},
doi = {10.1016/j.artint.2013.10.003},
abstract = {Perhaps surprisingly, it is possible to predict how long an algorithm will take to run on a previously unseen input, using machine learning techniques to build a model of the algorithm@?s runtime as a function of problem-specific instance features. Such models have important applications to algorithm analysis, portfolio-based algorithm selection, and the automatic configuration of parameterized algorithms. Over the past decade, a wide variety of techniques have been studied for building such models. Here, we describe extensions and improvements of existing models, new families of models, and-perhaps most importantly-a much more thorough treatment of algorithm parameters as model inputs. We also comprehensively describe new and existing features for predicting algorithm runtime for propositional satisfiability (SAT), travelling salesperson (TSP) and mixed integer programming (MIP) problems. We evaluate these innovations through the largest empirical analysis of its kind, comparing to a wide range of runtime modelling techniques from the literature. Our experiments consider 11 algorithms and 35 instance distributions; they also span a very wide range of SAT, MIP, and TSP instances, with the least structured having been generated uniformly at random and the most structured having emerged from real industrial applications. Overall, we demonstrate that our new models yield substantially better runtime predictions than previous approaches in terms of their generalization to new problem instances, to new algorithms from a parameterized space, and to both simultaneously.},
journal = {Artif. Intell.},
month = jan,
pages = {79–111},
numpages = {33},
keywords = {Travelling salesperson problem, Supervised machine learning, Response surface models, Propositional satisfiability, Performance prediction, Mixed integer programming, Highly parameterized algorithms, Empirical performance models}
}

@inproceedings{10.1145/3412841.3442068,
author = {Bhagtya, Paras and Raghavan, S and Chandraseakran, K and D., Usha},
title = {Workload classification in multi-vm cloud environment using deep neural network model},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442068},
doi = {10.1145/3412841.3442068},
abstract = {In this competitive world, everyone needs to be prepared for future risks and emergency conditions. In a multi-cloud environment users can easily shift from one cloud to another cloud because of the available data and application transfer technologies. Therefore a strong forecast system is mandatory for such conditions and to stop user migration to other clouds. Virtual Machine (VM) plays an important role in effective resource management and cost reduction in cloud infrastructure. Workload prediction in multi-VM is very useful to handle uncertain situations. In this paper, we propose a promising workload prediction technique that can handle the workload from multiple virtual machines. It has a pre-processing and feature selection engine that handles direct data from these virtual machines and the model is strong enough in classifying data based on historical workloads. This classification enables extra knowledge for the cloud vendor to optimize resource usage. This strategy can be used for producing an alarm whenever there is continuously high utilization of resources in the future. Here, our prediction methodology is experimented with a popular real-world Grid Workload Archive (GWA) dataset and it achieves more than 85% prediction accuracy for CPU, Memory and Disk Utilization.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {79–82},
numpages = {4},
keywords = {grid workload archive, long short term memory, neural network, virtual machine},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1155/2021/8100371,
author = {Dong, Hai and Gao, Xiuxiu and Wei, Mingqi and Hern\'{a}ndez-P\'{e}rez, Jos\'{e} Alfredo},
title = {Quality Prediction of Fused Deposition Molding Parts Based on Improved Deep Belief Network},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/8100371},
doi = {10.1155/2021/8100371},
abstract = {Tensile strength, warping degree, and surface roughness are important indicators to evaluate the quality of fused deposition modeling (FDM) parts, and their accurate and stable prediction is helpful to the development of FDM technology. Thus, a quality prediction method of FDM parts based on an optimized deep belief network was proposed. To determine the combination of process parameters that have the greatest influence on the quality of FDM parts, the correlation analysis method was used to screen the key quality factors that affect the quality of FDM parts. Then, we use 10-fold cross-validation and grid search (GS) to determine the optimal hyperparameter combination of the sparse constrained deep belief network (SDBN), propose an adaptive cuckoo search (ACS) algorithm to optimize the weights and biases of the SDBN, and complete the construction of prediction model based on the above work. The results show that compared with DBN, LSTM, RBFNN, and BPNN, the ACS-SDBN model designed in this article can map the complex nonlinear relationship between FDM part quality characteristics and process parameters more effectively, and the CV verification accuracy of the model can reach more than 95.92%. The prediction accuracy can reach more than 96.67%, and the model has higher accuracy and stability.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {14}
}

@article{10.1155/2021/9485654,
author = {Liu, Fang and Sun, Le},
title = {Design and Implementation of Intelligent Educational Administration System Using Fuzzy Clustering Algorithm},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/9485654},
doi = {10.1155/2021/9485654},
abstract = {The present work aims to solve the problems that the traditional educational administration management system has, such as low efficiency in analyzing big data, and the analysis results have low value, which is based on manual rules definition in big data analysis and processing. The work proposes a student achievement prediction model FCM-CF based on Fuzzy C-means (FCM) and Collaborative Filtering (CF). The work also introduces it into the research of educational administration management to construct an intelligent educational administration management system. At the beginning, the FCM-CF model is described in detail. Then, the system requirements and specific design methods are described in detail. Eventually, with the students’ performance prediction as an example, the performance of the system is tested by designed simulation experiments. The result shows that the students’ achievement in study is closely related to their daily study performance such as preparation before class, classroom performance, attendance, extracurricular study, and homework completion. Generally, the examination scores of students are significant to their daily performances. Under the same experimental conditions, the prediction error of the FCM-CF model proposed here is less than 10.8% of that of other algorithms. The model has better prediction performance and is more suitable for the prediction of middle school students’ examination scores in educational administration management system. The innovation of intelligent educational administration management system is that, in addition to the basic information management function, it also has two other functions: students’ performance prediction analysis and teacher evaluation prediction. It can provide data support for improving teaching quality. The research purpose is to provide important technical support for more intelligent educational administration and reduce the loss of human resources in educational administration.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@article{10.1016/j.chb.2014.04.002,
author = {Hu, Ya-Han and Lo, Chia-Lun and Shih, Sheng-Pao},
title = {Developing early warning systems to predict students' online learning performance},
year = {2014},
issue_date = {July 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {36},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2014.04.002},
doi = {10.1016/j.chb.2014.04.002},
abstract = {We develop early warning systems to predict at-risk students while a course is in progress.Learning portfolios from a fully online course are evaluated by data mining techniques.The results show that CART supplemented by AdaBoost has the best classification performance.Time-dependent variables are essential to identify student online learning performance. An early warning system can help to identify at-risk students, or predict student learning performance by analyzing learning portfolios recorded in a learning management system (LMS). Although previous studies have shown the applicability of determining learner behaviors from an LMS, most investigated datasets are not assembled from online learning courses or from whole learning activities undertaken on courses that can be analyzed to evaluate students' academic achievement. Previous studies generally focus on the construction of predictors for learner performance evaluation after a course has ended, and neglect the practical value of an "early warning" system to predict at-risk students while a course is in progress. We collected the complete learning activities of an online undergraduate course and applied data-mining techniques to develop an early warning system. Our results showed that, time-dependent variables extracted from LMS are critical factors for online learning. After students have used an LMS for a period of time, our early warning system effectively characterizes their current learning performance. Data-mining techniques are useful in the construction of early warning systems; based on our experimental results, classification and regression tree (CART), supplemented by AdaBoost is the best classifier for the evaluation of learning performance investigated by this study.},
journal = {Comput. Hum. Behav.},
month = jul,
pages = {469–478},
numpages = {10},
keywords = {e-Learning, Learning performance prediction, Learning management system, Early warning system, Data-mining}
}

@article{10.1145/1328195.1328196,
author = {Ipek, Engin and McKee, Sally A. and Singh, Karan and Caruana, Rich and Supinski, Bronis R. de and Schulz, Martin},
title = {Efficient architectural design space exploration via predictive modeling},
year = {2008},
issue_date = {January 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/1328195.1328196},
doi = {10.1145/1328195.1328196},
abstract = {Efficiently exploring exponential-size architectural design spaces with many interacting parameters remains an open problem: the sheer number of experiments required renders detailed simulation intractable. We attack this via an automated approach that builds accurate predictive models. We simulate sampled points, using results to teach our models the function describing relationships among design parameters. The models can be queried and are very fast, enabling efficient design tradeoff discovery. We validate our approach via two uniprocessor sensitivity studies, predicting IPC with only 1--2% error. In an experimental study using the approach, training on 1% of a 250-K-point CMP design space allows our models to predict performance with only 4--5% error. Our predictive modeling combines well with techniques that reduce the time taken by each simulation experiment, achieving net time savings of three-four orders of magnitude.},
journal = {ACM Trans. Archit. Code Optim.},
month = jan,
articleno = {1},
numpages = {34},
keywords = {sensitivity studies, performance prediction, design space exploration, Artificial neural networks}
}

@inproceedings{10.1007/978-3-030-82153-1_4,
author = {Zhao, HaoZhe and Rao, Guozheng},
title = {Traffic Accident Prediction Methods Based on Multi-factor Models},
year = {2021},
isbn = {978-3-030-82152-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-82153-1_4},
doi = {10.1007/978-3-030-82153-1_4},
abstract = {Road traffic accident prediction has always been a complex problem for intelligent transportation since it is affected by many factors. However, to simplify the calculation complexity, most of the current research considers the impact of a few key factors and ignores multiple factors’ impact in reality. To address this problem, we propose traffic accident prediction methods based on multi-factor models. The model introduces information including the severity of the traffic accident, the weather in which the accident occurred, and the external geographic environment to construct a multiple factors model to improve the prediction accuracy. Also, we can use more factors to construct the multi-factor model with the enrichment of data information. The multi-factor model can overcome the shortcomings of existing models in filtering data fluctuations and achieve more accurate predictions by extracting time-periodic features in time series. Furthermore, we combine the multi-factor models with different deep learning models to propose multiple traffic accident prediction methods to explore multi-factor models’ effects in traffic accident prediction. The experimental results on the 2004–2018 Connecticut Crash Date Repository data of the University of Connecticut show that the C(T)+R+W+RC multi-factor model has better prediction performance than other multi-factor models. Moreover, Multi Factors (C(T)+R+W+RC) Based Bi-LSTM-Attention Method for Traffic Accident Prediction achieved the best performance on this data set.},
booktitle = {Knowledge Science, Engineering and Management: 14th International Conference, KSEM 2021, Tokyo, Japan, August 14–16, 2021, Proceedings, Part III},
pages = {41–52},
numpages = {12},
keywords = {Bi-LSTM-attention, Multi-factor model, Time series, Traffic accident prediction, Road traffic safety},
location = {Tokyo, Japan}
}

@article{10.1007/s10916-016-0517-2,
author = {Li, Sheng and Tang, Bo and He, Haibo},
title = {An Imbalanced Learning based MDR-TB Early Warning System},
year = {2016},
issue_date = {Jul 2016},
publisher = {Plenum Press},
address = {USA},
volume = {40},
number = {7},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-016-0517-2},
doi = {10.1007/s10916-016-0517-2},
abstract = {As a man-made disease, multidrug-resistant tuberculosis (MDR-TB) is mainly caused by improper treatment programs and poor patient supervision, most of which could be prevented. According to the daily treatment and inspection records of tuberculosis (TB) cases, this study focuses on establishing a warning system which could early evaluate the risk of TB patients converting to MDR-TB using machine learning methods. Different imbalanced sampling strategies and classification methods were compared due to the disparity between the number of TB cases and MDR-TB cases in historical data. The final results show that the relative optimal predictions results can be obtained by adopting CART-USBagg classification model in the first 90 days of half of a standardized treatment process.},
journal = {J. Med. Syst.},
month = jul,
pages = {1–9},
numpages = {9},
keywords = {MDR-TB, Imbalanced learning, Early warning system, Disease prediction}
}

@inproceedings{10.1109/DAC.2018.8465821,
author = {Gupta, Ujjwal and Babu, Manoj and Ayoub, Raid and Kishinevsky, Michael and Paterna, Francesco and Ogras, Umit Y.},
title = {STAFF: Online Learning with Stabilized Adaptive Forgetting Factor and Feature Selection Algorithm},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC.2018.8465821},
doi = {10.1109/DAC.2018.8465821},
abstract = {Dynamic resource management techniques rely on power consumption and performance models to optimize the operating frequency and utilization of processing elements, such as CPU and GPU. Despite the importance of these decisions, many existing approaches rely on fixed power and performance models that are learned offline. However, offline models cannot guarantee accuracy when workloads differ significantly from the training available at design time. This paper presents an online learning framework (STAFF) that constructs adaptive run-time models for stationary and non-stationary workloads. STAFF is the first framework that (1) guarantees stability while quickly adapting to workload changes, (2) performs online feature selection with linear complexity, and (3) adapts to new model coefficients by employing adaptively varying forgetting factor, all at the same time. Experiments on an Intel&lt;sup&gt;®&lt;/sup&gt; Core™ i5 6&lt;sup&gt;th&lt;/sup&gt; generation platform demonstrate up to 6× improvement in the performance prediction accuracy compared to existing techniques.},
booktitle = {2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)},
pages = {1–6},
numpages = {6},
location = {San Francisco, CA, USA}
}

@article{10.1016/j.jss.2011.04.013,
author = {Kousiouris, George and Cucinotta, Tommaso and Varvarigou, Theodora},
title = {The effects of scheduling, workload type and consolidation scenarios on virtual machine performance and their prediction through optimized artificial neural networks},
year = {2011},
issue_date = {August, 2011},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {8},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.04.013},
doi = {10.1016/j.jss.2011.04.013},
abstract = {The aim of this paper is to study and predict the effect of a number of critical parameters on the performance of virtual machines (VMs). These parameters include allocation percentages, real-time scheduling decisions and co-placement of VMs when these are deployed concurrently on the same physical node, as dictated by the server consolidation trend and the recent advances in the Cloud computing systems. Different combinations of VM workload types are investigated in relation to the aforementioned factors in order to find the optimal allocation strategies. What is more, different levels of memory sharing are applied, based on the coupling of VMs to cores on a multi-core architecture. For all the aforementioned cases, the effect on the score of specific benchmarks running inside the VMs is measured. Finally, a black box method based on genetically optimized artificial neural networks is inserted in order to investigate the degradation prediction ability a priori of the execution and is compared to the linear regression method.},
journal = {J. Syst. Softw.},
month = aug,
pages = {1270–1291},
numpages = {22},
keywords = {Virtualization, Real-time scheduling, Performance prediction, Genetic algorithms, Cloud computing, Artificial neural networks}
}

@article{10.1007/s00521-018-3896-0,
author = {Khamparia, Aditya and Singh, Aman and Anand, Divya and Gupta, Deepak and Khanna, Ashish and Arun Kumar, N. and Tan, Joseph},
title = {RETRACTED ARTICLE: A novel deep learning-based multi-model ensemble method for the prediction of neuromuscular disorders},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {15},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3896-0},
doi = {10.1007/s00521-018-3896-0},
abstract = {Neuromuscular disorder is a complex progressive health problem which results in muscle weakness and fatigue. In recent years, with emergence and development of machine learning- and sequencing-driven technologies, the prediction of neuromuscular disorders could be made on the basis of gene expression for accurate diagnosis of disease. The intent is to correctly distinguish the patients affected from neuromuscular disorder from the healthy one with the help of various classification methods used in machine learning. In this paper, we proposed a novel feature selection method which applies deep learning method for grouping the outputs generated through various classifiers. The feature selection is performed on the basis of integrated Bhattacharya coefficient and genetic algorithm (GA) where fitness is computed on the basis of ensemble outputs of various classifiers which is performed using deep learning methods. The Bhattacharya coefficient computed the most effective gene subset; then, the most discriminative gene subset will be formulated using GA. The proposed integrated deep learning multi-model ensemble method was applied on two commercially available neuromuscular disorder datasets. The obtained results encouraged that the proposed integrated approach enhances the prediction accuracy of neuromuscular disorders as compared with different datasets and other classifier algorithms. The proposed deep learning-driven ensemble method provides more accurate and effective results for neuromuscular disorder prediction and classification with the help of distinguished classifiers.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {11083–11095},
numpages = {13},
keywords = {Deep learning, Ensemble, Multi-model, Neuromuscular disorder, Bhattacharya coefficient}
}

@article{10.1007/s10270-013-0364-2,
author = {Acher, Mathieu and Cleve, Anthony and Collet, Philippe and Merle, Philippe and Duchien, Laurence and Lahire, Philippe},
title = {Extraction and evolution of architectural variability models in plugin-based systems},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0364-2},
doi = {10.1007/s10270-013-0364-2},
abstract = {Variability management is a key issue when building and evolving software-intensive systems, making it possible to extend, configure, customize and adapt such systems to customers' needs and specific deployment contexts. A wide form of variability can be found in extensible software systems, typically built on top of plugin-based architectures that offer a (large) number of configuration options through plugins. In an ideal world, a software architect should be able to generate a system variant on-demand, corresponding to a particular assembly of plugins. To this end, the variation points and constraints between architectural elements should be properly modeled and maintained over time (i.e., for each version of an architecture). A crucial, yet error-prone and time-consuming, task for a software architect is to build an accurate representation of the variability of an architecture, in order to prevent unsafe architectural variants and reach the highest possible level of flexibility. In this article, we propose a reverse engineering process for producing a variability model (i.e., a feature model) of a plugin-based architecture. We develop automated techniques to extract and combine different variability descriptions, including a hierarchical software architecture model, a plugin dependency model and the software architect knowledge. By computing and reasoning about differences between versions of architectural feature models, software architect can control both the variability extraction and evolution processes. The proposed approach has been applied to a representative, large-scale plugin-based system (FraSCAti), considering different versions of its architecture. We report on our experience in this context.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1367–1394},
numpages = {28},
keywords = {Variability, Software evolution, Reverse engineering, Product lines, Configuration management, Architecture recovery}
}

@article{10.1016/j.parco.2015.09.003,
author = {Li, Lu and Dastgeer, Usman and Kessler, Christoph},
title = {Pruning strategies in adaptive off-line tuning for optimized composition of components on heterogeneous systems},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {51},
number = {C},
issn = {0167-8191},
url = {https://doi.org/10.1016/j.parco.2015.09.003},
doi = {10.1016/j.parco.2015.09.003},
abstract = {We consolidate our convexity assumption that forms the basis for adaptive pruning of the sampling space.We provide better control of trade-offs between sampling time, runtime overhead and accuracy in adaptive empirical modeling.Reducing training time and improving prediction accuracy can be achieved simultaneously.Our method can converge faster and reaches higher accuracy than random sampling. Adaptive program optimizations, such as automatic selection of the expected fastest implementation variant for a computation component depending on hardware architecture and runtime context, are important especially for heterogeneous computing systems but require good performance models. Empirical performance models which require no or little human efforts show more practical feasibility if the sampling and training cost can be reduced to a reasonable level.In previous work we proposed an early version of adaptive sampling for efficient exploration and selection of training samples, which yields a decision-tree based method for representing, predicting and selecting the fastest implementation variants for given run-time call context's property values. For adaptive pruning we use a heuristic convexity assumption. In this paper we consolidate and improve the method by new pruning techniques to better support the convexity assumption and control the trade-off between sampling time, prediction accuracy and runtime prediction overhead. Our results show that the training time can be reduced by up to 39 times without noticeable prediction accuracy decrease.},
journal = {Parallel Comput.},
month = jan,
pages = {37–45},
numpages = {9},
keywords = {Smart sampling, Heterogeneous systems, Component selection}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00012,
author = {Nuryyev, Batyr and Nadi, Sarah and Bhuiyan, Nazim Uddin and Banderali, Leonardo},
title = {Challenges of implementing software variability in eclipse OMR: an interview study},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00012},
doi = {10.1109/ICSE-SEIP52600.2021.00012},
abstract = {Software variability is the ability of a software system to be customized or configured for a particular context. In this paper, we discuss our experience investigating software variability implementation challenges in practice. Eclipse OMR, developed by IBM, is a set of highly configurable C++ components for building language runtimes; it supports multiple programming languages and target architectures. We conduct an interview study with 6 Eclipse OMR developers and identify 8 challenges incurred by the existing variability implementation, and 3 constraints that need to be taken into account for any reengineering effort. We discuss these challenges and investigate the literature and existing open-source systems for potential solutions. We contribute a solution for one of the challenges, namely adding variability to enumerations and arrays. We also share our experiences and lessons learned working with a large-scale highly configurable industry project. For example, we found that the "latest and greatest" research solutions may not always be favoured by developers due to small practical considerations such as build dependencies, or even C++ version constraints.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {31–40},
numpages = {10},
keywords = {variability implementation, software variability, language runtimes, eclipse OMR},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1145/2884781.2884831,
author = {Melo, Jean and Brabrand, Claus and W\k{a}sowski, Andrzej},
title = {How does the degree of variability affect bug finding?},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884831},
doi = {10.1145/2884781.2884831},
abstract = {Software projects embrace variability to increase adaptability and to lower cost; however, others blame variability for increasing complexity and making reasoning about programs more difficult. We carry out a controlled experiment to quantify the impact of variability on debugging of preprocessor-based programs. We measure speed and precision for bug finding tasks defined at three different degrees of variability on several subject programs derived from real systems.The results show that the speed of bug finding decreases linearly with the degree of variability, while effectiveness of finding bugs is relatively independent of the degree of variability. Still, identifying the set of configurations in which the bug manifests itself is difficult already for a low degree of variability. Surprisingly, identifying the exact set of affected configurations appears to be harder than finding the bug in the first place. The difficulty in reasoning about several configurations is a likely reason why the variability bugs are actually introduced in configurable programs.We hope that the detailed findings presented here will inspire the creation of programmer support tools addressing the challenges faced by developers when reasoning about configurations, contributing to more effective debugging and, ultimately, fewer bugs in highly-configurable systems.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {679–690},
numpages = {12},
keywords = {variability, preprocessors, bug finding},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3377024.3377034,
author = {Schlie, Alexander and Schulze, Sandro and Schaefer, Ina},
title = {Recovering variability information from source code of clone-and-own software systems},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377034},
doi = {10.1145/3377024.3377034},
abstract = {Clone-and-own prevails as an ad-hoc reuse strategy that addresses changing requirements by copying and modifying existing system variants. Proper documentation is typically not cherished and knowledge about common and varying parts between individual variants, denoted their variability information, is lost with a growing system family. With overall maintainability impaired in the longrun, software product lines (SPLs) or concepts thereof, can be a remedy. However, migrating a system family towards structured reuse requires a prior recovery of the systems' variability information. For software systems resulting from clone-and-own, this information is not explicitly available and recovering it remains an open challenge.We aim to bridge this gap and propose a fine-grained metric and analysis procedure, which compares software systems to the extent of individual statements including their nesting. By that, we recover variability information from software systems written in imperative programming languages. Moreover, we create a software family representation of all analyzed systems, called a 150% model, which contains implementation artifacts and their identified variability information. We demonstrate the feasibility of our approach using two case studies implemented in Java and show our approach to exhibit a good performance and the 150% model to precisely capture variability information of the analyzed systems.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {9},
keywords = {variability, source code, recovering, clone-and-own, 150% model},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@article{10.3233/KES-170356,
author = {Alidra, Abdelghani and Kimour, Mohamed Tahar},
title = {Adapting large pervasive and context-aware systems. A new evolutionary-based approach},
year = {2017},
issue_date = {2017},
publisher = {IOS Press},
address = {NLD},
volume = {21},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-170356},
doi = {10.3233/KES-170356},
abstract = {In order to enable ``anywhere, anytime'' computing, pervasive
systems must autonomously adapt at runtime. The use of dynamic software
product lines has emerged as a promising paradigm where well established
variability management techniques are leveraged at runtime to describe
evolution strategies and adaptation scenarios in terms of combinations of
features. In order to identify the optimal target configuration of the
system under certain circumstances, most existing approaches generate the
set of valid combinations of features and return the best one. Obviously,
while such approaches are well suited to small systems with a reduced number
of configurations, they fail in the case of large modern pervasive systems
because the generation/evaluation of all valid combinations is very costly
in terms of resources and time consumption. In the present article, we
introduce a new scalable, evolutionary-based approach to runtime adaptation
of pervasive systems. To this end, we define the concept of transitive
dependency between features and we exploit it to fasten the generation of
the optimal configuration of the system. We evaluate the scalability of our
proposal by reporting experimental results that show that our genetic
algorithm converges in up to 90% less time than the one from the
literature while preserving the exploration capabilities and solutions
quality. Finally, we illustrate our proposal on the smart homes use case.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {103–121},
numpages = {19},
keywords = {genetic algorithms, features transitive dependencies, dynamic software product lines, online adaptation, pervasive systems, Context-awareness}
}

@article{10.1016/j.future.2018.10.027,
author = {Aldossary, Mohammad and Djemame, Karim and Alzamil, Ibrahim and Kostopoulos, Alexandros and Dimakis, Antonis and Agiatzidou, Eleni},
title = {Energy-aware cost prediction and pricing of virtual machines in cloud computing environments},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {93},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.10.027},
doi = {10.1016/j.future.2018.10.027},
journal = {Future Gener. Comput. Syst.},
month = apr,
pages = {442–459},
numpages = {18},
keywords = {Pricing schemes, Energy prediction, Workload prediction, Cost estimation, Energy efficiency, Cloud computing}
}

@inproceedings{10.1007/978-3-030-56725-5_12,
author = {Zhaoyan, Ji and Hongfei, Yan and Siping, Ying and Chong, Chen and Qi, Su},
title = {Semi-supervised Sentiment Analysis for Chinese Stock Texts in Scarce Labeled Data Scenario and Price Prediction},
year = {2020},
isbn = {978-3-030-56724-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-56725-5_12},
doi = {10.1007/978-3-030-56725-5_12},
abstract = {The application of neural network in stock prediction is developing rapidly these years because of its excellency in series data processing. However, as most of research are conducted in English, data sources and labeled data are inadequate in Chinese. Especially for natural language processing tasks in specific domain where specialized labeled data are required to train models to adapt to terminology processing, specialized labeled Chinese in text data are very scarce, such as financial text data. To tackle this challenge, we proposed a semi-supervised learning method to generate well-labeled data and train BERT, a leading natural language processing model, to obtain a trained sentiment machine. Then we got stock-related text data sentiment score based on this machine and further combine the sentiment score and other transaction data as inputs for different neural networks to predict stock price. The experimental results on a large scale of Chinese stock data and texts showed that our proposed method successfully improved prediction accuracy compared to other established methods. Besides, we also examined our method’s applicability combined with different neural networks when predicting different types of stock.},
booktitle = {Information Retrieval: 26th China Conference, CCIR 2020, Xi'an, China, August 14–16, 2020, Proceedings},
pages = {149–160},
numpages = {12},
keywords = {Stock prediction, Sentiment analysis in scarce labeled data domain, Deep neural networks},
location = {Xi'an, China}
}

@inproceedings{10.1007/978-3-642-30473-6_7,
author = {Lochau, Malte and Schaefer, Ina and Kamischke, Jochen and Lity, Sascha},
title = {Incremental model-based testing of delta-oriented software product lines},
year = {2012},
isbn = {9783642304729},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-30473-6_7},
doi = {10.1007/978-3-642-30473-6_7},
abstract = {Software product line (SPL) engineering provides a promising approach for developing variant-rich software systems. But, testing of every product variant in isolation to ensure its correctness is in general not feasible due to the large number of product variants. Hence, a systematic approach that applies SPL reuse principles also to testing of SPLs in a safe and efficient way is essential. To address this issue, we propose a novel, model-based SPL testing framework that is based on a delta-oriented SPL test model and regression-based test artifact derivations. Test artifacts are incrementally constructed for every product variant by explicitly considering commonality and variability between two consecutive products under test. The resulting SPL testing process is proven to guarantee stable test coverage for every product variant and allows the derivation of redundancy-reduced, yet reliable retesting obligations. We compare our approach with an alternative SPL testing strategy by means of a case study from the automotive domain.},
booktitle = {Proceedings of the 6th International Conference on Tests and Proofs},
pages = {67–82},
numpages = {16},
keywords = {regression testing, model-based testing, delta-oriented software product lines},
location = {Prague, Czech Republic},
series = {TAP'12}
}

@article{10.1007/s11042-016-4199-z,
author = {Jian, Chuanxia and Gao, Jian and Ao, Yinhui},
title = {Imbalanced defect classification for mobile phone screen glass using multifractal features and a new sampling method},
year = {2017},
issue_date = {Nov 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {22},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-016-4199-z},
doi = {10.1007/s11042-016-4199-z},
abstract = {Defect classification has drawn significant attention in the mobile phone screen glass (MPSG) manufacturing field because it helps to determine problems in the manufacturing process. Two problems exist in MPSG defect classification: (1) the high dimensionality of the defect feature; (2) imbalanced defect example classification. The first problem tends to yield low accuracy for classifying overall defect examples, and the second problem has a low accuracy for minority ones. To address these two problems, an imbalanced MPSG defect classification scheme is presented. First, based on the multifractal spectrum, defect features are extracted to reduce the feature dimensionality. Defect features are distinguishably characterized by two multifractal metrics to promote the performance of classifying defects. Second, considering example contributions to determine the classification boundary, a new sampling method is proposed to address the imbalanced defect example classification. This method improves the classification accuracy of the minority class through implementation of different sampling strategies to SVs (support vectors) and NSVs (non support vectors) in the majority and minority classes. Experiments are conducted on real MPSG defect examples, and the experimental results show that the imbalanced MPSG defect classification scheme achieves a 96.61% overall accuracy and a 93.27% geometric mean of the classification accuracies of four-type defects; these results are superior to the results achieved by other methods used in the experiment.},
journal = {Multimedia Tools Appl.},
month = nov,
pages = {24413–24434},
numpages = {22},
keywords = {Sampling, Multifractal features, Mobile phone screen glass, Imbalanced datasets, Defect classification}
}

@inproceedings{10.1145/3303084.3309492,
author = {Prodromou, Andreas and Venkat, Ashish and Tullsen, Dean M.},
title = {Deciphering Predictive Schedulers for Heterogeneous-ISA Multicore Architectures},
year = {2019},
isbn = {9781450362900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303084.3309492},
doi = {10.1145/3303084.3309492},
abstract = {Heterogeneous architectures have become increasingly common. From co-packaging small and large cores, to GPUs alongside CPUs, to general-purpose heterogeneous-ISA architectures with cores implementing different ISAs. As diversity of execution cores grows, predictive models become of paramount importance for scheduling and resource allocation. In this paper, we investigate the capabilities of performance predictors in a heterogeneous-ISA setting, as well as the predictors' effects on scheduler quality. We follow an unbiased feature selection methodology to identify the optimal set of features for this task, instead of pre-selecting features before training. We propose metrics that bridge the gap between traditional prediction accuracy metrics and a scheduler's performance. We further present our evaluation methodology, which was meticulously designed with this study in mind, and finally, we incorporate our findings in ML-based schedulers and evaluate their sensitivity to the underlying system's level of heterogeneity.},
booktitle = {Proceedings of the 10th International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = {51–60},
numpages = {10},
location = {Washington, DC, USA},
series = {PMAM'19}
}

@inproceedings{10.1145/3018896.3036391,
author = {Al-Hadi, Ismail Ahmed Al-Qasem and Sharef, Nurfadhlina Mohd and Sulaiman, Md Nasir and Mustapha, Norwati},
title = {Bacterial foraging optimization algorithm with temporal features to solve data sparsity in recommendation system},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3036391},
doi = {10.1145/3018896.3036391},
abstract = {A recommender system provides users with personalized suggestions for items based on the user's behaviour history. This system often uses the collaborative filtering for analysing the rating scores of users for items in the scoring matrix. The scoring matrix of a recommendation system contains a high percentage of data sparsity which lowers the quality of the prediction based on the collaborative filtering. Recently, the temporal with matrix factorization is one of the successful collaborative-based approaches which address data sparsity. However, the user's rating scores have drifted over time and the predicted rating scores are over-fitted which are the significant challenges in the temporal based factorization approaches. Therefore, the ShortTemporalMF approach has proposed to address these challenges. The ShortTemporalMF uses the bacterial foraging optimization algorithm (BFOA) and the k-means algorithm to minimize the over-fitting by exploiting several latent features. BFOA learns the drift in the latent space according to tracking the rich nutrients. The ShortTemporalMF is tested on the Netflix Prize dataset. The experimental results show that the prediction accuracy of ShortTemporalMF approach is the highest compared to the prediction accuracy of whole benchmark approaches of factorization and temporal.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {148},
numpages = {6},
keywords = {recommendation system, overfitting, matrix factorization, data sparsity, collaborative filtering, clustering, bacterial foraging},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/1168857.1168882,
author = {\"{I}pek, Engin and McKee, Sally A. and Caruana, Rich and de Supinski, Bronis R. and Schulz, Martin},
title = {Efficiently exploring architectural design spaces via predictive modeling},
year = {2006},
isbn = {1595934510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1168857.1168882},
doi = {10.1145/1168857.1168882},
abstract = {Architects use cycle-by-cycle simulation to evaluate design choices and understand tradeoffs and interactions among design parameters. Efficiently exploring exponential-size design spaces with many interacting parameters remains an open problem: the sheer number of experiments renders detailed simulation intractable. We attack this problem via an automated approach that builds accurate, confident predictive design-space models. We simulate sampled points, using the results to teach our models the function describing relationships among design parameters. The models produce highly accurate performance estimates for other points in the space, can be queried to predict performance impacts of architectural changes, and are very fast compared to simulation, enabling efficient discovery of tradeoffs among parameters in different regions. We validate our approach via sensitivity studies on memory hierarchy and CPU design spaces: our models generally predict IPC with only 1-2% error and reduce required simulation by two orders of magnitude. We also show the efficacy of our technique for exploring chip multiprocessor (CMP) design spaces: when trained on a 1% sample drawn from a CMP design space with 250K points and up to 55x performance swings among different system configurations, our models predict performance with only 4-5% error on average. Our approach combines with techniques to reduce time per simulation, achieving net time savings of three-four orders of magnitude.},
booktitle = {Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {195–206},
numpages = {12},
keywords = {sensitivity studies, performance prediction, design space exploration, artificial neural networks},
location = {San Jose, California, USA},
series = {ASPLOS XII}
}

@article{10.1016/j.is.2019.01.006,
author = {Witt, Carl and Bux, Marc and Gusew, Wladislaw and Leser, Ulf},
title = {Predictive performance modeling for distributed batch processing using black box monitoring and machine learning},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {82},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2019.01.006},
doi = {10.1016/j.is.2019.01.006},
journal = {Inf. Syst.},
month = may,
pages = {33–52},
numpages = {20},
keywords = {Black box monitoring, Machine learning, Resource management, Distributed computing}
}

@article{10.1007/s00158-020-02673-6,
author = {Xu, Can and Liu, Zhao and Zhu, Ping and Li, Mushi},
title = {Sensitivity-based adaptive sequential sampling for metamodel uncertainty reduction in multilevel systems},
year = {2020},
issue_date = {Sep 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {62},
number = {3},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-020-02673-6},
doi = {10.1007/s00158-020-02673-6},
abstract = {Decomposition-based technique is often used in the analysis and design of complex engineering systems for reducing the computational complexity by studying the subsystems decomposed from multilevel systems. Metamodels, as a replacement of original simulation models, can further alleviate the computational burden. However, discrepancy between the simulation models and metamodels, which is defined as metamodel uncertainty, may be introduced in the analysis process of multilevel systems owing to the lack of data. The metamodel uncertainties of sub-models will be further amplified because of the hierarchical uncertainty propagation and interaction between uncertainties, which will have a great impact on the system results. An adaptive sequential sampling strategy based on sensitivity is proposed in this paper so as to improve the prediction accuracy of system response. In this strategy, polynomial-chaos expansion is used to realize the forward propagation of metamodel uncertainty quantified by the Kriging model. The forward propagation is combined with optimization based on maximum variance criterion for searching the input locations that results in the largest variance of system response. Then, the indices of subsystems are obtained to make decisions about which subsystem needs extra samples by combining Karhunen-Loeve expansion and sensitivity analysis. The effectiveness of the proposed sequential sampling strategy method is verified by two mathematical examples and a multiscale composite material.},
journal = {Struct. Multidiscip. Optim.},
month = sep,
pages = {1473–1496},
numpages = {24},
keywords = {Kriging, Polynomial-chaos expansion, Sensitivity analysis, Sequential sampling, Multilevel systems, Metamodel uncertainty}
}

@inproceedings{10.1145/2602576.2602585,
author = {Etxeberria, Leire and Trubiani, Catia and Cortellessa, Vittorio and Sagardui, Goiuria},
title = {Performance-based selection of software and hardware features under parameter uncertainty},
year = {2014},
isbn = {9781450325769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2602576.2602585},
doi = {10.1145/2602576.2602585},
abstract = {Configurable software systems allow stakeholders to derive variants by selecting software and/or hardware features. Performance analysis of feature-based systems has been of large interest in the last few years, however a major research challenge is still to conduct such analysis before achieving full knowledge of the system, namely under a certain degree of uncertainty. In this paper we present an approach to analyze the correlation between selection of features embedding uncertain parameters and system performance. In particular, we provide best and worst case performance bounds on the basis of selected features and, in cases of wide gaps among these bounds, we carry on a sensitivity analysis process aimed at taming the uncertainty of parameters. The application of our approach to a case study in the e-health domain demonstrates how to support stakeholders in the identification of system variants that meet performance requirements.},
booktitle = {Proceedings of the 10th International ACM Sigsoft Conference on Quality of Software Architectures},
pages = {23–32},
numpages = {10},
keywords = {uncertainty, software architectures, performance analysis, feature selection},
location = {Marcq-en-Bareul, France},
series = {QoSA '14}
}

@inproceedings{10.1145/2723576.2723590,
author = {Elbadrawy, Asmaa and Studham, R. Scott and Karypis, George},
title = {Collaborative multi-regression models for predicting students' performance in course activities},
year = {2015},
isbn = {9781450334174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723576.2723590},
doi = {10.1145/2723576.2723590},
abstract = {Methods that accurately predict the grade of a student at a given activity or course can identify students that are at risk in failing a course and allow their educational institution to take corrective actions. Though a number of prediction models have been developed, they either estimate a single model for all students based on their past course performance and interactions with learning management systems (LMS), or estimate student-specific models that do not take into account LMS interactions; thus, failing to exploit fine-grain information related to a student's engagement. In this work we present a class of collaborative multi-regression models that are personalized to each student and also take into account features related to student's past performance, engagement and course characteristics. These models use all historical information to estimate a small number of regression models shared by all students along with student-specific combination weights. This allows for information sharing and also generating personalized predictions. Our experimental evaluation on a large set of students, courses, and activities shows that these models are capable of improving the performance prediction accuracy by over 20%. In addition, we show that by analyzing the estimated models and the student-specific combination functions we can gain insights on the effectiveness of the educational material that is made available at the courses of different departments.},
booktitle = {Proceedings of the Fifth International Conference on Learning Analytics And Knowledge},
pages = {103–107},
numpages = {5},
keywords = {predicting student performance, collaborative multi-regression models, analyzing student behavior},
location = {Poughkeepsie, New York},
series = {LAK '15}
}

@inproceedings{10.1007/978-3-662-54494-5_23,
author = {Beek, Maurice H. and Vink, Erik P. and Willemse, Tim A.},
title = {Family-Based Model Checking with mCRL2},
year = {2017},
isbn = {9783662544938},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-54494-5_23},
doi = {10.1007/978-3-662-54494-5_23},
abstract = {Family-based model checking targets the simultaneous verification of multiple system variants, a technique to handle feature-based variability that is intrinsic to software product lines SPLs. We present an approach for family-based verification based on the feature $$mu $$-calculus $$mu L {}_f$$, which combines modalities with feature expressions. This logic is interpreted over featured transition systems, a well-accepted model of SPLs, which allows one to reason over the collective behavior of a number of variants a family of products. Via an embedding into the modal $$mu $$-calculus with data, underpinned by the general-purpose mCRL2 toolset, off-the-shelf tool support for\"{\i} \'{z}$$mu L {}_f$$ becomes readily available. We illustrate the feasibility of our approach on an SPL benchmark model and show the runtime improvement that family-based model checking with mCRL2 offers with respect to model checking the benchmark product-by-product.},
booktitle = {Proceedings of the 20th International Conference on Fundamental Approaches to Software Engineering - Volume 10202},
pages = {387–405},
numpages = {19}
}

@article{10.1007/s10845-018-1428-5,
author = {Wu, Qianhui and Ding, Keqin and Huang, Biqing},
title = {Approach for fault prognosis using recurrent neural network},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {7},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-018-1428-5},
doi = {10.1007/s10845-018-1428-5},
abstract = {In general, fault prognosis research usually leads to the research of remaining useful life prediction and performance prediction (prediction of target feature), which can be regarded as a sequence learning problem. Considering the significant success achieved by the recurrent neural network in sequence learning problems such as precise timing, speech recognition, and so on, this paper proposes a novel approach for fault prognosis with the degradation sequence of equipment based on the recurrent neural network. Long short-term memory (LSTM) network is utilized due to its capability of learning long-term dependencies, which takes the concatenated feature and operation state indicator of the equipment as the input. Note that the indicator is a one-hot vector, and based on it, the remaining useful life can be estimated without any pre-defined threshold. The outputs of the LSTM networks are connected to a fully-connected layer to map the hidden state into the parameters of a Gaussian mixture model and a categorical distribution so that the predicted output sequence can be sampled from them. The performance of the proposed method is verified by the health monitoring data of aircraft turbofan engines. The result shows that the proposed approach is able to achieve significant performance whether in one-step prediction task, in long-term prediction task, or in remaining useful life prediction task.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {1621–1633},
numpages = {13},
keywords = {Remaining useful life, Turbofan engine, Long short-term memory, Recurrent neural network, Fault prognosis}
}

@article{10.1504/IJGUC.2009.027921,
author = {Pllana, Sabri and Benkner, Siegfried and Xhafa, Fatos and Barolli, Leonard},
title = {A novel approach for hybrid performance modelling and prediction of large-scale computing systems},
year = {2009},
issue_date = {August 2009},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {1},
number = {4},
issn = {1741-847X},
url = {https://doi.org/10.1504/IJGUC.2009.027921},
doi = {10.1504/IJGUC.2009.027921},
abstract = {We present a novel approach for hybrid performance modelling and prediction of large-scale parallel and distributed computing systems, which combines Mathematical Modelling (MathMod) and Discrete-Event Simulation (DES). We use MathMod to develop parameterised performance models for components of the system. Thereafter, we use DES to describe the structure of system and the interaction among its components. As a result we obtain a high-level performance model, which combines the evaluation speed of mathematical models with the structure awareness and fidelity of the simulation model. We evaluate empirically our approach with a real-world material science program that comprises more than 15,000 lines of code.},
journal = {Int. J. Grid Util. Comput.},
month = aug,
pages = {316–327},
numpages = {12},
keywords = {performance prediction, performance modelling, parallel programming, mathematical modelling, large-scale computing systems, distributed computing, discrete event simulation, MathMod}
}

@article{10.1016/j.patcog.2015.08.014,
author = {Sok, Hong Kuan and Ooi, Melanie Po-Leen and Kuang, Ye Chow and Demidenko, Serge},
title = {Multivariate alternating decision trees},
year = {2016},
issue_date = {February 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {50},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2015.08.014},
doi = {10.1016/j.patcog.2015.08.014},
abstract = {Decision trees are comprehensible, but at the cost of a relatively lower prediction accuracy compared to other powerful black-box classifiers such as SVMs. Boosting has been a popular strategy to create an ensemble of decision trees to improve their classification performance, but at the expense of comprehensibility advantage. To this end, alternating decision tree (ADTree) has been proposed to allow boosting within a single decision tree to retain comprehension. However, existing ADTrees are univariate, which limits their applicability. This research proposes a novel algorithm - multivariate ADTree. It presents and discusses its different variations (Fisher's ADTree, Sparse ADTree, and Regularized Logistic ADTree) along with their empirical validation on a set of publicly available datasets. It is shown that multivariate ADTree has high prediction accuracy comparable to that of decision tree ensembles, while retaining good comprehension which is close to comprehension of individual univariate decision trees. Novel concept of multivariate alternating decision tree (ADTree) with boosting.Offering high prediction accuracy similar to decision tree ensembles.Retaining good comprehension similar to individual univariate decision trees.Bridging powerful regularization techniques to decision tree research.Introduction and validation of multivariate ADTree algorithms on public datasets.},
journal = {Pattern Recogn.},
month = feb,
pages = {195–209},
numpages = {15},
keywords = {Multivariate decision tree, Lasso, LARS, Boosting, Alternating decision tree}
}

@article{10.1007/s10586-020-03158-3,
author = {Kehrer, Stefan and Zietlow, Dominik and Scheffold, Jochen and Blochinger, Wolfgang},
title = {Self-tuning serverless task farming using proactive elasticity control},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-020-03158-3},
doi = {10.1007/s10586-020-03158-3},
abstract = {The cloud evolved into an attractive execution environment for parallel applications, which make use of compute resources to speed up the computation of large problems in science and industry. Whereas Infrastructure as a Service (IaaS) offerings have been commonly employed, more recently, serverless computing emerged as a novel cloud computing paradigm with the goal of freeing developers from resource management issues. However, as of today, serverless computing platforms are mainly used to process computations triggered by events or user requests that can be executed independently of each other and benefit from on-demand and elastic compute resources as well as per-function billing. In this work, we discuss how to employ serverless computing platforms to operate parallel applications. We specifically focus on the class of parallel task farming applications and introduce a novel approach to free developers from both parallelism and resource management issues. Our approach includes a proactive elasticity controller that adapts the physical parallelism per application run according to user-defined goals. Specifically, we show how to consider a user-defined execution time limit after which the result of the computation needs to be present while minimizing the associated monetary costs. To evaluate our concepts, we present a prototypical elastic parallel system architecture for self-tuning serverless task farming and implement two applications based on our framework. Moreover, we report on performance measurements for both applications as well as the prediction accuracy of the proposed proactive elasticity control mechanism and discuss our key findings.},
journal = {Cluster Computing},
month = jun,
pages = {799–817},
numpages = {19},
keywords = {Programming model, Elasticity, Parallel cloud programming, Function-as-a-service, Parallel computing, Cloud computing}
}

@article{10.1007/s00366-018-0681-8,
author = {Al-Musawi, Abeer A. and Alwanas, Afrah A. H. and Salih, Sinan Q. and Ali, Zainab Hasan and Tran, Minh Tung and Yaseen, Zaher Mundher},
title = {Shear strength of SFRCB without stirrups simulation: implementation of hybrid artificial intelligence model},
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {36},
number = {1},
issn = {0177-0667},
url = {https://doi.org/10.1007/s00366-018-0681-8},
doi = {10.1007/s00366-018-0681-8},
abstract = {Recent developments on shear strength (Vf) of steel fiber-reinforced concrete beam (SFRCB) simulation have been shifted to the implementation of the computer aid advancements. The current study is attempted to explore new hybrid artificial intelligence (AI) model called integrative support vector regression with firefly optimization algorithm (SVR-FFA) for shear strength prediction of SFRCB. The developed hybrid predictive model is constructed using laboratory experimental data set gathered from the literature and belongs to the shear failure capacity. The related beam dimensional and concrete properties are utilized as input attributes to predict Vf. The proposed SVR-FFA model is validated against classical SVR model and eight empirical formulations obtained from published researches. The attained results of the proposed hybrid AI model exhibited a reliable resultant performance in terms of prediction accuracy. Based on the examined root-mean-square error (RMSE) and the correlation coefficient (R2) over the testing phase, SVR-FFA achieved (RMSE ≈ 0.25&nbsp;MPa) and (R2 ≈ 0.96).},
journal = {Eng. with Comput.},
month = jan,
pages = {1–11},
numpages = {11},
keywords = {Empirical formulations, Steel fiber-reinforced concrete beam, Shear strength, Hybrid intelligence model}
}

@article{10.1155/2021/5519769,
author = {Adnan, Muhammad and AlSaeed, Duaa H. and Al-Baity, Heyam H. and Rehman, Abdur and Aziz, Furqan},
title = {Leveraging the Power of Deep Learning Technique for Creating an Intelligent, Context-Aware, and Adaptive M-Learning Model},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/5519769},
doi = {10.1155/2021/5519769},
abstract = {Machine learning (ML) and deep learning (DL) algorithms work well where future estimations and predictions are required. Particularly, in educational institutions, ML and DL algorithms can help instructors in predicting the learning performance of learners. Furthermore, the prediction of the learning performance of learners can assist instructors and intelligent learning systems (ILSs) in taking preemptive measures (i.e., early engagement or early intervention measures) so that the learning performance of weak learners could be increased thus reducing learners’ failures and dropout rates. In this study, we propose an intelligent learning system (ILS) powered by the mobile learning (M-learning) model that predicts learners’ performance and classify them into various performance groups. Subsequently, adaptive feedback and support are provided to those learners who struggle in their studies. Four M-learning models were created for different learners considering their learning features (study behavior) and their weight values. The M-learning model was based on the artificial neural network (ANN) algorithm with the aim to predict learners’ performance and classify them into five performance groups, whereas the random forest (RF) algorithm was used to determine each feature’s importance in the creation of the M-learning model. In the last stage of this study, we performed an early intervention/engagement experiment on those learners who showed weak performance in their study. End-user computing satisfaction (EUCS) model questionnaire was adopted to measure the attitude of learners towards using an ILS. As compared to traditional machine learning algorithms, ANN achieved the highest prediction accuracy for all four learning models, i.e., model 1 = 90.77%, model 2 = 87.69%, model 3 = 83.85%, and model 4 = 80.00%. Moreover, the five most important features that significantly affect the students’ final performance were MP3 = 0.34, MP1 = 0.26, MP2 = 0.24, NTAQ = 0.05, and AST = 0.018.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@article{10.1016/j.datak.2017.07.004,
author = {Chu, Victor W. and Wong, Raymond K. and Chen, Fang and Ho, Ivan and Lee, Joe},
title = {Enhancing portfolio return based on sentiment-of-topic},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {123},
number = {C},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2017.07.004},
doi = {10.1016/j.datak.2017.07.004},
journal = {Data Knowl. Eng.},
month = sep,
numpages = {15},
keywords = {Business intelligence, Text mining, Topic modeling, Sentiment-of-topic}
}

@article{10.1016/j.jss.2015.08.026,
author = {Vogel-Heuser, Birgit and Fay, Alexander and Schaefer, Ina and Tichy, Matthias},
title = {Evolution of software in automated production systems},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {110},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.08.026},
doi = {10.1016/j.jss.2015.08.026},
abstract = {Automated Production Systems (aPS) impose specific requirements regarding evolution.We present a classification of how Automated Production Systems evolve.We discuss the state of art and research needs for the development phases of aPS.Model-driven engineering and Variability Management are key issues.Cross-discipline analysis of (non)-functional requirements must be improved. Coping with evolution in automated production systems implies a cross-disciplinary challenge along the system's life-cycle for variant-rich systems of high complexity. The authors from computer science and automation provide an interdisciplinary survey on challenges and state of the art in evolution of automated production systems. Selected challenges are illustrated on the case of a simple pick and place unit. In the first part of the paper, we discuss the development process of automated production systems as well as the different type of evolutions during the system's life-cycle on the case of a pick and place unit. In the second part, we survey the challenges associated with evolution in the different development phases and a couple of cross-cutting areas and review existing approaches addressing the challenges. We close with summarizing future research directions to address the challenges of evolution in automated production systems. Display Omitted},
journal = {J. Syst. Softw.},
month = dec,
pages = {54–84},
numpages = {31},
keywords = {Software engineering, Evolution, Automation, Automated production systems}
}

@inproceedings{10.1109/DSDIS.2015.100,
author = {Chen, Yu and Cao, Jian and Guo, Pinglei},
title = {CPU Load Prediction Based on a Multidimensional Spatial Voting Model},
year = {2015},
isbn = {9781509002146},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DSDIS.2015.100},
doi = {10.1109/DSDIS.2015.100},
abstract = {Resource performance prediction has become more and more important in cloud environment as CPU load prediction is key for system maintenance and application schedule. This paper presents a multidimensional spatial voting prediction model to predict real-time CPU load accurately. We improved the real-time CPU load prediction accuracy by gray prediction model under the one-dimension prediction, we also applied voting mechanism to find a more appropriate classifier prediction model for predicting the CPU load in real time. Our experiments showed that multidimensional spatial voting prediction model led to better predictions than classic models. Our model is not problem-specific, and can be applied to problems in the fields of other predictions.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Data Science and Data Intensive Systems (DSDIS)},
pages = {97–102},
numpages = {6},
series = {DSDIS '15}
}

@inproceedings{10.1145/3447548.3467264,
author = {Zhou, Yuqiang and Liu, Qi and Wu, Jinze and Wang, Fei and Huang, Zhenya and Tong, Wei and Xiong, Hui and Chen, Enhong and Ma, Jianhui},
title = {Modeling Context-aware Features for Cognitive Diagnosis in Student Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467264},
doi = {10.1145/3447548.3467264},
abstract = {The contexts and cultures have a direct impact on student learning by affecting student's implicit cognitive states, such as the preference and the proficiency on specific knowledge. Motivated by the success of context-aware modeling in various fields, such as recommender systems, in this paper, we propose to study how to model context-aware features and adapt them for more precisely diagnosing student's knowledge proficiency. Specifically, by analyzing the characteristics of educational contexts, we design a two-stage framework ECD (Educational context-aware Cognitive Diagnosis), where a hierarchical attentive network is first proposed to represent the context impact on students and then an adaptive optimization is used to achieve diagnosis enhancement by aggregating the cognitive states reflected from both educational contexts and students' historical learning records. Moreover, we give three implementations of general ECD framework following the typical cognitive diagnosis solutions. Finally, we conduct extensive experiments on nearly 52 million records of the students sampled by PISA (Programme for International Student Assessment) from 73 countries and regions. The experimental results not only prove that ECD is more effective in student performance prediction since it can well capture the impact from educational contexts to students' cognitive states, but also give some interesting discoveries regarding the difference among different educational contexts in different countries and regions.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2420–2428},
numpages = {9},
keywords = {learning process, educational context, cognitive diagnosis},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1007/s00521-016-2477-3,
author = {Yu, Ruiyun and An, Xuanmiao and Jin, Bo and Shi, Jia and Move, Oguti Ann and Liu, Yonghe},
title = {Particle classification optimization-based BP network for telecommunication customer churn prediction},
year = {2018},
issue_date = {February  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {29},
number = {3},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2477-3},
doi = {10.1007/s00521-016-2477-3},
abstract = {Customer churn prediction is critical for telecommunication companies to retain users and provide customized services. In this paper, a particle classification optimization-based BP network for telecommunication customer churn prediction (PBCCP) algorithm is proposed, which iteratively executes the particle classification optimization (PCO) and the particle fitness calculation (PFC). PCO classifies the particles into three categories according to their fitness values, and updates the velocity of different category particles using distinct equations. PFC calculates the fitness value of a particle in each forward training process of a BP neural network. PBCCP optimizes the initial weights and thresholds of the BP neural network, and brings remarkable improvement on customer churn prediction accuracy.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {707–720},
numpages = {14},
keywords = {Telecommunication networks, Particle classification optimization, PSO, Customer churn, BP neural network}
}

@inproceedings{10.1145/3450613.3456831,
author = {Wang, Chunpai and Sahebi, Shaghayegh and Zhao, Siqian and Brusilovsky, Peter and Moraes, Laura O.},
title = {Knowledge Tracing for Complex Problem Solving: Granular Rank-Based Tensor Factorization},
year = {2021},
isbn = {9781450383660},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450613.3456831},
doi = {10.1145/3450613.3456831},
abstract = {Knowledge Tracing (KT), which aims to model student knowledge level and predict their performance, is one of the most important applications of user modeling. Modern KT approaches model and maintain an up-to-date state of student knowledge over a set of course concepts according to students’ historical performance in attempting the problems. However, KT approaches were designed to model knowledge by observing relatively small problem-solving steps in Intelligent Tutoring Systems. While these approaches were applied successfully to model student knowledge by observing student solutions for simple problems, such as multiple-choice questions, they do not perform well for modeling complex problem solving in students. Most importantly, current models assume that all problem attempts are equally valuable in quantifying current student knowledge. However, for complex problems that involve many concepts at the same time, this assumption is deficient. It results in inaccurate knowledge states and unnecessary fluctuations in estimated student knowledge, especially if students guess the correct answer to a problem that they have not mastered all of its concepts or slip in answering the problem that they have already mastered all of its concepts. In this paper, we argue that not all attempts are equivalently important in discovering students’ knowledge state, and some attempts can be summarized together to better represent student performance. We propose a novel student knowledge tracing approach, Granular RAnk based TEnsor factorization (GRATE), that dynamically selects student attempts that can be aggregated while predicting students’ performance in problems and discovering the concepts presented in them. Our experiments on three real-world datasets demonstrate the improved performance of GRATE, compared to the state-of-the-art baselines, in the task of student performance prediction. Our further analysis shows that attempt aggregation eliminates the unnecessary fluctuations from students’ discovered knowledge states and helps in discovering complex latent concepts in the problems.},
booktitle = {Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {179–188},
numpages = {10},
keywords = {tensor factorization, knowledge tracing, complex problem solving, aggregation},
location = {Utrecht, Netherlands},
series = {UMAP '21}
}

@inproceedings{10.1145/3020078.3021745,
author = {Han, Song and Kang, Junlong and Mao, Huizi and Hu, Yiming and Li, Xin and Li, Yubin and Xie, Dongliang and Luo, Hong and Yao, Song and Wang, Yu and Yang, Huazhong and Dally, William (Bill) J.},
title = {ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA},
year = {2017},
isbn = {9781450343541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3020078.3021745},
doi = {10.1145/3020078.3021745},
abstract = {Long Short-Term Memory (LSTM) is widely used in speech recognition. In order to achieve higher prediction accuracy, machine learning scientists have built increasingly larger models. Such large model is both computation intensive and memory intensive. Deploying such bulky model results in high power consumption and leads to a high total cost of ownership (TCO) of a data center. To speedup the prediction and make it energy efficient, we first propose a load-balance-aware pruning method that can compress the LSTM model size by 20x (10x from pruning and 2x from quantization) with negligible loss of the prediction accuracy. The pruned model is friendly for parallel processing. Next, we propose a scheduler that encodes and partitions the compressed model to multiple PEs for parallelism and schedule the complicated LSTM data flow. Finally, we design the hardware architecture, named Efficient Speech Recognition Engine (ESE) that works directly on the sparse LSTM model.Implemented on Xilinx KU060 FPGA running at 200MHz, ESE has a performance of 282 GOPS working directly on the sparse LSTM network, corresponding to 2.52 TOPS on the dense one, and processes a full LSTM for speech recognition with a power dissipation of 41 Watts. Evaluated on the LSTM for speech recognition benchmark, ESE is 43x and 3x faster than Core i7 5930k CPU and Pascal Titan X GPU implementations. It achieves 40x and 11.5x higher energy efficiency compared with the CPU and GPU respectively.},
booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {75–84},
numpages = {10},
keywords = {speech recognition, software-hardware co-design, model compression, hardware acceleration, deep learning, FPGA},
location = {Monterey, California, USA},
series = {FPGA '17}
}

@article{10.1109/TCBB.2020.3037465,
author = {Bankapur, Sanjay and Patil, Nagamma},
title = {An Effective Multi-Label Protein Sub-Chloroplast Localization Prediction by Skipped-Grams of Evolutionary Profiles Using Deep Neural Network},
year = {2020},
issue_date = {May-June 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2020.3037465},
doi = {10.1109/TCBB.2020.3037465},
abstract = {Chloroplast is one of the most classic organelles in algae and plant cells. Identifying the locations of chloroplast proteins in the chloroplast organelle is an important as well as a challenging task in deciphering their functions. Biological-based experiments to identify the Protein Sub-Chloroplast Localization (PSCL) is time-consuming and cost-intensive. Over the last decade, a few computational methods have been developed to predict PSCL in which earlier works assumed to predict only single-location; whereas, recent works are able to predict multiple-locations of chloroplast organelle. However, the performances of all the state-of-the-art predictors are poor. This article proposes a novel skip-gram technique to extract highly discriminating patterns from evolutionary profiles and a multi-label deep neural network to predict the PSCL. The proposed model is assessed on two publicly available datasets, i.e., Benchmark and Novel. Experimental results demonstrate that the proposed work outperforms significantly when compared to the state-of-the-art multi-label PSCL predictors. A multi-label prediction accuracy (i.e., Overall Actual Accuracy) of the proposed model is enhanced by an absolute minimum margin of 6.7 percent on Benchmark dataset and 7.9 percent on Novel dataset when compared to the best PSCL predictor from the literature. Further, result of statistical t-test concludes that the performance of the proposed work is significantly improved and thus, the proposed work is an effective computational model to solve multi-label PSCL prediction. The proposed prediction model is hosted on web-server and available at &lt;uri&gt;https://nitkit-vgst727-nppsa.nitk.ac.in/deeplocpred/&lt;/uri&gt;.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = nov,
pages = {1449–1458},
numpages = {10}
}

@article{10.1007/s10664-014-9357-1,
author = {B\'{e}can, Guillaume and Acher, Mathieu and Baudry, Benoit and Nasr, Sana Ben},
title = {Breathing ontological knowledge into feature model synthesis: an empirical study},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9357-1},
doi = {10.1007/s10664-014-9357-1},
abstract = {Feature Models (FMs) are a popular formalism for modeling and reasoning about the configurations of a software product line. As the manual construction of an FM is time-consuming and error-prone, management operations have been developed for reverse engineering, merging, slicing, or refactoring FMs from a set of configurations/dependencies. Yet the synthesis of meaningless ontological relations in the FM --- as defined by its feature hierarchy and feature groups --- may arise and cause severe difficulties when reading, maintaining or exploiting it. Numerous synthesis techniques and tools have been proposed, but only a few consider both configuration and ontological semantics of an FM. There are also few empirical studies investigating ontological aspects when synthesizing FMs. In this article, we define a generic, ontologic-aware synthesis procedure that computes the likely siblings or parent candidates for a given feature. We develop six heuristics for clustering and weighting the logical, syntactical and semantical relationships between feature names. We then perform an empirical evaluation on hundreds of FMs, coming from the SPLOT repository and Wikipedia. We provide evidence that a fully automated synthesis (i.e., without any user intervention) is likely to produce FMs far from the ground truths. As the role of the user is crucial, we empirically analyze the strengths and weaknesses of heuristics for computing ranking lists and different kinds of clusters. We show that a hybrid approach mixing logical and ontological techniques outperforms state-of-the-art solutions. We believe our approach, environment, and empirical results support researchers and practitioners working on reverse engineering and management of FMs.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1794–1841},
numpages = {48},
keywords = {Variability, Software product lines, Reverse engineering, Refactoring, Model management, Feature model}
}

@article{10.1155/2011/183764,
author = {Sharkawy, Abdel Badie},
title = {Prediction of surface roughness in end milling process using intelligent systems: a comparative study},
year = {2011},
issue_date = {January 2011},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2011},
issn = {1687-9724},
url = {https://doi.org/10.1155/2011/183764},
doi = {10.1155/2011/183764},
abstract = {A study is presented to model surface roughness in end milling process. Three types of intelligent networks have been considered. They are (i) radial basis function neural networks (RBFNs), (ii) adaptive neurofuzzy inference systems (ANFISs), and (iii) genetically evolved fuzzy inference systems (G-FISs). The machining parameters, namely, the spindle speed, feed rate, and depth of cut have been used as inputs to model the workpiece surface roughness. The goal is to get the best prediction accuracy. The procedure is illustrated using experimental data of end milling 6061 aluminum alloy. The three networks have been trained using experimental training data. After training, they have been examined using another set of data, that is, validation data. Results are compared with previously published results. It is concluded that ANFIS networks may suffer the local minima problem, and genetic tuning of fuzzy networks cannot insure perfect optimality unless suitable parameter setting (population size, number of generations etc.) and tuning range for the FIS, parameters are used which can be hardly satisfied. It is shown that the RBFN model has the best performance (prediction accuracy) in this particular case.},
journal = {Appl. Comp. Intell. Soft Comput.},
month = jan,
articleno = {8},
numpages = {1}
}

@article{10.1504/ijwbc.2019.101814,
author = {Ravi, Logesh and Devarajan, Malathi and Jeon, Gwanggil and Bayat, Oguz and Subramaniyaswamy, V.},
title = {An intelligent fuzzy-induced recommender system for cloud-based cultural communities},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {15},
number = {3},
issn = {1477-8394},
url = {https://doi.org/10.1504/ijwbc.2019.101814},
doi = {10.1504/ijwbc.2019.101814},
abstract = {The rapid development of communication technologies and web-based services generate a large amount of information. In recent years, recommender systems (RS) emerge as an effective mechanism to tackle the information overloading problems. By exploiting the cloud computing paradigm, RS discovers interesting new cultural items based on user preferences and interests. Recent investigations on RS reveal that employing social network data can yield enhanced personalised recommendations with better prediction accuracy. Since users tend to visit only conventional monuments, and many charming cultural items are hidden from them due to lack of awareness about the cultural sites. This article proposes a personalised recommendation model in the field of cultural heritage (CH) with the help of the cloud computing environment. The experimental results obtained demonstrate the improved performance of developed RS in the area of cultural heritage tourism services.},
journal = {Int. J. Web Based Communities},
month = jan,
pages = {271–288},
numpages = {17},
keywords = {cultural heritage, LBSN, location-based social network, fuzzy-KNN, personalised recommender system, cloud computing}
}

@article{10.1016/j.future.2019.02.001,
author = {Sakr, Sherif and Zomaya, Albert and Vasilakos, Athanasios V.},
title = {Editorial for Special issue of FGCS special issue on “Benchmarking big data systems”},
year = {2019},
issue_date = {Jul 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.02.001},
doi = {10.1016/j.future.2019.02.001},
journal = {Future Gener. Comput. Syst.},
month = jul,
pages = {32–34},
numpages = {3}
}

@article{10.1016/j.procs.2018.11.063,
author = {Zuev, Dmitry and Kalistratov, Alexey and Zuev, Andrey},
title = {Machine Learning in IT Service Management},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {145},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.11.063},
doi = {10.1016/j.procs.2018.11.063},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {675–679},
numpages = {5},
keywords = {machine learning, information technology services management, gradient boosting decision trees}
}

@article{10.1007/s00521-020-05461-x,
author = {Duru, Cihat and Alemdar, Hande and Baran, \"{O}zg\"{u}r U\u{g}ra\c{s}},
title = {CNNFOIL: convolutional encoder decoder modeling for pressure fields around airfoils},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {12},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05461-x},
doi = {10.1007/s00521-020-05461-x},
abstract = {In this study, we propose an encoder–decoder convolutional neural network-based approach for estimating the pressure field around an airfoil. The developed tool is one of the early steps of a machine-learning-based aerodynamic performance prediction tool. Network training and evaluation are performed from a set of computational fluid dynamics (CFD)-based solutions of the 2-D flow field around a group of known airfoils involving symmetrical, cambered, thick and thin airfoils. Reynolds averaged Navier Stokes-based CFD simulations are performed at a selected single Mach number and for an angle of attack condition. The calculated pressure field, which is the main parameter for lift and drag calculations, is fed to the neural network training algorithm. Pressure data are calculated using CFD methods on high-quality structured computational grids. For the better shape learning, a distance map is generated from airfoil shape and provided to the algorithm at data locations of the pressure points relative to the airfoil shape. Experiments are conducted with unseen airfoil shapes to evaluate the predictive capability of our model. Performance analysis for airfoils with different thicknesses and cambers is conducted. We also investigated the effect of the shock on the performance of our model. Overall, our model achieves 88% accuracy for unseen airfoil shapes and shows promise to capture the overall flow pattern accurately. Also, significant speed-up is achieved compared to time-consuming CFD simulations. We achieve almost four orders of speed-up with a much cheaper computational resource.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {6835–6849},
numpages = {15},
keywords = {Aerodynamics, Convolutional neural network, Machine learning, Computational fluid dynamics}
}

@inproceedings{10.1007/978-3-030-78089-0_10,
author = {Basile, Davide and ter Beek, Maurice H. and Degano, Pierpaolo and Legay, Axel and Ferrari, Gian-Luigi and Gnesi, Stefania and Di Giandomenico, Felicita},
title = {Supervisory Synthesis of Configurable Behavioural Contracts with Modalities},
year = {2021},
isbn = {978-3-030-78088-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78089-0_10},
doi = {10.1007/978-3-030-78089-0_10},
abstract = {Service contracts characterise the desired behavioural compliance of a composition of services, typically defined by the fulfilment of all service requests through service offers. Contract automata are a formalism for specifying behavioural service contracts. Based on the notion of synthesis of the most permissive controller from Supervisory Control Theory, a safe orchestration of contract automata can be computed that refines a composition into a compliant one. This short paper summarises the contributions published in&nbsp;[8], where we endow contract automata with two orthogonal layers of variability: (i)&nbsp;at the structural level, constraints over service requests and offers define different configurations of a contract automaton, depending on which requests and offers are selected or discarded; and (ii)&nbsp;at the behavioural level, service requests of different levels of criticality can be declared, which induces the novel notion of semi-controllability. The synthesis of orchestrations is thus extended to respect both the structural and the behavioural variability constraints. Finally, we show how to efficiently compute the orchestration of all configurations from only a subset of these configurations. A recently redesigned and refactored tool supports the developed theory.},
booktitle = {Formal Techniques for Distributed Objects, Components, and Systems: 41st IFIP WG 6.1 International Conference, FORTE 2021, Held as Part of the 16th International Federated Conference on Distributed Computing Techniques, DisCoTec 2021, Valletta, Malta, June 14–18, 2021, Proceedings},
pages = {177–181},
numpages = {5},
location = {Valletta, Malta}
}

@article{10.1155/2021/5531595,
author = {Chu, Na and Ma, Wanzhi and Wang, Wei},
title = {Distribution of Large-Scale English Test Scores Based on Data Mining},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/5531595},
doi = {10.1155/2021/5531595},
abstract = {Data mining technology is an effective knowledge mining and data relationship induction technology based on massive data, which is widely used in data analysis in many fields. In order to improve the utilization effect of students’ performance and meet the teaching needs of modern education, data mining technology can be applied to the existing performance database to mine the data information and treatment. Data mining technology is used to analyse and process the data stored in the student achievement management system, which provides the basis for improving the teaching quality and optimizing the teaching resources. Based on the analysis of the relevant data of large-scale English test results, this paper finds out the relevant rules that affect college English test results, forms the corresponding performance prediction rules, uses data mining technology to more comprehensively analyse the factors that affect students’ performance, establishes a model, and uses data mining tools to mine and analyse students’ English test data. It is of great practical significance to select the model with high accuracy, further optimize the parameters, make good use of the data, and then take targeted measures to guide the teaching reform, help students make more efficient learning plans, and improve and perfect the existing problems in teaching.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@inproceedings{10.5555/3031929.3032020,
author = {Sazonau, Viachaslau and Sattler, Uli and Brown, Gavin},
title = {Predicting performance of OWL reasoners: locally or globally?},
year = {2014},
isbn = {1577356578},
publisher = {AAAI Press},
abstract = {We propose a novel approach for performance prediction of OWL reasoners that selects suitable, small ontology subsets, and then extrapolates reasoner's performance on them to the whole ontology. We investigate intercorrelation of ontology features using PCA and discuss various error measures for performance prediction.},
booktitle = {Proceedings of the Fourteenth International Conference on Principles of Knowledge Representation and Reasoning},
pages = {661–664},
numpages = {4},
location = {Vienna, Austria},
series = {KR'14}
}

@inproceedings{10.1007/978-3-642-32820-6_11,
author = {de Oliveira Castro, Pablo and Petit, Eric and Beyler, Jean Christophe and Jalby, William},
title = {ASK: adaptive sampling kit for performance characterization},
year = {2012},
isbn = {9783642328190},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-32820-6_11},
doi = {10.1007/978-3-642-32820-6_11},
abstract = {Characterizing performance is essential to optimize programs and architectures. The open source Adaptive Sampling Kit (ASK) measures the performance trade-offs in large design spaces. Exhaustively sampling all points is computationally intractable. Therefore, ASK concentrates exploration in the most irregular regions of the design space through multiple adaptive sampling methods. The paper presents the ASK architecture and a set of adaptive sampling strategies, including a new approach: Hierarchical Variance Sampling. ASK's usage is demonstrated on two performance characterization problems: memory stride accesses and stencil codes. ASK builds precise models of performance with a small number of measures. It considerably reduces the cost of performance exploration. For instance, the stencil code design space, which has more than 31.108 points, is accurately predicted using only 1 500 points.},
booktitle = {Proceedings of the 18th International Conference on Parallel Processing},
pages = {89–101},
numpages = {13},
location = {Rhodes Island, Greece},
series = {Euro-Par'12}
}

@article{10.1007/s10586-017-1466-3,
author = {Wang, Kewen and Khan, Mohammad Maifi Hasan and Nguyen, Nhan and Gokhale, Swapna},
title = {Design and implementation of an analytical framework for interference aware job scheduling on Apache Spark platform},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-017-1466-3},
doi = {10.1007/s10586-017-1466-3},
abstract = {Apache Spark is one of the recently popularized open-source platforms that is increasingly being used for large-scale data analytic applications. However, while performance prediction in such systems is important for efficient job scheduling and optimizing resource allocation, interference among multiple Apache Spark jobs running concurrently in a virtualized environment makes it extremely difficult, which is addressed in this paper. Towards that, first, we develop data-driven analytical models to estimate the effect of interference among multiple Apache Spark jobs on job execution time in virtualized cloud environments. Next, we present the design of an interference aware job scheduling algorithm leveraging the developed analytical framework. We evaluated the accuracy of our models using four real-life applications (e.g., Page rank, K-means, Logistic regression, and Word count) on a 6 node cluster while running up to four jobs concurrently. Our experimental results show that the scheduling algorithm reduces the average execution time of individual jobs and the total execution time significantly, and ranges between 47 and 26% for individual jobs and 2–13% for total execution time respectively.},
journal = {Cluster Computing},
month = jan,
pages = {2223–2237},
numpages = {15},
keywords = {Execution time prediction, Performance interference modeling, Job scheduling, Apache Spark}
}

@inproceedings{10.1109/CCGRID.2017.85,
author = {Li, Zengxiang and Zhang, Bowen and Ren, Shen and Liu, Yong and Qin, Zheng and Goh, Rick Siow Mong and Gurusamy, Mohan},
title = {Performance Modelling and Cost Effective Execution for Distributed Graph Processing on Configurable VMs},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.85},
doi = {10.1109/CCGRID.2017.85},
abstract = {Graph Processing has been widely used to capture complex data dependency and uncover relationship insights. Due to the ever-growing graph scale and algorithm complexity, distributed graph processing has become more and more popular. In this paper, we investigate how to balance performance and cost for large scale graph processing on configurable virtual machines (VMs). We analyze the system architecture and implementation details of a Pregel-like distributed graph processing framework and develop a system-aware model to predict the execution time. Consequently, cost effective execution scenarios are recommended by selecting a certain number of VMs with specified capability subject to the predefined resource price and user preference. Experiments using synthetic and real world graphs have verified that system-aware model can achieve much higher prediction accuracy than popular machine-learning models which treat graph processing framework as a black box. As a result, the recommended execution scenarios have comparable cost efficiency to the optimal scenarios.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {74–83},
numpages = {10},
keywords = {Resource Virtualization and Provisioning, Performance Modelling and Prediction, Distributed Graph Processing, Cost Effective Execution},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1007/978-3-642-39479-9_34,
author = {Liu, Xia and Zhou, Zhigang and Du, Xiaojiang and Zhang, Hongli and Wu, Junchao},
title = {Glaucus: predicting computing-intensive program's performance for cloud customers},
year = {2013},
isbn = {9783642394782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39479-9_34},
doi = {10.1007/978-3-642-39479-9_34},
abstract = {As Cloud computing has gained much popularity recently, many organizations consider transmitting their large-scale computing-intensive programs to cloud. However, cloud service market is still in its infant stage. Many companies offer a variety of cloud computing services with different pricing schemes, while customers have the demand of "spending the least, gaining the most". It makes a challenge which cloud service provider is more suitable for their programs and how much computing resource should be purchased. To address this issue, in this paper, we present a performance prediction scheme for computing-intensive program on cloud. The basic idea is to map program into an abstract tree, and create a miniature version program, and insert checkpoints in head and tail for each computable independent unit, which record the beginning &amp; end timestamp. Then we use the method of dynamic analysis, run the miniature version program on small data locally, and predict the whole program's cost on cloud. We find several features which have close relationship with program's performance, and through analyzing these features we can predict program's cost on the cloud. Our real-network experiments show that the scheme can achieve high prediction accuracy with low overhead.},
booktitle = {Proceedings of the 9th International Conference on Intelligent Computing Theories},
pages = {285–294},
numpages = {10},
keywords = {predict, performance, cost, cloud computing},
location = {Nanning, China},
series = {ICIC'13}
}

@article{10.1007/s11227-015-1520-y,
author = {Barati, Masoud and Sharifian, Saeed},
title = {A hybrid heuristic-based tuned support vector regression model for cloud load prediction},
year = {2015},
issue_date = {November  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {71},
number = {11},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-015-1520-y},
doi = {10.1007/s11227-015-1520-y},
abstract = {Cloud computing elasticity helps the cloud providers to handle large amount of computation and storage demands in an efficient manner. Proactively provisioning cloud workload is essential in order to keep the cloud utilization and service-level agreement at an acceptable level. Problems such as new virtual machine start-up latency, energy minimization and efficient resource provisioning, requires to predict resource demands for a few minutes ahead. Since the Cloud workloads have a very dynamic nature, CPU/memory usage varies considerably in the cloud. Also, existing prediction methods have considerable prediction error and erroneous results. So we propose a novel tuned support vector regression (TSVR) scheme that carefully selects three SVR parameters by a hybrid genetic algorithm and particle swarm optimization method. A chaotic sequence is devised into the algorithm to improve prediction accuracy and simultaneously avoid premature converging. To demonstrate the prediction accuracy of our TSVR model, we conduct a simulation study using Google cloud traces. The simulation results show that the proposed TSVR model achieves better prediction performance than conventional models in terms of standard metrics.},
journal = {J. Supercomput.},
month = nov,
pages = {4235–4259},
numpages = {25},
keywords = {VM, SVR, PSO, GA, Forecasting, Cloud computing}
}

@inproceedings{10.1007/978-3-642-25271-6_11,
author = {Clarke, Dave and Muschevici, Radu and Proen\c{c}a, Jos\'{e} and Schaefer, Ina and Schlatte, Rudolf},
title = {Variability modelling in the ABS language},
year = {2010},
isbn = {9783642252709},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25271-6_11},
doi = {10.1007/978-3-642-25271-6_11},
abstract = {The HATS project aims at developing a model-centric methodology for the design, implementation and verification of highly configurable systems, such as software product lines, centred around the Abstract Behavioural Specification (ABS) modelling Language. This article describes the variability modelling features of the ABS Modelling framework. It consists of four languages, namely, &lt;em&gt;μ&lt;/em&gt; TVL for describing feature models at a high level of abstraction, the Delta Modelling Language DML for describing variability of the ‘code' base in terms of delta modules, the Product Line Configuration Language CL for linking feature models and delta modules together and the Product Selection Language PSL for describing a specific product to extract from a product line. Both formal semantics and examples of each language are presented.},
booktitle = {Proceedings of the 9th International Conference on Formal Methods for Components and Objects},
pages = {204–224},
numpages = {21},
location = {Graz, Austria},
series = {FMCO'10}
}

@article{10.1016/j.knosys.2019.07.030,
author = {Shi, Maolin and Zhang, Liyong and Sun, Wei and Song, Xueguan},
title = {A fuzzy c-means algorithm guided by attribute correlations and its application in the big data analysis of tunnel boring machine},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {182},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.07.030},
doi = {10.1016/j.knosys.2019.07.030},
journal = {Know.-Based Syst.},
month = oct,
numpages = {14},
keywords = {Operation data, TBM, Attribute correlation, Data clustering}
}

@phdthesis{10.5555/AAI28261692,
author = {Pacheco, Ronny and Liu, Tieming and Yousefian, Fazard and Pappas, James},
advisor = {Manjunath, Kamath,},
title = {Development of a Parametric-Decomposition Methodology for Solving Queueing Networks with Simultaneous Resource Possession under Capacity Restrictions},
year = {2020},
isbn = {9798515255541},
publisher = {Oklahoma State University},
address = {USA},
abstract = {Motivated by applications in health care systems, this study focused on queueing network models with instances of simultaneous resource possession under capacity restrictions in different stages.  Customers during service at certain nodes in the first-level or primary system may simultaneously need service from a second-level server.  In this simultaneous resource possession situation, the time the customer spends waiting for the second-level server will impact the overall service time at first-level server and consequently the performance of the entire system. Closed queueing networks and fork/join approximations for one and two-stage systems were used to capture the capacity restriction effects in different sections of the primary system. An iterative algorithm was developed to incorporate the effect of the second-level server on the performance of the entire system. This study used a modular approach rooted in the parametric-decomposition method and two-moment approximations.  Different systems showing the proposed building blocks and their combinations to solve more complex systems illustrated the application of the proposed modeling approach.To evaluate the performance prediction accuracy of the solution algorithms, the analytical results were compared to simulation estimates for several configurations with single and multi-server nodes, a wide range of service time variability, and different levels of capacity constraints.  The analytical results tracked the simulation estimates well with errors less than 10% in more than 80% of the configurations simulated.  Higher errors in the 15% to 20% range were observed for system with low capacity limits, high service time variability (SCV=2), and high demand (p=0.75) for the second-level server.},
note = {AAI28261692}
}

@inproceedings{10.1145/3313831.3376589,
author = {Duan, Peitong and Wierzynski, Casimir and Nachman, Lama},
title = {Optimizing User Interface Layouts via Gradient Descent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376589},
doi = {10.1145/3313831.3376589},
abstract = {Automating parts of the user interface (UI) design process has been a longstanding challenge. We present an automated technique for optimizing the layouts of mobile UIs. Our method uses gradient descent on a neural network model of task performance with respect to the model's inputs to make layout modifications that result in improved predicted error rates and task completion times. We start by extending prior work on neural network based performance prediction to 2-dimensional mobile UIs with an expanded interaction space. We then apply our method to two UIs, including one that the model had not been trained on, to discover layout alternatives with significantly improved predicted performance. Finally, we confirm these predictions experimentally, showing improvements up to 9.2 percent in the optimized layouts. This demonstrates the algorithm's efficacy in improving the task performance of a layout, and its ability to generalize and improve layouts of new interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data-driven design, deep learning, gradient descent, lstm, mobile interfaces, optimization, performance modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{10.1109/TCBB.2020.3005813,
author = {Yang, Yuning and Yu, Jiawen and Liu, Zhe and Wang, Xi and Wang, Han and Ma, Zhiqiang and Xu, Dong},
title = {An Improved Topology Prediction of Alpha-Helical Transmembrane Protein Based on Deep Multi-Scale Convolutional Neural Network},
year = {2020},
issue_date = {Jan.-Feb. 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2020.3005813},
doi = {10.1109/TCBB.2020.3005813},
abstract = {Alpha-helical proteins (&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$alpha$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="wang-ieq1-3005813.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;TMPs) are essential in various biological processes. Despite their tertiary structures are crucial for revealing complex functions, experimental structure determination remains challenging and costly. In the past decades, various sequence-based topology prediction methods have been developed to bridge the gap between the sequences and structures by characterizing the structural features, but significant improvements are still required. Deep learning brings a great opportunity for its powerful representation learning capability from limited original data. In this work, we improved our &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$alpha$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="wang-ieq2-3005813.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;TMP topology prediction method DMCTOP using deep learning, which composed of two deep convolutional blocks to simultaneously extract local and global contextual features. Consequently, the inputs were simplified to reflect the original features of the sequence, including a protein sequence feature and an evolutionary conservation feature. DMCTOP can efficiently and accurately identify all topological types and the N-terminal orientation for an &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$alpha$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="wang-ieq3-3005813.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;TMP sequence. To validate the effectiveness of our method, we benchmarked DMCTOP against 13 peer methods according to the whole sequence, the transmembrane segment and the traditional criterion in testing experiments. All the results reveal that our method achieved the highest prediction accuracy and outperformed all the previous methods. The method is available at &lt;uri&gt;https://icdtools.nenu.edu.cn/dmctop&lt;/uri&gt;.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jun,
pages = {295–304},
numpages = {10}
}

@article{10.1145/3380982,
author = {Qin, Zhou and Cao, Fang and Yang, Yu and Wang, Shuai and Liu, Yunhuai and Tan, Chang and Zhang, Desheng},
title = {CellPred: A Behavior-aware Scheme for Cellular Data Usage Prediction},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3380982},
doi = {10.1145/3380982},
abstract = {Cellular data usage consumption prediction is an important topic in cellular networks related researches. Accurately predicting future data usage can benefit both the cellular operators and the users, which can further enable a wide range of applications. Different from previous work focusing on statistical approaches, in this paper, we propose a scheme called CellPred to predict cellular data usage from an individual user perspective considering user behavior patterns. Specifically, we utilize explicit user behavioral tags collected from subscription data to function as an external aid to enhance the user's mobility and usage prediction. Then we aggregate individual user data usage to cell tower level to obtain the final prediction results. To our knowledge, this is the first work studying cellular data usage prediction from an individual user behavior-aware perspective based on large-scale cellular signaling and behavior tags from the subscription data. The results show that our method improves the data usage prediction accuracy compared to the state-of-the-art methods; we also comprehensively demonstrate the impacts of contextual factors on CellPred performance. Our work can shed light on broad cellular networks researches related to human mobility and data usage. Finally, we discuss issues such as limitations, applications of our approach, and insights from our work.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {40},
numpages = {24},
keywords = {Urban Computing, Prediction, Deep Learning, Cellular networks, Behaviors}
}

@inproceedings{10.5555/2045445.2045497,
author = {Krohn-Grimberghe, Artus and Busche, Andre and Nanopoulos, Alexandros and Schmidt-Thieme, Lars},
title = {Active learning for technology enhanced learning},
year = {2011},
isbn = {9783642239847},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Suggesting tasks and learning resources of appropriate difficulty to learners is challenging. Neither should they be too difficult and nor too easy. Well-chosen tasks would enable a quick assessment of the learner, well-chosen learning resources would speed up the learning curve most. We connect active learning to classical pedagogical theory and propose the uncertainty sampling framework as a means to the challenge of selecting optimal tasks and learning resources to learners. To assess the efficiency of this strategy, we compared different exercise selection strategies and evaluated their effect on different datasets. We consistently find that uncertainty sampling significantly outperforms several alternative exercise selection approaches and thus leads to a faster convergence to the true assessment. These findings demonstrate that active (machine) learning is consistent with classic learning theory. It is a valuable instrument for choosing appropriate exercises as well as learning resources both from a teacher's and from a learner's perspective.},
booktitle = {Proceedings of the 6th European Conference on Technology Enhanced Learning: Towards Ubiquitous Learning},
pages = {512–518},
numpages = {7},
keywords = {student performance prediction, recommender systems, optimal learning, intelligent tutoring systems, active learning},
location = {Palermo, Italy},
series = {EC-TEL'11}
}

@article{10.3233/JHS-170580,
author = {Li, Peng and Dong, Lu and Xu, He and Lau, Ting Fung},
title = {Spark’s operation time predictive in cloud computing environment based on SRC-WSVR},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {24},
number = {1},
issn = {0926-6801},
url = {https://doi.org/10.3233/JHS-170580},
doi = {10.3233/JHS-170580},
abstract = {In Apache Spark cloud computing environment, computation capability of each node varies, together with the data size and uncertainties in application execution, these result in the differences in task execution time of a job. In order to enhance the accuracy in load execution time prediction, and reasonably guide the user to apply for Spark cluster resources, this paper researches on the execution flow of Spark job, collects the load time consumption index, and puts forward the time index fusion calculation scheme. And then, this paper researches on the multiple linear regression model and support vector machine model to explore the payload execution time and CPU Core, inputting data volume, memory size and other performance indicators. Based on the two models above, this paper proposes a Standard Regression Coefficient-based Weighted Support Vector Regression time prediction model (SRC-WSVR). Finally, through comparing the results from the prediction model proposed in this paper with conventional regression prediction model and Standard Support Vector Machine model, it proves that SRC-WSVR has a higher prediction accuracy, which can provide valid data reference for predicting Spark resource consumption.},
journal = {J. High Speed Netw.},
month = jan,
pages = {49–62},
numpages = {14},
keywords = {Spark, keyword five, performance benchmark, execution time prediction, Standard Regression Coefficient, Weighted Support Vector Regression Machine}
}

@inproceedings{10.1007/11554844_17,
author = {Trew, Tim},
title = {Enabling the smooth integration of core assets: defining and packaging architectural rules for a family of embedded products},
year = {2005},
isbn = {3540289364},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11554844_17},
doi = {10.1007/11554844_17},
abstract = {One of the remaining challenges in product line engineering is how to establish the quality of the reusable assets so that we can be confident that they can be configured and composed reliably. This is desirable, both to avoid having to completely re-test each product and to avoid integration faults only being detected late in product development. One of the diversity mechanisms of Philips’ high-end TV product line is the selection and com position of sub-systems, so different sub-system variants must integrate reli ably if the aims of the product line are to be realized. An earlier study of in tegration testing obligations in Philips products concluded that certain design policies must be imposed if integration testing is to be feasible, but it did not describe how relevant policies could be identified at the earliest stages of de sign. This paper addresses how a set of architectural rules were established for the TV product line through a root-cause analysis of problem reports, and packaged so that developers can recognize when they should be applied. The approach builds on other work on the impact of design choices on non-func-tional requirements to ensure that all quality attributes are addressed.},
booktitle = {Proceedings of the 9th International Conference on Software Product Lines},
pages = {137–149},
numpages = {13},
location = {Rennes, France},
series = {SPLC'05}
}

@inproceedings{10.1145/2491411.2491437,
author = {Liebig, J\"{o}rg and von Rhein, Alexander and K\"{a}stner, Christian and Apel, Sven and D\"{o}rre, Jens and Lengauer, Christian},
title = {Scalable analysis of variable software},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491437},
doi = {10.1145/2491411.2491437},
abstract = {The advent of variability management and generator technology enables users to derive individual variants from a variable code base based on a selection of desired configuration options. This approach gives rise to the generation of possibly billions of variants that, however, cannot be efficiently analyzed for errors with classic analysis techniques. To address this issue, researchers and practitioners usually apply sampling heuristics. While sampling reduces the analysis effort significantly, the information obtained is necessarily incomplete and it is unknown whether sampling heuristics scale to billions of variants. Recently, researchers have begun to develop variability-aware analyses that analyze the variable code base directly exploiting the similarities among individual variants to reduce analysis effort. However, while being promising, so far, variability-aware analyses have been applied mostly only to small academic systems. To learn about the mutual strengths and weaknesses of variability-aware and sampling-based analyses of software systems, we compared the two strategies by means of two concrete analysis implementations (type checking and liveness analysis), applied them to three subject systems: Busybox, the x86 Linux kernel, and OpenSSL. Our key finding is that variability-aware analysis outperforms most sampling heuristics with respect to analysis time while preserving completeness.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {81–91},
numpages = {11},
keywords = {Variability-aware Analysis, Type Checking, Software Product Lines, Liveness Analysis, C Preprocessor},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/1383559.1383581,
author = {Happe, Jens and Friedrich, Holger and Becker, Steffen and Reussner, Ralf H.},
title = {A pattern-based performance completion for Message-oriented Middleware},
year = {2008},
isbn = {9781595938732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1383559.1383581},
doi = {10.1145/1383559.1383581},
abstract = {Details about the underlying Message-oriented Middleware (MOM) are essential for accurate performance predictions of software systems using message-based communication. The MOM's configuration and usage strongly influence its throughput, resource utilisation and timing behaviour. Prediction models need to reflect these effects and allow software architects to evaluate the performance influence of MOM configured for their needs. Performance completions [31, 32] provide the general concept to include low-level details of execution environments in abstract performance models. In this paper, we extend the Palladio Component Model (PCM) [4] by a performance completion for Message-oriented Middleware. With our extension to the model, software architects can specify and configure message-based communication using a language based on messaging patterns. For performance evaluation, a model-to-model transformation integrates the low-level details of a MOM into the high-level software architecture model. A case study based on the SPECjms2007 Benchmark [1] predicts the performance of message-based communication with an error less than 20%.},
booktitle = {Proceedings of the 7th International Workshop on Software and Performance},
pages = {165–176},
numpages = {12},
keywords = {software architecture, model-based performance prediction, message-oriented middleware},
location = {Princeton, NJ, USA},
series = {WOSP '08}
}

@inproceedings{10.1145/3387902.3392633,
author = {Liu, Frank and Miniskar, Narasinga Rao and Chakraborty, Dwaipayan and Vetter, Jeffrey S.},
title = {Deffe: a data-efficient framework for performance characterization in domain-specific computing},
year = {2020},
isbn = {9781450379564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387902.3392633},
doi = {10.1145/3387902.3392633},
abstract = {As the computer architecture community moves toward the end of traditional device scaling, domain-specific architectures are becoming more pervasive. Given the number of diverse workloads and emerging heterogeneous architectures, exploration of this design space is a constrained optimization problem in a high-dimensional parameter space. In this respect, predicting workload performance both accurately and efficiently is a critical task for this exploration. In this paper, we present Deffe: a framework to estimate workload performance across varying architectural configurations. Deffe uses machine learning to improve the performance of this design space exploration. By casting the work of performance prediction itself as transfer learning tasks, the modelling component of Deffe can leverage the learned knowledge on one workload and "transfer" it to a new workload. Our extensive experimental results on a contemporary architecture toolchain (RISC-V and GEM5) and infrastructure show that the method can achieve superior testing accuracy with an effective reduction of 32-80\texttimes{} in terms of the amount of required training data. The overall run-time can be reduced from 400 hours to 5 hours when executed over 24 CPU cores. The infrastructure component of Deffe is based on scalable and easy-to-use open-source software components.},
booktitle = {Proceedings of the 17th ACM International Conference on Computing Frontiers},
pages = {182–191},
numpages = {10},
keywords = {workload characterization, transfer learning, multichannel convolution, machine learning, RISC-V},
location = {Catania, Sicily, Italy},
series = {CF '20}
}

@article{10.1007/s10115-018-1272-0,
author = {Raza, Basit and Sher, Asma and Afzal, Sana and Malik, Ahmad Kamran and Anjum, Adeel and Kumar, Yogan Jaya and Faheem, Muhammad},
title = {Autonomic workload performance tuning in large-scale data repositories},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {61},
number = {1},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-018-1272-0},
doi = {10.1007/s10115-018-1272-0},
abstract = {The workload in large-scale data repositories involves concurrent users and contains homogenous and heterogeneous data. The large volume of data, dynamic behavior and versatility of large-scale data repositories is not easy to be managed by humans. This requires computational power for managing the load of current servers. Autonomic technology can support predicting the workload type; decision support system or online transaction processing can help servers to autonomously adapt to the workloads. The intelligent system could be designed by knowing the type of workload in advance and predict the performance of workload that could autonomically adapt the changing behavior of workload. Workload management involves effectively monitoring and controlling the workflow of queries in large-scale data repositories. This work presents a taxonomy through systematic analysis of workload management in large-scale data repositories with respect to autonomic computing (AC) including database management systems and data warehouses. The state-of-the-art practices in large-scale data repositories are reviewed with respect to AC for characterization, performance prediction and adaptation of workload. Current issues are highlighted at the end with future directions.},
journal = {Knowl. Inf. Syst.},
month = oct,
pages = {27–63},
numpages = {37},
keywords = {Decision support system (DSS), Online transaction processing (OLTP), Adaptation, Prediction, Classification, Large-scale data repositories, Workload management, Autonomic computing}
}

@inproceedings{10.1145/3324884.3416573,
author = {M\"{u}hlbauer, Stefan and Apel, Sven and Siegmund, Norbert},
title = {Identifying software performance changes across variants and versions},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416573},
doi = {10.1145/3324884.3416573},
abstract = {We address the problem of identifying performance changes in the evolution of configurable software systems. Finding optimal configurations and configuration options that influence performance is already difficult, but in the light of software evolution, configuration-dependent performance changes may lurk in a potentially large number of different versions of the system.In this work, we combine two perspectives---variability and time---into a novel perspective. We propose an approach to identify configuration-dependent performance changes retrospectively across the software variants and versions of a software system. In a nutshell, we iteratively sample pairs of configurations and versions and measure the respective performance, which we use to update a model of likelihoods for performance changes. Pursuing a search strategy with the goal of measuring selectively and incrementally further pairs, we increase the accuracy of identified change points related to configuration options and interactions.We have conducted a number of experiments both on controlled synthetic data sets as well as in real-world scenarios with different software systems. Our evaluation demonstrates that we can pinpoint performance shifts to individual configuration options and interactions as well as commits introducing change points with high accuracy and at scale. Experiments on three real-world systems explore the effectiveness and practicality of our approach.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {611–622},
numpages = {12},
keywords = {active learning, configurable software systems, machine learning, software evolution, software performance},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3331184.3331192,
author = {Chen, Chong and Zhang, Min and Wang, Chenyang and Ma, Weizhi and Li, Minming and Liu, Yiqun and Ma, Shaoping},
title = {An Efficient Adaptive Transfer Neural Network for Social-aware Recommendation},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331192},
doi = {10.1145/3331184.3331192},
abstract = {Many previous studies attempt to utilize information from other domains to achieve better performance of recommendation. Recently, social information has been shown effective in improving recommendation results with transfer learning frameworks, and the transfer part helps to learn users' preferences from both item domain and social domain. However, two vital issues have not been well-considered in existing methods: 1) Usually, a static transfer scheme is adopted to share a user's common preference between item and social domains, which is not robust in real life where the degrees of sharing and information richness are varied for different users. Hence a non-personalized transfer scheme may be insufficient and unsuccessful. 2) Most previous neural recommendation methods rely on negative sampling in training to increase computational efficiency, which makes them highly sensitive to sampling strategies and hence difficult to achieve optimal results in practical applications.To address the above problems, we propose an Efficient Adaptive Transfer Neural Network (EATNN). By introducing attention mechanisms, the proposed model automatically assign a personalized transfer scheme for each user. Moreover, we devise an efficient optimization method to learn from the whole training set without negative sampling, and further extend it to support multi-task learning. Extensive experiments on three real-world public datasets indicate that our EATNN method consistently outperforms the state-of-the-art methods on Top-K recommendation task, especially for cold-start users who have few item interactions. Remarkably, EATNN shows significant advantages in training efficiency, which makes it more practical to be applied in real E-commerce scenarios. The code is available at (https://github.com/chenchongthu/EATNN).},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {225–234},
numpages = {10},
keywords = {whole-data based learning, social connections, recommender systems, implicit feedback, adaptive transfer learning},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3338906.3338974,
author = {Ne\v{s}i\'{c}, Damir and Kr\"{u}ger, Jacob and St\u{a}nciulescu, undefinedtefan and Berger, Thorsten},
title = {Principles of feature modeling},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338974},
doi = {10.1145/3338906.3338974},
abstract = {Feature models are arguably one of the most intuitive and successful notations for modeling the features of a variant-rich software system. Feature models help developers to keep an overall understanding of the system, and also support scoping, planning, development, variant derivation, configuration, and maintenance activities that sustain the system's long-term success. Unfortunately, feature models are difficult to build and evolve. Features need to be identified, grouped, organized in a hierarchy, and mapped to software assets. Also, dependencies between features need to be declared. While feature models have been the subject of three decades of research, resulting in many feature-modeling notations together with automated analysis and configuration techniques, a generic set of principles for engineering feature models is still missing. It is not even clear whether feature models could be engineered using recurrent principles. Our work shows that such principles in fact exist. We analyzed feature-modeling practices elicited from ten interviews conducted with industrial practitioners and from 31 relevant papers. We synthesized a set of 34 principles covering eight different phases of feature modeling, from planning over model construction, to model maintenance and evolution. Grounded in empirical evidence, these principles provide practical, context-specific advice on how to perform feature modeling, describe what information sources to consider, and highlight common characteristics of feature models. We believe that our principles can support researchers and practitioners enhancing feature-modeling tooling, synthesis, and analyses techniques, as well as scope future research.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {62–73},
numpages = {12},
keywords = {software product lines, modeling principles, Feature models},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1016/j.infsof.2016.08.005,
author = {Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Requirements monitoring frameworks},
year = {2016},
issue_date = {December 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {80},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2016.08.005},
doi = {10.1016/j.infsof.2016.08.005},
abstract = {Analyze the characteristics and application areas of monitoring approaches proposed in different domains.Systematically identify frameworks supporting requirements monitoring.Analyze to what extent the monitoring frameworks support requirements monitoring in SoS. ContextSoftware systems today often interoperate with each other, thus forming a system of systems (SoS). Due to the scale, complexity, and heterogeneity of SoS, determining compliance with their requirements is challenging, despite the range of existing monitoring approaches. The fragmented research landscape and the diversity of existing approaches, however, make it hard to understand and analyze existing research regarding its suitability for SoS. ObjectiveThe aims of this paper are thus to systematically identify, describe, and classify existing approaches for requirements-based monitoring of software systems at runtime. Specifically, we (i) analyze the characteristics and application areas of monitoring approaches proposed in different domains, we (ii) systematically identify frameworks supporting requirements monitoring, and finally (iii) analyze their support for requirements monitoring in SoS. MethodWe performed a systematic literature review (SLR) to identify existing monitoring approaches and to classify their key characteristics and application areas. Based on this analysis we selected requirements monitoring frameworks, following a definition by Robinson, and analyzed them regarding their support for requirements monitoring in SoS. ResultsWe identified 330 publications, which we used to produce a comprehensive overview of the landscape of requirements monitoring approaches. We analyzed these publications regarding their support for Robinson's requirements monitoring layers, resulting in 37 identified frameworks. We investigated how well these frameworks support requirements monitoring in SoS. ConclusionsWe conclude that most existing approaches are restricted to certain kinds of checks, particular types of events and data, and mostly also limited to one particular architectural style and technology. This lack of flexibility makes their application in an SoS context difficult. Also, systematic and automated variability management is still missing. Regarding their evaluation, many existing frameworks focus on measuring the performance overhead, while only few frameworks have been assessed in cases studies with real-world systems.},
journal = {Inf. Softw. Technol.},
month = dec,
pages = {89–109},
numpages = {21},
keywords = {Systems of systems, Systematic literature review, Requirements monitoring}
}

@article{10.1109/TCBB.2019.2937862,
author = {Hossain, Md. Ekramul and Khan, Arif and Moni, Mohammad Ali and Uddin, Shahadat},
title = {Use of Electronic Health Data for Disease Prediction: A Comprehensive Literature Review},
year = {2021},
issue_date = {March-April 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {18},
number = {2},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2937862},
doi = {10.1109/TCBB.2019.2937862},
abstract = {Disease prediction has the potential to benefit stakeholders such as the government and health insurance companies. It can identify patients at risk of disease or health conditions. Clinicians can then take appropriate measures to avoid or minimize the risk and in turn, improve quality of care and avoid potential hospital admissions. Due to the recent advancement of tools and techniques for data analytics, disease risk prediction can leverage large amounts of semantic information, such as demographics, clinical diagnosis and measurements, health behaviours, laboratory results, prescriptions and care utilisation. In this regard, electronic health data can be a potential choice for developing disease prediction models. A significant number of such disease prediction models have been proposed in the literature over time utilizing large-scale electronic health databases, different methods, and healthcare variables. The goal of this comprehensive literature review was to discuss different risk prediction models that have been proposed based on electronic health data. Search terms were designed to find relevant research articles that utilized electronic health data to predict disease risks. Online scholarly databases were searched to retrieve results, which were then reviewed and compared in terms of the method used, disease type, and prediction accuracy. This paper provides a comprehensive review of the use of electronic health data for risk prediction models. A comparison of the results from different techniques for three frequently modelled diseases using electronic health data was also discussed in this study. In addition, the advantages and disadvantages of different risk prediction models, as well as their performance, were presented. Electronic health data have been widely used for disease prediction. A few modelling approaches show very high accuracy in predicting different diseases using such data. These modelling approaches have been used to inform the clinical decision process to achieve better outcomes.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = apr,
pages = {745–758},
numpages = {14}
}

@inproceedings{10.1145/3277453.3277477,
author = {Zhao, Xinchao and Lv, Weimin},
title = {Reliability Evaluation of Complex Equipment Based on Virtual Samples and Performance Degradation},
year = {2018},
isbn = {9781450365413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277453.3277477},
doi = {10.1145/3277453.3277477},
abstract = {Aiming at the difficulties in reliability evaluation of small samples and multi-performance parameter products, a reliability evaluation method based on virtual samples and performance degradation is proposed. Firstly, the multi-performance parameter distance concept is introduced, and the original parameter is virtual augmented with the performance parameter distance. Secondly, the improved Elman neural network is used to process the sample to obtain the complete degradation trajectory. Finally, this method is combined with the performance prediction method based on performance degradation to process the degradation data of a certain type of space relay and obtain a lifetime of 128 hours. The result shows the method effectively solves the processing problem of the rare sample data in the accelerated degradation test, which has certain reference significance.},
booktitle = {Proceedings of the 2018 International Conference on Electronics and Electrical Engineering Technology},
pages = {112–117},
numpages = {6},
keywords = {Virtual sample, Reliability, Performance degradation, Distance analysis},
location = {Tianjin, China},
series = {EEET '18}
}

@article{10.1007/s00521-020-04871-1,
author = {Liu, Xuze and Fotouhi, Abbas},
title = {Formula-E race strategy development using artificial neural networks and Monte Carlo tree search},
year = {2020},
issue_date = {Sep 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {18},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04871-1},
doi = {10.1007/s00521-020-04871-1},
abstract = {Energy management has been one of the most important parts in electric race strategies since the F\'{e}d\'{e}ration Internationale de l’Automobile Formula-E championships were launched in 2014. Since that time, a number of unfavorable race finishes have been witnessed due to poor energy management. Previous researches have been focused on managing the power flow between different energy sources or different energy consumers based on a fixed cycle. However, there is no published work in the literature about energy management of a full electric racing car on repeated course but with changeable settings and driving styles. Different from traditional energy management problems, the electric race strategy is more of a multi-stage decision-making problem which has a very large scale. Meanwhile, this is a time-critical task in motorsport where fast prediction tools are needed and decisions have to be made in seconds to benefit the final outcome of the race. In this study, the use of artificial neural networks (ANN) and tree search techniques is investigated as an approach to solve such a large-scale problem. ANN prediction models are developed to replace the traditional lap time simulation as a much faster performance prediction tool. Implementation of Monte Carlo tree search based on the proposed ANN fast prediction models has provided decent capability to generate decision-making solution for both pre-race planning and in-race reaction to unexpected scenarios.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {15191–15207},
numpages = {17},
keywords = {Artificial neural networks, Machine learning, Energy management, Formula-E race strategy}
}

@article{10.1016/j.micpro.2020.103185,
author = {Agosta, Giovanni and Fornaciari, William and Atienza, David and Canal, Ramon and Cilardo, Alessandro and Flich Cardo, Jos\'{e} and Hernandez Luz, Carles and Kulczewski, Michal and Massari, Giuseppe and Tornero Gavil\'{a}, Rafael and Zapater, Marina},
title = {The RECIPE approach to challenges in deeply heterogeneous high performance systems},
year = {2020},
issue_date = {Sep 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {77},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103185},
doi = {10.1016/j.micpro.2020.103185},
journal = {Microprocess. Microsyst.},
month = sep,
numpages = {13},
keywords = {Run-time management, Heterogeneous computing, HPC}
}

@article{10.1145/1496909.1496927,
author = {Dayal, Umeshwar and Kuno, Harumi and Wiener, Janet L. and Wilkinson, Kevin and Ganapathi, Archana and Krompass, Stefan},
title = {Managing operational business intelligence workloads},
year = {2009},
issue_date = {January 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1496909.1496927},
doi = {10.1145/1496909.1496927},
abstract = {We explore how to manage database workloads that contain a mixture of OLTP-like queries that run for milliseconds as well as business intelligence queries and maintenance tasks that last for hours. As data warehouses grow in size to petabytes and complex analytic queries play a greater role in day-to-day business operations, factors such as inaccurate cardinality estimates, data skew, and resource contention all make it notoriously difficult to predict how such queries will behave before they start executing. However, traditional workload management assumes that accurate expectations for the resource requirements and performance characteristics of a workload are available at compile-time, and relies on such information in order to make critical workload management decisions. In this paper, we describe our approach to dealing with inaccurate predictions. First, we evaluate the ability of workload management algorithms to handle workloads that include unexpectedly long-running queries. Second, we describe a new and more accurate method for predicting the resource usage of queries before runtime. We have carried out an extensive set of experiments, and report on a few of our results.},
journal = {SIGOPS Oper. Syst. Rev.},
month = jan,
pages = {92–98},
numpages = {7},
keywords = {database workload managment, database performance prediction, business intelligence databases}
}

@inproceedings{10.5555/3016100.3016232,
author = {Zhe, Shandian and Qi, Yuan and Park, Youngja and Xu, Zenglin and Molloy, Ian and Chari, Suresh},
title = {DinTucker: scaling up Gaussian process models on large multidimensional arrays},
year = {2016},
publisher = {AAAI Press},
abstract = {Tensor decomposition methods are effective tools for modelling multidimensional array data (i.e., tensors). Among them, nonparametric Bayesian models, such as Infinite Tucker Decomposition (InfTucker), are more powerful than multilinear factorization approaches, including Tucker and PARAFAC, and usually achieve better predictive performance. However, they are difficult to handle massive data due to a prohibitively high training cost. To address this limitation, we propose Distributed infinite Tucker (DINTUCKER), a new hierarchical Bayesian model that enables local learning of InfTucker on subarrays and global information integration from local results. We further develop a distributed stochastic gradient descent algorithm, coupled with variational inference for model estimation. In addition, the connection between DINTUCKER and InfTucker is revealed in terms of model evidence. Experiments demonstrate that DINTUCKER maintains the predictive accuracy of InfTucker and is scalable on massive data: On multidimensional arrays with billions of elements from two real-world applications, DINTUCKER achieves significantly higher prediction accuracy with less training time, compared with the state-of-the-art large-scale tensor decomposition method, GigaTensor.},
booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
pages = {2386–2392},
numpages = {7},
location = {Phoenix, Arizona},
series = {AAAI'16}
}

@article{10.3233/JIFS-189675,
author = {Wang, Hongyi and Sanju\'{a}n Mart\'{\i}nez, Oscar and Fenza, Giuseppe and Gonzalez Crespo, Ruben},
title = {Research on influencing factors of financial performance of listed companies based on multiple linear regression and fuzzy logic system},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-189675},
doi = {10.3233/JIFS-189675},
abstract = {The ultimate goal of listed companies is to maximize shareholders’ wealth. With the increasingly fierce market competition, enterprise managers are constantly exploring the key indicators that have an important impact on the financial performance (FP) of enterprises, and achieve the expected FP of shareholders by improving these key indicators. On the basis of the existing enterprise performance measurement system and index research, through expert scoring to determine the secondary indicators, this paper selects 87 small and medium-sized board listed companies which officially announced the implementation of equity incentive from 2009 to 2012 as the sample, takes the financial information disclosed in 2013 as the empirical data, and analyzes the traditional multiple linear regression analysis (MLR) When dealing with big data, especially the data with hierarchical structure, this paper proposes a partial regression coefficient calculation model based on hierarchical data, constructs a multiple nonlinear regression model, and concludes through empirical analysis that there is a nonlinear correlation between equity incentive ratio and corporate performance, and that there is an interval effect between equity incentive ratio and corporate performance. We also present Fuzzy based financial performance prediction of listed companies. Finally, we demonstrate Comparative analysis for financial prediction in term of accuracy between multiple regression model and fuzzy logic system and result deduce that fuzzy logic gives better accuracy than regression model.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {8549–8561},
numpages = {13},
keywords = {Multiple linear regression, data mining, hierarchical data, superior company finance; performance influencing factors}
}

@inproceedings{10.1145/3220162.3220188,
author = {Ma, Xiaofeng and Yang, Yan and Zhou, Zhurong},
title = {Using Machine Learning Algorithm to Predict Student Pass Rates In Online Education},
year = {2018},
isbn = {9781450364577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220162.3220188},
doi = {10.1145/3220162.3220188},
abstract = {In online education, the quality evaluation of education is crucial importance to schools and even to the entire range of educational institutions. There are many ways to evaluate online education. Taking the prediction of student pass rates as an example, many researchers have used machine Learning algorithms to predict student pass rates and find out important student features affecting learning. However, they did not establish feature model for online education that predicts the student pass rates and introduce deep neural network (DNN) algorithms - a new method in machine learning into online education. Therefore, this study first explores how to establish a feature model that predicts the student pass rates for online education, and then uses the grid search (GS) algorithm to optimize the decision tree algorithm (DT) and support vector machine (SVM) algorithm to improve the prediction accuracy. Finally, compared the improved algorithm with the DNN algorithm, we find a suitable algorithm for student pass rate prediction. The purpose of this study is to improve the quality of online teaching by predicting the student pass rates, increasing students' academic performance and strengthening online educational management.},
booktitle = {Proceedings of the 3rd International Conference on Multimedia Systems and Signal Processing},
pages = {156–161},
numpages = {6},
keywords = {Support Vector Machine Algorithm, Grid Search Algorithm, Feature Model, Deep Neural Network, Decision Tree Algorithm},
location = {Shenzhen, China},
series = {ICMSSP '18}
}

@inproceedings{10.1145/3229710.3229756,
author = {Chahal, Dheeraj and Mathew, Benny and Nambiar, Manoj},
title = {Predicting the Runtime of Memory Intensive Batch Workloads},
year = {2018},
isbn = {9781450365239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229710.3229756},
doi = {10.1145/3229710.3229756},
abstract = {Data centers use their non-peak business hours to run batch jobs in order to maximize the resource utilization. Large data centers may run thousands of batch jobs every day. These jobs typically process large volumes of data and can either be compute or memory intensive. Batch jobs may perform data reconciliation, risk analysis, and carry out analytics that are critical for the business. Hence, it is imperative that these jobs complete within the available time frame.New servers with large number of core and Non-Uniform Memory Access (NUMA) architecture provide very large compute capacity. This means that many batch jobs can be run concurrently to minimize their collective completion time. However, excessive parallelism may create memory access bottleneck and adversely affect the completion time.The objective of this work is to predict the completion time of concurrently running batch jobs. We assume each job to be multithreaded and memory intensive. A prediction model based on memory and CPU contention is proposed. Our predictions are based on server simulation that uses individual batch job data to predict the completion time of concurrently running jobs.The efficacy of our approach is validated using STREAM, a well-known open source synthetic benchmark. We also study the effect of hyper-threading and memory binding on prediction accuracy of our model.},
booktitle = {Workshop Proceedings of the 47th International Conference on Parallel Processing},
articleno = {45},
numpages = {8},
keywords = {Service demand, Hyper-Threading, Batch jobs},
location = {Eugene, OR, USA},
series = {ICPP Workshops '18}
}

@article{10.5555/2596938.2596942,
author = {Chaurasia, Priyanka and McClean, Sally and Scotney, Bryan and Nugent, Chris},
title = {Duration discretisation for activity recognition},
year = {2012},
issue_date = {July 2012},
publisher = {IOS Press},
address = {NLD},
volume = {20},
number = {4},
issn = {0928-7329},
abstract = {Activity recognition has become a key component within smart environments that aim at providing assistive solutions for their users. Learning high level activities from low level sensor data depends on several parameters, one of which is the duration of the activities themselves. Nevertheless, directly incorporating continuous duration values into a model is a complex process and may not prove to be very qualitative. In this paper we aim at discretising activity related durations using different clustering algorithms. We explore the possibility of discretising duration data through the use of rudimentary clustering algorithms such as visual inspection to more established methods such as model based clustering. In addition, a probabilistic model is built that predicts both person and activities from the observed values of sensor sequence, time and discrete duration values. Each of the models created is compared in terms of its performance in the prediction of activities. Following analysis of the results attained it has been found that irrespective of the clustering algorithm used for duration discretisation, incorporating the duration information increases the prediction performance. Prediction accuracy was improved by almost 3% when the model was built incorporating durations.},
journal = {Technol. Health Care},
month = jul,
pages = {277–295},
numpages = {19},
keywords = {Duration, Discretisation, Clustering Algorithms, Activity Recognition}
}

@inproceedings{10.1145/3357765.3359525,
author = {Feichtinger, Kevin and Hinterreiter, Daniel and Linsbauer, Lukas and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {Supporting feature model evolution by suggesting constraints from code-level dependency analyses},
year = {2019},
isbn = {9781450369800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357765.3359525},
doi = {10.1145/3357765.3359525},
abstract = {Feature models are a de facto standard for representing the commonalities and variability of product lines and configurable software systems. Requirements-level features are commonly implemented in multiple source code artifacts, which results in complex dependencies at the code level. As developers change and evolve features frequently, it is challenging to keep feature models consistent with their implementation. We thus present an approach combining feature-to-code mappings and code dependency analyses to inform engineers about possible inconsistencies. Our focus is on code-level changes requiring updates in feature dependencies and constraints. Our approach uses static code analysis and a variation control system to lift complex code-level dependencies to feature models. We present the suggested dependencies to the engineer in two ways: directly as links between features in a feature model and as a heatmap visualizing the dependency changes of all features in a model. We present results of an evaluation on the Pick-and-Place Unit system, which demonstrates the utility and performance of our approach and the quality of the suggestions.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {129–142},
numpages = {14},
keywords = {variation control system, static code analysis, product lines, dependency analysis},
location = {Athens, Greece},
series = {GPCE 2019}
}

@article{10.1007/s11227-020-03475-9,
author = {Sheidaeian, Hamed and Fatemi, Omid},
title = {Toward a general framework for jointly processor-workload empirical modeling},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {6},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-020-03475-9},
doi = {10.1007/s11227-020-03475-9},
abstract = {The complexity of state-of-the-art processor architectures and their consequent vast design spaces have made it difficult and time-consuming to explore the best configuration for them. Design space exploration (DSE) refers to systematic analysis and pruning of unwanted design points based on parameters of interest. DSE requires analysis and estimation of performance criteria of design points. A more accurate estimation produces a more efficient target design. A typical estimation method is machine learning approaches based on statistical inference, also known as empirical modeling, which requires only a limited number of simulations. Undoubtedly, an empirical model finds the optima much faster than using cycle-accurate simulations and is much more accurate than employing analytical models. For that purpose, our paper proposes a general methodology and a framework to find an appropriate and most accurate empirical model to estimate the performance of general-purpose or embedded multiprocessors running multithreaded workloads. This framework consists of three main steps: (1) Workload characterization and clustering, (2) Finding optimal model, and (3) Estimating the performance of a new workload outside the training set. These optimal performance prediction models could be utilized in the process of exploring the architectural design space. An experimental case is also tested using this framework for feasibility purposes. Validation experiments show MAEs less than 10% for this case.},
journal = {J. Supercomput.},
month = jun,
pages = {5319–5353},
numpages = {35},
keywords = {Performance Estimation, Combined Algorithm Selection and Hyper-parameters Optimization, Workload clustering, Empirical models, Processor modeling}
}

@inproceedings{10.1145/2528265.2528267,
author = {Apel, Sven and Kolesnikov, Sergiy and Siegmund, Norbert and K\"{a}stner, Christian and Garvin, Brady},
title = {Exploring feature interactions in the wild: the new feature-interaction challenge},
year = {2013},
isbn = {9781450321686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2528265.2528267},
doi = {10.1145/2528265.2528267},
abstract = {The feature-interaction problem has been keeping researchers and practitioners in suspense for years. Although there has been substantial progress in developing approaches for modeling, detecting, managing, and resolving feature interactions, we lack sufficient knowledge on the kind of feature interactions that occur in real-world systems. In this position paper, we set out the goal to explore the nature of feature interactions systematically and comprehensively, classified in terms of order and visibility. Understanding this nature will have significant implications on research in this area, for example, on the efficiency of interaction-detection or performance-prediction techniques. A set of preliminary results as well as a discussion of possible experimental setups and corresponding challenges give us confidence that this endeavor is within reach but requires a collaborative effort of the community.},
booktitle = {Proceedings of the 5th International Workshop on Feature-Oriented Software Development},
pages = {1–8},
numpages = {8},
keywords = {feature-oriented software development, feature-interaction problem, feature modularity, feature interactions},
location = {Indianapolis, Indiana, USA},
series = {FOSD '13}
}

@inproceedings{10.1145/2897937.2897977,
author = {Zheng, Xinnian and John, Lizy K. and Gerstlauer, Andreas},
title = {Accurate phase-level cross-platform power and performance estimation},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2897977},
doi = {10.1145/2897937.2897977},
abstract = {Fast and accurate performance and power prediction is a key challenge in co-development of hardware and software. Traditional analytical or simulation-based approaches are often too inaccurate or slow. In this work, we propose LACross, a novel learning-based, analytical cross-platform prediction framework that provides fast and accurate estimation of time-varying software performance and power consumption on a target hardware platform. We employ a fine-grained phase-based approach, where the learning algorithm synthesizes analytical proxy models that predict the performance and power of the workload in each program phase from performance statistics obtained through hardware counter measurements on the host. Our learning approach relies on a one-time training phase using a target reference model or real hardware. We applied our approach to 35 benchmarks from SPEC 2006, SD-VBS and MiBench. Results show on average over 97% prediction accuracy for predicting both fine-grain performance and power traces at speeds of over 500 MIPS.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {4},
numpages = {6},
location = {Austin, Texas},
series = {DAC '16}
}

@inproceedings{10.1145/3292500.3330868,
author = {Liu, Kunpeng and Fu, Yanjie and Wang, Pengfei and Wu, Le and Bo, Rui and Li, Xiaolin},
title = {Automating Feature Subspace Exploration via Multi-Agent Reinforcement Learning},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330868},
doi = {10.1145/3292500.3330868},
abstract = {Feature selection is the preprocessing step in machine learning which tries to select the most relevant features for the subsequent prediction task. Effective feature selection could help reduce dimensionality, improve prediction accuracy and increase result comprehensibility. It is very challenging to find the optimal feature subset from the subset space as the space could be very large. While much effort has been made by existing studies, reinforcement learning can provide a new perspective for the searching strategy in a more global way. In this paper, we propose a multi-agent reinforcement learning framework for the feature selection problem. Specifically, we first reformulate feature selection with a reinforcement learning framework by regarding each feature as an agent. Then, we obtain the state of environment in three ways, i.e., statistic description, autoencoder and graph convolutional network (GCN), in order to make the algorithm better understand the learning progress. We show how to learn the state representation in a graph-based way, which could tackle the case when not only the edges, but also the nodes are changing step by step. In addition, we study how the coordination between different features would be improved by more reasonable reward scheme. The proposed method could search the feature subset space globally and could be easily adapted to the real-time case (real-time feature selection) due to the nature of reinforcement learning. Also, we provide an efficient strategy to accelerate the convergence of multi-agent reinforcement learning. Finally, extensive experimental results show the significant improvement of the proposed method over conventional approaches.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {207–215},
numpages = {9},
keywords = {multi-agent reinforcement learning, feature selection, automated exploration},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1007/s00521-020-05244-4,
author = {Armaghani, Danial Jahed and Asteris, Panagiotis G.},
title = {A comparative study of ANN and ANFIS models for the prediction of cement-based mortar materials compressive strength},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05244-4},
doi = {10.1007/s00521-020-05244-4},
abstract = {Despite the extensive use of mortars materials in constructions over the last decades, there is not yet a reliable and robust method, available in the literature, which can estimate its strength based on its mix parameters. This limitation is due to the highly nonlinear relation between the mortar’s compressive strength and the mixed components. In this paper, the application of artificial intelligence techniques toward the prediction of the compressive strength of cement-based mortar materials with or without metakaolin has been investigated. Specifically, surrogate models (such as artificial neural network, ANN and adaptive neuro-fuzzy inference system, ANFIS models) have been developed to the prediction of the compressive strength of mortars trained using experimental data available in the literature. The comparison of the derived results with the experimental findings demonstrates the ability of both ANN and ANFIS models to approximate the compressive strength of mortars in a reliable and robust manner. Although ANFIS was able to obtain higher performance prediction to estimate the compressive strength of mortars compared to ANN model, it was found through the verification process of some other additional data, the ANFIS model has overfitted the data. Therefore, the developed ANN model has been introduced as the best predictive technique for solving problem of the compressive strength of mortars. Furthermore, using the optimum developed model an ambitious attempt to reveal the nature of mortar materials has been made.},
journal = {Neural Comput. Appl.},
month = may,
pages = {4501–4532},
numpages = {32},
keywords = {Adaptive neuro-fuzzy inference system, Artificial intelligence techniques, Mortar, Metakaolin, Compressive strength, Cement, Artificial neural networks}
}

@article{10.1007/s10664-020-09868-x,
author = {Falessi, Davide and Huang, Jacky and Narayana, Likhita and Thai, Jennifer Fong and Turhan, Burak},
title = {On the need of preserving order of data when validating within-project defect classifiers},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09868-x},
doi = {10.1007/s10664-020-09868-x},
abstract = {We are in the shoes of a practitioner who uses previous project releases’ data to predict which classes of the current release are defect-prone. In this scenario, the practitioner would like to use the most accurate classifier among the many available ones. A validation technique, hereinafter “technique”, defines how to measure the prediction accuracy of a classifier. Several previous research efforts analyzed several techniques. However, no previous study compared validation techniques in the within-project across-release class-level context or considered techniques that preserve the order of data. In this paper, we investigate which technique recommends the most accurate classifier. We use the last release of a project as the ground truth to evaluate the classifier’s accuracy and hence the ability of a technique to recommend an accurate classifier. We consider nine classifiers, two industry and 13 open projects, and three validation techniques: namely 10-fold cross-validation (i.e., the most used technique), bootstrap (i.e., the recommended technique), and walk-forward (i.e., a technique preserving the order of data). Our results show that: 1) classifiers differ in accuracy in all datasets regardless of their entity per value, 2) walk-forward outperforms both 10-fold cross-validation and bootstrap statistically in all three accuracy metrics: AUC of the selected classifier, bias and absolute bias, 3) surprisingly, all techniques resulted to be more prone to overestimate than to underestimate the performances of classifiers, and 3) the defect rate resulted in changing between the second and first half in both industry projects and 83% of open-source datasets. This study recommends the use of techniques that preserve the order of data such as walk-forward over 10-fold cross-validation and bootstrap in the within-project across-release class-level context given the above empirical results and that walk-forward is by nature more simple, inexpensive, and stable than the other two techniques.},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {4805–4830},
numpages = {26},
keywords = {Model validation techniques, Classifiers, Defect classifiers}
}

@inproceedings{10.1007/978-3-642-31762-0_5,
author = {Wong, Peter Y. H. and Diakov, Nikolay and Schaefer, Ina},
title = {Modelling adaptable distributed object oriented systems using the HATS approach: a fredhopper case study},
year = {2011},
isbn = {9783642317613},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31762-0_5},
doi = {10.1007/978-3-642-31762-0_5},
abstract = {The HATS project aims at developing a model-centric engineering methodology for the design, implementation and verification of distributed, concurrent and highly configurable systems. Such systems also have high demands on their dependability and trustworthiness. The HATS approach is centered around the Abstract Behavioural Specification modelling language (ABS) and its accompanying tools suite. The HATS approach allows the precise specification and analysis of the abstract behaviour of distributed software systems and their variability. The HATS project measures its success by applying its framework not only to toy examples, but to real industrial scenarios. In this paper, we evaluate the HATS approach for modelling an industrial scale case study provided by the eCommerce company Fredhopper. In this case study we consider Fredhopper Access Server (FAS). We model the commonality and variability of FAS's replication system using the ABS language and provide an evaluation based on our experience.},
booktitle = {Proceedings of the 2011 International Conference on Formal Verification of Object-Oriented Software},
pages = {49–66},
numpages = {18},
keywords = {variability modelling, software product lines, industrial case study, formal modelling and specification, evaluation},
location = {Turin, Italy},
series = {FoVeOOS'11}
}

@article{10.1016/j.jss.2013.11.1096,
author = {Lochau, Malte and Lity, Sascha and Lachmann, Remo and Schaefer, Ina and Goltz, Ursula},
title = {Delta-oriented model-based integration testing of large-scale systems},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.11.1096},
doi = {10.1016/j.jss.2013.11.1096},
abstract = {Software architecture specifications are of growing importance for coping with the complexity of large-scale systems. They provide an abstract view on the high-level structural system entities together with their explicit dependencies and build the basis for ensuring behavioral conformance of component implementations and interactions, e.g., using model-based integration testing. The increasing inherent diversity of such large-scale variant-rich systems further complicates quality assurance. In this article, we present a combination of architecture-driven model-based testing principles and regression-inspired testing strategies for efficient, yet comprehensive variability-aware conformance testing of variant-rich systems. We propose an integrated delta-oriented architectural test modeling and testing approach for component as well as integration testing that allows the generation and reuse of test artifacts among different system variants. Furthermore, an automated derivation of retesting obligations based on accurate delta-oriented architectural change impact analysis is provided. Based on a formal conceptual framework that guarantees stable test coverage for every system variant, we present a sample implementation of our approach and an evaluation of the validity and efficiency by means of a case study from the automotive domain.},
journal = {J. Syst. Softw.},
month = may,
pages = {63–84},
numpages = {22},
keywords = {Variable software architectures, Regression testing, Model-based testing, Large-scale systems}
}

@article{10.1016/j.eswa.2013.07.046,
author = {Thammasiri, Dech and Delen, Dursun and Meesad, Phayung and Kasap, Nihat},
title = {A critical assessment of imbalanced class distribution problem: The case of predicting freshmen student attrition},
year = {2014},
issue_date = {February, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {2},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2013.07.046},
doi = {10.1016/j.eswa.2013.07.046},
abstract = {Predicting student attrition is an intriguing yet challenging problem for any academic institution. Class-imbalanced data is a common in the field of student retention, mainly because a lot of students register but fewer students drop out. Classification techniques for imbalanced dataset can yield deceivingly high prediction accuracy where the overall predictive accuracy is usually driven by the majority class at the expense of having very poor performance on the crucial minority class. In this study, we compared different data balancing techniques to improve the predictive accuracy in minority class while maintaining satisfactory overall classification performance. Specifically, we tested three balancing techniques-over-sampling, under-sampling and synthetic minority over-sampling (SMOTE)-along with four popular classification methods-logistic regression, decision trees, neuron networks and support vector machines. We used a large and feature rich institutional student data (between the years 2005 and 2011) to assess the efficacy of both balancing techniques as well as prediction methods. The results indicated that the support vector machine combined with SMOTE data-balancing technique achieved the best classification performance with a 90.24% overall accuracy on the 10-fold holdout sample. All three data-balancing techniques improved the prediction accuracy for the minority class. Applying sensitivity analyses on developed models, we also identified the most important variables for accurate prediction of student attrition. Application of these models has the potential to accurately predict at-risk students and help reduce student dropout rates.},
journal = {Expert Syst. Appl.},
month = feb,
pages = {321–330},
numpages = {10},
keywords = {Student retention, Sensitivity analysis, Sampling, SMOTE, Prediction, Imbalanced class distribution, Attrition}
}

@inproceedings{10.5555/2616606.2616884,
author = {Zhang, Shuangyue and Lin, Fan and Hsu, Chun-Kai and Cheng, Kwang-Ting and Wang, Hong},
title = {Joint virtual probe: joint exploration of multiple test items' spatial patterns for efficient silicon characterization and test prediction},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Virtual Probe (VP), proposed for characterization of spatial variations and for test time reduction, can effectively reconstruct the spatial pattern of a test item for an entire wafer using measurement values from only a small fraction of dies on the wafer. However, VP calculates the spatial signature of each test item separately, one item at a time, resulting in very long runtime for complex chips which often require hundreds, or even thousands, of test items in production. In this paper, we propose a new method, named Joint Virtual Probe (JVP), which can jointly derive spatial patterns of multiple test items.By simultaneously handling a large group of test items, JVP significantly reduces the overall runtime. And the prediction accuracy can also be improved because of JVP's implicit use of inter-test-item correlations in predicting spatial patterns. The experimental results on two industrial products, with 277 and 985 parametric test items in the production test programs respectively, demonstrate that, JVP achieves an average speedup of ~170X and ~50X over VP in the pre-test analysis and the test application phases respectively, as well as a slightly higher prediction accuracy than VP.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {227},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '14}
}

@article{10.1016/j.ipm.2019.02.013,
author = {Ozdikis, Ozer and Ramampiaro, Heri and N\o{}rv\r{a}g, Kjetil},
title = {Locality-adapted kernel densities of term co-occurrences for location prediction of tweets},
year = {2019},
issue_date = {Jul 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {56},
number = {4},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2019.02.013},
doi = {10.1016/j.ipm.2019.02.013},
journal = {Inf. Process. Manage.},
month = jul,
pages = {1280–1299},
numpages = {20},
keywords = {Spatial point patterns, Kernel density estimation, Twitter, Location prediction}
}

@article{10.1007/s11219-021-09571-0,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {Dynamic test prioritization of product lines: An application on configurable simulation models},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-021-09571-0},
doi = {10.1007/s11219-021-09571-0},
abstract = {Product line testing is challenging due to the potentially huge number of configurations. Several approaches have tackled this challenge; most of them focused on reducing the number of tested products by selecting a representative subset. However, little attention has been paid to product line test optimization using test results, while tests are executed. This paper aims at optimizing the testing process of product lines by increasing the fault detection rate. To this end we propose a dynamic test prioritization approach. In contrast to traditional static test prioritization, our dynamic test prioritization leverages information of tests being executed in specific products. Processing this information, the initially prioritized tests are rearranged in order to find non-discovered faults. The proposed approach is valid for any kind of product lines, but we have adapted it to the context of configurable simulation models, an area where testing is especially time-consuming and optimization methods are paramount. The approach was empirically evaluated by employing two case studies. The results of this evaluation reveal that the proposed test prioritization approach improves both the static prioritization algorithm and the selected baseline technique. The results provide a basis for suggesting that the proposed dynamic test prioritization approach is appropriate to optimize the testing process of product lines.},
journal = {Software Quality Journal},
month = dec,
pages = {943–988},
numpages = {46},
keywords = {Cyber-Physical systems, Simulation-based testing, Software product lines, Test prioritization}
}

@inproceedings{10.1109/COMPSAC.2015.27,
author = {Nikravesh, Ali Yadavar and Ajila, Samuel A. and Lung, Chung-Horng},
title = {Evaluating Sensitivity of Auto-Scaling Decisions in an Environment with Different Workload Patterns},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.27},
doi = {10.1109/COMPSAC.2015.27},
abstract = {Cost-performance trade off is one of the critical challenges in cloud computing environments. Predictive auto-scaling systems mitigate this issue by scaling in/out system automatically based on performance prediction results. The goal of this research is to investigate the impact of different prediction results on the scaling actions generated by predictive auto-scaling systems. In this study, predictive auto-scaling systems are divided into Predictor and Decision-maker components, and experiments have been conducted to measure the influence of the Predictor results on the Decision-maker output. We have used Support Vector Machine (SVM) and Neural Networks (NN) as the Predictor component and the threshold-based technique as the Decision-maker component. In addition, the influence of different workload patterns on the prediction accuracy of SVM and NN has been investigated in this paper. The experiment results show that although either of the prediction algorithms (i.e., SVM and NN) is suitable for a specific workload pattern, SVM and NN predictions lead to similar scaling actions in 97.9% of time, which suggests that focus should be on the decision-maker techniques.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {415–420},
numpages = {6},
keywords = {Workload Pattern, Support Vector Machine, Sensitivity, Neural Networks, Auto-scaling},
series = {COMPSAC '15}
}

@inproceedings{10.1145/2463372.2463425,
author = {Lu, Jianfeng and Li, Bin and Jin, Yaochu},
title = {An evolution strategy assisted by an ensemble of local Gaussian process models},
year = {2013},
isbn = {9781450319638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2463372.2463425},
doi = {10.1145/2463372.2463425},
abstract = {Surrogate models used in evolutionary algorithms (EAs) aim to reduce computationally expensive objective function evaluations. However, low-quality surrogates may mislead EAs and as a result, surrogate-assisted EAs may fail to locate the global optimum. Among various machine learning models for surrogates, Gaussian Process (GP) models have shown to be effective as GP models are able to provide fitness estimation as well as a confidence level. One weakness of GP models is that the computational cost for training increases rapidly as the number of training samples increases. To reduce the computational cost for training, here we propose to adopt an ensemble of local Gaussian Process models. Different from independent local Gaussian Process models, local Gaussian Process models share the same model parameters. Then the performance of the covariance matrix adaptation evolution strategy (CMA-ES) assisted by an ensemble of local Gaussian Process models with five different sampling strategies is compared. Experiments on eight benchmark functions demonstrate that ensembles of local Gaussian Process models can provide reliable fitness prediction and uncertainty estimation. Among the compared strategies, the clustering technique using the lower confidence bound sampling strategy exhibits the best global search performance.},
booktitle = {Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation},
pages = {447–454},
numpages = {8},
keywords = {surrogate models, sampling strategy, local gaussian process models, ensembles, covariance matrix adaptation evolution strategy},
location = {Amsterdam, The Netherlands},
series = {GECCO '13}
}

@inproceedings{10.1145/3079628.3079677,
author = {Huang, Yun and Guerra-Hollstein, Julio and Barria-Pineda, Jordan and Brusilovsky, Peter},
title = {Learner Modeling for Integration Skills},
year = {2017},
isbn = {9781450346351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3079628.3079677},
doi = {10.1145/3079628.3079677},
abstract = {Complex skill mastery requires not only acquiring individual basic component skills, but also practicing integrating such basic skills. However, traditional approaches to knowledge modeling, such as Bayesian knowledge tracing, only trace knowledge of each decomposed basic component skill. This risks early assertion of mastery or ineffective remediation failing to address skill integration. We introduce a novel integration-level approach to model learners' knowledge and provide fine-grained diagnosis: a Bayesian network based on a new kind of knowledge graph with progressive integration skills. We assess the value of such a model from multifaceted aspects: performance prediction, parameter plausibility, expected instructional effectiveness, and real-world recommendation helpfulness. Our experiments based on a Java programming tutor show that proposed model significantly improves two popular multiple-skill knowledge tracing models on all these four aspects.},
booktitle = {Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization},
pages = {85–93},
numpages = {9},
keywords = {skill integration, programming patterns, learner modeling, knowledge tracing, bayesian network},
location = {Bratislava, Slovakia},
series = {UMAP '17}
}

@article{10.1007/s10664-020-09912-w,
author = {Damasceno, Carlos Diego Nascimento and Mousavi, Mohammad Reza and Simao, Adenilso da Silva},
title = {Learning by sampling: learning behavioral family models from software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09912-w},
doi = {10.1007/s10664-020-09912-w},
abstract = {Family-based behavioral analysis operates on a single specification artifact, referred to as family model, annotated with feature constraints to express behavioral variability in terms of conditional states and transitions. Family-based behavioral modeling paves the way for efficient model-based analysis of software product lines. Family-based behavioral model learning incorporates feature model analysis and model learning principles to efficiently unify product models into a family model and integrate the behavior of various products into a behavioral family model. Albeit reasonably effective, the exhaustive analysis of product lines is often infeasible due to the potentially exponential number of valid configurations. In this paper, we first present a family-based behavioral model learning techniques, called FFSMDiff. Subsequently, we report on our experience on learning family models by employing product sampling. Using 105 products of six product lines expressed in terms of Mealy machines, we evaluate the precision of family models learned from products selected from different settings of the T-wise product sampling criterion. We show that product sampling can lead to models as precise as those learned by exhaustive analysis and hence, reduce the costs for family model learning.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {46},
keywords = {T-wise sampling, Family model, Model learning, Software product lines}
}

@inproceedings{10.1145/3303772.3303795,
author = {Ding, Mucong and Yang, Kai and Yeung, Dit-Yan and Pong, Ting-Chuen},
title = {Effective Feature Learning with Unsupervised Learning for Improving the Predictive Models in Massive Open Online Courses},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303795},
doi = {10.1145/3303772.3303795},
abstract = {The effectiveness of learning in massive open online courses (MOOCs) can be significantly enhanced by introducing personalized intervention schemes which rely on building predictive models of student learning behaviors such as some engagement or performance indicators. A major challenge that has to be addressed when building such models is to design handcrafted features that are effective for the prediction task at hand. In this paper, we make the first attempt to solve the feature learning problem by taking the unsupervised learning approach to learn a compact representation of the raw features with a large degree of redundancy. Specifically, in order to capture the underlying learning patterns in the content domain and the temporal nature of the clickstream data, we train a modified auto-encoder (AE) combined with the long short-term memory (LSTM) network to obtain a fixed-length embedding for each input sequence. When compared with the original features, the new features that correspond to the embedding obtained by the modified LSTM-AE are not only more parsimonious but also more discriminative for our prediction task. Using simple supervised learning models, the learned features can improve the prediction accuracy by up to 17% compared with the supervised neural networks and reduce overfitting to the dominant low-performing group of students, specifically in the task of predicting students' performance. Our approach is generic in the sense that it is not restricted to a specific supervised learning model nor a specific prediction task for MOOC learning analytics.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {135–144},
numpages = {10},
keywords = {Unsupervised Learning, Long Short-Term Memory, Learning Behavior, Feature Learning, Dimensionality Reduction, Autoencoder},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@article{10.1016/j.asoc.2019.02.030,
author = {Deng, Jifei and Sun, Jie and Peng, Wen and Hu, Yaohui and Zhang, Dianhua},
title = {Application of neural networks for predicting hot-rolled strip crown},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {78},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.02.030},
doi = {10.1016/j.asoc.2019.02.030},
journal = {Appl. Soft Comput.},
month = may,
pages = {119–131},
numpages = {13},
keywords = {Non-dominated sorting genetic algorithm II (NSGA II), Deep neural network (DNN), Artificial neural network (ANN), Strip crown, Hot-rolled strip}
}

@phdthesis{10.5555/AAI28263687,
author = {Wang, Bo and Lin, Yingzi and Zhang, Qiong},
advisor = {Wei, Xie,},
title = {Simulation and Artificial Intelligent Methodologies for End-to-End Bio-Pharmaceutical Manufacturing and Supply Chain Risk Management},
year = {2020},
isbn = {9798557042765},
publisher = {Northeastern University},
address = {USA},
abstract = {Driven by the critical challenges in the bio-pharmaceutical industry, including complexity, high variability, and lengthy lead time, we create new simulation and artificial intelligent methodologies to improve the end-to-end bioprocess understanding, guide the decision making, facilitate the development of modular, flexible, intensified, reliable and automated biomanufacturing supply chain. First, we construct a stochastic simulation for biomanufacturing process to control the key sources of uncertainty leading to batch-to-batch production variation. It incorporates the physical chemical interactions and dynamics. This simulation model can be used to guide biomanufacturing risk management and coherent operational decision making. Second, to ensure the drug safety, delivery reliability, transparency, responsiveness, and data integrity, we introduce a blockchain enabled interoperability framework with reputation-based Proof-of-Authority smart contract and state sharding, which can efficiently utilize the supply chain surveillance resources and simultaneously process the jobs from different areas. Then, a simulation-based platform is developed for the biopharmaceutical supply chain risk management. Third, to ensure the digital twin faithfully represents the real biopharmaceutical systems; and balance computational time and calibration accuracy, we develop a new Bayesian sequential design of experiments for simulation calibration. It can simultaneously support the real-time digital twin calibration and guide the optimal decision making. Fourth, we propose a quantile estimator by pooling detailed simulation trajectories from parallel computing, that can efficiently use the computational resources and accurately assess the risk behaviors. Then, we introduce a distributional metamodel which can model a sequence of percentile surfaces and improve the system risk performance prediction accuracy and efficiency. Further, we introduce a new probabilistic knowledge graph characterizing the end-to-end bioprocess spatial-temporal causal interdependencies. Systematic risk and sensitivity analyses are proposed to quickly identify and remove the bottlenecks, guide the process specifications and risk control, and accelerate quality-by-design. Fifth, to support the biomanufacturing automation, we introduce a bioprocess model-based reinforcement learning accounting for model risk, which can simultaneously support bioprocess online learning and guide the customized stopping policy for multi-phase fermentation process. By conducting structural and sensitivity analyses and comprehensive empirical study, we investigate the impact of model risk on the optimal policy and provide insightful guidance on fermentation process control.},
note = {AAI28263687}
}

@article{10.1007/s10664-021-09947-7,
author = {Vescan, Andreea and Pintea, Adrian and Linsbauer, Lukas and Egyed, Alexander},
title = {Genetic programming for feature model synthesis: a replication study},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09947-7},
doi = {10.1007/s10664-021-09947-7},
abstract = {Software Product Lines (SPLs) make it possible to configure a single system based on features in order to create many different variants and cater to a wide range of customers with varying requirements. This configuration space is often modeled using Feature Models (FMs). However, in practice, the SPL (and consequently the FM) is often created after a set of variants has already been created manually. Automating the task of reverse engineering a feature model that describes a set of variants makes the process of adopting an SPL easier. The genetic programming pipeline is a good fit for feature models and has been shown to produce good reverse engineering results. In this paper, we replicate the results of such an existing approach with a larger set of feature models and investigate the effects of various genetic programming parameters and operators on the results. The design of our replication experiments employs three perspectives: duplicate the exact conditions using various features models, study the interaction of two parameters of the genetic programming approach, and optimize the values for the population and generation parameters and for the mutation and crossover operators. Results reinforce the previously obtained outcome, the original study being confirmed. The relations between the number of features and number of generations, respectively number of features and size of populations were also investigated and best values based on obtained results are provided. The current study also aimed to optimize various parameters of the genetic programming approach, the interpretation of those experiments discovering concrete values.},
journal = {Empirical Softw. Engg.},
month = jul,
numpages = {29},
keywords = {Software product lines, Reverse engineering, Replication study, Feature models}
}

@article{10.1016/j.jpdc.2014.09.005,
author = {You, Yang and Fu, Haohuan and Song, Shuaiwen Leon and Randles, Amanda and Kerbyson, Darren and Marquez, Andres and Yang, Guangwen and Hoisie, Adolfy},
title = {Scaling Support Vector Machines on modern HPC platforms},
year = {2015},
issue_date = {February 2015},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2014.09.005},
doi = {10.1016/j.jpdc.2014.09.005},
abstract = {Support Vector Machines (SVM) have been widely used in data-mining and Big Data applications as modern commercial databases start to attach an increasing importance to the analytic capabilities. In recent years, SVM was adapted to the field of High Performance Computing for power/performance prediction, auto-tuning, and runtime scheduling. However, even at the risk of losing prediction accuracy due to insufficient runtime information, researchers can only afford to apply offline model training to avoid significant runtime training overhead. Advanced multi- and many-core architectures offer massive parallelism with complex memory hierarchies which can make runtime training possible, but form a barrier to efficient parallel SVM design.To address the challenges above, we designed and implemented MIC-SVM, a highly efficient parallel SVM for x86 based multi-core and many-core architectures, such as the Intel Ivy Bridge CPUs and Intel Xeon Phi co-processor (MIC). We propose various novel analysis methods and optimization techniques to fully utilize the multilevel parallelism provided by these architectures and serve as general optimization methods for other machine learning tools.MIC-SVM achieves 4.4-84\'{\i} and 18-47\'{\i} speedups against the popular LIBSVM, on MIC and Ivy Bridge CPUs respectively, for several real-world data-mining datasets. Even compared with GPUSVM, running on the NVIDIA k20x GPU, the performance of our MIC-SVM is competitive. We also conduct a cross-platform performance comparison analysis, focusing on Ivy Bridge CPUs, MIC and GPUs, and provide insights on how to select the most suitable advanced architectures for specific algorithms and input data patterns. An efficient parallel support vector machine for x86 based multi-core platforms.The novel optimization techniques to fully utilize the multi-level parallelism.The improvement for the deficiencies of the current SVM tools.Select the best architectures for input data patterns to achieve best performance.The large-scale distributed algorithm and power-efficient approach.},
journal = {J. Parallel Distrib. Comput.},
month = feb,
pages = {16–31},
numpages = {16},
keywords = {Support Vector Machine, Performance analysis, Optimization techniques, Multi- &amp; many-core architectures, Machine learning models, Dynamic modeling}
}

@article{10.1016/j.future.2017.09.049,
author = {Rahmanian, Ali Asghar and Ghobaei-Arani, Mostafa and Tofighy, Sajjad},
title = {A learning automata-based ensemble resource usage prediction algorithm for cloud computing environment},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {79},
number = {P1},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2017.09.049},
doi = {10.1016/j.future.2017.09.049},
abstract = {Infrastructure as a service (IaaS) providers are interested in increasing their profit by gathering more and more customers besides providing more efficiency in cloud resource usage. There are several approaches to reach the resource usage efficiency goal such as dynamic consolidation of virtual machines (VMs). Resource management techniques such as VM consolidation must be aware of the current and future resource usage of the cloud resources. Hence, applying prediction models for current cloud resource management is a must. While cloud resource usage varies widely time to time and server to server, determining the best time-series model for predicting cloud resource usage depend not only on time but the cloud resource usage trend. Thus, applying ensemble prediction algorithms that combine several prediction models can be suitable to reach the mentioned goal. In this paper, an ensemble cloud resource usage prediction algorithm based on Learning Automata (LA) theory is proposed that combines state of the art prediction models, and it determines weights for individual constituent models. The proposed algorithm predicts by combining the prediction values of all constituent models based on their performance. The extensive experiments on CPU load prediction of several VMs gathered from the dataset of the CoMon project indicated that the proposed approach outperforms other ensemble prediction algorithms. We proposed a LA-based ensemble resource usage prediction algorithm for cloud computing environment.We designed a framework for cloud resource management.We conducted a series of experiments in terms of prediction accuracy metrics.},
journal = {Future Gener. Comput. Syst.},
month = feb,
pages = {54–71},
numpages = {18},
keywords = {Virtual machine, Prediction, Learning automata, Ensemble algorithm, Cloud computing environment}
}

@inproceedings{10.1145/1370018.1370028,
author = {Peper, Christian and Schneider, Daniel},
title = {Component engineering for adaptive ad-hoc systems},
year = {2008},
isbn = {9781605580371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370018.1370028},
doi = {10.1145/1370018.1370028},
abstract = {Dynamic computing systems with small, distributed, and communicating embedded devices, as they are expected for the future, must be able to manage appearance and loss of devices and resources. For the development of static systems, component-oriented engineering approaches have been shown to foster well-structured, configurable systems. Frameworks for the dynamic integration of such components often rely on a centralized component integration platform, containing service brokers and similar. This paper describes several aspects of a component-oriented approach for the development of dynamic-adaptive systems that distributes all needed infrastructure among the participating embedded devices. This results in a runtime framework working whenever two components come together and form an ad-hoc system.},
booktitle = {Proceedings of the 2008 International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
pages = {49–56},
numpages = {8},
keywords = {ubiquitous computing, embedded systems, distributed systems, ambient intelligence, adaptivity, ad-hoc systems},
location = {Leipzig, Germany},
series = {SEAMS '08}
}

@inproceedings{10.1145/1722024.1722064,
author = {Mallika, V. and Sivakumar, K. C. and Soniya, E. V.},
title = {A novel system for predicting plant protein kinase superfamily by using machine learning methodology},
year = {2010},
isbn = {9781605587226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1722024.1722064},
doi = {10.1145/1722024.1722064},
abstract = {Protein kinases, one of the largest superfamily of proteins which involved in almost every cellular processes. In plants, due to their important roles in cellular communication, growth and development more researches are going on in this particular protein. Developing a tool to identify the probability of the sequence being a plant protein kinase will simplify the efforts and accelerate the experimental characterization. In this approach, a high performance prediction server 'PhytokinaseSVM' has been developed and implemented which is available at http://type3pks.in/kinase. Support vector machine, a kernel based supervised learning technology and compositional properties including dipeptide and multiplet frequency were used in the developmental procedure. Based on the limited available data, the tool provides a simple unique platform to identify the probability of a particular sequence, being a plant protein kinase or not with moderately high accuracy (98%). PhytokinaseSVM achieved 96% specificity and 100% sensitivity when tested with 500 protein kinases and 500 non-protein kinases that were not the part of the training dataset. We expect that this tool may serve as a useful resource for plant protein kinase researchers as it is freely available. The tool also allows the prediction of other eukaryotic protein kinases. Currently work is being progressed for further betterment of prediction accuracy by including more sequence features in the training dataset.},
booktitle = {Proceedings of the International Symposium on Biocomputing},
articleno = {34},
numpages = {4},
keywords = {support vector machine, protein kinase, phytokinase, machine learning, kernel methods, data mining, SVMs},
location = {Calicut, Kerala, India},
series = {ISB '10}
}

@inproceedings{10.1109/ASE.2019.00065,
author = {M\"{u}hlbauer, Stefan and Apel, Sven and Siegmund, Norbert},
title = {Accurate modeling of performance histories for evolving software systems},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00065},
doi = {10.1109/ASE.2019.00065},
abstract = {Learning from the history of a software system's performance behavior does not only help discovering and locating performance bugs, but also identifying evolutionary performance patterns and general trends, such as when technical debt accumulates. Exhaustive regression testing is usually impractical, because rigorous performance benchmarking requires executing a realistic workload per revision, which results in large execution times. In this paper, we propose a novel active revision sampling approach, which aims at tracking and understanding a system's performance history by approximating the performance behavior of a software system across all of its revisions. In a nutshell, we iteratively sample and measure the performance of specific revisions that help us building an exact performance-evolution model, and we use Gaussian Process models to assess in which revision ranges our model is most uncertain with the goal to sample further revisions for measurement. We have conducted an empirical analysis of the evolutionary performance behavior modeled as a time series of the histories of six real-world software systems. Our evaluation demonstrates that Gaussian Process models are able to accurately estimate the performance-evolution history of real-world software systems with only few measurements and to reveal interesting behaviors and trends.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {640–652},
numpages = {13},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3278122.3278130,
author = {Ruland, Sebastian and Luthmann, Lars and B\"{u}rdek, Johannes and Lity, Sascha and Th\"{u}m, Thomas and Lochau, Malte and Ribeiro, M\'{a}rcio},
title = {Measuring effectiveness of sample-based product-line testing},
year = {2018},
isbn = {9781450360456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278122.3278130},
doi = {10.1145/3278122.3278130},
abstract = {Recent research on quality assurance (QA) of configurable software systems (e.g., software product lines) proposes different analysis strategies to cope with the inherent complexity caused by the well-known combinatorial-explosion problem. Those strategies aim at improving efficiency of QA techniques like software testing as compared to brute-force configuration-by-configuration analysis. Sampling constitutes one of the most established strategies, defining criteria for selecting a drastically reduced, yet sufficiently diverse subset of software configurations considered during QA. However, finding generally accepted measures for assessing the impact of sample-based analysis on the effectiveness of QA techniques is still an open issue. We address this problem by lifting concepts from single-software mutation testing to configurable software. Our framework incorporates a rich collection of mutation operators for product lines implemented in C to measure mutation scores of samples, including a novel family-based technique for product-line mutation detection. Our experimental results gained from applying our tool implementation to a collection of subject systems confirms the widely-accepted assumption that pairwise sampling constitutes the most reasonable efficiency/effectiveness trade-off for sample-based product-line testing.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {119–133},
numpages = {15},
keywords = {Software Product Lines, Sample-Based Testing, Mutation Testing},
location = {Boston, MA, USA},
series = {GPCE 2018}
}

@inbook{10.5555/2167981.2167999,
author = {Snook, Colin and Poppleton, Michael and Johnson, Ian},
title = {Towards a method for rigorous development of generic requirements patterns},
year = {2006},
isbn = {3540482652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We present work in progress on a method for the engineering, validation and verification of generic requirements using domain engineering and formal methods. The need to develop a generic requirement set for subsequent system instantiation is complicated by the addition of the high levels of verification demanded by safety-critical domains such as avionics. Our chosen application domain is the failure detection and management function for engine control systems: here generic requirements drive a software product line of target systems.A pilot formal specification and design exercise is undertaken on a small (two-sensor) system element. This exercise has a number of aims: to support the domain analysis, to gain a view of appropriate design abstractions, for a B novice to gain experience in the B method and tools, and to evaluate the usability and utility of that method. We also present a prototype method for the production and verification of a generic requirement set in our UML-based formal notation, UML-B, and tooling developed in support. The formal verification both of the structural generic requirement set, and of a particular application, is achieved via translation to the formal specification language, B, using our U2B and ProB tools.},
booktitle = {Rigorous Development of Complex Fault-Tolerant Systems},
pages = {326–342},
numpages = {17}
}

@inproceedings{10.1145/2591062.2591196,
author = {Tarvo, Alexander},
title = {Automatic performance modeling of multithreaded programs},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591196},
doi = {10.1145/2591062.2591196},
abstract = {Multithreaded programs express a complex non-linear dependency between their configuration and the performance. To better understand this dependency performance prediction models are used. However, building performance models manually is time-consuming and error-prone. We present a novel methodology for automatically building performance models of industrial multithreaded programs.},
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {721–723},
numpages = {3},
keywords = {program analysis, model, Performance},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/3050748.3050753,
author = {Zhang, Jinshi and Dong, Eddie and Li, Jian and Guan, Haibing},
title = {MigVisor: Accurate Prediction of VM Live Migration Behavior using a Working-Set Pattern Model},
year = {2017},
isbn = {9781450349482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3050748.3050753},
doi = {10.1145/3050748.3050753},
abstract = {Live migration of a virtual machine (VM) is a powerful technique with benefits of server maintenance, resource management, dynamic workload re-balance, etc. Modern research has effectively reduced the VM live migration (VMLM) time to dozens of milliseconds, but live migration still exhibits failures if it cannot terminate within the given time constraint. The ability to predict this type of failure can avoid wasting networking and computing resources on the VM migration, and the associated system performance degradation caused by wasting these resources. The cost of VM live migration highly depends on the application workload of the VM, which may undergo frequent changes. At the same time, the available system resources for VM migration can also change substantially and frequently. To account for these issues, we present a solution called MigVisor, which can accurately predict the behaviour of VM migration using working-set model. This can enable system managers to predict the migration cost and enhance the system management efficacy. The experimental results prove the design suitability and show that the MigVisor has a high prediction accuracy since the average relative error between the predicted value and the measured value is only 6.2%~9%.},
booktitle = {Proceedings of the 13th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {30–43},
numpages = {14},
keywords = {virtual machine, prediction, live migration},
location = {Xi'an, China},
series = {VEE '17}
}

@article{10.4018/jertcs.2011040102,
author = {Streitferdt, Detlef and Kantz, Florian and Nenninger, Philipp and Ruschival, Thomas and Kaul, Holger and Bauer, Thomas and Hussain, Tanvir and Eschbach, Robert},
title = {Model-Based Testing of Highly Configurable Embedded Systems in the Automation Domain},
year = {2011},
issue_date = {April 2011},
publisher = {IGI Global},
address = {USA},
volume = {2},
number = {2},
issn = {1947-3176},
url = {https://doi.org/10.4018/jertcs.2011040102},
doi = {10.4018/jertcs.2011040102},
abstract = {This article reports the results of an industrial case study demonstrating the efficacy of a model-based testing process in assuring the quality of highly configurable systems from the automation domain. Escalating demand for flexibility has made modern embedded software systems highly configurable. This configurability is often realized through parameters and a highly configurable system possesses a handful of those. Small changes in parameter values can account for significant changes in the system's behavior, whereas in other cases, changed parameters may not result in any perceivable reaction. This case study addresses the challenge of applying model-based testing to configurable embedded software systems to reduce development effort. As a result of the case study, a model-based testing process was developed and tailored toward the needs of the automation domain. This process integrates existing model-based testing methods and tools, such as combinatorial design and constraint processing. The testing process was applied as part of the case study and analyzed in terms of its actual saving potentials, which reduced the testing effort by more than a third.},
journal = {Int. J. Embed. Real-Time Commun. Syst.},
month = apr,
pages = {22–41},
numpages = {20},
keywords = {Statistical Testing, Softstarter, Model-Based Testing, Configuration Parameter, Automation Domain}
}

@inproceedings{10.1109/ASE.2011.6100073,
author = {Rathfelder, Christoph and Kounev, Samuel and Evans, David},
title = {Capacity planning for event-based systems using automated performance predictions},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100073},
doi = {10.1109/ASE.2011.6100073},
abstract = {Event-based communication is used in different domains including telecommunications, transportation, and business information systems to build scalable distributed systems. The loose coupling of components in such systems makes it easy to vary the deployment. At the same time, the complexity to estimate the behavior and performance of the whole system is increased, which complicates capacity planning. In this paper, we present an automated performance prediction method supporting capacity planning for event-based systems. The performance prediction is based on an extended version of the Palladio Component Model - a performance meta-model for component-based systems. We apply this method on a real-world case study of a traffic monitoring system. In addition to the application of our performance prediction techniques for capacity planning, we evaluate the prediction results against measurements in the context of the case study. The results demonstrate the practicality and effectiveness of the proposed approach.},
booktitle = {Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {352–361},
numpages = {10},
series = {ASE '11}
}

@inproceedings{10.1145/2304736.2304740,
author = {Brosig, Fabian and Huber, Nikolaus and Kounev, Samuel},
title = {Modeling parameter and context dependencies in online architecture-level performance models},
year = {2012},
isbn = {9781450313452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304736.2304740},
doi = {10.1145/2304736.2304740},
abstract = {Modern service-oriented enterprise systems have increasingly complex and dynamic loosely-coupled architectures that often exhibit poor performance and resource efficiency and have high operating costs. This is due to the inability to predict at run-time the effect of dynamic changes in the system environment and adapt the system configuration accordingly. Architecture-level performance models provide a powerful tool for performance prediction, however, current approaches to modeling the execution context of software components are not suitable for use at run-time. In this paper, we analyze the typical online performance prediction scenarios and propose a novel performance meta-model for expressing and resolving parameter and context dependencies, specifically designed for use in online scenarios. We motivate and validate our approach in the context of a realistic and representative online performance prediction scenario based on the SPECjEnterprise2010 standard benchmark.},
booktitle = {Proceedings of the 15th ACM SIGSOFT Symposium on Component Based Software Engineering},
pages = {3–12},
numpages = {10},
keywords = {parameter dependencies, architecture-level performance model},
location = {Bertinoro, Italy},
series = {CBSE '12}
}

@article{10.1145/3284971.3284975,
author = {Lazreg, Sami and Collet, Philippe and Mosser, S\'{e}bastien},
title = {Functional feasibility analysis of variability-intensive data flow-oriented applications over highly-configurable platforms},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1559-6915},
url = {https://doi.org/10.1145/3284971.3284975},
doi = {10.1145/3284971.3284975},
abstract = {Data-flow oriented embedded systems, such as automotive systems used to render HMI (e.g., instrument clusters, infotainments), are increasingly built from highly variable specifications while targeting different constrained hardware platforms configurable in a fine-grained way. These variabilities at two different levels lead to a huge number of possible embedded system solutions, which functional feasibility is extremely complex and tedious to predetermine. In this paper, we propose a tooled approach that capture high level specifications as variable dataflows, and targeted platforms as variable component models. Dataflows can then be mapped onto platforms to express a specification of such variability-intensive systems. The proposed solution transforms this specification into structural and behavioral variability models and reuses automated reasoning techniques to explore and assess the functional feasibility of all variants in a single run. We also report on the validation of the proposed approach. A qualitative evaluation has been conducted on an industrial case study of automotive instrument cluster, while a quantitative one is reported on large generated datasets.},
journal = {SIGAPP Appl. Comput. Rev.},
month = oct,
pages = {32–48},
numpages = {17},
keywords = {variability modeling, feature model, embedded system design engineering, behavioral product lines model checking}
}

@phdthesis{10.5555/2604417,
author = {Pallipuram Krishnamani, Venkittaraman Vivek},
advisor = {Smith, Melissa C.},
title = {Exploring multiple levels of performance modeling for heterogeneous systems},
year = {2013},
isbn = {9781303691577},
publisher = {Clemson University},
address = {USA},
abstract = {The current trend in High-Performance Computing (HPC) is to extract concurrency from clusters that include heterogeneous resources such as General Purpose Graphical Processing Units (GPGPUs) and Field Programmable Gate Array (FPGAs). Although these heterogeneous systems can provide substantial performance for massively parallel applications, much of the available computing resources are often under-utilized due to inefficient application mapping, load balancing, and tuning. While several performance prediction models exist to efficiently tune applications, they often require significant computing architecture knowledge for reliable prediction. In addition, they do not address multiple levels of design space abstraction and it is often difficult to choose a reliable prediction model for a given design.  In this research, we develop a multi-level suite of performance prediction models for heterogeneous systems that primarily targets Synchronous Iterative Algorithms (SIAs). The modeling suite aims to produce accurate and straightforward application runtime prediction prior to the actual large-scale implementation. This suite addresses two levels of system abstraction: 1) low-level where partial knowledge of the application implementation is present along with the system specifications and 2) high-level where the implementation details are minimum and only high-level computing system specifications are given. The performance prediction modeling suite is developed using our proposed Synchronous Iterative GPGPU Execution (SIGE) model for GPGPU clusters, motivated by the RC Amenability Test for Scalable Systems (RATSS) model for FPGA clusters.   The low-level abstraction for GPGPU clusters consists of a regression-based performance prediction framework that statistically abstracts system architecture characteristics, enabling performance prediction without detailed architecture knowledge. In this framework, the overall execution time of an application is predicted using regression models developed for host-device computations and network-level communications performed in the algorithm. We have used a family of Spiking Neural Network (SNN) models and an Anisotropic Diffusion Filter (ADF) algorithm as SIA case studies for verification of the regression-based framework and achieved over 90% prediction accuracy compared to the actual implementations for several GPGPU cluster configurations tested. The results establish the adequacy of the low-level abstraction model for advanced, fine-grained performance prediction and design space exploration (DSE). The high-level abstraction consists of the following two primary modeling approaches: qualitative modeling that uses existing subjective-analytical models for computation and communication; and quantitative modeling that predicts computation and communication performance by measuring hardware events associated with objective-analytical models using micro-benchmarks. The performance prediction provided by the high-level abstraction approaches, albeit coarse-grained, delivers useful insight into application performance on the chosen heterogeneous system. A blend of the two high-level modeling approaches, labeled as hybrid modeling, is explored for insightful preliminary performance prediction.  The performance prediction models in the multi-level suite are verified and compared for their accuracy and ease-of-use, allowing developers to choose a model that best satisfies their design space abstraction. We also construct a roadmap that guides user from optimal Application-to-Accelerator (A2A) mapping to fine-grained performance prediction, thereby providing a hierarchical approach to optimal application porting on the target heterogeneous system. The end goal of this dissertation research is to offer the HPC community a thorough, non-architecture specific, performance prediction framework in the form of a hierarchical modeling suite that enables them to optimally utilize the heterogeneous resources.},
note = {AAI3609787}
}

@inproceedings{10.5555/1759868.1759882,
author = {Chou, Chau-Yi and Chang, Hsi-Ya and Wang, Shuen-Tai and Huang, Kuo-Chan and Shen, Cherng-Yeu},
title = {An improved model for predicting HPL performance},
year = {2007},
isbn = {9783540723592},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we propose an improved model for predicting HPL (High performance Linpack) performance. In order to accurately predict the maximal LINPACK performance we first divide the performance model into two parts: computational cost and message passing overhead. In the message passing overhead, we adopt Xu and Hwang's broadcast model instead of the point-to-point message passing model. HPL performance prediction is a multi-variables problem. In this proposed model we improved the existing model by introducing a weighting function to account for many effects such that the proposed model could more accurately predict the maximal LINPACK performance Rmax. This improvement in prediction accuracy has been verified on a variety of architectures, including IA64 and IA32 CPUs in a Myrinet-based environment, as well as in Quadrics, Gigabits Ethernet and other network environments. Our improved model can help cluster users in estimating the maximal HPL performance of their systems.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Grid and Pervasive Computing},
pages = {158–168},
numpages = {11},
location = {Paris, France},
series = {GPC'07}
}

@article{10.1016/j.elerap.2020.100943,
author = {Sarkar, Joy Lal and Majumder, Abhishek and Panigrahi, Chhabi Rani and Roy, Sudipta},
title = {MULTITOUR: A multiple itinerary tourists recommendation engine},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1567-4223},
url = {https://doi.org/10.1016/j.elerap.2020.100943},
doi = {10.1016/j.elerap.2020.100943},
journal = {Electron. Commer. Rec. Appl.},
month = mar,
numpages = {20},
keywords = {Point-of-interest, Itineraries, Cost, Tourist, Tour recommendation}
}

@inproceedings{10.1145/2487575.2487647,
author = {Zhao, Peilin and Hoi, Steven C.H.},
title = {Cost-sensitive online active learning with application to malicious URL detection},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487647},
doi = {10.1145/2487575.2487647},
abstract = {Malicious Uniform Resource Locator (URL) detection is an important problem in web search and mining, which plays a critical role in internet security. In literature, many existing studies have attempted to formulate the problem as a regular supervised binary classification task, which typically aims to optimize the prediction accuracy. However, in a real-world malicious URL detection task, the ratio between the number of malicious URLs and legitimate URLs is highly imbalanced, making it very inappropriate for simply optimizing the prediction accuracy. Besides, another key limitation of the existing work is to assume a large amount of training data is available, which is impractical as the human labeling cost could be potentially quite expensive. To solve these issues, in this paper, we present a novel framework of Cost-Sensitive Online Active Learning (CSOAL), which only queries a small fraction of training data for labeling and directly optimizes two cost-sensitive measures to address the class-imbalance issue. In particular, we propose two CSOAL algorithms and analyze their theoretical performance in terms of cost-sensitive bounds. We conduct an extensive set of experiments to examine the empirical performance of the proposed algorithms for a large-scale challenging malicious URL detection task, in which the encouraging results showed that the proposed technique by querying an extremely small-sized labeled data (about 0.5% out of 1-million instances) can achieve better or highly comparable classification performance in comparison to the state-of-the-art cost-insensitive and cost-sensitive online classification algorithms using a huge amount of labeled data.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {919–927},
numpages = {9},
keywords = {online learning, malicious url detection, cost-sensitive learning, active learning},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@article{10.1007/s10291-018-0729-7,
author = {Li, Yafeng and Wang, Meiling and Shivaramaiah, Nagaraj C.},
title = {Design and analysis of a generalized DLL/FLL discriminator for GPS receivers},
year = {2018},
issue_date = {July      2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {3},
issn = {1080-5370},
url = {https://doi.org/10.1007/s10291-018-0729-7},
doi = {10.1007/s10291-018-0729-7},
abstract = {High-performance discriminators are of a significant interest in GPS receiver tracking-loop design. Main lobes of both the auto-correlation function of the band-limited pseudorandom noise code and the sinc function resulting from the carrier frequency tracking, resemble the shape of an inverted parabola. This interesting observation led to the proposal of a generalized DLL/FLL discriminator based on parabola fitting, which is the topic of this research. To provide better insight into the mechanism of this discriminator, a semi-analytical noise performance prediction method is presented based on the Gauss---Hermite cubature transformation, and simple loss functions are defined to comprehensively measure the S-curve-related performances. On this basis, design parameter optimization for the generalized DLL/FLL discriminator is addressed by trade-off analysis. Controlled experiments with real and simulated signals show that the overall performance of the generalized discriminator is significantly better than the commonly used DLL and FLL discriminators and is more suitable for use in applications that need to handle weak signal, high dynamics and/or large offsets in frequency and code phase estimation during the acquisition to tracking transition.},
journal = {GPS Solut.},
month = jul,
pages = {1–17},
numpages = {17},
keywords = {Tracking loop, Pull-in range, GPS, FLL, Discriminator, DLL}
}

@inproceedings{10.1145/1835698.1835741,
author = {Tan, Yongmin and Gu, Xiaohui and Wang, Haixun},
title = {Adaptive system anomaly prediction for large-scale hosting infrastructures},
year = {2010},
isbn = {9781605588889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835698.1835741},
doi = {10.1145/1835698.1835741},
abstract = {Large-scale hosting infrastructures require automatic system anomaly management to achieve continuous system operation. In this paper, we present a novel adaptive runtime anomaly prediction system, called ALERT, to achieve robust hosting infrastructures. In contrast to traditional anomaly detection schemes, ALERT aims at raising advance anomaly alerts to achieve just-in-time anomaly prevention. We propose a novel context-aware anomaly prediction scheme to improve prediction accuracy in dynamic hosting infrastructures. We have implemented the ALERT system and deployed it on several production hosting infrastructures such as IBM System S stream processing cluster and PlanetLab. Our experiments show that ALERT can achieve high prediction accuracy for a range of system anomalies and impose low overhead to the hosting infrastructure.},
booktitle = {Proceedings of the 29th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing},
pages = {173–182},
numpages = {10},
keywords = {context-aware prediction model, anomaly prediction},
location = {Zurich, Switzerland},
series = {PODC '10}
}

@inproceedings{10.5555/2468184.2468219,
author = {Klambauer, Thomas and Holl, Gerald and Gr\"{u}nbacher, Paul},
title = {Monitoring system-of-systems requirements in multi product lines},
year = {2013},
isbn = {9783642374210},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {[Context and motivation] Large-scale software-intensive systems are often considered as systems of systems comprising several interrelated product lines from which system variants are derived to meet the overall requirements. [Question/problem] If multiple teams and experts configure these individual systems, their individual configuration choices might conflict with the system-of-systems requirements. [Principal ideas/results] This research preview paper presents our ongoing work on a tool-supported approach for monitoring system-of-systems requirements formalized as constraints during distributed product derivation in multi product lines. [Contribution] The approach allows detecting violations of multi system requirements during the configuration of individual systems and provides immediate feedback to the involved configurers. Our approach is integrated in the product configuration tool DOPLER developed in cooperation with an industrial partner.},
booktitle = {Proceedings of the 19th International Conference on Requirements Engineering: Foundation for Software Quality},
pages = {379–385},
numpages = {7},
location = {Essen, Germany},
series = {REFSQ'13}
}

@inproceedings{10.1145/3337821.3337873,
author = {Zheng, Haoyue and Xu, Fei and Chen, Li and Zhou, Zhi and Liu, Fangming},
title = {Cynthia: Cost-Efficient Cloud Resource Provisioning for Predictable Distributed Deep Neural Network Training},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337873},
doi = {10.1145/3337821.3337873},
abstract = {It becomes an increasingly popular trend for deep neural networks with large-scale datasets to be trained in a distributed manner in the cloud. However, widely known as resource-intensive and time-consuming, distributed deep neural network (DDNN) training suffers from unpredictable performance in the cloud, due to the intricate factors of resource bottleneck, heterogeneity and the imbalance of computation and communication which eventually cause severe resource under-utilization. In this paper, we propose Cynthia, a cost-efficient cloud resource provisioning framework to provide predictable DDNN training performance and reduce the training budget. To explicitly explore the resource bottleneck and heterogeneity, Cynthia predicts the DDNN training time by leveraging a lightweight analytical performance model based on the resource consumption of workers and parameter servers. With an accurate performance prediction, Cynthia is able to optimally provision the cost-efficient cloud instances to jointly guarantee the training performance and minimize the training budget. We implement Cynthia on top of Kubernetes by launching a 56-docker cluster to train four representative DNN models. Extensive prototype experiments on Amazon EC2 demonstrate that Cynthia can provide predictable training performance while reducing the monetary cost for DDNN workloads by up to 50.6%, in comparison to state-of-the-art resource provisioning strategies, yet with acceptable runtime overhead.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {86},
numpages = {11},
keywords = {resource heterogeneity, resource bottleneck, predictable performance, deep neural network training, cloud resource provisioning},
location = {Kyoto, Japan},
series = {ICPP '19}
}

@article{10.1007/s10791-017-9301-2,
author = {P\"{a}\"{a}kk\"{o}nen, Teemu and Kek\"{a}l\"{a}inen, Jaana and Keskustalo, Heikki and Azzopardi, Leif and Maxwell, David and J\"{a}rvelin, Kalervo},
title = {Validating simulated interaction for retrieval evaluation},
year = {2017},
issue_date = {Aug 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-017-9301-2},
doi = {10.1007/s10791-017-9301-2},
abstract = {A searcher’s interaction with a retrieval system consists of actions such as query formulation, search result list interaction and document interaction. The simulation of searcher interaction has recently gained momentum in the analysis and evaluation of interactive information retrieval (IIR). However, a key issue that has not yet been adequately addressed is the validity of such IIR simulations and whether they reliably predict the performance obtained by a searcher across the session. The aim of this paper is to determine the validity of the common interaction model (CIM) typically used for simulating multi-query sessions. We focus on search result interactions, i.e., inspecting snippets, examining documents and deciding when to stop examining the results of a single query, or when to stop the whole session. To this end, we run a series of simulations grounded by real world behavioral data to show how accurate and responsive the model is to various experimental conditions under which the data were produced.
 We then validate on a second real world data set derived under similar experimental conditions. We seek to predict cumulated gain across the session. We find that the interaction model with a query-level stopping strategy based on consecutive non-relevant snippets leads to the highest prediction accuracy, and lowest deviation from ground truth, around 9 to 15% depending on the experimental conditions. To our knowledge, the present study is the first validation effort of the CIM that shows that the model’s acceptance and use is justified within IIR evaluations. We also identify and discuss ways to further improve the CIM and its behavioral parameters for more accurate simulations.},
journal = {Inf. Retr.},
month = aug,
pages = {338–362},
numpages = {25},
keywords = {Session-based evaluation, IR interaction, Simulation}
}

@inproceedings{10.5555/3327144.3327276,
author = {Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten},
title = {Neural code comprehension: a learnable representation of code semantics},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {3589–3601},
numpages = {13},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@article{10.1016/j.infsof.2007.10.010,
author = {Snook, Colin and Poppleton, Michael and Johnson, Ian},
title = {Rigorous engineering of product-line requirements: A case study in failure management},
year = {2008},
issue_date = {January, 2008},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {50},
number = {1–2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2007.10.010},
doi = {10.1016/j.infsof.2007.10.010},
abstract = {We consider the failure detection and management function for engine control systems as an application domain where product line engineering is indicated. The need to develop a generic requirement set - for subsequent system instantiation - is complicated by the addition of the high levels of verification demanded by this safety-critical domain, subject to avionics industry standards. We present our case study experience in this area as a candidate method for the engineering, validation and verification of generic requirements using domain engineering and Formal Methods techniques and tools. For a defined class of systems, the case study produces a generic requirement set in UML and an example system instance. Domain analysis and engineering produce a validated model which is integrated with the formal specification/verification method B by the use of our UML-B profile. The formal verification both of the generic requirement set, and of a simple system instance, is demonstrated using our U2B, ProB and prototype Requirements Manager tools. This work is a demonstrator for a tool-supported method which will be an output of EU project RODIN (This work is conducted in the setting of the EU funded Research Project: IST 511599 RODIN (Rigorous Open Development Environment for Complex Systems) http://rodin.cs.ncl.ac.uk/). The use of existing and prototype formal verification and support tools is discussed. The method, developed in application to this novel combination of product line, failure management and safety-critical engineering, is evaluated and considered to be applicable to a wide range of domains.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {112–129},
numpages = {18},
keywords = {Verification, UML-B, Tools, Refinement, Product line, Generic requirements, Formal specification}
}

@inproceedings{10.1145/1712605.1712613,
author = {Kapova, Lucia and Buhnova, Babora and Martens, Anne and Happe, Jens and Reussner, Ralf},
title = {State dependence in performance evaluation of component-based software systems},
year = {2010},
isbn = {9781605585635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1712605.1712613},
doi = {10.1145/1712605.1712613},
abstract = {Integrating rising variability of software systems in performance prediction models is crucial to allow widespread industrial use of performance prediction. One of such variabilities is the dependency of system performance on the context and history-dependent internal state of the system (or its components). The questions that rise for current prediction models are (i) how to include the state properties in a prediction model, and (ii) how to balance the expressiveness and complexity of created models.Only a few performance prediction approaches deal with modelling states in component-based systems. Currently, there is neither a consensus in the definition, nor in the method to include the state in prediction models. For these reasons, we have conducted a state-of-the-art survey of existing approaches addressing their expressiveness to model stateful components. Based on the results, we introduce a classification scheme and present the state-defining and state-dependent model parameters. We extend the Palladio Component Model (PCM), a model-based performance prediction approach, with state-modelling capabilities, and study the performance impact of modelled state. A practical influences of the internal state on software performance is evaluated on a realistic case study.},
booktitle = {Proceedings of the First Joint WOSP/SIPEW International Conference on Performance Engineering},
pages = {37–48},
numpages = {12},
keywords = {state dependency, performance, design-time prediction},
location = {San Jose, California, USA},
series = {WOSP/SIPEW '10}
}

@article{10.1007/s10710-016-9265-9,
author = {Mart\'{\i}nez, Yuliana and Trujillo, Leonardo and Legrand, Pierrick and Galv\'{a}n-L\'{o}pez, Edgar},
title = {Prediction of expected performance for a genetic programming classifier},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {1389-2576},
url = {https://doi.org/10.1007/s10710-016-9265-9},
doi = {10.1007/s10710-016-9265-9},
abstract = {The estimation of problem difficulty is an open issue in genetic programming (GP). The goal of this work is to generate models that predict the expected performance of a GP-based classifier when it is applied to an unseen task. Classification problems are described using domain-specific features, some of which are proposed in this work, and these features are given as input to the predictive models.
 These models are referred to as predictors of expected performance. We extend this approach by using an ensemble of specialized predictors (SPEP), dividing classification problems into groups and choosing the corresponding SPEP. The proposed predictors are trained using 2D synthetic classification problems with balanced datasets. The models are then used to predict the performance of the GP classifier on unseen real-world datasets that are multidimensional and imbalanced. This work is the first to provide a performance prediction of a GP system on test data,
 while previous works focused on predicting training performance. Accurate predictive models are generated by posing a symbolic regression task and solving it with GP. These results are achieved by using highly descriptive features and including a dimensionality reduction stage that simplifies the learning and testing process. The proposed approach could be extended to other classification algorithms and used as the basis of an expert system for algorithm selection.},
journal = {Genetic Programming and Evolvable Machines},
month = dec,
pages = {409–449},
numpages = {41},
keywords = {Supervised learning, Problem difficulty, Prediction of expected performance, Genetic programming}
}

@article{10.1016/j.neucom.2016.08.093,
author = {Liu, Jie and Zio, Enrico},
title = {Feature vector regression with efficient hyperparameters tuning and geometric interpretation},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {218},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2016.08.093},
doi = {10.1016/j.neucom.2016.08.093},
abstract = {Machine learning methods employing positive kernels have been developed and widely used for classification, regression, prediction and unsupervised learning applications, whereby the estimate function takes the form of a weighted-sum kernel expansion. Unacceptable computational burden with large datasets and difficulty in tuning hyperparameters are usually the drawbacks of kernel methods. In order to reduce the computational burden, this paper presents a modified version of the Feature Vector Selection (FVS) method, proposing an approximation of the estimate function as a weighted sum of the predicted values of the Feature Vectors (FVs), where the weights are computed as the oblique projections of the new data points on the FVs in the feature space. Such approximation is, then, obtained by optimizing only the predicted values of the FVs. By defining a least square error optimization problem with equal constraints, analytic solutions of the predicted values of the FVs can be obtained. The proposed method is named Feature Vector Regression (FVR). The tuning of hyperparameters in FVR is also explained in the paper and shown to be less complicated than for other kernel methods. Comparisons with some other popular kernel methods for regression on several public datasets show that FVR, with a small subset of the training dataset (i.e. selected FVs), gives results comparable with those of the methods which give best results in terms of the prediction accuracy. The main contribution of this paper is the new kernel method (i.e. FVR), capable of achieving satisfactory results with reduced efforts because of the small number of hyperparameters to be tuned and the reduced training dataset size used.},
journal = {Neurocomput.},
month = dec,
pages = {411–422},
numpages = {12},
keywords = {Regression, Prediction, Kernel method, Hyperparameters tuning, Feature vector selection, Feature Vector Regression, Computational complexity}
}

@article{10.1109/TSP.2015.2496278,
author = {Meier, Yannick and Xu, Jie and Atan, Onur and van der Schaar, Mihaela},
title = {Predicting Grades},
year = {2016},
issue_date = {Feb.15, 2016},
publisher = {IEEE Press},
volume = {64},
number = {4},
issn = {1053-587X},
url = {https://doi.org/10.1109/TSP.2015.2496278},
doi = {10.1109/TSP.2015.2496278},
abstract = {To increase efficacy in traditional classroom courses as well as in Massive Open Online Courses (MOOCs), automated systems supporting the instructor are needed. One important problem is to automatically detect students that are going to do poorly in a course early enough to be able to take remedial actions. Existing grade prediction systems focus on maximizing the accuracy of the prediction while overseeing the importance of issuing timely and personalized predictions. This paper proposes an algorithm that predicts the final grade of each student in a class. It issues a prediction for each student individually, when the expected accuracy of the prediction is sufficient. The algorithm learns online what is the optimal prediction and time to issue a prediction based on past history of students’ performance in a course. We derive a confidence estimate for the prediction accuracy and demonstrate the performance of our algorithm on a dataset obtained based on the performance of approximately 700 UCLA undergraduate students who have taken an introductory digital signal processing over the past seven years. We demonstrate that for 85% of the students we can predict with 76% accuracy whether they are going do well or poorly in the class after the fourth course week. Using data obtained from a pilot course, our methodology suggests that it is effective to perform early in-class assessments such as quizzes, which result in timely performance prediction for each student, thereby enabling timely interventions by the instructor (at the student or class level) when necessary.},
journal = {Trans. Sig. Proc.},
month = feb,
pages = {959–972},
numpages = {14}
}

@article{10.1007/s00366-016-0497-3,
author = {Taheri, Khalil and Hasanipanah, Mahdi and Golzar, Saeid Bagheri and Majid, Muhd Zaimi},
title = {A hybrid artificial bee colony algorithm-artificial neural network for forecasting the blast-produced ground vibration},
year = {2017},
issue_date = {July      2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3},
issn = {0177-0667},
url = {https://doi.org/10.1007/s00366-016-0497-3},
doi = {10.1007/s00366-016-0497-3},
abstract = {Drilling and blasting is an inseparable part of the rock fragmentation process in open-pit mines. Prediction of blast-produced ground vibration is considered as an important issue in blasting works. The aim of this study is to propose a hybrid model for predicting blast-produced ground vibration in the Miduk copper mine, Iran, using combination of the artificial neural network (ANN) combined with artificial bee colony (ABC) (codename ABC-ANN). Here, ABC was used as an optimization algorithm to adjust weights and biases of the ANN. The predicted values of ground vibration by ANN and ABC-ANN models were also compared with several empirical models. In this regard, 89 blasting events were monitored and values of two influential factors on ground vibration, i.e., maximum charge weight used per delay (MC) and distance between monitoring station and blasting-point (DI) together with their peak particle velocity values (as an index of ground vibration) were carefully measured. The results of the predictive models have been compared with the data at hand using mean absolute percentage error, root mean squared error and coefficient of correlation (R2) criteria. Eventually, it was indicated that the constructed ABC-ANN model outperforms the other models in terms of the prediction accuracy and the generalization capability.},
journal = {Eng. with Comput.},
month = jul,
pages = {689–700},
numpages = {12},
keywords = {Multiple regression, Ground vibration, ANN, ABC-ANN}
}

@inproceedings{10.1145/2989081.2989101,
author = {Ghasempour, Mohsen and Jaleel, Aamer and Garside, Jim D. and Luj\'{a}n, Mikel},
title = {HAPPY: Hybrid Address-based Page Policy in DRAMs},
year = {2016},
isbn = {9781450343053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2989081.2989101},
doi = {10.1145/2989081.2989101},
abstract = {Memory controllers have used static page closure policies to decide whether a row should be left open, open-page policy, or closed immediately, close-page policy, after the row has been accessed. The appropriate choice for a particular access can reduce the average memory latency. However, since application access patterns change at run time, static page policies cannot guarantee to deliver optimum execution time. Hybrid page policies have been investigated as a means of covering these dynamic scenarios and are now implemented in state-of-the-art processors. Hybrid page policies switch between open-page and close-page policies while the application is running, by monitoring the access pattern of row hits/conflicts and predicting future behavior. Unfortunately, as the size of DRAM memory increases, fine-grain tracking and analysis of memory access patterns does not remain practical.We propose a compact memory address-based encoding technique which can improve or maintain the performance of DRAMs page closure predictors while reducing the hardware overhead in comparison with state-of-the-art techniques. As a case study, we integrate our technique, HAPPY, with a state-of-the-art Intel-adaptive monitor (e.g. part of the Intel Xeon X5650) and a traditional Hybrid page policy. We evaluate them across 70 memory intensive workload mixes consisting of single-thread and multi-thread applications. The experimental results show that using the HAPPY encoding applied to the Intel-adaptive page closure policy can reduce the hardware overhead by 5x for the evaluated 64 GB memory (up to 40\texttimes{} for a 512 GB memory) while maintaining the prediction accuracy.},
booktitle = {Proceedings of the Second International Symposium on Memory Systems},
pages = {311–321},
numpages = {11},
keywords = {Page Closure Policy, Memory Systems, DRAM},
location = {Alexandria, VA, USA},
series = {MEMSYS '16}
}

@inproceedings{10.1007/978-3-642-29253-8_13,
author = {Cheng, Bing and Chen, Tianqi and Yang, Diyi and Zhang, Weinan and Wang, Yongqiang and Yu, Yong},
title = {Feature based informative model for discriminating favorite items from unrated ones},
year = {2012},
isbn = {9783642292521},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-29253-8_13},
doi = {10.1007/978-3-642-29253-8_13},
abstract = {In this paper, we describe a feature based informative model to the second track of this year's KDD Cup Challenge. The goal is to discriminate songs rated highly by the user from ones never rated by him/her. The informative model is used to incorporate different kinds of information, such as taxonomy of items, item neighborhoods, user specific features and implicit feedback, into a single model. Additionally, we also adopt ranking oriented SVD and negative sampling to improve prediction accuracy. Our final model achieves an error rate of 3.10% on the test set with a single predictor, which is the best result of single predictors in all the publicized results on this task, even better than many ensemble models.},
booktitle = {Proceedings of the 14th Asia-Pacific International Conference on Web Technologies and Applications},
pages = {146–157},
numpages = {12},
keywords = {ranking oriented SVD, negative sampling, feature based informative model},
location = {Kunming, China},
series = {APWeb'12}
}

@inproceedings{10.5555/1876210.1876237,
author = {Huang, Jin and Shirabad, Jelber Sayyad and Matwin, Stan and Su, Jiang},
title = {Improving co-training with agreement-based sampling},
year = {2010},
isbn = {3642135285},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Co-training is an effective semi-supervised learning method which uses unlabeled instances to improve prediction accuracy. In the cotraining process, a random sampling is used to gradually select unlabeled instances to train classifiers. In this paper we explore whether other sampling methods can improve co-training performance. A novel selective sampling method, agreement-based sampling, is proposed. Experimental results show that our new sampling method can improve co-training significantly.},
booktitle = {Proceedings of the 7th International Conference on Rough Sets and Current Trends in Computing},
pages = {197–206},
numpages = {10},
location = {Warsaw, Poland},
series = {RSCTC'10}
}

@inproceedings{10.1007/978-3-319-25007-6_19,
author = {Kang, Yong-Bin and Krishnaswamy, Shonali and Li, Yuan-Fang},
title = {RO: An Efficient Ranking-Based Reasoner for OWL Ontologies},
year = {2015},
isbn = {978-3-319-25006-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-25007-6_19},
doi = {10.1007/978-3-319-25007-6_19},
abstract = {It has been shown, both theoretically and empirically, that performing core reasoning tasks on large and expressive ontologies in OWL 1 and OWL 2 is time-consuming and resource-intensive. Moreover, due to the different reasoning algorithms and optimisation techniques employed, each reasoner may be efficient for ontologies with different characteristics. In this paper, we present RO, a meta-reasoner that automatically combines, ranks and selects from a number of state-of-the-art OWL 2 DL reasoners to achieve high efficiency, making use of performance prediction models and ranking models. Our comprehensive evaluation on a large ontology corpus shows that RO significantly and consistently outperforms 6 state-of-the-art OWL 2 DL reasoners on average performance, with an average speedup of up to 14x. RO also shows a 1.4x speedup over Konclude, the current dominant OWL 2 DL reasoner.},
booktitle = {The Semantic Web - ISWC 2015: 14th International Semantic Web Conference, Bethlehem, PA, USA, October 11-15, 2015, Proceedings, Part I},
pages = {322–338},
numpages = {17},
keywords = {Ranking Matrix, Reasoning Task, Ranking Model, Description Logic, Reasoning Time},
location = {Bethlehem, PA, USA}
}

@inproceedings{10.1145/2883851.2883949,
author = {Pardos, Zachary A. and Xu, Yanbo},
title = {Improving efficacy attribution in a self-directed learning environment using prior knowledge individualization},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883949},
doi = {10.1145/2883851.2883949},
abstract = {Models of learning in EDM and LAK are pushing the boundaries of what can be measured from large quantities of historical data. When controlled randomization is present in the learning platform, such as randomized ordering of problems within a problem set, natural quasi-randomized controlled studies can be conducted, post-hoc. Difficulty and learning gain attribution are among factors of interest that can be studied with secondary analyses under these conditions. However, much of the content that we might like to evaluate for learning value is not administered as a random stimulus to students but instead is being self-selected, such as a student choosing to seek help in the discussion forums, wiki pages, or other pedagogically relevant material in online courseware. Help seekers, by virtue of their motivation to seek help, tend to be the ones who have the least knowledge. When presented with a cohort of students with a bi-modal or uniform knowledge distribution, this can present problems with model interpretability when a single point estimation is used to represent cohort prior knowledge. Since resource access is indicative of a low knowledge student, a model can tend towards attributing the resources with low or negative learning gain in order to better explain performance given the higher average prior point estimate. In this paper we present several individualized prior strategies and demonstrate how learning efficacy attribution validity and prediction accuracy improve as a result. Level of education attained, relative past assessment performance, and the prior per student cold start heuristic were employed and compared as prior knowledge individualization strategies.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {435–439},
numpages = {5},
keywords = {self-selection bias, self-directed learning, prior knowledge, massive open online courses (MOOCs), individualization, efficacy attribution, education, Bayesian knowledge tracing},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@article{10.1007/s10664-010-9135-7,
author = {Garvin, Brady J. and Cohen, Myra B. and Dwyer, Matthew B.},
title = {Evaluating improvements to a meta-heuristic search for constrained interaction testing},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-010-9135-7},
doi = {10.1007/s10664-010-9135-7},
abstract = {Combinatorial interaction testing (CIT) is a cost-effective sampling technique for discovering interaction faults in highly-configurable systems. Constrained CIT extends the technique to situations where some features cannot coexist in a configuration, and is therefore more applicable to real-world software. Recent work on greedy algorithms to build CIT samples now efficiently supports these feature constraints. But when testing a single system configuration is expensive, greedy techniques perform worse than meta-heuristic algorithms, because greedy algorithms generally need larger samples to exercise the same set of interactions. On the other hand, current meta-heuristic algorithms have long run times when feature constraints are present. Neither class of algorithm is suitable when both constraints and the cost of testing configurations are important factors. Therefore, we reformulate one meta-heuristic search algorithm for constructing CIT samples, simulated annealing, to more efficiently incorporate constraints. We identify a set of algorithmic changes and experiment with our modifications on 35 realistic constrained problems and on a set of unconstrained problems from the literature to isolate the factors that improve performance. Our evaluation determines that the optimizations reduce run time by a factor of 90 and accomplish the same coverage objectives with even fewer system configurations. Furthermore, the new version compares favorably with greedy algorithms on real-world problems, and, though our modifications were aimed at constrained problems, it shows similar advantages when feature constraints are absent.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {61–102},
numpages = {42},
keywords = {Search based software engineering, Constrained combinatorial interaction testing, Configurable software}
}

@article{10.1145/2757279,
author = {Duan, Qing and Koneru, Abhishek and Zeng, Jun and Chakrabarty, Krishnendu and Dispoto, Gary},
title = {Accurate Analysis and Prediction of Enterprise Service-Level Performance},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1084-4309},
url = {https://doi.org/10.1145/2757279},
doi = {10.1145/2757279},
abstract = {An enterprise service-level performance time series is a sequence of data points that quantify demand, throughput, average order-delivery time, quality of service, or end-to-end cost. Analytical and predictive models of such time series can be embedded into an enterprise information system (EIS) in order to provide meaningful insights into potential business problems and generate guidance for appropriate solutions. Time-series analysis includes periodicity detection, decomposition, and correlation analysis. Time-series prediction can be modeled as a regression problem to forecast a sequence of future time-series datapoints based on the given time series. The state-of-the-art (baseline) methods employed in time-series prediction generally apply advanced machine-learning algorithms. In this article, we propose a new univariate method for dealing with midterm time-series prediction. The proposed method first analyzes the hierarchical periodic structure in one time series and decomposes it into trend, season, and noise components. By discarding the noise component, the proposed method only focuses on predicting repetitive season and smoothed trend components. As a result, this method significantly improves upon the performance of baseline methods in midterm time-series prediction. Moreover, we propose a new multivariate method for dealing with short-term time-series prediction. The proposed method utilizes cross-correlation information derived from multiple time series. The amount of data taken from each time series for training the regression model is determined by results from hierarchical cross-correlation analysis. Such a data-filtering strategy leads to improved algorithm efficiency and prediction accuracy. By combining statistical methods with advanced machine-learning algorithms, we have achieved a significantly superior performance in both short-term and midterm time-series predictions compared to state-of-the-art (baseline) methods.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = sep,
articleno = {52},
numpages = {23},
keywords = {prediction, optimization, Machine learning}
}

@article{10.1016/j.patrec.2015.03.002,
author = {Sok, Hong Kuan and Ooi, Melanie Po-Leen and Kuang, Ye Chow},
title = {Sparse alternating decision tree},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {60},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2015.03.002},
doi = {10.1016/j.patrec.2015.03.002},
abstract = {Alternating decision tree (ADTree) brings interpretability to boosting.A novel sparse version of multivariate ADTree is presented.Sparse ADTree is a better generalization of existing univariate ADTree.The decision nodes are designed based on modified sparse discriminant analysis.The complexity of the decision nodes can be regularized easily. Alternating decision tree (ADTree) is a special decision tree representation that brings interpretability to boosting, a well-established ensemble algorithm. This has found success in wide applications. However, existing variants of ADTree are implementing univariate decision nodes where potential interactions between features are ignored. To date, there has been no multivariate ADTree. We propose a sparse version of multivariate ADTree such that it remains comprehensible. The proposed sparse ADTree is empirically tested on UCI datasets as well as spectral datasets from the University of Eastern Finland (UEF). We show that sparse ADTree is competitive against both univariate decision trees (original ADTree, C4.5, and CART) and multivariate decision trees (Fisher's decision tree and a single multivariate decision tree from oblique Random Forest). It achieves the best average rank in terms of prediction accuracy, second in terms of decision tree size and faster induction time than existing ADTree. In addition, it performs especially well on datasets with correlated features such as UEF spectral datasets. Thus, the proposed sparse ADTree extends the applicability of ADTree to a wider variety of applications.},
journal = {Pattern Recogn. Lett.},
month = aug,
pages = {57–64},
numpages = {8},
keywords = {Sparse discriminant analysis, Feature selection, Decision tree, Boosting, Alternating decision tree}
}

@article{10.1145/3185751,
author = {Hu, Xiameng and Wang, Xiaolin and Zhou, Lan and Luo, Yingwei and Wang, Zhenlin and Ding, Chen and Ye, Chencheng},
title = {Fast Miss Ratio Curve Modeling for Storage Cache},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1553-3077},
url = {https://doi.org/10.1145/3185751},
doi = {10.1145/3185751},
abstract = {The reuse distance (least recently used (LRU) stack distance) is an essential metric for performance prediction and optimization of storage cache. Over the past four decades, there have been steady improvements in the algorithmic efficiency of reuse distance measurement. This progress is accelerating in recent years, both in theory and practical implementation.In this article, we present a kinetic model of LRU cache memory, based on the average eviction time (AET) of the cached data. The AET model enables fast measurement and use of low-cost sampling. It can produce the miss ratio curve in linear time with extremely low space costs. On storage trace benchmarks, AET reduces the time and space costs compared to former techniques. Furthermore, AET is a composable model that can characterize shared cache behavior through sampling and modeling individual programs or traces.},
journal = {ACM Trans. Storage},
month = apr,
articleno = {12},
numpages = {34},
keywords = {miss ratio curve, data locality, Cache system}
}

@inproceedings{10.5220/0005104007510755,
author = {Lee, Chan and Gwon Kil, Hyun},
title = {The Design, Performance and CFD Analyses of Regenerative Blower used for Fuel Cell System},
year = {2014},
isbn = {9789897580383},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005104007510755},
doi = {10.5220/0005104007510755},
abstract = {For efficient design of regenerative blower used for fuel cell system, the design and the performance analysis methods of regenerative blower are developed, and CFD modeling and simulation are carried out on the designed blower. The design process of regenerative blower is conducted to determine the geometries of rotating impellers and stationary side channel with several design variables. The performance analysis on the designed blower is made by incorporating momentum exchange theory between impellers and side channel with meanline analysis method, and its pressure loss and leakage flow models are constructed from related fluid mechanics data and correlations which can be expressed in terms of blower design variables. The internal flow field of blower is analyzed by using the CFX code, a CFD code specialized for fluid machinery. The present performance analysis method is applied to four existing models for verifying its prediction accuracy, and the comparison between the prediction and the test results are well-agreed with a few percent relative error. Furthermore, the present design and performance analysis methods are also applied in developing a new blower used for fuel cell application, and the newly designed blower is manufactured and tested through chamber-type test facility. The performance prediction by the present method is well-agreed with the test and the CFD simulation results. Therefore, from the comparison results, the prediction design and performance analysis methods are shown to be suitable for the actual design practice of regenerative blower.},
booktitle = {Proceedings of the 4th International Conference on Simulation and Modeling Methodologies, Technologies and Applications},
pages = {751–755},
numpages = {5},
keywords = {Regenerative Blower, Performance, Design, CFD},
location = {Vienna, Austria},
series = {SIMULTECH 2014}
}

@inproceedings{10.1145/3078597.3078614,
author = {Xie, Bing and Huang, Yezhou and Chase, Jeffrey S. and Choi, Jong Youl and Klasky, Scott and Lofstead, Jay and Oral, Sarp},
title = {Predicting Output Performance of a Petascale Supercomputer},
year = {2017},
isbn = {9781450346993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078597.3078614},
doi = {10.1145/3078597.3078614},
abstract = {In this paper, we develop a predictive model useful for output performance prediction of supercomputer file systems under production load. Our target environment is Titan---the 3rd fastest supercomputer in the world---and its Lustre-based multi-stage write path. We observe from Titan that although output performance is highly variable at small time scales, the mean performance is stable and consistent over typical application run times. Moreover, we find that output performance is non-linearly related to its correlated parameters due to interference and saturation on individual stages on the path. These observations enable us to build a predictive model of expected write times of output patterns and I/O configurations, using feature transformations to capture non-linear relationships. We identify the candidate features based on the structure of the Lustre/Titan write path, and use feature transformation functions to produce a model space with 135,000 candidate models. By searching for the minimal mean square error in this space we identify a good model and show that it is effective.},
booktitle = {Proceedings of the 26th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {181–192},
numpages = {12},
keywords = {petascale supercomputer, output performance, linear regression},
location = {Washington, DC, USA},
series = {HPDC '17}
}

@article{10.1007/s10707-019-00377-8,
author = {Karimi, Firoozeh and Sultana, Selima and Babakan, Ali Shirzadi and Suthaharan, Shan},
title = {Urban expansion modeling using an enhanced decision tree algorithm},
year = {2021},
issue_date = {Oct 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {4},
issn = {1384-6175},
url = {https://doi.org/10.1007/s10707-019-00377-8},
doi = {10.1007/s10707-019-00377-8},
abstract = {Decision tree (DT) algorithms have been applied for classification and change detection in various geospatial studies and more recently, for urban expansion and land use/land cover (LULC) change modeling. However, these studies have not elaborated on specification of DT algorithms regarding data sampling, predictor variables, model configuration, and model evaluation. The focus of this study is to explore several balanced and unbalanced sampling methods, various predictor variables, different configurations of stopping rules, and reliable evaluation metrics to enhance the performance of classification and regression tree (CART), one of the most efficacious DT algorithms, for urban expansion modeling. The implementation of the model in the Triangle Region, North Carolina (NC) State, over the period of 2001 to 2011 demonstrates a striking performance with the training accuracy of 97%, the testing accuracy of 94%, and the Kappa value of 0.80. This performance was achieved using a training dataset containing all changed land cells and three times of that randomly selected from unchanged land cells and regulating the minimum number of records in a leaf node equal to 1, the minimum number of records in a parent node equal to 2, and the value of 10,000 for the maximum number of splits. The CART DT algorithm indicates that proximity to built areas, proximity to highways, current LULC type, elevation, and distance to water bodies are the most significant predictor variables for the urban expansion prediction in the study area.},
journal = {Geoinformatica},
month = oct,
pages = {715–731},
numpages = {17},
keywords = {Classification and regression tree (CART), Decision tree, Machine learning, Land-use/land-cover change, GIS, Urban growth}
}

@inproceedings{10.5555/2643634.2643656,
author = {Su, Bo and Greathouse, Joseph L. and Gu, Junli and Boyer, Michael and Shen, Li and Wang, Zhiying},
title = {Implementing a leading loads performance predictor on commodity processors},
year = {2014},
isbn = {9781931971102},
publisher = {USENIX Association},
address = {USA},
abstract = {Modern CPUs employ Dynamic Voltage and Frequency Scaling (DVFS) to boost performance, lower power, and improve energy efficiency. Good DVFS decisions require accurate performance predictions across frequencies. A new hardware structure for measuring leading load cycles was recently proposed and demonstrated promising performance prediction abilities in simulation.This paper proposes a method of leveraging existing hardware performance monitors to emulate a leading loads predictor. Our proposal, LL-MAB, uses existing miss status handling register occupancy information to estimate leading load cycles. We implement and validate LL-MAB on a collection of commercial AMD CPUs. Experiments demonstrate that it can accurately predict performance with an average error of 2.7% using an AMD Opteron™4386 processor over a 2.2x change in frequency. LL-MAB requires no hardware- or application-specific training, and it is more accurate and requires fewer counters than similar approaches.},
booktitle = {Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference},
pages = {205–210},
numpages = {6},
location = {Philadelphia, PA},
series = {USENIX ATC'14}
}

@inproceedings{10.5555/2039976.2040024,
author = {Keller, Christoph G. and Hermes, Christoph and Gavrila, Dariu M.},
title = {Will the pedestrian cross? probabilistic path prediction based on learned motion features},
year = {2011},
isbn = {9783642231223},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Future vehicle systems for active pedestrian safety will not only require a high recognition performance, but also an accurate analysis of the developing traffic situation. In this paper, we present a system for pedestrian action classification (walking vs. stopping) and path prediction at short, sub-second time intervals. Apart from the use of positional cues, obtained by a pedestrian detector, we extract motion features from dense optical flow. These augmented features are used in a probabilistic trajectory matching and filtering framework.The vehicle-based system was tested in various traffic scenes. We compare its performance to that of a state-of-the-art IMM Kalman filter (IMM-KF), and for the action classification task, to that of human observers, as well. Results show that human performance is best, followed by that of the proposed system, which outperforms the IMM-KF and the simpler system variants.},
booktitle = {Proceedings of the 33rd International Conference on Pattern Recognition},
pages = {386–395},
numpages = {10},
location = {Frankfurt, Germany},
series = {DAGM'11}
}

@inproceedings{10.1145/2342356.2342417,
author = {Zhang, Daqiang and Vasilakos, Athanasios V. and Xiong, Haoyi},
title = {Predicting location using mobile phone calls},
year = {2012},
isbn = {9781450314190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2342356.2342417},
doi = {10.1145/2342356.2342417},
abstract = {Location prediction using mobile phone traces has attracted increasing attention. Owing to the irregular user mobility patterns, it still remains challenging to predict user location. Our empirical study in this paper shows that the call patterns are strongly correlated with co-locate patterns (i.e., visiting the same cell tower at the same period), and the call patterns mainly affect user short-time mobility. On top of these findings, we propose NextMe --- a novel scheme to enhance the location prediction accuracy by leveraging the social interplay revealed in the cellular calls. To identify when the social interplay will affect user mobility, we introduce the concepts of the Critical Call Pattern (CCP), and the Critical Call (CC). We validate NextMe with the MIT Reality Mining dataset, involving 350,000-hour activity logs of 106 persons, and 112,508 cellular calls. Experimental results show that the social interplay significantly improves the accuracy.},
booktitle = {Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {295–296},
numpages = {2},
keywords = {social networks, social interplay, mobile phone calls},
location = {Helsinki, Finland},
series = {SIGCOMM '12}
}

@article{10.1145/2377677.2377738,
author = {Zhang, Daqiang and Vasilakos, Athanasios V. and Xiong, Haoyi},
title = {Predicting location using mobile phone calls},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2377677.2377738},
doi = {10.1145/2377677.2377738},
abstract = {Location prediction using mobile phone traces has attracted increasing attention. Owing to the irregular user mobility patterns, it still remains challenging to predict user location. Our empirical study in this paper shows that the call patterns are strongly correlated with co-locate patterns (i.e., visiting the same cell tower at the same period), and the call patterns mainly affect user short-time mobility. On top of these findings, we propose NextMe --- a novel scheme to enhance the location prediction accuracy by leveraging the social interplay revealed in the cellular calls. To identify when the social interplay will affect user mobility, we introduce the concepts of the Critical Call Pattern (CCP), and the Critical Call (CC). We validate NextMe with the MIT Reality Mining dataset, involving 350,000-hour activity logs of 106 persons, and 112,508 cellular calls. Experimental results show that the social interplay significantly improves the accuracy.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {295–296},
numpages = {2},
keywords = {social networks, social interplay, mobile phone calls}
}

@article{10.1007/s11227-014-1361-0,
author = {Chen, Wei and Lee, Young Choon and Fekete, Alan and Zomaya, Albert Y.},
title = {Adaptive multiple-workflow scheduling with task rearrangement},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {71},
number = {4},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-014-1361-0},
doi = {10.1007/s11227-014-1361-0},
abstract = {Large-scale distributed computing systems like grids and more recently clouds are a platform of choice for many resource-intensive applications. Workflow applications account for the majority of these applications, particularly in science and engineering. A workflow application consists of multiple precedence-constrained tasks with data dependencies. Since resources in those systems are shared by many users and applications deployed there are very diverse, scheduling is complicated. Often, the actual execution of applications differs from the original schedule following delays such as those caused by resource contention and other issues in performance prediction. These delays have further impact when running multiple workflow applications due to inter-task dependencies. In this paper, we investigate the problem of scheduling multiple workflow applications concurrently, explicitly taking into account scheduling robustness. We present a dynamic task rearrangement and rescheduling algorithm that exploits the scheduling flexibility from precedence constraints among tasks. The algorithm optimizes resource allocation among multiple workflows, and it often stops the influence of delayed execution passing to subsequent tasks. The experimental results demonstrate that our approach can significantly improve performance in multiple-workflow scheduling.},
journal = {J. Supercomput.},
month = apr,
pages = {1297–1317},
numpages = {21},
keywords = {Workflow scheduling, Workflow applications, Scheduling, Rescheduling}
}

@inproceedings{10.1007/978-3-642-13821-8_3,
author = {Babka, Vlastimil and T\r{u}ma, Petr and Bulej, Lubom\'{\i}r},
title = {Validating model-driven performance predictions on random software systems},
year = {2010},
isbn = {3642138209},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13821-8_3},
doi = {10.1007/978-3-642-13821-8_3},
abstract = {Software performance prediction methods are typically validated by taking an appropriate software system, performing both performance predictions and performance measurements for that system, and comparing the results. The validation includes manual actions, which makes it feasible only for a small number of systems.To significantly increase the number of systems on which software performance prediction methods can be validated, and thus improve the validation, we propose an approach where the systems are generated together with their models and the validation runs without manual intervention. The approach is described in detail and initial results demonstrating both its benefits and its issues are presented.},
booktitle = {Proceedings of the 6th International Conference on Quality of Software Architectures: Research into Practice - Reality and Gaps},
pages = {3–19},
numpages = {17},
keywords = {performance validation, performance modeling, MDD},
location = {Prague, Czech Republic},
series = {QoSA'10}
}

@inproceedings{10.1145/3444950.3447284,
author = {Bouhali, Noureddine and Ouarnoughi, Hamza and Niar, Smail and El Cadi, Abdessamad Ait},
title = {Execution Time Modeling for CNN Inference on Embedded GPUs},
year = {2021},
isbn = {9781450389525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444950.3447284},
doi = {10.1145/3444950.3447284},
abstract = {Machine learning is one of the most cutting edge methods in computer vision. Convolutional Neural Networks (CNN) in particular are widely used in edge computing based applications such as autonomous driving for image recognition or object tracking. Different constraints exist in this application area such as real-time, energy consumption, memory resources, etc. Choosing the optimal CNN for each GPU at hand is really hard to do, while maintaining high levels of accuracy and performance. This makes prior knowledge about the execution time a necessary prerequisite information before the final deployment of the CNN on the edge GPU platform. In this paper, we compare 5 execution time prediction models on a large set of CNNs-based applications. The tested predictors use machine learning regression approach. The proposed methodology is based on the utilization of high level CNN features. At the opposite of state-of-the-art approaches, no implementation or profiling on the hardware is required. A Mean Absolute Percentage Error (MAPE) of 5% using Support Vector Regression and Artificial Neural Networks has been obtained in the experiments. Our comparison shows the efficiency of these models to rapidly explore a large space of CNN models or Hardware configurations.},
booktitle = {Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings},
pages = {59–65},
numpages = {7},
location = {Budapest, Hungary},
series = {DroneSE and RAPIDO '21}
}

@inproceedings{10.1145/2635868.2666610,
author = {Devroey, Xavier and Perrouin, Gilles and Cordy, Maxime and Papadakis, Mike and Legay, Axel and Schobbens, Pierre-Yves},
title = {A variability perspective of mutation analysis},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2666610},
doi = {10.1145/2635868.2666610},
abstract = {Mutation testing is an effective technique for either improving or generating fault-finding test suites. It creates defective or incorrect program artifacts of the program under test and evaluates the ability of test suites to reveal them. Despite being effective, mutation is costly since it requires assessing the test cases with a large number of defective artifacts. Even worse, some of these artifacts are behaviourally ``equivalent'' to the original one and hence, they unnecessarily increase the testing effort. We adopt a variability perspective on mutation analysis. We model a defective artifact as a transition system with a specific feature selected and consider it as a member of a mutant family. The mutant family is encoded as a Featured Transition System, a compact formalism initially dedicated to model-checking of software product lines. We show how to evaluate a test suite against the set of all candidate defects by using mutant families. We can evaluate all the considered defects at the same time and isolate some equivalent mutants. We can also assist the test generation process and efficiently consider higher-order mutants.},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {841–844},
numpages = {4},
keywords = {Mutation Testing, Featured Transition Systems},
location = {Hong Kong, China},
series = {FSE 2014}
}

@article{10.1007/s10270-013-0316-x,
author = {Rathfelder, Christoph and Klatt, Benjamin and Sachs, Kai and Kounev, Samuel},
title = {Modeling event-based communication in component-based software architectures for performance predictions},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0316-x},
doi = {10.1007/s10270-013-0316-x},
abstract = {Event-based communication is used in different domains including telecommunications, transportation, and business information systems to build scalable distributed systems. Such systems typically have stringent requirements for performance and scalability as they provide business and mission critical services. While the use of event-based communication enables loosely-coupled interactions between components and leads to improved system scalability, it makes it much harder for developers to estimate the system's behavior and performance under load due to the decoupling of components and control flow. In this paper, we present our approach enabling the modeling and performance prediction of event-based systems at the architecture level. Applying a model-to-model transformation, our approach integrates platform-specific performance influences of the underlying middleware while enabling the use of different existing analytical and simulation-based prediction techniques. In summary, the contributions of this paper are: (1) the development of a meta-model for event-based communication at the architecture level, (2) a platform aware model-to-model transformation, and (3) a detailed evaluation of the applicability of our approach based on two representative real-world case studies. The results demonstrate the effectiveness, practicability and accuracy of the proposed modeling and prediction approach.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1291–1317},
numpages = {27},
keywords = {Software architecture, Performance model, Performance evaluation, Event-based, Component-based}
}

@article{10.1145/1105734.1105738,
author = {Davis, John D. and Fu, Cong and Laudon, James},
title = {The RASE (Rapid, Accurate Simulation Environment) for chip multiprocessors},
year = {2005},
issue_date = {November 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {0163-5964},
url = {https://doi.org/10.1145/1105734.1105738},
doi = {10.1145/1105734.1105738},
abstract = {We present RASE, a full system high performance simulation methodology for simulating complex server applications and server class chip multiprocessors enabled with fine-grain multithreading (CMTs). RASE combines application knowledge, operating system information, and data access patterns with an instruction stream from a highly-tuned, scalable steady-state benchmark [5] [22] to generate multiple representative instruction streams that can be mapped to a variety of CMT configurations. We use execution-driven simulation to generate instruction streams for M processors and store them as instruction trace files (several billion instructions per processor) that can be post-processed and augmented for larger than M processor system simulation. We use SPEC JBB2000, TPC-C, and an XML server benchmark to compare the performance estimates of RASE to a reference prototype CMT system. By varying M, we find that our trace-driven simulation methodology predicts within 5% of the instructions per cycle (IPC) of the reference hardware for the applications. Without post-processing the traces, in the best cases, the performance prediction accuracy degrades to 20-40% of the real IPC for instruction traces that require a high replication factor.},
journal = {SIGARCH Comput. Archit. News},
month = nov,
pages = {14–23},
numpages = {10}
}

@inproceedings{10.1109/IPDPS.2014.88,
author = {You, Yang and Song, Shuaiwen Leon and Fu, Haohuan and Marquez, Andres and Dehnavi, Maryam Mehri and Barker, Kevin and Cameron, Kirk W. and Randles, Amanda Peters and Yang, Guangwen},
title = {MIC-SVM: Designing a Highly Efficient Support Vector Machine for Advanced Modern Multi-core and Many-Core Architectures},
year = {2014},
isbn = {9781479938001},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IPDPS.2014.88},
doi = {10.1109/IPDPS.2014.88},
abstract = {Support Vector Machine (SVM) has been widely used in data-mining and Big Data applications as modern commercial databases start to attach an increasing importance to the analytic capabilities. In recent years, SVM was adapted to the field of High Performance Computing for power/performance prediction, auto-tuning, and runtime scheduling. However, even at the risk of losing prediction accuracy due to insufficient runtime information, researchers can only afford to apply offline model training to avoid significant runtime training overhead. Advanced multi- and many-core architectures offer massive parallelism with complex memory hierarchies which can make runtime training possible, but form a barrier to efficient parallel SVM design. To address the challenges above, we designed and implemented MIC-SVM, a highly efficient parallel SVM for x86 based multi-core and many-core architectures, such as the Intel Ivy Bridge CPUs and Intel Xeon Phi co-processor (MIC). We propose various novel analysis methods and optimization techniques to fully utilize the multilevel parallelism provided by these architectures and serve as general optimization methods for other machine learning tools. MIC-SVM achieves 4.4-84x and 18-47x speedups against the popular LIBSVM, on MIC and Ivy Bridge CPUs respectively, for several real-world data-mining datasets. Even compared with GPUSVM, run on a top of the line NVIDIA k20x GPU, the performance of our MIC-SVM is competitive. We also conduct a cross-platform performance comparison analysis, focusing on Ivy Bridge CPUs, MIC and GPUs, and provide insights on how to select the most suitable advanced architectures for specific algorithms and input data patterns.},
booktitle = {Proceedings of the 2014 IEEE 28th International Parallel and Distributed Processing Symposium},
pages = {809–818},
numpages = {10},
keywords = {Support Vector Machine, Multi-&amp; Many-Core architectures, Parallelization, Optimization Techniques, Performance Analysis},
series = {IPDPS '14}
}

@inproceedings{10.1109/WORKS.2014.12,
author = {Pietri, Ilia and Juve, Gideon and Deelman, Ewa and Sakellariou, Rizos},
title = {A performance model to estimate execution time of scientific workflows on the cloud},
year = {2014},
isbn = {9781479970674},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/WORKS.2014.12},
doi = {10.1109/WORKS.2014.12},
abstract = {Scientific workflows, which capture large computational problems, may be executed on large-scale distributed systems such as Clouds. Determining the amount of resources to be provisioned for the execution of scientific workflows is a key component to achieve cost-efficient resource management and good performance. In this paper, a performance prediction model is presented to estimate execution time of scientific workflows for a different number of resources, taking into account their structure as well as their system-dependent characteristics. In the evaluation, three real-world scientific workflows are used to compare the estimated makespan calculated by the model with the actual makespan achieved on different system configurations of Amazon EC2. The results show that the proposed model can predict execution time with an error of less than 20% for over 96.8% of the experiments.},
booktitle = {Proceedings of the 9th Workshop on Workflows in Support of Large-Scale Science},
pages = {11–19},
numpages = {9},
location = {New Orleans, Louisiana},
series = {WORKS '14}
}

@article{10.1016/j.entcs.2013.04.002,
author = {Kounev, Samuel and Rathfelder, Christoph and Klatt, Benjamin},
title = {Modeling of Event-based Communication in Component-based Architectures: State-of-the-Art and Future Directions},
year = {2013},
issue_date = {May, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {295},
issn = {1571-0661},
url = {https://doi.org/10.1016/j.entcs.2013.04.002},
doi = {10.1016/j.entcs.2013.04.002},
abstract = {Event-based communication is used in different domains including telecommunications, transportation, and business information systems to build scalable distributed systems. Such systems typically have stringent requirements for performance and scalability as they provide business and mission critical services. While the use of event-based communication enables loosely-coupled interactions between components and leads to improved system scalability, it makes it much harder for developers to estimate the system@?s behavior and performance under load due to the decoupling of components and control flow. We present an overview on our approach enabling the modeling and performance prediction of event-based system at the architecture level. Applying a model-to-model transformation, our approach integrates platform-specific performance influences of the underlying middleware while enabling the use of different existing analytical and simulation-based prediction techniques. The results of two real world case studies demonstrate the effectiveness, practicability and accuracy of the proposed modeling and prediction approach.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = may,
pages = {3–9},
numpages = {7},
keywords = {event-based system, distributed systems, Component based architecture}
}

@inproceedings{10.1145/2503210.2503263,
author = {Jain, Nikhil and Bhatele, Abhinav and Robson, Michael P. and Gamblin, Todd and Kale, Laxmikant V.},
title = {Predicting application performance using supervised learning on communication features},
year = {2013},
isbn = {9781450323789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2503210.2503263},
doi = {10.1145/2503210.2503263},
abstract = {Task mapping on torus networks has traditionally focused on either reducing the maximum dilation or average number of hops per byte for messages in an application. These metrics make simplified assumptions about the cause of network congestion, and do not provide accurate correlation with execution time. Hence, these metrics cannot be used to reasonably predict or compare application performance for different mappings. In this paper, we attempt to model the performance of an application using communication data, such as the communication graph and network hardware counters. We use supervised learning algorithms, such as randomized decision trees, to correlate performance with prior and new metrics. We propose new hybrid metrics that provide high correlation with application performance, and may be useful for accurate performance prediction. For three different communication patterns and a production application, we demonstrate a very strong correlation between the proposed metrics and the execution time of these codes.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {95},
numpages = {12},
keywords = {torus networks, task mapping, supervised learning, prediction, modeling, contention},
location = {Denver, Colorado},
series = {SC '13}
}

@article{10.1145/1964218.1964231,
author = {Cook, Jeanine and Cook, Jonathan and Alkohlani, Waleed},
title = {A statistical performance model of the opteron processor},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/1964218.1964231},
doi = {10.1145/1964218.1964231},
abstract = {Cycle-accurate simulation is the dominant methodology for processor design space analysis and performance prediction. However, with the prevalence of multi-core, multi-threaded architectures, this method has become highly impractical as the sole means for design due to its extreme slowdowns. We have developed a statistical technique for modeling multicore processors that is based on Monte Carlo methods. Using this method, processor models of contemporary architectures can be developed and applied to performance prediction, bottleneck detection, and limited design space analysis. To date, we have accurately modeled the IBM Cell, the Intel Itanium, and the Sun Niagara 1 and Niagara 2 processors [23, 22, 8]. In this paper, we present a work in progress which is applying this methodology to an out-of-order execution processor. We present the initial single-core model and results for the AMD Barcelona (Opteron) processor.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = mar,
pages = {75–80},
numpages = {6}
}

@article{10.1016/j.future.2017.08.061,
author = {Farias, Victor A.E. and Sousa, Flvio R.C. and Maia, Jos Gilvan R. and Gomes, Joo Paulo P. and Machado, Javam C.},
title = {Regression based performance modeling and provisioning for NoSQL cloud databases},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {79},
number = {P1},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2017.08.061},
doi = {10.1016/j.future.2017.08.061},
abstract = {Cloud computing is a successful and emerging paradigm that supports on-demand services with pay-as-you-go model. Because of the exponential growth of data, NoSQL databases have been used to manage data in the cloud. In this scenario, it is fundamental for cloud providers guarantee Quality of Service (QoS) by avoiding violations to Service Level Agreement (SLA) contract while reducing the operational costs related to overprovisioning and underprovisioning. In this regard, elastic provisioning mechanisms are employed to maintain QoS by dynamically adding and removing resources to handle workload fluctuations. These mechanisms can also take more accurate provisioning decisions based on performance predictions of the cluster shrinkage and growth. Performance prediction is a challenging task since concurrent access of distributed data can cause non-linear effects on performance. This paper presents a performance modeling approach for NoSQL databases in terms of SLA-based metrics capable of capturing non-linear effects caused by concurrency and distribution aspects. Moreover we present a elastic provisioning strategy that takes advantage on performance models to deliver a reliable resource provisioning. We carried out experiments in order to evaluate our performance modeling and provisioning approaches. The results confirmed that our performance modeling can accurately predict throughput and SLA violations measurements under a wide range of workload settings and also that our elastic provisioning approach can ensure QoS while using resources efficiently. Cloud SLA aware performance modeling approach for NoSQL database systems.SLA-based metric prediction by capturing non-linear effects.Provisioning approach for NoSQL systems taking advantage of performance modeling.NoSQL resource allocation based on service workload and cluster infrastructure.},
journal = {Future Gener. Comput. Syst.},
month = feb,
pages = {72–81},
numpages = {10},
keywords = {Workload analysis, Performance modeling, NoSQL databases, Cloud computing}
}

@article{10.1016/j.is.2018.02.001,
author = {Cuzzocrea, Alfredo and Folino, Francesco and Guarascio, Massimo and Pontieri, Luigi},
title = {Predictive monitoring of temporally-aggregated performance indicators of business processes against low-level streaming events},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {81},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2018.02.001},
doi = {10.1016/j.is.2018.02.001},
journal = {Inf. Syst.},
month = mar,
pages = {236–266},
numpages = {31},
keywords = {Event-driven systems, Business process intelligence, Business process monitoring}
}

@inproceedings{10.1145/3454127.3457634,
author = {SAHLAOUI, Hayat and ABDELLAOUI ALAOUI, El Arbi and Agoujil, Said},
title = {A framework towards more accurate and explanatory student performance model},
year = {2021},
isbn = {9781450388719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3454127.3457634},
doi = {10.1145/3454127.3457634},
abstract = {The ability to predict students academic performance in a timely manner is very important in learning institutions [18]. Student performance prediction is an important area as it can help teachers identify students who need additional academic support [14]. Predicting student academic performance helps teachers develop a good understanding of how well or how badly students are doing in their classes so that teachers can take proactive steps to improve student learning. Accurately predicting students future performance based on their ongoing academic records is critical to effectively conducting the educational interventions required to ensure students complete the course on time and in a satisfactory manner [4]. To achieve these goals, however, a large amount of student data must be analyzed and predicted using various machine learning models. Having a wealth of options is good, but deciding which model to implement in production is critical. While we have a number of performance metrics to evaluate a model, it is not advisable to implement every algorithm for every problem. This takes a lot of time and effort. Additionally, machine learning (ML) models are amazingly good at making predictions, but often cannot provide explanations for their predictions that humans can easily understand. Most machine learning-based projects focused primarily on results, on updating the accuracy of student grade models without considering mechanisms for their interpretability. Therefore it is important to know how to choose the right algorithm for a given task and how to choose the ”right” interpretability tool. To that end, we provide a guide for machine learning practitioners and researchers that shows the thought process that they might find useful in improving the performance and interpretability of their models, and they can even get great results on their prediction problems. The study concludes that machine learning practitioners can improve the performance of predictive models with data tactics such as getting more data, cleaning data, resampling data and rescaling data. And with algorithms optimization tactics by searching for the best hyper-parameters by using random search of algorithm hyper parameters to expose configurations that never thought of. And learning to combine by using a new model to learn how to best combine the predictions from multiple well-performing models. And can also improve the interpretability of the model by choosing the “right” interpretability tool. As machine learning becomes more ubiquitous, understanding how these models find answers is critical to improve their performance and reliability. When deciding to implement a machine learning model, choosing the right model mean analyzing your needs and expected results. Finally, developing the right solution to a problem in real life is rarely just an applied math problem. It requires awareness of business needs, rules and regulations, and stakeholder concerns, as well as considerable expertise. When solving a machine problem, it is crucial to be able to combine and balance them out. Those who can do this can create the greatest value.},
booktitle = {Proceedings of the 4th International Conference on Networking, Information Systems &amp; Security},
articleno = {58},
numpages = {8},
keywords = {Students’ performance, Model performance, Machine learning algorithms, Interpretability.},
location = {KENITRA, AA, Morocco},
series = {NISS '21}
}

@article{10.1155/2012/610487,
author = {Kumar, Shiva and Pai, P. Srinivasa and Rao, B. R. Shrinivasa},
title = {Radial-basis-function-network-based prediction of performance and emission characteristics in a bio diesel engine run on WCO ester},
year = {2012},
issue_date = {January 2012},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2012},
issn = {1687-7470},
url = {https://doi.org/10.1155/2012/610487},
doi = {10.1155/2012/610487},
abstract = {Radial basis function neural networks (RBFNNs), which is a relatively new class of neural networks, have been investigated for their applicability for prediction of performance and emission characteristics of a diesel engine fuelled with waste cooking oil (WCO). The RBF networks were trained using the experimental data, where in load percentage, compression ratio, blend percentage, injection timing, and injection pressure were taken as the input parameters, and brake thermal efficiency (BTE), brake specific energy consumption (BSEC), exhaust gas temperature (Texh), and engine emissions were used as the output parameters. The number of RBF centers was selected randomly. The network was initially trained using variable width values for the RBF units using a heuristic and then was trained by using fixed width values. Studies showed that RBFNN predicted results matched well with the experimental results over a wide range of operating conditions. Prediction accuracy for all the output parameters was above 90% in case of performance parameters and above 70% in case of emission parameters.},
journal = {Adv. in Artif. Intell.},
month = jan,
articleno = {10},
numpages = {1}
}

@inproceedings{10.1109/MICRO.2014.53,
author = {Zhang, Yunqi and Laurenzano, Michael A. and Mars, Jason and Tang, Lingjia},
title = {SMiTe: Precise QoS Prediction on Real-System SMT Processors to Improve Utilization in Warehouse Scale Computers},
year = {2014},
isbn = {9781479969982},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICRO.2014.53},
doi = {10.1109/MICRO.2014.53},
abstract = {One of the key challenges for improving efficiency in warehouse scale computers (WSCs) is to improve server utilization while guaranteeing the quality of service (QoS) of latency-sensitive applications. To this end, prior work has proposed techniques to precisely predict performance and QoS interference to identify 'safe' application co-locations. However, such techniques are only applicable to resources shared across cores. Achieving such precise interference prediction on real-system simultaneous multithreading (SMT) architectures has been a significantly challenging open problem due to the complexity introduced by sharing resources within a core.In this paper, we demonstrate through a real-system investigation that the fundamental difference between resource sharing behaviors on CMP and SMT architectures calls for a redesign of the way we model interference. For SMT servers, the interference on different shared resources, including private caches, memory ports, as well as integer and floating-point functional units, do not correlate with each other. This insight suggests the necessity of decoupling interference into multiple resource sharing dimensions. In this work, we propose SMiTe, a methodology that enables precise performance prediction for SMT co-location on real-system commodity processors. With a set of Rulers, which are carefully designed software stressors that apply pressure to a multidimensional space of shared resources, we quantify application sensitivity and contentiousness in a decoupled manner. We then establish a regression model to combine the sensitivity and contentiousness in different dimensions to predict performance interference. Using this methodology, we are able to precisely predict the performance interference in SMT co-location with an average error of 2.80% on SPEC CPU2006 and 1.79% on Cloud Suite. Our evaluation shows that SMiTe allows us to improve the utilization of WSCs by up to 42.57% while enforcing an application's QoS requirements.},
booktitle = {Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {406–418},
numpages = {13},
keywords = {warehouse scale computer, simultaneous multithreading, quality of service, datacenter},
location = {Cambridge, United Kingdom},
series = {MICRO-47}
}

@article{10.1145/2699836,
author = {Duan, Qing and Zeng, Jun and Chakrabarty, Krishnendu and Dispoto, Gary},
title = {Data-Driven Optimization of Order Admission Policies in a Digital Print Factory},
year = {2015},
issue_date = {February 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/2699836},
doi = {10.1145/2699836},
abstract = {On-demand digital print service is an example of a real-time embedded enterprise system. It offers mass customization and exemplifies personalized manufacturing services. Once a print order is submitted to the print factory by a client, the print service provider (PSP) needs to make a real-time decision on whether to accept or refuse this order. Based on the print factory's current capacity and the order's properties and requirements, an order is refused if its acceptance is not profitable for the PSP. The order is accepted with the most appropriate due date in order to maximize the profit that can result from this order. We have developed an automated learning-based order admission framework that can be embedded into an enterprise environment to provide real-time admission decisions for new orders. The framework consists of three classifiers: Support Vector Machine (SVM), Decision Tree (DT), and Bayesian Probabilistic Model (BPM). The classifiers are trained by history orders and used to predict completion status for new orders. A decision integration technique is implemented to combine the results of the classifiers and predict due dates. Experimental results derived using real factory data from a leading print service provider and Weka open-source software show that the order completion status prediction accuracy is significantly improved by the decision integration strategy. The proposed multiclassifier model also outperforms a standalone regression model.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = mar,
articleno = {21},
numpages = {25},
keywords = {prediction, optimization, Machine learning}
}

@inproceedings{10.1007/978-3-319-21024-7_28,
author = {Al-Saleem, Mona and Al-Kathiry, Norah and Al-Osimi, Sara and Badr, Ghada},
title = {Mining Educational Data to Predict Students' Academic Performance},
year = {2015},
isbn = {9783319210230},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-21024-7_28},
doi = {10.1007/978-3-319-21024-7_28},
abstract = {Data mining is the process of extracting useful information from a huge amount of data. One of the most common applications of data mining is the use of different algorithms and tools to estimate future events based on previous experiences. In this context, many researchers have been using data mining techniques to support and solve challenges in higher education. There are many challenges facing this level of education, one of which is helping students to choose the right course to improve their success rate. An early prediction of students' grades may help to solve this problem and improve students' performance, selection of courses, success rate and retention. In this paper we use different classification techniques in order to build a performance prediction model, which is based on previous students' academic records. The model can be easily integrated into a recommender system that can help students in their course selection, based on their and other graduated students' grades. Our model uses two of the most recognised decision tree classification algorithms: ID3 and J48. The advantages of such a system have been presented along with a comparison in performance between the two algorithms.},
booktitle = {Proceedings of the 11th International Conference on Machine Learning and Data Mining in Pattern Recognition - Volume 9166},
pages = {403–414},
numpages = {12},
location = {Hamburg, Germany},
series = {MLDM 2015}
}

@inproceedings{10.5555/1791889.1791901,
author = {Xu, Qiang and Subhlok, Jaspal},
title = {Construction and evaluation of coordinated performance skeletons},
year = {2008},
isbn = {9783540898931},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Performance prediction is particularly challenging for dynamic environmentsthat cannot be modeled well due to reasons such as resource sharingand foreign system components. The approach to performance prediction takenin this work is based on the concept of a performance skeleton which is a shortrunning program whose execution time in any scenario reflects the estimated executiontime of the application it represents. The fundamental technical challengeaddressed in this paper is the automatic construction of performance skeletonsfor parallel MPI programs. The steps in the skeleton construction procedure are1) generation of process execution traces and conversion to a single coordinatedlogical program trace, 2) compression of the logical program trace, and 3) conversionto an executable parallel skeleton program. Results are presented to validatethe construction methodology and prediction power of performance skeletons.The execution scenarios analyzed involve network sharing, different architecturesand different MPI libraries. The emphasis is on identifying the strength and limitationsof this approach to performance prediction.},
booktitle = {Proceedings of the 15th International Conference on High Performance Computing},
pages = {73–86},
numpages = {14},
location = {Bangalore, India},
series = {HiPC'08}
}

@inproceedings{10.1145/2991041.2991053,
author = {Alidra, Abdelghani and Kimour, Mohamed Tahar},
title = {Prototyping Software Product Lines analysis with Pharo},
year = {2016},
isbn = {9781450345248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2991041.2991053},
doi = {10.1145/2991041.2991053},
abstract = {Software Product Lines (SPLs) are an emerging software engineering paradigm that aims to optimize software development costs and time to market trough systematic development of reusable of core assets. At the heart of SPL engineering is variability modelling. Feature models (FM) are a common way to model variability and reason about it. Examples of reasoning are for instance checking that at least one product is represented by a given FM (satisfiability) or finding the product that best fits a given set of requirements. In practice however, such operations are often complex and time consuming. In order to address these challenges, we introduce in the present article the notion of transitive dependency between features and show how it can be used as the basis for efficient analysis and automatic reasoning on feature models. We exploit this new concept to implement a first platform for prototyping and reasoning on large SPLs in Pharo. Finally we illustrate the efficiency of our proposal on the problem of features selection optimisation.},
booktitle = {Proceedings of the 11th Edition of the International Workshop on Smalltalk Technologies},
articleno = {12},
numpages = {11},
keywords = {automatic reasoning, analysis environment, Software Product Lines, Feature models},
location = {Prague, Czech Republic},
series = {IWST'16}
}

@inproceedings{10.1145/2487575.2487691,
author = {Tang, Jie and Wu, Sen and Sun, Jimeng},
title = {Confluence: conformity influence in large social networks},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487691},
doi = {10.1145/2487575.2487691},
abstract = {Conformity is a type of social influence involving a change in opinion or behavior in order to fit in with a group. Employing several social networks as the source for our experimental data, we study how the effect of conformity plays a role in changing users' online behavior. We formally define several major types of conformity in individual, peer, and group levels. We propose Confluence model to formalize the effects of social conformity into a probabilistic model. Confluence can distinguish and quantify the effects of the different types of conformities. To scale up to large social networks, we propose a distributed learning method that can construct the Confluence model efficiently with near-linear speedup. Our experimental results on four different types of large social networks, i.e., Flickr, Gowalla, Weibo and Co-Author, verify the existence of the conformity phenomena. Leveraging the conformity information, Confluence can accurately predict actions of users. Our experiments show that Confluence significantly improves the prediction accuracy by up to 5-10% compared with several alternative methods.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {347–355},
numpages = {9},
keywords = {social network, social influence, conformity},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@article{10.1177/0278364915584007,
author = {Hardy, Jason and Havlak, Frank and Campbell, Mark},
title = {Multi-step prediction of nonlinear Gaussian Process dynamics models with adaptive Gaussian mixtures},
year = {2015},
issue_date = {8 2015},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {34},
number = {9},
issn = {0278-3649},
url = {https://doi.org/10.1177/0278364915584007},
doi = {10.1177/0278364915584007},
abstract = {This paper presents an adaptive Gaussian Mixture Model aGMM formulation for performing multiple-step probabilistic state predictions using a nonparametric Gaussian Process GP regression model. The presented prediction algorithm is applicable to any dynamic system that is challenging to model parametrically, but where data is available. Gaussian mixture elements are propagated through the GP by analytically evaluating expectation integrals for the moments of the output distribution. Two metrics are presented and compared for adaptively splitting the initial state distribution into a sum of Gaussians to reduce the effect of nonlinearities on prediction accuracy: 1 an analytical evaluation of the excess kurtosis which measures the non-Gaussianity of the output distribution, and 2 a weighted least-squares regression model which evaluates the local nonlinearity of the GP mapping with respect to the input distribution. In addition, an on-the-fly data selection method is presented to reduce the computational complexity associated with analytically evaluating the higher-order moments of the GP output distribution. The proposed adaptive GP-aGMM formulation is applied to the case of anticipating driver behavior at road intersections using a GP driver behavior model in combination with a parametric vehicle model. Prediction performance for this scenario is evaluated using driving data collected from three human subjects navigating a standard four-way intersection. Results demonstrate that the presented prediction algorithm is capable of accurately capturing multimodal behavior in the GP training data.},
journal = {Int. J. Rob. Res.},
month = aug,
pages = {1211–1227},
numpages = {17},
keywords = {obstacle anticipation, machine learning, driver modeling, Gaussian Process, Gaussian Mixture Models}
}

@inproceedings{10.1145/1646461.1646465,
author = {Wang, Gongyu and Stitt, Greg and Lam, Herman and George, Alan D.},
title = {A framework for core-level modeling and design of reconfigurable computing algorithms},
year = {2009},
isbn = {9781605587219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1646461.1646465},
doi = {10.1145/1646461.1646465},
abstract = {Reconfigurable computing (RC) is rapidly becoming a vital technology for many applications, from high-performance computing to embedded systems. The inherent advantages of custom-logic hardware devices, such as the FPGA, combined with the versatility of software-driven hardware configuration often boost performance while reducing power consumption. However, compared to software design tools, the relatively immature state of RC design tools significantly limits productivity and consequently limits widespread adoption of RC. Long and tedious design-translate-execute (DTE) processes for RC applications (e.g., using RTL through HDL) must be repeated in order to meet mission requirements. Novel methods for rapid virtual prototyping and performance prediction can reduce DTE repetitions by providing fast and accurate tradeoff analysis before the design stage. This paper presents a novel core-level modeling and design (CMD) framework for RC algorithms to support fast, accurate and early design-space exploration (DSE). The framework provides support for core-level modeling, performance prediction, and rapid bridging to design and translation. Core-level modeling enables detailed DSE without the need for coding. Performance prediction, such as maximum clock frequency, supports core-level DSE and can help system-level modeling and design tools to achieve more accurate system-level DSE. Finally, core-level models can be used to generate code templates and design constraints that feed translation tools and to rapidly obtain predicted performance.},
booktitle = {Proceedings of the Third International Workshop on High-Performance Reconfigurable Computing Technology and Applications},
pages = {29–38},
numpages = {10},
location = {Portland, Oregon},
series = {HPRCTA '09}
}

@inproceedings{10.1145/1810295.1810297,
author = {Huber, Nikolaus and Becker, Steffen and Rathfelder, Christoph and Schweflinghaus, Jochen and Reussner, Ralf H.},
title = {Performance modeling in industry: a case study on storage virtualization},
year = {2010},
isbn = {9781605587196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810295.1810297},
doi = {10.1145/1810295.1810297},
abstract = {In software engineering, performance and the integration of performance analysis methodologies gain increasing importance, especially for complex systems. Well-developed methods and tools can predict non-functional performance properties like response time or resource utilization in early design stages, thus promising time and cost savings. However, as performance modeling and performance prediction is still a young research area, the methods are not yet well-established and in wide-spread industrial use. This work is a case study of the applicability of the Palladio Component Model as a performance prediction method in an industrial environment. We model and analyze different design alternatives for storage virtualization on an IBM* system. The model calibration, validation and evaluation is based on data measured on a System z9* as a proof of concept. The results show that performance predictions can identify performance bottlenecks and evaluate design alternatives in early stages of system development. The experiences gained were that performance modeling helps to understand and analyze a system. Hence, this case study substantiates that performance modeling is applicable in industry and a valuable method for evaluating design decisions.},
booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2},
pages = {1–10},
numpages = {10},
location = {Cape Town, South Africa},
series = {ICSE '10}
}

@inproceedings{10.1145/2882903.2882938,
author = {Wang, Zhigang and Gu, Yu and Bao, Yubin and Yu, Ge and Yu, Jeffrey Xu},
title = {Hybrid Pulling/Pushing for I/O-Efficient Distributed and Iterative Graph Computing},
year = {2016},
isbn = {9781450335317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2882903.2882938},
doi = {10.1145/2882903.2882938},
abstract = {Billion-node graphs are rapidly growing in size in many applications such as online social networks. Most graph algorithms generate a large number of messages during iterative computations. Vertex-centric distributed systems usually store graph data and message data on disk to improve scalability. Currently, these distributed systems with disk-resident data take a push-based approach to handle messages. This works well if few messages reside on disk. Otherwise, it is I/O-inefficient due to expensive random writes. By contrast, the existing memory-resident pull-based approach individually pulls messages for each vertex on demand. Although it can be used to avoid disk operations regarding messages, expensive I/O costs are incurred by random and frequent access to vertices.This paper proposes a hybrid solution to support switching between push and pull adaptively, to obtain optimal performance for distributed systems with disk-resident data in different scenarios. We first employ a new block-centric technique (b-pull) to improve the I/O-performance of pulling messages, although the iterative computation is vertex-centric. I/O costs of data accesses are shifted from the receiver side where messages are written/read by push to the sender side where graph data are read by b-pull. Graph data are organized by clustering vertices and edges to achieve high I/O-efficiency in b-pull. Second, we design a seamless switching mechanism and a prominent performance prediction method to guarantee efficiency when switching between push and b-pull. We conduct extensive performance studies to confirm the effectiveness of our proposals over existing up-to-date solutions using a broad spectrum of real-world graphs.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
pages = {479–494},
numpages = {16},
keywords = {push, pull, distributed graph computing, I/O-efficient},
location = {San Francisco, California, USA},
series = {SIGMOD '16}
}

@inproceedings{10.1109/SEAMS.2019.00015,
author = {Jamshidi, Pooyan and C\'{a}mara, Javier and Schmerl, Bradley and K\"{a}stner, Christian and Garlan, David},
title = {Machine learning meets quantitative planning: enabling self-adaptation in autonomous robots},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2019.00015},
doi = {10.1109/SEAMS.2019.00015},
abstract = {Modern cyber-physical systems (e.g., robotics systems) are typically composed of physical and software components, the characteristics of which are likely to change over time. Assumptions about parts of the system made at design time may not hold at run time, especially when a system is deployed for long periods (e.g., over decades). Self-adaptation is designed to find reconfigurations of systems to handle such run-time inconsistencies. Planners can be used to find and enact optimal reconfigurations in such an evolving context. However, for systems that are highly configurable, such planning becomes intractable due to the size of the adaptation space. To overcome this challenge, in this paper we explore an approach that (a) uses machine learning to find Pareto-optimal configurations without needing to explore every configuration and (b) restricts the search space to such configurations to make planning tractable. We explore this in the context of robot missions that need to consider task timeliness and energy consumption. An independent evaluation shows that our approach results in high-quality adaptation plans in uncertain and adversarial environments.},
booktitle = {Proceedings of the 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {39–50},
numpages = {12},
keywords = {self-adaptive systems, robotics systems, quantitative planning, machine learning, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {SEAMS '19}
}

@inproceedings{10.1145/2479871.2479910,
author = {Noorshams, Qais and Bruhn, Dominik and Kounev, Samuel and Reussner, Ralf},
title = {Predictive performance modeling of virtualized storage systems using optimized statistical regression techniques},
year = {2013},
isbn = {9781450316361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479871.2479910},
doi = {10.1145/2479871.2479910},
abstract = {Modern virtualized environments are key for reducing the operating costs of data centers. By enabling the sharing of physical resources, virtualization promises increased resource efficiency with decreased administration costs. With the increasing popularity of I/O-intensive applications, however, the virtualized storage used in such environments can quickly become a bottleneck and lead to performance and scalability issues. Performance modeling and evaluation techniques applied prior to system deployment help to avoid such issues. In current practice, however, virtualized storage and its performance-influencing factors are often neglected or treated as a black-box. In this paper, we present a measurement-based performance prediction approach for virtualized storage systems based on optimized statistical regression techniques. We first propose a general heuristic search algorithm to optimize the parameters of regression techniques. Then, we apply our optimization approach and create performance models using four regression techniques. Finally, we present an in-depth evaluation of our approach in a real-world representative environment based on IBM System z and IBM DS8700 server hardware. Using our optimized techniques, we effectively create performance models with less than 7% prediction error in the most typical scenario. Furthermore, our optimization approach reduces the prediction error by up to 74%.},
booktitle = {Proceedings of the 4th ACM/SPEC International Conference on Performance Engineering},
pages = {283–294},
numpages = {12},
keywords = {virtualization, storage, prediction, performance, i/o},
location = {Prague, Czech Republic},
series = {ICPE '13}
}

@inproceedings{10.1145/2207676.2208412,
author = {Gomez, Steven and Laidlaw, David},
title = {Modeling task performance for a crowd of users from interaction histories},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208412},
doi = {10.1145/2207676.2208412},
abstract = {We present TOME, a novel framework that helps developers quantitatively evaluate user interfaces and design iterations by using histories from crowds of end users. TOME collects user-interaction histories via an interface instrumentation library as end users complete tasks; these histories are compiled using the Keystroke-Level Model (KLM) into task completion-time predictions using CogTool. With many histories, TOME can model prevailing strategies for tasks without needing an HCI specialist to describe users' interaction steps. An unimplemented design change can be evaluated by perturbing a TOME task model in CogTool to reflect the change, giving a new performance prediction. We found that predictions for quick (5-60s) query tasks in an instrumented brain-map interface averaged within 10% of measured expert times. Finally, we modified a TOME model to predict closely the speed-up yielded by a proposed interaction before implementing it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2465–2468},
numpages = {4},
keywords = {user interfaces, performance modeling, klm, histories},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3377024.3377026,
author = {Kenner, Andy and Dassow, Stephan and Lausberger, Christian and Kr\"{u}ger, Jacob and Leich, Thomas},
title = {Using variability modeling to support security evaluations: virtualizing the right attack scenarios},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377026},
doi = {10.1145/3377024.3377026},
abstract = {A software system's security is constantly threatened by vulnerabilities that result from faults in the system's design (e.g., unintended feature interactions) and which can be exploited with attacks. While various databases summarize information on vulnerabilities and other security issues for many software systems, these databases face severe limitations. For example, the information's quality is unclear, often only semi-structured, and barely connected to other information. Consequently, it can be challenging for any security-related stakeholder to extract and understand what information is relevant, considering that most systems exist in different variants and versions. To tackle this problem, we propose to design vulnerability feature models that represent the vulnerabilities of a system and enable developers to virtualize corresponding attack scenarios. In this paper, we report a first case study on Mozilla Firefox for which we extracted vulnerabilities and used them to virtualize vulnerable instances in Docker. To this end, we focused on extracting information from available databases and on evaluating the usability of the results. Our findings indicate several problems with the extraction that complicate modeling, understanding, and testing of vulnerabilities. Nonetheless, the databases provide a valuable foundation for our technique, which we aim to extend with automatic synthesis and analyses of feature models, as well as virtualization for attack scenarios in future work.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {10},
numpages = {9},
keywords = {vulnerability, variability model, software architecture, feature model, exploit, docker-container, attack scenarios},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@article{10.1016/j.eswa.2005.01.006,
author = {Razi, Muhammad A. and Athappilly, Kuriakose},
title = {A comparative predictive analysis of neural networks (NNs), nonlinear regression and classification and regression tree (CART) models},
year = {2005},
issue_date = {July, 2005},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {29},
number = {1},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2005.01.006},
doi = {10.1016/j.eswa.2005.01.006},
abstract = {Numerous articles comparing performances of statistical and Neural Networks (NNs) models are available in the literature, however, very few involved Classification and Regression Tree (CART) models in their comparative studies. We perform a three-way comparison of prediction accuracy involving nonlinear regression, NNs and CART models using a continuous dependent variable and a set of dichotomous and categorical predictor variables. A large dataset on smokers is used to run these models. Different prediction accuracy measuring procedures are used to compare performances of these models. The outcomes of predictions are discussed and the outcomes of this research are compared with the results of similar studies.},
journal = {Expert Syst. Appl.},
month = jul,
pages = {65–74},
numpages = {10},
keywords = {Regression, Neural networks, Classification and regression tree}
}

@article{10.1016/j.cie.2011.11.030,
author = {Kamath, Manjunath and Srivathsan, Sandeep},
title = {A comparative evaluation of analytical approximations for analyzing production-inventory networks},
year = {2012},
issue_date = {March, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {2},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2011.11.030},
doi = {10.1016/j.cie.2011.11.030},
abstract = {Since the early 1990s, there has been an increased interest in developing analytical models for production-inventory networks, which consider queueing and planned inventory issues in a unified manner. There appears to be considerable similarity among the analytical models and approximations developed by different researchers. The purpose of this article is to clearly identify the similarities and differences among the various approaches by using a tandem production-inventory network as a test-bed. In addition, numerical experiments were performed by varying different parameters to gain better insight into the performance prediction capability of the different approximations and to rank order the different approaches.},
journal = {Comput. Ind. Eng.},
month = mar,
pages = {644–652},
numpages = {9},
keywords = {Stochastic modeling, Queueing, Pull production system, Production-inventory system, Base-stock policy}
}

@inproceedings{10.1145/3427921.3450255,
author = {Han, Xue and Yu, Tingting and Pradel, Michael},
title = {ConfProf: White-Box Performance Profiling of Configuration Options},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450255},
doi = {10.1145/3427921.3450255},
abstract = {Modern software systems are highly customizable through configuration options. The sheer size of the configuration space makes it challenging to understand the performance influence of individual configuration options and their interactions under a specific usage scenario. Software with poor performance may lead to low system throughput and long response time. This paper presents ConfProf, a white-box performance profiling technique with a focus on configuration options. ConfProf helps developers understand how configuration options and their interactions influence the performance of a software system. The approach combines dynamic program analysis, machine learning, and feedback-directed configuration sampling to profile the program execution and analyze the performance influence of configuration options. Compared to existing approaches, ConfProf uses a white-box approach combined with machine learning to rank performance-influencing configuration options from execution traces. We evaluate the approach with 13 scenarios of four real-world, highly-configurable software systems. The results show that ConfProf ranks performance-influencing configuration options with high accuracy and outperform a state of the art technique.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {1–8},
numpages = {8},
keywords = {software performance, performance profiling},
location = {Virtual Event, France},
series = {ICPE '21}
}

@article{10.1016/j.aei.2012.03.005,
author = {Chi, Seokho and Suk, Sung-Joon and Kang, Youngcheol and Mulva, Stephen P.},
title = {Development of a data mining-based analysis framework for multi-attribute construction project information},
year = {2012},
issue_date = {August, 2012},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {26},
number = {3},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2012.03.005},
doi = {10.1016/j.aei.2012.03.005},
abstract = {Data mining techniques extract repeated and useful patterns from a large data set that in turn are utilized to predict the outcome of future events. The main purpose of the research presented in this paper is to investigate data mining strategies and develop an efficient framework for multi-attribute project information analysis to predict the performance of construction projects. The research team first reviewed existing data mining algorithms, applied them to systematically analyze a large project data set collected by the survey, and finally proposed a data-mining-based decision support framework for project performance prediction. To evaluate the potential of the framework, a case study was conducted using data collected from 139 capital projects and analyzed the relationship between use of information technology and project cost performance. The study results showed that the proposed framework has potential to promote fast, easy to use, interpretable, and accurate project data analysis.},
journal = {Adv. Eng. Inform.},
month = aug,
pages = {574–581},
numpages = {8},
keywords = {Qualitative project information acquisition, Project performance analysis, Multi-attribute survey, Construction data mining}
}

@inproceedings{10.1145/2339530.2339732,
author = {Shen, Yelong and Jin, Ruoming},
title = {Learning personal + social latent factor model for social recommendation},
year = {2012},
isbn = {9781450314626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2339530.2339732},
doi = {10.1145/2339530.2339732},
abstract = {Social recommendation, which aims to systematically leverage the social relationships between users as well as their past behaviors for automatic recommendation, attract much attention recently. The belief is that users linked with each other in social networks tend to share certain common interests or have similar tastes (homophily principle); such similarity is expected to help improve the recommendation accuracy and quality. There have been a few studies on social recommendations; however, they almost completely ignored the heterogeneity and diversity of the social relationship.In this paper, we develop a joint personal and social latent factor (PSLF) model for social recommendation. Specifically, it combines the state-of-the-art collaborative filtering and the social network modeling approaches for social recommendation. Especially, the PSLF extracts the social factor vectors for each user based on the state-of-the-art mixture membership stochastic blockmodel, which can explicitly express the varieties of the social relationship. To optimize the PSLF model, we develop a scalable expectation-maximization (EM) algorithm, which utilizes a novel approximate mean-field technique for fast expectation computation. We compare our approach with the latest social recommendation approaches on two real datasets, Flixter and Douban (both with large social networks). With similar training cost, our approach has shown a significant improvement in terms of prediction accuracy criteria over the existing approaches.},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1303–1311},
numpages = {9},
keywords = {social recommender system, personal + social factor},
location = {Beijing, China},
series = {KDD '12}
}

@article{10.1016/j.eswa.2012.10.018,
author = {Kalsyte, Zivile and Verikas, Antanas and Bacauskiene, Marija and Gelzinis, Adas},
title = {A novel approach to designing an adaptive committee applied to predicting company's future performance},
year = {2013},
issue_date = {May, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {6},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2012.10.018},
doi = {10.1016/j.eswa.2012.10.018},
abstract = {Highlights We present a novel technique to create adaptive committees of models. SOM enables building committees, specific for each data point analyzed. Adaptive committees were significantly more accurate than committees of other types. This article presents an approach to designing an adaptive, data dependent, committee of models applied to prediction of several financial attributes for assessing company's future performance. Current liabilities/Current assets, Total liabilities/Total assets, Net income/Total assets, and Operating Income/Total liabilities are the attributes used in this paper. A self-organizing map (SOM) used for data mapping and analysis enables building committees, which are specific (committee size and aggregation weights) for each SOM node. The number of basic models aggregated into a committee and the aggregation weights depend on accuracy of basic models and their ability to generalize in the vicinity of the SOM node. A random forest is used a basic model in this study. The developed technique was tested on data concerning companies from ten sectors of the healthcare industry of the United States and compared with results obtained from averaging and weighted averaging committees. The proposed adaptivity of a committee size and aggregation weights led to a statistically significant increase in prediction accuracy if compared to other types of committees.},
journal = {Expert Syst. Appl.},
month = may,
pages = {2051–2057},
numpages = {7},
keywords = {SOM, Random forest, Financial attribute, Data proximity, Committee}
}

@inproceedings{10.1145/2661829.2661931,
author = {Wu, Hao and Fang, Hui},
title = {Analytical Performance Modeling for Top-K Query Processing},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661931},
doi = {10.1145/2661829.2661931},
abstract = {Top-K query processing is one of the most important problems in large-scale Information Retrieval systems. Since query processing time varies for different queries, an accurate run-time performance prediction is critical for online query scheduling and load balancing, which could eventually reduce the query waiting time and improve the throughput. Previous studies estimated the query processing time based on the combination of term-level features. Unfortunately, these features were often selected arbitrarily, and the linear combination of these features might not be able to accurately capture the complexity in the query processing.In this paper, we propose a novel analytical performance modeling framework for top-K query processing. Our goal is to provide a systematic way of identifying important features for the efficiency prediction and then develop a general framework for estimating the query processing time. Specifically, we divide the query processing into three stages, identify useful features and discuss how to use them to model the query processing time for each stage. After that, we propose to fit the model using a step-by-step strategy and compute the approximated feature values based on easily obtained statistics. Experimental results on TREC collections show that the developed performance model can predict the query processing time more accurately than the state of the art efficiency predictor, in particular for the dynamic pruning methods.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1619–1628},
numpages = {10},
keywords = {efficiency prediction, performance modeling, top-k query processing},
location = {Shanghai, China},
series = {CIKM '14}
}

@article{10.1007/s11280-012-0179-z,
author = {Liu, Yang and Yu, Xiaohui and An, Aijun and Huang, Xiangji},
title = {Riding the tide of sentiment change: sentiment analysis with evolving online reviews},
year = {2013},
issue_date = {July      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {1386-145X},
url = {https://doi.org/10.1007/s11280-012-0179-z},
doi = {10.1007/s11280-012-0179-z},
abstract = {The last decade has seen a rapid growth in the volume of online reviews. A great deal of research has been done in the area of opinion mining, aiming at analyzing the sentiments expressed in those reviews towards products and services. Most of the such work focuses on mining opinions from a collection of reviews posted during a particular period, and does not consider the change in sentiments when the collection of reviews evolve over time. In this paper, we fill in this gap, and study the problem of developing adaptive sentiment analysis models for online reviews. Given the success of latent semantic modeling techniques, we propose two adaptive methods to capture the evolving sentiments. As a case study, we also investigate the possibility of using the extracted adaptive patterns for sales prediction. Our proposal is evaluated on an IMDB dataset consisting of reviews of selected movies and their box office revenues. Experimental results show that the adaptive methods can capture sentiment changes arising from newly available reviews, which helps greatly improve the prediction accuracy.},
journal = {World Wide Web},
month = jul,
pages = {477–496},
numpages = {20},
keywords = {sentiment analysis, opinion mining, adaptive algorithm}
}

@article{10.1007/s10844-020-00632-7,
author = {Li, Cheng-Te and Chen, Hsin-Yu and Zhang, Yang},
title = {On exploring feature representation learning of items to forecast their rise and fall in social media},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {3},
issn = {0925-9902},
url = {https://doi.org/10.1007/s10844-020-00632-7},
doi = {10.1007/s10844-020-00632-7},
abstract = {User-item interactions in social media provide a rich dataset for wide applications such as viral marketing and recommender systems. Post retweeting behaviors and venue check-in events by users are the most representative. While existing studies predict items’ rise and fall, i.e., tweet popularity and venue closure detection, using hand-crafted features, this paper aims at exploring feature representation learning to improve prediction performance. We target at two essential time-series classification tasks on social media, including Shutdown Risk Prediction (SRP) of venues and Tweet Popularity Prediction (TPP) of posts. We study how feature representation learning of items can benefit both SRP and TPP tasks. The main idea is to learn item embedding vectors as features in item-item graphs constructed from time series of check-in events and retweeting behaviors. The learned features are used together with manually-defined features to enlarge the representation capability. In the TPP task, we also propose a pattern-aware self-exciting point process (PSEISMIC) model to generate time-series features. Experiments conducted on Instagram, Foursquare, and Twitter datasets exhibit promising performance of jointly utilizing learned and extracted features in both tasks. PSEISMIC can also further boost TPP accuracy. The major contribution of this work is three-fold. First, we propose to jointly deal with SRP and TPP under the same framework of feature extraction and learning. Second, we show that feature presentation learning of items can benefit these two prediction tasks with time series data. Third, by incorporating time series patterns, the proposed PSEISMIC further improves the performance of popularity prediction.},
journal = {J. Intell. Inf. Syst.},
month = jun,
pages = {409–433},
numpages = {25},
keywords = {Tweet popularity prediction, Shutdown risk prediction, Feature representation learning, Social media}
}

@article{10.1007/s10664-015-9410-8,
author = {Unterkalmsteiner, Michael and Gorschek, Tony and Feldt, Robert and Lavesson, Niklas},
title = {Large-scale information retrieval in software engineering - an experience report from industrial application},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9410-8},
doi = {10.1007/s10664-015-9410-8},
abstract = {Software Engineering activities are information intensive. Research proposes Information Retrieval (IR) techniques to support engineers in their daily tasks, such as establishing and maintaining traceability links, fault identification, and software maintenance. We describe an engineering task, test case selection, and illustrate our problem analysis and solution discovery process. The objective of the study is to gain an understanding of to what extent IR techniques (one potential solution) can be applied to test case selection and provide decision support in a large-scale, industrial setting. We analyze, in the context of the studied company, how test case selection is performed and design a series of experiments evaluating the performance of different IR techniques. Each experiment provides lessons learned from implementation, execution, and results, feeding to its successor. The three experiments led to the following observations: 1) there is a lack of research on scalable parameter optimization of IR techniques for software engineering problems; 2) scaling IR techniques to industry data is challenging, in particular for latent semantic analysis; 3) the IR context poses constraints on the empirical evaluation of IR techniques, requiring more research on developing valid statistical approaches. We believe that our experiences in conducting a series of IR experiments with industry grade data are valuable for peer researchers so that they can avoid the pitfalls that we have encountered. Furthermore, we identified challenges that need to be addressed in order to bridge the gap between laboratory IR experiments and real applications of IR in the industry.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {2324–2365},
numpages = {42},
keywords = {Test case selection, Information retrieval, Experiment, Data mining}
}

@article{10.1016/j.compeleceng.2021.107215,
author = {Ardagna, Claudio A. and Bellandi, Valerio and Damiani, Ernesto and Bezzi, Michele and Hebert, Cedric},
title = {Big Data Analytics-as-a-Service: Bridging the gap between security experts and data scientists},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {93},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107215},
doi = {10.1016/j.compeleceng.2021.107215},
journal = {Comput. Electr. Eng.},
month = jul,
numpages = {10},
keywords = {Security and privacy, Machine learning, Big Data Analytics, Artificial intelligence}
}

@article{10.1016/j.eswa.2011.12.028,
author = {Kang, Pilsung and Cho, Sungzoon and MacLachlan, Douglas L.},
title = {Improved response modeling based on clustering, under-sampling, and ensemble},
year = {2012},
issue_date = {June, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {39},
number = {8},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.12.028},
doi = {10.1016/j.eswa.2011.12.028},
abstract = {The purpose of response modeling for direct marketing is to identify those customers who are likely to purchase a campaigned product, based upon customers' behavioral history and other information available. Contrary to mass marketing strategy, well-developed response models used for targeting specific customers can contribute profits to firms by not only increasing revenues, but also lowering marketing costs. Endemic in customer data used for response modeling is a class imbalance problem: the proportion of respondents is small relative to non-respondents. In this paper, we propose a novel data balancing method based on clustering, under-sampling, and ensemble to deal with the class imbalance problem, and thus improve response models. Using publicly available response modeling data sets, we compared the proposed method with other data balancing methods in terms of prediction accuracy and profitability. To investigate the usability of the proposed algorithm, we also employed various prediction algorithms when building the response models. Based on the response rate and profit analysis, we found that our proposed method (1) improved the response model by increasing response rate as well as reducing performance variation, and (2) increased total profit by significantly boosting revenue.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {6738–6753},
numpages = {16},
keywords = {Response modeling, Ensemble, Direct marketing, Data balancing, Clustering, Class imbalance, CRM}
}

@inproceedings{10.5555/1299133.1299587,
author = {Ogor, Emmanuel N.},
title = {Student Academic Performance Monitoring and Evaluation Using Data Mining Techniques},
year = {2007},
isbn = {0769529747},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Assessment as a dynamic process produces data that reasonable conclusions are derived by stakeholders for decision making that expectedly impact on students' learning outcomes. The data mining methodology while extracting useful, valid patterns from higher education database environment contribute to proactively ensuring students maximize their academic output. This paper develops a methodology by the derivation of performance prediction indicators to deploying a simple student performance assessment and monitoring system within a teaching and learning environment by mainly focusing on performance monitoring of students' continuous assessment (tests) and examination scores in order to predict their final achievement status upon graduation. Based on various data mining techniques (DMT) and the application of machine learning processes, rules are derived that enable the classification of students in their predicted classes. The deployment of the prototyped solution, integrates measuring, "recycling' and reporting procedures in the new system to optimize prediction accuracy.},
booktitle = {Proceedings of the Electronics, Robotics and Automotive Mechanics Conference},
pages = {354–359},
numpages = {6},
keywords = {stakeholders, performance monitoring, decision rules, assessment, KD, DMT, DM},
series = {CERMA '07}
}

@inproceedings{10.5555/1928328.1928355,
author = {P\'{e}rez-Iglesias, Joaqu\'{\i}n and Araujo, Lourdes},
title = {Standard deviation as a query hardness estimator},
year = {2010},
isbn = {3642163203},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper a new Query Performance Prediction method is introduced. This method is based on the hypothesis that different score distributions appear for 'hard' and 'easy' queries. Following we propose a set of measures which try to capture the differences between both types of distributions, focusing on the dispersion degree among the scores. We have applied some variants of the classic standard deviation and have studied methods to find out the most suitable size of the ranking list for these measures. Finally, we present the results obtained performing the experiments on two different data-sets.},
booktitle = {Proceedings of the 17th International Conference on String Processing and Information Retrieval},
pages = {207–212},
numpages = {6},
location = {Los Cabos, Mexico},
series = {SPIRE'10}
}

@article{10.1007/s10270-015-0512-y,
author = {Linsbauer, Lukas and Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
title = {Variability extraction and modeling for product variants},
year = {2017},
issue_date = {October   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0512-y},
doi = {10.1007/s10270-015-0512-y},
abstract = {Fast-changing hardware and software technologies in addition to larger and more specialized customer bases demand software tailored to meet very diverse requirements. Software development approaches that aim at capturing this diversity on a single consolidated platform often require large upfront investments, e.g., time or budget. Alternatively, companies resort to developing one variant of a software product at a time by reusing as much as possible from already-existing product variants. However, identifying and extracting the parts to reuse is an error-prone and inefficient task compounded by the typically large number of product variants. Hence, more disciplined and systematic approaches are needed to cope with the complexity of developing and maintaining sets of product variants. Such approaches require detailed information about the product variants, the features they provide and their relations. In this paper, we present an approach to extract such variability information from product variants. It identifies traces from features and feature interactions to their implementation artifacts, and computes their dependencies. This work can be useful in many scenarios ranging from ad hoc development approaches such as clone-and-own to systematic reuse approaches such as software product lines. We applied our variability extraction approach to six case studies and provide a detailed evaluation. The results show that the extracted variability information is consistent with the variability in our six case study systems given by their variability models and available product variants.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1179–1199},
numpages = {21},
keywords = {Variability, Trace, Product variant, Feature, Dependency}
}

@inproceedings{10.5555/2971808.2971919,
author = {Zhang, Sai and Shanbhag, Naresh R.},
title = {Probabilistic error models for machine learning kernels implemented on stochastic nanoscale fabrics},
year = {2016},
isbn = {9783981537062},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Presented in this paper are probabilistic error models for machine learning kernels implemented on low-SNR circuit fabrics where errors arise due to voltage overscaling (VOS), process variations, or defects. Four different variants of the additive error model are proposed that describe the error probability mass function (PMF): additive over Reals Error Model with independent Bernoulli RVs (REM-i), additive over Reals Error Model with joint Bernoulli random variables (RVs) (REM-j), additive over Galois field Error Model with independent Bernoulli RVs (GEM-i), and additive over Galois field Error Model with joint Bernoulli RVs (GEM-j). Analytical expressions for the error PMF is derived. Kernel level model validation is accomplished by comparing the Jensen-Shannon divergence DJS between the modeled PMF and the PMFs obtained via HDL simulations in a commercial 45nm CMOS process of MAC units used in a 2nd order polynomial support vector machine (SVM) to classify data from the UCI machine learning repository. Results indicate that at the MAC unit level, DJS for the GEM-j models are 1-to-2-orders-of-magnitude lower (better) than the REM models for VOS and process variation errors. However, when considering errors due to defects, DJS for REM-j is between 1-to-2-orders-of-magnitude lower than the others. Performance prediction of the SVM using these models indicate that when compared with Monte Carlo with HDL generated error statistics, probability of detection pdet estimated using GEM-j is within 3% for VOS error when the error rate pη ≤ 80%, and within 5% for process variation error when supply voltage Vdd is between 0.3 V and 0.7 V. In addition, pdet using REM-j is within 2% for defect errors when the defect rate (the percentage of circuit nets subject to stuck-at-faults) psaf is between 10-3 and 0.2.},
booktitle = {Proceedings of the 2016 Conference on Design, Automation &amp; Test in Europe},
pages = {481–486},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '16}
}

@article{10.1109/TPDS.2010.92,
author = {Rao, Jia and Xu, Cheng-Zhong},
title = {Online Capacity Identification of Multitier Websites Using Hardware Performance Counters},
year = {2011},
issue_date = {March 2011},
publisher = {IEEE Press},
volume = {22},
number = {3},
issn = {1045-9219},
url = {https://doi.org/10.1109/TPDS.2010.92},
doi = {10.1109/TPDS.2010.92},
abstract = {Understanding server capacity is crucial to system capacity planning, configuration, and QoS-aware resource management. Conventional stress testing approaches measure server capacity offline in terms of application-level performance metrics like response time and throughput. They are limited in measurement accuracy and timeliness. In a multitier website, resource bottleneck often shifts between tiers as client access pattern changes. This makes the problem of online capacity measurement even more challenge. This paper presents an online measurement approach based on low-level hardware performance metrics such as instructions execution rate and cache access behavior. Such metrics together define a system internal running state. The measurement approach uses machine learning techniques to infer application-level performance at each tier from a set of selected hardware performance counters. A coordinated predictor is induced over individual tier-wide models to make global system performance prediction and identify the bottleneck when the system becomes overloaded. Experiments were conducted on a two-tier Tomcat/MySQL-configured website using TPC-W benchmarks. Experimental results demonstrated that this approach was able to achieve an overload prediction accuracy of higher than 90 percent for a priori known input traffic mix and over 85 percent accuracy even for traffic causing frequent bottleneck shifting. It costs less than 0.5 percent runtime overhead for data collection and no more than 50 ms for each online decision making.},
journal = {IEEE Trans. Parallel Distrib. Syst.},
month = mar,
pages = {426–438},
numpages = {13},
keywords = {machine learning, hardware performance counter., Multitier website, machine learning, hardware performance counter., Multitier website}
}

@inproceedings{10.1145/3477244.3477985,
author = {van der Sanden, Bram and Li, Yonghui and van den Aker, Joris and Akesson, Benny and Bijlsma, Tjerk and Hendriks, Martijn and Triantafyllidis, Kostas and Verriet, Jacques and Voeten, Jeroen and Basten, Twan},
title = {Model-driven system-performance engineering for cyber-physical systems},
year = {2021},
isbn = {9781450387125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477244.3477985},
doi = {10.1145/3477244.3477985},
abstract = {System-Performance Engineering (SysPE) encompasses modeling formalisms, methods, techniques, and industrial practices to design systems for performance, where performance is taken integrally into account during the whole system life cycle. Industrial SysPE state of practice is generally model-based. Due to the rapidly increasing complexity of systems, there is a need to develop and establish model-driven methods and techniques. To structure the field of SysPE, we identify (1) industrial challenges motivating the importance of SysPE, (2) scientific challenges that need to be addressed to establish model-driven SysPE, (3) important focus areas for SysPE and (4) best practices. We conducted a survey to collect feedback on our views. The responses were used to update and validate the identified challenges, focus areas, and best practices. The final result is presented in this paper. Interesting observations are that industry sees a need for better design-space exploration support, more than for additional performance modeling and analysis techniques. Also tools and integral methods for SysPE need attention. From the identified focus areas, scheduling and supervisory control is seen as lacking established best practices.},
booktitle = {Proceedings of the 2021 International Conference on Embedded Software},
pages = {11–22},
numpages = {12},
keywords = {system-performance engineering, model-driven design, CPS},
location = {Virtual Event},
series = {EMSOFT '21}
}

@inproceedings{10.1145/2675744.2675767,
author = {Sarkar, Santonu and Mitra, Sayantan},
title = {Execution profile driven speedup estimation for porting sequential code to GPU},
year = {2014},
isbn = {9781605588148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675744.2675767},
doi = {10.1145/2675744.2675767},
abstract = {Parallelization of an existing sequential application to achieve a good speed-up on a data-parallel infrastructure is quite difficult and time consuming effort. One of the important steps towards this is to assess whether the existing application in its current form can be parallelized to get the desired speedup. In this paper, we propose a method of analyzing an existing sequential source code that contains data-parallel loops, and give a reasonably accurate prediction of the extent of speedup possible from this algorithm. The proposed method performs static and dynamic analysis of the sequential source code to determine the time required by various portions of the code, including the data-parallel portions. Subsequently, it uses a set of novel invariants to calculate various bottlenecks that exists if the program is to be transferred to a GPGPU platform and predicts the extent of parallelization necessary by the GPU in order to achieve the desired end-to-end speedup. Our approach does not require creation of GPU code skeletons of the data parallel portions in the sequential code, thereby reducing the performance prediction effort. We observed a reasonably accurate speedup prediction when we tested our approach on multiple well-known Rodinia benchmark applications, a popular matrix multiplication program and a fast Walsh transform program.},
booktitle = {Proceedings of the 7th ACM India Computing Conference},
articleno = {21},
numpages = {6},
keywords = {warp, speedup estimation, instrumentation, data transfer, code analysis, SIMT, GPU},
location = {Nagpur, India},
series = {COMPUTE '14}
}

@inproceedings{10.1145/2739482.2768422,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley K.G. and Fischer, Stefan and Vergilio, Silvia R. and Egyed, Alexander},
title = {Genetic Improvement for Software Product Lines: An Overview and a Roadmap},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2768422},
doi = {10.1145/2739482.2768422},
abstract = {Software Product Lines (SPLs) are families of related software systems that provide different combinations of features. Extensive research and application attest to the significant economical and technological benefits of employing SPL practices. However, there are still several challenges that remain open. Salient among them is reverse engineering SPLs from existing variants of software systems and their subsequent evolution. In this paper, we aim at sketching connections between research on these open SPL challenges and ongoing work on Genetic Improvement. Our hope is that by drawing such connections we can spark the interest of both research communities on the exciting synergies at the intersection of these subject areas.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {823–830},
numpages = {8},
keywords = {variability, software product lines, genetic programming, genetic improvement, evolutionary algorithms},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@article{10.1007/s10845-013-0808-0,
author = {Hsu, Chia-Yu},
title = {Integrated data envelopment analysis and neural network model for forecasting performance of wafer fabrication operations},
year = {2014},
issue_date = {Oct 2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {5},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-013-0808-0},
doi = {10.1007/s10845-013-0808-0},
abstract = {With the rapid change of manufacturing environments, semiconductor fabricators are forced to make continuous investments in advanced technology to maintain their competitive advantage. Wafer fabrication (fab) performance evaluations are important for examining past operations such as the capacity and resource allocation. In addition, forecasting provides useful information for what-if analyses to anticipate useful strategies early to avoid potential losses. However, the integration of performance evaluation and forecast based on a consideration of the relative performance along the time horizon has rarely been addressed. In particular, the part of performance evaluation is to generate the relative performance in a period with rolling data. Then, the forecast part is to build a model for performance prediction based on the result of present performance. This study aimed to construct a performance forecast model by integrating data envelopment analysis and a back-propagation neural network for performance evaluation and forecast, respectively. Empirical data from a leading semiconductor company in Taiwan was used to test the proposed model. The results provide basic information and early alarms to adjust the resource allocation before the future performance declines. The empirical analysis demonstrated the practical feasibility of the proposed approach.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {945–960},
numpages = {16},
keywords = {Semiconductor manufacturing, Performance of fab operation, Forecast, Data envelopment analysis (DEA), Back-propagation neural network (BPNN)}
}

@phdthesis{10.5555/AAI28772957,
author = {Arafa, Yehia and Jonathan, Cook, and Phillip, DeLeon, and Stephan, Eidenbenz, and Wei, Tang, and Nandakishore, Santhi,},
advisor = {A, Badawy, Abdel-Hameed},
title = {Performance Modeling and Prediction of Contemporary GPU Architectures},
year = {2021},
isbn = {9798762193887},
publisher = {New Mexico State University},
address = {USA},
abstract = {he ending of Moore's law and Dennard scaling (MOSFET scaling) law has shifted the focus of academia and industry towards hardware accelerators and domain-specific architectures (DSA). Specialized hardware components are increasingly infused at the various computing levels. In particular, graphics processor units (GPUs) are now considered the most common hardware used to accelerate scientific computations at all scales, from embedded to exascale systems. The increasing computational demands in areas like high-performance computing (HPC), machine learning (ML) and specifically deep learning (DL), computational molecular dynamics (CFD), and big data analytics have pushed GPUs over the top in popularity and versatility way beyond gaming.The broader use of GPUs has motivated the research community to invest in developing modeling and simulation (ModSim) tools. Such tools are critical in exploring the design space of the hardware. It also guides architects and developers in optimizing their applications' performance by doing performance characterizations and sensitivity analysis on the workloads. However, with complexities found in the microarchitecture of various GPU architectures, having a fast and accurate ModSim is a non-trivial task. The currently available models represent good progress. Nevertheless, they are either limited to a specific GPU generation, very slow, focus on a particular hardware component, or lack prediction accuracy. A verified GPU performance model is still an open problem in terms of accuracy, comprehensiveness, and scalability.This dissertation solves the limitations in the current ModSim tools by presenting PPT-GPU, Performance Prediction Toolkit for GPUs. PPT-GPU is a comprehensive end-to-end modeling tool that predicts the performance of contemporary GPU architectures without scarifying the accuracy of prediction or the speed of simulation.PPT-GPU achieves scalability through a hybrid high-level modeling approach where some computations are extrapolated, and multiple parts of the model are parallelized. More specifically, we use parallel discrete event simulation (PDES) and process-based parallelism to scale and speed up the simulations. PPT-GPU predictions models use pre-collected memory and instructions traces of the workloads to accurately predict the performance, capturing the kernels' dynamic effects.To verify the accuracy of the PPT-GPU, we use a broad set of benchmarks and compare the prediction results against actual hardware metrics collected using the vendor's profiling tools. Furthermore, we compare the results against state-of-the-art cycle-accurate simulators. PPT-GPU reports an extensive array of GPU performance metrics similar to those reported by the profiling tools while being quickly extensible to accommodate future updates in the GPU microarchitecture. Compared to silicon, the prediction results show that PPT-GPU produces highly correlated pre- dictions. The mean absolute percentage error (MAPE) for the cycles predictions is 13.57% and 22.84% for the Volta Tesla V100 GPU and the Turing TITAN RTX GPU, respectively. The rest of the performance metrics predictions are also highly correlated, with a Pearson Correlation of more than 0.97. Furthermore, the tool is orders of magnitude faster (1300x)) than the other simulators while maintaining high accuracy. More specifically, a projection of a hundred runs on cycle-accurate simulators can take up to 2 years to finish execution. It would only take nine hours on PPT-GPU.This dissertation's second contribution is a low overhead and portable analysis to measure NVIDIA GPU instructions latencies in cycles via microbenchmarking. We provide an exhaustive comparison of all the instructions found in the NVIDIA instruction set architecture(s) (ISA). This analysis is done on various NVIDIA GPU generations. The instructions cycles latency is an essential component of the PPT-GPU prediction methodology. In the third contribution, we extended the instructions cycle latency analysis to measure the instructions' energy consumption. We used different software measuring approaches to measure the energy and compared them to a custom in-house designed hardware measuring setup.The scalability of the tool enables conducting efficient sensitivity analyses for performance- critical applications. We point out some use cases for PPT-GPU by showing examples of how the tool can be used in the early design space explorations of the GPU architectures and the sensitivity analysis of the workloads, which cannot be done on the actual hardware.},
note = {AAI28772957}
}

@inproceedings{10.1109/SPDP.1994.346118,
author = {Bruck and de Coster and Dewulf and Ching-Tien Ho and Lauwereins},
title = {On the design and implementation of broadcast and global combine operations using the postal model},
year = {1994},
isbn = {0818664274},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPDP.1994.346118},
doi = {10.1109/SPDP.1994.346118},
abstract = {Two models for message passing parallel systems are the postal model and its generalization, the LogP model. In the postal model a parameter /spl lambda/ is used to model the communication latency of the message-passing system. Each node during each round can send a fixed-size message and simultaneously, receive a message of the same size. Furthermore, a message sent out during round r will incur a latency of /spl lambda/ and will arrive at the receiving node at round r+/spl lambda/-1. The goal of the article is to bridge the gap between the theoretical modeling and the practical implementation. In particular we investigate a number of practical issues related to the design and implementation of two collective communication operations, namely, the broadcast operation, and the global combine operation. Those practical issues include, for example: techniques for measurement of the value of /spl lambda/ on a given machine; creating efficient broadcast algorithms that get the latency /spl lambda/ and the number of nodes n as parameters; and creating efficient global combine algorithms for parallel machines with /spl lambda/ which is not an integer. We propose solutions that address those practical issues and present results of an experimental study of the new algorithms on the Intel Delta machine. The main conclusion is that the postal model can help in performance prediction and tuning, for example, a properly tuned broadcast improves the known implementation by more than 20%.},
booktitle = {Proceedings of the 1994 6th IEEE Symposium on Parallel and Distributed Processing},
pages = {594–602},
numpages = {9},
keywords = {theoretical modeling, postal model, performance prediction, parallel machines, message passing parallel systems, latency, global combine operations, fixed-size message, communication latency, collective communication operations, broadcast algorithms, LogP model, Intel Delta machine},
series = {SPDP '94}
}

@inproceedings{10.1007/978-3-030-89363-7_28,
author = {Dai, Huan and Zhang, Yupei and Yun, Yue and Shang, Xuequn},
title = {An Improved Deep Model for Knowledge Tracing and Question-Difficulty Discovery},
year = {2021},
isbn = {978-3-030-89362-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89363-7_28},
doi = {10.1007/978-3-030-89363-7_28},
abstract = {Knowledge Tracing (KT) aims to analyze a student’s acquisition of skills over time by examining the student’s performance on questions of those skills. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods. However, DKT and its variants often lead to oscillation results on a skill’s state may due to it ignoring the skill’s difficulty or the question’s difficulty. As a result, even when a student performs well on a skill, the prediction of that skill’s mastery level decreases instead, and vice versa. This is undesirable and unreasonable because student’s performance is expected to transit gradually over time. In this paper, we propose to learn the knowledge tracing model in a “simple-to-difficult” process, leading to a method of Self-paced Deep Knowledge Tracing (SPDKT). SPDKT learns the difficulty of per question from the student’s responses to optimize the question’s order and smooth the learning process. With mitigating the cause of oscillations, SPDKT has the capability of robustness to the puzzling questions. The experiments on real-world datasets show SPDKT achieves state-of-the-art performance on question response prediction and reaches interesting interpretations in education.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part II},
pages = {362–375},
numpages = {14},
keywords = {Personalized education, Deep learning, Self-paced learning, Knowledge tracing},
location = {Hanoi, Vietnam}
}

@article{10.1016/j.knosys.2017.09.041,
author = {Jiang, He and Dong, Yao},
title = {Dimension reduction based on a penalized kernel support vector machine model},
year = {2017},
issue_date = {December 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {138},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2017.09.041},
doi = {10.1016/j.knosys.2017.09.041},
abstract = {Penalized Kernel Support Vector machines (PKSVM) model combined with Support Vector Information Criterion (SVMIC) is proposed.We reformulate the PKSVM model as a linear-in-the-parameters problem.We derive a PKSVM+SVMIC algorithm which is easy to implement and computational efficient.Both 10-fold Cross Validation and Support Vector Information Criterion are utilized to optimize the model parameters.The experiment reveals that our developed models get better performance. Prediction and dimension reduction play increasingly significant roles in high-dimensional data analysis; however, they suffer from model inaccuracy, selection inconsistency and a prohibitively expensive computational cost as the model dimension increases exponentially. Although a support vector machine (SVM) is one of the most powerful forecasting approaches that are widely used by the research community, it does not provide an interpretable model that violates the principle of Occams razor. In classical regression problems, a penalized linear SVM model for the dimension reduction task has been investigated in the linear feature space under the assumption that the underlying true model is linear. In this paper, the penalized kernel SVM (PKSVM) model is proposed and investigated combining with a SVM information criterion (SVMIC) for the dimension reduction task in the nonlinear kernel space using radial basis function for prediction and model representation. Instead of pursuing sparsity in the original feature space of the SVM, dimension reduction is performed in the kernel feature space. Computationally, a fast and simple-to-implement algorithm is derived. Furthermore, both SVMIC and cross-validation are utilized to select the kernel and regularization parameters to guarantee the model consistency. Real data applications including microarray data analysis and global solar radiation forecasting are provided. The first application selected significant components in genetic study and the important data information is extracted for grid-connected photovoltaic installations in the second application. The proposed dimension reduction technique avoids the model redundancy which is of great importance for knowledge discovery.},
journal = {Know.-Based Syst.},
month = dec,
pages = {79–90},
numpages = {12},
keywords = {SVMIC, SVM, PKSVM, Dimension reduction}
}

@article{10.1016/j.cor.2016.07.011,
author = {Srivathsan, Sandeep and Kamath, Manjunath},
title = {Performance modeling of a two-echelon supply chain under different levels of upstream inventory information sharing},
year = {2017},
issue_date = {January 2017},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {77},
number = {C},
issn = {0305-0548},
url = {https://doi.org/10.1016/j.cor.2016.07.011},
doi = {10.1016/j.cor.2016.07.011},
abstract = {The advancement in information technology has facilitated the sharing of information in supply chain networks (SCNs), resulting in effective management of inventory and storage capacity. In this paper, our focus is on upstream inventory information sharing. Existing analytical performance evaluation models of SCNs are not capable of assessing the impact of inventory information sharing. To address this need, we develop performance evaluation models of SCNs that explicitly consider production capacity, inventory related decisions, variability, transit delays and inventory information sharing in a unified manner. We employ a two-echelon SCN configuration with two retail stores and two production facilities as a test bed. The retail stores have inventory information from the production facilities. We model three levels of inventory information sharing in our study; the information shared ranges from the stock-out information at the lowest level to inventory and backorder level information at the highest level. We develop analytical models first for Poisson arrivals and exponential processing times under all levels of inventory information sharing. We extend these models to general inter-arrival and processing time distributions and subsequently include transit delays between the production facilities and the retail stores. We demonstrate the performance prediction capability of the analytical models developed via extensive numerical experimentation. HighlightsWe focus on modeling inventory information sharing in supply chains.We model capacity, inventory, transit delay, and variability in a unified manner.Models show the marginal benefits of sharing additional inventory information.Models accurately capture trend in performance change as parameters are varied.High variability in the arrival process or service times has a dominating effect.},
journal = {Comput. Oper. Res.},
month = jan,
pages = {210–225},
numpages = {16},
keywords = {Supply chain network, Queueing models, Inventory information sharing, Base-stock policy}
}

@inproceedings{10.1007/978-3-642-11950-7_17,
author = {Schindewolf, Martin and Kramer, David and Cintra, Marcelo},
title = {Compiler-Directed performance model construction for parallel programs},
year = {2010},
isbn = {3642119492},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-11950-7_17},
doi = {10.1007/978-3-642-11950-7_17},
abstract = {During the last decade, performance prediction for industrial and scientific workloads on massively parallel high-performance computing systems has been and still is an active research area. Due to the complexity of applications, the approach to deriving an analytical performance model from current workloads becomes increasingly challenging: automatically generated models often suffer from inaccurate performance prediction; manually constructed analytical models show better prediction, but are very labor-intensive. Our approach aims at closing the gap between compiler-supported automatic model construction and the manual analytical modeling of workloads. Commonly, performance-counter values are used to validate the model, so that prediction errors can be determined and quantified. Instead of manually instrumenting the executable for accessing performance counters, we modified the GCC compiler to insert calls to run-time system functions. Added compiler options enable the user to control the instrumentation process. Subsequently, the instrumentation focuses on frequently executed code parts. Similar to established frameworks, a run-time system is used to track the application behavior: traces are generated at run-time, enabling the construction of architecture independent models (using quadratic programming) and, thus, the prediction of larger workloads. In this paper, we introduce our framework and demonstrate its applicability to benchmarks as well as real world numerical workloads. The experiments reveal an average error rate of 9% for the prediction of larger workloads.},
booktitle = {Proceedings of the 23rd International Conference on Architecture of Computing Systems},
pages = {187–198},
numpages = {12},
location = {Hannover, Germany},
series = {ARCS'10}
}

@article{10.1016/j.asoc.2015.06.046,
author = {Dahal, Keshav and Almejalli, Khaled and Hossain, M. Alamgir and Chen, Wenbing},
title = {GA-based learning for rule identification in fuzzy neural networks},
year = {2015},
issue_date = {October 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {35},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.06.046},
doi = {10.1016/j.asoc.2015.06.046},
abstract = {GA-based approach within a three stages-learning for Fuzzy Neural Network systems.GA to identify relevant rules in a promising way from all possible fuzzy rules.Performance comparison with other 19 approaches reported in the literatures. Employing an effective learning process is a critical topic in designing a fuzzy neural network, especially when expert knowledge is not available. This paper presents a genetic algorithm (GA) based learning approach for a specific type of fuzzy neural network. The proposed learning approach consists of three stages. In the first stage the membership functions of both input and output variables are initialized by determining their centers and widths using a self-organizing algorithm. The second stage employs the proposed GA based learning algorithm to identify the fuzzy rules while the final stage tunes the derived structure and parameters using a back-propagation learning algorithm. The capabilities of the proposed GA-based learning approach are evaluated using a well-examined benchmark example and its effectiveness is analyzed by means of a comparative study with other approaches. The usefulness of the proposed GA-based learning approach is also illustrated in a practical case study where it is used to predict the performance of road traffic control actions. Results from the benchmarking exercise and case study effectively demonstrate the ability of the proposed three stages learning approach to identify relevant fuzzy rules from a training data set with a higher prediction accuracy than alternative approaches.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {605–617},
numpages = {13},
keywords = {Mamdani-type fuzzy neural network, Genetic algorithm, Fuzzy rule identification, Back-propagation learning algorithm}
}

@inproceedings{10.1007/978-3-030-49435-3_29,
author = {Reinhartz-Berger, Iris and Abbas, Sameh},
title = {A Variability-Driven Analysis Method for Automatic Extraction of Domain Behaviors},
year = {2020},
isbn = {978-3-030-49434-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-49435-3_29},
doi = {10.1007/978-3-030-49435-3_29},
abstract = {Domain engineering focuses on modeling knowledge in an application domain for supporting systematic reuse in the context of complex and constantly evolving systems. Automatically supporting this task is challenging; most existing methods assume high similarity of variants which limits reuse of the generated domain artifacts, or provide very low-level features rather than actual domain features. As a result, these methods are limited in handling common scenarios such as similarly behaving systems developed by different teams, or merging existing products. To address this gap, we propose a method for extracting domain knowledge in the form of domain behaviors, building on a previously developed framework for behavior-based variability analysis among class operations. Machine learning techniques are applied for identifying clusters of operations that can potentially form domain behaviors. The approach is evaluated on a set of open-source video games, named apo-games.},
booktitle = {Advanced Information Systems Engineering: 32nd International Conference, CAiSE 2020, Grenoble, France, June 8–12, 2020, Proceedings},
pages = {467–481},
numpages = {15},
keywords = {Domain engineering, Systematic reuse, Variability analysis},
location = {Grenoble, France}
}

@inproceedings{10.5555/1609067.1609127,
author = {Louis, Annie and Nenkova, Ani},
title = {Performance confidence estimation for automatic summarization},
year = {2009},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We address the task of automatically predicting if summarization system performance will be good or bad based on features derived directly from either single- or multi-document inputs. Our labelled corpus for the task is composed of data from large scale evaluations completed over the span of several years. The variation of data between years allows for a comprehensive analysis of the robustness of features, but poses a challenge for building a combined corpus which can be used for training and testing. Still, we find that the problem can be mitigated by appropriately normalizing for differences within each year. We examine different formulations of the classification task which considerably influence performance. The best results are 84% prediction accuracy for single- and 74% for multi-document summarization.},
booktitle = {Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics},
pages = {541–548},
numpages = {8},
location = {Athens, Greece},
series = {EACL '09}
}

@proceedings{10.1145/2993236,
title = {GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/3078597.3078605,
author = {Liu, Zhengchun and Balaprakash, Prasanna and Kettimuthu, Rajkumar and Foster, Ian},
title = {Explaining Wide Area Data Transfer Performance},
year = {2017},
isbn = {9781450346993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078597.3078605},
doi = {10.1145/3078597.3078605},
abstract = {Disk-to-disk wide-area file transfers involve many subsystems and tunable application parameters that pose significant challenges for bottleneck detection, system optimization, and performance prediction. Performance models can be used to address these challenges but have not proved generally usable because of a need for extensive online experiments to characterize subsystems. We show here how to overcome the need for such experiments by applying machine learning methods to historical data to estimate parameters for predictive models. Starting with log data for millions of Globus transfers involving billions of files and hundreds of petabytes, we engineer features for endpoint CPU load, network interface card load, and transfer characteristics; and we use these features in both linear and nonlinear models of transfer performance, We show that the resulting models have high explanatory power. For a representative set of 30,653 transfers over 30 heavily used source-destination pairs ("edges''),totaling 2,053 TB in 46.6 million files, we obtain median absolute percentage prediction errors (MdAPE) of 7.0% and 4.6% when using distinct linear and nonlinear models per edge, respectively; when using a single nonlinear model for all edges, we obtain an MdAPE of 7.8%. Our work broadens understanding of factors that influence file transfer rate by clarifying relationships between achieved transfer rates, transfer characteristics, and competing load. Our predictions can be used for distributed workflow scheduling and optimization, and our features can also be used for optimization and explanation.},
booktitle = {Proceedings of the 26th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {167–178},
numpages = {12},
keywords = {wide area data transfer, machine learning, gridftp, globus},
location = {Washington, DC, USA},
series = {HPDC '17}
}

@inproceedings{10.1145/3167132.3167354,
author = {Lazreg, Sami and Collet, Philippe and Mosser, S\'{e}bastien},
title = {Assessing the functional feasibility of variability-intensive data flow-oriented systems},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167354},
doi = {10.1145/3167132.3167354},
abstract = {Data-flow oriented embedded systems, such as automotive systems used to render HMI (e.g., instrument clusters, infotainments), are increasingly built from highly variable specifications while targeting different constrained hardware platforms configurable in a finegrained way. These variabilities at two different levels lead to a huge number of possible embedded system solutions, which feasibility is extremely complex and tedious to predetermine. In this paper, we propose a tooled approach that capture high level specifications as variable dataflows, and targeted platforms as variable component models. Dataflows can then be mapped onto platforms to express a specification of such variability-intensive systems. The proposed tool support transforms this specification into structural and behavioral variability models and reuses automated reasoning techniques to explore and assess the feasibility of all variants in a single run. We also report on the application of the proposed approach to an industrial case study of automotive instrument cluster.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {2066–2075},
numpages = {10},
keywords = {variability modeling, feature model, embedded system design engineering, behavioral product lines model checking},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1109/CCGrid.2014.60,
author = {Kumbhare, Alok Gautam and Simmhan, Yogesh and Prasanna, Viktor K.},
title = {PLAStiCC: predictive look-ahead scheduling for continuous dataflows on clouds},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.60},
doi = {10.1109/CCGrid.2014.60},
abstract = {Scalable stream processing and continuous dataflow systems are gaining traction with the rise of big data due to the need for processing high velocity data in near real time. Unlike batch processing systems such as MapReduce and workflows, static scheduling strategies fall short for continuous dataflows due to the variations in the input data rates and the need for sustained throughput. The elastic resource provisioning of cloud infrastructure is valuable to meet the changing resource needs of such continuous applications. However, multi-tenant cloud resources introduce yet another dimension of performance variability that impacts the application's throughput. In this paper we propose PLAStiCC, an adaptive scheduling algorithm that balances resource cost and application throughput using a prediction-based look-ahead approach. It not only addresses variations in the input data rates but also the underlying cloud infrastructure. In addition, we also propose several simpler static scheduling heuristics that operate in the absence of accurate performance prediction model. These static and adaptive heuristics are evaluated through extensive simulations using performance traces obtained from Amazon AWS IaaS public cloud. Our results show an improvement of up to 20% in the overall profit as compared to the reactive adaptation algorithm.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {344–353},
numpages = {10},
keywords = {stream processing, predictive scheduling, elastic resource management, continuous dataflows, IaaS clouds},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/3462757.3466085,
author = {Aumiller, Dennis and Almasian, Satya and Lackner, Sebastian and Gertz, Michael},
title = {Structural text segmentation of legal documents},
year = {2021},
isbn = {9781450385268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462757.3466085},
doi = {10.1145/3462757.3466085},
abstract = {The growing complexity of legal cases has lead to an increasing interest in legal information retrieval systems that can effectively satisfy user-specific information needs. However, such downstream systems typically require documents to be properly formatted and segmented, which is often done with relatively simple pre-processing steps, disregarding topical coherence of segments. Systems generally rely on representations of individual sentences or paragraphs, which may lack crucial context, or document-level representations, which are too long for meaningful search results. To address this issue, we propose a segmentation system that can predict topical coherence of sequential text segments spanning several paragraphs, effectively segmenting a document and providing a more balanced representation for downstream applications. We build our model on top of popular transformer networks and formulate structural text segmentation as topical change detection, by performing a series of independent classifications that allow for efficient fine-tuning on task-specific data. We crawl a novel dataset consisting of roughly 74,000 online Terms-of-Service documents, including hierarchical topic annotations, which we use for training. Results show that our proposed system significantly outperforms baselines, and adapts well to structural peculiarities of legal documents. We release both data and trained models to the research community for future work.1},
booktitle = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},
pages = {2–11},
numpages = {10},
keywords = {text segmentation, outline generation, document understanding},
location = {S\~{a}o Paulo, Brazil},
series = {ICAIL '21}
}

@article{10.1007/s10586-011-0194-3,
author = {Liu, Haikun and Jin, Hai and Xu, Cheng-Zhong and Liao, Xiaofei},
title = {Performance and energy modeling for live migration of virtual machines},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-011-0194-3},
doi = {10.1007/s10586-011-0194-3},
abstract = {Live migration of virtual machine (VM) provides a significant benefit for virtual server mobility without disrupting service. It is widely used for system management in virtualized data centers. However, migration costs may vary significantly for different workloads due to the variety of VM configurations and workload characteristics. To take into account the migration overhead in migration decision-making, we investigate design methodologies to quantitatively predict the migration performance and energy consumption. We thoroughly analyze the key parameters that affect the migration cost from theory to practice. We construct application-oblivious models for the cost prediction by using learned knowledge about the workloads at the hypervisor (also called VMM) level. This should be the first kind of work to estimate VM live migration cost in terms of both performance and energy in a quantitative approach. We evaluate the models using five representative workloads on a Xen virtualized environment. Experimental results show that the refined model yields higher than 90% prediction accuracy in comparison with measured cost. Model-guided decisions can significantly reduce the migration cost by more than 72.9% at an energy saving of 73.6%.},
journal = {Cluster Computing},
month = jun,
pages = {249–264},
numpages = {16},
keywords = {Virtual machine, Performance model, Live migration, Energy}
}

@article{10.1016/j.jss.2021.111070,
author = {Rosiak, Kamil and Schlie, Alexander and Linsbauer, Lukas and Vogel-Heuser, Birgit and Schaefer, Ina},
title = {Custom-tailored clone detection for IEC 61131-3 programming languages},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111070},
doi = {10.1016/j.jss.2021.111070},
journal = {J. Syst. Softw.},
month = dec,
numpages = {18},
keywords = {Reverse engineering, IEC&nbsp;61131-3, Variability mining, Clone detection}
}

@inproceedings{10.1145/1842752.1842811,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Categorizing and modeling variation in families of systems: a position paper},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842811},
doi = {10.1145/1842752.1842811},
abstract = {This paper presents an approach that considers variation in systems and system architectures according to the kind of relation among the variants in the software family. The approach highlights why it is beneficial to consider such different variation relations separately and gives examples of what these relations may be.Two main categories of variation relations are presented, based on whether the system architecture remains constant (architecture-based variation), or whether the architecture itself is variable, i.e. the variants do not share a common architecture. The paper introduces several different kinds of variation families that seem to belong to these two categories, as well as yet other families comprising variants that do not neatly fit in either category, with only a subset of the variants sharing a common architecture. Each kind of variation relation is illustrated with an example software family from different domains, including operating systems (OS).},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {316–323},
numpages = {8},
keywords = {variation, variability, system architectures, software product lines, software families},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@article{10.1007/s00165-017-0441-3,
author = {Str\"{u}ber, D. and Rubin, J. and Arendt, T. and Chechik, M. and Taentzer, G. and Pl\"{o}ger, J.},
title = {Variability-based model transformation: formal foundation and application},
year = {2018},
issue_date = {Jan 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {1},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-017-0441-3},
doi = {10.1007/s00165-017-0441-3},
abstract = {Model transformation systems often contain transformation rules that are substantially similar to each other, causing maintenance issues and performance bottlenecks. To address these issues, we introduce variability-based model transformation. The key idea is to encode a set of similar rules into a compact representation, called variability-based rule. We provide an algorithm for applying such rules in an efficient manner. In addition, we introduce rule merging, a three-component mechanism for enabling the automatic creation of variability-based rules. Our rule application and merging mechanisms are supported by a novel formal framework, using category theory to provide precise definitions and to prove correctness. In two realistic application scenarios, the created variability-based rules enabled considerable speedups, while also allowing the overall specifications to become more compact.},
journal = {Form. Asp. Comput.},
month = jan,
pages = {133–162},
numpages = {30},
keywords = {Category theory, Variability, Graph transformation, Model transformation}
}

@inproceedings{10.1145/3239372.3239397,
author = {Ballar\'{\i}n, Manuel and Marc\'{e}n, Ana C. and Pelechano, Vicente and Cetina, Carlos},
title = {Measures to report the Location Problem of Model Fragment Location},
year = {2018},
isbn = {9781450349499},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239372.3239397},
doi = {10.1145/3239372.3239397},
abstract = {Model Fragment Location (MFL) aims at identifying model elements that are relevant to a requirement, feature, or bug. Many MFL approaches have been introduced in the last few years to address the identification of the model elements that correspond to a specific functionality. However, there is a lack of detail when the measurements about the search space (models) and the measurements about the solution to be found (model fragment) are reported. Generally, the only reported measure is the model size. In this paper, we propose using five measurements (size, volume, density, multiplicity, and dispersion) to report the location problems. These measurements are the result of analyzing 1,308 MFLs in a family of industrial models over the last four years. Using two MFL approaches, we emphasize the importance of these measurements in order to compare results. Our work not only proposes improving the reporting of the location problem, but it also provides real measurements of location problems that are useful to other researchers in the design of synthetic location problems.},
booktitle = {Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {189–199},
numpages = {11},
keywords = {Traceability Link Recovery, Model Fragment Location, Feature Location, Bug Location},
location = {Copenhagen, Denmark},
series = {MODELS '18}
}

@inproceedings{10.1007/978-3-030-86957-1_6,
author = {Feely, Ciara and Caulfield, Brian and Lawlor, Aonghus and Smyth, Barry},
title = {A Case-Based Reasoning Approach to&nbsp;Predicting and Explaining Running Related Injuries},
year = {2021},
isbn = {978-3-030-86956-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86957-1_6},
doi = {10.1007/978-3-030-86957-1_6},
abstract = {When training for endurance activities, such as the marathon, the risk of injury is ever-present, especially for first-time or inexperienced athletes. And because injuries depend on various factors, there is an opportunity to provide athletes with greater levels of support and guidance when it comes to the risks associated with their training. Hence, in this work we propose a case-based reasoning approach to predict injury risk for marathoners and provide actionable explanations so that runners can understand this risk and potentially reduce it. We do this using the type of activity data collected by common training apps, with extended training breaks used as a proxy for injury (in the absence of explicit injury data), and we show how future breaks can be predicted based on the training patterns of similar runners. Furthermore, we demonstrate how counterfactual explanations can be used to highlight those features that are unique to injured runners (those suffering from training breaks) to emphasise training behaviours that may be responsible for higher levels of injury risk for the target runner. We evaluate our work with a dataset of real-world training data by more than 5,000 real marathon runners.},
booktitle = {Case-Based Reasoning Research and Development: 29th International Conference, ICCBR 2021, Salamanca, Spain, September 13–16, 2021, Proceedings},
pages = {79–93},
numpages = {15},
keywords = {Counterfactual explanations, Injury prediction, Marathon running, CBR for health and exercise},
location = {Salamanca, Spain}
}

@article{10.1016/j.jss.2016.06.102,
author = {Lung, Chung-Horng and Zhang, Xu and Rajeswaran, Pragash},
title = {Improving software performance and reliability in a distributed and concurrent environment with an architecture-based self-adaptive framework},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.06.102},
doi = {10.1016/j.jss.2016.06.102},
abstract = {We proposed a novel software architecture-level adaptation approach.We adopted known architectural patterns in distributed and concurrent systems.We developed a framework to support the self-adaptive mechanism.We developed and evaluated five adaptive policies.Our approach improved performance and increased reliability in our experiments. More and more, modern software systems in a distributed and parallel environment are becoming highly complex and difficult to manage. A self-adaptive approach that integrates monitoring, analyzing, and actuation functionalities has the potential to accommodate an ever dynamically changing environment. This paper proposes an architecture-level self-adaptive framework with the aim of improving performance and reliability. To meet such a goal, this paper presents a Self-Adaptive Framework for Concurrency Architectures (SAFCA) that consists of multiple well-documented architectural patterns in addition to monitoring and adaptive capabilities. With this framework, a system using an architectural alternative can activate another alternative at runtime to cope with increasing demands or to recover from failure. Five adaptation mechanisms have been developed for concept demonstration and evaluation; four focus on performance improvement and one deals with failover and reliability enhancement. We have performed a number of experiments with this framework. The experimental results demonstrate that the proposed adaptive framework can mitigate the over-provisioning method commonly used in practice. As a result, resource usage becomes more efficient for most normal conditions, while the system is still able to effectively handle bursty or growing demands using an adaptive mechanism. The performance of SAFCA is also better than systems using only standalone architectural alternatives without an adaptation scheme. Moreover, the experimental results show that a fast recovery can be realized in the case of failure by conducting an architecture switchover to maintain the desired service.},
journal = {J. Syst. Softw.},
month = nov,
pages = {311–328},
numpages = {18},
keywords = {Software architecture, Reliability, Performance, Patterns, Elastic computing, Distributed and concurrent architecture, Autonomic computing}
}

@inproceedings{10.1145/2462902.2462904,
author = {Bu, Xiangping and Rao, Jia and Xu, Cheng-zhong},
title = {Interference and locality-aware task scheduling for MapReduce applications in virtual clusters},
year = {2018},
isbn = {9781450319102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462902.2462904},
doi = {10.1145/2462902.2462904},
abstract = {MapReduce emerges as an important distributed programming paradigm for large-scale applications. Running MapReduce applications in clouds presents an attractive usage model for enterprises. In a virtual MapReduce cluster, the interference between virtual machines (VMs) causes performance degradation of map and reduce tasks and renders existing data locality-aware task scheduling policy, like delay scheduling, no longer effective. On the other hand, virtualization offers an extra opportunity of data locality for co-hosted VMs. In this paper, we present a task scheduling strategy to mitigate interference and meanwhile preserving task data locality for MapReduce applications. The strategy includes an interference-aware scheduling policy, based on a task performance prediction model, and an adaptive delay scheduling algorithm for data locality improvement. We implement the interference and locality-aware (ILA) scheduling strategy in a virtual MapReduce framework. We evaluated its effectiveness and efficiency on a 72-node Xen-based virtual cluster. Experimental results with 10 representative CPU and IO-intensive applications show that ILA is able to achieve a speedup of 1.5 to 6.5 times for individual jobs and yield an improvement of up to 1.9 times in system throughput in comparison with four other MapReduce schedulers.},
booktitle = {Proceedings of the 22nd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {227–238},
numpages = {12},
keywords = {task scheduling, cloud computing, MapReduce},
location = {New York, New York, USA},
series = {HPDC '13}
}

@inproceedings{10.1007/978-3-030-79025-7_24,
author = {Hassan, Mohamed W. and Athanas, Peter M. and Hanafy, Yasser Y.},
title = {Domain-Specific Modeling and&nbsp;Optimization for Graph Processing on&nbsp;FPGAs},
year = {2021},
isbn = {978-3-030-79024-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79025-7_24},
doi = {10.1007/978-3-030-79025-7_24},
abstract = {The use of High Level Synthesis (HLS) tools is on the rise; however, performance modelling research has been mainly focused on regular applications with uniform memory access patterns. These performance models fail to accurately capture the performance of graph applications with irregular memory access patterns. This paper presents a domain-specific performance model targeting graph applications synthesized using HLS tools for FPGAs. The performance model utilizes information from the hardware specification, the application’s kernel, and the graph input. While the compilation process of HLS tools takes hours, the information required by the performance model can be extracted from the intermediate compilation report, which compiles in seconds. The goal of this work is to provide FPGA users with a performance modelling framework for graph applications, to estimate performance and explore the optimization space. We tested the framework on Intel’s new Devcloud platform and achieved speedup up&nbsp;to 3.4\texttimes{} by applying our framework’s recommended optimization strategy compared to the single pipeline implementation. The framework recommended the best optimization strategy in 90% of the test cases.},
booktitle = {Applied Reconfigurable Computing. Architectures, Tools, and Applications: 17th International Symposium, ARC 2021, Virtual Event, June 29–30, 2021, Proceedings},
pages = {315–326},
numpages = {12},
keywords = {Graph data-sets, FPGA, Domain-specific optimization, Performance modelling, Graph processing}
}

@article{10.1023/A:1011219601502,
author = {Zhong, Ning and Dong, Juzhen and Ohsuga, Setsuo},
title = {Using Rough Sets with Heuristics for Feature Selection},
year = {2001},
issue_date = {August 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {3},
issn = {0925-9902},
url = {https://doi.org/10.1023/A:1011219601502},
doi = {10.1023/A:1011219601502},
abstract = {Practical machine learning algorithms are known to degrade in performance (prediction accuracy) when faced with many features (sometimes attribute is used instead of feature) that are not necessary for rule discovery. To cope with this problem, many methods for selecting a subset of features have been proposed. Among such methods, the filter approach that selects a feature subset using a preprocessing step, and the wrapper approach that selects an optimal feature subset from the space of possible subsets of features using the induction algorithm itself as a part of the evaluation function, are two typical ones. Although the filter approach is a faster one, it has some blindness and the performance of induction is not considered. On the other hand, the optimal feature subsets can be obtained by using the wrapper approach, but it is not easy to use because of the complexity of time and space. In this paper, we propose an algorithm which is using rough set theory with greedy heuristics for feature selection. Selecting features is similar to the filter approach, but the evaluation criterion is related to the performance of induction. That is, we select the features that do not damage the performance of induction.},
journal = {J. Intell. Inf. Syst.},
month = oct,
pages = {199–214},
numpages = {16},
keywords = {rough sets, knowledge discovery in databases, inductive learning, heuristics, feature selection}
}

@inproceedings{10.1145/2493123.2462904,
author = {Bu, Xiangping and Rao, Jia and Xu, Cheng-zhong},
title = {Interference and locality-aware task scheduling for MapReduce applications in virtual clusters},
year = {2013},
isbn = {9781450319102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2493123.2462904},
doi = {10.1145/2493123.2462904},
abstract = {MapReduce emerges as an important distributed programming paradigm for large-scale applications. Running MapReduce applications in clouds presents an attractive usage model for enterprises. In a virtual MapReduce cluster, the interference between virtual machines (VMs) causes performance degradation of map and reduce tasks and renders existing data locality-aware task scheduling policy, like delay scheduling, no longer effective. On the other hand, virtualization offers an extra opportunity of data locality for co-hosted VMs. In this paper, we present a task scheduling strategy to mitigate interference and meanwhile preserving task data locality for MapReduce applications. The strategy includes an interference-aware scheduling policy, based on a task performance prediction model, and an adaptive delay scheduling algorithm for data locality improvement. We implement the interference and locality-aware (ILA) scheduling strategy in a virtual MapReduce framework. We evaluated its effectiveness and efficiency on a 72-node Xen-based virtual cluster. Experimental results with 10 representative CPU and IO-intensive applications show that ILA is able to achieve a speedup of 1.5 to 6.5 times for individual jobs and yield an improvement of up to 1.9 times in system throughput in comparison with four other MapReduce schedulers.},
booktitle = {Proceedings of the 22nd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {227–238},
numpages = {12},
keywords = {task scheduling, cloud computing, MapReduce},
location = {New York, New York, USA},
series = {HPDC '13}
}

@article{10.1145/2207243.2207249,
author = {Pardos, Zachary A, and Gowda, Sujith M. and Baker, Ryan S.J.d. and Heffernan, Neil T.},
title = {The sum is greater than the parts: ensembling models of student knowledge in educational software},
year = {2012},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/2207243.2207249},
doi = {10.1145/2207243.2207249},
abstract = {Many competing models have been proposed in the past decade for predicting student knowledge within educational software. Recent research attempted to combine these models in an effort to improve performance but have yielded inconsistent results. While work in the 2010 KDD Cup data set showed the benefits of ensemble methods, work in the Genetics Tutor failed to show similar benefits. We hypothesize that the key factor has been data set size. We explore the potential for improving student performance prediction with ensemble methods in a data set drawn from a different tutoring system, the ASSISTments Platform, which contains 15 times the number of responses of the Genetics Tutor data set. We evaluated the predictive performance of eight student models and eight methods of ensembling predictions. Within this data set, ensemble approaches were more effective than any single method with the best ensemble approach producing predictions of student performance 10% better than the best individual student knowledge model.},
journal = {SIGKDD Explor. Newsl.},
month = may,
pages = {37–44},
numpages = {8}
}

@article{10.1145/2678277,
author = {Breughe, Maximilien B. and Eyerman, Stijn and Eeckhout, Lieven},
title = {Mechanistic Analytical Modeling of Superscalar In-Order Processor Performance},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/2678277},
doi = {10.1145/2678277},
abstract = {Superscalar in-order processors form an interesting alternative to out-of-order processors because of their energy efficiency and lower design complexity. However, despite the reduced design complexity, it is nontrivial to get performance estimates or insight in the application--microarchitecture interaction without running slow, detailed cycle-level simulations, because performance highly depends on the order of instructions within the application’s dynamic instruction stream, as in-order processors stall on interinstruction dependences and functional unit contention. To limit the number of detailed cycle-level simulations needed during design space exploration, we propose a mechanistic analytical performance model that is built from understanding the internal mechanisms of the processor.The mechanistic performance model for superscalar in-order processors is shown to be accurate with an average performance prediction error of 3.2% compared to detailed cycle-accurate simulation using gem5. We also validate the model against hardware, using the ARM Cortex-A8 processor and show that it is accurate within 10% on average. We further demonstrate the usefulness of the model through three case studies: (1) design space exploration, identifying the optimum number of functional units for achieving a given performance target; (2) program--machine interactions, providing insight into microarchitecture bottlenecks; and (3) compiler--architecture interactions, visualizing the impact of compiler optimizations on performance.},
journal = {ACM Trans. Archit. Code Optim.},
month = jan,
articleno = {50},
numpages = {26},
keywords = {processor design space exploration, performance modeling, inter-instruction dependences, functional units, cycle stacks, Superscalar in-order processors}
}

@inproceedings{10.5555/2075462.2075499,
author = {Serrano, M\'{o}nica and Sahuquillo, Julio and Hassan, Houcine and Petit, Salvador and Duato, Jos\'{e}},
title = {A cluster computer performance predictor for memory scheduling},
year = {2011},
isbn = {9783642246685},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Remote Memory Access (RMA) hardware allow a given motherboard in a cluster to directly access the memory installed in a remote motherboard of the same cluster. In recent works, this characteristic has been used to extend the addressable memory space of selected motherboards, which enable a better balance of main memory resources among cluster applications. This way is much more cost-effective than than implementing a full-fledged shared memory system.In this context, the memory scheduler is in charge of finding a suitable distribution of local and remote memory that maximizes the performance and guarantees a minimum QoS among the applications. Note that since changing the memory distribution is a slow process involving several motherboards, the memory scheduler needs to make sure that the target distribution provides better performance than the current one.In this paper, a performance predictor is designed in order to find the best memory distribution for a given set of applications executing in a cluster motherboard. The predictor uses simple hardware counters to estimate the expected impact on performance of the different memory distributions. The hardware counters provide the predictor with the information about the time spent in processor, memory access and network.The performance model used by the predictor has been validated in a detailed microarchitectural simulator using real benchmarks. Results show that the prediction accuracy never deviates more than 5% compared to the real results, being less than 0.5% in most of the cases.},
booktitle = {Proceedings of the 11th International Conference on Algorithms and Architectures for Parallel Processing - Volume Part II},
pages = {353–362},
numpages = {10},
keywords = {remote memory assignment, performance estimation, memory scheduling, cluster computers},
location = {Melbourne, Australia},
series = {ICA3PP'11}
}

@inproceedings{10.1007/11527800_25,
author = {Czarnecki, Krzysztof},
title = {Overview of generative software development},
year = {2004},
isbn = {3540278842},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11527800_25},
doi = {10.1007/11527800_25},
abstract = {System family engineering seeks to exploit the commonalities among systems from a given problem domain while managing the variabilities among them in a systematic way. In system family engineering, new system variants can be rapidly created based on a set of reusable assets (such as a common architecture, components, models, etc.). Generative software development aims at modeling and implementing system families in such a way that a given system can be automatically generated from a specification written in one or more textual or graphical domain-specific languages. This paper gives an overview of the basic concepts and ideas of generative software development including DSLs, domain and application engineering, generative domain models, networks of domains, and technology projections. The paper also discusses the relationship of generative software development to other emerging areas such as Model Driven Development and Aspect-Oriented Software Development.},
booktitle = {Proceedings of the 2004 International Conference on Unconventional Programming Paradigms},
pages = {326–341},
numpages = {16},
location = {Le Mont Saint Michel, France},
series = {UPP'04}
}

@inproceedings{10.5555/3291291.3291314,
author = {Wehling, Kenny and Wille, David and Seidl, Christoph and Schaefer, Ina},
title = {Reducing variability of technically related software systems in large-scale IT landscapes},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {The number of software systems in a company typically grows with the business requirements. Therefore, IT landscapes in large companies can consist of hundreds or thousands of different software systems. As the evolution of such large-scale landscapes is often uncoordinated, they commonly comprise different groups of related software systems using a common core technology (e.g., Java Web-Application) implemented by a variety of architectural components (e.g., different application servers or databases). This leads to increased costs and higher effort for maintaining and evolving these software systems and the entire IT landscape. To alleviate these problems, the variability of such technically related software systems has to be reduced. For this purpose, experts have to assess and evaluate restructuring potentials in order to take appropriate restructuring decisions. As a manual analysis requires high effort and is not feasible for large-scale IT landscapes, experts face a major challenge. To overcome this challenge, we introduce a novel approach to automatically support experts in taking reasonable restructuring decisions. By providing automated methods for assessing, evaluating and simulating restructuring potentials, experts are capable of reducing the variability of related software systems in large-scale IT landscapes. We show suitability of our approach by expert interviews and an industrial case study with architectures of real-world software systems.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {224–235},
numpages = {12},
keywords = {variability, technology architecture, software systems, restructuring},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@article{10.1016/j.scico.2019.102344,
author = {Basile, Davide and ter Beek, Maurice H. and Degano, Pierpaolo and Legay, Axel and Ferrari, Gian-Luigi and Gnesi, Stefania and Di Giandomenico, Felicita},
title = {Controller synthesis of service contracts with variability},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {187},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2019.102344},
doi = {10.1016/j.scico.2019.102344},
journal = {Sci. Comput. Program.},
month = feb,
numpages = {23},
keywords = {Behavioural variability, Variability, Service orchestrations, Contract automata, Supervisory control theory}
}

@inproceedings{10.1007/978-3-642-13821-8_4,
author = {Happe, Jens and Westermann, Dennis and Sachs, Kai and Kapov\'{a}, Lucia},
title = {Statistical inference of software performance models for parametric performance completions},
year = {2010},
isbn = {3642138209},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13821-8_4},
doi = {10.1007/978-3-642-13821-8_4},
abstract = {Software performance engineering (SPE) enables software architects to ensure high performance standards for their applications. However, applying SPE in practice is still challenging. Most enterprise applications include a large software basis, such as middleware and legacy systems. In many cases, the software basis is the determining factor of the system’s overall timing behavior, throughput, and resource utilization. To capture these influences on the overall system’s performance, established performance prediction methods (model-based and analytical) rely on models that describe the performance-relevant aspects of the system under study. Creating such models requires detailed knowledge on the system’s structure and behavior that, in most cases, is not available. In this paper, we abstract from the internal structure of the system under study. We focus on message-oriented middleware (MOM) and analyze the dependency between the MOM’s usage and its performance. We use statistical inference to conclude these dependencies from observations. For ActiveMQ 5.3, the resulting functions predict the performance with a relative mean square error 0.1.},
booktitle = {Proceedings of the 6th International Conference on Quality of Software Architectures: Research into Practice - Reality and Gaps},
pages = {20–35},
numpages = {16},
location = {Prague, Czech Republic},
series = {QoSA'10}
}

@inproceedings{10.1109/ICSE.2019.00090,
author = {Lillack, Max and St\u{a}nciulescu, \c{S}tefan and Hedman, Wilhelm and Berger, Thorsten and W\k{a}sowski, Andrzej},
title = {Intention-based integration of software variants},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00090},
doi = {10.1109/ICSE.2019.00090},
abstract = {Cloning is a simple way to create new variants of a system. While cheap at first, it increases maintenance cost in the long term. Eventually, the cloned variants need to be integrated into a configurable platform. Such an integration is challenging: it involves merging the usual code improvements between the variants, and also integrating the variable code (features) into the platform. Thus, variant integration differs from traditional software merging, which does not produce or organize configurable code, but creates a single system that cannot be configured into variants. In practice, variant integration requires fine-grained code edits, performed in an exploratory manner, in multiple iterations. Unfortunately, little tool support exists for integrating cloned variants.In this work, we show that fine-grained code edits needed for integration can be alleviated by a small set of integration intentions---domain-specific actions declared over code snippets controlling the integration. Developers can interactively explore the integration space by declaring (or revoking) intentions on code elements. We contribute the intentions (e.g., 'keep functionality' or 'keep as a configurable feature') and the IDE tool INCLINE, which implements the intentions and five editable views that visualize the integration process and allow declaring intentions producing a configurable integrated platform. In a series of experiments, we evaluated the completeness of the proposed intentions, the correctness and performance of INCLINE, and the benefits of using intentions for variant integration. The experiments show that INCLINE can handle complex integration tasks, that views help to navigate the code, and that it consistently reduces mistakes made by developers during variant integration.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {831–842},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3411764.3445179,
author = {Wu, Aoyu and Xie, Liwenhan and Lee, Bongshin and Wang, Yun and Cui, Weiwei and Qu, Huamin},
title = {Learning to Automate Chart Layout Configurations Using Crowdsourced Paired Comparison},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445179},
doi = {10.1145/3411764.3445179},
abstract = {We contribute a method to automate parameter configurations for chart layouts by learning from human preferences. Existing charting tools usually determine the layout parameters using predefined heuristics, producing sub-optimal layouts. People can repeatedly adjust multiple parameters (e.g., chart size, gap) to achieve visually appealing layouts. However, this trial-and-error process is unsystematic and time-consuming, without a guarantee of improvement. To address this issue, we develop Layout Quality Quantifier (LQ2), a machine learning model that learns to score chart layouts from paired crowdsourcing data. Combined with optimization techniques, LQ2 recommends layout parameters that improve the charts’ layout quality. We apply LQ2 on bar charts and conduct user studies to evaluate its effectiveness by examining the quality of layouts it produces. Results show that LQ2 can generate more visually appealing layouts than both laypeople and baselines. This work demonstrates the feasibility and usages of quantifying human preferences and aesthetics for chart layouts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {14},
numpages = {13},
keywords = {Visualization, Visual Design, Machine Learning, Image Quality Assessment, Crowdsourced},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1109/CCGRID.2007.84,
author = {Li, Hui},
title = {Performance Evaluation in Grid Computing: A Modeling and Prediction Perspective},
year = {2007},
isbn = {0769528333},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2007.84},
doi = {10.1109/CCGRID.2007.84},
abstract = {Experimental performance studies on computer systems, including Grids, require deep understandings on their work- load characteristics. The need arises from two important and closely related topics in performance evaluation, namely, workload modeling and performance prediction. Both top- ics rely heavily on the representative workload data and have their arsenal from statistics and machine learning. Neverthe- less, their goals and the nature of research differ considerably. Workload modeling aims at building mathematical models to generate workloads that can be used in simulation-based per- formance evaluation studies. It should statistically resem- ble the original real-world data therefore marginal statis- tics and second-order properties such as autocorrelation and power spectrum are important matching criteria. Perfor- mance prediction, on the other hand, intends to provide real- time forecast of important performance metrics (such as ap- plication run time and queue wait time) which can support Grid scheduling decisions. From this perspective prediction accuracy as well as performance should be considered to evaluate candidate techniques. My PhD research focuses primarily on these two topics in space-shared, data-intensive Grid environments. Starting from a comprehensive workload analysis with emphasis on the correlation structures and the scaling behavior, several basic job arrival patterns such as pseudo-periodicity and long range dependence are identified. Models are further proposed to capture these important arrival patterns and a complete workload model including run time is being investigated. The strong autocorrelations present in run time and queue wait time series inspire the research for performance prediction based on learning from historical data. Techniques based on a Instance Based Learning algorithm and several improvements are proposed and empirically evaluated. Research plans are proposed to use the results of workload modeling and perfor- mance prediction in the evaluation of scheduling strategies in data-intensive Grid environments.},
booktitle = {Proceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid},
pages = {869–874},
numpages = {6},
series = {CCGRID '07}
}

@article{10.14529/jsfi140202,
author = {Shoukourian, Hayk and Wilde, Torsten and Auweter, Axel and Bode, Arndt},
title = {Predicting the Energy and Power Consumption of Strong and Weak Scaling HPC Applications},
year = {2014},
issue_date = {July 2014},
publisher = {South Ural State University},
address = {Chelyabinsk, RUS},
volume = {1},
number = {2},
issn = {2409-6008},
url = {https://doi.org/10.14529/jsfi140202},
doi = {10.14529/jsfi140202},
abstract = {Keeping energy costs in budget and operating within available capacities of power distribution and cooling systems is becoming an important requirement for High Performance Computing HPC data centers. It is even more important when considering the estimated power requirements for Exascale computing. Power and energy capping are two of emerging techniques aimed towards controlling and efficient budgeting of power and energy consumption within the data center. Implementation of both techniques requires a knowledge of, potentially unknown, power and energy consumption data of the given parallel HPC applications for different numbers of compute servers nodes.This paper introduces an Adaptive Energy and Power Consumption Prediction AEPCP model capable of predicting the power and energy consumption of parallel HPC applications for different number of compute nodes. The suggested model is application specific and describes the behavior of power and energy with respect to the number of utilized compute nodes, taking as an input the available history power/energy data of an application. It provides a generic solution that can be used for each application but it produces an application specific result. The AEPCP model allows for ahead of time power and energy consumption prediction and adapts with each additional execution of the application improving the associated prediction accuracy. The model does not require any application code instrumentation and does not introduce any application performance degradation. Thus it is a high level application energy and power consumption prediction model. The validity and the applicability of the suggested AEPCP model is shown in this paper through the empirical results achieved using two application-benchmarks on the SuperMUC HPC system the 10th fastest supercomputer in the world, according to Top500 November 2013 rankings deployed at Leibniz Supercomputing Centre.},
journal = {Supercomput. Front. Innov.: Int. J.},
month = jul,
pages = {20–41},
numpages = {22},
keywords = {power consumption, power capping, node scaling, energy measurement, energy consumption, energy capping, adaptive prediction, HPC, EtS prediction, AEPCP model}
}

@inproceedings{10.1145/1596473.1596479,
author = {Happe, Jens and Li, Hui and Theilmann, Wolfgang},
title = {Black-box performance models: prediction based on observation},
year = {2009},
isbn = {9781605587097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1596473.1596479},
doi = {10.1145/1596473.1596479},
abstract = {Software performance engineering enables software architects to find potential performance problems, such as bottlenecks and long delays, prior to implementation and testing. Such early feedback on the system's performance is essential to develop and maintain efficient and scalable applications. However, the unavailability of data necessary to design performance models often hinders its application in practice. During system maintenance, the existing system has to be included into the performance model. For large, heterogeneous, and complex systems that have grown over time, modelling becomes infeasible due to the sheer size and complexity of the systems. Re-engineering approaches also fail due to the large and heterogeneous technology stack. Especially for such systems, performance prediction is essential. In this position statement, we propose goal-oriented abstractions of large parts of a software system based on systematic measurements. The measurements provide the information necessary to determine Black-box Performance Models that directly capture the influence of a system's usage and workload on performance (response time, throughput, and resource utilisation). We outline the research challenges that need to be addressed in order to apply Black-box Performance Models.},
booktitle = {Proceedings of the 1st International Workshop on Quality of Service-Oriented Software Systems},
pages = {19–24},
numpages = {6},
keywords = {model extraction, measurement, black-box performance model},
location = {Amsterdam, The Netherlands},
series = {QUASOSS '09}
}

@article{10.1007/s10664-020-09922-8,
author = {Grebhahn, Alexander and Kaltenecker, Christian and Engwer, Christian and Siegmund, Norbert and Apel, Sven},
title = {Lightweight, semi-automatic variability extraction: a case study on scientific computing},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09922-8},
doi = {10.1007/s10664-020-09922-8},
abstract = {In scientific computing, researchers often use feature-rich software frameworks to simulate physical, chemical, and biological processes. Commonly, researchers follow a clone-and-own approach: Copying the code of an existing, similar simulation and adapting it to the new simulation scenario. In this process, a user has to select suitable artifacts (e.g., classes) from the given framework and replaces the existing artifacts from the cloned simulation. This manual process incurs substantial effort and cost as scientific frameworks are complex and provide large numbers of artifacts. To support researchers in this area, we propose a lightweight API-based analysis approach, called VORM, that recommends appropriate artifacts as possible alternatives for replacing given artifacts. Such alternative artifacts can speed up performance of the simulation or make it amenable to other use cases, without modifying the overall structure of the simulation. We evaluate the practicality of VORM—especially, as it is very lightweight but possibly imprecise—by means of a case study on the DUNE numerics framework and two simulations from the realm of physical simulations. Specifically, we compare the recommendations by VORM with recommendations by a domain expert (a developer of DUNE). VORM recommended 34 out of the 37 artifacts proposed by the expert. In addition, it recommended 2 artifacts that are applicable but have been missed by the expert and 32 artifacts not recommended by the expert, which however are still applicable in the simulation scenario with slight modifications. Diving deeper into the results, we identified an undiscovered bug and an inconsistency in DUNE, which corroborates the usefulness of VORM.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {22},
keywords = {Variability analysis, Variability extraction, Configuration, Software variability}
}

@article{10.1145/3447721,
author = {Saban, Motaz El},
title = {Data science for the oil and gas industry in the Arab region},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3447721},
doi = {10.1145/3447721},
journal = {Commun. ACM},
month = mar,
pages = {54–56},
numpages = {3}
}

@article{10.1016/j.entcs.2011.09.006,
author = {Fernandes, Paulo and Sales, Afonso and Santos, Alan R. and Webber, Thais},
title = {Performance Evaluation of Software Development Teams: a Practical Case Study},
year = {2011},
issue_date = {September, 2011},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {275},
issn = {1571-0661},
url = {https://doi.org/10.1016/j.entcs.2011.09.006},
doi = {10.1016/j.entcs.2011.09.006},
abstract = {Software development projects have become a challenge for both industry and academia regarding the performance evaluation of teams. Recently, a Stochastic Automata Networks (SAN) model was proposed as theoretical representation for performance prediction of software development teams. In this paper, we present an exercise of such SAN analytical modeling for a practical case study from an Information Technology company that has multiple sites and different participants@? roles and expertises. We present the matching of our model predictions with the actual project observations. Then, we focus our attention on the central entity varying its availability and the level of provided support in order to observe the impact on the participants@? performance. We summarize our study with further discussions of numerical results and possible model extensions.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = sep,
pages = {73–92},
numpages = {20},
keywords = {Team Building Process, Stochastic Automata Networks, Performance Evaluation, Global Software Development, Analytical Modeling}
}

@inproceedings{10.1109/GRID.2007.4354138,
author = {Wu, Yongwei and Yuan, Yulai and Yang, Guangwen and Zheng, Weimin},
title = {Load prediction using hybrid model for computational grid},
year = {2007},
isbn = {9781424415595},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GRID.2007.4354138},
doi = {10.1109/GRID.2007.4354138},
abstract = {Due to the dynamic nature of grid environments, schedule algorithms always need assistance of a long-time-ahead load prediction to make decisions on how to use grid resources efficiently. In this paper, we present and evaluate a new hybrid model, which predicts the n-step-ahead load status by using interval values. This model integrates autoregressive (AR) model with confidence interval estimations to forecast the future load of a system. Meanwhile, two filtering technologies from signal processing field are also introduced into this model to eliminate data noise and enhance prediction accuracy. The results of experiments conducted on a real grid environment demonstrate that this new model is more capable of predicting n-step-ahead load in a computational grid than previous works. The proposed hybrid model performs well on prediction advance time for up to 50 minutes, with significant less prediction errors than conventional AR model. It also achieves an interval length acceptable for task scheduler.},
booktitle = {Proceedings of the 8th IEEE/ACM International Conference on Grid Computing},
pages = {235–242},
numpages = {8},
series = {GRID '07}
}

@article{10.1145/2427631.2427632,
author = {Wu, Meng-Ju and Yeung, Donald},
title = {Efficient Reuse Distance Analysis of Multicore Scaling for Loop-Based Parallel Programs},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0734-2071},
url = {https://doi.org/10.1145/2427631.2427632},
doi = {10.1145/2427631.2427632},
abstract = {Reuse Distance (RD) analysis is a powerful memory analysis tool that can potentially help architects study multicore processor scaling. One key obstacle, however, is that multicore RD analysis requires measuring Concurrent Reuse Distance (CRD) and Private-LRU-stack Reuse Distance (PRD) profiles across thread-interleaved memory reference streams. Sensitivity to memory interleaving makes CRD and PRD profiles architecture dependent, preventing them from analyzing different processor configurations. For loop-based parallel programs, CRD and PRD profiles shift coherently across RD values with core count scaling because interleaving threads are symmetric. Simple techniques can predict such shifting, making the analysis of numerous multicore configurations from a small set of CRD and PRD profiles feasible. Given the ubiquity of parallel loops, such techniques will be extremely valuable for studying future large multicore designs.This article investigates using RD analysis to efficiently analyze multicore cache performance for loop-based parallel programs, making several contributions. First, we provide an in-depth analysis on how CRD and PRD profiles change with core count scaling. Second, we develop techniques to predict CRD and PRD profile scaling, in particular employing reference groups [Zhong et al. 2003] to predict coherent shift, demonstrating 90% or greater prediction accuracy. Third, our CRD and PRD profile analyses define two application parameters with architectural implications: Ccore is the minimum shared cache capacity that “contains” locality degradation due to core count scaling, and Cshare is the capacity at which shared caches begin to provide a cache-miss reduction compared to private caches. And fourth, we apply CRD and PRD profiles to analyze multicore cache performance. When combined with existing problem scaling prediction, our techniques can predict shared LLC MPKI (private L2 cache MPKI) to within 10.7% (13.9%) of simulation across 1,728 (1,440) configurations using only 36 measured CRD (PRD) profiles.},
journal = {ACM Trans. Comput. Syst.},
month = feb,
articleno = {1},
numpages = {37},
keywords = {reuse distance, chip multiprocessors, Cache performance}
}

@inproceedings{10.1109/WICSA.2005.26,
author = {Zhu, Liming and Liu, Yan and Gorton, Ian and Bui, Ngoc Bao},
title = {Customized Benchmark Generation Using MDA},
year = {2005},
isbn = {0769525482},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WICSA.2005.26},
doi = {10.1109/WICSA.2005.26},
abstract = {This paper describes an approach for generating customized benchmark applications from a software architecture description using a Model Driven Architecture (MDA) approach. The benchmark generation and performance data capture tool implementation is based on widely used open source MDA frameworks. The business logic of the benchmark application is modeled in UML and generated by taking advantage of the existing generation "cartridges" so that the current component technology can be exploited in the benchmark. This greatly reduces the effort and expertise needed for benchmarking with complex component technology. We have also extended the MDA framework to model and generate a load testing suite and automatic performance measurement infrastructure. The approach complements current model-based performance prediction and analysis methods by generating the benchmark application from the same application architecture that the performance models are derived from. This provides the potential for tightly integrating runtime performance measurement with model-based prediction either for model validation or improving model prediction accuracy. We illustrate the approach using a case study based on EJB component technology.},
booktitle = {Proceedings of the 5th Working IEEE/IFIP Conference on Software Architecture},
pages = {35–44},
numpages = {10},
series = {WICSA '05}
}

@inproceedings{10.1145/3474198.3478215,
author = {Du, Xiaozhi and Yue, Hehe and Dong, Honglei},
title = {Software Defect Prediction Method based on Hybrid Sampling},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478215},
doi = {10.1145/3474198.3478215},
abstract = {Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However, the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue, this paper proposes a software defect prediction method based on hybrid sampling, which combines the strategies of over-sampling with under-sampling. For minority class, over-sampling uses k-means to cluster samples, then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class, under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples, whose instance hardness values are lower than the threshold, are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN, SMOTE-Tomek, SMOTE and DBSMOTE, the accuracy of our method is improved by 17.60%, 6.99%, 8.66% and 26.18% on average respectively.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {93},
numpages = {9},
keywords = {Software defect prediction, Hybrid sampling, Data imbalance},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/3394486.3403218,
author = {Yang, Zhen and Ding, Ming and Zhou, Chang and Yang, Hongxia and Zhou, Jingren and Tang, Jie},
title = {Understanding Negative Sampling in Graph Representation Learning},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403218},
doi = {10.1145/3394486.3403218},
abstract = {Graph representation learning has been extensively studied in recent years, in which sampling is a critical point. Prior arts usually focus on sampling positive node pairs, while the strategy for negative sampling is left insufficiently explored. To bridge the gap, we systematically analyze the role of negative sampling from the perspectives of both objective and risk, theoretically demonstrating that negative sampling is as important as positive sampling in determining the optimization objective and the resulted variance. To the best of our knowledge, we are the first to derive the theory and quantify that a nice negative sampling distribution is pn(u|v) ∝ pd(u|v)α, 0 &lt; α &lt; 1. With the guidance of the theory, we propose MCNS, approximating the positive distribution with self-contrast approximation and accelerating negative sampling by Metropolis-Hastings. We evaluate our method on 5 datasets that cover extensive downstream graph learning tasks, including link prediction, node classification and recommendation, on a total of 19 experimental settings. These relatively comprehensive experimental results demonstrate its robustness and superiorities.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1666–1676},
numpages = {11},
keywords = {network embedding, negative sampling, graph representation learning},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.5555/2997189.2997288,
author = {Huang, Ling and Jia, Jinzhu and Yu, Bin and Chun, Byung-Gon and Maniatis, Petros and Naik, Mayur},
title = {Predicting execution time of computer programs using sparse polynomial regression},
year = {2010},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Predicting the execution time of computer programs is an important but challenging problem in the community of computer systems. Existing methods require experts to perform detailed analysis of program code in order to construct predictors or select important features. We recently developed a new system to automatically extract a large number of features from program execution on sample inputs, on which prediction models can be constructed without expert knowledge. In this paper we study the construction of predictive models for this problem. We propose the SPORE (Sparse POlynomial REgression) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs. Our two SPORE algorithms are able to build relationships between responses (e.g., the execution time of a computer program) and features, and select a few from hundreds of the retrieved features to construct an explicitly sparse and non-linear model to predict the response variable. The compact and explicitly polynomial form of the estimated model could reveal important insights into the computer program (e.g., features and their non-linear combinations that dominate the execution time), enabling a better understanding of the program's behavior. Our evaluation on three widely used computer programs shows that SPORE methods can give accurate prediction with relative error less than 7% by using a moderate number of training data samples. In addition, we compare SPORE algorithms to state-of-the-art sparse regression algorithms, and show that SPORE methods, motivated by real applications, outperform the other methods in terms of both interpretability and prediction accuracy.},
booktitle = {Proceedings of the 24th International Conference on Neural Information Processing Systems - Volume 1},
pages = {883–891},
numpages = {9},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'10}
}

@inproceedings{10.1145/3023956.3023963,
author = {Halin, Axel and Nuttinck, Alexandre and Acher, Mathieu and Devroey, Xavier and Perrouin, Gilles and Heymans, Patrick},
title = {Yo variability! JHipster: a playground for web-apps analyses},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023963},
doi = {10.1145/3023956.3023963},
abstract = {Though variability is everywhere, there has always been a shortage of publicly available cases for assessing variability-aware tools and techniques as well as supports for teaching variability-related concepts. Historical software product lines contains industrial secrets their owners do not want to disclose to a wide audience. The open source community contributed to large-scale cases such as Eclipse, Linux kernels, or web-based plugin systems (Drupal, WordPress). To assess accuracy of sampling and prediction approaches (bugs, performance), a case where all products can be enumerated is desirable. As configuration issues do not lie within only one place but are scattered across technologies and assets, a case exposing such diversity is an additional asset. To this end, we present in this paper our efforts in building an explicit product line on top of JHipster, an industrial open-source Web-app configurator that is both manageable in terms of configurations (≈ 163,000) and diverse in terms of technologies used. We present our efforts in building a variability-aware chain on top of JHipster's configurator and lessons learned using it as a teaching case at the University of Rennes. We also sketch the diversity of analyses that can be performed with our infrastructure as well as early issues found using it. Our long term goal is both to support students and researchers studying variability analysis and JHipster developers in the maintenance and evolution of their tools.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {44–51},
numpages = {8},
keywords = {web-apps, variability-related analyses, case study},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@article{10.1016/j.jss.2019.04.051,
author = {Sampaio, Gabriela and Borba, Paulo and Teixeira, Leopoldo},
title = {Partially safe evolution of software product lines},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {155},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.051},
doi = {10.1016/j.jss.2019.04.051},
journal = {J. Syst. Softw.},
month = sep,
pages = {17–42},
numpages = {26},
keywords = {Product line refinement, Product line maintenance, Product line evolution}
}

@article{10.1016/j.ins.2021.08.100,
author = {Song, Xiangyu and Li, Jianxin and Tang, Yifu and Zhao, Taige and Chen, Yunliang and Guan, Ziyu},
title = {JKT: A joint graph convolutional network based Deep Knowledge Tracing},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {580},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.08.100},
doi = {10.1016/j.ins.2021.08.100},
journal = {Inf. Sci.},
month = nov,
pages = {510–523},
numpages = {14},
keywords = {Network representation learning, Intelligent tutoring systems, Learning analytics, Graph neural network, Knowledge Tracing}
}

@inproceedings{10.1145/3377811.3380372,
author = {Lienhardt, Michael and Damiani, Ferruccio and Johnsen, Einar Broch and Mauro, Jacopo},
title = {Lazy product discovery in huge configuration spaces},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380372},
doi = {10.1145/3377811.3380372},
abstract = {Highly-configurable software systems can have thousands of interdependent configuration options across different subsystems. In the resulting configuration space, discovering a valid product configuration for some selected options can be complex and error prone. The configuration space can be organized using a feature model, fragmented into smaller interdependent feature models reflecting the configuration options of each subsystem.We propose a method for lazy product discovery in large fragmented feature models with interdependent features. We formalize the method and prove its soundness and completeness. The evaluation explores an industrial-size configuration space. The results show that lazy product discovery has significant performance benefits compared to standard product discovery, which in contrast to our method requires all fragments to be composed to analyze the feature model. Furthermore, the method succeeds when more efficient, heuristics-based engines fail to find a valid configuration.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1509–1521},
numpages = {13},
keywords = {Linux distribution, composition, configurable software, feature models, software product lines, variability modeling},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1016/j.eswa.2015.05.047,
author = {Ma, Zhiwei and Leung, Juliana Y. and Zanon, Stefan and Dzurman, Peter},
title = {Practical implementation of knowledge-based approaches for steam-assisted gravity drainage production analysis},
year = {2015},
issue_date = {Nov 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {21},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.05.047},
doi = {10.1016/j.eswa.2015.05.047},
journal = {Expert Syst. Appl.},
month = nov,
pages = {7326–7343},
numpages = {18},
keywords = {Production forecast, Data mining, Petroleum engineering, Steam-assisted gravity drainage, Model uncertainties, Neural networks, Statistical analysis}
}

@article{10.1016/j.ins.2012.12.050,
author = {Ofoghi, Bahadorreza and Zeleznikow, John and Macmahon, Clare and Dwyer, Dan},
title = {Supporting athlete selection and strategic planning in track cycling omnium: A statistical and machine learning approach},
year = {2013},
issue_date = {June, 2013},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {233},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2012.12.050},
doi = {10.1016/j.ins.2012.12.050},
abstract = {This article describes the implementation of machine learning techniques that assist cycling experts in the crucial decision-making processes for athlete selection and strategic planning in the track cycling omnium. The omnium is a multi-event competition that was included in the Olympic Games for the first time in 2012. Presently, selectors and cycling coaches make decisions based on experience and opinion. They rarely have access to knowledge that helps predict athletic performances. The omnium presents a unique and complex decision-making challenge as it is not clear what type of athlete is best suited to the omnium (e.g., sprint or endurance specialist) and tactical decisions made by the coach and athlete during the event will have significant effects on the overall performance of the athlete. In the present work, a variety of machine learning techniques were used to analyze omnium competition data from the World Championships since 2007. The analysis indicates that sprint events have slightly more influence in determining the medalists, than endurance-based events. Using a probabilistic analysis, we created a model of performance prediction that provides an unprecedented level of supporting information that assists coaches with strategic and tactical decisions during the omnium.},
journal = {Inf. Sci.},
month = jun,
pages = {200–213},
numpages = {14},
keywords = {Machine learning, Decision support, Bayesian network, Track cycling omnium, Statistical analysis}
}

@article{10.1016/j.eswa.2013.06.025,
author = {Sowan, Bilal and Dahal, Keshav and Hossain, M. A. and Zhang, Li and Spencer, Linda},
title = {Fuzzy association rule mining approaches for enhancing prediction performance},
year = {2013},
issue_date = {December, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {17},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2013.06.025},
doi = {10.1016/j.eswa.2013.06.025},
abstract = {This paper presents an investigation into two fuzzy association rule mining models for enhancing prediction performance. The first model (the FCM-Apriori model) integrates Fuzzy C-Means (FCM) and the Apriori approach for road traffic performance prediction. FCM is used to define the membership functions of fuzzy sets and the Apriori approach is employed to identify the Fuzzy Association Rules (FARs). The proposed model extracts knowledge from a database for a Fuzzy Inference System (FIS) that can be used in prediction of a future value. The knowledge extraction process and the performance of the model are demonstrated through two case studies of road traffic data sets with different sizes. The experimental results show the merits and capability of the proposed KD model in FARs based knowledge extraction. The second model (the FCM-MSapriori model) integrates FCM and a Multiple Support Apriori (MSapriori) approach to extract the FARs. These FARs provide the knowledge base to be utilized within the FIS for prediction evaluation. Experimental results have shown that the FCM-MSapriori model predicted the future values effectively and outperformed the FCM-Apriori model and other models reported in the literature.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {6928–6937},
numpages = {10},
keywords = {Prediction, Knowledge discovery, Fuzzy association rules, Fuzzy C-Mean, Data mining, Apriori algorithms}
}

@article{10.1145/3011286.3011291,
author = {Galster, Matthias and Zdun, Uwe and Weyns, Danny and Rabiser, Rick and Zhang, Bo and Goedicke, Michael and Perrouin, Gilles},
title = {Variability and Complexity in Software Design: Towards a Research Agenda},
year = {2017},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/3011286.3011291},
doi = {10.1145/3011286.3011291},
abstract = {Many of today's software systems accommodate different usage and deployment scenarios. Intentional and unintentional variability in functionality or quality attributes (e.g., performance) of software significantly increases the complexity of the problem and design space of those systems. The complexity caused by variability becomes increasingly difficult to handle due to the increasing size of software systems, new and emerging application domains, dynamic operating conditions under which software systems have to operate, fast moving and highly competitive markets, and more powerful and versatile hardware. This paper reports results of the first International Workshop on Variability and Complexity in Software Design that brought together researchers and engineers interested in the topic of complexity and variability. It also outlines directions the field might move in the future},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {27–30},
numpages = {4},
keywords = {software design, complexity, Variability}
}

@article{10.1016/j.jss.2015.12.024,
author = {Preuveneers, Davy and Heyman, Thomas and Berbers, Yolande and Joosen, Wouter},
title = {Systematic scalability assessment for feature oriented multi-tenant services},
year = {2016},
issue_date = {June 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {116},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.12.024},
doi = {10.1016/j.jss.2015.12.024},
abstract = {We present tool support and methodology for systematic scalability assessments.Scalar delivers strategic insights for multi-tenant customizable SaaS applications.It measures impact and scalability potential of feature combinations across tenants.Detection of unanticipated feature interactions is demonstrated in e-payment case.Automated scalability analysis is reusable asset in continuous integration process. Recent software engineering paradigms such as software product lines, supporting development techniques like feature modeling, and cloud provisioning models such as platform and infrastructure as a service, allow for great flexibility during both software design and deployment, resulting in potentially large cost savings. However, all this flexibility comes with a catch: as the combinatorial complexity of optional design features and deployment variability increases, the difficulty of assessing system qualities such as scalability and quality of service increases too. And if the software itself is not scalable (for instance, because of a specific set of selected features), deploying additional service instances is a futile endeavor. Clearly there is a need to systematically measure the impact of feature selection on scalability, as the potential cost savings can be completely mitigated by the risk of having a system that is unable to meet service demand.In this work, we document our results on systematic load testing for automated quality of service and scalability analysis. The major contribution of our work is tool support and a methodology to analyze the scalability of these distributed, feature oriented multi-tenant software systems in a continuous integration process. We discuss our approach to select features for load testing such that a representative set of feature combinations is used to elicit valuable information on the performance impact and feature interactions. Additionally, we highlight how our methodology and framework for performance and scalability prediction differs from state-of-practice solutions. We take the viewpoint of both the tenant of the service and the service provider, and report on our experiences applying the approach to an industrial use case in the domain of electronic payments. We conclude that the integration of systematic scalability tests in a continuous integration process offers strong advantages to software developers and service providers, such as the ability to quantify the impact of new features in existing service compositions, and the early detection of hidden feature interactions that may negatively affect the overall performance of multi-tenant services.},
journal = {J. Syst. Softw.},
month = jun,
pages = {162–176},
numpages = {15},
keywords = {Tool support, Scalability, Distributed systems}
}

@article{10.1016/j.neucom.2020.10.115,
author = {Wu, Xing and Chen, Cheng and Zhong, Mingyu and Wang, Jianjia},
title = {HAL: Hybrid active learning for efficient labeling in medical domain},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {456},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.10.115},
doi = {10.1016/j.neucom.2020.10.115},
journal = {Neurocomput.},
month = oct,
pages = {563–572},
numpages = {10},
keywords = {Prediction loss, Sample diversity, Transfer learning, Computer-aided diagnosis, Active learning}
}

@inproceedings{10.1109/SE4Science.2019.00010,
author = {Vogel, Thomas and Druskat, Stephan and Scheidgen, Markus and Draxl, Claudia and Grunske, Lars},
title = {Challenges for verifying and validating scientific software in computational materials science},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SE4Science.2019.00010},
doi = {10.1109/SE4Science.2019.00010},
abstract = {Many fields of science rely on software systems to answer different research questions. For valid results researchers need to trust the results scientific software produces, and consequently quality assurance is of utmost importance. In this paper we are investigating the impact of quality assurance in the domain of computational materials science (CMS). Based on our experience in this domain we formulate challenges for validation and verification of scientific software and their results. Furthermore, we describe directions for future research that can potentially help dealing with these challenges.},
booktitle = {Proceedings of the 14th International Workshop on Software Engineering for Science},
pages = {25–32},
numpages = {8},
keywords = {computational materials science, verification and validation, scientific software},
location = {Montreal, Quebec, Canada},
series = {SE4Science '19}
}

@inproceedings{10.1145/2908812.2908871,
author = {Arrieta, Aitor and Wang, Shuai and Sagardui, Goiuria and Etxeberria, Leire},
title = {Test Case Prioritization of Configurable Cyber-Physical Systems with Weight-Based Search Algorithms},
year = {2016},
isbn = {9781450342063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908812.2908871},
doi = {10.1145/2908812.2908871},
abstract = {Cyber-Physical Systems (CPSs) can be found in many sectors (e.g., automotive and aerospace). These systems are usually configurable to give solutions based on different needs. The variability of these systems is large, which implies they can be set into millions of configurations. As a result, different testing processes are needed to efficiently test these systems: the appropriate configurations must be selected and relevant test cases for each configuration must be chosen as well as prioritized. Prioritizing the order in which the test cases are executed reduces the time for detecting faults in these kinds of systems. However, the test suite size is often large and exploring all the possible test case orders is infeasible. Search algorithms can help find optimal solutions from a large solution space. This paper presents an approach based on weight-based search algorithms for prioritizing the test cases for configurable CPSs. We empirically evaluate the performance of the following algorithms with two case studies: Weight-Based Genetic Algorithms, Random Weighted Genetic Algorithms, Greedy, Alternating Variable Method and Random Search (RS). Our results suggest that all the search algorithms outperform RS, which is taken as a baseline. Local search algorithms have shown better performance than global search algorithms.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
pages = {1053–1060},
numpages = {8},
keywords = {configurable cyber-physical systems, search algorithms, test case prioritization, testing},
location = {Denver, Colorado, USA},
series = {GECCO '16}
}

@inproceedings{10.1145/3168365.3168372,
author = {Acher, Mathieu and Temple, Paul and J\'{e}z\'{e}quel, Jean-Marc and Galindo, Jos\'{e} A. and Martinez, Jabier and Ziadi, Tewfik},
title = {VaryLATEX: Learning Paper Variants That Meet Constraints},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168372},
doi = {10.1145/3168365.3168372},
abstract = {How to submit a research paper, a technical report, a grant proposal, or a curriculum vitae that respect imposed constraints such as formatting instructions and page limits? It is a challenging task, especially when coping with time pressure. In this work, we present VaryLATEX, a solution based on variability, constraint programming, and machine learning techniques for documents written in LATEX to meet constraints and deliver on time. Users simply have to annotate LATEX source files with variability information, e.g., (de)activating portions of text, tuning figures' sizes, or tweaking line spacing. Then, a fully automated procedure learns constraints among Boolean and numerical values for avoiding non-acceptable paper variants, and finally, users can further configure their papers (e.g., aesthetic considerations) or pick a (random) paper variant that meets constraints, e.g., page limits. We describe our implementation and report the results of two experiences with VaryLATEX.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {83–88},
numpages = {6},
keywords = {LATEX, constraint programming, generators, machine learning, technical writing, variability modelling},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@article{10.5555/1351183.1351225,
author = {Sahiner, Berkman and Chan, Heang-Ping and Hadjiiski, Lubomir},
title = {2008 Special Issue: Classifier performance estimation under the constraint of a finite sample size: Resampling schemes applied to neural network classifiers},
year = {2008},
issue_date = {March, 2008},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {21},
number = {2–3},
issn = {0893-6080},
abstract = {In a practical classifier design problem the sample size is limited, and the available finite sample needs to be used both to design a classifier and to predict the classifier's performance for the true population. Since a larger sample is more representative of the population, it is advantageous to design the classifier with all the available cases, and to use a resampling technique for performance prediction. We conducted a Monte Carlo simulation study to compare the ability of different resampling techniques in predicting the performance of a neural network (NN) classifier designed with the available sample. We used the area under the receiver operating characteristic curve as the performance index for the NN classifier. We investigated resampling techniques based on the cross-validation, the leave-one-out method, and three different types of bootstrapping, namely, the ordinary, .632, and .632+ bootstrap. Our results indicated that, under the study conditions, there can be a large difference in the accuracy of the prediction obtained from different resampling methods, especially when the feature space dimensionality is relatively large and the sample size is small. Although this investigation is performed under some specific conditions, it reveals important trends for the problem of classifier performance prediction under the constraint of a limited data set.},
journal = {Neural Netw.},
month = mar,
pages = {476–483},
numpages = {8},
keywords = {Finite sample size, Performance estimation, Resampling}
}

@article{10.14778/3476311.3476380,
author = {Li, Guoliang and Zhou, Xuanhe and Sun, Ji and Yu, Xiang and Han, Yue and Jin, Lianyuan and Li, Wenbo and Wang, Tianqing and Li, Shifu},
title = {openGauss: an autonomous database system},
year = {2021},
issue_date = {July 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3476311.3476380},
doi = {10.14778/3476311.3476380},
abstract = {Although learning-based database optimization techniques have been studied from academia in recent years, they have not been widely deployed in commercial database systems. In this work, we build an autonomous database framework and integrate our proposed learning-based database techniques into an open-source database system openGauss. We propose effective learning-based models to build learned optimizers (including learned query rewrite, learned cost/cardinality estimation, learned join order selection and physical operator selection) and learned database advisors (including self-monitoring, self-diagnosis, self-configuration, and self-optimization). We devise an effective validation model to validate the effectiveness of learned models. We build effective training data management and model management platforms to easily deploy learned models. We have evaluated our techniques on real-world datasets and the experimental results validated the effectiveness of our techniques. We also provide our learnings of deploying learning-based techniques.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {3028–3042},
numpages = {15}
}

@article{10.1016/j.peva.2009.07.007,
author = {Koziolek, Heiko},
title = {Performance evaluation of component-based software systems: A survey},
year = {2010},
issue_date = {August, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {67},
number = {8},
issn = {0166-5316},
url = {https://doi.org/10.1016/j.peva.2009.07.007},
doi = {10.1016/j.peva.2009.07.007},
abstract = {Performance prediction and measurement approaches for component-based software systems help software architects to evaluate their systems based on component performance specifications created by component developers. Integrating classical performance models such as queueing networks, stochastic Petri nets, or stochastic process algebras, these approaches additionally exploit the benefits of component-based software engineering, such as reuse and division of work. Although researchers have proposed many approaches in this direction during the last decade, none of them has attained widespread industrial use. On this basis, we have conducted a comprehensive state-of-the-art survey of more than 20 of these approaches assessing their applicability. We classified the approaches according to the expressiveness of their component performance modelling languages. Our survey helps practitioners to select an appropriate approach and scientists to identify interesting topics for future research.},
journal = {Perform. Eval.},
month = aug,
pages = {634–658},
numpages = {25},
keywords = {CBSE, Classification, Measurement, Modelling, Performance, Prediction, Software component, Survey}
}

@inproceedings{10.5555/2021855.2021877,
author = {Pardos, Zachary A. and Heffernan, Neil T.},
title = {KT-IDEM: introducing item difficulty to the knowledge tracing model},
year = {2011},
isbn = {9783642223617},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Many models in computer education and assessment take into account difficulty. However, despite the positive results of models that take difficulty in to account, knowledge tracing is still used in its basic form due to its skill level diagnostic abilities that are very useful to teachers. This leads to the research question we address in this work: Can KT be effectively extended to capture item difficulty and improve prediction accuracy? There have been a variety of extensions to KT in recent years. One such extension was Baker's contextual guess and slip model. While this model has shown positive gains over KT in internal validation testing, it has not performed well relative to KT on unseen in-tutor data or post-test data, however, it has proven a valuable model to use alongside other models. The contextual guess and slip model increases the complexity of KT by adding regression steps and feature generation. The added complexity of feature generation across datasets may have hindered the performance of this model. Therefore, one of the aims of our work here is to make the most minimal of modifications to the KT model in order to add item difficulty and keep the modification limited to changing the topology of the model. We analyze datasets from two intelligent tutoring systems with KT and a model we have called KT-IDEM (Item Difficulty Effect Model) and show that substantial performance gains can be achieved with this minor modification that incorporates item difficulty.},
booktitle = {Proceedings of the 19th International Conference on User Modeling, Adaption, and Personalization},
pages = {243–254},
numpages = {12},
keywords = {Bayesian networks, data mining, item difficulty, knowledge tracing, user modeling},
location = {Girona, Spain},
series = {UMAP'11}
}

@article{10.1016/j.asoc.2010.11.005,
author = {Joshi, S. N. and Pande, S. S.},
title = {Intelligent process modeling and optimization of die-sinking electric discharge machining},
year = {2011},
issue_date = {March, 2011},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {11},
number = {2},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2010.11.005},
doi = {10.1016/j.asoc.2010.11.005},
abstract = {This paper reports an intelligent approach for process modeling and optimization of electric discharge machining (EDM). Physics based process modeling using finite element method (FEM) has been integrated with the soft computing techniques like artificial neural networks (ANN) and genetic algorithm (GA) to improve prediction accuracy of the model with less dependency on the experimental data. A two-dimensional axi-symmetric numerical (FEM) model of single spark EDM process has been developed based on more realistic assumptions such as Gaussian distribution of heat flux, time and energy dependent spark radius, etc. to predict the shape of crater, material removal rate (MRR) and tool wear rate (TWR). The model is validated using the reported analytical and experimental results. A comprehensive ANN based process model is proposed to establish relation between input process conditions (current, discharge voltage, duty cycle and discharge duration) and the process responses (crater size, MRR and TWR) .The ANN model was trained, tested and tuned by using the data generated from the numerical (FEM) model. It was found to accurately predict EDM process responses for chosen process conditions. The developed ANN process model was used in conjunction with the evolutionary non-dominated sorting genetic algorithm II (NSGA-II) to select optimal process parameters for roughing and finishing operations of EDM. Experimental studies were carried out to verify the process performance for the optimum machining conditions suggested by our approach. The proposed integrated (FEM-ANN-GA) approach was found efficient and robust as the suggested optimum process parameters were found to give the expected optimum performance of the EDM process.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {2743–2755},
numpages = {13},
keywords = {Artificial neural networks (ANN), Electric discharge machining (EDM), Finite element method (FEM), Non-dominated sorting genetic algorithm (NSGA), Process modeling and optimization, Scaled conjugate gradient algorithm (SCG)}
}

@inproceedings{10.1145/3178876.3186058,
author = {Feng, Jie and Li, Yong and Zhang, Chao and Sun, Funing and Meng, Fanchao and Guo, Ang and Jin, Depeng},
title = {DeepMove: Predicting Human Mobility with Attentional Recurrent Networks},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3178876.3186058},
doi = {10.1145/3178876.3186058},
abstract = {Human mobility prediction is of great importance for a wide spectrum of location-based applications. However, predicting mobility is not trivial because of three challenges: 1) the complex sequential transition regularities exhibited with time-dependent and high-order nature; 2) the multi-level periodicity of human mobility; and 3) the heterogeneity and sparsity of the collected trajectory data. In this paper, we propose DeepMove, an attentional recurrent network for mobility prediction from lengthy and sparse trajectories. In DeepMove, we first design a multi-modal embedding recurrent neural network to capture the complicated sequential transitions by jointly embedding the multiple factors that govern the human mobility. Then, we propose a historical attention model with two mechanisms to capture the multi-level periodicity in a principle way, which effectively utilizes the periodicity nature to augment the recurrent neural network for mobility prediction. We perform experiments on three representative real-life mobility datasets, and extensive evaluation results demonstrate that our model outperforms the state-of-the-art models by more than 10%. Moreover, compared with the state-of-the-art neural network models, DeepMove provides intuitive explanations into the prediction and sheds light on interpretable mobility prediction.},
booktitle = {Proceedings of the 2018 World Wide Web Conference},
pages = {1459–1468},
numpages = {10},
keywords = {attention, human mobility, recurrent neural network},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3239235.3239240,
author = {Aljarallah, Sulaiman and Lock, Russell},
title = {An exploratory study of software sustainability dimensions and characteristics: end user perspectives in the kingdom of Saudi Arabia (KSA)},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3239240},
doi = {10.1145/3239235.3239240},
abstract = {Background: Sustainability has become an important topic globally and the focus on ICT sustainability is increasing. However, issues exist, including vagueness and complexity of the concept itself, in addition to immaturity of the Software Engineering (SE) field. Aims: The study surveys respondents on software sustainability dimensions and characteristics from their perspectives, and seeks to derive rankings for their priority. Method: An exploratory study was conducted to quantitatively investigate Saudi Arabian (KSA) software user's perceptions with regard to the concept itself, the dimensions and characteristics of the software sustainability. Survey data was gathered from 906 respondents. Results: The results highlight key dimensions for sustainability and their priorities to users. The results also indicate that the characteristics perceived to be the most significant, were security, usability, reliability, maintainability, extensibility and portability, whereas respondents were relatively less concerned with computer ethics (e.g. privacy and trust), functionality, efficiency and reusability. A key finding was that females considered the environmental dimension to be more important than males. Conclusions: The dimensions and characteristics identified here can be used as a means of providing valuable feedback for the planning and implementation of future development of sustainable software.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {14},
numpages = {10},
keywords = {empirical study, software sustainability, sustainability dimensions},
location = {Oulu, Finland},
series = {ESEM '18}
}

@article{10.5555/2793723.2793882,
author = {Sahiner, Berkman and Chan, Heang-Ping and Hadjiiski, Lubomir},
title = {Classifier performance estimation under the constraint of a finite sample size},
year = {2008},
issue_date = {March 2008},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {21},
number = {2},
issn = {0893-6080},
abstract = {In a practical classifier design problem the sample size is limited, and the available finite sample needs to be used both to design a classifier and to predict the classifier's performance for the true population. Since a larger sample is more representative of the population, it is advantageous to design the classifier with all the available cases, and to use a resampling technique for performance prediction. We conducted a Monte Carlo simulation study to compare the ability of different resampling techniques in predicting the performance of a neural network (NN) classifier designed with the available sample. We used the area under the receiver operating characteristic curve as the performance index for the NN classifier. We investigated resampling techniques based on the cross-validation, the leave-one-out method, and three different types of bootstrapping, namely, the ordinary, .632, and .632+ bootstrap. Our results indicated that, under the study conditions, there can be a large difference in the accuracy of the prediction obtained from different resampling methods, especially when the feature space dimensionality is relatively large and the sample size is small. Although this investigation is performed under some specific conditions, it reveals important trends for the problem of classifier performance prediction under the constraint of a limited data set.},
journal = {Neural Netw.},
month = mar,
pages = {476–483},
numpages = {8},
keywords = {Finite sample size, Performance estimation, Resampling}
}

@inproceedings{10.1007/978-3-030-62463-7_34,
author = {Geng, Shuang and Huang, Miaojia and Wang, Zhibo},
title = {A Swarm Enhanced Light Gradient Boosting Machine for Crowdfunding Project Outcome Prediction},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62463-7_34},
doi = {10.1007/978-3-030-62463-7_34},
abstract = {Crowdfunding is an emerging financing method that project founders could obtain funding from vast investors through the online platform. Therefore, investigating the critical features of crowdfunding projects to forecast the project outcomes have become indispensable. This research draws upon some potential factors and introduces a swarm enhanced light gradient boosting machine (S-LightGBM) model to forecast the crowdfunding performance. Text mining and lexicon-based sentiment analysis methods were employed to derive the linguistic and sentiment features of project descriptions. This study compares the predictive power of logistic regression, support vector machine, light gradient boosting machine, and S-LightGBM on 5916 crowdfunding projects between 2017 and 2018. The result shows that the S-LightGBM approach achieves superior accuracy results than conventional methods. The usefulness of linguistic and sentiment features was also investigated and discussed. This research contributes to the existing research on machine learning methods and crowdfunding and provides fundraisers guidance for the presentation and illustration of innovative projects on crowdfunding platforms.},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {372–382},
numpages = {11},
keywords = {Crowdfunding, Machine learning, Sentiment analysis, Particle swarm optimization},
location = {Guangzhou, China}
}

@inproceedings{10.1007/978-3-030-90888-1_10,
author = {Cui, Shuangshuang and Wang, Hongzhi and Gu, Haiyao and Xie, Yuntian},
title = {Cost-Based Lightweight Storage Automatic Decision for In-Database Machine Learning},
year = {2021},
isbn = {978-3-030-90887-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90888-1_10},
doi = {10.1007/978-3-030-90888-1_10},
abstract = {Storage structure decision for a database aims to automatically determine the effective storage structure according to the data distribution and workload. With the integration of machine learning and database becoming closer, complex machine learning tasks are directly executed in database, and need the support of efficient storage structure. The existing storage decision methods are mainly oriented to common workloads and rely on the decision of experienced DBAs, which has low efficiency and high risk of error. Thus, an automated storage structure decision method for in-database machine learning is urgently needed. We propose a cost-based lightweight row-column storage automatic decision system. To the best of our knowledge, this is the first storage structure selection for machine learning tasks. Extensive experiments show that the accuracy of the storage structure above 90%, shorten the task execution time by about 85%, and greatly reduce the risk of decision error.},
booktitle = {Web Information Systems Engineering – WISE 2021: 22nd International Conference on Web Information Systems Engineering, WISE 2021, Melbourne, VIC, Australia, October 26–29, 2021, Proceedings, Part I},
pages = {119–126},
numpages = {8},
keywords = {AI for DB, Row and column storage, Data partition},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3427921.3450237,
author = {Barnert, Maximilian and Krcmar, Helmut},
title = {Simulation of In-Memory Database Workload: Markov Chains versus Relative Invocation Frequency and Equal Probability - A Trade-off between Accuracy and Time},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450237},
doi = {10.1145/3427921.3450237},
abstract = {In the last years, performance modeling approaches have been proposed to tackle new concepts for modern In-Memory Database Systems (IMDB). While these approaches model specific performance-relevant aspects, workload representation during performance modeling is considered only marginally. Furthermore, the manual integration of workload into modeling approaches comes along with high effort and requires deep domain-specific knowledge.This paper presents our experience in representing workload within performance models for IMDB. In particular, we use a Markov chain-based approach to extract and reflect probabilistic user behavior during performance modeling. An automatic model generation process is integrated to simplify and reduce the effort for transferring workload characteristics from traces to performance models.In an experimental series running analytical and transactional workloads on an IMDB, we compare this approach with two other methods which rely on less granular data to reflect database workload within performance models, namely reproducing the relative invocation frequency of queries and using the same query execution probability. The results reveal a trade-off between accuracy and speed when simulating database workload. Markov chains are the most accurate independent from workload characteristics, but the relative invocation frequency approach is appropriate for scenarios where simulation speed is important.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {73–80},
numpages = {8},
keywords = {Markov chains, SAP HANA, database workload, in-memory database systems, performance modeling, workload representation},
location = {Virtual Event, France},
series = {ICPE '21}
}

@article{10.1007/s11036-021-01775-9,
author = {Lang, Fei and Liang, Lili and Huang, Kai and Chen, Teng and Zhu, Suxia},
title = {Movie Recommendation System for Educational Purposes Based on Field-Aware Factorization Machine},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {5},
issn = {1383-469X},
url = {https://doi.org/10.1007/s11036-021-01775-9},
doi = {10.1007/s11036-021-01775-9},
abstract = {With rich resources, movies have been applied as instructional media in the domain of education, such as fields of Second/Foreign Language Leaning, Communication, and Media Art. Factorization machine (FM) can effectively simulate common matrix factorization models by changing the form of real-value vector, which can be utilized in movies recommendation under the context of education. However, it is usually used to solve classification tasks. This paper applies the field-aware factorization machine (FFM) to solve movie rating prediction and help users select appropriate movies for learning purposes. In order to further enhance the availability of the model, clustering algorithm is also integrated in FFM for adding new fields. The experimental results demonstrate the effectiveness of the proposed methods in reducing the RMSE.},
journal = {Mob. Netw. Appl.},
month = oct,
pages = {2199–2205},
numpages = {7},
keywords = {Movies recommendation, Education, Collaborative filtering, Field-aware factorization machine, Clustering}
}

@inproceedings{10.1145/3430895.3460143,
author = {Soleimani, Farahnaz and Lee, Jeonghyun},
title = {Comparative Analysis of the Feature Extraction Approaches for Predicting Learners Progress in Online Courses: MicroMasters Credential versus Traditional MOOCs},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460143},
doi = {10.1145/3430895.3460143},
abstract = {Although MicroMasters courses differ from traditional undergraduate level MOOCs in student demographics, course design, and outcomes, the various aspects of this type of program have not yet been sufficiently investigated. This study aims to pave the path towards enhancing the design of constituent courses of MicroMasters programs with the focus on the application of Machine Learning algorithms. Thereby, we use a large-scale clickstream edX database to explore the trends in the online engagement of learners in a MicroMasters program, detect clickstream events that are highly correlated with the students' progress, and investigate how the engagements differ from those in a classic individual MOOC. Contrary to the previous application of machine learning algorithms in learning analytics, we implement various well-known machine learning approaches such as stepwise regression and tree-based algorithms, evaluate their performance, and propose the best-performed approach. We elaborate on noticeable differences between the engagements of the considered two groups.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {151–159},
numpages = {9},
keywords = {clickstream data, learning analytics, machine learning., micromasters, mooc, online higher education},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@article{10.1016/j.eswa.2005.07.026,
author = {Yu, Enzhe and Cho, Sungzoon},
title = {Constructing response model using ensemble based on feature subset selection},
year = {2006},
issue_date = {February, 2006},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {30},
number = {2},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2005.07.026},
doi = {10.1016/j.eswa.2005.07.026},
abstract = {In building a response model, determining the inputs to the model has been an important issue because of the complexities of the marketing problem and limitations of mental models for decision-making. It is common that the customers' historical purchase data contains many irrelevant or redundant features thus result in bad model performance. Furthermore, single complex models based on feature subset selection may not always report improved performance largely because of overfitting and instability. Ensemble is a widely adopted mechanism for alleviating such problems. In this paper, we propose an ensemble creation method based on GA based wrapper feature subset selection mechanism. Through experimental studies on DMEF4 data set, we found that the proposed method has, at least, two distinct advantages over other models: first, the ability to account for the important inputs to the response model; second, improved prediction accuracy and stability.},
journal = {Expert Syst. Appl.},
month = feb,
pages = {352–360},
numpages = {9},
keywords = {Ensemble, Feature selection, Response model, SVM}
}

@article{10.1016/j.eswa.2008.09.025,
author = {Tsai, Chih-Fong and Chiou, Yen-Jiun},
title = {Earnings management prediction: A pilot study of combining neural networks and decision trees},
year = {2009},
issue_date = {April, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.09.025},
doi = {10.1016/j.eswa.2008.09.025},
abstract = {Many financial crisis cases related to the public companies have increased recently, but many investors and creditors are difficult to foresee the financial crisis, especially in the cases with earnings management. Earnings management is manipulating earnings to fulfill managers' purposes using certain methods or processes. In literature, many studies related to earnings management only focus on identifying some related factors which can significantly affect earnings management. Therefore, we can only figure out the correlation between these factors and earnings management. However, these factors have not been used directly to forecast the level of earnings management in advance (i.e. upward and downward earnings management). In order to decrease the financial crisis risks derived from earnings management and help the investors avoid suffering a great loss in the stock market, we developed a neural network model to predict the level of earnings management. By using the Taiwan Economic Journal (TEJ) dataset and 11 factors which affect earnings management studied in literature, the model provides the highest prediction rate of 81% in the cases of manipulating earnings upwards. In addition, the cases which are correctly predicted by the neural network model are used to construct a decision tree model to generate useful decision rules. Two important rules are identified to allow investors and creditors for effective earnings management prediction. Combining the neural network and decision tree models provide not only higher rate of prediction accuracy but also important decision rules compared with using the neural network model alone.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {7183–7191},
numpages = {9},
keywords = {Decision trees, Earnings management, Neural networks}
}

@inproceedings{10.1007/978-3-642-11970-5_15,
author = {Jiang, Yunlian and Zhang, Eddy Z. and Tian, Kai and Shen, Xipeng},
title = {Is reuse distance applicable to data locality analysis on chip multiprocessors?},
year = {2010},
isbn = {3642119697},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-11970-5_15},
doi = {10.1007/978-3-642-11970-5_15},
abstract = {On Chip Multiprocessors (CMP), it is common that multiple cores share certain levels of cache. The sharing increases the contention in cache and memory-to-chip bandwidth, further highlighting the importance of data locality analysis.As a rigorous and hardware-independent locality metric, reuse distance has served for a variety of locality analysis, program transformations, and performance prediction. However, previous studies have concentrated on sequential programs running on unicore processors. On CMP, accesses by different threads (or jobs) interact in the shared cache. How reuse distance applies to the new architecture remains an open question—particularly, how the interactions in shared cache affect the collection and application of reuse distance, and how reuse-distance–based locality analysis should adapt to such architecture changes.This paper presents our explorations towards answering those questions. It first introduces the concept of concurrent reuse distance, a direct extension of the traditional concept of reuse distance with data references by all co-running threads (or jobs) considered. It then discusses the properties of concurrent reuse distance, revealing the special challenges facing the collection and application of concurrent reuse distance on CMP platforms. Finally, it presents the solutions to those challenges for a class of multithreading applications. The solutions center on a probabilistic model that connects concurrent reuse distance with the data locality of each individual thread. Experiments demonstrate the effectiveness of the proposed techniques in facilitating the uses of concurrent reuse distance for CMP computing.},
booktitle = {Proceedings of the 19th Joint European Conference on Theory and Practice of Software, International Conference on Compiler Construction},
pages = {264–282},
numpages = {19},
location = {Paphos, Cyprus},
series = {CC'10/ETAPS'10}
}

@article{10.1007/s00500-021-05850-x,
author = {Bai, Anita and Hira, Swati},
title = {An intelligent hybrid deep belief network model for predicting students employability},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {14},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-05850-x},
doi = {10.1007/s00500-021-05850-x},
abstract = {In recent times, the question of employability has become a critical concern not only for degree holders but for educational organizations. Hence, employability prediction models play an important role in analyzing the student’s capability to get employment. In this paper, a hybrid model of deep belief network and soft max regression (DBN-SR) is proposed for student employability prediction. Initially, pre-processing is performed on student’s data for removing irrelevant attributes to achieve data consistency. Further, to enhance the accuracy of the prediction model, the crow search algorithm-based feature selection model is employed to select the optimal subset of features from original features. Then, the selected subset of features is taken as the input of the deep belief network (DBN) for intrinsic feature learning to obtain high-level feature representation. Finally, the soft max regression (SR) is used to predict the class of students as employed or unemployed. The proposed employability prediction model achieves above 98% of accuracy which is comparatively 2.5%, 5% higher than the deep autoencoder and deep neural network-based models. The performance outcomes proved that the proposed DBN-SR model has been well suitable for predicting student’s employability.},
journal = {Soft Comput.},
month = jul,
pages = {9241–9254},
numpages = {14},
keywords = {Employability prediction, Crow search algorithm, Deep belief network-softmax regression, Data mining}
}

@inproceedings{10.1145/3377325.3377519,
author = {Alqaraawi, Ahmed and Schuessler, Martin and Wei\ss{}, Philipp and Costanza, Enrico and Berthouze, Nadia},
title = {Evaluating saliency map explanations for convolutional neural networks: a user study},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377519},
doi = {10.1145/3377325.3377519},
abstract = {Convolutional neural networks (CNNs) offer great machine learning performance over a range of applications, but their operation is hard to interpret, even for experts. Various explanation algorithms have been proposed to address this issue, yet limited research effort has been reported concerning their user evaluation. In this paper, we report on an online between-group user study designed to evaluate the performance of "saliency maps" - a popular explanation algorithm for image classification applications of CNNs. Our results indicate that saliency maps produced by the LRP algorithm helped participants to learn about some specific image features the system is sensitive to. However, the maps seem to provide very limited help for participants to anticipate the network's output for new images. Drawing on our findings, we highlight implications for design and further research on explainable AL In particular, we argue the HCI and AI communities should look beyond instance-level explanations.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {275–285},
numpages = {11},
keywords = {explainable AI, heatmap, human-AI interaction, saliency-maps, user studies},
location = {Cagliari, Italy},
series = {IUI '20}
}

@inproceedings{10.1145/3456389.3456406,
author = {Yu, Zhenyu and Wang, Zhibao and Bai, Lu and Chen, Liangfu and Tao, Jinhua},
title = {Parameter Optimization on Spark for Particulate Matter Estimation},
year = {2021},
isbn = {9781450389945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3456389.3456406},
doi = {10.1145/3456389.3456406},
abstract = {With the rapid growth of remote sensing satellites, the volume of remote sensing data has been continuously increasing, which makes it necessary to utilize the big data platform for the rapid practical application of remote sensing inversion algorithms. This paper proposes an atmospheric remote sensing inversion processing method based on Spark. As a popular large-scale data processing framework, the memory-based iterable calculation model of Spark makes it suitable for the application of atmospheric remote sensing inversion. In this paper, we use the Spark computing framework to calculate the average value of the particulate matter in China over the past 10 years and the running time is much faster than the traditional single-node method. Furthermore, how Spark configuration parameters affect the performance of the task is explored. Different regression models in XGBoost are used to evaluate the performance of the parameters obtained by the parameter optimization algorithm in order to find the Spark optimal configuration parameters that meet the requirements.},
booktitle = {2021 Workshop on Algorithm and Big Data},
pages = {9–13},
numpages = {5},
location = {Fuzhou, China},
series = {WABD 2021}
}

@article{10.1016/j.knosys.2021.107248,
author = {Yang, Lu and Liu, Yezheng and Jiang, Yuanchun and Wu, Le and Sun, Jianshan},
title = {Predicting personalized grouping and consumption: A collaborative evolution model},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {228},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107248},
doi = {10.1016/j.knosys.2021.107248},
journal = {Know.-Based Syst.},
month = sep,
numpages = {20},
keywords = {Consumption behavior, Grouping behavior, Group norms, Collaborative evolution and prediction, Temporal probabilistic matrix factorization}
}

@inproceedings{10.1145/3459637.3482094,
author = {Giatrakos, Nikos and Kougioumtzi, Eleni and Kontaxakis, Antonios and Deligiannakis, Antonios and Kotidis, Yannis},
title = {EasyFlinkCEP: Big Event Data Analytics for Everyone},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482094},
doi = {10.1145/3459637.3482094},
abstract = {FlinkCEP is the Complex Event Processing (CEP) API of the Flink Big Data platform. The high expressive power of the language of FlinkCEP comes at the cost of cumbersome parameterization of the queried patterns, acting as a barrier for FlinkCEP's adoption. Moreover, properly configuring a FlinkCEP program to run over a computer cluster requires advanced skills on modern hardware administration which non-expert programmers do not possess. In this work (i) we build a novel, logical CEP operator that receives CEP pattern queries in the form of extended regular expressions and seamlessly re-writes them to FlinkCEP programs, (ii) we build a CEP Optimizer that automatically decides good job configurations for these FlinkCEP programs. We also present an experimental evaluation which demonstrates the significant benefits of our approach.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {3029–3033},
numpages = {5},
keywords = {big data, complex event processing, flinkcep, optimizer},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@phdthesis{10.5555/2604693,
author = {Wang, Guanying},
advisor = {Butt, Ali R.},
title = {Evaluating mapreduce system performance: a simulation approach},
year = {2012},
isbn = {9781303790713},
publisher = {Virginia Polytechnic Institute &amp; State University},
address = {USA},
abstract = {Scale of data generated and processed is exploding in the Big Data era. The MapReduce system popularized by open-source Hadoop is a powerful tool for the exploding data problem, and is widely employed in many areas involving large scale of data. In many circumstances, hypothetical MapReduce systems must be evaluated, e.g. to provision a new MapReduce system to provide certain performance goal, to upgrade a currently running system to meet increasing business demands, to evaluate novel network topology, new scheduling algorithms, or resource arrangement schemes. The traditional trial-and-error solution involves the time- consuming and costly process in which a real cluster is first built and then benchmarked. In this dissertation, we propose to simulate MapReduce systems and evaluate hypothetical MapReduce systems using simulation. This simulation approach offers significantly lower turn-around time and lower cost than experiments. Simulation cannot entirely replace experiments, but can be used as a preliminary step to reveal potential flaws and gain critical insights. We studied MapReduce systems in detail and developed a comprehensive performance model for MapReduce, including sub-task phase level performance models for both map and reduce tasks and a model for resource contention between multiple processes running in concurrent. Based on the performance model, we developed a comprehensive simulator for MapReduce, MRPerf. MRPerf is the first full-featured MapReduce simulator. It supports both workload simulation and resource contention, and it still offers the most complete features among all MapReduce simulators to date. Using MRPerf, we conducted two case studies to evaluate scheduling algorithms in MapReduce and shared storage in MapReduce, without building real clusters. Furthermore, in order to further integrate simulation and performance prediction into Map- Reduce systems and leverage predictions to improve system performance, we developed on- line prediction framework for MapReduce, which periodically runs simulations within a live Hadoop MapReduce system. The framework can predict task execution within a window in near future. These predictions can be used by other components in MapReduce systems in order to improve performance. Our results show that the framework can achieve high prediction accuracy and incurs negligible overhead. We present two potential use cases, prefetching and dynamic adapting scheduler.},
note = {AAI3585937}
}

@inproceedings{10.1145/3385412.3385995,
author = {Ritter, Fabian and Hack, Sebastian},
title = {PMEvo: portable inference of port mappings for out-of-order processors by evolutionary optimization},
year = {2020},
isbn = {9781450376136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385412.3385995},
doi = {10.1145/3385412.3385995},
abstract = {Achieving peak performance in a computer system requires optimizations in every layer of the system, be it hardware or software. A detailed understanding of the underlying hardware, and especially the processor, is crucial to optimize software. One key criterion for the performance of a processor is its ability to exploit instruction-level parallelism. This ability is determined by the port mapping of the processor, which describes the execution units of the processor for each instruction.  Processor manufacturers usually do not share the port mappings of their microarchitectures. While approaches to automatically infer port mappings from experiments exist, they are based on processor-specific hardware performance counters that are not available on every platform.  We present PMEvo, a framework to automatically infer port mappings solely based on the measurement of the execution time of short instruction sequences. PMEvo uses an evolutionary algorithm that evaluates the fitness of candidate mappings with an analytical throughput model formulated as a linear program. Our prototype implementation infers a port mapping for Intel's Skylake architecture that predicts measured instruction throughput with an accuracy that is competitive to existing work. Furthermore, it finds port mappings for AMD's Zen+ architecture and the ARM Cortex-A72 architecture, which are out of scope of existing techniques.},
booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {608–622},
numpages = {15},
keywords = {evolutionary algorithm, port mapping, processor reverse engineering},
location = {London, UK},
series = {PLDI 2020}
}

@article{10.1155/2021/1670593,
author = {Xiao, Wen and Ji, Ping and Hu, Juan and Wang, Pengwei},
title = {RnkHEU: A Hybrid Feature Selection Method for Predicting Students’ Performance},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/1670593},
doi = {10.1155/2021/1670593},
abstract = {Predicting students’ performance is one of the most concerned issues in education data mining (EDM), which has received more and more attentions. Feature selection is the key step to build prediction model of students’ performance, which can improve the accuracy of prediction and help to identify factors that have significant impact on students’ performance. In this paper, a hybrid feature selection method named rank and heuristic (RnkHEU) was proposed. This novel feature selection method generates the set of candidate features by scoring and ranking firstly and then uses heuristic method to generate the final results. The experimental results show that the four major evaluation criteria have similar performance in predicting students’ performance, and the heuristic search strategy can significantly improve the accuracy of prediction compared with forward search method. Because the proposed RnkHEU integrates ranking-based forward and heuristic search, it can further improve the accuracy of predicting students’ performance with commonly used classifiers about 10% and improve the precision of predicting students’ academic failure by up to 45%.},
journal = {Sci. Program.},
month = jan,
numpages = {16}
}

@article{10.1145/2542182.2542195,
author = {Elahi, Mehdi and Ricci, Francesco and Rubens, Neil},
title = {Active learning strategies for rating elicitation in collaborative filtering: A system-wide perspective},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2542182.2542195},
doi = {10.1145/2542182.2542195},
abstract = {The accuracy of collaborative-filtering recommender systems largely depends on three factors: the quality of the rating prediction algorithm, and the quantity and quality of available ratings. While research in the field of recommender systems often concentrates on improving prediction algorithms, even the best algorithms will fail if they are fed poor-quality data during training, that is, garbage in, garbage out. Active learning aims to remedy this problem by focusing on obtaining better-quality data that more aptly reflects a user's preferences. However, traditional evaluation of active learning strategies has two major flaws, which have significant negative ramifications on accurately evaluating the system's performance (prediction error, precision, and quantity of elicited ratings). (1) Performance has been evaluated for each user independently (ignoring system-wide improvements). (2) Active learning strategies have been evaluated in isolation from unsolicited user ratings (natural acquisition).In this article we show that an elicited rating has effects across the system, so a typical user-centric evaluation which ignores any changes of rating prediction of other users also ignores these cumulative effects, which may be more influential on the performance of the system as a whole (system centric). We propose a new evaluation methodology and use it to evaluate some novel and state-of-the-art rating elicitation strategies. We found that the system-wide effectiveness of a rating elicitation strategy depends on the stage of the rating elicitation process, and on the evaluation measures (MAE, NDCG, and Precision). In particular, we show that using some common user-centric strategies may actually degrade the overall performance of a system. Finally, we show that the performance of many common active learning strategies changes significantly when evaluated concurrently with the natural acquisition of ratings in recommender systems.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {13},
numpages = {33},
keywords = {Recommender systems, active learning, cold start, rating elicitation}
}

@article{10.1007/s10586-021-03287-3,
author = {Park, Jueon and Lee, Kyungyong},
title = {S-MPEC: Sparse Matrix Multiplication Performance Estimator on a Cloud Environment},
year = {2021},
issue_date = {Oct 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03287-3},
doi = {10.1007/s10586-021-03287-3},
abstract = {Sparse matrix multiplication (SPMM) is widely used for various machine learning algorithms. As the applications of SPMM using large-scale datasets become prevalent, executing SPMM jobs on an optimized setup has become very important. Execution environments of distributed SPMM tasks on cloud resources can be set up in diverse ways with respect to the input sparse datasets, distinct SPMM implementation methods, and the choice of cloud instance types. In this paper, we propose S-MPEC which can predict latency to complete various SPMM tasks using Apache Spark on distributed cloud environments. We first characterize various distributed SPMM implementations on Apache Spark. Considering the characters and hardware specifications on the cloud, we propose unique features to build a GB-regressor model and Bayesian optimizations. Our proposed S-MPEC model can predict latency on an arbitrary SPMM task accurately and recommend an optimal implementation method. Thorough evaluation of the proposed system reveals that a user can expect 44% less latency to complete SPMM tasks compared with the native SPMM implementations in Apache Spark.},
journal = {Cluster Computing},
month = may,
pages = {2563–2576},
numpages = {14},
keywords = {Cloud computing, Instance recommendation, Sparse matrix multiplication, Apache Spark}
}

@article{10.1007/s00500-020-05023-2,
author = {Liu, Tianyu and Zhu, Xiubin and Pedrycz, Witold and Li, Zhiwu},
title = {A design of information granule-based under-sampling method in imbalanced data classification},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05023-2},
doi = {10.1007/s00500-020-05023-2},
abstract = {In numerous real-world problems, we are faced with difficulties in learning from imbalanced data. The classification performance of a “standard” classifier (learning algorithm) is evidently hindered by the imbalanced distribution of data. The over-sampling and under-sampling methods have been researched extensively with the aim to increase the predication accuracy over the minority class. However, traditional under-sampling methods tend to ignore important characteristics pertinent to the majority class. In this paper, a novel under-sampling method based on information granules is proposed. The method exploits the concepts and algorithms of granular computing. First, information granules are built around the selected patterns coming from the majority class to capture the essence of the data belonging to this class. In the sequel, the resultant information granules are evaluated in terms of their quality and those with the highest specificity values are selected. Next, the selected numeric data are augmented by some weights implied by the size of information granules. Finally, a support vector machine and a K-nearest-neighbor classifier, both being regarded here as representative classifiers, are built based on the weighted data. Experimental studies are carried out using synthetic data as well as a suite of imbalanced data sets coming from the public machine learning repositories. The experimental results quantify the performance of support vector machine and K-nearest-neighbor with under-sampling method based on information granules. The results demonstrate the superiority of the performance obtained for these classifiers endowed with conventional under-sampling method. In general, the improvement of performance expressed in terms of G-means is over 10% when applying information granule under-sampling compared with random under-sampling.},
journal = {Soft Comput.},
month = nov,
pages = {17333–17347},
numpages = {15},
keywords = {Imbalanced data, Information granule, Support vector machine (SVM), K-nearest-neighbor (KNN), Under-sampling}
}

@article{10.1016/j.jnca.2008.11.002,
author = {Lee, Byoung-Dai and Weissman, Jon B. and Nam, Young-Kwang},
title = {Adaptive middleware supporting scalable performance for high-end network services},
year = {2009},
issue_date = {May, 2009},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {32},
number = {3},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2008.11.002},
doi = {10.1016/j.jnca.2008.11.002},
abstract = {Network service-based computation is a promising paradigm for both scientific and engineering, and enterprise computing. The network service allows users to focus on their application and obtain services when needed, simply by invoking the service across the network. In this paper, we show that an adaptive, general-purpose run-time infrastructure in support of effective resource management can be built for a wide range of high-end network services running in a single-site cluster and in a Grid. The primary components of the run-time infrastructure are: (1) dynamic performance prediction; (2) adaptive intra-site resource management; and (3) adaptive inter-site resource management. The novel aspect of our approach is that the run-time system is able to dynamically select the most appropriate performance predictor or resource management strategy over time. This capability not only improves the performance, but also makes the infrastructure reusable across different high-end services. To evaluate the effectiveness and applicability of our approach, we have transformed two different classes of high-end applications-data parallel and distributed applications-into network services using the infrastructure. The experimental results show that the network services running on the infrastructure significantly reduce the overall service times under dynamically varying circumstances.},
journal = {J. Netw. Comput. Appl.},
month = may,
pages = {510–524},
numpages = {15},
keywords = {Adaptivity, Grid, Network service, Resource management}
}

@inproceedings{10.1007/978-3-031-21671-8_10,
author = {Li, Huao and Le, Long and Chis, Max and Zheng, Keyang and Hughes, Dana and Lewis, Michael and Sycara, Katia},
title = {Sequential Theory of Mind Modeling in Team Search and Rescue Tasks},
year = {2021},
isbn = {978-3-031-21670-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21671-8_10},
doi = {10.1007/978-3-031-21671-8_10},
abstract = {The ability to make inferences about other’s mental states is referred to as having a Theory of Mind (ToM). Such ability is fundamental for human social activities such as empathy, teamwork, and communication. As intelligent agents being involved in diverse human-agent teams, they are also expected to be socially intelligent to become effective teammates. In this paper, we propose a computational ToM model which observes team behaviors and infer their mental states in a simulated search and rescue task. The model structure consists of a transformer-based language module and an RNN-based sequential mental state module in order to capture both team communication and behaviors for the ToM inference. To provide a feasible baseline for our ToM model, we present the same inference task to human observers recruited from Amazon MTurk. Results show that our proposed computational model achieves a comparable performance with human observers in the ToM inference task.},
booktitle = {Computational Theory of Mind for Human-Machine Teams: First International Symposium, ToM for Teams 2021, Virtual Event, November 4–6, 2021, Revised Selected Papers},
pages = {158–172},
numpages = {15},
keywords = {Theory of mind, Cognitive modeling, Neural networks, Natural language processing}
}

@article{10.1016/j.comnet.2013.02.025,
author = {Apel, Sven and Von Rhein, Alexander and Th\"{u}m, Thomas and K\"{a}stner, Christian},
title = {Feature-interaction detection based on feature-based specifications},
year = {2013},
issue_date = {August, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {57},
number = {12},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2013.02.025},
doi = {10.1016/j.comnet.2013.02.025},
abstract = {Formal specification and verification techniques have been used successfully to detect feature interactions. We investigate whether feature-based specifications can be used for this task. Feature-based specifications are a special class of specifications that aim at modularity in open-world, feature-oriented systems. The question we address is whether modularity of specifications impairs the ability to detect feature interactions, which cut across feature boundaries. In an exploratory study on 10 feature-oriented systems, we found that the majority of feature interactions could be detected based on feature-based specifications, but some specifications have not been modularized properly and require undesirable workarounds to modularization. Based on the study, we discuss the merits and limitations of feature-based specifications, as well as open issues and perspectives. A goal that underlies our work is to raise awareness of the importance and challenges of feature-based specification.},
journal = {Comput. Netw.},
month = aug,
pages = {2399–2409},
numpages = {11},
keywords = {Feature interaction, Feature orientation, Feature-based specification, Modularity, Software product lines}
}

@inproceedings{10.1145/3456887.3459691,
author = {Sun, Han and Song, Yujun},
title = {Research on Predictive Control of Students' Achievements in Physical Education Class and Physical Education Class Universities Based on Mathematical Model Analysis of Multiple Linear Regression Equations},
year = {2021},
isbn = {9781450389969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3456887.3459691},
doi = {10.1145/3456887.3459691},
abstract = {The academic achievement is influenced by many factors, which is an important basis for teachers and teaching management departments to analyze and study the teaching reform and improve the teaching quality. In many economic forecasting problems, there are often more than one factor affecting the forecast object, and the influence of these factors on the forecast object is linear or nonlinear. For nonlinear regression, it is often transformed into linear regression through appropriate transformation. According to the multivariate linear regression analysis method in multivariate linear statistical analysis, the test score indicators are quantified, and the regression model of test score evaluation and prediction is established, which can effectively predict the ranking of students. Through comparative analysis, the application conditions of this method are explained, and the effectiveness of this method is verified. Finally, the specific ways of applying this method to teaching are analyzed.},
booktitle = {2021 2nd International Conference on Computers, Information Processing and Advanced Education},
pages = {1420–1424},
numpages = {5},
keywords = {Achievement prediction, Multiple linear regression, Physical education class},
location = {Ottawa, ON, Canada},
series = {CIPAE 2021}
}

@article{10.1016/j.ipm.2021.102667,
author = {Luo, Cheng},
title = {Analyzing the impact of social networks and social behavior on electronic business during COVID-19 pandemic},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {58},
number = {5},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2021.102667},
doi = {10.1016/j.ipm.2021.102667},
journal = {Inf. Process. Manage.},
month = sep,
numpages = {13},
keywords = {COVID-19 pandemic situation, E-business, Social networks, Social behavior}
}

@article{10.5555/3546258.3546366,
author = {Li, Zhu and Ton, Jean-Francois and Oglic, Dino and Sejdinovic, Dino},
title = {Towards a unified analysis of random Fourier features},
year = {2021},
issue_date = {January 2021},
publisher = {JMLR.org},
volume = {22},
number = {1},
issn = {1532-4435},
abstract = {Random Fourier features is a widely used, simple, and effective technique for scaling up kernel methods. The existing theoretical analysis of the approach, however, remains focused on specific learning tasks and typically gives pessimistic bounds which are at odds with the empirical results. We tackle these problems and provide the first unified risk analysis of learning with random Fourier features using the squared error and Lipschitz continuous loss functions. In our bounds, the trade-off between the computational cost and the learning risk convergence rate is problem specific and expressed in terms of the regularization parameter and the number of effective degrees of freedom. We study both the standard random Fourier features method for which we improve the existing bounds on the number of features required to guarantee the corresponding minimax risk convergence rate of kernel ridge regression, as well as a data-dependent modification which samples features proportional to ridge leverage scores and further reduces the required number of features. As ridge leverage scores are expensive to compute, we devise a simple approximation scheme which provably reduces the computational cost without loss of statistical efficiency. Our empirical results illustrate the effectiveness of the proposed scheme relative to the standard random Fourier features method.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {108},
numpages = {51},
keywords = {Kernel methods, random Fourier features, stationary kernels, kernel ridge regression, Lipschitz continuous loss, support vector machines, logistic regression, ridge leverage scores}
}

@inproceedings{10.1007/11573067_12,
author = {Schmidt-Heck, Wolfgang and Zeilinger, Katrin and Pless, Gesine and Gerlach, Joerg C. and Pfaff, Michael and Guthke, Reinhard},
title = {Prediction of the performance of human liver cell bioreactors by donor organ data},
year = {2005},
isbn = {3540296743},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11573067_12},
doi = {10.1007/11573067_12},
abstract = {Human liver cell bioreactors are used in extracorporeal liver support therapy. To optimize bioreactor operation with respect to clinical application an early prediction of the long-term bioreactor culture performance is of interest. Data from 70 liver cell bioreactor runs labeled by low (n=18), medium (n=34) and high (n=18) performance were analyzed by statistical and machine learning methods. 25 variables characterizing donor organ properties, organ preservation, cell isolation and cell inoculation prior to bioreactor operation were analyzed with respect to their importance to bioreactor performance prediction. Results obtained were compared and assessed with respect to their robustness. The inoculated volume of liver cells was found to be the most relevant variable allowing the prediction of low versus medium/high bioreactor performance with an accuracy of 84 %.},
booktitle = {Proceedings of the 6th International Conference on Biological and Medical Data Analysis},
pages = {109–119},
numpages = {11},
location = {Aveiro, Portugal},
series = {ISBMDA'05}
}

@article{10.1016/j.mejo.2010.01.004,
author = {Suwa, Tohru and Hadim, Hamid},
title = {Optimal placement of heat generating components at various levels of electronics packaging},
year = {2010},
issue_date = {February, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {41},
number = {2–3},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2010.01.004},
doi = {10.1016/j.mejo.2010.01.004},
abstract = {A multidisciplinary placement optimization methodology for heat generating electronics components is demonstrated at various levels of electronics packaging design. The proposed methodology is capable of handling a large number of conflicting multidisciplinary design requirements and complex trade-offs including thermal, mechanical, electrical, electromagnetic, cost among others, which are optimized simultaneously using a genetic algorithm. An effective thermal performance prediction methodology is developed to shorten the calculation time while retaining sufficient accuracy. For simpler thermal problems, a superposition method is used to predict the temperature distribution caused by arbitrarily placed multiple heat sources. For more complex problems (e.g. variable local heat transfer coefficient) artificial neural networks (ANNs) and the superposition method are combined for more efficient prediction of surface (case) and junction temperatures. The proposed methodology is designed to handle existing complex design trade-offs at the crucial early design stage. Capabilities of the present methodology are demonstrated by applying it to several standard benchmarks at the enclosure (PCB) and chip (logic block) levels.},
journal = {Microelectron. J.},
month = feb,
pages = {129–134},
numpages = {6},
keywords = {Artificial neural network, Component placement optimization, Electronics packaging}
}

@article{10.1145/3149485.3149524,
author = {Galster, Matthias and Weyns, Danny and Goedicke, Michael and Zdun, Uwe and Cunha, J\'{a}come and Chavarriaga, Jaime},
title = {Variability and Complexity in Software Design: Towards Quality through Modeling and Testing},
year = {2018},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3149485.3149524},
doi = {10.1145/3149485.3149524},
abstract = {Today's software systems must accommodate a wide range of usage and deployment scenarios. The increasing size and heterogeneity of software-intensive systems, dynamic and critical operating conditions, fast moving and highly competitive markets, and increasingly powerful and versatile hardware makes it more and more difficult to handle the additional complexity in design caused by variability. This paper reports results of the Second International Workshop on Variability and Complexity in Software Design. It also outlines directions the field might move in the future.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {35–37},
numpages = {3},
keywords = {Variability, complexity, software design}
}

@inproceedings{10.1145/3477132.3483583,
author = {Qiu, Yiming and Xing, Jiarong and Hsu, Kuo-Feng and Kang, Qiao and Liu, Ming and Narayana, Srinivas and Chen, Ang},
title = {Automated SmartNIC Offloading Insights for Network Functions},
year = {2021},
isbn = {9781450387095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477132.3483583},
doi = {10.1145/3477132.3483583},
abstract = {The gap between CPU and networking speeds has motivated the development of SmartNICs for NF (network functions) offloading. However, offloading performance is predicated upon intricate knowledge about SmartNIC hardware and careful hand-tuning of the ported programs. Today, developers cannot easily reason about the offloading performance or the effectiveness of different porting strategies without resorting to a trial-and-error approach.Clara is an automated tool that improves the productivity of this workflow by generating offloading insights. Our tool can a) analyze a legacy NF in its unported form, predicting its performance characteristics on a SmartNIC (e.g., compute vs. memory intensity); and b) explore and suggest porting strategies for the given NF to achieve higher performance. To achieve these goals, Clara uses program analysis techniques to extract NF features, and combines them with machine learning techniques to handle opaque SmartNIC details. Our evaluation using Click NF programs on a Netronome Smart-NIC shows that Clara achieves high accuracy in its analysis, and that its suggested porting strategies lead to significant performance improvements.},
booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
pages = {772–787},
numpages = {16},
keywords = {Machine learning, Network function, SmartNIC},
location = {Virtual Event, Germany},
series = {SOSP '21}
}

@article{10.1007/s10619-020-07286-y,
author = {Al-Sayeh, Hani and Hagedorn, Stefan and Sattler, Kai-Uwe},
title = {A gray-box modeling methodology for runtime prediction of Apache Spark jobs},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {38},
number = {4},
issn = {0926-8782},
url = {https://doi.org/10.1007/s10619-020-07286-y},
doi = {10.1007/s10619-020-07286-y},
abstract = {Apache Spark jobs are often characterized by processing huge data sets and, therefore, require runtimes in the range of minutes to hours. Thus, being able to predict the runtime of such jobs would be useful not only to know when the job will finish, but also for scheduling purposes, to estimate monetary costs for cloud deployment, or to determine an appropriate cluster configuration, such as the number of nodes. However, predicting Spark job runtimes is much more challenging than for standard database queries: cluster configuration and parameters have a significant performance impact and jobs usually contain a lot of user-defined code making it difficult to estimate cardinalities and execution costs. In this paper, we present a gray-box modeling methodology for runtime prediction of Apache Spark jobs. Our approach comprises two steps: first, a white-box model for predicting the cardinalities of the input RDDs of each operator is built based on prior knowledge about the behavior and application parameters such as applied filters data, number of iterations, etc. In the second step, a black-box model for each task constructed by monitoring runtime metrics while varying allocated resources and input RDD cardinalities is used. We further show how to use this gray-box approach not only for predicting the runtime of a given job, but also as part of a decision model for reusing intermediate cached results of Spark jobs. Our methodology is validated with experimental evaluation showing a highly accurate prediction of the actual job runtime and a performance improvement if intermediate results can be reused.},
journal = {Distrib. Parallel Databases},
month = dec,
pages = {819–839},
numpages = {21},
keywords = {Big data, Runtime prediction, Modeling}
}

@inproceedings{10.1145/800040.801412,
author = {Suri, Rajan and Cao, Xiren},
title = {The phantom customer and marked customer methods for optimization of closed queueing networks with blocking and general service times},
year = {1983},
isbn = {0897911121},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800040.801412},
doi = {10.1145/800040.801412},
abstract = {This paper is based on a recent technique called perturbation analysis of discrete event systems. The aims of the paper are two-fold. The first, is to bring this technique, which is still relatively new, to the attention of a wider audience, since the method is particularly relevant to practical systems optimization. The second, is to develop two new methods, the phantom customer method and the marked customer method, as extensions of the perturbation analysis approach. These methods enable efficient and accurate optimization of closed queueing networks with blocking and general service-time distributions. Useful practical applications of these methods would be for optimization of performance of computer systems, communication networks, and automated manufacturing complexes. The accuracy of the methods is illustrated by several numerical examples.},
booktitle = {Proceedings of the 1983 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems},
pages = {243–256},
numpages = {14},
keywords = {Discrete event systems, Performance evaluation, Performance prediction, Perturbation analysis, Queueing networks, Sample path analysis, Simulation},
location = {Minneapolis, Minnesota, USA},
series = {SIGMETRICS '83}
}

@article{10.1504/ijitm.2021.114161,
author = {Zaffar, Maryam and Hashmani, Manzoor Ahmed and Savita, K.S. and Khan, Sameer Ahmad},
title = {A review on feature selection methods for improving the performance of classification in educational data mining},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {20},
number = {1–2},
issn = {1461-4111},
url = {https://doi.org/10.1504/ijitm.2021.114161},
doi = {10.1504/ijitm.2021.114161},
abstract = {Educational data mining (EDM) evaluates and predicts students' performance that assists to discover important factors affecting students' academic performance and also guides educational managers to make appropriate decisions accordingly. The most common technique for discovering meaningful information from the educational database is classification. The accuracy of classification algorithms on educational data can be increased by applying feature selection algorithms. Feature selection algorithms help in selecting robots and meaningful features for predicting students' performance with high accuracy. This paper presents different EDM approaches for forecasting students' performance using different data mining techniques. In addition, this paper also presents an evaluation of recent classification algorithms and feature selection algorithms used in educational data mining. Furthermore, the paper will guide the researchers on new and possible dimensions in building a prediction model in EDM.},
journal = {Int. J. Inf. Technol. Manage.},
month = jan,
pages = {110–131},
numpages = {21},
keywords = {educational data mining, EDM, classification algorithms, feature selection in educational data mining, filter feature selection, wrapper feature selection}
}

@inproceedings{10.1145/3340531.3412041,
author = {Wang, Yaojing and Pan, Guosheng and Yao, Yuan and Tong, Hanghang and Yang, Hongxia and Xu, Feng and Lu, Jian},
title = {Bringing Order to Network Embedding: A Relative Ranking based Approach},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412041},
doi = {10.1145/3340531.3412041},
abstract = {Network embedding aims to automatically learn the node representations in networks. The basic idea of network embedding is to first construct a network to describe the neighborhood context for each node, and then learn the node representations by designing an objective function to preserve certain properties of the constructed context network. The vast majority of the existing methods, explicitly or implicitly, follow a pointwise design principle. That is, the objective can be decomposed into the summation of the certain goodness function over each individual edge of the context network. In this paper, we propose to go beyond such pointwise approaches, and introduce the ranking-oriented design principle for network embedding. The key idea is to decompose the overall objective function into the summation of a goodness function over a set of edges to collectively preserve their relative rankings on the context network. We instantiate the ranking-oriented design principle by two new network embedding algorithms, including a pairwise network embedding method PaWine which optimizes the relative weights of edge pairs, and a listwise method LiWine which optimizes the relative weights of edge lists. Both proposed algorithms bear a linear time complexity, making themselves scalable to large networks. We conduct extensive experimental evaluations on five real datasets with a variety of downstream learning tasks, which demonstrate that the proposed approaches consistently outperform the existing methods.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {1585–1594},
numpages = {10},
keywords = {listwise ranking, network embedding, pairwise ranking},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@inproceedings{10.1109/GRID.2007.4354111,
author = {Yan, Yonghong and Chapman, Barbara},
title = {Scientific workflow scheduling in computational grids   Planning, reservation, and data/network-awareness},
year = {2007},
isbn = {9781424415595},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GRID.2007.4354111},
doi = {10.1109/GRID.2007.4354111},
abstract = {A very important issue in executing a scientific workflow in computational grids is how to map and schedule workflow tasks onto multiple distributed resources and handle task dependencies in a timely manner to deliver users’ expected performance. In this paper, we present our work to develop and evaluate an advanced workflow scheduler in computational grid environments, the GRACCE scheduler. The GRACCE scheduler applies advanced scheduling techniques, such as resource negotiation and reservation, data/network-aware scheduling and performance prediction in the resource allocation and execution planning process. To evaluate the scheduler, we have set up an experimental environment that models a computational grid in those aspects relevant to workflow scheduling. Our results show the average performance improvement, using the GRACCE scheduler, is about 20% under high resource loads.},
booktitle = {Proceedings of the 8th IEEE/ACM International Conference on Grid Computing},
pages = {18–25},
numpages = {8},
series = {GRID '07}
}

@article{10.1155/2009/382501,
author = {Wrulich, Martin and Rupp, Markus},
title = {Computationally efficient MIMO HSDPA system-level modeling},
year = {2009},
issue_date = {February 2009},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2009},
issn = {1687-1472},
url = {https://doi.org/10.1155/2009/382501},
doi = {10.1155/2009/382501},
abstract = {Multiple-inputmultiple-output (MIMO) techniques are regarded as the crucial enhancement of todays wireless access technologies to allow for a significant increase in spectral efficiency. After intensive research on single link performance, the third Generation Partnership Project (3GPP) integrated a spatial multiplexing scheme as MIMO extension of High-Speed Downlink Packet Access (HSDPA). Despite the scientific findings on the link-level performance of MIMO techniques, many questions relevant for the design and optimization of cellular networks remain unanswered. In particular, it has to be identified whether, and to which amount, the predicted MIMO link-level performance gains can be achieved in an entire network. In this paper, we present a computationally efficient link-to-system level model for system-level evaluations of MIMO HSDPA and an exemplary embedding in a MATLAB-based system-level simulator. The introduced equivalent fading parameter structure allows for a semianalytic physical-layer abstraction with high prediction accuracy and simultaneous moderate complexity.},
journal = {EURASIP J. Wirel. Commun. Netw.},
month = feb,
articleno = {10},
numpages = {14}
}

@article{10.1007/s10009-012-0253-y,
author = {Schaefer, Ina and Rabiser, Rick and Clarke, Dave and Bettini, Lorenzo and Benavides, David and Botterweck, Goetz and Pathak, Animesh and Trujillo, Salvador and Villela, Karina},
title = {Software diversity: state of the art and perspectives},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0253-y},
doi = {10.1007/s10009-012-0253-y},
abstract = {Diversity is prevalent in modern software systems to facilitate adapting the software to customer requirements or the execution environment. Diversity has an impact on all phases of the software development process. Appropriate means and organizational structures are required to deal with the additional complexity introduced by software variability. This introductory article to the special section "Software Diversity--Modeling, Analysis and Evolution" provides an overview of the current state of the art in diverse systems development and discusses challenges and potential solutions. The article covers requirements analysis, design, implementation, verification and validation, maintenance and evolution as well as organizational aspects. It also provides an overview of the articles which are part of this special section and addresses particular issues of diverse systems development.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {477–495},
numpages = {19},
keywords = {Software diversity, Software product lines, Variability}
}

@article{10.1007/s10664-018-9658-x,
author = {Rodrigues Santos, Alcemir and Carmo Machado, Ivan and Santana De Almeida, Eduardo and Siegmund, Janet and Apel, Sven},
title = {Comparing the influence of using feature-oriented programming and conditional compilation on comprehending feature-oriented software},
year = {2019},
issue_date = {Jun 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9658-x},
doi = {10.1007/s10664-018-9658-x},
abstract = {Several variability representations have been proposed over the years. Software maintenance in the presence of variability is known to be hard. One of the reasons is that maintenance tasks require a large amount of cognitive effort for program comprehension. In fact, the different ways of representing variability in source code might influence the comprehension process in different ways. Despite the differences, there is little evidence about how these variability representations --- such as conditional-compilation directives or feature-oriented programming --- influence program comprehension. Existing research has focused primarily on either understanding how code using modern paradigms evolves compared to the traditional way of realizing variability, namely conditional compilation, or on the aspects influencing the comprehension of conditional compilation only. We used two different programs implemented in Java and each of these variability representations. As Java does not support conditional compilation natively, we relied on the mimicking (i.e., preprocessing annotations in comments) that has been used in the literature. Our results show no significant statistical differences regarding the evaluated measures (correctness, understanding, or response time) in the tasks. Our heterogeneous sample allowed us to produce evidence about the influence of using CC and FOP variability representations on the aspects involved in the comprehension of feature-oriented software, while addressing bug-finding tasks.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1226–1258},
numpages = {33},
keywords = {Conditional compilation, Feature-oriented software development, FeatureHouse, Graduate students, Quasi-experiments, Replication}
}

@inproceedings{10.5555/2840819.2840871,
author = {Sangaiah, Karthik and Hempstead, Mark and Taskin, Baris},
title = {Uncore RPD: Rapid Design Space Exploration of the Uncore via Regression Modeling},
year = {2015},
isbn = {9781467383899},
publisher = {IEEE Press},
abstract = {A regression-based design space exploration methodology is proposed that models the impacts of the memory hierarchy and the network-on-chip (NoC) on the overall chip multiprocessor (CMP) performance. Designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the cache configuration and memory hierarchy which determine the amount and pattern of the traffic on the NoC. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by designing memory and NoC-specific regression models and leveraging recent advances in uncore simulation. To show the utility of our methodology, UncoreRPD, two case studies are presented: i) analyzing and refining regression models for an 8-core CMP and ii) performing a rapid design space exploration to find best performing designs of a NoC-based CMP given area-constraints for CMPs of up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can refine uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the NoC design space by up to four orders of magnitude.},
booktitle = {Proceedings of the IEEE/ACM International Conference on Computer-Aided Design},
pages = {365–372},
numpages = {8},
location = {Austin, TX, USA},
series = {ICCAD '15}
}

@article{10.1016/j.envsoft.2006.07.003,
author = {R\'{a}duly, B. and Gernaey, K. V. and Capodaglio, A. G. and Mikkelsen, P. S. and Henze, M.},
title = {Artificial neural networks for rapid WWTP performance evaluation: Methodology and case study},
year = {2007},
issue_date = {August, 2007},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {22},
number = {8},
issn = {1364-8152},
url = {https://doi.org/10.1016/j.envsoft.2006.07.003},
doi = {10.1016/j.envsoft.2006.07.003},
abstract = {Reliable performance evaluation of wastewater treatment plants (WWTPs) can be done by simulating the plant behavior over a wide range of influent disturbances, including series of rain events with different intensity and duration, seasonal temperature variations, holiday effects, etc. Such simulation-based WWTP performance evaluations are in practice limited by the long simulation time of the mechanistic WWTP models. By moderate simplification (avoiding big losses in prediction accuracy) of the mechanistic WWTP model only a limited reduction of the simulation time can be achieved. The approach proposed in this paper combines an influent disturbance generator with a mechanistic WWTP model for generating a limited sequence of training data (4months of dynamic data). An artificial neural network (ANN) is then trained on the available WWTP input-output data, and is subsequently used to simulate the remainder of the influent time series (20years of dynamic data) generated with the influent disturbance generator. It is demonstrated that the ANN reduces simulation time by a factor of 36, even when including the time needed for the generation of training data and for ANN training. For repeated integrated urban wastewater system simulations that do not require repeated training of the ANN, the ANN reduces simulation time by a factor of 1300 compared to the mechanistic model. ANN prediction of effluent ammonium, BOD"5 and total suspended solids was good when compared to mechanistic WWTP model predictions, whereas prediction of effluent COD and total nitrogen concentrations was a bit less satisfactory. With correlation coefficients R^2&gt;0.95 and prediction errors lower than 10%, the accuracy of the ANN is sufficient for applications in simulation-based WWTP design and simulation of integrated urban wastewater systems, especially when taking into account the uncertainties related to mechanistic WWTP modeling.},
journal = {Environ. Model. Softw.},
month = aug,
pages = {1208–1216},
numpages = {9},
keywords = {Artificial neural networks, Modeling, Performance evaluation, Plant design, Simulation speed, Time series, Wastewater treatment plant}
}

@article{10.1007/s00500-020-05166-2,
author = {Xie, Chuan and Zhang, Peng and Yan, Zhi},
title = {Correlation analysis of aeroengine operation monitoring using deep learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05166-2},
doi = {10.1007/s00500-020-05166-2},
abstract = {To analyze the reliability of aeroengine more accurately, based on the analysis of operation reliability and complex reliability, the deep learning method is adopted to deal with the nonlinear and time-varying problems between the state parameters and operation reliability of aeroengine, and the condition monitoring method and deep learning of aeroengine are discussed. The results show that, based on the deep learning integrated network, the remaining useful life of aeroengine is predicted, and the key parameters of aeroengine are fitted and predicted by the back propagation (BP) algorithm. The artificial neural network method is used to predict the aeroengine parameters. For the collected aeroengine monitoring parameters, the greedy layer by layer training algorithm is used to mine the relationship between the parameters, extract the evaluation features, and evaluate the performance degradation, which verify the statistical significance and robustness of the conclusions. The proposed algorithm is more accurate and robust than the results of back BP neural network and support vector machine. It can prevent the over-fitting of small samples in aeroengine condition monitoring and further improve its nonlinear processing and generalization ability.},
journal = {Soft Comput.},
month = jan,
pages = {551–562},
numpages = {12},
keywords = {Artificial neural network, BP algorithm, Predictive performance, Aeroengine, Deep learning}
}

@inproceedings{10.1007/978-3-030-29249-2_12,
author = {Kenny, Eoin M. and Ruelle, Elodie and Geoghegan, Anne and Shalloo, Laurence and O’Leary, Miche\'{a}l and O’Donovan, Michael and Keane, Mark T.},
title = {Predicting Grass Growth for Sustainable Dairy Farming: A CBR System Using Bayesian Case-Exclusion and Post-Hoc, Personalized Explanation-by-Example (XAI)},
year = {2019},
isbn = {978-3-030-29248-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29249-2_12},
doi = {10.1007/978-3-030-29249-2_12},
abstract = {Smart agriculture has emerged as a rich application domain for AI-driven decision support systems (DSS) that support sustainable and responsible agriculture, by improving resource-utilization through better on-farm, management decisions. However, smart agriculture’s promise is often challenged by the high barriers to user adoption. This paper develops a case-based reasoning (CBR) system called PBI-CBR to predict grass growth for dairy farmers, that combines predictive accuracy and explanation capabilities designed to improve user adoption. The system provides post-hoc, personalized explanation-by-example for its predictions, by using explanatory cases from the same farm or county. A key novelty of PBI-CBR is its use of Bayesian methods for case exclusion in this regression domain. Experiments report the tradeoff that occurs between predictive accuracy and explanatory adequacy for different parametric variants of PBI-CBR, and how updating Bayesian priors each year reduces error.},
booktitle = {Case-Based Reasoning Research and Development: 27th International Conference, ICCBR 2019, Otzenhausen, Germany, September 8–12, 2019, Proceedings},
pages = {172–187},
numpages = {16},
keywords = {CBR, Bayesian analysis, Smart agriculture, Case exclusion, XAI},
location = {Otzenhausen, Germany}
}

@inproceedings{10.5555/1884795.1884805,
author = {Augonnet, C\'{e}dric and Thibault, Samuel and Namyst, Raymond},
title = {Automatic calibration of performance models on heterogeneous multicore architectures},
year = {2009},
isbn = {3642141218},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Multicore architectures featuring specialized accelerators are getting an increasing amount of attention, and this success will probably influence the design of future High Performance Computing hardware. Unfortunately, programmers are actually having a hard time trying to exploit all these heterogeneous computing units efficiently, and most existing efforts simply focus on providing tools to offload some computations on available accelerators. Recently, some runtime systems have been designed that exploit the idea of scheduling - as opposed to offloading - parallel tasks over the whole set of heterogeneous computing units. Scheduling tasks over heterogeneous platforms makes it necessary to use accurate prediction models in order to assign each task to its most adequate computing unit [2]. A deep knowledge of the application is usually required to model per-task performance models, based on the algorithmic complexity of the underlying numeric kernel.We present an alternate, auto-tuning performance prediction approach based on performance history tables dynamically built during the application run. This approach does not require that the programmer provides some specific information. We show that, thanks to the use of a carefully chosen hash-function, our approach quickly achieves accurate performance estimations automatically. Our approach even outperforms regular algorithmic performance models with several linear algebra numerical kernels.},
booktitle = {Proceedings of the 2009 International Conference on Parallel Processing},
pages = {56–65},
numpages = {10},
location = {Delft, The Netherlands},
series = {Euro-Par'09}
}

@article{10.1155/2021/6649605,
author = {Wei, Jun and Ye, Tao and Zhang, Zhe and Hassanien, Abd E.I.-Baset},
title = {A Machine Learning Approach to Evaluate the Performance of Rural Bank},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6649605},
doi = {10.1155/2021/6649605},
abstract = {In the current performance evaluation works of commercial banks, most of the researches only focus on the relationship between a single characteristic and performance and lack a comprehensive analysis of characteristics. On the other hand, they mainly focus on causal inference and lack systematic quantitative conclusions from the perspective of prediction. This paper is the first to comprehensively investigate the predictability of multidimensional features on commercial bank performance using boosting regression tree. The dimensionality in the financial-related fields is relatively high. There are not only observable price data, financial fundamentals data, etc., but also many unobservable undisclosed data and undisclosed events; more sources of income cannot be explained by existing models. Aiming at the characteristics of commercial bank data, this paper proposes an adaptively reduced step size gradient boosting regression tree algorithm for bank performance evaluation. In this method, a random subsample sampling is performed before training each regression tree. The adaptive reduction step size is used to replace the reduction step size setting of the original algorithm, which overcomes the shortcomings of low accuracy and poor generalization ability of the existing regression decision tree model. Compared to the BIRCH algorithm for classification of existing data, our proposed gradient boosting regression tree algorithm with adaptively reduced step size obtains better classification results. This paper empirically uses data from rural banks in 30 provinces in China to classify the different characteristics of rural banks’ performance in order to better evaluate their performance.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@inproceedings{10.4108/ICST.VALUETOOLS2009.7988,
author = {Rolia, Jerry and Casale, Giuliano and Krishnamurthy, Diwakar and Dawson, Stephen and Kraft, Stephan},
title = {Predictive modelling of SAP ERP applications: challenges and solutions},
year = {2009},
isbn = {9789639799707},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/ICST.VALUETOOLS2009.7988},
doi = {10.4108/ICST.VALUETOOLS2009.7988},
abstract = {Analytic performance models are being increasingly used to support system runtime optimization. This paper considers the modelling features needed to predict the response time behaviour of an industrial enterprise resource planning (ERP) application, SAP ERP. A number of studies have reported modelling success with the application of basic product-form Queueing Network Models (QNMs) to multi-tier systems. Such QNMs are often preferred in the context of optimization studies due to the low computational costs of their solution. However, we show that these simple models do not support many important features required to accurately characterize industrial applications such as ERP systems. Specifically, our results indicate that software threading levels, asynchronous database calls, priority scheduling, multiple phases of processing, and the parallelism offered by multi-core processors all have a significant impact on response time that cannot be neglected.Starting from these observations, the paper shows that Layered Queueing Models (LQMs) are a robust alternative to basic QNMs, while still enjoying analytical solution algorithms that facilitate their integration in optimization studies. A case study for a sales and distribution workload demonstrates that many of the features supported by LQMs are critical for achieving good prediction accuracy. Results show that, remarkably, all of the features we considered that are not captured by basic product-form QNMs are needed to predict mean response times to within 15% of measured values for a wide range of load levels. If any key feature is absent, the mean response time estimates could differ by 36% to 117% compared to the measured values, thus making the case that such non-product-form modelling features are needed for complex real-world applications.},
booktitle = {Proceedings of the Fourth International ICST Conference on Performance Evaluation Methodologies and Tools},
articleno = {9},
numpages = {9},
location = {Pisa, Italy},
series = {VALUETOOLS '09}
}

@inproceedings{10.5555/3491440.3492097,
author = {Kenny, Eoin M. and Ruelle, Elodie and Geoghegan, Anne and Shalloo, Laurence and O'Leary, Mich\'{e}al and O'Donovan, Michael and Temraz, Mohammed and Keane, Mark T.},
title = {Bayesian case-exclusion and personalized explanations for sustainable dairy farming (extended abstract)},
year = {2021},
isbn = {9780999241165},
abstract = {Smart agriculture (SmartAg) has emerged as a rich domain for AI-driven decision support systems (DSS); however, it is often challenged by user-adoption issues. This paper reports a case-based reasoning (CBR) system, PBI-CBR, that predicts grass growth for dairy farmers, combining predictive accuracy and explanations to improve user adoption. PBI-CBR's novelty lies in the use of Bayesian methods for case-base maintenance in a regression domain. Experiments report the tradeoff between predictive accuracy and explanatory capability for variants of PBI-CBR, and how updating Bayesian priors each year improves performance.},
booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
articleno = {657},
numpages = {5},
location = {Yokohama, Yokohama, Japan},
series = {IJCAI'20}
}

@inproceedings{10.1145/3442381.3449859,
author = {Li, Zelong and Ji, Jianchao and Fu, Zuohui and Ge, Yingqiang and Xu, Shuyuan and Chen, Chong and Zhang, Yongfeng},
title = {Efficient Non-Sampling Knowledge Graph Embedding},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449859},
doi = {10.1145/3442381.3449859},
abstract = {Knowledge Graph (KG) is a flexible structure that is able to describe the complex relationship between data entities. Currently, most KG embedding models are trained based on negative sampling, i.e., the model aims to maximize some similarity of the connected entities in the KG, while minimizing the similarity of the sampled disconnected entities. Negative sampling helps to reduce the time complexity of model learning by only considering a subset of negative instances, which may fail to deliver stable model performance due to the uncertainty in the sampling procedure. To avoid such deficiency, we propose a new framework for KG embedding—Efficient Non-Sampling Knowledge Graph Embedding (NS-KGE). The basic idea is to consider all of the negative instances in the KG for model learning, and thus to avoid negative sampling. The framework can be applied to square-loss based knowledge graph embedding models or models whose loss can be converted to a square loss. A natural side-effect of this non-sampling strategy is the increased computational complexity of model learning. To solve the problem, we leverage mathematical derivations to reduce the complexity of non-sampling loss function, which eventually provides us both better efficiency and better accuracy in KG embedding compared with existing models. Experiments on benchmark datasets show that our NS-KGE framework can achieve a better performance on efficiency and accuracy over traditional negative sampling based models, and that the framework is applicable to a large class of knowledge graph embedding models.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {1727–1736},
numpages = {10},
keywords = {Computational Efficiency, Knowledge Graph Embedding, Non-Sampling Machine Learning, Space Efficiency},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1007/11564096_66,
author = {Oblinger, Daniel and Castelli, Vittorio and Lau, Tessa and Bergman, Lawrence D.},
title = {Similarity-based alignment and generalization},
year = {2005},
isbn = {3540292438},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11564096_66},
doi = {10.1007/11564096_66},
abstract = {We present a novel approach to learning predictive sequential models, called similarity-based alignment and generalization, which incorporates in the induction process a specific form of domain knowledge derived from a similarity function between the points in the input space. When applied to Hidden Markov Models, our framework yields a new class of learning algorithms called SimAlignGen. We discuss the application of our approach to the problem of programming by demonstration–the problem of learning a procedural model of user behavior by observing the interaction an application Graphical User Interface (GUI). We describe in detail the SimIOHMM, a specific instance of SimAlignGen that extends the known Input-Output Hidden Markov Model (IOHMM). Empirical evaluations of the SimIOHMM show the dependence of the prediction accuracy on the introduced similarity bias, and the computational gains over the IOHMM.},
booktitle = {Proceedings of the 16th European Conference on Machine Learning},
pages = {657–664},
numpages = {8},
location = {Porto, Portugal},
series = {ECML'05}
}

@inproceedings{10.1145/2889160.2889175,
author = {Meinicke, Jens and Th\"{u}m, Thomas and Schr\"{o}ter, Reimar and Krieter, Sebastian and Benduhn, Fabian and Saake, Gunter and Leich, Thomas},
title = {FeatureIDE: taming the preprocessor wilderness},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889175},
doi = {10.1145/2889160.2889175},
abstract = {Preprocessors are a common way to implement variability in software. They are used in numerous software systems, such as operating systems and databases. Due to the ability of preprocessors to enable and disable code fragments, not all parts of the program are active at the same time. Thus, programmers and tools need to handle the interactions resulting from annotations in the program. With our Eclipse-based tool FeatureIDE, we provide tool support to tackle multiple challenges with preprocessors, such as code comprehension, feature traceability, separation of concerns, and program analysis. With FeatureIDE, instead of focusing on one particular preprocessor, we provide tool support, which can easily be adopted for further preprocessors. Currently, we support development with CPP, Antenna, and Munge. https://youtu.be/jVe7f32mLCQ},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {629–632},
numpages = {4},
keywords = {code analysis, feature traceability, preprocessor},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1007/978-3-030-88361-4_24,
author = {Jain, Nitisha and Tran, Trung-Kien and Gad-Elrab, Mohamed H. and Stepanova, Daria},
title = {Improving Knowledge Graph Embeddings with Ontological Reasoning},
year = {2021},
isbn = {978-3-030-88360-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88361-4_24},
doi = {10.1007/978-3-030-88361-4_24},
abstract = {Knowledge graph (KG) embedding models have emerged as powerful means for KG completion. To learn the representation of KGs, entities and relations are projected in a low-dimensional vector space so that not only existing triples in the KG are preserved but also new triples can be predicted. Embedding models might learn a good representation of the input KG, but due to the nature of machine learning approaches, they often lose the semantics of entities and relations, which might lead to nonsensical predictions. To address this issue we propose to improve the accuracy of embeddings using ontological reasoning. More specifically, we present a novel iterative approach ReasonKGE that identifies dynamically via symbolic reasoning inconsistent predictions produced by a given embedding model and feeds them as negative samples for retraining this model. In order to address the scalability problem that arises when integrating ontological reasoning into the training process, we propose an advanced technique to generalize the inconsistent predictions to other semantically similar negative samples during retraining. Experimental results demonstrate the improvements in accuracy of facts produced by our method compared to the state-of-the-art.},
booktitle = {The Semantic Web – ISWC 2021: 20th International Semantic Web Conference, ISWC 2021, Virtual Event, October 24–28, 2021, Proceedings},
pages = {410–426},
numpages = {17}
}

@inproceedings{10.1145/2025113.2025177,
author = {Mori, Marco},
title = {A software lifecycle process for context-aware adaptive systems},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025177},
doi = {10.1145/2025113.2025177},
abstract = {It is increasingly important for computing systems to evolve their behavior at run-time because of resources uncertainty, system failures and emerging user needs. Our approach supports software engineers to analyze and develop context-aware adaptive applications. The software lifecycle process we propose supports static and dynamic decision making mechanisms, run-time consistent evolution and it is amenable to be automated.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {412–415},
numpages = {4},
keywords = {consistent evolution, context-aware adaptive systems, feature engineering, software lifecycle process},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}

@article{10.1016/j.comcom.2019.07.007,
author = {Zhao, Zhongliang and Carrera V., Jos\'{e} Luis and Braun, Torsten and Pan, Zhiyang},
title = {Conditional probability-based ensemble learning for indoor landmark localization},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {145},
number = {C},
issn = {0140-3664},
url = {https://doi.org/10.1016/j.comcom.2019.07.007},
doi = {10.1016/j.comcom.2019.07.007},
journal = {Comput. Commun.},
month = sep,
pages = {319–325},
numpages = {7}
}

@inproceedings{10.1145/3481646.3481660,
author = {Yagnik, Tarjana and Chen, Feng and Kasraian, Laleh},
title = {Component Profiling and Prediction Models for QoS-Aware Self-Adapting DSMS Framework},
year = {2021},
isbn = {9781450390408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3481646.3481660},
doi = {10.1145/3481646.3481660},
abstract = {Quality of Service (QoS) has been identified as an important attribute of system performance of Data Stream Management Systems (DSMS). A DSMS should have the ability to allocate physical computing resources between different submitted queries and fulfil QoS specifications in a fair and square manner. System scheduling strategies need to be adjusted dynamically to utilise available physical resources to guarantee the end-to-end quality of service levels. In this paper, we present a proactive method that utilises a multi-level component profiling approach to build prediction models that anticipate several QoS violations and performance degradations. The models are constructed using several incremental machine learning algorithms that are enhanced with ensemble learning and abnormal detection techniques. The approach performs accurate predictions in near real-time with accuracy up to 85% and with abnormal detection techniques, the accuracy reaches 100%. This is a major component within a proposed QoS-Aware Self-Adapting Data Stream Management Framework.},
booktitle = {Proceedings of the 2021 5th International Conference on Cloud and Big Data Computing},
pages = {88–94},
numpages = {7},
keywords = {Data Streams, Prediction Models, Quality of Service, Resource Allocation.},
location = {Liverpool, United Kingdom},
series = {ICCBDC '21}
}

@inproceedings{10.1145/3407982.3408001,
author = {Zorins, Aleksejs},
title = {Understanding the Essence of Artificial Intelligence: Towards Ecological Safety of AI in Human Society},
year = {2020},
isbn = {9781450377683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407982.3408001},
doi = {10.1145/3407982.3408001},
abstract = {Most members of scientific community would agree that Artificial Intelligence (AI) has already dramatically changed our society and all of it aspects including science and research. There are thousands of publications declaring the great advantages of AI and only few are trying to go deeper and reveal other aspects of computerized world.In the present time the name cyber security has become hugely popular among governmental, business, social and other structures. However, usually it means only safety of personal or organizational data (financial and other resources) and stability and integrity of a computer system. Nothing more...In this article the author would like to look at the cyber systems especially based on AI from a perspective of ecological safety for humanity of such a system. The article provides definition of ecological safety of AI and discusses its relevance to a modern science and society.},
booktitle = {Proceedings of the 21st International Conference on Computer Systems and Technologies},
pages = {56–60},
numpages = {5},
keywords = {Artificial intelligence, artificial superintelligence, ecological safety of artificial intelligence},
location = {Ruse, Bulgaria},
series = {CompSysTech '20}
}

@inproceedings{10.1007/978-3-030-73973-7_12,
author = {Carletti, Vincenzo and Foggia, Pasquale and Greco, Antonio and Roberto, Antonio and Vento, Mario},
title = {Predicting Polypharmacy Side Effects Through a Relation-Wise Graph Attention Network},
year = {2021},
isbn = {978-3-030-73972-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-73973-7_12},
doi = {10.1007/978-3-030-73973-7_12},
abstract = {Polypharmacy is the combined use of multiple drugs, widely adopted in medicine to treat patients that suffer of complex diseases. Therefore, it is important to have reliable tools able to predict if the activity of a drug could unfavorably change when combined with others. State-of-the-art methods face this problem as a link prediction task on a multilayer graph describing drug-drug interactions (DDI) and protein-protein interactions (PPI), since it has been demonstrated to be the most effective representation. Graph Convolutional Networks (GCN) are the method most commonly chosen in recent research for this problem. We propose to improve the performance of GCN on this link prediction task through the addition of a novel relation-wise Graph Attention Network (GAT), used to assign different weight to the different relationships in the multilayer graph. We experimentally demonstrate that the proposed GCN, compared with other recent methods, is able to achieve a state-of-the-art performance on a publicly available polypharmacy side effect network.},
booktitle = {Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshops, S+SSPR 2020, Padua, Italy, January 21–22, 2021, Proceedings},
pages = {119–128},
numpages = {10}
}

@inproceedings{10.1145/3340555.3353765,
author = {Dermouche, Soumia and Pelachaud, Catherine},
title = {Engagement Modeling in Dyadic Interaction},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340555.3353765},
doi = {10.1145/3340555.3353765},
abstract = {In the recent years, engagement modeling has gained increasing attention due the important role it plays in human-agent interaction. The agent should be able to detect, in real time, the engagement level of the user in order to react accordingly. In this context, our goal is to develop a computational model to predict engagement level of the user in real time. Relying on previous findings, we use facial expressions, head movements and gaze direction as predictive features. Moreover, engagement is not only measured from single cues, but from the combination of several cues that arise over a certain time window. Thus, for better engagement prediction, we consider the variation of multimodal behaviors over time. To this end, we rely on LSTM that can jointly model the temporality and the sequentiality of multimodal behaviors.},
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {440–445},
numpages = {6},
keywords = {Engagement, Facial expression, LSTM, human-agent interaction},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.1145/3452412.3462754,
author = {Bode, Vincent and Huseynli, Fariz and Schreiber, Matrtin and Trinitis, Carsten and Schulz, Martin},
title = {On the Exploration and Optimization of High-Dimensional Architectural Design Space},
year = {2021},
isbn = {9781450383875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452412.3462754},
doi = {10.1145/3452412.3462754},
abstract = {The rise of heterogeneity in High-Performance Computing (HPC) architectures has caused a spike in the number of viable hardware solutions for different workloads. In order to take advantage of the increasing possibilities to influence how hardware can be tailored to boost software performance, collaboration between hardware manufacturers, computing centers and application developers must intensify with the goal of hardware-software co-design.To support the co-design effort, we need efficient methods to compare the performance of the many potential architectures running user-supplied applications. We present the High-Dimensional Exploration and Optimization Tool (HOT), a tool for visualizing and comparing software performance on CPU/GPU hybrid architectures. HOT is currently based on data acquired from Intel's Offload Advisor (I-OA) to model application performance, allowing us to extract performance predictions for existing/custom accelerator architectures. This eliminates the necessity of porting applications to different (parallel) programming models and also avoids benchmarking the application on target hardware. However, tools like I-OA allow users to tweak many hardware parameters, making it tedious to evaluate and compare results. HOT, therefore, focuses on visualizing these high-dimensional design spaces and assists the user in identifying suitable hardware configurations for given applications. Thus, users can gain rapid insights into how hardware/software influence each other in heterogeneous environments.We show the usage of HOT on several case studies. To determine the accuracy of collected performance data with I-OA, we analyze LULESH on different architectures. Next, we apply HOT to the synthetic benchmarks STREAM and 2MM to demonstrate the tool's visualization under these well-defined and known workloads, validating both the tool and its usage. Finally, we apply HOT to the real world code Gadget and the proxy application LULESH allowing us to easily identify their bottlenecks and optimize the choice of compute architecture for them.},
booktitle = {Proceedings of the 2021 on Performance EngineeRing, Modelling, Analysis, and VisualizatiOn STrategy},
pages = {19–26},
numpages = {8},
keywords = {high-dimensional visualization, hw/sw co-design, performance analysis, performance modeling},
location = {Virtual Event, Sweden},
series = {PERMAVOST '21}
}

@inproceedings{10.1145/3468264.3468603,
author = {Ding, Yi and Pervaiz, Ahsan and Carbin, Michael and Hoffmann, Henry},
title = {Generalizable and interpretable learning for configuration extrapolation},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468603},
doi = {10.1145/3468264.3468603},
abstract = {Modern software applications are increasingly configurable, which puts a burden on users to tune these configurations for their target hardware and workloads. To help users, machine learning techniques can model the complex relationships between software configuration parameters and performance. While powerful, these learners have two major drawbacks: (1) they rarely incorporate prior knowledge and (2) they produce outputs that are not interpretable by users. These limitations make it difficult to (1) leverage information a user has already collected (e.g., tuning for new hardware using the best configurations from old hardware) and (2) gain insights into the learner’s behavior (e.g., understanding why the learner chose different configurations on different hardware or for different workloads). To address these issues, this paper presents two configuration optimization tools, GIL and GIL+, using the proposed generalizable and interpretable learning approaches. To incorporate prior knowledge, the proposed tools (1) start from known configurations, (2) iteratively construct a new linear model, (3) extrapolate better performance configurations from that model, and (4) repeat. Since the base learners are linear models, these tools are inherently interpretable. We enhance this property with a graphical representation of how they arrived at the highest performance configuration. We evaluate GIL and GIL+ by using them to configure Apache Spark workloads on different hardware platforms and find that, compared to prior work, GIL and GIL+ produce comparable, and sometimes even better performance configurations, but with interpretable results.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {728–740},
numpages = {13},
keywords = {Configuration, generalizability, interpretability, machine learning},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3357236.3395545,
author = {Sultanum, Nicole and Ghorashi, Soroush and Meek, Christopher and Ramos, Gonzalo},
title = {A Teaching Language for Building Object Detection Models},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395545},
doi = {10.1145/3357236.3395545},
abstract = {Object detection is a key application of machine learning. Currently, these detector models rely on deep networks that offer model builders limited agency over model construction, refinement and maintenance. Human-centered approaches to address these issues explore the exchange of knowledge between a human-in-the-loop and a learning system. This exchange, mediated through a teaching language, is often restricted to the specification of labels and constrains user expressiveness communicating other forms of knowledge to the system. We propose and assess an expressive teaching language for specifying object detectors which includes constructs such as concepts and relationships. From a formative study, we identified language building blocks and articulated design goals for creating interactive experiences in teaching object detection. We applied these goals through a design probe that highlighted further research questions and a set of design takeaways.},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1223–1234},
numpages = {12},
keywords = {interactive machine learning, machine teaching, object detection, qualitative study, teaching language},
location = {Eindhoven, Netherlands},
series = {DIS '20}
}

@inproceedings{10.1007/978-3-030-78270-2_77,
author = {Zia, Aayesha and Nouri, Jalal and Afzaal, Muhammad and Wu, Yongchao and Li, Xiu and Weegar, Rebecka},
title = {An Ensemble Approach for Question-Level Knowledge Tracing},
year = {2021},
isbn = {978-3-030-78269-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78270-2_77},
doi = {10.1007/978-3-030-78270-2_77},
abstract = {Knowledge tracing—where a machine models the students’ knowledge as they interact with coursework—is a well-established area in the field of Artificial Intelligence in Education. In this paper, an ensemble approach is proposed that addresses existing limitations in question-centric knowledge tracing and achieves the goal of predicting future question correctness. The proposed approach consists of two models; one is Light Gradient Boosting Machine (LightGBM) built by incorporating all relevant key features engineered from the data. The second model is a Multiheaded-Self-Attention Knowledge Tracing model (MSAKT) that extracts historical student knowledge of future question by calculating their contextual similarity with previously attempted questions. The proposed model’s effectiveness is evaluated by conducting experiments on a big Kaggle dataset achieving an Area Under ROC Curve (AUC) score of 0.84 with 84% accuracy using 10fold cross-validation.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part II},
pages = {433–437},
numpages = {5},
keywords = {Adaptive learning, Knowledge tracing, Question-level prediction, Artificial Intelligence, Intelligent education},
location = {Utrecht, The Netherlands}
}

@inproceedings{10.1145/1629911.1630038,
author = {Jayaseelan, Ramkumar and Mitra, Tulika},
title = {Dynamic thermal management via architectural adaptation},
year = {2009},
isbn = {9781605584973},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629911.1630038},
doi = {10.1145/1629911.1630038},
abstract = {Exponentially rising cooling/packaging costs due to high power density call for architectural and software-level thermal management. Dynamic thermal management (DTM) techniques continuously monitor the on-chip processor temperature. Appropriate mechanisms (e.g., dynamic voltage or frequency scaling (DVFS), clock gating, fetch gating, etc.) are engaged to lower the temperature if it exceeds a threshold. However, all these mechanisms incur significant performance penalty. We argue that runtime adaptation of micro-architectural parameters, such as instruction window size and issue width, is a more effective mechanism for DTM. If the architectural parameters can be tailored to track the available instruction-level parallelism of the program, the temperature is reduced with minimal performance degradation. Moreover, synergistically combining architectural adaptation with DVFS and fetch gating can achieve the best performance under thermal constraints. The key difficulty in using multiple mechanisms is to select the optimal configuration at runtime for time varying workloads. We present a novel software-level thermal management framework that searches through the configuration space at regular intervals to find the best performing design point that is thermally safe. The central components of our framework are (1) a neural-network based classifier that filters the thermally unsafe configurations, (2) a fast performance prediction model for any configuration, and (3) an efficient configuration space search algorithm. Experimental results indicate that our adaptive scheme achieves 59% reduction in performance overhead compared to DVFS and 39% reduction in overhead compared to DVFS combined with fetch gating.},
booktitle = {Proceedings of the 46th Annual Design Automation Conference},
pages = {484–489},
numpages = {6},
keywords = {architecture adaptation, dynamic thermal management},
location = {San Francisco, California},
series = {DAC '09}
}

@article{10.1162/evco_a_00271,
author = {Thomson, Sarah L. and Ochoa, Gabriela and Verel, S\'{e}bastien and Veerapen, Nadarajen},
title = {Inferring Future Landscapes: Sampling the Local Optima Level},
year = {2020},
issue_date = {Winter 2020},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {28},
number = {4},
issn = {1063-6560},
url = {https://doi.org/10.1162/evco_a_00271},
doi = {10.1162/evco_a_00271},
abstract = {Connection patterns among Local Optima Networks (LONs) can inform heuristic design for optimisation. LON research has predominantly required complete enumeration of a fitness landscape, thereby restricting analysis to problems diminutive in size compared to real-life situations. LON sampling algorithms are therefore important. In this article, we study LON construction algorithms for the Quadratic Assignment Problem (QAP). Using machine learning, we use estimated LON features to predict search performance for competitive heuristics used in the QAP domain. The results show that by using random forest regression, LON construction algorithms produce fitness landscape features which can explain almost all search variance. We find that LON samples better relate to search than enumerated LONs do. The importance of fitness levels of sampled LONs in search predictions is crystallised. Features from LONs produced by different algorithms are combined in predictions for the first time, with promising results for this “super-sampling”: a model to predict tabu search success explained 99% of variance. Arguments are made for the use-case of each LON algorithm and for combining the exploitative process of one with the exploratory optimisation of the other.},
journal = {Evol. Comput.},
month = dec,
pages = {621–641},
numpages = {21},
keywords = {Combinatorial optimisation, fitness landscapes, local optima networks, funnel landscapes.}
}

@inproceedings{10.1145/3404835.3463245,
author = {Anelli, Vito Walter and Bellogin, Alejandro and Ferrara, Antonio and Malitesta, Daniele and Merra, Felice Antonio and Pomo, Claudio and Donini, Francesco Maria and Di Noia, Tommaso},
title = {Elliot: A Comprehensive and Rigorous Framework for Reproducible Recommender Systems Evaluation},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463245},
doi = {10.1145/3404835.3463245},
abstract = {Recommender Systems have shown to be an effective way to alleviate the over-choice problem and provide accurate and tailored recommendations. However, the impressive number of proposed recommendation algorithms, splitting strategies, evaluation protocols, metrics, and tasks, has made rigorous experimental evaluation particularly challenging. Puzzled and frustrated by the continuous recreation of appropriate evaluation benchmarks, experimental pipelines, hyperparameter optimization, and evaluation procedures, we have developed an exhaustive framework to address such needs. Elliot is a comprehensive recommendation framework that aims to run and reproduce an entire experimental pipeline by processing a simple configuration file. The framework loads, filters, and splits the data considering a vast set of strategies (13 splitting methods and 8 filtering approaches, from temporal training-test splitting to nested K-folds Cross-Validation). Elliot(https://github.com/sisinflab/elliot) optimizes hyperparameters (51 strategies) for several recommendation algorithms (50), selects the best models, compares them with the baselines providing intra-model statistics, computes metrics (36) spanning from accuracy to beyond-accuracy, bias, and fairness, and conducts statistical analysis (Wilcoxon and Paired t-test).},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2405–2414},
numpages = {10},
keywords = {bias, evaluation, fairness, recommender systems, reproducibility},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@article{10.1016/j.cie.2019.106191,
author = {Lima-Junior, Francisco Rodrigues and Carpinetti, Luiz Cesar Ribeiro},
title = {An adaptive network-based fuzzy inference system to supply chain performance evaluation based on SCOR® metrics},
year = {2020},
issue_date = {Jan 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {139},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2019.106191},
doi = {10.1016/j.cie.2019.106191},
journal = {Comput. Ind. Eng.},
month = jan,
numpages = {19},
keywords = {Supply chain performance evaluation, SCOR® model, ANFIS, Neuro-fuzzy systems, Supply chain management}
}

@inproceedings{10.1007/978-3-319-99247-1_21,
author = {Wang, Jingyuan and Xu, Xiaofei and He, Jun and Li, Li},
title = {P-DBL: A Deep Traffic Flow Prediction Architecture Based on Trajectory Data},
year = {2018},
isbn = {978-3-319-99246-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-99247-1_21},
doi = {10.1007/978-3-319-99247-1_21},
abstract = {Predicting large-scale transportation network traffic flow has become an important and challenging topic in recent decades. However, accurate traffic flow prediction is still hard to realize. Weather factors such as precipitation in residential areas and tourist destinations affect traffic flow on the surrounding roads. In this paper, we attempt to take precipitation impact into consideration when predicting traffic flow. To realize this idea, we propose a deep traffic flow prediction architecture by introducing a deep bi-directional long short-term memory model, precipitation information, residual connection, regression layer and dropout training method. The proposed model has good ability to capture the deep features of traffic flow. Besides, it can take full advantage of time-aware traffic flow data and additional precipitation data. We evaluate the prediction architecture on taxi trajectory dataset in Chongqing and taxi trajectory dataset in Beijing with corresponding precipitation data from China Meteorological Data Service Center (CMDC). The experiment results demonstrate that the proposed model for traffic flow prediction obtains high accuracy compared with other models.},
booktitle = {Knowledge Science, Engineering and Management: 11th International Conference, KSEM 2018, Changchun, China, August 17–19, 2018, Proceedings, Part II},
pages = {244–254},
numpages = {11},
keywords = {Traffic flow prediction, Bi-directional LSTM, Precipitation impact, Trajectory data},
location = {Changchun, China}
}

@article{10.1016/j.jss.2015.07.008,
author = {Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul and Seyerlehner, Klaus and Wallner, Stefan and Zeisel, Helmut},
title = {ReMinds},
year = {2016},
issue_date = {February 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {112},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.07.008},
doi = {10.1016/j.jss.2015.07.008},
abstract = {The identification of challenges for monitoring system-of-systems architectures.The flexible and extensible REMINDS framework for developing domain-specific monitoring applications.An evaluation of the framework by applying it to concrete systems of an industrial system of systems including performance analyses of the framework. Many software-intensive systems today can be characterized as systems of systems (SoS) comprising complex, interrelated, and heterogeneous systems. The behavior of SoS often only emerges at runtime due to complex interactions between the involved systems and their environment. It is thus necessary to determine unexpected behavior by monitoring SoS at runtime, i.e., collecting and analyzing events and data at different layers and levels of granularity. Existing monitoring approaches are often limited to individual systems, particular architectural styles, or technologies. In this paper we thus derive challenges for monitoring SoS based on an industrial case. We present a flexible framework adaptable to different system architectures and technologies. We discuss its capabilities for instrumenting systems, collecting and persisting events and data, checking constraints on events and data, and visualizing the systems' behavior to users. We demonstrate the framework's flexibility by tailoring and applying it to an industrial SoS and assessing its performance and scalability. Our results show that the framework is flexible and scalable for monitoring an industrial SoS with realistic event loads.},
journal = {J. Syst. Softw.},
month = feb,
pages = {123–136},
numpages = {14},
keywords = {Framework, Runtime monitoring, System-of-systems architectures}
}

@article{10.1016/j.advengsoft.2011.05.018,
author = {Mahapatra, S. S. and Nanda, Santosh Kumar and Panigrahy, B. K.},
title = {A Cascaded Fuzzy Inference System for Indian river water quality prediction},
year = {2011},
issue_date = {October, 2011},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {42},
number = {10},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2011.05.018},
doi = {10.1016/j.advengsoft.2011.05.018},
abstract = {Now-a-days, Fuzzy Inference System (FIS) is considered as an effective tool for solution of many complex engineering systems when ambiguity and uncertainly is associated with the systems. Mamdani and Takagi, Sugeno and Kang (TSK) models poses simplicity in modeling but their system performance prediction capability is severely affected as complexity of the problem increases. In a multi-input, multi-output situation where a system consists of many subsystems and different outputs are desired from each subsystem, an improved version of FIS must be adopted rather than developing FIS for each subsystem. When dealing with such a system, it is prudent to use cascading systems rather than developing models for individual systems. To this end, a new Cascaded Mamdani Fuzzy Inference System is proposed in this paper and its performance is evaluated with the help of prediction of Indian River water quality index (WQI). In general, WQI value is a dimensionless number ranging from 0 to 100 (best quality) and plays an important role in evaluating the water quality of rivers. The proposed model is designed to predict WQI for five rivers in India. The cascaded fuzzy system simplifies and speeds up the computation of WQI as compared to the currently existing standards. In this paper, the proposed model is compared with three International water quality criteria and it is found that the designed model results in accurate prediction.},
journal = {Adv. Eng. Softw.},
month = oct,
pages = {787–796},
numpages = {10},
keywords = {Cascaded Fuzzy Inference System (CFS), Fuzzy Inference System (FIS), Fuzzy numbers, MATLAB, Membership function, Water quality index (WQI)}
}

@inproceedings{10.1007/978-3-030-84060-0_12,
author = {Terblanche, Michelle and Marivate, Vukosi},
title = {Towards Financial Sentiment Analysis in&nbsp;a South African Landscape},
year = {2021},
isbn = {978-3-030-84059-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-84060-0_12},
doi = {10.1007/978-3-030-84060-0_12},
abstract = {Sentiment analysis as a sub-field of natural language processing has received increased attention in the past decade enabling organisations to more effectively manage their reputation through online media monitoring. Many drivers impact reputation, however, this thesis focuses only the aspect of financial performance and explores the gap with regards to financial sentiment analysis in a South African context. Results showed that pre-trained sentiment analysers are least effective for this task and that traditional lexicon-based and machine learning approaches are best suited to predict financial sentiment of news articles. The evaluated methods produced accuracies of 84%–94%. The predicted sentiments correlated quite well with share price and highlighted the potential use of sentiment as an indicator of financial performance. A main contribution of the study was updating an existing sentiment dictionary for financial sentiment analysis. Model generalisation was less acceptable due to the limited amount of training data used. Future work includes expanding the data set to improve general usability and contribute to an open-source financial sentiment analyser for South African data.},
booktitle = {Machine Learning and Knowledge Extraction: 5th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2021, Virtual Event, August 17–20, 2021, Proceedings},
pages = {185–202},
numpages = {18},
keywords = {Financial sentiment analysis, Natural language processing, Corporate reputation, Share price}
}

@inproceedings{10.1007/978-3-030-27562-4_10,
author = {Prodromou, Andreas and Venkat, Ashish and Tullsen, Dean M.},
title = {Platform-Agnostic Learning-Based Scheduling},
year = {2019},
isbn = {978-3-030-27561-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27562-4_10},
doi = {10.1007/978-3-030-27562-4_10},
abstract = {Heterogeneous architectures have become increasingly common. From co-packaging small and large cores, to GPUs alongside CPUs, to general-purpose heterogeneous-ISA architectures with cores implementing different ISAs. As diversity of execution cores grows, predictive models become of paramount importance for scheduling and resource allocation. In this paper, we investigate the capabilities of performance predictors in a heterogeneous-ISA setting, as well as the predictors’ effects on scheduler quality. We follow an unbiased feature selection methodology to identify the optimal set of features for this task, instead of pre-selecting features before training. Finally, we incorporate our findings in ML-based schedulers and evaluate their sensitivity to the underlying system’s level of heterogeneity. We show our schedulers to perform within 2–11% of an oracular scheduler across a variety of underlying heterogeneous-ISA multicore systems without modification.},
booktitle = {Embedded Computer Systems: Architectures, Modeling, and Simulation: 19th International Conference, SAMOS 2019, Samos, Greece, July 7–11, 2019, Proceedings},
pages = {142–154},
numpages = {13},
location = {Pythagorion, Greece}
}

@inproceedings{10.1145/2517208.2517213,
author = {Kolesnikov, Sergiy and von Rhein, Alexander and Hunsen, Claus and Apel, Sven},
title = {A comparison of product-based, feature-based, and family-based type checking},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517213},
doi = {10.1145/2517208.2517213},
abstract = {Analyzing software product lines is difficult, due to their inherent variability. In the past, several strategies for product-line analysis have been proposed, in particular, product-based, feature-based, and family-based strategies. Despite recent attempts to conceptually and empirically compare different strategies, there is no work that empirically compares all of the three strategies in a controlled setting. We close this gap by extending a compiler for feature-oriented programming with support for product-based, feature-based, and family-based type checking. We present and discuss the results of a comparative performance evaluation that we conducted on a set of 12 feature-oriented, Java-based product lines. Most notably, we found that the family-based strategy is superior for all subject product lines: it is substantially faster, it detects all kinds of errors, and provides the most detailed information about them.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {115–124},
numpages = {10},
keywords = {feature-oriented programming, fuji, product-line analysis, type checking},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@inproceedings{10.5555/1365869.1365879,
author = {Ng, A. W. M. and Tran, D. H. and Osman, N. Y. and Mcmanus, K. J.},
title = {Application of neural networks in modelling serviceability deterioration of concrete stormwater pipes},
year = {2006},
isbn = {9608457467},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Stormwater pipe systems in Australia are designed to convey water from rainfall and surface runoff only and do not transport sewage. Any blockage can cause flooding events with the probability of subsequent property damage. Proactive maintenance plans that can enhance their serviceability need to be developed based on a sound deterioration model. This paper uses a neural network (NN) approach to model deterioration in serviceability of concrete stormwater pipes, which make up the bulk of the stormwater network in Australia. System condition data was collected using CCTV images. The outcomes of model are the identification of the significant factors influencing the serviceability deterioration and the forecasting of the change of serviceability condition over time for individual pipes based on the pipe attributes. The proposed method is validated and compared with multiple discriminant analysis, a traditionally statistical method. The results show that the NN model can be applied to forecasting serviceability deterioration. However, further improvements in data collection and condition grading schemes should be carried out to increase the prediction accuracy of the NN model.},
booktitle = {Proceedings of the 7th WSEAS International Conference on Neural Networks},
pages = {53–60},
numpages = {8},
keywords = {deterioration model, multiple discriminant analysis, neural networks, stormwater pipes},
location = {Cavtat, Croatia},
series = {NN'06}
}

@article{10.1016/j.mejo.2008.01.087,
author = {Suwa, Tohru and Hadim, Hamid},
title = {Multidisciplinary heat generating logic block placement optimization using genetic algorithm},
year = {2008},
issue_date = {October, 2008},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {39},
number = {10},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2008.01.087},
doi = {10.1016/j.mejo.2008.01.087},
abstract = {A multidisciplinary optimization methodology for placement of heat generating semiconductor logic blocks on integrated circuit chips is presented. The methodology includes thermal and wiring length criteria, which are optimized simultaneously using a genetic algorithm. An effective thermal performance prediction methodology based on a superposition method is used to determine the temperature distribution on a silicon chip due to multiple heat generating logic blocks. Using the superposition method, the predicted temperature distribution in the silicon chip is obtained in much shorter time than with a detailed finite element model and with comparable accuracy. The main advantage of the present multidisciplinary design and optimization methodology is its ability to handle multiple design objectives simultaneously for optimized placement of heat generating logic blocks. Capabilities of the present methodology are demonstrated by applying it to several standard benchmarks. The multidisciplinary logic block placement optimization results indicate that the maximum temperature on a silicon chip can be reduced by up to 7.5^oC, compared to the case in which only the wiring length is minimized.},
journal = {Microelectron. J.},
month = oct,
pages = {1200–1208},
numpages = {9},
keywords = {IC logic block placement, IC thermal design, IC wiring length, Multidisciplinary design optimization}
}

@inproceedings{10.5555/978-3-030-29983-5_fm,
title = {Front Matter},
year = {2019},
isbn = {978-3-030-29982-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Software Architecture: 13th European Conference, ECSA 2019, Paris, France, September 9–13, 2019, Proceedings},
pages = {i–xxii},
location = {Paris, France}
}

@article{10.5555/2873826.2874006,
author = {Hervieu, Aymeric and Marijan, Dusica and Gotlieb, Arnaud and Baudry, Benoit},
title = {Practical minimization of pairwise-covering test configurations using constraint programming},
year = {2016},
issue_date = {March 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {71},
number = {C},
issn = {0950-5849},
abstract = {Context: Testing highly-configurable software systems is challenging due to a large number of test configurations that have to be carefully selected in order to reduce the testing effort as much as possible, while maintaining high software quality. Finding the smallest set of valid test configurations that ensure sufficient coverage of the system's feature interactions is thus the objective of validation engineers, especially when the execution of test configurations is costly or time-consuming. However, this problem is NP-hard in general and approximation algorithms have often been used to address it in practice.Objective: In this paper, we explore an alternative exact approach based on constraint programming that will allow engineers to increase the effectiveness of configuration testing while keeping the number of configurations as low as possible.Method: Our approach consists in using a (time-aware) minimization algorithm based on constraint programming. Given the amount of time, our solution generates a minimized set of valid test configurations that ensure coverage of all pairs of feature values (a.k.a. pairwise coverage). The approach has been implemented in a tool called PACOGEN.Results: PACOGEN was evaluated on 224 feature models in comparison with the two existing tools that are based on a greedy algorithm. For 79% of 224 feature models, PACOGEN generated up to 60% fewer test configurations than the competitor tools. We further evaluated PACOGEN in the case study of an industrial video conferencing product line with a feature model of 169 features, and found 60% fewer configurations compared with the manual approach followed by test engineers. The set of test configurations generated by PACOGEN decreased the time required by test engineers in manual test configuration by 85%, increasing the feature-pairs coverage at the same time.Conclusion: Our experimental evaluation concluded that optimal time-aware minimization of pairwise-covering test configurations is efficiently addressed using constraint programming techniques.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {129–146},
numpages = {18},
keywords = {Constraint programming, Highly-configurable software systems, Variability testing}
}

@article{10.1504/IJHPCN.2018.093229,
title = {Distributed predictive performance anomaly detection for virtualised platforms},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1740-0562},
url = {https://doi.org/10.1504/IJHPCN.2018.093229},
doi = {10.1504/IJHPCN.2018.093229},
abstract = {Predicting subsequent values of quality of service QoS properties is a key component of autonomic solutions. Predictions help in the management of cloud-based applications by preventing QoS breaches from happening. The huge amount of monitoring data generated by cloud platforms motivated the applicability of scalable data mining and machine learning techniques for predicting performance anomalies. Building prediction models individually for thousands of virtual machines VMs requires a robust generic methodology with minimal human intervention. In this work, we focus on these issues and present three main contributions. First, we compare several time series modelling approaches to evidence the predictive capabilities of these approaches. Second, we propose estimation-classification models that augment the predictive capabilities of machine learning classification methods random forest, decision tree, and support vector machine by combining them with time series analysis methods AR, ARIMA and ETS. Third, we show how the data mining techniques in conjunction with Hadoop framework can be a useful, practical, and inexpensive method for predicting QoS attributes.},
journal = {Int. J. High Perform. Comput. Netw.},
month = jan,
pages = {279–290},
numpages = {12}
}

@inproceedings{10.1145/990064.990068,
author = {Gurun, Selim and Krintz, Chandra and Wolski, Rich},
title = {NWSLite: a light-weight prediction utility for mobile devices},
year = {2004},
isbn = {1581137931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/990064.990068},
doi = {10.1145/990064.990068},
abstract = {Computation off-loading, i.e., remote execution, has been shown to be effective for extending the computational power and battery life of resource-restricted devices, e.g., hand-held, wearable, and pervasive computers. Remote execution systems must predict the cost of executing both locally and remotely to determine when off-loading will be most beneficial. These costs however, are dependent upon the execution behavior of the task being considered and the highly-variable performance of the underlying resources, e.g., CPU (local and remote), bandwidth, and network latency. As such, remote execution systems must employ sophisticated, prediction techniques that accurately guide computation off-loading. Moreover, these techniques must be efficient, i.e., they cannot consume significant resources, e.g., energy, execution time, etc., since they are performed on the mobile device.In this paper, we present NWSLite, a computationally efficient, highly accurate prediction utility for mobile devices. NWSLite is an extension to the Network Weather Service (NWS), a dynamic forecasting toolkit for adaptive scheduling of high-performance Computational Grid applications. We significantly scaled down the NWS to reduce its resource consumption yet still achieve accuracy that exceeds that of extant remote execution prediction methods. We empirically analyze and compare both the prediction accuracy and the cost of NWSLite and a number of different forecasting methods from existing remote execution systems. We evaluate the efficacy of the different methods using a wide range of mobile applications and resources.},
booktitle = {Proceedings of the 2nd International Conference on Mobile Systems, Applications, and Services},
pages = {2–11},
numpages = {10},
keywords = {CPU availability estimation, fidelity, network performance estimation, prediction, remote execution, resource-restricted devices},
location = {Boston, MA, USA},
series = {MobiSys '04}
}

@inproceedings{10.1145/191995.192013,
author = {Talcott, A. R. and Yamamoto, W. and Serrano, M. J. and Wood, R. C. and Nemirovsky, M.},
title = {The impact of unresolved branches on branch prediction scheme performance},
year = {1994},
isbn = {0818655100},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
url = {https://doi.org/10.1145/191995.192013},
doi = {10.1145/191995.192013},
abstract = {In this paper, we examine the benefits of the early resolution of branch instructions and the impact of unresolved branches on history-based branch prediction schemes by using two new metrics that are more revealing than branch prediction accuracy alone. We first briefly review a number of branch prediction schemes and introduce two new branch prediction scheme performance metrics. We then utilize these metrics to gauge the improvement in branch prediction scheme performance when only the outcomes of unresolved branches are predicted. Finally, we examine two approaches for handling multiple unresolved branches in history-based branch prediction schemes, and determine that prediction accuracy remains quite stable when older branch histories are used.},
booktitle = {Proceedings of the 21st Annual International Symposium on Computer Architecture},
pages = {12–21},
numpages = {10},
location = {Chicago, Illinois, USA},
series = {ISCA '94}
}

@inproceedings{10.1145/3404709.3404751,
author = {Guo, Song and Zeng, Deze},
title = {Pedagogical Data Federation toward Education 4.0},
year = {2020},
isbn = {9781450375337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404709.3404751},
doi = {10.1145/3404709.3404751},
abstract = {Pedagogical data analysis has been recognized as one of the most important issues in pursuing Education 4.0. The recent rapid development of IT technologies benefits pedagogical data analysis via the provisioning of many advanced technologies such as big data analysis and machine learning. Meanwhile, the privacy of the students become another concern and this makes the educational institutions reluctant to share their students' data, forming isolated data islands and hindering the realization of big pedagogical data analysis. To tackle such challenge, in this paper, we propose a federated learning based education data analysis framework FEEDAN, via which pedagogical data federations can be formed by a number of institutions. None of them needs to direct exchange the their pedagogical data with each other and they always keep the data in their own place to guarantee their students' privacy. We apply our framework to analyze real pedagogical data. The experiment results show that it not only guarantees the students' privacy but also indeed breaks the borders of data island by achieving a higher analysis quality. Our framework can much approach the performance of centralized analysis which needs to collect the data in a common place with the risk of privacy exposure.},
booktitle = {Proceedings of the 6th International Conference on Frontiers of Educational Technologies},
pages = {51–55},
numpages = {5},
keywords = {Pedagogical data analytics, education 4.0, federated learning},
location = {Tokyo, Japan},
series = {ICFET '20}
}

@article{10.1155/2021/6147032,
author = {Guo, Chengcheng and Jan, Mian Ahmad},
title = {Prediction and Evaluation Model of Physical Training for Volleyball Players’ Effect Based on Grey Markov Theory},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/6147032},
doi = {10.1155/2021/6147032},
abstract = {Physical competition is becoming the new focus of volleyball in an increasingly perfect technical and tactical system. Unfortunately, poor physical fitness is a recognized weakness of volleyball players and a critical factor that has restricted the rapid development of volleyball for a long time. This paper proposes a grey Markov model-based approach to improve the evaluation ability of physical training. It aims to construct an empirical analysis model by combining statistical results and analyzing the evaluation parameters for physical training effects. The sports parameter analysis method is adopted to establish an optimal model of these parameters. Finally, a distribution model of moments of inertia combined with fuzzy information fusion’s feature extraction method is proposed for the distributed reconstruction of physical training. The optimization of training effects based on parameter optimization and construction of a grey Markov model enhances the physical training of volleyball players.},
journal = {Sci. Program.},
month = jan,
numpages = {8}
}

@inproceedings{10.1145/3338906.3338914,
author = {Lin, Jinkun and Cai, Shaowei and Luo, Chuan and Lin, Qingwei and Zhang, Hongyu},
title = {Towards more efficient meta-heuristic algorithms for combinatorial test generation},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338914},
doi = {10.1145/3338906.3338914},
abstract = {Combinatorial interaction testing (CIT) is a popular approach to detecting faults in highly configurable software systems. The core task of CIT is to generate a small test suite called a t-way covering array (CA), where t is the covering strength. Many meta-heuristic algorithms have been proposed to solve the constrained covering array generating (CCAG) problem. A major drawback of existing algorithms is that they usually need considerable time to obtain a good-quality solution, which hinders the wider applications of such algorithms. We observe that the high time consumption of existing meta-heuristic algorithms for CCAG is mainly due to the procedure of score computation. In this work, we propose a much more efficient method for score computation. The score computation method is applied to a state-of-the-art algorithm TCA, showing significant improvements. The new score computation method opens a way to utilize algorithmic ideas relying on scores which were not affordable previously. We integrate a gradient descent search step to further improve the algorithm, leading to a new algorithm called FastCA. Experiments on a broad range of real-world benchmarks and synthetic benchmarks show that, FastCA significantly outperforms state-of-the-art algorithms for CCAG algorithms, in terms of both the size of obtained covering array and the run time.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {212–222},
numpages = {11},
keywords = {Combinatorial interaction testing, covering array generation, local search},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1016/j.asoc.2020.107067,
author = {Hong, Sheng and Zeng, Yining},
title = {A health assessment framework of lithium-ion batteries for cyber defense},
year = {2021},
issue_date = {Mar 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {101},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.107067},
doi = {10.1016/j.asoc.2020.107067},
journal = {Appl. Soft Comput.},
month = mar,
numpages = {8},
keywords = {Health assessment, Locally linear embedding, Isomap, Lithium-ion battery}
}

@article{10.1016/j.jpdc.2011.10.013,
author = {Xu, Meilian and Thulasiraman, Parimala and Noghanian, Sima},
title = {Microwave tomography for breast cancer detection on Cell broadband engine processors},
year = {2012},
issue_date = {September, 2012},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {72},
number = {9},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2011.10.013},
doi = {10.1016/j.jpdc.2011.10.013},
abstract = {Microwave tomography (MT) is a safe screening modality that can be used for breast cancer detection. The technique uses the dielectric property contrasts between different breast tissues at microwave frequencies to determine the existence of abnormalities. Our proposed MT approach is an iterative process that involves two algorithms: Finite-Difference Time-Domain (FDTD) and Genetic Algorithm (GA). It is a compute intensive problem: (i) the number of iterations can be quite large to detect small tumors; (ii) many fine-grained computations and discretizations of the object under screening are required for accuracy. In our earlier work, we developed a parallel algorithm for microwave tomography on CPU-based homogeneous, multi-core, distributed memory machines. The performance improvement was limited due to communication and synchronization latencies inherent in the algorithm. In this paper, we exploit the parallelism of microwave tomography on the Cell BE processor. Since FDTD is a numerical technique with regular memory accesses, intensive floating point operations and SIMD type operations, the algorithm can be efficiently mapped on the Cell processor achieving significant performance. The initial implementation of FDTD on Cell BE with 8 SPEs is 2.9 times faster than an eight node shared memory machine and 1.45 times faster than an eight node distributed memory machine. In this work, we modify the FDTD algorithm by overlapping computations with communications during asynchronous DMA transfers. The modified algorithm also orchestrates the computations to fully use data between DMA transfers to increase the computation-to-communication ratio. We see 54% improvement on 8 SPEs (27.9% on 1 SPE) for the modified FDTD in comparison to our original FDTD algorithm on Cell BE. We further reduce the synchronization latency between GA and FDTD by using mechanisms such as double buffering. We also propose a performance prediction model based on DMA transfers, number of instructions and operations, the processor frequency and DMA bandwidth. We show that the execution time from our prediction model is comparable (within 0.5 s difference) with the execution time of the experimental results on one SPE.},
journal = {J. Parallel Distrib. Comput.},
month = sep,
pages = {1106–1116},
numpages = {11},
keywords = {Breast cancer detection, Cell BE processor, Finite-difference time-domain (FDTD), Microwave tomography (MT)}
}

@article{10.1145/3460865,
author = {Wu, Hanlu and Ma, Tengfei and Wu, Lingfei and Xu, Fangli and Ji, Shouling},
title = {Exploiting Heterogeneous Graph Neural Networks with Latent Worker/Task Correlation Information for Label Aggregation in Crowdsourcing},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/3460865},
doi = {10.1145/3460865},
abstract = {Crowdsourcing has attracted much attention for its convenience to collect labels from non-expert workers instead of experts. However, due to the high level of noise from the non-experts, a label aggregation model that infers the true label from noisy crowdsourced labels is required. In this article, we propose a novel framework based on graph neural networks for aggregating crowd labels. We construct a heterogeneous graph between workers and tasks and derive a new graph neural network to learn the representations of nodes and the true labels. Besides, we exploit the unknown latent interaction between the same type of nodes (workers or tasks) by adding a homogeneous attention layer in the graph neural networks. Experimental results on 13 real-world datasets show superior performance over state-of-the-art models.},
journal = {ACM Trans. Knowl. Discov. Data},
month = sep,
articleno = {27},
numpages = {18},
keywords = {Crowdsourcing, graph neural network, label aggregation}
}

@article{10.1007/s00607-021-01017-6,
author = {Memeti, Suejb and Pllana, Sabri},
title = {Optimization of heterogeneous systems with AI planning heuristics and machine learning: a performance and energy aware approach},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {103},
number = {12},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-021-01017-6},
doi = {10.1007/s00607-021-01017-6},
abstract = {Heterogeneous computing systems provide high performance and energy efficiency. However, to optimally utilize such systems, solutions that distribute the work across host CPUs and accelerating devices are needed. In this paper, we present a performance and energy aware approach that combines AI planning heuristics for parameter space exploration with a machine learning model for performance and energy evaluation to determine a near-optimal system configuration. For data-parallel applications our approach determines a near-optimal host-device distribution of work, number of processing units required and the corresponding scheduling strategy. We evaluate our approach for various heterogeneous systems accelerated with GPU or the Intel Xeon Phi. The experimental results demonstrate that our approach finds a near-optimal system configuration by evaluating only about 7% of reasonable configurations. Furthermore, the performance per Joule estimation of system configurations using our machine learning model is more than 1000 \texttimes{} faster compared to the system evaluation by program execution.},
journal = {Computing},
month = dec,
pages = {2943–2966},
numpages = {24},
keywords = {Heterogeneous computing, Optimization, Artificial intelligence (AI), Machine learning (ML), Planning heuristics, 90C59, 68T20, 68W10}
}

@article{10.1016/j.scico.2021.102694,
author = {Liebrenz, Timm and Herber, Paula and Glesner, Sabine},
title = {Service-oriented decomposition and verification of hybrid system models using feature models and contracts},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {211},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2021.102694},
doi = {10.1016/j.scico.2021.102694},
journal = {Sci. Comput. Program.},
month = nov,
numpages = {25},
keywords = {Hybrid systems, Compositional verification, Theorem proving, Model-driven development}
}

@inproceedings{10.1007/978-3-030-59419-0_12,
author = {Ni, Jingxiong and Zhao, Yan and Zeng, Kai and Su, Han and Zheng, Kai},
title = {DeepQT : Learning Sequential Context for Query Execution Time Prediction},
year = {2020},
isbn = {978-3-030-59418-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59419-0_12},
doi = {10.1007/978-3-030-59419-0_12},
abstract = {Query Execution Time Prediction is an important and challenging problem in the database management system. It is even more critical for a distributed database system to effectively schedule the query jobs in order to maximize the resource utilization and minimize the waiting time of users based on the query execution time prediction. While a number of works have explored this problem, they mostly ignore the sequential context of query jobs, which may affect the performance of prediction significantly. In this work, we propose a novel Deep learning framework for Query execution Time prediction, called DeepQT, in which the sequential context of a query job and other features at the same time are learned to improve the performance of prediction through jointly training a recurrent neural network and a deep feed-forward network. The results of the experiments conducted on two datasets of a commercial distributed computing platform demonstrate the superiority of our proposed approach.},
booktitle = {Database Systems for Advanced Applications: 25th International Conference, DASFAA 2020, Jeju, South Korea, September 24–27, 2020, Proceedings, Part III},
pages = {188–203},
numpages = {16},
keywords = {Deep learning, Query-time prediction, Distributed database, Jointly training},
location = {Jeju, Korea (Republic of)}
}

@article{10.1109/TNET.2020.3013548,
author = {Munir, Ali and He, Ting and Raghavendra, Ramya and Le, Franck and Liu, Alex X.},
title = {Network Scheduling and Compute Resource Aware Task Placement in Datacenters},
year = {2020},
issue_date = {Dec. 2020},
publisher = {IEEE Press},
volume = {28},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2020.3013548},
doi = {10.1109/TNET.2020.3013548},
abstract = {To improve the performance of data-intensive applications, existing datacenter schedulers optimize either the placement of tasks or the scheduling of network flows. The task scheduler strives to place tasks close to their input data (i.e., maximize data locality) to minimize network traffic, while assuming fair sharing of the network. The network scheduler strives to finish flows as quickly as possible based on their sources and destinations determined by the task scheduler, while the scheduling is based on flow properties (e.g., size, deadline, and correlation) and not bound to fair sharing. Inconsistent assumptions of the two schedulers can compromise the overall application performance. In this paper, we propose NEAT+, a task scheduling framework that leverages information from the underlying network scheduler and available compute resources to make task placement decisions. The core of NEAT+ is a task completion time predictor that estimates the completion time of a task under given network condition and a given network scheduling policy. NEAT+ leverages the predicted task completion times to minimize the average completion time of active tasks. Evaluation using ns2 simulations and real-testbed shows that NEAT+ improves application performance by up to &lt;inline-formula&gt; &lt;tex-math notation="LaTeX"&gt;$3.7times$ &lt;/tex-math&gt;&lt;/inline-formula&gt; for the suboptimal network scheduling policies and up to 33% for the optimal network scheduling policy.},
journal = {IEEE/ACM Trans. Netw.},
month = dec,
pages = {2435–2448},
numpages = {14}
}

@inproceedings{10.1145/3459637.3482276,
author = {Ai, Qingyao and Narayanan.R, Lakshmi},
title = {Model-agnostic vs. Model-intrinsic Interpretability for Explainable Product Search},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482276},
doi = {10.1145/3459637.3482276},
abstract = {Product retrieval systems have served as the main entry for customers to discover and purchase products online. With increasing concerns on the transparency and accountability of AI systems, studies on explainable information retrieval has received more and more attention in the research community. Interestingly, in the domain of e-commerce, despite the extensive studies on explainable product recommendation, the studies of explainable product search is still in an early stage. In this paper, we study how to construct effective explainable product search by comparing model-agnostic explanation paradigms with model-intrinsic paradigms and analyzing the important factors that determine the performance of product search explanations. We propose an explainable product search model with model-intrinsic interpretability and conduct crowdsourcing to compare it with the state-of-the-art explainable product search model with model-agnostic interpretability. We observe that both paradigms have their own advantages and the effectiveness of search explanations on different properties are affected by different factors. For example, explanation fidelity is more important for user's overall satisfaction on the system while explanation novelty may be more useful in attracting user purchases. These findings could have important implications for the future studies and design of explainable product search engines.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {5–15},
numpages = {11},
keywords = {attention mechanism, product search, search explanation},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@article{10.1155/2021/5558561,
author = {Shao, Yanli and Zhao, Jingru and Wang, Xingqi and Wu, Weiwei and Fang, Jinglong and Gao, Honghao},
title = {Research on Cross-Company Defect Prediction Method to Improve Software Security},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/5558561},
doi = {10.1155/2021/5558561},
abstract = {As the scale and complexity of software increase, software security issues have become the focus of society. Software defect prediction (SDP) is an important means to assist developers in discovering and repairing potential defects that may endanger software security in advance and improving software security and reliability. Currently, cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) are widely studied to improve the defect prediction performance, but there are still problems such as inconsistent metrics and large differences in data distribution between source and target projects. Therefore, a new CCDP method based on metric matching and sample weight setting is proposed in this study. First, a clustering-based metric matching method is proposed. The multigranularity metric feature vector is extracted to unify the metric dimension while maximally retaining the information contained in the metrics. Then use metric clustering to eliminate metric redundancy and extract representative metrics through principal component analysis (PCA) to support one-to-one metric matching. This strategy not only solves the metric inconsistent and redundancy problem but also transforms the cross-company heterogeneous defect prediction problem into a homogeneous problem. Second, a sample weight setting method is proposed to transform the source data distribution. Wherein the statistical source sample frequency information is set as an impact factor to increase the weight of source samples that are more similar to the target samples, which improves the data distribution similarity between the source and target projects, thereby building a more accurate prediction model. Finally, after the above two-step processing, some classical machine learning methods are applied to build the prediction model, and 12 project datasets in NASA and PROMISE are used for performance comparison. Experimental results prove that the proposed method has superior prediction performance over other mainstream CCDP methods.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {19}
}

@inproceedings{10.1007/978-3-030-58112-1_3,
author = {Liefooghe, Arnaud and Verel, S\'{e}bastien and Derbel, Bilel and Aguirre, Hernan and Tanaka, Kiyoshi},
title = {Dominance, Indicator and Decomposition Based Search for Multi-objective QAP: Landscape Analysis and Automated Algorithm Selection},
year = {2020},
isbn = {978-3-030-58111-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58112-1_3},
doi = {10.1007/978-3-030-58112-1_3},
abstract = {We investigate the properties of large-scale multi-objective quadratic assignment problems (mQAP) and how they impact the performance of multi-objective evolutionary algorithms. The landscape of a diversified dataset of bi-, multi-, and many-objective mQAP instances is characterized by means of previously-identified features. These features measure complementary facets of problem difficulty based on a sample of solutions collected along random and adaptive walks over the landscape. The strengths and weaknesses of a dominance-based, an indicator-based, and a decomposition-based search algorithm are then highlighted by relating their expected approximation quality in view of landscape features. We also discriminate between algorithms by revealing the most suitable one for subsets of instances. At last, we investigate the performance of a feature-based automated algorithm selection approach. By relying on low-cost features, we show that our recommendation system performs best in more than  of the considered mQAP instances.},
booktitle = {Parallel Problem Solving from Nature – PPSN XVI: 16th International Conference, PPSN 2020, Leiden, The Netherlands, September 5-9, 2020, Proceedings, Part I},
pages = {33–47},
numpages = {15},
location = {Leiden, The Netherlands}
}

@inproceedings{10.1007/978-3-030-72904-2_3,
author = {Cosson, Rapha\"{e}l and Derbel, Bilel and Liefooghe, Arnaud and Aguirre, Hern\'{a}n and Tanaka, Kiyoshi and Zhang, Qingfu},
title = {Decomposition-Based Multi-objective Landscape Features and Automated Algorithm Selection},
year = {2021},
isbn = {978-3-030-72903-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-72904-2_3},
doi = {10.1007/978-3-030-72904-2_3},
abstract = {Landscape analysis is of fundamental interest for improving our understanding on the behavior of evolutionary search, and for developing general-purpose automated solvers based on techniques from statistics and machine learning. In this paper, we push a step towards the development of a landscape-aware approach by proposing a set of landscape features for multi-objective combinatorial optimization, by decomposing the original multi-objective problem into a set of single-objective sub-problems. Based on a comprehensive set of bi-objective 

[inline-graphic not available: see fulltext]

 and three variants of the state-of-the-art Moea/d algorithm, we study the association between the proposed features, the global properties of the considered landscapes, and algorithm performance. We also show that decomposition-based features can be integrated into an automated approach for predicting algorithm performance and selecting the most accurate one on blind instances. In particular, our study reveals that such a landscape-aware approach is substantially better than the single best solver computed over the three considered Moea/d variants.},
booktitle = {Evolutionary Computation in Combinatorial Optimization: 21st European Conference, EvoCOP 2021, Held as Part of EvoStar 2021, Virtual Event, April 7–9, 2021, Proceedings},
pages = {34–50},
numpages = {17}
}

@article{10.1007/s00158-019-02352-1,
author = {Kianifar, Mohammed Reza and Campean, Felician},
title = {Performance evaluation of metamodelling methods for engineering problems: towards a practitioner guide},
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {61},
number = {1},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-019-02352-1},
doi = {10.1007/s00158-019-02352-1},
abstract = {Metamodelling or surrogate modelling techniques are frequently used across the engineering disciplines in conjunction with expensive simulation models or physical experiments. With the proliferation of metamodeling techniques developed to provide enhanced performance for specific problems, and the wide availability of a diverse choice of tools in engineering software packages, the engineering task of selecting a robust metamodeling technique for practical problems is still a challenge. This research introduces a framework for describing the typology of engineering problems, in terms of dimensionality and complexity, and the modelling conditions, reflecting the noisiness of the signals and the affordability of sample sizes, and on this basis presents a systematic evaluation of the performance of frequently used metamodeling techniques. A set of metamodeling techniques, selected based on their reported use for engineering problems (i.e. Polynomial, Radial Basis Function, and Kriging), were systematically evaluated in terms of accuracy and robustness against a carefully assembled set of 18 test functions covering different types of problems, sampling conditions and noise conditions. A set of four real-world engineering case studies covering both computer simulation and physical experiments were also analysed as validation tests for the proposed guidelines. The main conclusions drawn from the study are that Kriging model with Mat\'{e}rn 5/2 correlation function performs consistently well across different problem types with smooth (i.e. not noisy) data, while Kriging model with Mat\'{e}rn 3/2 correlation function provides robust performance under noisy conditions, except for the very high noise conditions, where the Kriging model with nugget appears to provide better models. These results provide engineering practitioners with a guide for the choice of a metamodeling technique for problem types and modelling conditions represented in the study, whereas the evaluation framework and benchmarking problems set will be useful for researchers conducting similar studies.},
journal = {Struct. Multidiscip. Optim.},
month = jan,
pages = {159–186},
numpages = {28},
keywords = {Metamodelling, Kriging, Radial basis functions, Polynomials, Correlation function, Kernel functions, Response surfaces}
}

@inproceedings{10.1007/978-3-030-60117-1_38,
author = {Reis, Ars\'{e}nio and Rocha, T\^{a}nia and Martins, Paulo and Barroso, Jo\~{a}o},
title = {Using Artificial Intelligence to Predict Academic Performance},
year = {2020},
isbn = {978-3-030-60116-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60117-1_38},
doi = {10.1007/978-3-030-60117-1_38},
abstract = {The academic performance of a higher education student can be affected by several factors and in most cases Higher Education Institutions (HEI) have programs to intervene, prevent failure or students dropping out. These include student tutoring, mentoring, recovery classes, summer school, etc. Being able to identify the borderline cases is extremely important for planning and intervening in time. This position paper reports on an ongoing project, being developed at the University of Tr\'{a}s-os-Montes e Alto Douro (UTAD), which uses the students’ data and artificial intelligence algorithms to create models and predict the performance of students and classes. The main objective of the IA.EDU project is to research the usage of data, artificial intelligence and data science to create artificial intelligence solutions, including models and applications, to provide predictive information that can contribute to the increase in students’ academic success and a reduction in the dropout rate, by making it possible to act proactively with the students at risk, course directors and course designers.},
booktitle = {HCI International 2020 - Late Breaking Papers: Multimodality and Intelligence: 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {517–526},
numpages = {10},
keywords = {Artificial intelligence, Data science, Higher education, Prediction and inference, Academic performance},
location = {Copenhagen, Denmark}
}

