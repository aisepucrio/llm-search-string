@inproceedings{10.1145/3336294.3336304,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Software Product Line Engineering: A Practical Experience},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336304},
doi = {10.1145/3336294.3336304},
abstract = {The lack of mature tool support is one of the main reasons that make the industry to be reluctant to adopt Software Product Line (SPL) approaches. A number of systematic literature reviews exist that identify the main characteristics offered by existing tools and the SPL phases in which they can be applied. However, these reviews do not really help to understand if those tools are offering what is really needed to apply SPLs to complex projects. These studies are mainly based on information extracted from the tool documentation or published papers. In this paper, we follow a different approach, in which we firstly identify those characteristics that are currently essential for the development of an SPL, and secondly analyze whether the tools provide or not support for those characteristics. We focus on those tools that satisfy certain selection criteria (e.g., they can be downloaded and are ready to be used). The paper presents a state of practice with the availability and usability of the existing tools for SPL, and defines different roadmaps that allow carrying out a complete SPL process with the existing tool support.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {164–176},
numpages = {13},
keywords = {tooling roadmap, tool support, state of practice, spl in practice},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.infsof.2020.106389,
author = {Chac\'{o}n-Luna, Ana Eva and Guti\'{e}rrez, Antonio Manuel and Galindo, Jos\'{e} A. and Benavides, David},
title = {Empirical software product line engineering: A systematic literature review},
year = {2020},
issue_date = {Dec 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {128},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2020.106389},
doi = {10.1016/j.infsof.2020.106389},
journal = {Inf. Softw. Technol.},
month = dec,
numpages = {22},
keywords = {Systematic literature review, Experiment, Case study, Empirical strategies, Software product lines}
}

@inproceedings{10.1145/3307630.3342393,
author = {Krueger, Charles and Clements, Paul},
title = {Feature-Based Systems and Software Product Line Engineering with Gears from BigLever},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342393},
doi = {10.1145/3307630.3342393},
abstract = {This paper describes a demonstration of the product line engineering tool and framework called Gears from BigLever Software. Gears is the automation at the heart of a PLE Factory, which itself is the conceptual construct at the heart of Feature-based Product Line Engineering. (Feature-based PLE is the subject of an upcoming ISO standard.) Gears provides the means to create and maintain a Feature Catalog via a unified feature modeling language; the means to create and maintain a Bill-of-Features Portfolio, which is a way to specify the members of the product line by the features that each one exhibits; and a single variation point mechanism that works in Shared Assets across the entire product lifecycle. The result is an automated production line capability that can quickly produce any product in the portfolio from the same, single set of shared assets.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {42–43},
numpages = {2},
keywords = {variation points, software product lines, product portfolio, product line engineering, product configurator, product baselines, multistage configuration, hierarchical product lines, feature-based PLE, feature profiles, feature modeling, bill-of-features},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s11227-021-03627-5,
author = {Kiani, Azaz Ahmed and Hafeez, Yaser and Imran, Muhammad and Ali, Sadia},
title = {A dynamic variability management approach working with agile product line engineering practices for reusing features},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {8},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-021-03627-5},
doi = {10.1007/s11227-021-03627-5},
abstract = {Agile software development (ASD) and software product line (SPL) have shown significant benefits for software engineering processes and practices. Although both methodologies promise similar benefits, they are based on different foundations. SPL encourages systematic reuse that exploits the commonalities of various products belonging to a common domain and manages their variations systematically. In contrast, ASD stresses a flexible and rapid development of products using iterative and incremental approaches. ASD encourages active involvement of customers and their frequent feedback. Both ASD and SPL require alternatives to extend agile methods for several reasons such as (1) to manage reusability and variability across the products of any domain, (2) to avoid the risk of developing core assets that will become obsolete and not used in future projects, and (3) to meet the requirements of changing markets. This motivates the researchers for the integration of ASD and SPL approaches. As a result, an innovative approach called agile product line engineering (APLE) by integrating SPL and ASD has been introduced. The principal aim of APLE is to maximize the benefits of ASD and SPL and address the shortcomings of both. However, combining both is a major challenge. Researchers have proposed a few approaches that try to put APLE into practice, but none of the existing approaches cover all APLE features needed. This paper proposes a new dynamic variability approach for APLE that uses APLE practices for reusing features. The proposed approach (PA) is based on the agile method Scrum and the reactive approach of SPL. In this approach, reusable core assets respond reactively to customer requirements. The PA constructs and develops the SPL architecture iteratively and incrementally. It provides the benefits of reusability and maintainability of SPLs while keeping the delivery-focused approach from agile methods. We conducted a quantitative survey of software companies applying the APLE to assess the performance of the PA and hypotheses of empirical study. Findings of empirical evaluation provide evidence on integrating ASD and SPL and the application of APLE into practices.},
journal = {J. Supercomput.},
month = aug,
pages = {8391–8432},
numpages = {42},
keywords = {Agile product line engineering, Agile software product line, Agile software development, Software product line}
}

@inproceedings{10.1145/2593882.2593888,
author = {Metzger, Andreas and Pohl, Klaus},
title = {Software product line engineering and variability management: achievements and challenges},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593888},
doi = {10.1145/2593882.2593888},
abstract = {Software product line engineering has proven to empower organizations to develop a diversity of similar software-intensive systems (applications) at lower cost, in shorter time, and with higher quality when compared with the development of single systems. Over the last decade the software product line engineering research community has grown significantly. It has produced impressive research results both in terms of quality as well as quantity. We identified over 600 relevant research and experience papers published within the last seven years in established conferences and journals. We briefly summarize the major research achievements of these past seven years. We structure this research summary along a standardized software product line framework. Further, we outline current and future research challenges anticipated from major trends in software engineering and technology.},
booktitle = {Future of Software Engineering Proceedings},
pages = {70–84},
numpages = {15},
keywords = {variability modeling, variability management, requirements engineering, quality assurance, design, Software product lines},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@inproceedings{10.1145/3109729.3109744,
author = {Munoz, Daniel-Jesus},
title = {Achieving energy efficiency using a Software Product Line Approach},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109744},
doi = {10.1145/3109729.3109744},
abstract = {Green computing and energy-aware software engineering are trend approaches that try to address the development of applications respectful with the environment. To reduce the energy consumption of an application the developer needs: (i) to identify what are the concerns that will impact more in the energy consumption; (ii) to model the variability of alternative designs and implementations of each concern; (iii) to store and compare the experimentation results related with the energy and time consumption of concerns; (iv) to find out what is the most eco-efficient solution for each concern. HADAS addresses these issues by modelling the variability of energy consuming concerns for different energy contexts. It connects the variability model with a repository that stores energy measurements, providing a Software Product Line (SPL) service, helping developers to reason and find out what are the most eco-friendly configurations. We have an initial implementation of the HADAS toolkit using Clafer. We have tested our implementation with several case studies.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {131–138},
numpages = {8},
keywords = {Variability, Software Product Line, Repository, Optimisation, Metrics, Energy Efficiency, Clafer},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2648511.2648535,
author = {Hartmann, Herman and van der Linden, Frank and Bosch, Jan},
title = {Risk based testing for software product line engineering},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648535},
doi = {10.1145/2648511.2648535},
abstract = {The variability of product lines increases over time thereby leading to an increasing effort for testing. Since the available time for test activities is limited an efficiency improvement is needed to ensure that products have sufficient quality.This paper introduces risk-based testing for software product lines. Our approach is based on risk based testing for single system engineering which is extended with a dimension that captures the percentage of product variants that use a particular development artifact. Based on the risk of development artifacts, the priorities for domain and application engineering are determined. We demonstrate our approach using a case study from an existing product line and discuss tool support.We conclude that the basic ideas behind risk-based testing for product lines are intuitive, pragmatic in nature, and provide the means for practitioners for guiding the test effort.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {227–231},
numpages = {5},
keywords = {software product line engineering, risk based testing},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2934466.2934489,
author = {Nagamine, Motoi and Nakajima, Tsuyoshi and Kuno, Noriyoshi},
title = {A case study of applying software product line engineering to the air conditioner domain},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934489},
doi = {10.1145/2934466.2934489},
abstract = {Software development for embedded products requires high quality, high productivity, and short delivery time because of strong business demands. Although software product line engineering (SPLE) is widely recognized as a good approach for systematic reuse of software, few reports present the information needed for other organizations to implement SPLE. This paper describes a case study of applying SPLE to a product family of air-conditioners, including the effects on degree of implementation of SPLE'S three essential activities (domain engineering, application engineering, and management) and its evaluation over the long period. The use of an incomplete implementation of SPLE's three essential activities temporally improves the productivity of the application developments due to the effect of refactored software, but this gradually decreases through architecture erosion.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {220–226},
numpages = {7},
keywords = {software product line, embedded system, case study, SPL},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3233027.3233045,
author = {Becker, Martin and Zhang, Bo},
title = {How do our neighbours do product line engineering? a comparison of hardware and software product line engineering approaches from an industrial perspective},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233045},
doi = {10.1145/3233027.3233045},
abstract = {Product line engineering (PLE) approaches have been followed in industry for hardware and software solutions for more than three decades now. However, the different engineering disciplines (e.g. mechanics, electrics, software) have developed and evolved their approaches within their own realms, which is fine as long as there is no need for integrated approaches. Driven by the increasing complexity of systems, there is a rising need for interdisciplinary systems engineering these days. Companies engineering cyber-physical systems and their components have to integrate product line engineering approaches across the involved engineering disciplines to enable a global optimization of portfolio, solution structures, and assets along their lifecycle. From a bird's-eye view, there is noticeable commonality but also variety in the approaches followed for PLE in the different engineering disciplines, which renders the integration of approaches a non-trivial endeavour. In order to foster the development of integrated PLE approaches, this paper explores, maps, and compares PLE approaches in the field of hardware and software engineering. Furthermore, the paper identifies integration opportunities and challenges. As the paper targets industrial practitioners, it mainly provides references to respective industrial events and material and does not fully cover related work in the respective research communities.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {190–195},
numpages = {6},
keywords = {software product lines, industry, academia, SPLC},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1016/j.infsof.2018.01.016,
author = {Soares, Larissa Rocha and Schobbens, Pierre-Yves and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Feature interaction in software product line engineering: A systematic mapping study},
year = {2018},
issue_date = {Jun 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {98},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.01.016},
doi = {10.1016/j.infsof.2018.01.016},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {44–58},
numpages = {15},
keywords = {Systematic mapping, Software product lines, Feature interaction}
}

@inproceedings{10.1145/3106195.3106224,
author = {Tizzei, Leonardo P. and Nery, Marcelo and Segura, Vin\'{\i}cius C. V. B. and Cerqueira, Renato F. G.},
title = {Using Microservices and Software Product Line Engineering to Support Reuse of Evolving Multi-tenant SaaS},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106224},
doi = {10.1145/3106195.3106224},
abstract = {In order to achieve economies of scale, a Software as a Service (SaaS) should be configurable, multi-tenant efficient, and scalable. But building SaaS with these characteristics comes at a price of having more complex services. Some works in the literature integrate software product line engineering and service-oriented architecture to tackle the complexity of building multi-tenant SaaS. Most of these works focused on centralized approaches that rely on middleware or platforms, but they do not investigate the use of decentralized architectural style. Microservices architecture is an architectural style that relies on small, decentralized, and autonomous services that work together. Thus, this paper investigates the integrated use of microservices architecture and software produt line techniques to develop multi-tenant SaaS. We conducted an empirical study that analyzes the behavior of software reuse during the evolution of a multi-tenant SaaS. This empirical study showed an average software reuse of 62% of lines of code among tenants. We also provide lessons we learned during the the re-engineering and maintenance of such multi-tenant SaaS.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {205–214},
numpages = {10},
keywords = {Software Reuse, Software Evolution, Service-oriented Architectures, Multi-tenancy, Microservices},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3461001.3473060,
author = {Sch\"{a}fer, Andreas and Becker, Martin and Andres, Markus and Kistenfeger, Tim and Rohlf, Florian},
title = {Variability realization in model-based system engineering using software product line techniques: an industrial perspective},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473060},
doi = {10.1145/3461001.3473060},
abstract = {Efficiently handling system variants is rising of importance in industry and challenges the application of model-based systems engineering.This paper reveals the increasing industrial demand of guidance and decision support on how to handle variants and variability within SysML and UML models. While a substantial amount of variability realization approaches has already been published on source code level, there is little guidance for practitioners on system model level. Hence, there is major uncertainty in dealing with system changes or concurrent system modeling of related system. Due to a poor modularization and variability realization these model variants are ending up in interwoven and complex system models.In this paper, we aim to raise awareness of the need for appropriate guidance and decision support, identify important contextual factors of MBSE that influence variability realization, and derive well known variability mechanisms used in software coding for their applicability in system modeling.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {25–34},
numpages = {10},
keywords = {variant management, variability realization, variability mechanism, system and software product line engineering, model-based systems engineering, decision support, UML, SysML},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382025.3414942,
author = {Assun\c{c}\~{a}o, Wesley K. G. and Kr\"{u}ger, Jacob and Mendon\c{c}a, Willian D. F.},
title = {Variability management meets microservices: six challenges of re-engineering microservice-based webshops},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414942},
doi = {10.1145/3382025.3414942},
abstract = {A microservice implements a small unit of functionality that it provides through a network using lightweight protocols. So, microservices can be combined to fulfill tasks and implement features of a larger software system---resembling a variability mechanism in the context of a software product line (SPL). Microservices and SPLs have similar goals, namely facilitating reuse and customizing, but they are usually employed in different contexts. Any developer who has access to the network can provide a microservice for any task, while SPLs are usually intended to implement features of a specific domain. Due to their different concepts, using microservices to implement an SPL or adopting SPL practices (e.g., variability management) for microservices is a challenging cross-area research problem. However, both techniques can complement each other, and thus tackling this problem promises benefits for organizations that employ either technique. In this paper, we reason on the importance of advancing in this direction, and sketch six concrete challenges to initiate research, namely (1) feature identification, (2) variability modeling, (3) variable microservice architectures, (4) interchangeability, (5) deep customization, and (6) re-engineering an SPL. We intend these challenges to serve as a starting point for future research in this cross-area research direction---avoiding that the concepts of one area are reinvented in the other.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {22},
numpages = {6},
keywords = {variability management, software product line, re-engineering, microservices, cloud computing},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2811681.2811703,
author = {Tan, Lei and Lin, Yuqing},
title = {An Aspect-Oriented Feature Modelling Framework for Software Product Line Engineering},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2811703},
doi = {10.1145/2811681.2811703},
abstract = {Software Product Line Engineering (SPLE) is a software development paradigm that focusing on systematic software assets reuse. SPLE treats software products in the same application domains as a product family and developing various of assets could be reused in the product family. Feature modelling is a critical activity of SPLE, which developing the requirement model for product families and providing guidance for individual product implementation. In this paper, we discuss several drawbacks of current feature modelling and propose a solution which adopting aspect-oriented development ideas and approaches. The proposed framework is intended to better manage complex feature relationships, and enhance quality-aware feature modelling. We include a case study of a real-life experience to demonstrate the proposed approach.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {111–115},
numpages = {5},
keywords = {software product line engineering, feature modelling, aspectoriented},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@inproceedings{10.5555/2814058.2814112,
author = {Lobato, Luanna Lopes and Bittar, Thiago Jabur},
title = {A Risk Management Approach for Software Product Line Engineering},
year = {2015},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {TSoftware Product Line (SPL) Engineering is a software development paradigm that fosters systematic reuse. It is focused on improving software practices, leading companies to experience benefits, such as reduced time-to-market and effort, and higher quality for the products delivered to customers. However, establishing a SPL is neither a simple nor a cheap task, and may affect several aspects of a software company. Besides, it involves a range of risks that may hinder project success. These have to be managed accordingly, so as to minimize the likelihood of project failure. Despite the importance of Risk Management (RM) for SPL Engineering, little has been published in terms of suitable and structured practices to cope with that. This present paper reports an approach for RM in SPL Engineering, named RiPLERM (Rise Product Line Engineering and Risk Management). The approach presents activities to structure RM in SPL projects, The design of the RiPLE-RM approach elaborated on results from empirical investigations, and was proposed to facilitate the management and provide significant insights that can be used to avoid and solve risks.},
booktitle = {Proceedings of the Annual Conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1},
pages = {331–338},
numpages = {8},
keywords = {Software Product Line Engineering, Software Process, Risk Management, Project management},
location = {Goiania, Goias, Brazil},
series = {SBSI '15}
}

@inproceedings{10.1145/2648511.2648513,
author = {Harman, M. and Jia, Y. and Krinke, J. and Langdon, W. B. and Petke, J. and Zhang, Y.},
title = {Search based software engineering for software product line engineering: a survey and directions for future work},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648513},
doi = {10.1145/2648511.2648513},
abstract = {This paper presents a survey of work on Search Based Software Engineering (SBSE) for Software Product Lines (SPLs). We have attempted to be comprehensive, in the sense that we have sought to include all papers that apply computational search techniques to problems in software product line engineering. Having surveyed the recent explosion in SBSE for SPL research activity, we highlight some directions for future work. We focus on suggestions for the development of recent advances in genetic improvement, showing how these might be exploited by SPL researchers and practitioners: Genetic improvement may grow new products with new functional and non-functional features and graft these into SPLs. It may also merge and parameterise multiple branches to cope with SPL branchmania.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {5–18},
numpages = {14},
keywords = {program synthesis, genetic programming, SPL, SBSE},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1109/SPLC.2011.55,
author = {Dao, Tung M. and Lee, Hyesun and Kang, Kyo C.},
title = {Problem Frames-Based Approach to Achieving Quality Attributes in Software Product Line Engineering},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.55},
doi = {10.1109/SPLC.2011.55},
abstract = {In software product line engineering (SPLE), commonality and variability across products of a product line domain are captured typically by a feature model. Reusable components are then developed from features. However, mapping features to components remains a complex task requiring a systematic way of exploring and analyzing various concerns arising from inadequate/insufficient domain assumptions. Essentially, those concerns prevent SPLE from achieving various quality attributes. This paper proposes a problem frames-based approach to addressing this problem. An elevator product line example is used to demonstrate the feasibility of the approach.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {175–180},
numpages = {6},
keywords = {Quality Attributes, Problem Frames, Goal Models, Feature Models},
series = {SPLC '11}
}

@inproceedings{10.1145/3307630.3342418,
author = {Rinc\'{o}n, Luisa and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {Analyzing the Convenience of Adopting a Product Line Engineering Approach: An Industrial Qualitative Evaluation},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342418},
doi = {10.1145/3307630.3342418},
abstract = {Engineering Software Product Lines may be a strategy to reduce costs and efforts for developing software and increasing business productivity. However, it cannot be considered as a "silver bullet" that applies to all types of organizations. Companies must consider pros and cons to determine sound reasons and justify its adoption. In previous work, we proposed the APPLIES evaluation framework to help decision-makers find arguments that may justify (or not) adopting a product line engineering approach. This paper presents our experience using this framework in a mid-sized software development company with more than 25 years of experience but without previous experience in product line engineering. This industrial experience, conducted as a qualitative empirical evaluation, helped us to evaluate to what extent APPLIES is practical to be used in a real environment and to gather ideas from real potential users to improve the framework.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {90–97},
numpages = {8},
keywords = {qualitative evaluation, product line engineering, product line adoption, empirical evaluation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1007/978-3-319-35122-3_2,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Automated Composition of Service Mashups Through Software Product Line Engineering},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_2},
doi = {10.1007/978-3-319-35122-3_2},
abstract = {The growing number of online resources, including data and services, has motivated both researchers and practitioners to provide methods and tools for non-expert end-users to create desirable applications by putting these resources together leading to the so called mashups. In this paper, we focus on a class of mashups referred to as service mashups. A service mashup is built from existing services such that the developed service mashup offers added-value through new functionalities. We propose an approach which adopts concepts from software product line engineering and automated AI planning to support the automated composition of service mashups. One of the advantages of our work is that it allows non-experts to build and optimize desired mashups with little knowledge of service composition. We report on the results of the experimentation that we have performed which support the practicality and scalability of our proposed work.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {20–38},
numpages = {19},
keywords = {Workflow optimization, Software product lines, Service mashups, Planning, Feature model, Automated composition},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1145/2491627.2499880,
author = {Clarke, Dave and Schaefer, Ina and ter Beek, Maurice H. and Apel, Sven and Atlee, Joanne M.},
title = {Formal methods and analysis in software product line engineering: 4th edition of FMSPLE workshop series},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2499880},
doi = {10.1145/2491627.2499880},
abstract = {FMSPLE 2013 is the fourth edition of the FMSPLE workshop series aimed at connecting researchers and practitioners interested in raising the efficiency and the effectiveness of software product line engineering through the application of innovative analysis approaches and formal methods.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {266–267},
numpages = {2},
keywords = {verification, variability, testing, software product lines, semantics, formal methods, evolution},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00122,
author = {Rosiak, Kamil},
title = {Extractive multi product-line engineering},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00122},
doi = {10.1109/ICSE-Companion52605.2021.00122},
abstract = {Cloning is a general approach to create new functionality within variants as well as new system variants. It is a fast, flexible, intuitive, and economical approach to evolve systems in the short run. However, in the long run, the maintenance effort increases. A common solution to this problem is the extraction of a product line from a set of cloned variants. This process requires a detailed analysis of variants to extract variability information. However, clones within a variant are usually not considered in the process, but are also a cause for unsustainable software. This thesis proposes an extractive multi product-line engineering approach to re-establish the sustainable development of software variants. We propose an approach to re-engineer intra-system and inter-system clones into reusable, configurable components stored in an integrated platform and synthesize a matching multilayer feature model.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {263–265},
numpages = {3},
keywords = {variability mining, refactoring, multi product-line, clone detection},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3382026.3425774,
author = {Rinc\'{o}n, Luisa and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {A multi-company empirical evaluation of a framework that evaluates the convenience of adopting product line engineering},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425774},
doi = {10.1145/3382026.3425774},
abstract = {Companies considering adopting a product line engineering approach should ideally analyze the pros and cons to determine the sound reasons for this decision. In order to support this analysis, in previous work we proposed the APPLIES evaluation framework. This framework provides information to evaluate the convenience of adopting a product line engineering approach.This paper presents an empirical evaluation of APPLIES. This experience includes 18 potential practitioners that used the framework to evaluate the convenience of adopting product line engineering in 19 different companies. The collected evidence was used to evaluate the perceived usefulness, intention to use and ease of use of APPLIES. The results presented increase confidence that APPLIESis a useful tool, but also identify some possibilities for improvement. In addition, four categories for classifying potential adopters of product line engineering emerged during the analysis of the results: unprepared adopter, potential adopter, ready adopter, and unmotivated adopter. These categories could be useful to classify companies that are considering adopting product line engineering.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {13–20},
numpages = {8},
keywords = {product line engineering adoption, perceived usefulness, intention to use, ease of use, Empirical evaluation},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3336294.3336321,
author = {Ghofrani, Javad and Kozegar, Ehsan and Fehlhaber, Anna Lena and Soorati, Mohammad Divband},
title = {Applying Product Line Engineering Concepts to Deep Neural Networks},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336321},
doi = {10.1145/3336294.3336321},
abstract = {Deep Neural Networks (DNNs) are increasingly being used as a machine learning solution thanks to the complexity of their architecture and hyperparameters-weights. A drawback is the excessive demand for massive computational power during the training process. Not only as a whole but parts of neural networks can also be in charge of certain functionalities. We present a novel challenge in an intersection between machine learning and variability management communities to reuse modules of DNNs without further training. Let us assume that we are given a DNN for image processing that recognizes cats and dogs. By extracting a part of the network, without additional training a new DNN should be divisible with the functionality of recognizing only cats. Existing research in variability management can offer a foundation for a product line of DNNs composing the reusable functionalities. An ideal solution can be evaluated based on its speed, granularity of determined functionalities, and the support for adding variability to the network. The challenge is decomposed in three subchallenges: feature extraction, feature abstraction, and the implementation of a product line of DNNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {72–77},
numpages = {6},
keywords = {variability, transfer learning, software product lines, machine learning, deep neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3489849.3489948,
author = {Lebiedz, Jacek and Wiszniewski, Bogdan},
title = {CAVE applications: from craft manufacturing to product line engineering},
year = {2021},
isbn = {9781450390927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489849.3489948},
doi = {10.1145/3489849.3489948},
abstract = {Product line engineering model is suitable for engineering related software products in an efficient manner, taking advantage of their similarities while managing their differences. Our feature driven software product line (SPL) solution based on that model allows for instantiation of different CAVE products based on the set of core assets and driven by a set of common VR features with the minimal budget and time to market.},
booktitle = {Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology},
articleno = {57},
numpages = {2},
keywords = {production stations, core assets, VR application features},
location = {Osaka, Japan},
series = {VRST '21}
}

@inproceedings{10.1109/APSEC.2014.94,
author = {Tan, Lei and Lin, Yuqing and Liu, Li},
title = {Quality Ranking of Features in Software Product Line Engineering},
year = {2014},
isbn = {9781479974269},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2014.94},
doi = {10.1109/APSEC.2014.94},
abstract = {Software Product Line Engineering (SPLE) is a systematic software reuse approach that developing a set of similar software products as a family. All the visible characters of the products in a product family are represented as features and their relationships are modelled in a feature model. During application engineering, desired features are selected from the feature model in a configuration process based on the requirements. In this process, the quality of final product should be considered as early as possible which requires identifying and ranking associated features' contributions to related quality attributes before configuring member products. In this paper, we propose a ranking approach to address the issues in current quality based feature ranking approaches, we also include a case study to illustrate our approach at the end.},
booktitle = {Proceedings of the 2014 21st Asia-Pacific Software Engineering Conference - Volume 02},
pages = {57–62},
numpages = {6},
series = {APSEC '14}
}

@inproceedings{10.1145/1808937.1808938,
author = {Hanssen, Geir Kjetil},
title = {Opening up software product line engineering},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808938},
doi = {10.1145/1808937.1808938},
abstract = {The software industry is experiencing a shift towards more open processes, a globalized market and more active and engaged customers and end users. This change seems natural and inevitable, imposing necessary changes in how software product line organizations plan and drive the development of their products. This paper gives insight into some recent developments in a product line organization and discusses how their efforts have helped them in improving their development processes and their product line. Based on this experience, this paper provides some preliminary guidelines to both industry and research, indicating that software product line organizations should exploit open innovation, engage customers, build communities and simplify processes and organization.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {1–7},
numpages = {7},
keywords = {software product line engineering, open processes},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@inproceedings{10.1145/2846650.2846654,
author = {El-Sharkawy, Sascha and Kr\"{o}her, Christian and Eichelberger, Holger and Schmid, Klaus},
title = {Experience from implementing a complex eclipse extension for software product line engineering},
year = {2015},
isbn = {9781450339049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2846650.2846654},
doi = {10.1145/2846650.2846654},
abstract = {Software Product Line Engineering (SPLE) is a systematic approach for the development of related software products. These products share a common infrastructure but vary with respect to their individual capabilities, called variabilities. Variability management is a key part of SPLE and is responsible for developing, combining and configuring such variabilities. As these activities are inherently complex, SPLE significantly benefits from tool-support. We developed a customizable Eclipse extension for SPLE that consists of around 38 plug-ins. The resulting tool, called EASy-Producer, extends the Eclipse IDE by the capability to support the creation and management of software product line projects. To provide this capability, EASy-Producer utilizes the extension concepts of the Eclipse platform and integrates additional frameworks, like Xtext. In this paper, we share our experience while applying the Eclipse technologies and, in particular, realizing specific capabilities of our tool using the Eclipse framework. The focus of this paper is on our lessons learned regarding managing workspace information and conflicting build mechanism as well as using Eclipse extensions outside of Eclipse. These lessons serve as an input to the Eclipse community and may help other developers in realizing a complex Eclipse extension.},
booktitle = {Proceedings of the on Eclipse Technology EXchange},
pages = {13–18},
numpages = {6},
keywords = {Software Product Lines, Eclipse, EASy-Producer},
location = {Pittsburgh, PA, USA},
series = {ETX 2015}
}

@inproceedings{10.1145/3106195.3106219,
author = {Gregg, Susan P. and Albert, Denise M. and Clements, Paul},
title = {Product Line Engineering on the Right Side of the "V"},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106219},
doi = {10.1145/3106195.3106219},
abstract = {Product line engineering (PLE) is well-known for the savings it brings to organizations. This paper shows how a very large, in-service systems and software product line is achieving PLE-based savings in their verification and validation phase of development. The paper addresses how to achieve the sharing across product variants while the products being tested are evolving over time. Additionally, we will give a pragmatic set of decision criteria to help answer the longstanding issue in PLE-based testing of whether to test on the domain side or the application (product) side of the product derivation process.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {165–174},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product configurator, feature profiles, feature modeling, bill-of-features, Product line engineering, PLE factory, AEGIS Combat System},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3236405.3237200,
author = {Bilic, Damir and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter and Causevic, Adnan and Amlinger, Christoffer},
title = {Model-based product line engineering in an industrial automotive context: an exploratory case study},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237200},
doi = {10.1145/3236405.3237200},
abstract = {Product Line Engineering is an approach to reuse assets of complex systems by taking advantage of commonalities between product families. Reuse within complex systems usually means reuse of artifacts from different engineering domains such as mechanical, electronics and software engineering. Model-based systems engineering is becoming a standard for systems engineering and collaboration within different domains. This paper presents an exploratory case study on initial efforts of adopting Product Line Engineering practices within the model-based systems engineering process at Volvo Construction Equipment (Volvo CE), Sweden. We have used SysML to create overloaded models of the engine systems at Volvo CE. The variability within the engine systems was captured by using the Orthogonal Variability Modeling language. The case study has shown us that overloaded SysML models tend to become complex even on small scale systems, which in turn makes scalability of the approach a major challenge. For successful reuse and to, possibly, tackle scalability, it is necessary to have a database of reusable assets from which product variants can be derived.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {56–63},
numpages = {8},
keywords = {variability management, system product lines, orthogonal variability modeling, model-based systems engineering},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1002/spe.1064,
author = {Hanssen, Geir K.},
title = {Agile software product line engineering: enabling factors},
year = {2011},
issue_date = {July 2011},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {41},
number = {8},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.1064},
doi = {10.1002/spe.1064},
abstract = {This paper reports on a study of a software product line organization that has adopted agile software development to address process rigidity and slowing performance. Experience has showed that despite some impediments, this has become a valuable change to both the organization and its development process. The aim of this study is to identify and understand enabling factors of a combined process, and to understand their subsequent effects. Qualitative data are summarized and analyzed, giving insight into the actions taken, their effects that have emerged over time, and the enabling and contextual factors. The study concludes that a combined process is feasible, that the simplified approach makes the organization more flexible and thus capable of serving a volatile market with fast-changing technologies. This has also enabled the organization to collaborate better with external actors. Copyright © 2011 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Pract. Exper.},
month = jul,
pages = {883–897},
numpages = {15},
keywords = {software product line engineering, qualitative research, industrial case study, agile software development}
}

@inproceedings{10.1145/3106195.3106218,
author = {Krueger, Charles and Clements, Paul},
title = {Enterprise Feature Ontology for Feature-based Product Line Engineering and Operations},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106218},
doi = {10.1145/3106195.3106218},
abstract = {Feature trees have been the standard data structure for representing product diversity in feature-based systems and software product line engineering (PLE). For basic product lines of modest size or complexity, one or several modular feature trees can be sufficient for managing the and resolving the variation present across the engineering assets in the systems engineering 'V' --- from requirements, to design, through implementation, verification, validation, documentation, and more --- in the software, mechanical, and electrical disciplines. However, enterprises seeking to adopt PLE at all levels of their organization, including areas such as product marketing, portfolio planning, manufacturing, supply chain, product sales, product service and maintenance, Internet-of-Things, resource planning, and much more are finding that thousands of nonengineering users need different views and interaction scenarios with a feature diversity representation. This paper describes a feature ontology (a specification of the meaning of terms in the feature modeling realm) that is suitable for managing the feature-based product line engineering and operations in the largest and most complex product line organizations. This ontology is based on layers of abstraction that each incrementally constrain the complexity and combinatorics and targets specific roles in the organization for greater degrees of efficiency, precision, and automation across an entire business enterprise.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {227–236},
numpages = {10},
keywords = {variation points, software product lines, product portfolio, product configurator, feature-based product line engineering, feature profiles, feature modeling, enterprise feature ontology, bill-of-features, Product line engineering, PLE factory},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1007/s10664-020-09913-9,
author = {Lindohf, Robert and Kr\"{u}ger, Jacob and Herzog, Erik and Berger, Thorsten},
title = {Software product-line evaluation in the large},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09913-9},
doi = {10.1007/s10664-020-09913-9},
abstract = {Software product-line engineering is arguably one of the most successful methods for establishing large portfolios of software variants in an application domain. However, despite the benefits, establishing a product line requires substantial upfront investments into a software platform with a proper product-line architecture, into new software-engineering processes (domain engineering and application engineering), into business strategies with commercially successful product-line visions and financial planning, as well as into re-organization of development teams. Moreover, establishing a full-fledged product line is not always possible or desired, and thus organizations often adopt product-line engineering only to an extent that deemed necessary or was possible. However, understanding the current state of adoption, namely, the maturity or performance of product-line engineering in an organization, is challenging, while being crucial to steer investments. To this end, several measurement methods have been proposed in the literature, with the most prominent one being the Family Evaluation Framework (FEF), introduced almost two decades ago. Unfortunately, applying it is not straightforward, and the benefits of using it have not been assessed so far. We present an experience report of applying the FEF to nine medium- to large-scale product lines in the avionics domain. We discuss how we tailored and executed the FEF, together with the relevant adaptations and extensions we needed to perform. Specifically, we elicited the data for the FEF assessment with 27 interviews over a period of 11 months. We discuss experiences and assess the benefits of using the FEF, aiming at helping other organizations assessing their practices for engineering their portfolios of software variants.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {41},
keywords = {family evaluation framework, experience report, process maturity, software product lines}
}

@inproceedings{10.1145/3106195.3106205,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Green Configurations of Functional Quality Attributes},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106205},
doi = {10.1145/3106195.3106205},
abstract = {Functional quality attributes (FQAs) are those quality attributes that, to be satisfied, require the incorporation of additional functionality into the application architecture. By adding an FQA (e.g., security) we can improve the quality of the final product, but there is also an increase in energy consumption. This paper proposes a solution to help the software architect to generate configurations of FQAs whilst keeping the energy consumed by the application as low as possible. For this, a usage model is defined for each FQA, taking into account the variables that affect the energy consumption, and that the values of these variables change according to the part of the application where the FQA is required. We extend a Software Product Line that models a family of FQAs to incorporate the variability of the usage model and the existing frameworks that implement FQAs. We generate the most eco-efficient configuration of FQAs by selecting the framework with the most suitable characteristics according to the requirements of the application.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {79–83},
numpages = {5},
keywords = {Variability, SPL, Quality Attributes, FQA, Energy Consumption},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1016/j.infsof.2013.05.006,
author = {Mohabbati, Bardia and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and M\"{u}ller, Hausi A.},
title = {Combining service-orientation and software product line engineering: A systematic mapping study},
year = {2013},
issue_date = {November, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.006},
doi = {10.1016/j.infsof.2013.05.006},
abstract = {Context: Service-Orientation (SO) is a rapidly emerging paradigm for the design and development of adaptive and dynamic software systems. Software Product Line Engineering (SPLE) has also gained attention as a promising and successful software reuse development paradigm over the last decade and proven to provide effective solutions to deal with managing the growing complexity of software systems. Objective: This study aims at characterizing and identifying the existing research on employing and leveraging SO and SPLE. Method: We conducted a systematic mapping study to identify and analyze related literature. We identified 81 primary studies, dated from 2000-2011 and classified them with respect to research focus, types of research and contribution. Result: The mapping synthesizes the available evidence about combining the synergy points and integration of SO and SPLE. The analysis shows that the majority of studies focus on service variability modeling and adaptive systems by employing SPLE principles and approaches. In particular, SPLE approaches, especially feature-oriented approaches for variability modeling, have been applied to the design and development of service-oriented systems. While SO is employed in software product line contexts for the realization of product lines to reconcile the flexibility, scalability and dynamism in product derivations thereby creating dynamic software product lines. Conclusion: Our study summarizes and characterizes the SO and SPLE topics researchers have investigated over the past decade and identifies promising research directions as due to the synergy generated by integrating methods and techniques from these two areas.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1845–1859},
numpages = {15},
keywords = {Systematic mapping, Software product lines, Service-oriented architecture}
}

@article{10.1007/s10796-010-9230-8,
author = {Ahmed, Faheem and Capretz, Luiz Fernando},
title = {A business maturity model of software product line engineering},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-010-9230-8},
doi = {10.1007/s10796-010-9230-8},
abstract = {In the recent past, software product line engineering has become one of the most promising practices in software industry with the potential to substantially increase the software development productivity. Software product line engineering approach spans the dimensions of business, architecture, software engineering process and organization. The increasing popularity of software product line engineering in the software industry necessitates a process maturity evaluation methodology. Accordingly, this paper presents a business maturity model of software product line, which is a methodology to evaluate the current maturity of the business dimension of a software product line in an organization. This model examines the coordination between product line engineering and the business aspects of software product line. It evaluates the maturity of the business dimension of software product line as a function of how a set of business practices are aligned with product line engineering in an organization. Using the model presented in this paper, we conducted two case studies and reported the assessment results. This research contributes towards establishing a comprehensive and unified strategy for a process maturity evaluation of software product lines.},
journal = {Information Systems Frontiers},
month = sep,
pages = {543–560},
numpages = {18},
keywords = {Software product line, Software process model, Software process assessment, Organizational management, Maturity evaluation, Business process}
}

@inproceedings{10.1145/3483899.3483902,
author = {Marchezan, Luciano and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Carbonell, Jo\~{a}o and Rodrigues, Elder and Bernardino, Maicon and Basso, F\'{a}bio},
title = {SPLReePlan - Automated Support for Software Product Line Reengineering Planning},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483902},
doi = {10.1145/3483899.3483902},
abstract = {The extractive adoption of Software Product Lines (SPL) relies on the reuse of the already developed systems, employing a reengineering process. However, due to the diversity of options found in the daily practice of SPL development, rigorous planning of scenarios is critical to perform SPL reengineering. This diversity is the result of different organizational aspects, such as team experience and product portfolio. Hence, a proper planning process must consider technical and organizational aspects, however, most existing studies in the field do not take into account organizational aspects of the companies. In this work, we present SPLReePlan, an automated framework to aid the SPL reengineering planning taking into account technical and organizational aspects. Our framework is supported by a web-based tool, ready to be used in the industry. To investigate how flexible is SPLReePlan to support the SPL reengineering planning in diverse situations, we extracted eight different scenarios from the SPL literature, which are used as input for the evaluation of SPLReePlan. The results indicate that SPLReePlan can be satisfactorily customized to a variety of scenarios with different artifacts, feature retrieval techniques, and reengineering activities. As a contribution, we discuss the lessons learned within the evaluation, and present challenges that were faced, being a source of information for tool builders or motivating new studies.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {variability management, software product lines, reengineering process, automated support},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/3233027.3233032,
author = {Kr\"{o}her, Christian and Gerling, Lea and Schmid, Klaus},
title = {Identifying the intensity of variability changes in software product line evolution},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233032},
doi = {10.1145/3233027.3233032},
abstract = {The evolution of a Software Product Line (SPL) typically affects a variety of artifact types. The intensity (the frequency and the amount) in which developers change variability information in these different types of artifacts is currently unknown. In this paper, we present a fine-grained approach for the variability-centric extraction and analysis of changes to code, build, and variability model artifacts introduced by commits. This approach complements existing work that is typically based on a feature-perspective and, thus, abstracts from this level of detail. Further, it provides a detailed understanding of the intensity of changes affecting variability information in these types of artifacts. We apply our approach to the Linux kernel revealing that changes to variability information occur infrequently and only affect small parts of the analyzed artifacts. Further, we outline how these results may improve certain analysis and verification tasks during SPL evolution.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {54–64},
numpages = {11},
keywords = {variability changes, software product line evolution, intensity, evolution analysis},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106223,
author = {Iglesias, Aitziber and Lu, Hong and Arellano, Crist\'{o}bal and Yue, Tao and Ali, Shaukat and Sagardui, Goiuria},
title = {Product Line Engineering of Monitoring Functionality in Industrial Cyber-Physical Systems: A Domain Analysis},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106223},
doi = {10.1145/3106195.3106223},
abstract = {In recent years, manufacturing technology is evolving and progressively becoming more dynamic and complex. This means that manufacturing technology (e.g., based on Industry 4.0) should be able to control the production process at runtime by monitoring physical elements and adapting itself. Such functionality is aimed at increasing production effectiveness and reducing the production cost. We argue that monitoring process can be viewed as a software product line having commonalities and variability. To support our argument, we analyzed and conducted domain analysis of two monitoring systems of Industrial Cyber-Physical Systems (ICPSs) from two industrial domains including automated warehouses and press machines. Based on the domain analysis, we present a common solution for monitoring including a software product line. With such product line, a user can configure, monitor, and visualize data of an ICPS at runtime. However, such solution could not handle the dynamic functionality related to monitoring of ICPS. Thus, we propose the use of dynamic product line and present a set of research questions that must be addressed for such solution.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {195–204},
numpages = {10},
keywords = {Software Product Line, Industrial domains, Dynamic Software Product Line, Cyber Physical System},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3233027.3233029,
author = {Sree-Kumar, Anjali and Planas, Elena and Claris\'{o}, Robert},
title = {Extracting software product line feature models from natural language specifications},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233029},
doi = {10.1145/3233027.3233029},
abstract = {The specification of a family of software products may include documents written in natural language. Automatically extracting knowledge from these documents is a challenging problem that requires using Natural Language Processing (NLP) techniques. This knowledge can be formalized as a Feature Model (FM), a diagram capturing the key features and the relationships among them.In this paper, we first review previous works that have presented tools for extracting FMs from textual specifications and compare their strengths and limitations. Then, we propose a framework for feature and relationship extraction, which overcomes the identified limitations and is built upon state-of-the-art open-source NLP tools. This framework is evaluated against previous works using several case studies, showing improved results.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {43–53},
numpages = {11},
keywords = {software product line, requirements engineering, natural language processing, feature model extraction, NLTK},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3385032.3385043,
author = {Bilic, Damir and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter and Causevic, Adnan and Amlinger, Christoffer and Barkah, Dani},
title = {Towards a Model-Driven Product Line Engineering Process: An Industrial Case Study},
year = {2020},
isbn = {9781450375948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385032.3385043},
doi = {10.1145/3385032.3385043},
abstract = {Many organizations developing software-intensive systems face challenges with high product complexity and large numbers of variants. In order to effectively maintain and develop these product variants, Product-Line Engineering methods are often considered, while Model-based Systems Engineering practices are commonly utilized to tackle product complexity. In this paper, we report on an industrial case study concerning the ongoing adoption of Product Line Engineering in the Model-based Systems Engineering environment at Volvo Construction Equipment (Volvo CE) in Sweden. In the study, we identify and define a Product Line Engineering process that is aligned with Model-based Systems Engineering activities at the engines control department of Volvo CE. Furthermore, we discuss the implications of the migration from the current development process to a Model-based Product Line Engineering-oriented process. This process, and its implications, are derived by conducting and analyzing interviews with Volvo CE employees, inspecting artifacts and documents, and by means of participant observation. Based on the results of a first system model iteration, we were able to document how Model-based Systems Engineering and variability modeling will affect development activities, work products and stakeholders of the work products.},
booktitle = {Proceedings of the 13th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {9},
numpages = {11},
keywords = {Engine System Development, Model-Based Systems Engineering, Product Line Engineering},
location = {Jabalpur, India},
series = {ISEC '20}
}

@inproceedings{10.1145/2362536.2362576,
author = {ter Beek, Maurice H. and Becker, Martin and Classen, Andreas and Roos-Frantz, Fabricia and Schaefer, Ina and Wong, Peter Y. H.},
title = {Formal methods and analysis in software product line engineering: 3rd edition of FMSPLE workshop series},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362576},
doi = {10.1145/2362536.2362576},
abstract = {FMSPLE 2012 is the third edition of the FMSPLE workshop series, traditionally affiliated with SPLC, which aims to connect researchers and practitioners interested in raising the efficiency and the effectiveness of SPLE through the application of innovative analysis approaches and formal methods.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {286–287},
numpages = {2},
keywords = {verification, variability, testing, software product lines, semantics, formal methods, evolution},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1016/j.dam.2019.06.008,
author = {Carbonnel, Jessie and Bertet, Karell and Huchard, Marianne and Nebut, Cl\'{e}mentine},
title = {FCA for software product line representation: Mixing configuration and feature relationships in a unique canonical representation},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {273},
number = {C},
issn = {0166-218X},
url = {https://doi.org/10.1016/j.dam.2019.06.008},
doi = {10.1016/j.dam.2019.06.008},
journal = {Discrete Appl. Math.},
month = feb,
pages = {43–64},
numpages = {22},
keywords = {Concept lattice, Formal concept analysis, Feature model, Software product line}
}

@phdthesis{10.5555/2519127,
author = {Tawhid, Rasha},
title = {Integrating performance analysis in model driven software product line engineering},
year = {2012},
isbn = {9780494893104},
publisher = {Carleton University},
address = {CAN},
abstract = {A  Software Product Line  (SPL) is a set of similar software systems that share a common set of features satisfying a particular domain, and are built from a shared set of software assets using a common means of production. This research proposes to integrate performance analysis in the early phases of the model-driven development process of SPL. We start by adding generic performance annotations to the UML model representing the set of core reusable SPL assets using the MARTE Profile adopted by OMG. A model transformation realized in Atlas Transformation Language (ATL), derives the UML model of a specific product with concrete performance annotations from the SPL model, which is further transformed into a performance model by using a previously developed transformation called PUMA. The automatic derivation of a specific product model based on a given feature configuration is enabled through the mapping between features from the feature model and their realizations in the design model. An efficient mapping technique is proposed that aims to minimize the amount of explicit feature annotations in the UML model of SPL. Implicit feature mapping is inferred during product derivation from the relationships between annotated and non-annotated model elements as defined in the UML metamodel. The mapping technique is used to derive automatically a given product model. Performance is a run-time property of the deployed system and depends on other factors that are external to the design model, characterizing the underlying platforms and run-time environment. Performance completions provide a means to extend the modeling constructs of a system by including the influence of these factors. The variability space of the performance completions is covered and represented through Performance Completion-feature model (PC-feature model). Dealing manually with a large number of performance parameters annotating a UML+MARTE product model is an error-prone process. A model-driven user-friendly technique is proposed to automatically collect all generic performance parameters that need binding from the generated product model and present them to developers in a spreadsheet format, together with context and guiding information where each PC-feature is mapped to certain MARTE annotations corresponding to UML model elements in the product model.},
note = {AAINR89310}
}

@article{10.1007/s11334-011-0159-y,
author = {Ahmed, Faheem and Capretz, Luiz Fernando},
title = {An architecture process maturity model of software product line engineering},
year = {2011},
issue_date = {September 2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {7},
number = {3},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-011-0159-y},
doi = {10.1007/s11334-011-0159-y},
abstract = {Software architecture has been a key research area in the software engineering community due to its significant role in creating high-quality software. The trend of developing product lines rather than single products has made the software product line a viable option in the industry. Software product line architecture (SPLA) is regarded as one of the crucial components in the product lines, since all of the resulting products share this common architecture. The increased popularity of software product lines demands a process maturity evaluation methodology. Consequently, this paper presents an architecture process maturity model for software product line engineering to evaluate the current maturity of the product line architecture development process in an organization. Assessment questionnaires and a rating methodology comprise the framework of this model. The objective of the questionnaires is to collect information about the SPLA development process. Thus, in general this work contributes towards the establishment of a comprehensive and unified strategy for the process maturity evaluation of software product line engineering. Furthermore, we conducted two case studies and reported the assessment results, which show the maturity of the architecture development process in two organizations.},
journal = {Innov. Syst. Softw. Eng.},
month = sep,
pages = {191–207},
numpages = {17},
keywords = {Software product line, Software architecture, Process assessment, Domain engineering, Application engineering}
}

@inproceedings{10.1145/3382026.3431248,
author = {Ferreira, Thiago Nascimento and Vergilio, Silvia Regina and Kessentini, Mauroane},
title = {Many-objective Search-based Selection of Software Product Line Test Products with Nautilus},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431248},
doi = {10.1145/3382026.3431248},
abstract = {The Variability Testing of Software Product Lines (VTSPL) concerns the selection of the most representative products to be tested according to specific goals. Works in the literature use a great variety of objectives and distinct algorithms. However, they neither address all the objectives at the same time nor offer an automatic tool to support this task. To this end, this work introduces Nautilus/VTSPL, a tool to address the VTSPL problem, created by instantiating Nautilus Framework. Nautilus/VTSPL allows the tester to experiment and configure different objectives and categories of many-objective algorithms. The tool also offers support to visualization of the generated solutions, easing the decision-making process.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {1–4},
numpages = {4},
keywords = {sbse, product line testing, many-objective algorithms},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@article{10.1007/s10664-016-9439-3,
author = {Bagheri, Ebrahim and Benavides, David and Schmid, Klaus and Runeson, Per},
title = {Foreword to the special issue on empirical evidence on software product line engineering},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9439-3},
doi = {10.1007/s10664-016-9439-3},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1579–1585},
numpages = {7}
}

@inproceedings{10.1145/3483899.3483909,
author = {Furtado, Viviane and OliveiraJr, Edson and Kalinowski, Marcos},
title = {Guidelines for Promoting Software Product Line Experiments},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483909},
doi = {10.1145/3483899.3483909},
abstract = {The importance of experimentation for Software Engineering research has been notably established in the last years. The software engineering community has discussed how to proper report and evaluate experiments using different approaches, such as quality criteria, scales, and checklists. Nevertheless, there are no guidelines to support researchers and practitioners active in straightforward software engineering research areas, as in Software Product Lines (SPL), at conducting experiments. We hypothesize that experimentation guidelines may aid such a specific area by providing advice and actual excerpts reflecting good practices of SPL experimentation, thus experimentally evolving this area. Therefore, the goal of this paper is to provide guidelines for properly reporting and promoting SPL experiments. We defined such guidelines based on well-known software engineering experiment reports, quality evaluation checklists, and data extracted from 211 SPL experiments identified in a systematic mapping study. We evaluated the guidelines with a qualitative study with SPL and experimentation experts applying open and axial coding procedures. The evaluation enabled us to improve the guidelines. The resulting guidelines contain specific advice to researchers active in SPL and provide examples taken from published SPL experiments. The experts’ positive points indicate that the proposed guidelines can aid SPL researchers and practitioners. Sharing the resulting guidelines could support conducting SPL experiments and allow further area evolution based on prospective experiment replications and reproductions from well-designed and reported experiments.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {31–40},
numpages = {10},
keywords = {SPL Experiments, Qualitative Study, Guidelines, Experiment Reporting and Sharing},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/1982185.1982336,
author = {Asadi, Mohsen and Bagheri, Ebrahim and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Mohabbati, Bardia},
title = {Goal-driven software product line engineering},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982336},
doi = {10.1145/1982185.1982336},
abstract = {Feature Models encapsulate functionalities and quality properties of a product family. The employment of feature models for managing variability and commonality of large-scale product families raises an important question: on what basis should the features of a product family be selected for a target software application, which is going to be derived from the product family. Thus, the selection of the most suitable features for a specific application requires the understanding of its stakeholders' intentions and also the relationship between their intentions and the available software features. To address this important issue, we adopt a standard goal-oriented requirements engineering framework, i.e., the i* framework, for identifying stakeholders' intentions and propose an approach for explicitly mapping and bridging between the features of a product family and the goals and objectives of the stakeholders. We propose a novel approach to automatically preconfigure a given feature model based on the objectives of the target product stakeholders. Also, our approach is able to elucidate the rationale behind the selection of the most important features of a family for a target application.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {691–698},
numpages = {8},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@inproceedings{10.5555/2666064.2666075,
author = {Fant, Julie Street and Gomaa, Hassan and Pettit, Robert G.},
title = {Software product line engineering of space flight software},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {This paper presents a practical solution to a real-life industrial problem in the unmanned space flight software (FSW) domain using software product lines and software architectural design patterns. In the FSW domain, there exists a significant amount of variability in the required capabilities. For example, some FSW have a significant amount of hardware to control and operate in a nearly autonomous fashion. In contrast, other FSW have a small amount of hardware to control and rely heavily of commanding from the ground station to operate the spacecraft. The underlying architecture and component interactions needed for the different FSWs are quite different. This amount of architectural variability makes it difficult to develop a SPL architecture that covers the all possible variability in the FSW domain. Therefore, this paper presents a practical solution to this real world problem that leverages software product line concepts and software architectural design patterns.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {41–44},
numpages = {4},
keywords = {unmanned space flight software, software product lines, software architectural design patterns, UML},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1145/3106195.3106220,
author = {Young, Bobbi and Cheatwood, Judd and Peterson, Todd and Flores, Rick and Clements, Paul},
title = {Product Line Engineering Meets Model Based Engineering in the Defense and Automotive Industries},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106220},
doi = {10.1145/3106195.3106220},
abstract = {Product line engineering and model based engineering are two powerful engineering approaches that each bring significant advantages to system engineering projects. This paper explores how three companies - Raytheon, General Dynamics, and General Motors - are combining these two paradigms in unique and innovative ways in very challenging application domains to achieve engineering goals of critical importance to them.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {175–179},
numpages = {5},
keywords = {variation points, product configurator, model-based engineering, feature-based product line engineering, feature profiles, feature models, Product line engineering, PLE factory},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1016/j.jss.2015.11.005,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {An automatic process for weaving functional quality attributes using a software product line approach},
year = {2016},
issue_date = {February 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {112},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.11.005},
doi = {10.1016/j.jss.2015.11.005},
abstract = {We define a family of FQAs ready to be reused in many software architectures.We define an Aspect-Oriented SPL to inject customized FQAs into the applications.Two different implementations of the SPL are provided and compared.Modelling FQAs separately from the applications increases reusability.The final architectures exhibit a high degree of separation of concerns. Some quality attributes can be modelled using software components, and are normally known as Functional Quality Attributes (FQAs). Applications may require different FQAs, and each FQA (e.g., security) can be composed of many concerns (e.g., access control or authentication). They normally have dependencies between them and crosscut the system architecture. The goal of the work presented here is to provide the means for software architects to focus only on application functionality, without having to worry about FQAs. The idea is to model FQAs separately from application functionality following a Software Product Line (SPL) approach. By combining SPL and aspect-oriented mechanisms, we will define a generic process to model and automatically inject FQAs into the application without breaking the base architecture. We will provide and compare two implementations of our generic approach using different variability and architecture description languages: (i) feature models and an aspect-oriented architecture description language; and (ii) the Common Variability Language (CVL) and a MOF-compliant language (e.g., UML). We also discuss the benefits and limitations of our approach. Modelling FQAs separately from the base application has many advantages (e.g., reusability, less coupled components, high cohesive architectures).},
journal = {J. Syst. Softw.},
month = feb,
pages = {78–95},
numpages = {18},
keywords = {Weaving, Software product lines, Quality attributes}
}

@inproceedings{10.5555/1885639.1885680,
author = {Lutz, Robyn and Weiss, David and Krishnan, Sandeep and Yang, Jingwei},
title = {Software product line engineering for long-lived, sustainable systems},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The design and operation of long-lived, sustainable systems (LSS) are hampered by limited support for change over time and limited preservation of system knowledge. The solution we propose is to adopt software product-line engineering (SPLE) techniques for use in single, critical systems with requirements for sustainability. We describe how four categories of change in a LSS can be usefully handled as variabilities in a software product line. We illustrate our argument with examples of changes from the Voyager spacecraft.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {430–434},
numpages = {5},
keywords = {variability, sustainable system, software product line, long-lived system, commonality/variability analysis},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.5555/1753235.1753273,
author = {Takebe, Yasuaki and Fukaya, Naohiko and Chikahisa, Masaki and Hanawa, Toshihide and Shirai, Osamu},
title = {Experiences with software product line engineering in product development oriented organization},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Core asset development is a key activity for software product line engineering. However, for many organizations, it is difficult to set up a core asset development team due to environmental factors such as their business, scale and culture.This paper describes our method for software product line engineering in such product development oriented organization. In this method, a champion team is organized from champion members belonging to each product development teams, which is in charge of decision making on core asset issues.We present our experiences of applying our method to embedded software for a clinical analyzer product line in a product development oriented organization. We analyzed the cost of core asset development with a champion team and confirmed that the overhead of coordinating between product development teams is negligible in our case study. We also discuss some practices we had in our case study to overcome possible problems of core asset development in a product development oriented organizations.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {275–283},
numpages = {9},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2420942.2420948,
author = {Gonz\'{a}lez-Huerta, Javier and Insfran, Emilio and Abrah\~{a}o, Silvia and McGregor, John D.},
title = {Non-functional requirements in model-driven software product line engineering},
year = {2012},
isbn = {9781450318075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420942.2420948},
doi = {10.1145/2420942.2420948},
abstract = {Developing variant-rich software systems through the application of the software product line approach requires the management of a wide set of requirements. However, in most cases, the focus of those requirements is limited to the functional requirements. The non-functional requirements are often informally defined and their management does not provide traceability mechanisms for their validation. In this paper, we present a multimodel approach that allows the explicit representation of non-functional requirements for software product lines both at domain engineering, and application engineering levels. The multimodel allows the representation of different viewpoints of a software product line, including the non-functional requirements and the relationships that these non-functional requirements might have with features and functionalities. The feasibility of this approach is illustrated through a specific example from the automotive domain.},
booktitle = {Proceedings of the Fourth International Workshop on Nonfunctional System Properties in Domain Specific Modeling Languages},
articleno = {6},
numpages = {6},
keywords = {software product lines, non-functional requirements, model driven engineering},
location = {Innsbruck, Austria},
series = {NFPinDSML '12}
}

@inproceedings{10.1145/1985782.1985785,
author = {Remmel, Hanna and Paech, Barbara and Engwer, Christian and Bastian, Peter},
title = {Supporting the testing of scientific frameworks with software product line engineering: a proposed approach},
year = {2011},
isbn = {9781450305983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985782.1985785},
doi = {10.1145/1985782.1985785},
abstract = {Testing scientific software involves dealing with special challenges like missing test oracle and different possible sources of a problem. When testing scientific frameworks, additionally a large variety of mathematical algorithms and possible applications for the framework has to be handled. We propose to use concepts of software product line engineering to handle this variability.The contribution of this paper is a two-step process for reengineering a variability model out of a framework for scientific software. This process is explained with a real case study. Furthermore, we sketch how the variability model can be used to systematically derive system test applications for the framework.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering for Computational Science and Engineering},
pages = {10–18},
numpages = {9},
keywords = {variability modeling, testing, software product line engineering, scientific software, framework},
location = {Waikiki, Honolulu, HI, USA},
series = {SECSE '11}
}

@inproceedings{10.1145/2480362.2480694,
author = {Diwan, Piyush and Carey, Patricia and Franz, Eric and Li, Yixue and Bitterman, Thomas and Hudak, David E. and Ramnath, Rajiv},
title = {Applying software product line engineering in building web portals for supercomputing services},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480694},
doi = {10.1145/2480362.2480694},
abstract = {Supercomputing centers, typically non-profit, government or university-based organizations with scarce resources, are increasingly being requested to provide customized web portals for user-centered access to their services in order to support a demanding customer base. These portals often have very similar architectures and meet similar requirements, with the variations primarily being in the specialized analysis applications, and in the input and output of these applications. Given these characteristics, Software Production Line Engineering (SPLE) approaches will be valuable in enabling development teams to cost-effectively meet demands. In this paper, we demonstrate a suite of web portals developed at The Ohio Supercomputer Center (OSC) by applying SPLE methodologies. We show how we applied feature modeling on these applications to identify commonalities in their application level features despite differences in their problem domains. We describe a common framework (we term it Per User DrupaL, or PUDL), which serves as the common foundation for these portals. We demonstrate the effectiveness of SPLE in terms of reduced development time and effort, and discuss the technical challenges faced in this process. Finally we propose, as an extension to our work, an automation framework for portal generation, which users could build their own customized portals.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1765–1771},
numpages = {7},
keywords = {supercomputing, software-as-a-service, software product line engineering, portals, high performance computing, feature modeling, end-user computing, drupal},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@article{10.1007/s11219-009-9088-5,
author = {Ahmed, Faheem and Capretz, Luiz Fernando},
title = {An organizational maturity model of software product line engineering},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-009-9088-5},
doi = {10.1007/s11219-009-9088-5},
abstract = {Software product line engineering is an inter-disciplinary concept. It spans the dimensions of business, architecture, process, and the organization. Some of the potential benefits of this approach include cost reduction, improvements in product quality and a decrease in product development time. The increasing popularity of software product line engineering in the software industry necessitates a process maturity evaluation methodology. Accordingly, this paper presents an organizational maturity model of software product line engineering for evaluating the maturity of organizational dimension. The model assumes that organizational theories, behavior, and management play a critical role in the institutionalization of software product line engineering within an organization. Assessment questionnaires and a rating methodology comprise the framework of this model. The objective and design of the questionnaires are to collect information about the software product line engineering process from the dual perspectives of organizational behavior and management. Furthermore, we conducted two case studies and reported the assessment results using the organizational maturity model presented in this paper.},
journal = {Software Quality Journal},
month = jun,
pages = {195–225},
numpages = {31},
keywords = {Software process maturity, Software process improvement, Software process assessment, Software engineering, Software, Product Line}
}

@inproceedings{10.1145/3422392.3422402,
author = {da Silva, Leandro Flores and Oliveira, Edson},
title = {Evaluating usefulness, ease of use and usability of an UML-based Software Product Line Tool},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422402},
doi = {10.1145/3422392.3422402},
abstract = {Software Product Line (SPL) is a software development approach that systematically applies reuse of artifacts in a specific domain. In the last years, the industry has increasingly required the support of tools for most SPL life cycle activities, targeting feature models and related diagrams, variability management and SPL specific products configuration. However, existing literature does not present any tools with native support to UML-based SPLs. In addition, relying on manipulating XMI files for general-purpose UML tools for such SPLs takes significant effort, and it is time-consuming and error-prone. In this scenario, we developed SMartyModeling, with support to UML stereotype-based variability management. To evolve our tool, we evaluated it throughout a survey answered by 37 participants. We adopted questions from the Technology Acceptance Model (TAM) and the System Usability Scale (SUS). We organized it into three sections of Likert-scaled questions for usefulness, ease of use, and usability. A last section consisted of open questions focused on positive and negative aspects and an overview of the evalaution. SMartyModeling was well evaluated in relation to usefulness, ease of use, and usability. We analyzed and interpreted the respondents quotes using correlation techniques and open and axial coding. The analysis of open questions allowed us a direct identification of points to improve the tool, its limitations and positive aspects.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {798–807},
numpages = {10},
keywords = {SPL tool support, Software Product Line, UML},
location = {Natal, Brazil},
series = {SBES '20}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {product-line analysis, Software product lines}
}

@article{10.1016/j.procs.2020.03.380,
author = {Hitesh and Chhikara, Rita and Kumari, A. Charan},
title = {Feature Selection Optimization of HealthCare Software Product Line using BBO},
year = {2020},
issue_date = {2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {167},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2020.03.380},
doi = {10.1016/j.procs.2020.03.380},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1696–1704},
numpages = {9},
keywords = {Software Product Line, Biogeography based optimization(BBO), Feature Model(FM), Genetic Algorithm(GA)}
}

@inproceedings{10.1145/2701319.2701326,
author = {Soares, Larissa Rocha and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Non-Functional Properties in Software Product Lines: A Reuse Approach},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701326},
doi = {10.1145/2701319.2701326},
abstract = {Software Product Line Engineering (SPLE) emerges for software organizations interested in customized products at reasonable costs. Based on the selection of features, stakeholders can derive programs satisfying a range of functional properties and non-functional ones. The explicit definition of Non-Functional Properties (NFP) during software configuration has been considered a challenging task. Dealing with them is not well established yet, neither in theory nor in practice. In this sense, we present a framework to specify NFP for SPLE and we also propose a reuse approach that promotes the reuse of NFP values during the product configuration. We discuss the results of a case study aimed to evaluate the applicability of the proposed work.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {67–74},
numpages = {8},
keywords = {Software Product Line, Quality Attributes, Empirical Software Engineering},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@inproceedings{10.1007/978-3-030-83903-1_9,
author = {Shahin, Ramy and Kokaly, Sahar and Chechik, Marsha},
title = {Towards Certified Analysis of Software Product Line Safety Cases},
year = {2021},
isbn = {978-3-030-83902-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-83903-1_9},
doi = {10.1007/978-3-030-83903-1_9},
abstract = {Safety-critical software systems are in many cases designed and implemented as families of products, usually referred to as Software Product Lines (SPLs). Products within an SPL vary from each other in terms of which features they include. Applying existing analysis techniques to SPLs and their safety cases is usually challenging because of the potentially exponential number of products with respect to the number of supported features. In this paper, we present a methodology and infrastructure for certified lifting of existing single-product safety analyses to product lines. To ensure certified safety of our infrastructure, we implement it in an interactive theorem prover, including formal definitions, lemmas, correctness criteria theorems, and proofs.We apply this infrastructure to formalize and lift a Change Impact Assessment (CIA) algorithm. We present a formal definition of the lifted algorithm, outline its correctness proof (with the full machine-checked proof available online), and discuss its implementation within a model management framework.},
booktitle = {Computer Safety, Reliability, and Security: 40th International Conference, SAFECOMP 2021, York, UK, September 8–10, 2021, Proceedings},
pages = {130–145},
numpages = {16},
keywords = {Safety cases, Product lines, Lean, Certified analysis},
location = {York, United Kingdom}
}

@inproceedings{10.1145/2934466.2934483,
author = {Richenhagen, Johannes and Rumpe, Bernhard and Schlo\ss{}er, Axel and Schulze, Christoph and Thissen, Kevin and von Wenckstern, Michael},
title = {Test-driven semantical similarity analysis for software product line extraction},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934483},
doi = {10.1145/2934466.2934483},
abstract = {Software product line engineering rests upon the assumption that a set of products share a common base of similar functionality. The correct identification of similarities between different products can be a time-intensive task. Hence, this paper proposes an automated semantical similarity analysis supporting software product line extraction and maintenance. Under the assumption of an already identified compatible interface, the degree of semantical similarity is identified based on provided test cases. Therefore, the analysis can also be applied in a test-driven development. This is done by translating available test sequences for both components into two I/O extended finite automata and performing an abstraction of the defined behavior until a simulation relation is established. The test-based approach avoids complexity issues regarding the state space explosion problem, a common issue in model checking. The proposed approach is applied on different variants and versions of industrially used software components provided by an automotive supplier to demonstrate the method's applicability.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {174–183},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2934466.2934491,
author = {Fogdal, Thomas and Scherrebeck, Helene and Kuusela, Juha and Becker, Martin and Zhang, Bo},
title = {Ten years of product line engineering at Danfoss: lessons learned and way ahead},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934491},
doi = {10.1145/2934466.2934491},
abstract = {Software and systems product line engineering (PLE) has been an established approach for reducing time to market as well as cost and increasing quality in a set of related products for two decades now. Although there is a huge body of knowledge on PLE, adopting a concrete PLE approach is still not a trivial endeavor for interested companies. With the increasing importance of development speed, the advent of agile engineering approaches, and decreasing management interest in improvements that require large organizational transformations and only show benefits after several years, companies are facing challenges in successfully adopting this approach. They often hesitate as there is no clear adoption path, nor any certainty, that the intended improvement steps will also provide added value in the short- and mid-term perspective. In consequence, a considerable amount of PLE potential still remains unexploited.To help such companies with the adoption of PLE, the goal of this paper is to provide inspiration and evidence that PLE is a sound approach and its successful introduction is possible even in settings that differ substantially from those of pioneer product lines.To this end, this paper presents the following main contributions with the PLE adoption case at Danfoss Drives: an overview of the key change drivers and the motivation for adopting a PLE approach, a discussion of incremental PLE introduction in an agile engineering context, a presentation of the current PLE setting with a focus on key concepts, and finally a presentation of motivators and directions for future improvements.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {252–261},
numpages = {10},
keywords = {product line evaluation, product line adoption, industrial experiences},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3425269.3425271,
author = {Nicolodi, Luciane Baldo and Colanzi, Thelma Elita and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Architectural Feature Re-Modularization for Software Product Line Evolution},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425271},
doi = {10.1145/3425269.3425271},
abstract = {Extensive maintenance leads to the Software Product Line Architecture (PLA) degradation over time. When there is the need of evolving the Software Product Line (SPL) to include new features, or move to a new platform, a degraded PLA requires considerable effort to understand and modify, demanding expensive refactoring activity. In the state of the art, search-based algorithms are used to improve PLA at package level. However, recent studies have shown that the most variability and implementation details of an SPL are described in the level of classes. There is a gap between existing approaches and existing practical needs. In this work, we extend the current state of the art to deal with feature modularization in the level of classes by introducing a new search operator and a set of objective functions to deal with feature modularization in a finer granularity of the architectural elements, namely at class level. We evaluated the proposal in an exploratory study with a PLA widely investigated and a real-world PLA. The results of quantitative and qualitative analysis point out that our proposal provides solutions to properly re-modularize features in a PLA, being preferred by practitioners, in order to support the evolution of SPLs.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {31–40},
numpages = {10},
keywords = {Software Evolution, Search-based Software Engineering, Feature Modularization, Architectural Degradation},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@inproceedings{10.1145/3233027.3233028,
author = {Rabiser, Rick and Schmid, Klaus and Becker, Martin and Botterweck, Goetz and Galster, Matthias and Groher, Iris and Weyns, Danny},
title = {A study and comparison of industrial vs. academic software product line research published at SPLC},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233028},
doi = {10.1145/3233027.3233028},
abstract = {The study presented in this paper aims to provide evidence for the hypothesis that software product line research has been changing and that the works in industry and academia have diverged over time. We analysed a subset (140) of all (593) papers published at the Software Product Line Conference (SPLC) until 2017. The subset was randomly selected to cover all years as well as types of papers. We assessed the research type of the papers (academic or industry), the kind of evaluation (application example, empirical, etc.), and the application domain. Also, we assessed which product line life-cycle phases, development practices, and topics the papers address. We present an analysis of the topics covered by academic vs. industry research and discuss the evolution of these topics and their relation over the years. We also discuss implications for researchers and practitioners. We conclude that even though several topics have received more attention than others, academic and industry research on software product lines are actually rather in line with each other.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {14–24},
numpages = {11},
keywords = {software product lines, industry, academia, SPLC},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2791060.2791071,
author = {Wozniak, Len and Clements, Paul},
title = {How automotive engineering is taking product line engineering to the extreme},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791071},
doi = {10.1145/2791060.2791071},
abstract = {Automotive manufacturing ranks among the most extreme instances of systems and software product line engineering (PLE). The product family numbers in the millions, each product is highly complex in its own right, and the variation across products is literally astronomical in scale. This paper explores the aspects that make the domain extreme and the very specific implications they have for PLE. These implications include the need for efficient manufacturing, complexity management, concurrent development streams, globally distributed engineering and production, a hierarchical product family tree, multi-level variation binding, constraint management, and a highly robust and integrated PLE tooling environment. Happily, the PLE paradigm supporting these implications brings about a number of opportunities for analysis and automation that provide efficiencies of production previously unattainable. We focus on one example in depth: The management and automated generation of the many thousands of calibration parameters that determine vehicle-specific software behavior. Throughout, we use the vehicle product line at General Motors, which we believe to be the world's largest, to illustrate and ground our journey through automotive PLE.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {327–336},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product configurator, feature profiles, feature modeling, bill-of-features, automotive product lines},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2362536.2362545,
author = {Lee, Jihyun and Kang, Sungwon and Lee, Danhyung},
title = {A survey on software product line testing},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362545},
doi = {10.1145/2362536.2362545},
abstract = {Software product line (SPL) testing consists of two separate but closely related test engineering activities: domain testing and application testing. Various software product line testing approaches have been developed over the last decade, and surveys have been conducted on them. However, thus far none of them deeply addressed the questions of what researches have been conducted in order to overcome the challenges posed by the two separate testing activities and their relationships. Thus, this paper surveys the current software product line testing approaches by defining a reference SPL testing processes and identifying, based on them, key research perspectives that are important in SPL testing. Through this survey, we identify the researches that addressed the challenges and also derive open research opportunities from each perspective.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {31–40},
numpages = {10},
keywords = {software testing, software product line testing, software product line engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/978-3-642-33678-2_30,
author = {Braga, Rosana T. Vaccare and Trindade Junior, Onofre and Castelo Branco, Kalinka Regina and Neris, Luciano De Oliveira and Lee, Jaejoon},
title = {Adapting a software product line engineering process for certifying safety critical embedded systems},
year = {2012},
isbn = {9783642336775},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33678-2_30},
doi = {10.1007/978-3-642-33678-2_30},
abstract = {Software Product Line Engineering (SPLE) is a software development paradigm that aims at reducing the development effort and shorting time-to-market through systematic software reuse. While this paradigm has been successfully applied for the development of embedded systems in various domains, new challenges have emerged from the development of safety critical systems that require certification against a specific standard. Existing SPLE approaches do not explicitly consider the various certification standards or levels that products should satisfy. In this paper, we focus on several practical issues involved in the SPLE process, establishing an infrastructure of a product line engineering for certified products. A metamodel is proposed to capture the entities involved in SPL certification and the relationships among them. ProLiCES, which is a model-driven process for the development of SPLs, was modified to serve as an example of our approach, in the context of the UAV (Unmanned Aerial Vehicle) domain.},
booktitle = {Proceedings of the 31st International Conference on Computer Safety, Reliability, and Security},
pages = {352–363},
numpages = {12},
keywords = {software certification, safety-critical embedded systems, development process},
location = {Magdeburg, Germany},
series = {SAFECOMP'12}
}

@inproceedings{10.1007/978-3-030-64148-1_6,
author = {Hayashi, Kengo and Aoyama, Mikio},
title = {A Portfolio-Driven Development Model and Its Management Method of Agile Product Line Engineering Applied to Automotive Software Development},
year = {2020},
isbn = {978-3-030-64147-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64148-1_6},
doi = {10.1007/978-3-030-64148-1_6},
abstract = {In recent automotive systems development, realizing both variability and agility is the key competitiveness to meet the diverse requirements in global markets and rapidly increasing intelligent functions. This article proposes a portfolio-driven development method and its management method of APLE (Agile Product Line Engineering). The proposed method is intended to manage agile evolution of multiple product lines while increasing variability of products. To establish a portfolio management of development resources, it is necessary for an organization to manage multiple product lines on APLE in an entire development. We propose a portfolio-driven development method of three layers on APLE and its management method based on a concept of portfolio management life cycle. We applied the proposed management model and method to the multiple product lines of automotive software systems, and demonstrated an improvement of manageability with better predictability of both productivity and development size. This article contributes to provide an entire development management method for APLE, and its practical experience in the automotive multiple product lines.},
booktitle = {Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings},
pages = {88–105},
numpages = {18},
keywords = {Automotive software development, Portfolio management, Agile product line engineering, Agile software development, Software product line},
location = {Turin, Italy}
}

@inproceedings{10.1145/2491627.2493906,
author = {Bashari, Mahdi and Bagheri, Ebrahim},
title = {Engineering self-adaptive systems and dynamic software product line},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2493906},
doi = {10.1145/2491627.2493906},
abstract = {Self-adaptive systems are a class of software applications, which are able to dynamically transform their internal structure and hence their behavior in response to internal or external stimuli. The transformation may provide the basis for new functionalities or improve or maintain non-functional properties in order to match the application better to its operational requirements and standards. Software Product Line Engineering has rich methods and techniques in variability modeling and management which is one of the main issues in developing self-adaptive systems. Dynamic software product lines (DSPL) have been proposed to exploit the knowledge acquired in SPLE to develop self-adaptive software systems.In this tutorial, we portray the problem of developing self-adaptive systems. Then we investigate how the idea of dynamic software product line could help to deal with the challenges that we face in developing efficient self-adaptive software. We also offer insight into the different approaches that use dynamic software product line engineering for developing self-adaptive systems focusing on practical approaches by showing how the approaches are applied to real case studies and also methods for evaluating these approaches. This tutorial also discuss how DSPL could be used some relevant areas to self-adaptive systems and challenges which still exist in the area.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {285},
numpages = {1},
keywords = {self-adaptive systems, dynamic software product line},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.5555/1753235.1753277,
author = {Botterweck, Goetz and Groher, Iris and Polzer, Andreas and Schwanninger, Christa and Thiel, Steffen and V\"{o}lter, Markus},
title = {1st International Workshop on Model-driven Approaches in Software Product Line Engineering: (MAPLE 2009)},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {The MAPLE workshop focuses on the combination of Model-driven Software Engineering and Software Product Lines (SPL). It explores how model-driven approaches can help to achieve the goals of product lines in terms of reducing cost and time to market and increasing quality and productivity. In particular the workshop revolves around three themes: Efficient product derivation, the link between SPL research and industry practice, and SPL models with a meaning.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {297–298},
numpages = {2},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/1321631.1321730,
author = {Dhungana, Deepak and Rabiser, Rick and Gr\"{u}nbacher, Paul and Neumayer, Thomas},
title = {Integrated tool support for software product line engineering},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321730},
doi = {10.1145/1321631.1321730},
abstract = {Product line engineering comprises many heterogeneous activities such as capturing the variability of reusable assets, supporting the derivation of products from the product line, evolving the product line, or tailoring the approach to the specifics of a domain. The inherent complexity of product lines implicates that tool support is inevitable to facilitate smooth performance and to avoid costly errors. Product line engineering tools have to support heterogeneous stakeholders involved in diverse activities. Tool integration therefore is of particular importance to foster their seamless cooperation. However, the integration is difficult to achieve due to the diversity of models and work products. This paper describes the DOPLER tool suite which has been developed to provide such integrated support. The tool suite is flexible and extensible to support domain-specific needs},
booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {533–534},
numpages = {2},
keywords = {variability modeling, product line tools, product line engineering, product derivation, multi-team modeling, model evolution},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{10.1145/2364412.2364445,
author = {Martinez, Jabier and Thurimella, Anil Kumar},
title = {Collaboration and source code driven bottom-up product line engineering},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364445},
doi = {10.1145/2364412.2364445},
abstract = {Companies that develop similar software systems often transition from single-system development to software product line development. In this transition, reusable assets are identified and incrementally created over a period of time. Bottom-up Software Product Line Engineering approaches aid stakeholders to identify variability from the legacy artifacts. One of these artifacts is the legacy source code. In this paper, we contribute the Collaboration and Source Code Driven Bottom-up approach, with two main enhancements. We apply clone detection and architecture reengineering techniques for identifying variability from the legacy artifacts. These techniques which have been traditionally used for maintaining software are now used for identifying variability and analyze code coupling and cohesion from the legacy code. Our second enhancement is improving stakeholder collaboration by guiding the domain experts in order to decide on variability. In particular, we apply Questions, Options and Criteria technique for capturing rationale and supporting collaboration.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {196–200},
numpages = {5},
keywords = {variability modeling, software product line engineering, rationale, knowledge management, clone detection, architecture reengineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1016/j.csi.2016.03.003,
author = {Afzal, Uzma and Mahmood, Tariq and Shaikh, Zubair},
title = {Intelligent software product line configurations},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {48},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2016.03.003},
doi = {10.1016/j.csi.2016.03.003},
abstract = {A software product line (SPL) is a set of industrial software-intensive systems for configuring similar software products in which personalized feature sets are configured by different business teams. The integration of these feature sets can generate inconsistencies that are typically resolved through manual deliberation. This is a time-consuming process and leads to a potential loss of business resources. Artificial intelligence (AI) techniques can provide the best solution to address this issue autonomously through more efficient configurations, lesser inconsistencies and optimized resources. This paper presents the first literature review of both research and industrial AI applications to SPL configuration issues. Our results reveal only 19 relevant research works which employ traditional AI techniques on small feature sets with no real-life testing or application in industry. We categorize these works in a typology by identifying 8 perspectives of SPL. We also show that only 2 standard industrial SPL tools employ AI in a limited way to resolve inconsistencies. To inject more interest and application in this domain, we motivate and present future research directions. Particularly, using real-world SPL data, we demonstrate how predictive analytics (a state of the art AI technique) can separately model inconsistent and consistent patterns, and then predict inconsistencies in advance to help SPL designers during the configuration of a product. Literature review of AI applications to SPL configuration issuesDevelop a taxonomy based on eight different problem domainsThis review shows use of logic, constraint satisfaction, reasoning, ontology and optimization.Several important future research directions are proposed.We justify advanced analytics and swarm intelligence as better future applications.},
journal = {Comput. Stand. Interfaces},
month = nov,
pages = {30–48},
numpages = {19},
keywords = {Software product line, Predictive analytics, Literature review, Industrial SPL tools, Inconsistencies, Automated feature selection, Artificial intelligence}
}

@inproceedings{10.1109/APSEC.2008.45,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Kuhlemann, Martin and K\"{a}stner, Christian and Saake, Gunter},
title = {Measuring Non-Functional Properties in Software Product Line for Product Derivation},
year = {2008},
isbn = {9780769534466},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2008.45},
doi = {10.1109/APSEC.2008.45},
abstract = {A software product line (SPL) enables stakeholders to derive different software products for a domain while providing a high degree of reuse of their code units. Software products are derived in a configuration process by composing different code units. The configuration process becomes complex if SPLs contain hundreds of features. In many cases, a stakeholder is not only interested in functional but also in non-functional properties of a desired product. Because SPLs can be used in different application scenarios alternative implementations of already existing functionality are developed to meet special non-functional requirements, like restricted binary size and performance guarantees. To enable these complex configurations we discuss and present techniques to measure non-functional properties of software modules and use these values to compute SPL configurations optimized to the users needs.},
booktitle = {Proceedings of the 2008 15th Asia-Pacific Software Engineering Conference},
pages = {187–194},
numpages = {8},
keywords = {Software Product Lines, Product Derivation, Non-functional Properties},
series = {APSEC '08}
}

@inproceedings{10.1145/2934466.2934481,
author = {Sion, Laurens and Van Landuyt, Dimitri and Joosen, Wouter and de Jong, Gjalt},
title = {Systematic quality trade-off support in the software product-line configuration process},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934481},
doi = {10.1145/2934466.2934481},
abstract = {Software product line engineering is a compelling methodology that accomplishes systematic reuse in families of systems by relying on two key principles: (i) the decomposition of complex systems into composable and reusable building blocks (often logical units called features), and (ii) on-demand construction of products and product variants by composing these building blocks.However, unless the stakeholder responsible for product configuration has detailed knowledge of the technical ins and outs of the software product line (e.g., the architectural impact of a specific feature, or potential feature interactions), he is in many cases flying in the dark. Although many initial approaches and techniques have been proposed that take into account quality considerations and involve trade-off decisions during product configuration, no systematic support exists.In this paper, we present a reference architecture for product configuration tooling, providing support for (i) up-front generation of variants, and (ii) quality analysis of these variants. This allows pro-actively assessing and predicting architectural quality properties for each product variant and in turn, product configuration tools can take into account architectural considerations. In addition, we provide an in-depth discussion of techniques and tactics for dealing with the problem of variant explosion, and as such to maintain practical feasibility of such approaches.We validated and implemented our reference architecture in the context of a real-world industrial application, a product-line for the firmware of an automotive sensor. Our prototype, based on FeatureIDE, is open for extension and readily available.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {164–173},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1109/SPLC.2011.44,
author = {Nolan, Andy J. and Abrahao, Silvia and Clements, Paul and McGregor, John D. and Cohen, Sholom},
title = {Towards the Integration of Quality Attributes into a Software Product Line Cost Model},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.44},
doi = {10.1109/SPLC.2011.44},
abstract = {A good estimation tool offers a "model" of a project and is usually used to estimate cost and schedule, but it can also be used to help make trade decisions that affect cost and schedule as well as to estimate risks and opportunities. It was evident that Rolls-Royce needed a cost model to underpin decisions when they launched a Software Product Line initiative. The first generation cost model was based on COCOMO II, which represents the software product as a single size measure (Source Lines of Code) but makes limited use of the architecture or any characteristics of the product being developed. The next generation of the cost model, currently under development, is intended to account for the quality attributes of the core assets and the resulting products in order to estimate their impact on cost and net-benefit to the business. The objective of this paper is to describe our current efforts to integrate key quality attributes into the SPL cost model. We describe the quality attributes selected, the reason for their selection and the benefits we expect to obtain after integrating them into the model.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {203–212},
numpages = {10},
keywords = {Software Product Lines, Safety-Critical Software, Quality Attributes, Industrial Experiences, Cost Estimation},
series = {SPLC '11}
}

@inproceedings{10.1145/3307630.3342385,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {HADAS: Analysing Quality Attributes of Software Configurations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342385},
doi = {10.1145/3307630.3342385},
abstract = {Software Product Lines (SPLs) are highly configurable systems. Automatic analyses of SPLs rely on solvers to navigate complex dependencies among features and find legal solutions. Variability analysis tools are complex due to the diversity of products and domain-specific knowledge. On that, while there are experimental studies that analyse quality attributes, the knowledge is not easily accessible for developers, and its appliance is not trivial. Aiming to allow the industry to quality-explore SPL design spaces, we developed the HADAS assistant that: (1) models systems and collects quality attributes metrics in a cloud repository, and (2) reasons about it helping developers with quality attributes requirements.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {13–16},
numpages = {4},
keywords = {variability, software product line, numerical, model, attribute, NFQA},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10664-019-09787-6,
author = {Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp and Ziadi, Tewfik and Robin, Jacques and Martinez, Jabier},
title = {The state of adoption and the challenges of systematic variability management in industry},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09787-6},
doi = {10.1007/s10664-019-09787-6},
abstract = {Handling large-scale software variability is still a challenge for many organizations. After decades of research on variability management concepts, many industrial organizations have introduced techniques known from research, but still lament that pure textbook approaches are not applicable or efficient. For instance, software product line engineering—an approach to systematically develop portfolios of products—is difficult to adopt given the high upfront investments; and even when adopted, organizations are challenged by evolving their complex product lines. Consequently, the research community now mainly focuses on re-engineering and evolution techniques for product lines; yet, understanding the current state of adoption and the industrial challenges for organizations is necessary to conceive effective techniques. In this multiple-case study, we analyze the current adoption of variability management techniques in twelve medium- to large-scale industrial cases in domains such as automotive, aerospace or railway systems. We identify the current state of variability management, emphasizing the techniques and concepts they adopted. We elicit the needs and challenges expressed for these cases, triangulated with results from a literature review. We believe our results help to understand the current state of adoption and shed light on gaps to address in industrial practice.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {1755–1797},
numpages = {43},
keywords = {Challenges, Multiple-case study, Software product lines, Variability management}
}

@article{10.1007/s10664-012-9234-8,
author = {Reinhartz-Berger, Iris and Sturm, Arnon},
title = {Comprehensibility of UML-based software product line specifications},
year = {2014},
issue_date = {June      2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9234-8},
doi = {10.1007/s10664-012-9234-8},
abstract = {Software Product Line Engineering (SPLE) deals with developing artifacts that capture the common and variable aspects of software product families. Domain models are one kind of such artifacts. Being developed in early stages, domain models need to specify commonality and variability and guide the reuse of the artifacts in particular software products. Although different modeling methods have been proposed to manage and support these activities, the assessment of these methods is still in an inceptive stage. In this work, we examined the comprehensibility of domain models specified in ADOM, a UML-based SPLE method. In particular, we conducted a controlled experiment in which 116 undergraduate students were required to answer comprehension questions regarding a domain model that was equipped with explicit reuse guidance and/or variability specification. We found that explicit specification of reuse guidance within the domain model helped understand the model, whereas explicit specification of variability increased comprehensibility only to a limited extent. Explicit specification of both reuse guidance and variability often provided intermediate results, namely, results that were better than specification of variability without reuse guidance, but worse than specification of reuse guidance without variability. All these results were perceived in different UML diagram types, namely, use case, class, and sequence diagrams and for different commonality-, variability-, and reuse-related aspects.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {678–713},
numpages = {36},
keywords = {Variability management, UML, Software product line engineering, Empirical evaluation, Domain models}
}

@inproceedings{10.5555/1759394.1759427,
author = {Reis, Sacha and Metzger, Andreas and Pohl, Klaus},
title = {Integration testing in software product line engineering: a model-based technique},
year = {2007},
isbn = {9783540712886},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The development process in software product line engineering is divided into domain engineering and application engineering. As a consequence of this division, tests should be performed in both processes. However, existing testing techniques for single systems cannot be applied during domain engineering, because of the variability in the domain artifacts. Existing software product line test techniques only cover unit and system tests. Our contribution is a model-based, automated integration test technique that can be applied during domain engineering. For generating integration test case scenarios, the technique abstracts from variability and assumes that placeholders are created for variability. The generated scenarios cover all interactions between the integrated components, which are specified in a test model. Additionally, the technique reduces the effort for creating placeholders by minimizing the number of placeholders needed to execute the integration test case scenarios. We have experimentally measured the performance of the technique and the potential reduction of placeholders.},
booktitle = {Proceedings of the 10th International Conference on Fundamental Approaches to Software Engineering},
pages = {321–335},
numpages = {15},
location = {Braga, Portugal},
series = {FASE'07}
}

@article{10.1504/ijaip.2021.116357,
author = {Rajesh, Sudha and Sekar, A. Chandra},
title = {Evaluation of quality attributes of software design patterns using association rules},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {3–4},
issn = {1755-0386},
url = {https://doi.org/10.1504/ijaip.2021.116357},
doi = {10.1504/ijaip.2021.116357},
abstract = {For the past decades, there were many analysing methods used which in turn to analyse only the views of a single stakeholder. The analysing progression facilitates us to guarantee the quality of overall design. By doing so there were many limitations that lead to critical situations in the development process. This work proposes to collect all the stakeholders' decisions in a single structural view, which expose the centric-view decision in an architectural design. It also used to deal with the disagreement in vision by examining it, with the premium software quality characteristic. The quality attributes are evaluated by association rules to improve the excellence of the software design. Association rules are implemented using R tool to get the support, confidence, lift and count values of each attribute along with its metric. The best quality attributes are chosen after managing the stakeholders' conflicts, since all the systems are designed due to the stakeholders' concerns. The best design patterns can be evaluated along with the distinguished attributes. These patterns are evaluated by fixing the basic principles of patterns based on their excellence.},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {314–327},
numpages = {13},
keywords = {quality attributes, support, design patterns, confidence, association rules}
}

@inproceedings{10.1145/2491627.2491647,
author = {Murashkin, Alexandr and Antkiewicz, Micha\l{} and Rayside, Derek and Czarnecki, Krzysztof},
title = {Visualization and exploration of optimal variants in product line engineering},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491647},
doi = {10.1145/2491627.2491647},
abstract = {The decision-making process in Product Line Engineering (PLE) is often concerned with variant qualities such as cost, battery life, or security. Pareto-optimal variants, with respect to a set of objectives such as minimizing a variant's cost while maximizing battery life and security, are variants in which no single quality can be improved without sacrificing other qualities. We propose a novel method and a tool for visualization and exploration of a multi-dimensional space of optimal variants (i.e., a Pareto front). The visualization method is an integrated, interactive, and synchronized set of complementary views onto a Pareto front specifically designed to support PLE scenarios, including: understanding differences among variants and their positioning with respect to quality dimensions; solving trade-offs; selecting the most desirable variants; and understanding the impact of changes during product line evolution on a variant's qualities. We present an initial experimental evaluation showing that the visualization method is a good basis for supporting these PLE scenarios.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {111–115},
numpages = {5},
keywords = {visualization, product line engineering, pareto front, optimal variant, feature modeling, exploration, clafer, ClaferMoo visualizer, ClaferMoo},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3289402.3289504,
author = {Sebbaq, Hanane and Retbi, Asmaa and Idrissi, Mohammed Khalidi and Bennani, Samir},
title = {Software Product Line to overcome the variability issue in E-Learning: Systematic literature review},
year = {2018},
isbn = {9781450364621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289402.3289504},
doi = {10.1145/3289402.3289504},
abstract = {The disparity of educational technologies, pedagogies and learning styles implies a problem of variability when modeling E-learning systems. Furthermore, the current learning context, which has become very open and heterogeneous, raises the problem of automating the modeling, development and maintenance of personalized E-learning systems based on various pedagogies. For its part, the "Software Product Line" is a paradigm that aims to produce product families based on the principles of reuse, configuration and derivation. The main purpose of this literature review is to explore the different potential applications of "SPL" in the E-learning domain to figure out the problem of variability. We will adopt a protocol for a systematic review of literature, after which we will draw up an analysis report.},
booktitle = {Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications},
articleno = {4},
numpages = {8},
keywords = {variety, systematic literature review, scale, heterogeneity, Variability, Software Product line, E-learning},
location = {Rabat, Morocco},
series = {SITA'18}
}

@inproceedings{10.1145/2791060.2791081,
author = {Trask, Bruce and Roman, Angel},
title = {Leveraging model driven engineering in software product line architectures},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791081},
doi = {10.1145/2791060.2791081},
abstract = {The process of Developing Software Product Line Architectures can be a complex task. However, the use of Model Driven Engineering (MDE) techniques can facilitate the development of SPLAs by introducing Domain Specific Languages, Graphical Editors, and Generators. Together these are considered the sacred triad of MDE. Key to understanding MDE and how it fits into SPLAs is to know exactly what each part of the trinity means, how it relates to the other parts, and what the various implementations are for each.This tutorial has its foundations in years of industrial experience with large and complex SPLAs in various industries. This tutorial continues to be updated each year to include recent and critical innovations in MDE and SPL. This year will include information on key Model Transformation, Constraints and Textual Modeling Languages targeted at Software Product Lines. Additionally, it will cover advances in Software Product Line migration technologies which include techniques as to how to effectively migrate legacy systems toward and MDE/SPLA architecture and implementation. This year's tutorial includes extensive industrial experience on the testing of large and complex SPLAs.The goal of this tutorial is to educate attendees on what MDE technologies are, how exactly they relate synergistically to Software Product Line Architectures, and how to actually apply them using an existing Eclipse implementation.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {392},
numpages = {1},
keywords = {transformation, traceability, textual, requirements engineering, refinement, programming languages, modeling, meta model, language workbench, graphical, domain specific testing, domain specific, constraint, abstraction, MDE, DSL},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2364412.2364451,
author = {Machado, Ivan do Carmo},
title = {Towards a reasoning framework for software product line testing},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364451},
doi = {10.1145/2364412.2364451},
abstract = {Testing can still be considered a bottleneck for software product line engineering. The variability implemented in the source artifacts increases its complexity. Due to its key role for product line quality, testing requires cost-effective practices, such as techniques for test selection should be produced to enable companies to experience the substantial production cost savings. In this paper, we present the outline of a Ph.D. research aimed at developing a reasoning framework to improve SPL testing practices. Based on multiple sources of evidence, the framework intends to provide testers with an automated reasoner for determining which techniques may be suitable for a given variability implementation mechanism, and how these should be employed in order to makes testing in a SPL a more effective and efficient practice. We plan to perform empirical evaluations in order to assess the proposal effectiveness.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {229–232},
numpages = {4},
keywords = {variability management, software testing, software product lines, fault models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2648511.2648558,
author = {Trask, Bruce and Roman, Angel},
title = {Leveraging model driven engineering in software product line architectures},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648558},
doi = {10.1145/2648511.2648558},
abstract = {The process of Developing Software Product Line Architectures can be a complex task. However, the use of Model Driven Engineering (MDE) techniques can facilitate the development of SPLAs by introducing Domain Specific Languages, Graphical Editors, and Generators. Together these are considered the sacred triad of MDE. Key to understanding MDE and how it fits into SPLAs is to know exactly what each part of the trinity means, how it relates to the other parts, and what the various implementations are for each. This tutorial will demonstrate the use of the Eclipse Modeling Framework (EMF) and Eclipse's Graphical Modeling Framework (GMF) to create an actual MDE solution as applied to a sample SPLA. These tools collectively form what is called a Language Workbench. During this tutorial we will also illustrate how to model the visual artifacts of our Domain Model and generate a Domain Specific Graphical Editor using GMF.This tutorial has its foundations in years of industrial experience with large and complex SPLAs in various industries. This tutorial continues to be updated each year to include recent and critical innovations in MDE and SPL. This year will include information on key Model Transformation, Constraints and Textual Modeling Languages targeted at Software Product Lines. Additionally, it will cover advances in Software Product Line migration technologies which include techniques as to how to effectively migrate legacy systems toward and MDE/SPLA architecture and implementation. This year's tutorial includes extensive industrial experience on the testing of large and complex SPLAs.The goal of this tutorial is to educate attendees on what MDE technologies are, how exactly they relate synergistically to Software Product Line Architectures, and how to actually apply them using an existing Eclipse implementation.The benefits of the technology are so far reaching that we feel the intended audience spans technical managers, developers and CTOs. In general the target audience includes researchers and practitioners who are working on problems related to the design and implementation of SPLAs and would like to understand the benefits of applying MDE techniques towards SPLAs and leverage Eclipse as a framework to develop MDE solutions. The first half will be less technical than the second half where we cover the details of SPLA and MDE in action in complete detail showing patterns and code.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {360–361},
numpages = {2},
keywords = {transformation, traceability, textual, requirements engineering, refinement, programming languages, modeling, meta model, language workbench, graphical, domain specific testing, domain specific, constraint, abstraction, MDE, DSL},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3289402.3289508,
author = {Meftah, Chaimae and Retbi, Asma\^{a} and Bennani, Samir and Idrissi, Mohammed Khalidi},
title = {Exploration of Software Product Line to Enrich the Modeling of Mobile Serious Games},
year = {2018},
isbn = {9781450364621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289402.3289508},
doi = {10.1145/3289402.3289508},
abstract = {The marked interest of educational environments for the use of Serious Games (SG) promotes learning. The connected generation nowadays is influenced by the new practices of their use. Hence the integration of mobility that facilitates access to games. A learner focuses on training through the accessibility at all times, the quality of content, and the particularity and difference of the scenarios. The valorization of the use of Mobile Serious Games (MSG) requires the adoption of an approach. We have started our study by detecting the characteristics influencing the attachment of a learner, thereafter, we have studied the advantages of mobility in our connected society, then, we have explored the Software Product Line (SPL) modeling approach that presents the most appropriate solution to solve our problematic. Finally, we have treated the notion of variability. This concept allows the detection of common and variable points between the products of the set. This will then facilitate the modeling of serious games.},
booktitle = {Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications},
articleno = {8},
numpages = {5},
keywords = {variability, scenario, modeling, mobility, connected generation, Software Product Line, Mobile Serious Games, Learning},
location = {Rabat, Morocco},
series = {SITA'18}
}

@article{10.1007/s11704-016-6048-7,
author = {He, Fei and Gao, Yuan and Yin, Liangze},
title = {Efficient software product-line model checking using induction and a SAT solver},
year = {2018},
issue_date = {April     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {2},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-016-6048-7},
doi = {10.1007/s11704-016-6048-7},
abstract = {Software product line (SPL) engineering is increasingly being adopted in safety-critical systems. It is highly desirable to rigorously show that these systems are designed correctly. However, formal analysis for SPLs is more difficult than for single systems because an SPL may contain a large number of individual systems. In this paper, we propose an efficient model-checking technique for SPLs using induction and a SAT (Boolean satisfiability problem) solver. We show how an induction-based verification method can be adapted to the SPLs, with the help of a SAT solver. To combat the state space explosion problem, a novel technique that exploits the distinguishing characteristics of SPLs, called feature cube enlargement, is proposed to reduce the verification efforts. The incremental SAT mechanism is applied to further improve the efficiency. The correctness of our technique is proved. Experimental results show dramatic improvement of our technique over the existing binary decision diagram (BDD)-based techniques.},
journal = {Front. Comput. Sci.},
month = apr,
pages = {264–279},
numpages = {16},
keywords = {software product line, satisfiability, model checking}
}

@inproceedings{10.1145/2491627.2491649,
author = {Lanman, Jeremy and Darbin, Rowland and Rivera, Jorge and Clements, Paul and Krueger, Charles},
title = {The challenges of applying service orientation to the U.S. Army's live training software product line},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491649},
doi = {10.1145/2491627.2491649},
abstract = {Live Training Transformation (LT2) is the product line strategy put in place by the United States Army Program Executive Office for Simulation, Training and Instrumentation (PEO STRI). The purpose of the LT2 product line is to provide a common set of core assets including architectures, software components, standards and processes that form the basis of all Army Live Training systems. As products consuming LT2 core assets evolve to meet the latest requirements of the military live training community, changes to the core product line architecture must also be made. Based on thorough analysis of the LT2 core capabilities and user trends toward web-enabled and mobile computing technologies, a Service Oriented Architecture (SOA) strategy was identified and adopted as the objective architecture for the evolving LT2 product line. Future success of the LT2 product line now depends on the alignment of product line engineering concepts with the business and technical benefits of SOA, and to ensure that systematic reuse continues to provide substantial return-on-investment for the Army. This paper addresses the challenges of adopting SOA into an existing software product line, the unique circumstances of the LT2 SOA environment, and present a set of analysis and design considerations for the product line engineering community.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {244–253},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product derivation, product configurator, product baselines, product audit, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {clafer configurator, ClaferWiki, ClaferMOO visualizer, ClaferMOO, ClaferIG, Clafer},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1007/978-3-030-63882-5_12,
author = {Alves, Thayonara and Teixeira, Leopoldo and Alves, Vander and Castro, Thiago},
title = {Porting the Software Product Line Refinement Theory to the Coq Proof&nbsp;Assistant},
year = {2020},
isbn = {978-3-030-63881-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63882-5_12},
doi = {10.1007/978-3-030-63882-5_12},
abstract = {Software product lines are an engineering approach to systematically build similar software products from a common asset base. When evolving such systems, it is important to have assurance that we are not introducing errors or changing the behavior of existing products. The product line refinement theory establishes the necessary conditions for such assurance. This theory has been specified and proved using the PVS proof assistant. However, the Coq proof assistant is increasingly popular among researchers and practitioners, and, given that some programming languages are already formalized into such tool, the refinement theory might benefit from the potential integration. Therefore, in this work we present a case study on porting the PVS specification of the refinement theory to Coq. We compare the proof assistants based on the noted differences between the specifications and proofs of this theory, providing some reflections on the tactics and strategies used to compose the proofs. According to our study, PVS provided more succinct definitions than Coq, in several cases, as well as a greater number of successful automatic commands that resulted in shorter proofs. Despite that, Coq also brought facilities in definitions such as enumerated and recursive types, and features that support developers in their proofs.},
booktitle = {Formal Methods: Foundations and Applications: 23rd Brazilian Symposium, SBMF 2020, Ouro Preto, Brazil, November 25–27, 2020, Proceedings},
pages = {192–209},
numpages = {18},
keywords = {PVS, Coq, Theorem provers, Software product lines},
location = {Ouro Preto, Brazil}
}

@inproceedings{10.1109/APSEC.2010.25,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Quality Attributes Assessment for Feature-Based Product Configuration in Software Product Line},
year = {2010},
isbn = {9780769542669},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2010.25},
doi = {10.1109/APSEC.2010.25},
abstract = {Product configuration based on a feature model in software product lines is the process of selecting the desired features based on customers’ requirements. In most cases, application engineers focus on the functionalities of the target product during product configuration process whereas the quality attributes are handled until the final product is produced. However, it is costly to fix the problem if the quality attributes have not been considered in the product configuration stage. The key issue of assessing a quality attribute of a product configuration is to measure the impact on a quality attribute made by the set of functional variable features selected in a configuration. Current existing approaches have several limitations, such as no quantitative measurements provided or requiring existing valid products and heavy human effort for the assessment. To overcome theses limitations, we propose an Analytic Hierarchical Process (AHP) based approach to estimate the relative importance of each functional variable feature on a quality attribute. Based on the relative importance value of each functional variable feature on a quality attribute, the level of quality attributes of a product configuration in software product lines can be assessed. An illustrative example based on the Computer Aided Dispatch (CAD) software product line is presented to demonstrate how the proposed approach works.},
booktitle = {Proceedings of the 2010 Asia Pacific Software Engineering Conference},
pages = {137–146},
numpages = {10},
keywords = {quality attributes assessment, product configuration, Analytic Hierarchical Process (AHP)},
series = {APSEC '10}
}

@inproceedings{10.1145/2648511.2648537,
author = {Colanzi, Thelma Elita and Vergilio, Silvia Regina and Gimenes, Itana M. S. and Oizumi, Willian Nalepa},
title = {A search-based approach for software product line design},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648537},
doi = {10.1145/2648511.2648537},
abstract = {The Product Line Architecture (PLA) can be improved by taking into account key factors such as feature modularization, and by continuously evaluating its design according to metrics. Search-Based Software Engineering (SBSE) principles can be used to support an informed-design of PLAs. However, existing search-based design works address only traditional software design not considering intrinsic Software Product Line aspects. This paper presents MOA4PLA, a search-based approach to support the PLA design. It gives a multi-objective treatment to the design problem based on specific PLA metrics. A metamodel to represent the PLA and a novel search operator to improve feature modularization are proposed. Results point out that the application of MOA4PLA leads to PLA designs with well modularized features, contributing to improve features reusability and extensibility. It raises a set of solutions with different design trade-offs that can be used to improve the PLA design.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {237–241},
numpages = {5},
keywords = {software product lines, searchbased PLA design, multi-objective algorithms},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1016/j.cl.2016.07.007,
author = {Karimpour, Reza and Ruhe, Guenther},
title = {Evolutionary robust optimization for software product line scoping},
year = {2017},
issue_date = {January 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {47},
number = {P2},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2016.07.007},
doi = {10.1016/j.cl.2016.07.007},
abstract = {Background: Software product line (SPL) scoping is an important phase when planning for product line adoption. An SPL scope specifies: (1) the extent of the domain supported by the product line, (2) portfolio of products in the product line and (3) list of assets to be developed for reuse across the family of products.Issue: SPL scope planning is usually based on estimates about the state of the market and the engineering capabilities of the development team. One challenge with these estimates is that there are inaccuracies due to uncertainty in the environment or accuracy of measurement. This may result in issues ranging from suboptimal plans to infeasible plans.Objective: To address the above, we propose to include uncertainty as part of the SPL scoping model. Plans developed in consideration of uncertainty would be more robust against possible fluctuations in estimates.Approach: In this paper, a method to incorporate uncertainty in scoping optimization and its application to generate robust solutions is proposed. We capture uncertainty as part of the formulation and model scoping optimization as a multi-objective problem with profit and stability as fitness functions. Profit stability and feasibility stability are considered to represent stability concerns.Results: Results show that, compared to other scope optimization approaches, both performance stability and feasibility stability are improved while maintaining near optimal performance for profit objective. Also, generated results consist of solutions with trade-offs between profit and stability, providing the decision maker with enhanced decision support.Conclusion: Multi-objective optimization with stability consideration for SPL scoping provides project managers with a robust and flexible way to address uncertainty in the process of SPL scoping. HighlightsA robust multi-objective optimization approach for SPL scoping is proposed.Two types of stability are considered: performance stability and feasibility stability.Approach was able to find plans with higher stability.},
journal = {Comput. Lang. Syst. Struct.},
month = jan,
pages = {189–210},
numpages = {22},
keywords = {Software product line scoping, Search-based software engineering, Robust optimization, Evolutionary optimization}
}

@article{10.1145/1183236.1183266,
author = {Lee, Jaejoon and Muthig, Dirk},
title = {Feature-oriented variability management in product line engineering},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183266},
doi = {10.1145/1183236.1183266},
abstract = {Implementing feature-oriented variability modeling throughout the life cycle.},
journal = {Commun. ACM},
month = dec,
pages = {55–59},
numpages = {5}
}

@inproceedings{10.1145/3168365.3168373,
author = {Pereira, Juliana Alves and Schulze, Sandro and Krieter, Sebastian and Ribeiro, M\'{a}rcio and Saake, Gunter},
title = {A Context-Aware Recommender System for Extended Software Product Line Configurations},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168373},
doi = {10.1145/3168365.3168373},
abstract = {Mass customization of standardized products has become a trend to succeed in today's market environment. Software Product Lines (SPLs) address this trend by describing a family of software products that share a common set of features. However, choosing the appropriate set of features that matches a user's individual interests is hampered due to the overwhelming amount of possible SPL configurations. Recommender systems can address this challenge by filtering the number of configurations and suggesting a suitable set of features for the user's requirements. In this paper, we propose a context-aware recommender system for predicting feature selections in an extended SPL configuration scenario, i.e. taking nonfunctional properties of features into consideration. We present an empirical evaluation based on a large real-world dataset of configurations derived from industrial experience in the Enterprise Resource Planning domain. Our results indicate significant improvements in the predictive accuracy of our context-aware recommendation approach over a state-of-the-art binary-based approach.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {97–104},
numpages = {8},
keywords = {Software Product Lines, Recommender Systems, Non-Functional Properties, Feature Model, Configuration},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/2019136.2019172,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Using knowledge-based systems to manage quality attributes in software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019172},
doi = {10.1145/2019136.2019172},
abstract = {Product configuration in a feature model in software product line engineering is a process, in which the desired features are selected based on the customers' functional requirements and non-functional requirements. The functional requirements of the target product can be satisfied by including the proper functional features. However, there is no such a straightforward way to realize the non-functional requirements and quality attributes of the target product. In our early work, we have developed a quantitative based method to assess the quality attributes for a configured product. However, this approach cannot adequately represent the inter-relationships among quality attributes which play an important role in product configuration process. We supplement our previous work by introducing a quality attribute knowledge base (QA_KB) to represent the inter-relationships among different quality attributes in a SPL. Furthermore, we develop algorithms for configuring a product based on customers' quality requirements. We also use a case study to illustrate our approach.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {32},
numpages = {7},
keywords = {software product line, quality attributes, product configuration, non-functional requirements, feature model},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1016/j.chb.2017.04.026,
author = {Gharsellaoui, Hamza and Maazoun, Jihen and Bouassida, Nadia and Ahmed, Samir Ben and Ben-Abdallah, Hanene},
title = {A Software Product Line Design Based Approach for Real-time Scheduling of Reconfigurable Embedded Systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {115},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2017.04.026},
doi = {10.1016/j.chb.2017.04.026},
journal = {Comput. Hum. Behav.},
month = feb,
numpages = {11},
keywords = {UML marte, SPL design, Reconfigurable embedded systems, Real-time scheduling}
}

@article{10.1016/j.knosys.2019.104883,
author = {Ayala, Inmaculada and Amor, Mercedes and Horcas, Jose-Miguel and Fuentes, Lidia},
title = {A goal-driven software product line approach for evolving multi-agent systems in the Internet of Things},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {184},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.104883},
doi = {10.1016/j.knosys.2019.104883},
journal = {Know.-Based Syst.},
month = nov,
numpages = {18},
keywords = {GORE, Goal models, MAS-PL, Internet of Things, Evolution, Software product line}
}

@inproceedings{10.1145/2614628.2614630,
author = {Eichberg, Michael and Hermann, Ben},
title = {A software product line for static analyses: the OPAL framework},
year = {2014},
isbn = {9781450329194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2614628.2614630},
doi = {10.1145/2614628.2614630},
abstract = {Implementations of static analyses are usually tailored toward a single goal to be efficient, hampering reusability and adaptability of the components of an analysis. To solve these issues, we propose to implement static analyses as highly-configurable software product lines (SPLs). Furthermore, we also discuss an implementation of an SPL for static analyses -- called OPAL -- that uses advanced language features offered by the Scala programming language to get an easily adaptable and (type-)safe software product line.OPAL is a general purpose library for static analysis of Java Bytecode that is already successfully used. We present OPAL and show how a design based on software produce line engineering benefits the implementation of static analyses with the framework.},
booktitle = {Proceedings of the 3rd ACM SIGPLAN International Workshop on the State of the Art in Java Program Analysis},
pages = {1–6},
numpages = {6},
keywords = {static analysis, software product line engineering, program analysis, design, abstract interpretation},
location = {Edinburgh, United Kingdom},
series = {SOAP '14}
}

@article{10.1007/s10270-017-0614-9,
author = {Guizzo, Giovani and Colanzi, Thelma Elita and Vergilio, Silvia Regina},
title = {Applying design patterns in the search-based optimization of software product line architectures},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {2},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0614-9},
doi = {10.1007/s10270-017-0614-9},
abstract = {The design of the product line architecture (PLA) is a difficult activity that can benefit from the application of design patterns and from the use of a search-based optimization approach, which is generally guided by different objectives related, for instance, to cohesion, coupling and PLA extensibility. The use of design patterns for PLAs is a recent research field, not completely explored yet. Some works apply the patterns manually and for a specific domain. Approaches to search-based PLA design do not consider the usage of these patterns. To allow such use, this paper introduces a mutation operator named “Pattern-Driven Mutation Operator” that includes methods to automatically identify suitable scopes and apply the patterns Strategy, Bridge and Mediator with the search-based approach multi-objective optimization approach for PLA. A metamodel is proposed to represent and identify suitable scopes to receive each one of the patterns, avoiding the introduction of architectural anomalies. Empirical results are also presented, showing evidences that the use of the proposed operator produces a greater diversity of solutions and improves the quality of the PLAs obtained in the search-based optimization process, regarding the values of software metrics.},
journal = {Softw. Syst. Model.},
month = apr,
pages = {1487–1512},
numpages = {26},
keywords = {Software product line architecture, Search-based software engineering, Design pattern}
}

@inproceedings{10.1145/2648511.2648515,
author = {Wang, Shuai and Buchmann, David and Ali, Shaukat and Gotlieb, Arnaud and Pradhan, Dipesh and Liaaen, Marius},
title = {Multi-objective test prioritization in software product line testing: an industrial case study},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648515},
doi = {10.1145/2648511.2648515},
abstract = {Test prioritization is crucial for testing products in a product line considering limited budget in terms of available time and resources. In general, it is not practically feasible to execute all the possible test cases and so, ordering test case execution permits test engineers to discover faults earlier in the testing process. An efficient prioritization of test cases for one or more products requires a clear consideration of the tradeoff among various costs (e.g., time, required resources) and effectiveness (e.g., feature coverage) objectives. As an integral part of the future Cisco's test scheduling system for validating video conferencing products, we introduce a search-based multi-objective test prioritization technique, considering multiple cost and effectiveness measures. In particular, our multi-objective optimization setup includes the minimization of execution cost (e.g., time), and the maximization of number of prioritized test cases, feature pairwise coverage and fault detection capability. Based on cost-effectiveness measures, a novel fitness function is defined for such test prioritization problem. The fitness function is empirically evaluated together with three commonly used search algorithms (e.g., (1+1) Evolutionary algorithm (EA)) and Random Search as a comparison baseline based on the Cisco's industrial case study and 500 artificial designed problems. The results show that (1+1) EA achieves the best performance for solving the test prioritization problem and it scales up to solve the problems of varying complexity.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {32–41},
numpages = {10},
keywords = {test prioritization, software product lines, search algorithms, multi-objective optimization},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2993236.2993251,
author = {Steindorfer, Michael J. and Vinju, Jurgen J.},
title = {Towards a software product line of trie-based collections},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993251},
doi = {10.1145/2993236.2993251},
abstract = {Collection data structures in standard libraries of programming languages are designed to excel for the average case by carefully balancing memory footprint and runtime performance. These implicit design decisions and hard-coded trade-offs do constrain users from using an optimal variant for a given problem. Although a wide range of specialized collections is available for the Java Virtual Machine (JVM), they introduce yet another dependency and complicate user adoption by requiring specific Application Program Interfaces (APIs) incompatible with the standard library.  A product line for collection data structures would relieve library designers from optimizing for the general case. Furthermore, a product line allows evolving the potentially large code base of a collection family efficiently. The challenge is to find a small core framework for collection data structures which covers all variations without exhaustively listing them, while supporting good performance at the same time.  We claim that the concept of Array Mapped Tries (AMTs) embodies a high degree of commonality in the sub-domain of immutable collection data structures. AMTs are flexible enough to cover most of the variability, while minimizing code bloat in the generator and the generated code. We implemented a Data Structure Code Generator (DSCG) that emits immutable collections based on an AMT skeleton foundation. The generated data structures outperform competitive hand-optimized implementations, and the generator still allows for customization towards specific workloads.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {168–172},
numpages = {5},
keywords = {Software product line, Persistent data structure, Performance, Immutability, Hash trie, Code generation},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@inproceedings{10.1145/3266237.3266275,
author = {Filho, Helson Luiz Jakubovski and Ferreira, Thiago Nascimento and Vergilio, Silvia Regina},
title = {Multiple objective test set selection for software product line testing: evaluating different preference-based algorithms},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266275},
doi = {10.1145/3266237.3266275},
abstract = {The selection of optimal test sets for Software Product Lines (SPLs) is a complex task impacted by many factors and that needs to consider the tester's preferences. To help in this task, Preference-based Evolutionary Multi-objective Algorithms (PEMOAs) have been explored. They use a Reference Point (RP), which represents the user preference and guides the search, resulting in a greater number of solutions in the ROI (Region of Interest). This region contains solutions that are more interesting from the tester's point of view. However, the explored PEMOAs have not been compared yet and the results reported in the literature do not consider many-objective formulations. Such an evaluation is important because in the presence of more than three objectives the performance of the algorithms may change and the number of solutions increases. Considering this fact, this work presents evaluation results of four PEMOAs for selection of products in the SPL testing considering cost, testing criteria coverage, products similarity, and the number of revealed faults, given by the mutation score. The PEMOAs present better performance than traditional algorithms, avoiding uninteresting solutions. We introduce a hyper-heuristic version of the PEMOA R-NSGA-II that presents the best results in a general case.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {162–171},
numpages = {10},
keywords = {software product line testing, search-based software engineering, preference-based multi-objective algorithms},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@article{10.1016/j.jbi.2015.05.014,
author = {Costa, Gabriella Castro B. and Braga, Regina and David, Jos\'{e} Maria N. and Campos, Fernanda},
title = {A Scientific Software Product Line for the Bioinformatics domain},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {56},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2015.05.014},
doi = {10.1016/j.jbi.2015.05.014},
abstract = {Display Omitted An architecture to support a SPL for scientific applications.An approach where the semantics is highlighted.Use of ontologies in conjunction with feature models.The implementation of an SSPL.Case studies in the bioinformatics area (sequencing/genetic alignment). ContextMost specialized users (scientists) that use bioinformatics applications do not have suitable training on software development. Software Product Line (SPL) employs the concept of reuse considering that it is defined as a set of systems that are developed from a common set of base artifacts. In some contexts, such as in bioinformatics applications, it is advantageous to develop a collection of related software products, using SPL approach. If software products are similar enough, there is the possibility of predicting their commonalities, differences and then reuse these common features to support the development of new applications in the bioinformatics area. ObjectivesThis paper presents the PL-Science approach which considers the context of SPL and ontology in order to assist scientists to define a scientific experiment, and to specify a workflow that encompasses bioinformatics applications of a given experiment. This paper also focuses on the use of ontologies to enable the use of Software Product Line in biological domains. MethodIn the context of this paper, Scientific Software Product Line (SSPL) differs from the Software Product Line due to the fact that SSPL uses an abstract scientific workflow model. This workflow is defined according to a scientific domain and using this abstract workflow model the products (scientific applications/algorithms) are instantiated. ResultsThrough the use of ontology as a knowledge representation model, we can provide domain restrictions as well as add semantic aspects in order to facilitate the selection and organization of bioinformatics workflows in a Scientific Software Product Line. The use of ontologies enables not only the expression of formal restrictions but also the inferences on these restrictions, considering that a scientific domain needs a formal specification. ConclusionsThis paper presents the development of the PL-Science approach, encompassing a methodology and an infrastructure, and also presents an approach evaluation. This evaluation presents case studies in bioinformatics, which were conducted in two renowned research institutions in Brazil.},
journal = {J. of Biomedical Informatics},
month = aug,
pages = {239–264},
numpages = {26},
keywords = {Software Product Line, Sequence alignment, Scientific workflow, Ontology, Feature model}
}

@inproceedings{10.1145/2019136.2019182,
author = {McGregor, John D. and Monteith, J. Yates and Zhang, Jie},
title = {Quantifying value in software product line design},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019182},
doi = {10.1145/2019136.2019182},
abstract = {A software product line is a strategic investment for an organization. Besides the initial decision to use a product line approach other strategic decisions are made, including which variations to accommodate. In this paper we present an adaptation of an equation for computing option values. The equation can be used to understand the economic impact of adding a variation point to the product line architecture. The equation was exercised on multiple sets of hypothetical data and and produced the expected changes from one data set to another. In the future the equation will be validated with data from real projects. We describe some practical sources of values for the parameters of the equation.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {40},
numpages = {7},
keywords = {strategic software design, software engineering},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1007/s10664-014-9358-0,
author = {Koziolek, Heiko and Goldschmidt, Thomas and Gooijer, Thijmen and Domis, Dominik and Sehestedt, Stephan and Gamer, Thomas and Aleksy, Markus},
title = {Assessing software product line potential: an exploratory industrial case study},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9358-0},
doi = {10.1007/s10664-014-9358-0},
abstract = {Corporate organizations sometimes offer similar software products in certain domains due to former company mergers or due to the complexity of the organization. The functional overlap of such products is an opportunity for future systematic reuse to reduce software development and maintenance costs. Therefore, we have tailored existing domain analysis methods to our organization to identify commonalities and variabilities among such products and to assess the potential for software product line (SPL) approaches. As an exploratory case study, we report on our experiences and lessons learned from conducting the domain analysis in four application cases with large-scale software products. We learned that the outcome of a domain analysis was often a smaller integration scenario instead of an SPL and that business case calculations were less relevant for the stakeholders and managers from the business units during this phase. We also learned that architecture reconstruction using a simple block diagram notation aids domain analysis and that large parts of our approach were reusable across application cases.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {411–448},
numpages = {38},
keywords = {Software product lines, Domain analysis, Business case}
}

@inproceedings{10.1145/2892664.2892686,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Towards the dynamic reconfiguration of quality attributes},
year = {2016},
isbn = {9781450340335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2892664.2892686},
doi = {10.1145/2892664.2892686},
abstract = {There are some Quality Attributes (QAs) whose variability is addressed through functional variability in the software architecture. Separately modelling the variability of these QAs from the variability of the base functionality of the application has many advantages (e.g., a better reusability), and facilitates the reconfiguration of the QA variants at runtime. Many factors may vary the QA functionality: variations in the user preferences and usage needs; variations in the non-functional QAs; variations in resources, hardware, or even in the functionality of the base application, that directly affect the product's QAs. In this paper, we aim to elicit the relationships and dependencies between the functionalities required to satisfy the QAs and all those factors that can provoke a reconfiguration of the software architecture at runtime. We follow an approach in which the variability of the QAs is modelled separately from the base application functionality, and propose a dynamic approach to reconfigure the software architecture based on those reconfiguration criteria.},
booktitle = {Companion Proceedings of the 15th International Conference on Modularity},
pages = {131–136},
numpages = {6},
keywords = {variability, software architecture, reconfiguration, SPL, Quality attributes},
location = {M\'{a}laga, Spain},
series = {MODULARITY Companion 2016}
}

@inproceedings{10.1145/3167132.3167353,
author = {Pereira, Juliana Alves and Martinez, Jabier and Gurudu, Hari Kumar and Krieter, Sebastian and Saake, Gunter},
title = {Visual guidance for product line configuration using recommendations and non-functional properties},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167353},
doi = {10.1145/3167132.3167353},
abstract = {Software Product Lines (SPLs) are a mature approach for the derivation of a family of products using systematic reuse. Different combinations of predefined features enable tailoring the product to fit the needs of each customer. These needs are related to functional properties of the system (optional features) as well as non-functional properties (e.g., performance or cost of the final product). In industrial scenarios, the configuration process of a final product is complex and the tool support is usually limited to check functional properties interdependencies. In addition, the importance of nonfunctional properties as relevant drivers during configuration has been overlooked. Thus, there is a lack of holistic paradigms integrating recommendation systems and visualizations that can help the decision makers. In this paper, we propose and evaluate an interrelated set of visualizations for the configuration process filling these gaps. We integrate them as part of the FeatureIDE tool and we evaluate its effectiveness, scalability, and performance.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {2058–2065},
numpages = {8},
keywords = {visualization, software product lines, recommendation systems, feature model, configuration},
location = {Pau, France},
series = {SAC '18}
}

@article{10.1007/s10009-012-0242-1,
author = {Heymans, Patrick and Boucher, Quentin and Classen, Andreas and Bourdoux, Arnaud and Demonceau, Laurent},
title = {A code tagging approach to software product line development},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0242-1},
doi = {10.1007/s10009-012-0242-1},
abstract = {Software product line engineering seeks to systematise reuse when developing families of similar software systems so as to minimise development time, cost and defects. To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations. These concerns were the motivation for the industry---university collaboration described in this paper in which we developed a minimally intrusive coding technique based on tags. The approach was complemented with traceability from code to feature diagrams which were exploited for automated configuration. It is supported by a toolchain and is now in use in the partner company for the development of flight-grade satellite communication software libraries.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {553–566},
numpages = {14},
keywords = {Software product line engineering, Feature diagrams, Code tagging, Automation}
}

@inproceedings{10.5220/0005370300710081,
author = {Tang, Yutian and Leung, Hareton},
title = {Top-down Feature Mining Framework for Software Product Line},
year = {2015},
isbn = {9789897580970},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005370300710081},
doi = {10.5220/0005370300710081},
abstract = {Software product line engineering is regarded as a promising approach to generate tailored software productsby referencing shared software artefacts. However, converting software legacy into a product line is extremelydifficult, given the complexity, risk of the task and insufficient tool support. To cope with this, in this paper,we proposed a top-down feature-mining framework to facilitate developers extracting code fragments forfeatures concerned. Our work aims to fulfill the following targets: (1) identify features at a fine granularity,(2) locate code fragments for concerned feature hierarchically and consistently, and (3) combine programanalysis techniques and feature location strategies to improve mining performance. From our preliminary casestudies, the top-down framework can effectively locate features and performs as good as Christians approachand performs better than the topology feature location approach.},
booktitle = {Proceedings of the 17th International Conference on Enterprise Information Systems - Volume 2},
pages = {71–81},
numpages = {11},
keywords = {Variability, Top-down Framework, Software Product Line., Feature Mining, Concept Location},
location = {Barcelona, Spain},
series = {ICEIS 2015}
}

@inproceedings{10.5555/645882.758304,
author = {Brown, T. John and Spence, Ivor and Kilpatrick, Peter and Crookes, Danny},
title = {Adaptable Components for Software Product Line Engineering},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper explores techniques for implementing adaptable software components. Such techniques can greatly facilitate the implementation of software product lines. The techniques we present allow the construction of large transparently adaptable components via composition and parameterization. Functional and structural adaptation, to any level of nesting, is achieved at the point of instantiation via recursive argument lists whose structure mirrors that of the component. The techniques are currently based on the C++ language, although work is under way to extend them to other languages (particularly Java  ).},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {154–175},
numpages = {22},
series = {SPLC 2}
}

@article{10.4018/IJWSR.2019010103,
author = {Sun, Chang-ai and Wang, Zhen and Wang, Ke and Xue, Tieheng and Aiello, Marco},
title = {Adaptive BPEL Service Compositions via Variability Management: A Methodology and Supporting Platform},
year = {2019},
issue_date = {January 2019},
publisher = {IGI Global},
address = {USA},
volume = {16},
number = {1},
issn = {1545-7362},
url = {https://doi.org/10.4018/IJWSR.2019010103},
doi = {10.4018/IJWSR.2019010103},
abstract = {Service-Oriented Architectures are a popular development paradigm to enable distributed applications constructed from independent web services. When coordinated, web services are an infrastructure to fulfill dynamic and vertical integration of business. They may face frequent changes of both requirements and execution environments. Static and predefined service compositions using business process execution language BPEL are not able to cater for such rapid and unpredictable context shifts. The authors propose a variability management-based adaptive and configurable service composition approach that treats changes as first-class citizens and consists of identifying, expressing, realizing, and managing changes of service compositions. The proposed approach is realized with a language called VxBPEL to support variability in service compositions and a platform for design, execution, analysis, and maintenance of VxBPEL-based service compositions. Four case studies validate the feasibility of the proposed approach while exhibiting good performance of the supporting platform.},
journal = {Int. J. Web Serv. Res.},
month = jan,
pages = {37–69},
numpages = {33},
keywords = {Variability Management, Service Oriented Architectures, Service Composition, Business Process Execution Language, Adaptive Systems}
}

@inproceedings{10.1109/SPLC.2011.20,
author = {Siegmund, Norbert and Rosenmuller, Marko and Kastner, Christian and Giarrusso, Paolo G. and Apel, Sven and Kolesnikov, Sergiy S.},
title = {Scalable Prediction of Non-functional Properties in Software Product Lines},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.20},
doi = {10.1109/SPLC.2011.20},
abstract = {A software product line is a family of related software products, typically, generated from a set of common assets. Users can select features to derive a product that fulfills their needs. Often, users expect a product to have specific non-functional properties, such as a small footprint or a minimum response time. Because a product line can contain millions of products, it is usually not feasible to generate and measure non-functional properties for each possible product of a product line. Hence, we propose an approach to predict a product's non-functional properties, based on the product's feature selection. To this end, we generate and measure a small set of products, and by comparing the measurements, we approximate each feature's non-functional properties. By aggregating the approximations of selected features, we predict the product's properties. Our technique is independent of the implementation approach and language. We show how already little domain knowledge can improve predictions and discuss trade-offs regarding accuracy and the required number of measurements. Although our approach is in general applicable for quantifiable non-functional properties, we evaluate it for the non-functional property footprint. With nine case studies, we demonstrate that our approach usually predicts the footprint with an accuracy of 98% and an accuracy of over 99% if feature interactions are known.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {160–169},
numpages = {10},
keywords = {software product lines, predicition, non-functional properties, measurement, SPL Conqueror},
series = {SPLC '11}
}

@inproceedings{10.1145/2648511.2648534,
author = {Dieumegard, Arnaud and Toom, Andres and Pantel, Marc},
title = {A software product line approach for semantic specification of block libraries in dataflow languages},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648534},
doi = {10.1145/2648511.2648534},
abstract = {Dataflow modelling languages such as SCADE or Simulink are the de-facto standard for the Model Driven Development of safety critical embedded control and command systems. Software is mainly being produced by Automated Code Generators whose correctness can only be assessed meaningfully if the input language semantics is well known. These semantics share a common part but are mainly defined through block libraries. The writing of a complete formal specification for the block libraries of the usual languages is highly challenging due to the high variability of the structure and semantics of each block. This contribution relates the use of software product line principles in the design of a domain specific language targeting the formal specification of block libraries. It summarises the advantages of this DSL regarding the writing, validation and formal verification of such specifications. These experiments have been carried out in the context of the GeneAuto embedded code generator project targeting Simulink and Scicos; and are being extended and applied in its follow up projects ProjetP and Hi-MoCo.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {217–226},
numpages = {10},
keywords = {software qualification, simulink, scicos, model driven engineering, formal specification, feature modelling, automated code generation, Xcos, Why3},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1016/j.infsof.2012.07.020,
author = {Siegmund, Norbert and Rosenm\"{u}Ller, Marko and K\"{a}Stner, Christian and Giarrusso, Paolo G. and Apel, Sven and Kolesnikov, Sergiy S.},
title = {Scalable prediction of non-functional properties in software product lines: Footprint and memory consumption},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.020},
doi = {10.1016/j.infsof.2012.07.020},
abstract = {Context: A software product line is a family of related software products, typically created from a set of common assets. Users select features to derive a product that fulfills their needs. Users often expect a product to have specific non-functional properties, such as a small footprint or a bounded response time. Because a product line may have an exponential number of products with respect to its features, it is usually not feasible to generate and measure non-functional properties for each possible product. Objective: Our overall goal is to derive optimal products with respect to non-functional requirements by showing customers which features must be selected. Method: We propose an approach to predict a product's non-functional properties based on the product's feature selection. We aggregate the influence of each selected feature on a non-functional property to predict a product's properties. We generate and measure a small set of products and, by comparing measurements, we approximate each feature's influence on the non-functional property in question. As a research method, we conducted controlled experiments and evaluated prediction accuracy for the non-functional properties footprint and main-memory consumption. But, in principle, our approach is applicable for all quantifiable non-functional properties. Results: With nine software product lines, we demonstrate that our approach predicts the footprint with an average accuracy of 94%, and an accuracy of over 99% on average if feature interactions are known. In a further series of experiments, we predicted main memory consumption of six customizable programs and achieved an accuracy of 89% on average. Conclusion: Our experiments suggest that, with only few measurements, it is possible to accurately predict non-functional properties of products of a product line. Furthermore, we show how already little domain knowledge can improve predictions and discuss trade-offs between accuracy and required number of measurements. With this technique, we provide a basis for many reasoning and product-derivation approaches.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {491–507},
numpages = {17},
keywords = {Software product lines, SPL Conqueror, Prediction, Non-functional properties, Measurement}
}

@inproceedings{10.1145/3461002.3473947,
author = {Pinnecke, Marcus},
title = {Product-lining the elinvar wealthtech microservice platform},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473947},
doi = {10.1145/3461002.3473947},
abstract = {Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {60–68},
numpages = {9},
keywords = {variability management, technologies and concepts, product families, microservice platforms, configuration management},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/2499777.2500715,
author = {Ishida, Yuzo},
title = {Scalable variability management for enterprise applications with data model driven development},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500715},
doi = {10.1145/2499777.2500715},
abstract = {Unlike embedded systems, some of enterprise systems are evolved over the decades. The predictability of requirements is a key to success in building reusable assets however it is very hard to predict future business context changes, which are driving factors of requirements. Thus, both functional and context variability must be managed in order to satisfy ever-changing requirements. Scalability does matter for enterprise systems in two aspects. One aspect comes from data volume. Once data become big, it is difficult to maintain performance requirements without de-normalizing database schema. Since database de-normalization is driven by non-functional properties, a model driven approach is not feasible if the model cannot express such properties. Another aspect comes from the unpredictability of future functional requirements. A functional decomposition of enterprise systems usually introduces ever-increasing complexity among systems' interactions due to cross-cutting requirements across functional systems. This paper reflects our empirical studies in data intensive large enterprise systems such as retail and telecommunication industries with industry independent application framework to separate functional and non-functional concerns. Our variability management technique is based on database schema modeling, which can be evolved incrementally in scaling an enterprise system with both data and functional aspects.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {90–93},
numpages = {4},
keywords = {type theory, relational algebra, quality attributes, higher-order simple predicate logic, core assets},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@article{10.1007/s10664-016-9494-9,
author = {Li, Xuelin and Wong, W. Eric and Gao, Ruizhi and Hu, Linghuan and Hosono, Shigeru},
title = {Genetic Algorithm-based Test Generation for Software Product Line with the Integration of Fault Localization Techniques},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9494-9},
doi = {10.1007/s10664-016-9494-9},
abstract = {In response to the highly competitive market and the pressure to cost-effectively release good-quality software, companies have adopted the concept of software product line to reduce development cost. However, testing and debugging of each product, even from the same family, is still done independently. This can be very expensive. To solve this problem, we need to explore how test cases generated for one product can be used for another product. We propose a genetic algorithm-based framework which integrates software fault localization techniques and focuses on reusing test specifications and input values whenever feasible. Case studies using four software product lines and eight fault localization techniques were conducted to demonstrate the effectiveness of our framework. Discussions on factors that may affect the effectiveness of the proposed framework is also presented. Our results indicate that test cases generated in such a way can be easily reused (with appropriate conversion) between different products of the same family and help reduce the overall testing and debugging cost.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {1–51},
numpages = {51},
keywords = {Test generation, Software product line, Genetic algorithm, EXAM score, Debugging/fault localization, Coverage}
}

@inproceedings{10.1145/2364412.2364447,
author = {Vianna, Alexandre and Pinto, Felipe and Sena, Dem\'{o}stenes and Kulesza, Uir\'{a} and Coelho, Roberta and Santos, Jadson and Lima, Jalerson and Lima, Gleydson},
title = {Squid: an extensible infrastructure for analyzing software product line implementations},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364447},
doi = {10.1145/2364412.2364447},
abstract = {Software product line engineering is about producing a set of related products that share more commonalities than variabilities. This approach promotes benefits such as cost reduction, product quality, productivity and time to market, but it brings new challenges that must be considered during the evolution of the software product line. In this context, recent research has explored and proposed automated approaches based on code analysis and traceability techniques for change impact analysis. This paper presents Squid, an extensible infrastructure for analyzing software product line implementations. The approach uses information from variability modeling, variability mapping to code assets, and dependency relationships between code assets to perform analysis of SPL implementations. A Squid instantiation example is presented to illustrate the usage of the tool in practical scenarios.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {209–216},
numpages = {8},
keywords = {software product line evolution, software product line, software analysis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5220/0007955905140521,
author = {Derras, M. and Deruelle, L. and Douin, J.-M. and Levy, N. and Losavio, F. and Mahamane, R. and Reiner, V.},
title = {Approach for Variability Management of Legal Rights in Human Resources Software Product Lines},
year = {2019},
isbn = {9789897583797},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0007955905140521},
doi = {10.5220/0007955905140521},
abstract = {This work concerns software product lines (SPL); it comes from the experience gained collaborating with Berger-Levrault, a French society leader in Human Resources systems. This enterprise serves many French and European territorial communities. They had a variability problem associated to the differences of applicable legal rights in different countries or territories, and this activity was performed manually at a high cost. On the other hand, functionalities were common and mandatory and did not vary much. The crucial issue in SPL development and practice is to manage the correct selection of variants. However, no standard methods have been developed yet, and industry builds SPL using on-the-market or in-house techniques and methods, aware of the benefits a product line can provide; nevertheless, this development must return the investment, and this is not always the case. In this work an approach to variability management in case of legal rights applicability to different entities is proposed. This architecture-centric and quality-based approach uses a reference architecture that has been built with a bottom-up strategy. Variability is incorporated to the reference architecture at abstract level considering non-functional properties. A production plan to reduce the gap between abstraction and implementation levels is defined.},
booktitle = {Proceedings of the 14th International Conference on Software Technologies},
pages = {514–521},
numpages = {8},
keywords = {Variability Management, Software Product Lines (SPL), Legal Rights., Human Resources},
location = {Prague, Czech Republic},
series = {ICSOFT 2019}
}

@article{10.1016/j.asoc.2016.08.024,
author = {dos Santos Neto, Pedro de Alcntara and Britto, Ricardo and Rablo, Ricardo de Andrade Lira and Cruz, Jonathas Jivago de Almeida and Lira, Werney Ayala Luz},
title = {A hybrid approach to suggest software product line portfolios},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.024},
doi = {10.1016/j.asoc.2016.08.024},
abstract = {Graphical abstractDisplay Omitted HighlightsThe work proposes a hybrid approach to deal with the Product Portfolio Scope Problem.The approach is composed by a solution to deploy the feature relevance indicated by the customers into code assets of a SPL, based on a systematic method (SQFD).The approach includes a method to estimate the cost of an asset based on common and relevant measures related to source code, together with a fuzzy system to deal with the imprecision to set reference values.The work presents an application of an NSGA-II to search for products minimizing the cost and maximizing the relevance of the candidate products.The approach was evaluated using different scenarios, exploring the mains aspects related to method in the practice: size, granularity of features and products search space.The previous version of our hybrid approach was dependent on the employed technologies and algorithms. Herein we reformulate our approach, detaching it from any particular technique/algorithm.The data collection process associated with our approach was improved to facilitate the hybrid approach's usage and mitigate associated construct validity threats.A more comprehensive evaluation, which focused on show the real word usefulness and scalability of our hybrid approach. To validate the usefulness of our approach, it was used the SPL associated with a tool broadly employed in both industrial and academic contexts (ArgoUML-SPL). The scalability of our approach was evaluated using a synthetic SPL.All the experiments were based on the guidelines defined by Arcuri and Briand in order to evaluate the statistical significance of this kind of work. Software product line (SPL) development is a new approach to software engineering which aims at the development of a whole range of products. However, as long as SPL can be useful, there are many challenges regarding the use of that approach. One of the main problems which hinders the adoption of software product line (SPL) is the complexity regarding product management. In that context, we can remark the scoping problem. One of the existent ways to deal with scoping is the product portfolio scoping (PPS). PPS aims to define the products that should be developed as well as their key features. In general, that approach is driven by marketing aspects, like cost of the product and customer satisfaction. Defining a product portfolio by using the many different available aspects is a NP-hard problem. This work presents an improved hybrid approach to solve the feature model selection problem, aiming at supporting product portfolio scoping. The proposal is based in a hybrid approach not dependent on any particular algorithm/technology. We have evaluated the usefulness and scalability of our approach using one real SPL (ArgoUML-SPL) and synthetic SPLs. As per the evaluation results, our approach is both useful from a practitioner's perspective and scalable.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1243–1255},
numpages = {13},
keywords = {Software product lines, Search based software engineering, Search based feature model selection, Product portfolio scoping, NSGA-II, Fuzzy inference systems, Feature model selection problem}
}

@inproceedings{10.1145/3461001.3471147,
author = {Kenner, Andy and May, Richard and Kr\"{u}ger, Jacob and Saake, Gunter and Leich, Thomas},
title = {Safety, security, and configurable software systems: a systematic mapping study},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471147},
doi = {10.1145/3461001.3471147},
abstract = {Safety and security are important properties of any software system, particularly in safety-critical domains, such as embedded, automotive, or cyber-physical systems. Moreover, particularly those domains also employ highly-configurable systems to customize variants, for example, to different customer requirements or regulations. Unfortunately, we are missing an overview understanding of what research has been conducted on the intersection of safety and security with configurable systems. To address this gap, we conducted a systematic mapping study based on an automated search, covering ten years (2011--2020) and 65 relevant (out of 367) publications. We classified each publication based on established security and safety concerns (e.g., CIA triad) as well as the connection to configurable systems (e.g., ensuring security of such a system). In the end, we found that considerably more research has been conducted on safety concerns, but both properties seem under-explored in the context of configurable systems. Moreover, existing research focuses on two directions: Ensuring safety and security properties in product-line engineering; and applying product-line techniques to ensure safety and security properties. Our mapping study provides an overview of the current state-of-the-art as well as open issues, helping practitioners identify existing solutions and researchers define directions for future research.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {148–159},
numpages = {12},
keywords = {software product line engineering, security, safety, mapping study, configurable systems},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.5555/1753235.1753250,
author = {Jepsen, Hans Peter and Beuche, Danilo},
title = {Running a software product line: standing still is going backwards},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Danfoss Drives - one of the largest producers of frequency converters in the world - has been doing Software Product Line development for its frequency converter products for about 3 years. This paper describes the approach used and the experiences with it. It discusses processes, ways to convince the unconvinced and arising tool issues when doing product line development.This paper is a follow-up on a previous article which described the product line migration process in detail.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {101–110},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2499777.2500720,
author = {Nakagawa, Elisa Yumi and Oquendo, Flavio},
title = {Perspectives and challenges of reference architectures in multi software product line},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500720},
doi = {10.1145/2499777.2500720},
abstract = {Multi Software Product Line (MSPL or simply Multi Product Line - MPL) has recently emerged as a new approach to develop software systems, mainly those large, complex ones. This approach can be investigated to the development of Systems-of-Systems (SoS), i.e., a new class of software systems that are resulted by the integration of several operationally independent systems. In another perspective, a special type of architecture that contains knowledge about a specific domain has been increasingly investigated, resulting in the research area of Reference Architecture. In this context, the main motivation of this paper is that, in spite of the positive impact of this type of architecture on reuse and productivity, the use of the knowledge contained in existing reference architectures in order to develop MPL, specially to develop SoS, has not been widely explored yet. In this scenario, the main objective of this paper is to present a set of perspectives and challenges of research to use reference architectures in the context of MPL. For this, we have based on our previous experience as well as the literature of SPL, SoS, and reference architecture. As result, we have observed that reference architectures together with MPL seems to be a quite promising research topic. To conclude, we also intend this paper can identify new required research in this context, contributing to improve reuse and productivity in MPL.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {100–103},
numpages = {4},
keywords = {system-of-systems, reference architecture, multi product line},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2851613.2851977,
author = {Kim, Jin Hyun and Legay, Axel and Traonouez, Louis-Marie and Acher, Mathieu and Kang, Sungwon},
title = {A formal modeling and analysis framework for software product line of preemptive real-time systems},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851977},
doi = {10.1145/2851613.2851977},
abstract = {This paper presents a formal analysis framework to analyze a family of platform products w.r.t. real-time properties. First, we propose an extension of the widely-used feature model, called Property Feature Model (PFM), that distinguishes features and properties explicitly Second, we present formal behavioral models of components of a real-time scheduling unit such that all real-time scheduling units implied by a PFM are automatically composed to be analyzed against the properties given by the PFM. We apply our approach to the verification of the schedulability of a family of scheduling units using the symbolic and statistical model checkers of Uppaal.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1562–1565},
numpages = {4},
keywords = {model checking, platform-constrained, scheduling systems, software product line engineering},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/2556624.2556643,
author = {Fenske, Wolfram and Th\"{u}m, Thomas and Saake, Gunter},
title = {A taxonomy of software product line reengineering},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556643},
doi = {10.1145/2556624.2556643},
abstract = {In the context of single software systems, refactoring is commonly accepted to be the process of restructuring an existing body of code in order to improve its internal structure without changing its external behavior. This process is vital to the maintenance and evolution of software systems.Software product line engineering is a paradigm for the construction and customization of large-scale software systems. As systems grow in complexity and size, maintaining a clean structure becomes arguably more important. However, product line literature uses the term "refactoring" for such a wide range of reengineering activities that it has become difficult to see how these activities pertain to maintenance and evolution and how they are related.We improve this situation in the following way: i) We identify the dimensions along which product line reengineering occurs. ii) We derive a taxonomy that distinguishes and relates these reengineering activities. iii) We propose definitions for the three main branches of this taxonomy. iv) We classify a corpus of existing work.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {4},
numpages = {8},
keywords = {taxonomy, software product lines, refactoring, reengineering},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/3307630.3342384,
author = {El-Sharkawy, Sascha and Krafczyk, Adam and Schmid, Klaus},
title = {MetricHaven: More than 23,000 Metrics for Measuring Quality Attributes of Software Product Lines},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342384},
doi = {10.1145/3307630.3342384},
abstract = {Variability-aware metrics are designed to measure qualitative aspects of software product lines. As we identified in a prior SLR [6], there exist already many metrics that address code or variability separately, while the combination of both has been less researched. MetricHaven fills this gap, as it extensively supports combining information from code files and variability models. Further, we also enable the combination of well established single system metrics with novel variability-aware metrics, going beyond existing variability-aware metrics. Our tool supports most prominent single system and variability-aware code metrics. We provide configuration support for already implemented metrics, resulting in 23,342 metric variations. Further, we present an abstract syntax tree developed for MetricHaven, that allows the realization of additional code metrics.Tool: https://github.com/KernelHaven/MetricHavenVideo: https://youtu.be/vPEmD5Sr6gM},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {25–28},
numpages = {4},
keywords = {variability models, software product lines, metrics, implementation, feature models, SPL},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2364412.2364459,
author = {Lee, Hyesun and Yang, Jin-seok and Kang, Kyo C.},
title = {VULCAN: architecture-model-based workbench for product line engineering},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364459},
doi = {10.1145/2364412.2364459},
abstract = {Adaptability and reusability are important quality attributes for software targeted for global market due to diverse market needs, ever increasing number of features, rapidly changing technologies, and various laws/standards of different countries. In response to these requirements, software development organizations are interested in product line engineering and searching for support tools. However, most of the existing tools for supporting product line engineering focus only on providing mechanisms for instantiating products without adequately supporting development of software assets that are adaptable and reusable.To address this problem, we provide a CASE tool, called VULCAN, that provides architecture models/patterns that are adaptable/reusable and also supports mechanisms for instantiating products from assets. We have applied VULCAN to various product lines including glucose management systems and elevator control systems, and we could experience that maintainability of the assets has improved substantially because a large portion of the assets are specifications rather than low-level code and product-specific code is generated from the specifications.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {260–264},
numpages = {5},
keywords = {software product line, feature-oriented, architecture-model-based},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1109/SEAA.2014.48,
author = {Soares, Larissa Rocha and Potena, Pasqualina and Machado, Ivan do Carmo and Crnkovic, Ivica and Almeida, Eduardo Santana de},
title = {Analysis of Non-functional Properties in Software Product Lines: A Systematic Review},
year = {2014},
isbn = {9781479957958},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2014.48},
doi = {10.1109/SEAA.2014.48},
abstract = {Software Product Lines (SPL) approach has been widely developed in academia and successfully applied in industry. Based on the selection of features, stakeholders can efficiently derive tailor-made programs satisfying different requirements. While SPL was very successful at building products based on identified features, achievements and preservation of many nonfunctional properties (NFPs) remain challenging. A knowledge how to deal with NFPs is still not fully obtained. In this paper, we present a systematic literature review of NFPs analysis for SPL products, focusing on runtime NFPs. The goal of the paper is twofold: (i) to present an holistic overview of SPL approaches that have been reported regarding the analysis of runtime NFPs, and (ii) to categorize NFPs treated in the scientific literature regarding development of SPLs. We analyzed 36 research papers, and identified that system performance attributes are typically the most considered. The results also aid future research studies in NFPs analysis by providing an unbiased view of the body of empirical evidence and by guiding future research directions.},
booktitle = {Proceedings of the 2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {328–335},
numpages = {8},
keywords = {Systematic Literature Review, Software Product Lines, Product Derivation, Non-functional Properties},
series = {SEAA '14}
}

@inproceedings{10.5555/1753235.1753274,
author = {Pech, Daniel and Knodel, Jens and Carbon, Ralf and Schitter, Clemens and Hein, Dirk},
title = {Variability management in small development organizations: experiences and lessons learned from a case study},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Product line practices promise to reduce development and maintenance efforts, to improve the productivity and to reduce the time to market by systematic reuse of commonalities and variabilities. However, in order to reap the fruits of exploiting those, an upfront investment is required. This paper presents a case study, which analyzes the cost-benefit ratio for one product line discipline -- variability management. Wikon GmbH -- a small German development organization evolving a product line of remote monitoring and controlling devices -- switched from manual, file-based conditional compilation to tool-supported decision models. We discuss experiences made and show that the break-even was reached with the 4th product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {285–294},
numpages = {10},
keywords = {decision model, evolution, product line engineering, software architecture, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.4018/ijkss.2014100102,
author = {Tian, Kun},
title = {Adding More Agility to Software Product Line Methods: A Feasibility Study on Its Customization Using Agile Practices},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100102},
doi = {10.4018/ijkss.2014100102},
abstract = {Software Product Line Methods SPLMs have been continuously gaining attention, especially in practice, for on one hand, they address diverse market needs while controlling costs by planned systematic reuse in core assets development domain engineering, and on another hand, they reduce products' time-to-market, achieving a certain level of agility in product development application engineering. More cost-effective and agile as they are than traditional development methods for producing families of similar products, SPLMs still seem to be heavy weight in nature. In SPLMs, significant up-front commitments are involved in development of a flexible product platform, which will be modified into a range of products sharing common features. Agile Methods AMs share similar goals with SPLMs, e.g., on rapidly delivering high quality software that meets the changing needs of stakeholders. However, they appear to differ significantly practices. The purpose of this work is to compare Agile and Software Product line approaches from fundamental goals/principles, engineering, software quality assurance, sand project management perspectives, etc. The results of the study can be used to determine the feasibility of tailoring a software product line approach with Agile practices, resulting in a lighter-weight approach that provides mass customization, reduced time-to-market, and improved customer satisfaction.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {17–34},
numpages = {18},
keywords = {Time-To-Market, Software Product Line Methods SPLMs, Customer Satisfaction, Agile Methods AMs}
}

@inproceedings{10.1145/2739482.2764650,
author = {Karimpour, Reza and Ruhe, Guenther},
title = {A Search Based Approach Towards Robust Optimization in Software Product Line Scoping},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2764650},
doi = {10.1145/2739482.2764650},
abstract = {Software product line (SPL) scoping is important for planning upfront investment. One challenge with scoping comes from inaccuracies in estimated parameters and uncertainty in environment. In this paper, a method to incorporate uncertainty in SPL scoping optimization and its application to generate robust solutions is proposed. We model scoping optimization as a multi-objective problem with profit and stability as heuristics. To evaluate our proposal, a number of experiments are conducted. Analysis of results show that both performance stability and feasibility stability were improved providing the product line manager enhanced decision-making support.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1415–1416},
numpages = {2},
keywords = {uncertainty, software product line portfolio scoping, robust optimization, multi-objective},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.1145/2797433.2797456,
author = {Galster, Matthias},
title = {Architecting for Variability in Quality Attributes of Software Systems},
year = {2015},
isbn = {9781450333931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2797433.2797456},
doi = {10.1145/2797433.2797456},
abstract = {Variability in software systems is usually concerned with variability in features and functionality. However, variability also occurs in quality attributes (e.g., performance, security) and quality attribute requirements (for example, a performance requirement may state that a system must respond to a user request within 0.1 seconds). We discuss what variability in quality attributes is, including several scenarios in which variability in quality attributes can occur. We then discuss the state of research and what we know about variability in quality attributes, including some existing research to address the challenge of identifying, implementing and managing variability in quality attributes. Finally, we discuss potential directions for future research.},
booktitle = {Proceedings of the 2015 European Conference on Software Architecture Workshops},
articleno = {23},
numpages = {4},
keywords = {software architecture, quality attributes, Variability},
location = {Dubrovnik, Cavtat, Croatia},
series = {ECSAW '15}
}

@inproceedings{10.1145/2695664.2695797,
author = {Tizzei, Leonardo P. and Azevedo, Leonardo G. and de Bayser, Maximilien and Cerqueira, Renato F. G.},
title = {Architecting cloud tools using software product line techniques: an exploratory study},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695797},
doi = {10.1145/2695664.2695797},
abstract = {Multitenant cloud computing tools are usually complex and have to manage variabilities to support customization. Software Product Line (SPL) techniques have been successfully applied in the industry to manage variability in complex systems. However, few works in the literature discuss the application of SPL techniques to architect industry cloud computing tools, resulting in a lack of support to cloud architects on how to apply such techniques. This work presents how software product line techniques can be applied for architecting cloud tools, and discusses the benefits, drawbacks, and some challenges of applying such techniques to develop a real industry cloud tool, named as Installation Service.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1441–1448},
numpages = {8},
location = {Salamanca, Spain},
series = {SAC '15}
}

@article{10.1016/j.infsof.2012.09.007,
author = {Guana, Victor and Correal, Dario},
title = {Improving software product line configuration: A quality attribute-driven approach},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.09.007},
doi = {10.1016/j.infsof.2012.09.007},
abstract = {Context: During the definition of software product lines (SPLs) it is necessary to choose the components that appropriately fulfil a product's intended functionalities, including its quality requirements (i.e., security, performance, scalability). The selection of the appropriate set of assets from many possible combinations is usually done manually, turning this process into a complex, time-consuming, and error-prone task. Objective: Our main objective is to determine whether, with the use of modeling tools, we can simplify and automate the definition process of a SPL, improving the selection process of reusable assets. Method: We developed a model-driven strategy based on the identification of critical points (sensitivity points) inside the SPL architecture. This strategy automatically selects the components that appropriately match the product's functional and quality requirements. We validated our approach experimenting with different real configuration and derivation scenarios in a mobile healthcare SPL where we have worked during the last three years. Results: Through our SPL experiment, we established that our approach improved in nearly 98% the selection of reusable assets when compared with the unassisted analysis selection. However, using our approach there is an increment in the time required for the configuration corresponding to the learning curve of the proposed tools. Conclusion: We can conclude that our domain-specific modeling approach significantly improves the software architect's decision making when selecting the most suitable combinations of reusable components in the context of a SPL.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {541–562},
numpages = {22},
keywords = {Variability management, Software architecture, Sensitivity points, Quality evaluation, Model driven - software product lines, Domain specific modeling}
}

@article{10.1016/j.jss.2017.01.026,
author = {Arvanitou, Elvira Maria and Ampatzoglou, Apostolos and Chatzigeorgiou, Alexander and Galster, Matthias and Avgeriou, Paris},
title = {A mapping study on design-time quality attributes and metrics},
year = {2017},
issue_date = {May 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {127},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.01.026},
doi = {10.1016/j.jss.2017.01.026},
abstract = {Support to the quality attribute (QA) &amp; metric selection process.Maintainability is the most studied QA for most domains and development phases.Quality attributes are usually assessed through a correlation to a single metric.Metrics are validated in empirical settings and may lack theoretical validity. Developing a plan for monitoring software quality is a non-trivial task, in the sense that it requires: (a) the selection of relevant quality attributes, based on application domain and development phase, and (b) the selection of appropriate metrics to quantify quality attributes. The metrics selection process is further complicated due to the availability of various metrics for each quality attribute, and the constraints that impact metric selection (e.g., development phase, metric validity, and available tools). In this paper, we shed light on the state-of-research of design-time quality attributes by conducting a mapping study. We have identified 154 papers that have been included as primary studies. The study led to the following outcomes: (a) low-level quality attributes (e.g., cohesion, coupling, etc.) are more frequently studied than high-level ones (e.g., maintainability, reusability, etc.), (b) maintainability is the most frequently examined high-level quality attribute, regardless of the application domain or the development phase, (c) assessment of quality attributes is usually performed by a single metric, rather than a combination of multiple metrics, and (d) metrics are mostly validated in an empirical setting. These outcomes are interpreted and discussed based on related work, offering useful implications to both researchers and practitioners.},
journal = {J. Syst. Softw.},
month = may,
pages = {52–77},
numpages = {26},
keywords = {Software quality, Measurement, Mapping study, Design-time quality attributes}
}

@article{10.1016/j.infsof.2012.06.014,
author = {Andersson, Henric and Herzog, Erik and \"{O}Lvander, Johan},
title = {Experience from model and software reuse in aircraft simulator product line engineering},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.06.014},
doi = {10.1016/j.infsof.2012.06.014},
abstract = {Context: ''Reuse'' and ''Model Based Development'' are two prominent trends for improving industrial development efficiency. Product lines are used to reduce the time to create product variants by reusing components. The model based approach provides the opportunity to enhance knowledge capture for a system in the early stages in order to be reused throughout its lifecycle. This paper describes how these two trends are combined to support development and support of a simulator product line for the SAAB 39 Gripen fighter aircraft. Objective: The work aims at improving the support (in terms of efficiency and quality) when creating simulation model configurations. Software based simulators are flexible so variants and versions of included models may easily be exchanged. The objective is to increase the reuse when combining models for usage in a range of development and training simulators. Method: The research has been conducted with an interactive approach using prototyping and demonstrations, and the evaluation is based on an iterative and a retrospective method. Results: A product line of simulator models for the SAAB 39 Gripen aircraft has been analyzed and defined in a Product Variant Master. A configurator system has been implemented for creation, integration, and customization of stringent simulator model configurations. The system is currently under incorporation in the standard development process at SAAB Aeronautics. Conclusion: The explicit and visual description of products and their variability through a configurator system enables better insights and a common understanding so that collaboration on possible product configurations improves and the potential of software reuse increases. The combination of application fields imposes constraints on how traditional tools and methods may be utilized. Solutions for Design Automation and Knowledge Based Engineering are available, but their application has limitations for Software Product Line engineering and the reuse of simulation models.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {595–606},
numpages = {12},
keywords = {Software Product Line, SPL, PDM, Model Based Development, Knowledge Based Engineering, Configurator}
}

@inproceedings{10.1145/2851613.2851964,
author = {Cool, Benjamin and Knieke, Christoph and Rausch, Andreas and Schindler, Mirco and Strasser, Arthur and Vogel, Martin and Brox, Oliver and Jauns-Seyfried, Stefanie},
title = {From product architectures to a managed automotive software product line architecture},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851964},
doi = {10.1145/2851613.2851964},
abstract = {To keep the software development for vehicles cost efficient, software components are reused for different variants as well as for succeeding generations. Furthermore, cost reductions are achieved by software sharing between the Original Equipment Manufacturer (OEM) and the suppliers. However, as a consequence of the blackboxed view caused by software sharing, no common detailed software product line architecture specification for the Electronic Control Unit (ECU) software exists, as it would be required for analyzing the quality of the product line architecture, planning changes on the product line architecture, checking the compliance between the product architecture and the product line architecture, and therefore, avoiding architecture erosion. Thus, after several product generations, software erosion is growing steadily, resulting in an increasing effort of reusing software components, and planning of further development. Here, we propose an approach for repairing an eroded software consisting of a set of product architectures by applying strategies for recovery and discovery of the product line architecture. Furthermore, we give a methodology for a long-term manageable, plannable, and reuseable software product line architecture for automotive software systems.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1350–1353},
numpages = {4},
keywords = {architecture evolution, architecture quality measures, automotive, software erosion, software product lines},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/3382025.3414946,
author = {Fritsch, Claudia and Abt, Richard and Renz, Burkhardt},
title = {The benefits of a feature model in banking},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414946},
doi = {10.1145/3382025.3414946},
abstract = {This experience report describes the surprisingly beneficial introduction of feature modeling at KfW, a government promotional bank. On behalf of the government and based on promotional directives, KfW grants retail loans to small and medium enterprises, business founders, self-employed professionals, municipalities and private individuals. The promotional directives, called programs, define mandatory and optional properties of these loans. We have now successfully built a feature model from these properties.Our feature model will be presented with its outstanding characteristic, which is an additional subtree containing the programs as features. Complete and correct cross-tree constraints will also allow us to analyze and scope the portfolio, reduce complexity, and speed-up time-to-market. This is the advent of product line development at KfW.In order to standardize our portfolio, we have subsequently developed tools on top of the feature model, namely, a browser-based, multi-user configurator assisting non-technical-affine users in their product design, and a generator producing complete product documentation from the feature model and partial configurations. More applications are currently underway.This is our story of applying Software Product Line Engineering in banking, a domain where it is unusual or even unknown. We share our ideas, analyses, progress, and findings where the results have been thrilling us for the past two years and will continue to do so.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {9},
numpages = {11},
keywords = {software product line engineering, retail loans, partial configuration, mass customization, feature modeling, experience report, document generation},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1007/s00766-013-0165-8,
author = {Bagheri, Ebrahim and Ensan, Faezeh},
title = {Dynamic decision models for staged software product line configuration},
year = {2014},
issue_date = {June      2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0165-8},
doi = {10.1007/s00766-013-0165-8},
abstract = {Software product line engineering practices offer desirable characteristics such as rapid product development, reduced time-to-market, and more affordable development costs as a result of systematic representation of the variabilities of a domain of discourse that leads to methodical reuse of software assets. The development lifecycle of a product line consists of two main phases: domain engineering, which deals with the understanding and formally modeling of the target domain, and application engineering that is concerned with the configuration of a product line into one concrete product based on the preferences and requirements of the stakeholders. The work presented in this paper focuses on the application engineering phase and builds both the theoretical and technological tools to assist the stakeholders in (a) understanding the complex interactions of the features of a product line; (b) eliciting the utility of each feature for the stakeholders and hence exposing the stakeholders' otherwise implicit preferences in a way that they can more easily make decisions; and (c) dynamically building a decision model through interaction with the stakeholders and by considering the structural characteristics of software product line feature models, which will guide the stakeholders through the product configuration process. Initial exploratory empirical experiments that we have performed show that our proposed approach for helping stakeholders understand their feature preferences and its associated staged feature model configuration process is able to positively impact the quality of the end results of the application engineering process within the context of the limited number of participants. In addition, it has been observed that the offered tooling support is able to ease the staged feature model configuration process.},
journal = {Requir. Eng.},
month = jun,
pages = {187–212},
numpages = {26},
keywords = {Utility elicitation, Stakeholder preferences, Software product lines, Feature models}
}

@inproceedings{10.1145/3167132.3167350,
author = {Fischer, Stefan and Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
title = {Towards a fault-detection benchmark for evaluating software product line testing approaches},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167350},
doi = {10.1145/3167132.3167350},
abstract = {Software Product Lines (SPLs) are families of related software systems distinguished by the set of features each one provides. The commonly large number of variants that can be derived from an SPL poses a unique set of challenges, because it is not feasible to test all the individual variants. Over the last few years many approaches for SPL testing have been devised. They usually select a set of variants to test based on some covering criterion. A problem when evaluating these testing approaches is properly comparing them to one another. Even though some benchmarks have been proposed, they focus on covering criteria and do not consider fault data in their analysis. Considering the dire lack of publicly available fault data, in this paper we present the first results of our ongoing project to introduce simulated faults into SPLs along with using evolutionary techniques for synthesizing unit test cases for SPL examples.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {2034–2041},
numpages = {8},
keywords = {software product lines, mutation testing},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1145/2791060.2791065,
author = {Gregg, Susan P. and Scharadin, Rick and Clements, Paul},
title = {The more you do, the more you save: the superlinear cost avoidance effect of systems product line engineering},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791065},
doi = {10.1145/2791060.2791065},
abstract = {Product lines that use automated tools to configure shared assets (e.g., software or requirements or test cases or user documentation) based on product descriptions have long been known to bring about substantial development cost avoidance when compared to clone-and-own or product-specific development techniques. Now, however, it can be shown that the cost avoidance for configuring multiple shared assets is superlinear -- that is, the overall cost avoidance exceeds the sum of the that brought about by working with each of the shared assets in isolation. That is, a product line that configures (for example) requirements and code will avoid more cost than the sum of code-based plus requirements-based cost avoidance. In addition, we also observe a superlinear effect in terms of the number of products in the portfolio as well. This paper explores why these effects occur, and presents analytical and empirical evidence for their existence from one of the largest and most successful product lines in the literature, the AEGIS Weapon System. The result may lead to new insight into the economics of product line engineering in the systems engineering realm.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {303–310},
numpages = {8},
keywords = {variation points, systems and software product lines, second generation product line engineering, product line measurement, product line engineering, product line economics, product derivation, product configurator, feature modeling, AEGIS},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.5555/1158337.1158693,
author = {Trask, Bruce and Roman, Angel and Paniscotti, Dominick and Bhanot, Vikram},
title = {Using Model-Driven Engineering to Complement Software Product Line Engineering in Developing Software Defined Radio Components and Applications},
year = {2006},
isbn = {0769525997},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper details the application of Software Product Lines (SPL)15 and Model-Driven Engineering (MDE)16 to the software defined radio domain. More specifically it is an experience report emphasizing the synergy17 resulting from combining MDE and SPL technologies. The software defined radio domain has very unique characteristics as its systems typically are a confluence of a number of typically challenging aspects of software development. To name a few, these systems are usually described by modifiers such as, embedded, real-time, distributed, object-oriented, portable, heterogeneous, multithreaded, high performance, dynamic, resource-constrained, safetycritical, secure, networked, component based and fault-tolerant. Each one of these modifiers by themselves carries with it a set of unique challenges but building systems characterized by all of these modifiers all at the same time makes for quite an adventure in software development. In addition to all of these, it is quite common in these embedded systems for components to have multiple implementations that must run on disparate processing elements. With all of this taken into account, it stands to reason that these systems could and should benefit greatly from advances in software technology such as product line engineering, domain-specific modeling and modeldriven engineering. It is our experience that one big boon to the software development industry is the combination of the Software Product Lines and Model Driven Engineering technologies.},
booktitle = {Proceedings of the 10th International on Software Product Line Conference},
pages = {192–202},
numpages = {11},
series = {SPLC '06}
}

@inproceedings{10.1145/1985484.1985489,
author = {Michalik, Bartosz and Weyns, Danny and Van Betsbrugge, Wim},
title = {On the problems with evolving Egemin's software product line},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985489},
doi = {10.1145/1985484.1985489},
abstract = {Egemin, an industrial manufacturer of logistic systems is adopting a Software Product Line (SPL) approach to manage the development of their product portfolio. However, due to the intrinsic complexity of the logistic systems and lack of explicitly documented architectural knowledge evolution of the products is error-prone. Faulty updates increase maintenance costs and harm the company's reputation. Therefore, Egemin searches for a systematic solution that can improve their SPL evolution strategy.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {15–19},
numpages = {5},
keywords = {spl, software product line, evolution},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@inproceedings{10.5555/2662572.2662582,
author = {Colanzi, Thelma Elita and Vergilio, Silvia Regina},
title = {Representation of software product line architectures for search-based design},
year = {2013},
isbn = {9781467362849},
publisher = {IEEE Press},
abstract = {The Product-Line Architecture (PLA) is the main artifact of a Software Product Line (SPL). Search-based approaches can provide automated discovery of near-optimal PLAs and make its design less dependent on human architects. To do this, it is necessary to adopt a suitable PLA representation to apply the search operators. In this sense, we review existing architecture representations proposed by related work, but all of them need to be extended to encompass specific characteristics of SPL. Then, the use of such representations for PLA is discussed and, based on the performed analysis, we introduce a novel direct PLA representation for search-based optimization. Some implementation aspects are discussed involving implementation details about the proposed PLA representation, constraints and impact on specific search operators. Ongoing work addresses the application of specific search operators for the proposed representation and the definition of a fitness function to be applied in a multi-objective search-based approach for the PLA design.},
booktitle = {Proceedings of the 1st International Workshop on Combining Modelling and Search-Based Software Engineering},
pages = {28–33},
numpages = {6},
keywords = {software product line, multi-objective search-based approach, architecture modelling},
location = {San Francisco, California},
series = {CMSBSE '13}
}

@inproceedings{10.1109/SEAA.2013.20,
author = {Horcas, Jos\'{e} Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Variability and Dependency Modeling of Quality Attributes},
year = {2013},
isbn = {9780769550916},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2013.20},
doi = {10.1109/SEAA.2013.20},
abstract = {Functional Quality Attributes (FQAs) are quality attributes that have strong functional implications and so can be easily modeled by software components. Thus, we use an aspect-oriented software product line approach, to model the commonalities and variabilities of FQAs from the early stages of the software development. However, FQAs cannot be modeled in isolation since they usually have dependencies and interactions between them. In this paper we focus on identifying and modeling the dependencies among different FQAs. These dependencies are automatically incorporated into the final software architecture of the system under development, even when the software architect may be unaware of them.},
booktitle = {Proceedings of the 2013 39th Euromicro Conference on Software Engineering and Advanced Applications},
pages = {185–188},
numpages = {4},
keywords = {quality attributes, feature models, dependencies, AO-ADL},
series = {SEAA '13}
}

@article{10.1145/3034827,
author = {Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
title = {CASE Tool Support for Variability Management in Software Product Lines},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3034827},
doi = {10.1145/3034827},
abstract = {Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools’ characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {14},
numpages = {45},
keywords = {software variability, computer-aided software engineering, Software engineering}
}

@article{10.1145/2180921.2180941,
author = {Ripon, Shamim H.},
title = {A unified tabular method for modeling variants of software product line},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/2180921.2180941},
doi = {10.1145/2180921.2180941},
abstract = {Reuse of software is a promising approach to improving the efficiency of software development regarding time, cost and quality. Reuse requires a systematic approach. The best results are achieved if we focus on systems in a specific domain, so-called product line. The key difference between the conventional software engineering and software product line engineering is variant management. The main idea of software product line is to identify the common core functionality which can be implemented once and reused afterwards for all members of the product line. To facilitate this reuse opportunity the domain engineering phase makes the domain model comprising the common as well as variant requirements. In principle, common requirements among systems in a family are easy to handle. However, problem arises during handling variants. Different variants have dependencies on each other; a single variant can affect several variants of the domain model. These problems become complex when the volume of information grows in a domain and there are a lot of variants with several interdependencies. Hence, a separate model is required for handling the variants. This paper presents a mechanism, which we call, Unified Tabular Method to facilitate the management of variant dependencies in product lines. The tabular method consists of a variant part to model the variants and their dependencies, and a decision table to depict the customization decision regarding each variant while deriving customized products. Tabular method alleviates the problem of possible explosion of variant combinations and facilitates the tracing of variant information in the domain model},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–7},
numpages = {7},
keywords = {unified tabular method, software product line, modeling variants}
}

@inproceedings{10.1145/2993412.3004847,
author = {Anvaari, Mohsen and S\o{}rensen, Carl-Fredrik and Zimmermann, Olaf},
title = {Associating architectural issues with quality attributes: a survey on expert agreement},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3004847},
doi = {10.1145/2993412.3004847},
abstract = {The architectural decision-making process is a complex and crucial endeavor in companies that develop large and distributed software systems. In this process, choosing and evaluating a solution for each architectural issue depends on decision drivers. The drivers are mainly the business factors (e.g., cost, time-to-market, etc.) and software quality attributes (e.g., security, adaptability, etc.). This paper examines whether there is agreement among experts in associating (i.e., relating) architectural issues with relevant quality attributes. We conducted a survey with 37 experts from several industrial domains who, at least once a month, make one or more architectural decisions. The results show there is poor agreement among these experts in identifying and scoring relevant quality attributes for each architectural issue. Poor agreement implies that the associating task is subjective, and that experts inconsistently define and interpret the relevance of various quality attributes for a given architectural issue that may hurt the sustainability of their architectural decisions. This paper suggests that practitioners in their decision-making should employ approaches that are more systematic. The approaches should be supported by methods and tools designed to diminish the biases of intuitive, experience-based approaches of associating architectural issues with quality attributes.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {11},
numpages = {7},
keywords = {survey, software quality attribute, inter-rater agreement, architectural synthesis, architectural decision},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@article{10.1007/s11219-010-9127-2,
author = {Bagheri, Ebrahim and Gasevic, Dragan},
title = {Assessing the maintainability of software product line feature models using structural metrics},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9127-2},
doi = {10.1007/s11219-010-9127-2},
abstract = {A software product line is a unified representation of a set of conceptually similar software systems that share many common features and satisfy the requirements of a particular domain. Within the context of software product lines, feature models are tree-like structures that are widely used for modeling and representing the inherent commonality and variability of software product lines. Given the fact that many different software systems can be spawned from a single software product line, it can be anticipated that a low-quality design can ripple through to many spawned software systems. Therefore, the need for early indicators of external quality attributes is recognized in order to avoid the implications of defective and low-quality design during the late stages of production. In this paper, we propose a set of structural metrics for software product line feature models and theoretically validate them using valid measurement-theoretic principles. Further, we investigate through controlled experimentation whether these structural metrics can be good predictors (early indicators) of the three main subcharacteristics of maintainability: analyzability, changeability, and understandability. More specifically, a four-step analysis is conducted: (1) investigating whether feature model structural metrics are correlated with feature model maintainability through the employment of classical statistical correlation techniques; (2) understanding how well each of the structural metrics can serve as discriminatory references for maintainability; (3) identifying the sufficient set of structural metrics for evaluating each of the subcharacteristics of maintainability; and (4) evaluating how well different prediction models based on the proposed structural metrics can perform in indicating the maintainability of a feature model. Results obtained from the controlled experiment support the idea that useful prediction models can be built for the purpose of evaluating feature model maintainability using early structural metrics. Some of the structural metrics show significant correlation with the subjective perception of the subjects about the maintainability of the feature models.},
journal = {Software Quality Journal},
month = sep,
pages = {579–612},
numpages = {34},
keywords = {Structural complexity, Software product line, Software prediction model, Quality attributes, Maintainability, Feature model, Controlled experimentation}
}

@article{10.1016/j.infsof.2012.07.017,
author = {Ghezzi, Carlo and Molzam Sharifloo, Amir},
title = {Model-based verification of quantitative non-functional properties for software product lines},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.017},
doi = {10.1016/j.infsof.2012.07.017},
abstract = {Evaluating quality attributes of a design model in the early stages of development can significantly reduce the cost and risks of developing a low quality product. To make this possible, software designers should be able to predict quality attributes by reasoning on a model of the system under development. Although there exists a variety of quality-driven analysis techniques for software systems, only a few work address software product lines. This paper describes how probabilistic model checking techniques and tools can be used to verify non-functional properties of different configurations of a software product line. We propose a model-based approach that enables software engineers to assess their design solutions for software product lines in the early stages of development. Furthermore, we discuss how the analysis time can be surprisingly reduced by applying parametric model checking instead of classic model checking. The results show that the parametric approach is able to substantially alleviate the verification time and effort required to analyze non-functional properties of software product lines.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {508–524},
numpages = {17},
keywords = {Software product lines, Quality analysis, Probabilistic model checking, Parametric verification, Non-functional requirements}
}

@inproceedings{10.1145/2896982.2896988,
author = {Cu, Cuong and Zheng, Yongjie},
title = {Architecture-centric derivation of products in a software product line},
year = {2016},
isbn = {9781450341646},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896982.2896988},
doi = {10.1145/2896982.2896988},
abstract = {It is essential to architecture-centric product line development that product line architecture can be used to drive activities specific to product line development, such as product derivation. This requires a mechanism that can automatically derive the architecture and code of a product instance from the customization of product line architecture. In this paper, we analyze the insufficiency of two existing solutions in this area and present an architecture-centric approach that meets the requirement. The approach can support product line differences in platforms and functions, and generate both product line code and product code. It is based on a product line implementation mechanism that combines a code generation and separation pattern with an architecture-based code annotation technique. We have implemented the approach, and finished a preliminary evaluation with a chat application.},
booktitle = {Proceedings of the 8th International Workshop on Modeling in Software Engineering},
pages = {27–33},
numpages = {7},
keywords = {software architecture, product line architecture, architecture-centric development},
location = {Austin, Texas},
series = {MiSE '16}
}

@inproceedings{10.1109/SPLC.2011.33,
author = {Ghezzi, Carlo and Sharifloo, Amir Molzam},
title = {Verifying Non-functional Properties of Software Product Lines: Towards an Efficient Approach Using Parametric Model Checking},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.33},
doi = {10.1109/SPLC.2011.33},
abstract = {In this paper, we describe how probabilistic model checking techniques and tools can be used to verify non-functional properties of different configurations of a software product line. We propose a model-based approach that enables software engineers to assess their design solutions in the early stages of development. Furthermore, we discuss how verification time can surprisingly be reduced by applying parametric model checking instead of classic model checking, and show that the approach can be effective in practice.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {170–174},
numpages = {5},
keywords = {Software Product Lines, Probabilistic Model Checking, Non-Functional Requirements},
series = {SPLC '11}
}

@inproceedings{10.1109/APSEC.2010.26,
author = {Sincero, Julio and Schroder-Preikschat, Wolfgang and Spinczyk, Olaf},
title = {Approaching Non-functional Properties of Software Product Lines: Learning from Products},
year = {2010},
isbn = {9780769542669},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2010.26},
doi = {10.1109/APSEC.2010.26},
abstract = {Approaching the configuration of non-functional properties (NFPs) in traditional software systems is not an easy task, addressing the configuration of these properties in software product lines (SPLs) imposes even further challenges. Therefore, we have devised the Feedback Approach, which extends the traditional SPL development techniques in order to improve the configuration of NFPs. In this work we present the general guidelines of our approach and also we show the feasibility of the idea by presenting a case study using the Linux Kernel.},
booktitle = {Proceedings of the 2010 Asia Pacific Software Engineering Conference},
pages = {147–155},
numpages = {9},
keywords = {Software Product Lines, Non-Functional Properties, Linux},
series = {APSEC '10}
}

@article{10.1016/j.infsof.2015.09.004,
author = {Souza Neto, Pl\'{a}cido A. and Vargas-Solar, Genoveva and da Costa, Umberto Souza and Musicante, Martin A.},
title = {Designing service-based applications in the presence of non-functional properties},
year = {2016},
issue_date = {January 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {69},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.09.004},
doi = {10.1016/j.infsof.2015.09.004},
abstract = {ContextThe development of distributed software systems has become an important problem for the software engineering community. Service-based applications are a common solution for this kind of systems. Services provide a uniform mechanism for discovering, integrating and using these resources. In the development of service based applications not only the functionality of services and compositions should be considered, but also conditions in which the system operates. These conditions are called non-functional requirements (NFR). The conformance of applications to NFR is crucial to deliver software that meets the expectations of its users. ObjectiveThis paper presents the results of a systematic mapping carried out to analyze how NFR have been addressed in the development of service-based applications in the last years, according to different points of view. MethodOur analysis applies the systematic mapping approach. It focuses on the analysis of publications organized by categories called facets, which are combined to answer specific research questions. The facets compose a classification schema which is part of the contribution and results. ResultsThis paper presents our findings on how NFR have been supported in the development of service-based applications by proposing a classification scheme consisting in five facets: (i) programming paradigm (object/service oriented); (ii) contribution (methodology, system, middleware); (iii) software process phase; (iv) technique or mathematical model used for expressing NFR; and (v) the types of NFR addressed by the papers, based on the classification proposed by the ISO/IEC 9126 specification. The results of our systematic mapping are presented as bubble charts that provide a quantitative analysis to show the frequencies of publications for each facet. The paper also proposes a qualitative analysis based on these plots. This analysis discusses how NFR (quality properties) have been addressed in the design and development of service-based applications, including methodologies, languages and tools devised to support different phases of the software process. ConclusionThis systematic mapping showed that NFR are not fully considered in all software engineering phases for building service based applications. The study also let us conclude that work has been done for providing models and languages for expressing NFR and associated middleware for enforcing them at run time. An important finding is that NFR are not fully considered along all software engineering phases and this opens room for proposing methodologies that fully model NFR. The data collected by our work and used for this systematic mapping are available in https://github.com/placidoneto/systematic-mapping_service-based-app_nfr.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {84–105},
numpages = {22},
keywords = {Systematic mapping, Service-based software process, Non-functional requirements}
}

@article{10.4018/ijkss.2014100104,
author = {Ripon, Shamim H and Hossain, Sk. Jahir and Piash, Moshiur Mahamud},
title = {Logic-Based Analysis and Verification of Software Product Line Variant Requirement Model},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100104},
doi = {10.4018/ijkss.2014100104},
abstract = {Software Product Line SPL provides the facility to systematically reuse of software improving the efficiency of software development regarding time, cost and quality. The main idea of SPL is to identify the common core functionality that can be implemented once and reused afterwards. A variant model has also to be developed to manage the variants of the SPL. Usually, a domain model consisting of the common and variant requirements is developed during domain engineering phase to alleviate the reuse opportunity. The authors present a product line model comprising of a variant part for the management of variant and a decision table to depict the customization of decision regarding each variant. Feature diagrams are widely used to model SPL variants. Both feature diagram and our variant model, which is based on tabular method, lacks logically sound formal representation and hence, not amenable to formal verification. Formal representation and verification of SPL has gained much interest in recent years. This chapter presents a logical representation of the variant model by using first order logic. With this representation, the table based variant model as well as the graphical feature diagram can now be verified logically. Besides applying first-order-logic to model the features, the authors also present an approach to model and analyze SPL model by using semantic web approach using OWL-DL. The OWL-DL representation also facilitates the search and maintenance of feature models and support knowledge sharing within a reusable engineering context. Reasoning tools are used to verify the consistency of the feature configuration for both logic-based and semantic web-based approaches.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {52–76},
numpages = {25},
keywords = {Web-Based Approaches, Software Product Line SPL, OWL-DL, Feature Diagrams, Domain Model}
}

@inproceedings{10.1007/978-3-662-43652-3_34,
author = {Zulkoski, Ed and Kleynhans, Chris and Yee, Ming-Ho and Rayside, Derek and Czarnecki, Krzysztof},
title = {Optimizing Alloy for Multi-objective Software Product Line Configuration},
year = {2014},
isbn = {9783662436516},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-43652-3_34},
doi = {10.1007/978-3-662-43652-3_34},
abstract = {Software product line SPL engineering involves the modeling, analysis, and configuration of variability-rich systems. We improve the performance of the multi-objective optimization of SPLs in Alloy by several orders of magnitude with two techniques.First, we rewrite the model to remove binary relations that map to integers, which enables removing most of the integer atoms from the universe. SPL models often require using large bitwidths, hence the number of integer atoms in the universe can be orders of magnitude more than the other atoms. In our approach, the tuples for these integer-valued relations are computed outside the sat solver before returning the solution to the user. Second, we add a checkpointing facility to Kodkod, which allows the multi-objective optimization algorithm to reuse previously computed internal sat solver state, after backtracking.Together these result in orders of magnitude improvement in using Alloy as a multi-objective optimization tool for software product lines.},
booktitle = {Proceedings of the 4th International Conference on Abstract State Machines, Alloy, B, TLA, VDM, and Z - Volume 8477},
pages = {328–333},
numpages = {6},
keywords = {Product Lines, Multi-objective Optimization, Kodkod, Alloy},
location = {Toulouse, France},
series = {ABZ 2014}
}

@inproceedings{10.1007/978-3-642-34032-1_22,
author = {Ferrari, Alessio and Spagnolo, Giorgio Oronzo and Martelli, Giacomo and Menabeni, Simone},
title = {Product line engineering applied to CBTC systems development},
year = {2012},
isbn = {9783642340314},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34032-1_22},
doi = {10.1007/978-3-642-34032-1_22},
abstract = {Communications-based Train Control (CBTC) systems are the new frontier of automated train control and operation. Currently developed CBTC platforms are actually very complex systems including several functionalities, and every installed system, developed by a different company, varies in extent, scope, number, and even names of the implemented functionalities. International standards have emerged, but they remain at a quite abstract level, mostly setting terminology.This paper reports intermediate results in an effort aimed at defining a global model of CBTC, by mixing semi-formal modelling and product line engineering. The effort has been based on an in-depth market analysis, not limiting to particular aspects but considering as far as possible the whole picture. The adopted methodology is discussed and a preliminary model is presented.},
booktitle = {Proceedings of the 5th International Conference on Leveraging Applications of Formal Methods, Verification and Validation: Applications and Case Studies - Volume Part II},
pages = {216–230},
numpages = {15},
location = {Heraklion, Crete, Greece},
series = {ISoLA'12}
}

@article{10.1007/s10515-014-0160-4,
author = {Devine, Thomas and Goseva-Popstojanova, Katerina and Krishnan, Sandeep and Lutz, Robyn R.},
title = {Assessment and cross-product prediction of software product line quality: accounting for reuse across products, over multiple releases},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-014-0160-4},
doi = {10.1007/s10515-014-0160-4},
abstract = {The goals of cross-product reuse in a software product line (SPL) are to mitigate production costs and improve the quality. In addition to reuse across products, due to the evolutionary development process, a SPL also exhibits reuse across releases. In this paper, we empirically explore how the two types of reuse--reuse across products and reuse across releases--affect the quality of a SPL and our ability to accurately predict fault proneness. We measure the quality in terms of post-release faults and consider different levels of reuse across products (i.e., common, high-reuse variation, low-reuse variation, and single-use packages), over multiple releases. Assessment results showed that quality improved for common, low-reuse variation, and single-use packages as they evolved across releases. Surprisingly, within each release, among preexisting (`old') packages, the cross-product reuse did not affect the change and fault proneness. Cross-product predictions based on pre-release data accurately ranked the packages according to their post-release faults and predicted the 20 % most faulty packages. The predictions benefited from data available for other products in the product line, with models producing better results (1) when making predictions on smaller products (consisting mostly of common packages) rather than on larger products and (2) when trained on larger products rather than on smaller products.},
journal = {Automated Software Engg.},
month = jun,
pages = {253–302},
numpages = {50},
keywords = {Software product lines, Longitudinal study, Fault proneness prediction, Cross-release reuse, Cross-product reuse, Cross-product prediction, Assessment}
}

@inproceedings{10.1145/3461002.3473068,
author = {Santos, Edilton Lima dos},
title = {STARS: software technology for adaptable and reusable systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473068},
doi = {10.1145/3461002.3473068},
abstract = {Dynamic Software Product Lines (DSPLs) engineering implements self-adaptive systems by dynamically binding or unbinding features at runtime according to a feature model. However, these features may interact in unexpected and undesired ways leading to critical consequences for the DSPL. Moreover, (re)configurations may negatively affect the runtime system's architectural qualities, manifesting architectural bad smells. These issues are challenging to detect due to the combinatorial explosion of the number of interactions amongst features. As some of them may appear at runtime, we need a runtime approach to their analysis and mitigation. This thesis introduces the Behavioral Map (BM) formalism that captures information from different sources (feature model, code) to automatically detect these issues. We provide behavioral map inference algorithms. Using the Smart Home Environment (SHE) as a case study, we describe how a BM is helpful to identify critical feature interactions and architectural smells. Our preliminary results already show promising progress for both feature interactions and architectural bad smells identification at runtime.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {13–17},
numpages = {5},
keywords = {software testing, software product line engineering, software architecture, self-adapting system, dynamic software product lines engineering, MAPE-K loop},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.scico.2012.05.003,
author = {Laguna, Miguel A. and Crespo, Yania},
title = {A systematic mapping study on software product line evolution: From legacy system reengineering to product line refactoring},
year = {2013},
issue_date = {August, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {8},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.05.003},
doi = {10.1016/j.scico.2012.05.003},
abstract = {Software product lines (SPLs) are used in industry to develop families of similar software systems. Legacy systems, either highly configurable or with a story of versions and local variations, are potential candidates for reconfiguration as SPLs using reengineering techniques. Existing SPLs can also be restructured using specific refactorings to improve their internal quality. Although many contributions (including industrial experiences) can be found in the literature, we lack a global vision covering the whole life cycle of an evolving product line. This study aims to survey existing research on the reengineering of legacy systems into SPLs and the refactoring of existing SPLs in order to identify proven approaches and pending challenges for future research in both subfields. We launched a systematic mapping study to find as much literature as possible, covering the diverse terms involved in the search string (restructuring, refactoring, reengineering, etc. always connected with SPLs) and filtering the papers using relevance criteria. The 74 papers selected were classified with respect to several dimensions: main focus, research and contribution type, academic or industrial validation if included, etc. We classified the research approaches and analyzed their feasibility for use in industry. The results of the study indicate that the initial works focused on the adaptation of generic reengineering processes to SPL extraction. Starting from that foundation, several trends have been detected in recent research: the integrated or guided reengineering of (typically object-oriented) legacy code and requirements; specific aspect-oriented or feature-oriented refactoring into SPLs, and more recently, refactoring for the evolution of existing product lines. A majority of papers include academic or industrial case studies, though only a few are based on quantitative data. The degree of maturity of both subfields is different: Industry examples for the reengineering of the legacy system subfield are abundant, although more evaluation research is needed to provide better evidence for adoption in industry. Product line evolution through refactoring is an emerging topic with some pending challenges. Although it has recently received some attention, the theoretical foundation is rather limited in this subfield and should be addressed in the near future. To sum up, the main contributions of this work are the classification of research approaches as well as the analysis of remaining challenges, open issues, and research opportunities.},
journal = {Sci. Comput. Program.},
month = aug,
pages = {1010–1034},
numpages = {25},
keywords = {Software product line, Refactoring, Reengineering, Legacy system, Evolution}
}

@article{10.1016/j.jss.2007.10.025,
author = {Hanssen, Geir K. and F\'{\i}gri, Tor E.},
title = {Process fusion: An industrial case study on agile software product line engineering},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {6},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.10.025},
doi = {10.1016/j.jss.2007.10.025},
abstract = {This paper presents a case study of a software product company that has successfully integrated practices from software product line engineering and agile software development. We show how practices from the two fields support the company's strategic and tactical ambitions, respectively. We also discuss how the company integrates strategic, tactical and operational processes to optimize collaboration and consequently improve its ability to meet market needs, opportunities and challenges. The findings from this study are relevant to software product companies seeking ways to balance agility and product management. The findings also contribute to research on industrializing software engineering.},
journal = {J. Syst. Softw.},
month = jun,
pages = {843–854},
numpages = {12},
keywords = {Software product management, Software product line engineering, Software product development, Agile software development}
}

@inproceedings{10.5555/1753235.1753258,
author = {Ganesan, Dharmalingam and Lindvall, Mikael and Ackermann, Chris and McComas, David and Bartholomew, Maureen},
title = {Verifying architectural design rules of the flight software product line},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {This paper presents experiences of verifying architectural design rules of the NASA Core Flight Software (CFS) product line implementation. The goal is to check whether the implementation is consistent with the CFS' architectural rules derived from the developer's guide. The results indicate that consistency checking helps a) identifying architecturally significant deviations that were eluded during code reviews, b) clarifying the design rules to the team, and c) assessing the overall implementation quality. Furthermore, it helps connecting business goals to architectural principles, and to the implementation. This paper is the first step in the definition of a method for analyzing and evaluating product line implementations from an architecture-centric perspective.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {161–170},
numpages = {10},
keywords = {architectural rules, business goals, flight software, implemented architecture},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/1176617.1176733,
author = {Trask, Bruce and Paniscotti, Dominick and Roman, Angel and Bhanot, Vikram},
title = {Using model-driven engineering to complement software product line engineering in developing software defined radio components and applications},
year = {2006},
isbn = {159593491X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1176617.1176733},
doi = {10.1145/1176617.1176733},
abstract = {This paper details the application of Software Product Lines (SPL)16 and Model-Driven Engineering (MDE)15 to the software defined radio domain. More specifically it is an experience report emphasizing the synergy 17 resulting from combining MDE and SPL technologies. The software defined radio domain has very unique characteristics as its systems typically are a confluence of a number of typically challenging aspects of software development. To name a few, these systems are usually described by modifiers such as, embedded, real-time, distributed, object-oriented, portable, heterogeneous, multithreaded, high performance, dynamic, resource-constrained, safety-critical, secure, networked, component based and fault-tolerant. Each one of these modifiers by themselves carries with it a set of unique challenges, but building systems characterized by all of these modifiers all at the same time makes for a daunting task in software development. In addition to all of these, it is quite common in these embedded systems for components to have multiple implementations that must run on disparate processing elements. With all of this taken into account, it stands to reason that these systems could and should benefit greatly from advances in software technology such as product line engineering, domain-specific modeling and model-driven engineering. It is our experience that one big benefit to the software development industry is the combination of the Software Product Lines and Model Driven Engineering technologies.},
booktitle = {Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications},
pages = {846–853},
numpages = {8},
keywords = {model, language, generation, domain, development},
location = {Portland, Oregon, USA},
series = {OOPSLA '06}
}

@inproceedings{10.1109/GreenCom.2011.32,
author = {Duanmu, Zhu Yun and Yan, Jing Jing and Lee, You Fu},
title = {An Approach of Process Control in Software Product Line},
year = {2011},
isbn = {9780769544663},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GreenCom.2011.32},
doi = {10.1109/GreenCom.2011.32},
abstract = {Along with the development of software industry, softwares become much more professional and field-related, which were followed by the rapidly changing requirements as well as the increasing complexity of software products. In response to this trend, people have introduced the software product line from the traditional manufacturing to support the development of software. This paper described the general process of software development, followed by a proposal of a message-driven model of software process which included the structure model and the formalized runtime model. In addition, the way how the message-driven process is controlled has been discussed in details based on these models.},
booktitle = {Proceedings of the 2011 IEEE/ACM International Conference on Green Computing and Communications},
pages = {139–143},
numpages = {5},
keywords = {software process model, messages driven, Software product line, Software engineering},
series = {GREENCOM '11}
}

@inproceedings{10.1145/2701319.2701330,
author = {Rabiser, Rick and Vierhauser, Michael and Gr\"{u}nbacher, Paul},
title = {Variability Management for a Runtime Monitoring Infrastructure},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701330},
doi = {10.1145/2701319.2701330},
abstract = {Many software systems today are systems of systems (SoS), which are difficult to analyze due to their size, complexity, heterogeneity, and variability. For instance, unexpected behavior of SoS is often caused by the complex interactions between the involved systems and their environment at runtime. Monitoring infrastructures (MIs) provide support for engineers and support staff analyzing the behavior of SoS during development and operation. Variability plays an important role in MIs, however, while some approaches exist, managing variability of MIs remains challenging. In this paper, we describe how we applied a variability management approach to support the reconfiguration of a SoS monitoring infrastructure (MI) at runtime. Our approach provides configuration support for setting up the MI to reflect system variability. It also supports runtime reconfiguration of the MI to reflect the different monitoring tasks of users and to support evolution. We motivate our work using the case of monitoring a real-world SoS from the domain of industrial automation and discuss variability-related challenges in four monitoring scenarios. We evaluate the feasibility of our approach by applying it to these scenarios. We also demonstrate that our approach reduces manual reconfiguration effort and helps to reduce the overhead of the MI.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {35–42},
numpages = {8},
keywords = {variability management, reconfiguration, large-scale systems, Software monitoring},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@article{10.1016/j.advengsoft.2014.01.011,
author = {Rossel, Pedro O. and Bastarrica, Mar\'{\i}a Cecilia and Hitschfeld-Kahler, Nancy and D\'{\i}az, Violeta and Medina, Mario},
title = {Domain modeling as a basis for building a meshing tool software product line},
year = {2014},
issue_date = {April, 2014},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {70},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2014.01.011},
doi = {10.1016/j.advengsoft.2014.01.011},
abstract = {Meshing tools are highly complex software for generating and managing geometrical discretizations. Due to their complexity, they have generally been developed by end users - physicists, forest engineers, mechanical engineers - with ad hoc methodologies and not by applying well established software engineering practices. Different meshing tools have been developed over the years, making them a good application domain for Software Product Lines (SPLs). This paper proposes building a domain model that captures the different domain characteristics such as features, goals, scenarios and a lexicon, and the relationships among them. The model is partly specified using a formal language. The domain model captures product commonalities and variabilities as well as the particular characteristics of different SPL products. The paper presents a rigorous process for building the domain model, where specific roles, activities and artifacts are identified. This process also clearly establishes consistency and completeness conditions. The usefulness of the model and the process are validated by using them to generate a software product line of Tree Stem Deformation (TSD) meshing tools. We also present Meshing Tool Generator, a software that follows the SPL approach for generating meshing tools belonging to the TSD SPL. We show how an end user can easily generate three different TSD meshing tools using Meshing Tool Generator.},
journal = {Adv. Eng. Softw.},
month = apr,
pages = {77–89},
numpages = {13},
keywords = {Tree stem deformation, Software product line, Meshing tools, Domain model, Domain analysis, Code generator}
}

@article{10.1016/j.infsof.2007.10.013,
author = {Ahmed, Faheem and Capretz, Luiz Fernando},
title = {The software product line architecture: An empirical investigation of key process activities},
year = {2008},
issue_date = {October, 2008},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {50},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2007.10.013},
doi = {10.1016/j.infsof.2007.10.013},
abstract = {Software architecture has been a key area of concern in software industry due to its profound impact on the productivity and quality of software products. This is even more crucial in case of software product line, because it deals with the development of a line of products sharing common architecture and having controlled variability. The main contributions of this paper is to increase the understanding of the influence of key software product line architecture process activities on the overall performance of software product line by conducting a comprehensive empirical investigation covering a broad range of organizations currently involved in the business of software product lines. This is the first study to empirically investigate and demonstrate the relationships between some of the software product line architecture process activities and the overall software product line performance of an organization at the best of our knowledge. The results of this investigation provide empirical evidence that software product line architecture process activities play a significant role in successfully developing and managing a software product line.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1098–1113},
numpages = {16},
keywords = {Software product line, Software engineering, Software architecture, Empirical study, Domain engineering}
}

@article{10.1016/j.infsof.2011.01.001,
author = {Peng, Xin and Yu, Yijun and Zhao, Wenyun},
title = {Analyzing evolution of variability in a software product line: From contexts and requirements to features},
year = {2011},
issue_date = {July, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {7},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.01.001},
doi = {10.1016/j.infsof.2011.01.001},
abstract = {Context: In the long run, features of a software product line (SPL) evolve with respect to changes in stakeholder requirements and system contexts. Neither domain engineering nor requirements engineering handles such co-evolution of requirements and contexts explicitly, making it especially hard to reason about the impact of co-changes in complex scenarios. Objective: In this paper, we propose a problem-oriented and value-based analysis method for variability evolution analysis. The method takes into account both kinds of changes (requirements and contexts) during the life of an evolving software product line. Method: The proposed method extends the core requirements engineering ontology with the notions to represent variability-intensive problem decomposition and evolution. On the basis of problemorientation, the analysis method identifies candidate changes, detects influenced features, and evaluates their contributions to the value of the SPL. Results and Conclusion: The process of applying the analysis method is illustrated using a concrete case study of an evolving enterprise software system, which has confirmed that tracing back to requirements and contextual changes is an effective way to understand the evolution of variability in the software product line.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {707–721},
numpages = {15},
keywords = {Variability, Software product line, Requirements, Feature, Evolution, Context}
}

@inproceedings{10.1145/2996890.3007893,
author = {Ruiz, Carlos and Duran-Limon, Hector A. and Parlavantzas, Nikos},
title = {Towards a software product line-based approach to adapt IaaS cloud configurations},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.3007893},
doi = {10.1145/2996890.3007893},
abstract = {Cloud computing is nowadays one of the most promising IT technologies, since it provides seemingly unlimited resources on demand at low costs. Hence, different types of applications have been migrated to IaaS environments, e.g. multi-tier (distributed) applications. However, in order to benefit from such characteristics, cloud configurations (i.e. virtual resource configurations) should be designed accordingly to the necessities of the applications. Furthermore, such configurations have to provide the required resources not only at the application deployment-time, but also during the whole application execution time. Hence, adaptive paradigms are required when designing solutions to cloud applications with dynamic resource requirements. Software Product Lines (SPLs) provide great flexibility and a high level of abstraction to describe complete system configurations. Even though SPLs are not commonly used to describe changes after an initial product (configuration) has been created, their inherent characteristics can enable producing the required virtual resource configuration to adapt applications after their initial deployment, i.e., at runtime. In this paper, we present an approach to create and adapt cloud configurations at the IaaS level by using SPLs. We focus on the architectural design of our solution as well as on the possible implementation challenges we could face.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {398–403},
numpages = {6},
keywords = {software product lines, self-adaptation, cloud computing},
location = {Shanghai, China},
series = {UCC '16}
}

@article{10.1007/s10270-015-0471-3,
author = {Bonif\'{a}cio, Rodrigo and Borba, Paulo and Ferraz, Cristiano and Accioly, Paola},
title = {Empirical assessment of two approaches for specifying software product line use case scenarios},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0471-3},
doi = {10.1007/s10270-015-0471-3},
abstract = {Modularity benefits, including the independent maintenance and comprehension of individual modules, have been widely advocated. However, empirical assessments to investigate those benefits have mostly focused on source code, and thus, the relevance of modularity to earlier artifacts is still not so clear (such as requirements and design models). In this paper, we use a multimethod technique, including designed experiments, to empirically evaluate the benefits of modularity in the context of two approaches for specifying product line use case scenarios: PLUSS and MSVCM. The first uses an annotative approach for specifying variability, whereas the second relies on aspect-oriented constructs for separating common and variant scenario specifications. After evaluating these approaches through the specifications of several systems, we find out that MSVCM reduces feature scattering and improves scenario cohesion. These results suggest that evolving a product line specification using MSVCM requires only localized changes. On the other hand, the results of six experiments reveal that MSVCM requires more time to derive the product line specifications and, contrasting with the modularity results, reduces the time to evolve a product line specification only when the subjects have been well trained and are used to the task of evolving product line specifications.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {97–123},
numpages = {27},
keywords = {Usage scenarios, Software product lines, Software modularity, Requirements engineering, Experimentation in software engineering}
}

@inproceedings{10.1145/3461001.3471148,
author = {Krieter, Sebastian and Arens, Rahel and Nieke, Michael and Sundermann, Chico and He\ss{}, Tobias and Th\"{u}m, Thomas and Seidl, Christoph},
title = {Incremental construction of modal implication graphs for evolving feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471148},
doi = {10.1145/3461001.3471148},
abstract = {A feature model represents a set of variants as configurable features and dependencies between them. During variant configuration, (de)selection of a feature may entail that other features must or cannot be selected. A Modal Implication Graph (MIG) enables efficient decision propagation to perform automatic (de)selection of subsequent features. In addition, it facilitates other configuration-related activities such as t-wise sampling. Evolution of a feature model may change its configuration logic, thereby invalidating an existing MIG and forcing a full recomputation. However, repeated recomputation of a MIG is expensive, and thus hampers the overall usefulness of MIGs for frequently evolving feature models. In this paper, we devise a method to incrementally compute updated MIGs after feature model evolution. We identify expensive steps in the MIG construction algorithm, enable them for incremental computation, and measure performance compared to a full rebuild of a complete MIG within the evolution histories of four real-world feature models. Results show that our incremental method can increase the speed of MIG construction by orders of magnitude, depending on the given scenario and extent of evolutionary changes.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {64–74},
numpages = {11},
keywords = {software product line, evolution, configurable system},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.5555/2820656.2820666,
author = {Tzeremes, Vasilios and Gomaa, Hassan},
title = {A software product line approach for end user development of smart spaces},
year = {2015},
publisher = {IEEE Press},
abstract = {Several End User Development (EUD) tools have been proposed that enable end users to create software applications for smart spaces. Even though most of the tools focus on architecture and usability they don't take into account the end user background. For instance some end users are domain experts, experienced software developers, and others have very limited computer skills. Furthermore current EUD approaches do not address reuse. In this paper we present XANA, an EUD framework that extends existing EUD tools with Software Product Line (SPL) concepts. The framework targets two types of users: the application designers and the end users. Application designers create the SPL for end users. End users select SPL features and derive applications for their smart spaces. XANA promotes reuse by allowing end users to reuse features and components to create applications. We illustrate its use with examples in a smart home setting.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {23–26},
numpages = {4},
keywords = {software reuse, software product lines, smart spaces, feature modeling, end user development},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1145/1629716.1629724,
author = {Elsner, Christoph and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Product derivation for solution-driven product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629724},
doi = {10.1145/1629716.1629724},
abstract = {Solution-driven product line engineering is a project business where products are created for each customer individually. Although reuse of results from former projects is widely done, configuration and integration of the results currently is often a manual, time-consuming, and error-prone task and needs considerable knowledge about implementation details.In this paper, we elaborate and approach the challenges when giving automated support for product derivation (i.e., product configuration and generation) in a large-scale solution-driven product line context. Our PLiC approach resembles the fact that, in practice, the domain of a large product line is divided into sub-domains. A PLiC (product line component) packages all results (configuration, generation, and implementation assets) of a sub-domain and offers interfaces for configuration and generation. With our approach we tackle the challenges of using multiple and different types of configuration models and text files, give support for automated product generation, and integrate feature modeling to support application engineering as an extensive development task.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {35–41},
numpages = {7},
keywords = {feature modeling, software product line development, solution-driven software development},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {software variability, software testing, software product line, quality assurance, machine learning},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1109/ICIS.2012.43,
author = {Ryu, Duksan and Lee, Dan and Baik, Jongmoon},
title = {Designing an Architecture of SNS Platform by Applying a Product Line Engineering Approach},
year = {2012},
isbn = {9780769546940},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICIS.2012.43},
doi = {10.1109/ICIS.2012.43},
abstract = {The demand of new Social Networking Service (SNS) is high because the SNSs have been popular these days. In order to deliver various SNSs as early as possible, software product line (SPL) approach can be useful. By using the state of the practices of SPL, this paper shows how to manage commonalities and variabilities of SNS. Specifically, to make an architecture design, presented practices include: understanding relevant domains, requirements engineering, architecture definition. The strengths and weaknesses of Face book architecture are evaluated with the Architecture Tradeoff Analysis Method (ATAM). As a result of applying a framework for SPL practice, layered view and component-based view are illustrated along with variabilities represented by Product Line UML-based Software Engineering (PLUS) and Orthogonal Variability Model (OVM). Based on the analysis of requirements of SNS, additional services such as file sharing and instant messaging are represented as optional components. In case of Face book, three key quality attributes, i.e., availability, scalability, and privacy are analyzed by using quality attribute utility tree. We identified that Face book employs client-server architecture. Through ATAM, Peer-to-Peer (P2P) approach promoting privacy is explained.},
booktitle = {Proceedings of the 2012 IEEE/ACIS 11th International Conference on Computer and Information Science},
pages = {559–564},
numpages = {6},
keywords = {software product line, social networking service, architecture evaluation, architecture design},
series = {ICIS '12}
}

@inproceedings{10.1145/2602458.2602460,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Injecting quality attributes into software architectures with the common variability language},
year = {2014},
isbn = {9781450325776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2602458.2602460},
doi = {10.1145/2602458.2602460},
abstract = {Quality attributes that add new behavior to the functional software architecture are known as functional quality attributes (FQAs). These FQAs are applied to pieces of software from small components to entire systems, usually crosscutting some of them. Due to this crosscutting nature, modeling them separately from the base application has many advantages (e.g. reusability, less coupled architectures). However, different applications may require different configurations of an FQA (e.g. different levels of security), so we need a language that: (i) easily expresses the variability of the FQAs at the architectural level; and that (ii) also facilitates the automatic generation of architectural configurations with custom-made FQAs. In this sense, the Common Variability Language (CVL) is extremely suited for use at the architectural level, not requiring the use of a particular architectural language to model base functional requirements. In this paper we propose a method based on CVL to: (i) model separately and generate FQAs customized to the application requirements; (ii) automatically inject customized FQA components into the architecture of the applications. We quantitatively evaluate our approach and discuss its benefits with a case study.},
booktitle = {Proceedings of the 17th International ACM Sigsoft Symposium on Component-Based Software Engineering},
pages = {35–44},
numpages = {10},
keywords = {weaving, variability, spl, quality attributes, cvl},
location = {Marcq-en-Bareul, France},
series = {CBSE '14}
}

@inproceedings{10.1109/WICSA.2014.11,
author = {Smiley, Karen and Mahate, Shakeel and Wood, Paul},
title = {A Dynamic Software Product Line Architecture for Prepackaged Expert Analytics: Enabling Efficient Capture, Reuse and Adaptation of Operational Knowledge},
year = {2014},
isbn = {9781479934126},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WICSA.2014.11},
doi = {10.1109/WICSA.2014.11},
abstract = {Advanced asset health management solutions blend business intelligence with analytics that incorporate expert operational knowledge of industrial equipment and systems. Key challenges in developing these solutions include: streamlining the capture and prepackaging of operational experts' knowledge as analytic modules, efficiently evolving the modules as knowledge grows, adapting the analytics in the field for diverse operating circumstances and industries, and executing the analytics with high performance in industrial and enterprise software systems. A Quality Attribute Workshop (QAW) was used to elicit and analyze variability at development time and runtime for creating, integrating, evolving, and tailoring reusable analytic modules for ABB/Ventyx asset health solution offerings. Dynamic software product line (DSPL) architecture approaches were then applied in designing an analytics plug in architecture for asset health solutions. This paper describes our approach and experiences in designing the analytics product line architecture and its SME Workbench toolset, and how we achieved significant improvements in speed and flexibility of deploying industrial analytics.},
booktitle = {Proceedings of the 2014 IEEE/IFIP Conference on Software Architecture},
pages = {205–214},
numpages = {10},
keywords = {reusability, performance, knowledge, interoperability, industrial software systems, industrial analytics, extensibility, dynamic software product line, asset health},
series = {WICSA '14}
}

@article{10.1016/j.eswa.2012.01.109,
author = {Heradio, Ruben and Fernandez-Amoros, David and Torre-Cubillo, Luis and Perez Garcia-Plaza, Alberto},
title = {Improving the accuracy of COPLIMO to estimate the payoff of a software product line},
year = {2012},
issue_date = {July, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {39},
number = {9},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2012.01.109},
doi = {10.1016/j.eswa.2012.01.109},
abstract = {Software product line engineering pursues the efficient development of families of similar products. COPLIMO is an economic model that relies on COCOMO II to estimate the benefits of adopting a product line approach compared to developing the products one by one. Although COPLIMO is an ideal economic model to support decision making on the incremental development of a product line, it makes some simplifying assumptions that may produce high distortions in the estimates (e.g., COPLIMO takes for granted that all the products have the same size). This paper proposes a COPLIMO reformulation that avoids such assumptions and, consequently, improves the accuracy of the estimates. To support our proposal, we present an algorithm that infers the additional information that our COPLIMO reformulation requires from feature diagrams, which is a widespread notation to model the domain of a product line.},
journal = {Expert Syst. Appl.},
month = jul,
pages = {7919–7928},
numpages = {10},
keywords = {Software product line, Product counting, Feature diagram, Economic model, Decision support}
}

@article{10.1007/s10515-011-0099-7,
author = {Bagheri, Ebrahim and Ensan, Faezeh and Gasevic, Dragan},
title = {Decision support for the software product line domain engineering lifecycle},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0099-7},
doi = {10.1007/s10515-011-0099-7},
abstract = {Software product line engineering is a paradigm that advocates the reusability of software engineering assets and the rapid development of new applications for a target domain. These objectives are achieved by capturing the commonalities and variabilities between the applications of the target domain and through the development of comprehensive and variability-covering feature models. The feature models developed within the software product line development process need to cover the relevant features and aspects of the target domain. In other words, the feature models should be elaborate representations of the feature space of that domain. Given that feature models, i.e., software product line feature models, are developed mostly by domain analysts by sifting through domain documentation, corporate records and transcribed interviews, the process is a cumbersome and error-prone one. In this paper, we propose a decision support platform that assists domain analysts throughout the domain engineering lifecycle by: (1) automatically performing natural language processing tasks over domain documents and identifying important information for the domain analysts such as the features and integrity constraints that exist in the domain documents; (2) providing a collaboration platform around the domain documents such that multiple domain analysts can collaborate with each other during the process using a Wiki; (3) formulating semantic links between domain terminology with external widely used ontologies such as WordNet in order to disambiguate the terms used in domain documents; and (4) developing traceability links between the unstructured information available in the domain documents and their formal counterparts within the formal feature model representations. Results obtained from our controlled experimentations show that the decision support platform is effective in increasing the performance of the domain analysts during the domain engineering lifecycle in terms of both the coverage and accuracy measures.},
journal = {Automated Software Engg.},
month = sep,
pages = {335–377},
numpages = {43},
keywords = {Software product lines, NLP model inference, Feature models, Domain engineering}
}

@article{10.4018/ijismd.2014070103,
author = {Lotz, Alex and Ingl\'{e}s-Romero, Juan F. and Stampfer, Dennis and Lutz, Matthias and Vicente-Chicote, Cristina and Schlegel, Christian},
title = {Towards a Stepwise Variability Management Process for Complex Systems: A Robotics Perspective},
year = {2014},
issue_date = {July 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {3},
issn = {1947-8186},
url = {https://doi.org/10.4018/ijismd.2014070103},
doi = {10.4018/ijismd.2014070103},
abstract = {Complex systems are executed in environments with a huge number of potential situations and contingencies, therefore a mechanism is required to express dynamic variability at design-time that can be efficiently resolved in the application at run-time based on the then available information. We present an approach for dynamic variability modeling and its exploitation at run-time. It supports different developer roles and allows the separation of two different kinds of dynamic variability at design-time: (i) variability related to the system operation, and (ii) variability associated with QoS. The former provides robustness to contingencies, maintaining a high success rate in task fulfillment. The latter focuses on the quality of the application execution (defined in terms of non-functional properties like safety or task efficiency) under changing situations and limited resources. The authors also discuss different alternatives for the run-time integration of the two variability management mechanisms, and show real-world robotic examples to illustrate them.},
journal = {Int. J. Inf. Syst. Model. Des.},
month = jul,
pages = {55–74},
numpages = {20},
keywords = {Variability Management, VML, SmartTCL, Service Robotics, Modeling Run-Time Variability}
}

@article{10.1016/j.infsof.2010.05.011,
author = {Engstr\"{o}m, Emelie and Runeson, Per},
title = {Software product line testing - A systematic mapping study},
year = {2011},
issue_date = {January, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {1},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.05.011},
doi = {10.1016/j.infsof.2010.05.011},
abstract = {Context: Software product lines (SPL) are used in industry to achieve more efficient software development. However, the testing side of SPL is underdeveloped. Objective: This study aims at surveying existing research on SPL testing in order to identify useful approaches and needs for future research. Method: A systematic mapping study is launched to find as much literature as possible, and the 64 papers found are classified with respect to focus, research type and contribution type. Results: A majority of the papers are of proposal research types (64%). System testing is the largest group with respect to research focus (40%), followed by management (23%). Method contributions are in majority. Conclusions: More validation and evaluation research is needed to provide a better foundation for SPL testing.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {2–13},
numpages = {12},
keywords = {Testing, Systematic mapping, Systematic literature review, Software product line testing}
}

@inproceedings{10.1145/3461001.3471152,
author = {Silva, Publio and Bezerra, Carla I. M. and Machado, Ivan},
title = {A machine learning model to classify the feature model maintainability},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471152},
doi = {10.1145/3461001.3471152},
abstract = {Software Product Lines (SPL) are generally specified using a Feature Model (FM), an artifact designed in the early stages of the SPL development life cycle. This artifact can quickly become too complex, which makes it challenging to maintain an SPL. Therefore, it is essential to evaluate the artifact's maintainability continuously. The literature brings some approaches that evaluate FM maintainability through the aggregation of maintainability measures. Machine Learning (ML) models can be used to create these approaches. They can aggregate the values of independent variables into a single target data, also called a dependent variable. Besides, when using white-box ML models, it is possible to interpret and explain the ML model results. This work proposes white-box ML models intending to classify the FM maintainability based on 15 measures. To build the models, we performed the following steps: (i) we compared two approaches to evaluate the FM maintainability through a human-based oracle of FM maintainability classifications; (ii) we used the best approach to pre-classify the ML training dataset; (iii) we generated three ML models and compared them against classification accuracy, precision, recall, F1 and AUC-ROC; and, (iv) we used the best model to create a mechanism capable of providing improvement indicators to domain engineers. The best model used the decision tree algorithm that obtained accuracy, precision, and recall of 0.81, F1-Score of 0.79, and AUC-ROC of 0.91. Using this model, we could reduce the number of measures needed to evaluate the FM maintainability from 15 to 9 measures.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {35–45},
numpages = {11},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1016/j.jss.2013.12.038,
author = {Capilla, Rafael and Bosch, Jan and Trinidad, Pablo and Ruiz-Cort\'{e}s, Antonio and Hinchey, Mike},
title = {An overview of Dynamic Software Product Line architectures and techniques: Observations from research and industry},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.12.038},
doi = {10.1016/j.jss.2013.12.038},
abstract = {Over the last two decades, software product lines have been used successfully in industry for building families of systems of related products, maximizing reuse, and exploiting their variable and configurable options. In a changing world, modern software demands more and more adaptive features, many of them performed dynamically, and the requirements on the software architecture to support adaptation capabilities of systems are increasing in importance. Today, many embedded system families and application domains such as ecosystems, service-based applications, and self-adaptive systems demand runtime capabilities for flexible adaptation, reconfiguration, and post-deployment activities. However, as traditional software product line architectures fail to provide mechanisms for runtime adaptation and behavior of products, there is a shift toward designing more dynamic software architectures and building more adaptable software able to handle autonomous decision-making, according to varying conditions. Recent development approaches such as Dynamic Software Product Lines (DSPLs) attempt to face the challenges of the dynamic conditions of such systems but the state of these solution architectures is still immature. In order to provide a more comprehensive treatment of DSPL models and their solution architectures, in this research work we provide an overview of the state of the art and current techniques that, partially, attempt to face the many challenges of runtime variability mechanisms in the context of Dynamic Software Product Lines. We also provide an integrated view of the challenges and solutions that are necessary to support runtime variability mechanisms in DSPL models and software architectures.},
journal = {J. Syst. Softw.},
month = may,
pages = {3–23},
numpages = {21},
keywords = {Software architecture, Feature models, Dynamic variability, Dynamic Software Product Lines}
}

@inproceedings{10.1109/SBCARS.2015.14,
author = {Waku, Gustavo M. and Bollis, Edson R. and Rubira, Cecilia M. F. and Torres, Ricardo da S.},
title = {A Robust Software Product Line Architecture for Data Collection in Android Platform},
year = {2015},
isbn = {9781467396301},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBCARS.2015.14},
doi = {10.1109/SBCARS.2015.14},
abstract = {Android is an open platform, developed by Google and Open Mobile Handset Alliance targeting mobile devices. Its constant evolution and increasing cost reduction made them suitable for complex applications especially for data collection applications. Data collection is a domain which evolved to use mobile devices to collect information, targeting different fields of study including: physical and social sciences, humanities, business, demographic surveys, agriculture, biology, and geology. Android usually runs on different hardware and software domains with similar functional and non-functional features. The data collection domain has a lot of sub-domains, creating an opportunity to explore software variability and quality properties such as reliability, availability, and data integrity using Component-Based Development (CBD), Fault Tolerance Techniques and Software Product Line (SPL) with Aspect-Oriented Software Development (AOSD). However, the use of mobile application for data collection poses some challenges like severe hardware restrictions (such as limited power processing and short battery lifetime) and the use of sophisticated techniques can negatively impact in application performance, and quality properties. In this work, these issues were addressed by proposing the development of a robust SPL architecture called Robust SPL for Data Collection (R-SPL-DC) and a real application called E-Phenology Collector for data collection domain to assess the use fault tolerance techniques, CBD, SPL, and AOSD to ensure availability, reliability, and data integrity without significant impacts on the overall performance of the mobile device. The results have shown that the use of R-SPL-DC is promising and suits the requirements for data collection domain.},
booktitle = {Proceedings of the 2015 IX Brazilian Symposium on Components, Architectures and Reuse Software},
pages = {31–39},
numpages = {9},
keywords = {software architecture, fault tolerance, data collection, aspects, android},
series = {SBCARS '15}
}

@inproceedings{10.1145/2304676.2304679,
author = {Klatt, Benjamin and K\"{u}ster, Martin},
title = {Respecting component architecture to migrate product copies to a software product line},
year = {2012},
isbn = {9781450313483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304676.2304679},
doi = {10.1145/2304676.2304679},
abstract = {Software product lines (SPL) are a well-known concept to efficiently develop product variants. However, migrating existing, customised product copies to a product line is still an open issue due to the required comprehension of differences among products and SPL design decisions. Most existing SPL approaches are focused on forward engineering. Only few aim to handle SPL evolution, but even those lack support of variability reverse engineering, which is necessary for migrating product copies to a product line. In this paper, we present how component architecture information can be used to enhance a variabilty reverse engineering process to target this challenge and show the relevance of component architecture in the individual requirements on the resulting SPL. We further provide an illustrating example to show how the concept is applied.},
booktitle = {Proceedings of the 17th International Doctoral Symposium on Components and Architecture},
pages = {7–12},
numpages = {6},
keywords = {software product line, reverse engineering, component architecture},
location = {Bertinoro, Italy},
series = {WCOP '12}
}

@inproceedings{10.1145/2430502.2430529,
author = {Zhang, Bo and Becker, Martin},
title = {Mining complex feature correlations from software product line configurations},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430529},
doi = {10.1145/2430502.2430529},
abstract = {As a Software Product Line (SPL) evolves with increasing number of features and feature values, the feature correlations become extremely intricate, and the specifications of these correlations tend to be either incomplete or inconsistent with their realizations, causing misconfigurations in practice. In order to guide product configuration processes, we present a solution framework to recover complex feature correlations from existing product configurations. These correlations are further pruned automatically and validated by domain experts. During implementation, we use association mining techniques to automatically extract strong association rules as potential feature correlations. This approach is evaluated using a large-scale industrial SPL in the embedded system domain, and finally we identify a large number of complex feature correlations.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {7},
keywords = {product line configuration, feature correlation, association mining},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.5555/1753235.1753272,
author = {Dordowsky, Frank and Hipp, Walter},
title = {Adopting software product line principles to manage software variants in a complex avionics system},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Eurocopter is the majority partner in NH Industries, the international consortium that develops and produces the medium weight multi-role helicopter NH90. AgustaWestland and Stork Fokker are additional partners. The NH90 has been successfully sold to 14 nations and their armed forces. The software division at Eurocopter Germany develops the on-board software for three computers of the NH90 avionics CORE and MISSION Systems. The growing number of customers and their specific application domains for the NH90 has led to an increasing number of functionally different helicopter variants. Moreover, during the long development time that is typical for complex military avionics projects, the computing technology has changed considerably over time so that the current operational software has to fit to several processor architectures. In order to cope with the high number of software variants and technology variations, the NH90 software team developed concepts and strategies for SW architecture and tool modifications based on Software Product Line (SPL) principles.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {265–274},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1007/978-3-642-34059-8_10,
author = {Haber, Arne and Rendel, Holger and Rumpe, Bernhard and Schaefer, Ina},
title = {Evolving delta-oriented software product line architectures},
year = {2012},
isbn = {9783642340581},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34059-8_10},
doi = {10.1007/978-3-642-34059-8_10},
abstract = {Diversity is prevalent in modern software systems. Several system variants exist at the same time in order to adapt to changing user requirements. Additionally, software systems evolve over time in order to adjust to unanticipated changes in their application environment. In modern software development, software architecture modeling is an important means to deal with system complexity by architectural decomposition. This leads to the need of architectural description languages that can represent spatial and temporal variability. In this paper, we present delta modeling of software architectures as a uniform modeling formalism for architectural variability in space and in time. In order to avoid degeneration of the product line model under system evolution, we present refactoring techniques to maintain and improve the quality of the variability model. Using a running example from the automotive domain, we evaluate our approach by carrying out a case study that compares delta modeling with annotative variability modeling.},
booktitle = {Proceedings of the 17th Monterey Conference on Large-Scale Complex IT Systems: Development, Operation and Management},
pages = {183–208},
numpages = {26},
location = {Oxford, UK}
}

@article{10.5555/2336353.2336359,
author = {Dai, Lirong and Bai, Yan},
title = {A nonfunctional requirement tradeoff analysis approach for software product line architecture design},
year = {2011},
issue_date = {August 2011},
publisher = {IOS Press},
address = {NLD},
volume = {11},
number = {3, Supplement 1},
issn = {1472-7978},
abstract = {Software product line development paradigm allows the development of intensive products simultaneously. Nonfunctional requirement analysis for the paradigm is a challenge problem, mainly due to the massive products that are involved. Especially in the situation where some products' nonfunctional requirements are not met, how do architects keep the revision, and the impact caused by the revision both minimal? This paper investigates the issue of nonfunctional requirement tradeoff analysis for software product lines at the architecture design stage, and proposes an architectural approach to assist architects in making optimal revision decisions based on nonfunctional tradeoff analysis results. In particular, the nonfunctional requirement supported in the approach at this stage is performance. The little's law has been adopted to support performance analysis for software product line architecture design. A Unified Modeling Language profile is also developed to support performance modeling for software product line architecture design, thus to facilitate architectural performance analysis.},
journal = {J. Comp. Methods in Sci. and Eng.},
month = aug,
pages = {65–76},
numpages = {12},
keywords = {tradeoff analysis, software product line, nonfunctional requirements}
}

@article{10.1007/s11219-011-9156-5,
author = {Roos-Frantz, Fabricia and Benavides, David and Ruiz-Cort\'{e}s, Antonio and Heuer, Andr\'{e} and Lauenroth, Kim},
title = {Quality-aware analysis in product line engineering with the orthogonal variability model},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9156-5},
doi = {10.1007/s11219-011-9156-5},
abstract = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e.g., CPU and memory consumption) and constraints on these attributes (e.g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e.g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i.e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e.g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions.},
journal = {Software Quality Journal},
month = sep,
pages = {519–565},
numpages = {47},
keywords = {Software product lines, Quality-aware analysis, Quality modelling, Orthogonal variability model, Automated analysis}
}

@inproceedings{10.1145/2430502.2430511,
author = {Kolesnikov, Sergiy S. and Apel, Sven and Siegmund, Norbert and Sobernig, Stefan and K\"{a}stner, Christian and Senkaya, Semah},
title = {Predicting quality attributes of software product lines using software and network measures and sampling},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430511},
doi = {10.1145/2430502.2430511},
abstract = {Software product-line engineering aims at developing families of related products that share common assets to provide customers with tailor-made products. Customers are often interested not only in particular functionalities (i.e., features), but also in non-functional quality attributes, such as performance, reliability, and footprint. Measuring quality attributes of all products of a product line usually does not scale. In this research-in-progress report, we propose a systematic approach aiming at efficient and scalable prediction of quality attributes of products. To this end, we establish predictors for certain categories of quality attributes (e.g., a predictor for high memory consumption) based on software and network measures, and receiver operating characteristic analysis. We use these predictors to guide a sampling process that takes the assets of a product line as input and determines the products that fall into the category denoted by the given predictor (e.g., products with high memory consumption). We propose to use predictors to make the process of finding "acceptable" products more efficient. We discuss and compare several strategies to incorporate predictors in the sampling process.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {5},
keywords = {software product lines, sampling, quality attributes, prediction, metrics},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1109/ICWS.2015.20,
author = {Gamez, Nadia and El Haddad, Joyce and Fuentes, Lidia},
title = {SPL-TQSSS: A Software Product Line Approach for Stateful Service Selection},
year = {2015},
isbn = {9781467372725},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICWS.2015.20},
doi = {10.1109/ICWS.2015.20},
abstract = {An important problem in Web services composition process is optimal selection of services meeting the user functional requirements (tasks of a workflow) and ensuring a reliable execution of the composition. Therefore, non-functional properties of services such as their transactional behavior as well as their Quality of Service (QoS) must be considered. In this context, a challenging objective is to assist users in integrating on the fly the operations of services to realize their required tasks by further meeting their transactional and QoS preferences. Towards this purpose, we present SPLTQSSS, a Software Product Line based approach for Stateful (conversation-based) Service Selection problem with Transactional and QoS support. SPL-TQSSS considers the set of functionally-equivalent services as part of a service family by modeling their internal operations using Feature Models. Then, SPL-TQSSS chooses the best services, from the service families matching with every task of the workflow, which fit with the user transactional preference and satisfy QoS constraints.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Web Services},
pages = {73–80},
numpages = {8},
keywords = {Variability, Transactional, Software Product Line, Service Selection, QoS, Feature Model},
series = {ICWS '15}
}

@inproceedings{10.5555/2022115.2022131,
author = {Wu, Yijian and Peng, Xin and Zhao, Wenyun},
title = {Architecture evolution in software product line: an industrial case study},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A software product line (SPL) usually involves a shared set of core assets and a series of application products. To ensure consistency, the evolution of the core assets and all the application products should be coordinated and synchronized under a unified evolution process. Therefore, SPL evolution often involves cross-product propagation and synchronization besides application derivation based on core assets, presenting quite different characteristic from the evolution of individual software products. As software architectures, including the product line architecture (PLA) and application architectures, play a central role in SPL engineering and evolution, architecture-based evolution analysis is a natural way for analyzing and managing SPL evolution. In this paper, we explore common practices of architecture evolution and the rationale behind in industrial SPL development. To this end, we conduct a case study with Wingsoft examination system product line (WES-PL), an industrial product line with an evolution history of eight years and more than 10 application products. In the case study, we reviewed the evolution history of WES-PL architecture and analyzed several typical evolution cases. Based on the historical analysis, we identify some special problems in industrial SPL practice from the aspect of architecture evolution and summarize some useful experiences about SPL evolution decisions to complement classical SPL methodology. On the other hand, we also propose some possible improvements for the evolution management in WES-PL.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {135–150},
numpages = {16},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1145/3461001.3461660,
author = {Michelon, Gabriela Karoline and Obermann, David and Assun\c{c}\~{a}o, Wesley K. G. and Linsbauer, Lukas and Gr\"{u}nbacher, Paul and Egyed, Alexander},
title = {Managing systems evolving in space and time: four challenges for maintenance, evolution and composition of variants},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3461660},
doi = {10.1145/3461001.3461660},
abstract = {Software companies need to provide a large set of features satisfying functional and non-functional requirements of diverse customers, thereby leading to variability in space. Feature location techniques have been proposed to support software maintenance and evolution in space. However, so far only one feature location technique also analyses the evolution in time of system variants, which is required for feature enhancements and bug fixing. Specifically, existing tools for managing a set of systems over time do not offer proper support for keeping track of feature revisions, updating existing variants, and creating new product configurations based on feature revisions. This paper presents four challenges concerning such capabilities for feature (revision) location and composition of new product configurations based on feature/s (revisions). We also provide a benchmark containing a ground truth and support for computing metrics. We hope that this will motivate researchers to provide and evaluate tool-supported approaches aiming at managing systems evolving in space and time. Further, we do not limit the evaluation of techniques to only this benchmark: we introduce and provide instructions on how to use a benchmark extractor for generating ground truth data for other systems. We expect that the feature (revision) location techniques maximize information retrieval in terms of precision, recall, and F-score, while keeping execution time and memory consumption low.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {75–80},
numpages = {6},
keywords = {software product line, repository mining, feature revision, feature location, benchmark extractor},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2491627.2491655,
author = {Dumitrescu, Cosmin and Mazo, Raul and Salinesi, Camille and Dauron, Alain},
title = {Bridging the gap between product lines and systems engineering: an experience in variability management for automotive model based systems engineering},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491655},
doi = {10.1145/2491627.2491655},
abstract = {We present in this paper an experience in modeling a family of parking brake systems, with shared assets and alternative solutions, and relate them to the needs of Renault in terms of variability management. The models are realized using a set of customized tools for model based systems engineering and variability management, based on SysML models. The purpose is to present an industrial context that requires the adoption of a product line approach and of variability modeling techniques, outside of a pure-software domain. At Renault, the interest is in identifying variations and reuse opportunities early in the product development cycle, as well as in preparing vehicle configuration specifications during the systems engineering process. This would lead to lowering the engineering effort and to higher quality and confidence in carry-over and carry across based solutions. We advocate for a tight integration of variability management with the model based systems engineering approach, which needs to address methodological support, modeling techniques and efficient tools for interactive configuration, adapted for engineering activities.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {254–263},
numpages = {10},
keywords = {variability management, systems engineering},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.5555/2399776.2399785,
author = {Bagheri, Ebrahim and Ensan, Faezeh and Gasevic, Dragan},
title = {Grammar-based test generation for software product line feature models},
year = {2012},
publisher = {IBM Corp.},
address = {USA},
abstract = {Product lines are often employed for the facilitation of software re-use, rapid application development and increase in productivity. Despite the numerous advantages of software product lines, the task of testing them is a cumbersome process due to the fact that the number of applications that need to be tested is exponential to the number of features represented in the product line. In this paper, we attempt to reduce the number of required tests for testing a software product line while at the same time preserving an acceptable fault coverage. For this purpose, we introduce eight coverage criteria based on the transformation of software product line feature models into formal context-free grammars. The theoretical foundation for the proposed coverage criteria is based on the development of equivalence partitions on the software product line configuration space and the use of boundary value analysis for test suite generation. We have performed experiments on several SPLOT feature models, the results of which show that the test suite generation strategies based on the proposed coverage criteria are effective in significantly reducing the number of required tests and at the same time maintaining a high fault coverage ratio.},
booktitle = {Proceedings of the 2012 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {87–101},
numpages = {15},
location = {Toronto, Ontario, Canada},
series = {CASCON '12}
}

@inproceedings{10.5555/2337223.2337302,
author = {Cordy, Maxime and Classen, Andreas and Perrouin, Gilles and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel},
title = {Simulation-based abstractions for software product-line model checking},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Software Product Line (SPL) engineering is a software engineering paradigm that exploits the commonality between similar software products to reduce life cycle costs and time-to-market. Many SPLs are critical and would benefit from efficient verification through model checking. Model checking SPLs is more difficult than for single systems, since the number of different products is potentially huge. In previous work, we introduced Featured Transition Systems (FTS), a formal, compact representation of SPL behaviour, and provided efficient algorithms to verify FTS. Yet, we still face the state explosion problem, like any model checking-based verification. Model abstraction is the most relevant answer to state explosion. In this paper, we define a novel simulation relation for FTS and provide an algorithm to compute it. We extend well-known simulation preservation properties to FTS and thus lay the theoretical foundations for abstraction-based model checking of SPLs. We evaluate our approach by comparing the cost of FTS-based simulation and abstraction with respect to product-by-product methods. Our results show that FTS are a solid foundation for simulation-based model checking of SPL.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {672–682},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1007/978-3-642-12107-4_8,
author = {Alf\'{e}rez, Mauricio and Santos, Jo\~{a}o and Moreira, Ana and Garcia, Alessandro and Kulesza, Uir\'{a} and Ara\'{u}jo, Jo\~{a}o and Amaral, Vasco},
title = {Multi-view composition language for software product line requirements},
year = {2009},
isbn = {3642121063},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12107-4_8},
doi = {10.1007/978-3-642-12107-4_8},
abstract = {Composition of requirements models in Software Product Line (SPL) development enables stakeholders to derive the requirements of target software products and, very important, to reason about them. Given the growing complexity of SPL development and the various stakeholders involved, their requirements are often specified from heterogeneous, partial views. However, existing requirements composition languages are very limited to generate specific requirements views for SPL products. They do not provide specialized composition rules for referencing and composing elements in recurring requirements models, such as use cases and activity models. This paper presents a multi-view composition language for SPL requirements, the Variability Modeling Language for Requirements (VML4RE). This language describes how requirements elements expressed in different models should be composed to generate a specific SPL product. The use of VML4RE is illustrated with UML-based requirements models defined for a home automation SPL case study. The language is evaluated with additional case studies from different application domains, such as mobile phones and sales management.},
booktitle = {Proceedings of the Second International Conference on Software Language Engineering},
pages = {103–122},
numpages = {20},
keywords = {variability management, software product lines, requirements reuse, requirements engineering, cmposition languages},
location = {Denver, CO},
series = {SLE'09}
}

@article{10.1016/j.scico.2012.02.006,
author = {Ganesan, Dharmalingam and Lindvall, Mikael and Mccomas, David and Bartholomew, Maureen and Slegel, Steve and Medina, Barbara and Krikhaar, Rene and Verhoef, Chris and Montgomery, Lisa P.},
title = {An analysis of unit tests of a flight software product line},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.02.006},
doi = {10.1016/j.scico.2012.02.006},
abstract = {This paper presents an analysis of the unit testing approach developed and used by the Core Flight Software System (CFS) product line team at the NASA Goddard Space Flight Center (GSFC). The goal of the analysis is to understand, review, and recommend strategies for improving the CFS' existing unit testing infrastructure as well as to capture lessons learned and best practices that can be used by other software product line (SPL) teams for their unit testing. The results of the analysis show that the core and application modules of the CFS are unit tested in isolation using a stub framework developed by the CFS team. The application developers can unit test their code without waiting for the core modules to be completed, and vice versa. The analysis found that this unit testing approach incorporates many practical and useful solutions such as allowing for unit testing without requiring hardware and special OS features in-the-loop by defining stub implementations of dependent modules. These solutions are worth considering when deciding how to design the testing architecture for a SPL.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2360–2380},
numpages = {21},
keywords = {Unit testing, Stub, Software architecture, Self-testable components, Metrics, Flight software}
}

@phdthesis{10.5555/1354263,
author = {Ahmed, Faheem},
title = {Process maturity model for software product line},
year = {2007},
isbn = {9780494307748},
publisher = {University of Western Ontario},
address = {CAN},
abstract = {The recent trend of switching from single software product development to lines of software products in the software industry has made the software product line concept viable. As a result of its popularity, a methodology is required for the process assessment of software product lines. Although researchers and practitioners understand that current software process assessment approaches cannot be directly applied to assess the software product line process, apart from some initial conceptual work, no direct methodology has yet been proposed. The primary purpose of this research is to study the software product line process and to put forward a Process Maturity Model for Software Product Line in order to fill the research gap of a process maturity assessment methodology. The maturity models for business, organization, and architecture are proposed in this research so as to cover the three essential dimensions of the software product line process. Three separate empirical investigations are conducted to determine certain key factors that contribute to and have an impact on the performance of the business, organization, and architecture dimensions of the software product line. The methodology to evaluate an organization's maturity profile once the assessment results of the individual dimensions like business, architecture, process, and organization are evident is also an integral feature of this  Process Maturity Model for Software Product Line. This work further contributes to defining the overall maturity level scales for the software product line process. The Process Maturity Model for Software Product Line will assist organizations in carrying out process assessment of the software product line in order to determine the capability of the organization to define, manage, and control the software product line process. Keywords. software product line, software process assessment, software architecture, software engineering economics, organizational management and fuzzy logic.},
note = {AAINR30774}
}

@article{10.1016/j.infsof.2012.08.010,
author = {Mahdavi-Hezavehi, Sara and Galster, Matthias and Avgeriou, Paris},
title = {Variability in quality attributes of service-based software systems: A systematic literature review},
year = {2013},
issue_date = {February, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.08.010},
doi = {10.1016/j.infsof.2012.08.010},
abstract = {Context: Variability is the ability of a software artifact (e.g., a system, component) to be adapted for a specific context, in a preplanned manner. Variability not only affects functionality, but also quality attributes (e.g., security, performance). Service-based software systems consider variability in functionality implicitly by dynamic service composition. However, variability in quality attributes of service-based systems seems insufficiently addressed in current design practices. Objective: We aim at (a) assessing methods for handling variability in quality attributes of service-based systems, (b) collecting evidence about current research that suggests implications for practice, and (c) identifying open problems and areas for improvement. Method: A systematic literature review with an automated search was conducted. The review included studies published between the year 2000 and 2011. We identified 46 relevant studies. Results: Current methods focus on a few quality attributes, in particular performance and availability. Also, most methods use formal techniques. Furthermore, current studies do not provide enough evidence for practitioners to adopt proposed approaches. So far, variability in quality attributes has mainly been studied in laboratory settings rather than in industrial environments. Conclusions: The product line domain as the domain that traditionally deals with variability has only little impact on handling variability in quality attributes. The lack of tool support, the lack of practical research and evidence for the applicability of approaches to handle variability are obstacles for practitioners to adopt methods. Therefore, we suggest studies in industry (e.g., surveys) to collect data on how practitioners handle variability of quality attributes in service-based systems. For example, results of our study help formulate hypotheses and questions for such surveys. Based on needs in practice, new approaches can be proposed.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {320–343},
numpages = {24},
keywords = {Variability, Systematic literature review, Service-based systems, Quality attributes}
}

@inproceedings{10.1109/SBCARS.2010.13,
author = {Oliveira Junior, Edson A. and Maldonado, Jose C. and Gimenes, Itana M. S.},
title = {Empirical Validation of Complexity and Extensibility Metrics for Software Product Line Architectures},
year = {2010},
isbn = {9780769542591},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBCARS.2010.13},
doi = {10.1109/SBCARS.2010.13},
abstract = {The software product line (PL) architecture (PLA) is one of the most important PL core assets as it is the abstraction of the products that can be generated, and it represents similarities and variabilities of a PL. Its quality attributes analysis and evaluation can serve as a basis for analyzing the managerial and economical values of a PL. We proposed metrics for PLA complexity and extensibility quality attributes. This paper is concerned with the empirical validation of such metrics. As a result of the experimental work we can conclude that the metrics are relevant indicators of complexity and extensibility of PLA by presenting their correlation analysis.},
booktitle = {Proceedings of the 2010 Fourth Brazilian Symposium on Software Components, Architectures and Reuse},
pages = {31–40},
numpages = {10},
keywords = {software product line, product line architecture, metrics, extensibility, empirical validation, complexity},
series = {SBCARS '10}
}

@article{10.1016/j.infsof.2012.11.008,
author = {Krishnan, Sandeep and Strasburg, Chris and Lutz, Robyn R. and Goseva-Popstojanova, Katerina and Dorman, Karin S.},
title = {Predicting failure-proneness in an evolving software product line},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.11.008},
doi = {10.1016/j.infsof.2012.11.008},
abstract = {ContextPrevious work by researchers on 3years of early data for an Eclipse product has identified some predictors of failure-prone files that work well. Eclipse has also been used previously by researchers to study characteristics of product line software. ObjectiveThe work reported here investigates whether classification-based prediction of failure-prone files improves as the product line evolves. MethodThis investigation first repeats, to the extent possible, the previous study and then extends it by including four more recent years of data, comparing the prominent predictors with the previous results. The research then looks at the data for three additional Eclipse products as they evolve over time. The analysis compares results from three different types of datasets with alternative data collection and prediction periods. ResultsOur experiments with a variety of learners show that the difference between the performance of J48, used in this work, and the other top learners is not statistically significant. Furthermore, new results show that the effectiveness of classification significantly depends on the data collection period and prediction period. The study identifies change metrics that are prominent predictors across all four releases of all four products in the product line for the three different types of datasets. From the product line perspective, prediction of failure-prone files for the four products studied in the Eclipse product line shows statistically significant improvement in accuracy but not in recall across releases. ConclusionAs the product line matures, the learner performance improves significantly for two of the three datasets, but not for prediction of post-release failure-prone files using only pre-release change data. This suggests that it may be difficult to detect failure-prone files in the evolving product line. At least in part, this may be due to the continuous change, even for commonalities and high-reuse variation components, which we previously have shown to exist.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1479–1495},
numpages = {17},
keywords = {Software product lines, Reuse, Prediction, Post-release defects, Failure-prone files, Change metrics}
}

@inproceedings{10.5555/2486788.2487011,
author = {Gonzalez-Sanchez, Javier},
title = {Toward a software product line for affective-driven self-adaptive systems},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {One expected characteristic in modern systems is self-adaptation, the capability of monitoring and reacting to changes into the environment. A particular case of self-adaptation is affective-driven self-adaptation. Affective-driven self-adaptation is about having consciousness of user’s affects (emotions) and drive self-adaptation reacting to changes in those affects. Most of the previous work around self-adaptive systems deals with performance, resources, and error recovery as variables that trigger a system reaction. Moreover, most effort around affect recognition has been put towards offline analysis of affect, and to date only few applications exist that are able to infer user’s affect in real-time and trigger self-adaptation mechanisms. In response to this deficit, this work proposes a software product line approach to jump-start the development of affect-driven self-adaptive systems by offering the definition of a domain-specific architecture, a set of components (organized as a framework), and guidelines to tailor those components. Study cases with systems for learning and gaming will confirm the capability of the software product line to provide desired functionalities and qualities.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1381–1384},
numpages = {4},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@article{10.1016/j.jss.2006.09.010,
author = {Ahmed, Faheem and Capretz, Luiz Fernando and Sheikh, Shahbaz Ali},
title = {Institutionalization of software product line: An empirical investigation of key organizational factors},
year = {2007},
issue_date = {June, 2007},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {80},
number = {6},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2006.09.010},
doi = {10.1016/j.jss.2006.09.010},
abstract = {A good fit between the person and the organization is essential in a better organizational performance. This is even more crucial in case of institutionalization of a software product line practice within an organization. Employees' participation, organizational behavior and management contemplation play a vital role in successfully institutionalizing software product lines in a company. Organizational dimension has been weighted as one of the critical dimensions in software product line theory and practice. A comprehensive empirical investigation to study the impact of some organizational factors on the performance of software product line practice is presented in this work. This is the first study to empirically investigate and demonstrate the relationships between some of the key organizational factors and software product line performance of an organization. The results of this investigation provide empirical evidence and further support the theoretical foundations that in order to institutionalize software product lines within an organization, organizational factors play an important role.},
journal = {J. Syst. Softw.},
month = jun,
pages = {836–849},
numpages = {14},
keywords = {Software product line, Organizational theory, Organizational management, Organizational behavior, Empirical software engineering}
}

@article{10.1007/s00766-013-0185-4,
author = {Derakhshanmanesh, Mahdi and Fox, Joachim and Ebert, J\"{u}rgen},
title = {Requirements-driven incremental adoption of variability management techniques and tools: an industrial experience report},
year = {2014},
issue_date = {November  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0185-4},
doi = {10.1007/s00766-013-0185-4},
abstract = {In theory, software product line engineering has reached a mature state. In practice though, implementing a variability management approach remains a tough case-by-case challenge for any organization. To tame the complexity of this undertaking, it is inevitable to handle variability from multiple perspectives and to manage variability consistently across artifacts, tools, and workflows. Especially, a solid understanding and management of the requirements to be met by the products is an inevitable prerequisite. In this article, we share experiences from the ongoing incremental adoption of explicit variability management at TRW Automotive's department for automotive slip control systems--located in Koblenz, Germany. On the technical side, the three key drivers of this adoption effort are (a) domain modeling and scoping, (b) handling of variability in requirements and (c) tighter integration of software engineering focus areas (e.g., domain modeling, requirements engineering, architectural modeling) to make use of variability-related data. In addition to implementation challenges with using and integrating concrete third-party tools, social and workflow-related issues are covered as well. The lessons learned are presented, discussed, and thoroughly compared with the state of the art in research.},
journal = {Requir. Eng.},
month = nov,
pages = {333–354},
numpages = {22},
keywords = {Tool integration, Software product lines, Reuse, Requirements, Incremental adoption, Features}
}

@inproceedings{10.1145/3233027.3236402,
author = {Martinez, Jabier and Ordo\~{n}ez, Nicolas and T\"{e}rnava, Xhevahire and Ziadi, Tewfik and Aponte, Jairo and Figueiredo, Eduardo and Valente, Marco Tulio},
title = {Feature location benchmark with argoUML SPL},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236402},
doi = {10.1145/3233027.3236402},
abstract = {Feature location is a traceability recovery activity to identify the implementation elements associated to a characteristic of a system. Besides its relevance for software maintenance of a single system, feature location in a collection of systems received a lot of attention as a first step to re-engineer system variants (created through clone-and-own) into a Software Product Line (SPL). In this context, the objective is to unambiguously identify the boundaries of a feature inside a family of systems to later create reusable assets from these implementation elements. Among all the case studies in the SPL literature, variants derived from ArgoUML SPL stands out as the most used one. However, the use of different settings, or the omission of relevant information (e.g., the exact configurations of the variants or the way the metrics are calculated), makes it difficult to reproduce or benchmark the different feature location techniques even if the same ArgoUML SPL is used. With the objective to foster the research area on feature location, we provide a set of common scenarios using ArgoUML SPL and a set of utils to obtain metrics based on the results of existing and novel feature location techniques.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {257–263},
numpages = {7},
keywords = {software product lines, reverse-engineering, feature location, extractive software product line adoption, benchmark, argoUML},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s11219-011-9152-9,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Kuhlemann, Martin and K\"{a}stner, Christian and Apel, Sven and Saake, Gunter},
title = {SPL Conqueror: Toward optimization of non-functional properties in software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9152-9},
doi = {10.1007/s11219-011-9152-9},
abstract = {A software product line (SPL) is a family of related programs of a domain. The programs of an SPL are distinguished in terms of features, which are end-user visible characteristics of programs. Based on a selection of features, stakeholders can derive tailor-made programs that satisfy functional requirements. Besides functional requirements, different application scenarios raise the need for optimizing non-functional properties of a variant. The diversity of application scenarios leads to heterogeneous optimization goals with respect to non-functional properties (e.g., performance vs. footprint vs. energy optimized variants). Hence, an SPL has to satisfy different and sometimes contradicting requirements regarding non-functional properties. Usually, the actually required non-functional properties are not known before product derivation and can vary for each application scenario and customer. Allowing stakeholders to derive optimized variants requires us to measure non-functional properties after the SPL is developed. Unfortunately, the high variability provided by SPLs complicates measurement and optimization of non-functional properties due to a large variant space. With SPL Conqueror, we provide a holistic approach to optimize non-functional properties in SPL engineering. We show how non-functional properties can be qualitatively specified and quantitatively measured in the context of SPLs. Furthermore, we discuss the variant-derivation process in SPL Conqueror that reduces the effort of computing an optimal variant. We demonstrate the applicability of our approach by means of nine case studies of a broad range of application domains (e.g., database management and operating systems). Moreover, we show that SPL Conqueror is implementation and language independent by using SPLs that are implemented with different mechanisms, such as conditional compilation and feature-oriented programming.},
journal = {Software Quality Journal},
month = sep,
pages = {487–517},
numpages = {31},
keywords = {Software product lines, SPL Conqueror, Non-functional properties, Measurement and optimization, Feature-oriented software development}
}

@inproceedings{10.1145/2031759.2031768,
author = {Lence, Ram\'{o}n and Fuentes, Lidia and Pinto, M\'{o}nica},
title = {Quality attributes and variability in AO-ADL software architectures},
year = {2011},
isbn = {9781450306188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2031759.2031768},
doi = {10.1145/2031759.2031768},
abstract = {The quality attributes of a system are determined, to a large extend, by the decisions taken early on in the development process, noticeably affecting the specification of its software architecture. This is especially true for attributes such as security, usability, context awareness, etc., that have strong functional implications -- i.e. they require the incorporation of Specific functionality to the application architecture in order to satisfy them. Our approach models functional quality attributes considering that: (1) they are complex enough so as to be modeled by a large set of related concerns and the compositions among them. For instance, security includes authentication, access control, privacy, encryption, auditing, etc; (2) the same quality attributes are required by several applications, and thus should be modeled as separate, ready-to-use (re)usable architectural solutions that final applications can incorporate without "being previously prepared" for it; and (3) not all the concerns that are part of a quality attribute need to be instantiated for a particular application (e.g. only the authentication and access control concerns of security are required). In order to consider all the above requirements, in this paper we present a software product line approach that permits modeling the variability of quality attributes using feature models, and generating different configurations of their software architecture depending on the particular concerns required by each application.},
booktitle = {Proceedings of the 5th European Conference on Software Architecture: Companion Volume},
articleno = {7},
numpages = {10},
keywords = {variability, quality attributes, architectural templates, VML, Hydra, AO-ADL},
location = {Essen, Germany},
series = {ECSA '11}
}

@inproceedings{10.1145/3382025.3414969,
author = {Bilic, Damir and Carlson, Jan and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter},
title = {Detecting inconsistencies in annotated product line models},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414969},
doi = {10.1145/3382025.3414969},
abstract = {Model-based product line engineering applies the reuse practices from product line engineering with graphical modeling for the specification of software intensive systems. Variability is usually described in separate variability models, while the implementation of the variable systems is specified in system models that use modeling languages such as SysML. Most of the SysML modeling tools with variability support, implement the annotation-based modeling approach. Annotated product line models tend to be error-prone since the modeler implicitly describes every possible variant in a single system model. To identifying variability-related inconsistencies, in this paper, we firstly define restrictions on the use of SysML for annotative modeling in order to avoid situations where resulting instances of the annotated model may contain ambiguous model constructs. Secondly, inter-feature constraints are extracted from the annotated model, based on relations between elements that are annotated with features. By analyzing the constraints, we can identify if the combined variability- and system model can result in incorrect or ambiguous instances. The evaluation of our prototype implementation shows the potential of our approach by identifying inconsistencies in the product line model of our industrial partner which went undetected through several iterations of the model.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {20},
numpages = {11},
keywords = {variability modeling, product line engineering, model-based systems engineering, consistency checking, SysML},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1007/s10270-020-00839-w,
author = {Pol’la, Matias and Buccella, Agustina and Cechich, Alejandra},
title = {Analysis of variability models: a systematic literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00839-w},
doi = {10.1007/s10270-020-00839-w},
abstract = {Dealing with variability, during Software Product Line Engineering (SPLE), means trying to allow software engineers to develop a set of similar applications based on a manageable range of variable functionalities according to expert users’ needs. Particularly, variability management (VM) is an activity that allows flexibility and a high level of reuse during software development. In the last years, we have witnessed a proliferation of methods, techniques and supporting tools for VM in general, and for its analysis in particular. More precisely, a specific field has emerged, named (automated) variability analysis, focusing on verifying variability models across the SPLE’s phases. In this paper, we introduce a systematic literature review of existing proposals (as primary studies) focused on analyzing variability models. We define a classification framework, which is composed of 20 sub-characteristics addressing general aspects, such as scope and validation, as well as model-specific aspects, such as variability primitives, reasoner type. The framework allows to look at the analysis of variability models during its whole life cycle—from design to derivation—according to the activities involved during an SPL development. Also, the framework helps us answer three research questions defined for showing the state of the art and drawing challenges for the near future. Among the more interesting challenges, we can highlight the needs of more applications in industry, the existence of more mature tools, and the needs of providing more semantics in the way of variability primitives for identifying inconsistencies in the models.},
journal = {Softw. Syst. Model.},
month = aug,
pages = {1043–1077},
numpages = {35},
keywords = {Supporting tools, Variability management, Software Product Line, Variability analysis}
}

@article{10.1016/j.infsof.2010.12.006,
author = {Chen, Lianping and Ali Babar, Muhammad},
title = {A systematic review of evaluation of variability management approaches in software product lines},
year = {2011},
issue_date = {April, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {4},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.12.006},
doi = {10.1016/j.infsof.2010.12.006},
abstract = {ContextVariability management (VM) is one of the most important activities of software product-line engineering (SPLE), which intends to develop software-intensive systems using platforms and mass customization. VM encompasses the activities of eliciting and representing variability in software artefacts, establishing and managing dependencies among different variabilities, and supporting the exploitation of the variabilities for building and evolving a family of software systems. Software product line (SPL) community has allocated huge amount of effort to develop various approaches to dealing with variability related challenges during the last two decade. Several dozens of VM approaches have been reported. However, there has been no systematic effort to study how the reported VM approaches have been evaluated. ObjectiveThe objectives of this research are to review the status of evaluation of reported VM approaches and to synthesize the available evidence about the effects of the reported approaches. MethodWe carried out a systematic literature review of the VM approaches in SPLE reported from 1990s until December 2007. ResultsWe selected 97 papers according to our inclusion and exclusion criteria. The selected papers appeared in 56 publication venues. We found that only a small number of the reviewed approaches had been evaluated using rigorous scientific methods. A detailed investigation of the reviewed studies employing empirical research methods revealed significant quality deficiencies in various aspects of the used quality assessment criteria. The synthesis of the available evidence showed that all studies, except one, reported only positive effects. ConclusionThe findings from this systematic review show that a large majority of the reported VM approaches have not been sufficiently evaluated using scientifically rigorous methods. The available evidence is sparse and the quality of the presented evidence is quite low. The findings highlight the areas in need of improvement, i.e., rigorous evaluation of VM approaches. However, the reported evidence is quite consistent across different studies. That means the proposed approaches may be very beneficial when they are applied properly in appropriate situations. Hence, it can be concluded that further investigations need to pay more attention to the contexts under which different approaches can be more beneficial.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {344–362},
numpages = {19},
keywords = {Variability management, Systematic literature reviews, Software product line, Empirical studies}
}

@inproceedings{10.1109/SPLC.2011.27,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Automatic Derivation of a Product Performance Model from a Software Product Line Model},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.27},
doi = {10.1109/SPLC.2011.27},
abstract = {We propose to integrate performance analysis in the early phases of the model-driven development process for Software Product Lines (SPL). We start with a multi-view UML model of the core family assets representing the commonality and variability between different products, which we call the SPL model. We add another perspective to the SPL model, annotating it with generic performance specifications expressed in the standard UML profile MARTE, recently adopted by OMG. The runtime performance of a product is affected by factors contained in the UML model of the product (derived from the SPL model), but also by external factors depending on the implementation and execution environments. The external factors not contained in the SPL model need to be eventually represented in the performance model. In order to do so, we propose to represent the variability space of different possible implementation and execution environments through a so called "performance completion (PC) feature model". These PC features are mapped to MARTE performance-related stereotypes and attributes attached to the SPL model elements. A first model transformation realized in the Atlas Transformation Language (ATL) derives the UML model of a specific product with concrete MARTE annotations from the SPL model. A second transformation generates a Layered Queueing Network (LQN) performance model for the given product by applying an existing transformation named PUMA, developed in previous work. The proposed technique is illustrated with an e-commerce case study. A LQN model is derived for a product and the impact of different levels of secure communication channels on its performance is analyzed by using the LQN model.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {80–89},
numpages = {10},
keywords = {UML, SPL, Performance analysis, Performance Completion, Model-driven development, MARTE, ATL},
series = {SPLC '11}
}

@article{10.1016/j.jss.2007.12.797,
author = {Ajila, Samuel A. and Kaba, Ali B.},
title = {Evolution support mechanisms for software product line process},
year = {2008},
issue_date = {October, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {10},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.12.797},
doi = {10.1016/j.jss.2007.12.797},
abstract = {Software product family process evolution needs specific support for incremental change. Product line process evolution involves in addition to identifying new requirements the building of a meta-process describing the migration from the old process to the new one. This paper presents basic mechanisms to support software product line process evolution. These mechanisms share four strategies - change identification, change impact, change propagation, and change validation. It also examines three kinds of evolution processes - architecture, product line, and product. In addition, change management mechanisms are identified. Specifically we propose support mechanisms for static local entity evolution and complex entity evolution including transient evolution process. An evolution model prototype based on dependency relationships structure of the various product line artifacts is developed.},
journal = {J. Syst. Softw.},
month = oct,
pages = {1784–1801},
numpages = {18},
keywords = {Use case modeling, Transient process, Software product line process evolution, Software development process, Product line architecture, Meta-process, Feature-based object oriented model}
}

@article{10.1016/j.infsof.2006.05.004,
author = {Ahmed, Faheem and Capretz, Luiz Fernando},
title = {Managing the business of software product line: An empirical investigation of key business factors},
year = {2007},
issue_date = {February, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.05.004},
doi = {10.1016/j.infsof.2006.05.004},
abstract = {Business has been highlighted as a one of the critical dimensions of software product line engineering. This paper's main contribution is to increase the understanding of the influence of key business factors by showing empirically that they play an imperative role in managing a successful software product line. A quantitative survey of software organizations currently involved in the business of developing software product lines over a wide range of operations, including consumer electronics, telecommunications, avionics, and information technology, was designed to test the conceptual model and hypotheses of the study. This is the first study to demonstrate the relationships between the key business factors and software product lines. The results provide evidence that organizations in the business of software product line development have to cope with multiple key business factors to improve the overall performance of the business, in addition to their efforts in software development. The conclusions of this investigation reinforce current perceptions of the significance of key business factors in successful software product line business.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {194–208},
numpages = {15},
keywords = {Strategic planning, Software product line, Software engineering economics, Marketing strategy, Management, Key business factor}
}

@inproceedings{10.1145/3307630.3342704,
author = {Ca\~{n}ete, Angel},
title = {Energy Efficient Assignment and Deployment of Tasks in Structurally Variable Infrastructures},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342704},
doi = {10.1145/3307630.3342704},
abstract = {The importance of cyber-physical systems is growing very fast, being part of the Internet of Things vision. These devices generate data that could collapse the network and can not be assumed by the cloud. New technologies like Mobile Cloud Computing and Mobile Edge Computing are taking importance as solution for this issue. The idea is offloading some tasks to devices situated closer to the user device, reducing network congestion and improving applications performance (e.g., in terms of latency and energy). However, the variability of the target devices' features and processing tasks' requirements is very diverse, being difficult to decide which device is more adequate to deploy and run such processing tasks. Once decided, task offloading used to be done manually. Then, it is necessary a method to automatize the task assignation and deployment process. In this thesis we propose to model the structural variability of the deployment infrastructure and applications using feature models, on the basis of a SPL engineering process. Combining SPL methodology with Edge Computing, the deployment of applications is addressed as the derivation of a product. The data of the valid configurations is used by a task assignment framework, which determines the optimal tasks offloading solution in different network devices, and the resources of them that should be assigned to each task/user. Our solution provides the most energy and latency efficient deployment solution, accomplishing the QoS requirements of the application in the process.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {222–229},
numpages = {8},
keywords = {software product line, optimisation, mobile edge computing, mobile cloud computing, latency, energy efficiency},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342394,
author = {Mortara, Johann and T\"{e}rnava, Xhevahire and Collet, Philippe},
title = {symfinder: A Toolchain for the Identification and Visualization of Object-Oriented Variability Implementations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342394},
doi = {10.1145/3307630.3342394},
abstract = {When variability is implemented into a single variability-rich system with object-oriented techniques (e.g., inheritance, overloading, design patterns), the variation points and variants usually do not align with the domain features. It is then very hard and time consuming to manually identify these variation points to manage variability at the implementation level. symfinder is a toolchain to automatically identify and visualize these variability implementation locations inside a single object-oriented code base. For the identification part, it relies on the notion of symmetry between classes or methods to characterize uniformly some implementation techniques such as inheritance, overloading, or design patterns like Factory. The toolchain also generates an interactive Web-based visualization in which classes that are variation points are nodes linked together through their inheritance relationships, while the size, color, and texture of the nodes are used to represent some metrics on the number of overloaded constructors or methods. As a result, the visualization enables one to discern zones of interest where variation points are strongly present and to get relevant information over concerned classes. The toolchain, publicly available with its source code and an online demo, has been applied to several large open source projects.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {5–8},
numpages = {4},
keywords = {visualizing software variability, tool support for understanding software variability, software product line engineering, object-oriented variability-rich systems, identifying software variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2245276.2231956,
author = {Horikoshi, Hisayuki and Nakagawa, Hiroyuki and Tahara, Yasuyuki and Ohsuga, Akihiko},
title = {Dynamic reconfiguration in self-adaptive systems considering non-functional properties},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231956},
doi = {10.1145/2245276.2231956},
abstract = {Self-adaptive systems have recently been receiving much attention because of their ability to cope with the changes of environment, failures, and unanticipated events. These systems need an adaptation mechanism, which automatically computes the possible configurations, and decides the most appropriate configuration to fit the environment. In particular, the satisfaction of non-functional requirements must be considered when selecting the best reconfiguration. However, there are trade-off problems among non-functional requirements. Moreover, the adaptation mechanisms are typically developed separately from the components to be implemented, and it complicates the construction of such systems. We propose (1) a feature-oriented analysis technique, which can identify adaptation points, and calculate the contribution to non-functional goals of the configuration; (2) a component specification model, which extends an architectural description language for self-adaptation; (3) a reconfiguration framework aimed to reduce the complexity of the reconfiguration and generate the best configuration at run-time. We evaluate the feasibility of our framework by four different scenarios, and show that our framework reduces the complexity of the reconfiguration, and solves the trade-off problem among non-functional requirements.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1144–1150},
numpages = {7},
keywords = {software architecture, self-adaptive systems, feature-oriented analysis, dynamic reconfiguration, architecture description language},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/2430502.2430516,
author = {Lanceloti, Leandro A. and Maldonado, Jos\'{e} C. and Gimenes, Itana M. S. and Oliveira, Edson A.},
title = {SMartyParser: a XMI parser for UML-based software product line variability models},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430516},
doi = {10.1145/2430502.2430516},
abstract = {Variability management is an important issue for the software-intensive systems domain. Such an issue is essential for the success of software product line (SPL) adoption strategies. Although it is a well-discussed subject in the SPL community, there is a lack of tool support for environments that handle UML-based SPL variabilities, as several variability management approaches take UML as a basis, specially its profiling mechanism. Such environments might handle variabilities for several reasons, such as, evaluating SPLs, defining and applying metrics based on a SPL modeling, and automating the product generation. Therefore, this paper presents the SMartyParser, a parser for processing UML-based SPL models. Such models can be obtained, in the XMI format, from every UML specification-compliant tool. Such a parser provides several services to make it easier the handling of variability data in a particular SPL environment/tool. SMartyParser was built by taking the Open Core framework as a basis for processing XMI files. A parser use example is presented by taking into account the SPL Arcade Game Maker UML models.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {10},
numpages = {5},
keywords = {variability management, stereotype, software product line, parser, XMI, UML},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.5555/2022115.2022129,
author = {Gamez, Nadia and Fuentes, Lidia},
title = {Software product line evolution with cardinality-based feature models},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature models are widely used for modelling variability present in a Software Product Line family. We propose using cardinality-based feature models and clonable features to model and manage the evolution of the structural variability present in pervasive systems, composed by a large variety of heterogeneous devices. The use of clonable features increases the expressiveness of feature models, but also greatly increases the complexity of the resulting configurations. So, supporting the evolution of product configurations becomes an intractable task to do it manually. In this paper, we propose a model driven development process to propagate changes made in an evolved feature model, into existing configurations. Furthermore, our process allows us to calculate the effort needed to perform the evolution changes in the customized products. To do this, we have defined two operators, one to calculate the differences between two configurations and another to create a new configuration from a previous one. Finally, we validate our approach, showing that by using our tool support we can generate new configurations for a family of products with thousands of cloned features.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {102–118},
numpages = {17},
keywords = {software product lines, feature models, evolution},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1109/SERA.2010.17,
author = {Tanhaei, Mohammad and Moaven, Shahrouz and Habibi, Jafar and Ahmadi, Hamed},
title = {Toward a Business Model for Software Product Line Architecture},
year = {2010},
isbn = {9780769540757},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SERA.2010.17},
doi = {10.1109/SERA.2010.17},
abstract = {Nowadays, software product line is an approach to reduce costs of software development, decrease time to market, and increase capabilities of reuse in designing and exploiting software development processes. Moreover, other quality attributes of the project domain should be considered to enhance quality of the product. Meanwhile, taking advantage of software product line makes developers capable of estimating development costs and time to market in a more realistic way. However, old approaches to estimate cost of development and foresee time to market are not suitable enough for software product line. In this paper, some important business parameters and a way to calculate cost and time to market in a product line are presented. Changing components among time, portion of the change in a specific product and organization issues are observed in the estimation function.},
booktitle = {Proceedings of the 2010 Eighth ACIS International Conference on Software Engineering Research, Management and Applications},
pages = {50–56},
numpages = {7},
series = {SERA '10}
}

@inproceedings{10.1145/2362536.2362548,
author = {Soltani, Samaneh and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on functional and non-functional requirements},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362548},
doi = {10.1145/2362536.2362548},
abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {56–65},
numpages = {10},
keywords = {software product line engineering, planning techniques, feature model, configuration, artificial intelligence},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1887899.1887951,
author = {Lopez-Herrejon, Roberto E.},
title = {On the need of safe software product line architectures},
year = {2010},
isbn = {3642151132},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A Software Product Line (SPL) is a family of related software systems distinguished by the different sets of features each system provides. Over the last decade, the substantial benefits of SPL practices have been extensively documented and corroborated both in academia and industry. Several architecture methods have been proposed that employ different artifacts for expressing the components of a SPL, their properties and relationships. Of crucial importance for any SPL architecture method is to guarantee that the variability, for instance as expressed in feature models, is not only preserved but also kept consistent across all artifacts used. In this research challenge paper we argue that Safe Composition - the guarantee that all programs of a product line are type safe - can be leveraged to address this guarantee for structural properties of SPL architectures and the challenges that that entails.},
booktitle = {Proceedings of the 4th European Conference on Software Architecture},
pages = {493–496},
numpages = {4},
location = {Copenhagen, Denmark},
series = {ECSA'10}
}

@article{10.1007/s11219-011-9146-7,
author = {Montagud, Sonia and Abrah\~{a}o, Silvia and Insfran, Emilio},
title = {A systematic review of quality attributes and measures for software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9146-7},
doi = {10.1007/s11219-011-9146-7},
abstract = {It is widely accepted that software measures provide an appropriate mechanism for understanding, monitoring, controlling, and predicting the quality of software development projects. In software product lines (SPL), quality is even more important than in a single software product since, owing to systematic reuse, a fault or an inadequate design decision could be propagated to several products in the family. Over the last few years, a great number of quality attributes and measures for assessing the quality of SPL have been reported in literature. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the objective of identifying and interpreting all the available studies from 1996 to 2010 that present quality attributes and/or measures for SPL. These attributes and measures have been classified using a set of criteria that includes the life cycle phase in which the measures are applied; the corresponding quality characteristics; their support for specific SPL characteristics (e.g., variability, compositionality); the procedure used to validate the measures, etc. We found 165 measures related to 97 different quality attributes. The results of the review indicated that 92% of the measures evaluate attributes that are related to maintainability. In addition, 67% of the measures are used during the design phase of Domain Engineering, and 56% are applied to evaluate the product line architecture. However, only 25% of them have been empirically validated. In conclusion, the results provide a global vision of the state of the research within this area in order to help researchers in detecting weaknesses, directing research efforts, and identifying new research lines. In particular, there is a need for new measures with which to evaluate both the quality of the artifacts produced during the entire SPL life cycle and other quality characteristics. There is also a need for more validation (both theoretical and empirical) of existing measures. In addition, our results may be useful as a reference guide for practitioners to assist them in the selection or the adaptation of existing measures for evaluating their software product lines.},
journal = {Software Quality Journal},
month = sep,
pages = {425–486},
numpages = {62},
keywords = {Systematic literature review, Software product lines, Quality attributes, Quality, Measures}
}

@inproceedings{10.1145/3307630.3342705,
author = {Krieter, Sebastian},
title = {Enabling Efficient Automated Configuration Generation and Management},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342705},
doi = {10.1145/3307630.3342705},
abstract = {Creating and managing valid configurations is one of the main tasks in software product line engineering. Due to the often complex constraints from a feature model, some kind of automated configuration generation is required to facilitate the configuration process for users and developers. For instance, decision propagation can be applied to support users in configuring a product from a software product line (SPL) with less manual effort and error potential, leading to a semi-automatic configuration process. Furthermore, fully-automatic configuration processes, such as random sampling or t-wise interaction sampling can be employed to test or to optimize an SPL. However, current techniques for automated configuration generation still do not scale well to SPLs with large and complex feature models. Within our thesis, we identify current challenges regarding the efficiency and effectiveness of the semi- and fully-automatic configuration process and aim to address these challenges by introducing novel techniques and improving current ones. Our preliminary results show already show promising progress for both, the semi- and fully-automatic configuration process.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {215–221},
numpages = {7},
keywords = {uniform random sampling, t-wise sampling, software product lines, decision propagation, configurable system},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.infsof.2006.08.008,
author = {Her, Jin Sun and Kim, Ji Hyeok and Oh, Sang Hun and Rhew, Sung Yul and Kim, Soo Dong},
title = {A framework for evaluating reusability of core asset in product line engineering},
year = {2007},
issue_date = {July, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {7},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.08.008},
doi = {10.1016/j.infsof.2006.08.008},
abstract = {Product line engineering (PLE) is a new effective approach to software reuse, where applications are generated by instantiating a core asset which is a large-grained reuse unit. Hence, a core asset is a key element of PLE, and therefore the reusability of the core asset largely determines the success of PLE projects. However, current quality models to evaluate reusability do not adequately address the unique characteristics of core assets in PLE. This paper proposes a comprehensive framework for evaluating the reusability of core assets. We first identify the key characteristics of core assets, and derive a set of quality attributes that characterizes the reusability of core assets. Then, we define metrics for each quality attribute and finally present practical guidelines for applying the evaluation framework in PLE projects. Using the proposed framework, the reusability of core assets can be more effectively and precisely evaluated.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {740–760},
numpages = {21},
keywords = {Reusability, Quality model, Product line engineering, Metric, Core asset}
}

@article{10.1007/s10664-015-9414-4,
author = {Mkaouer, Mohamed Wiem and Kessentini, Marouane and Bechikh, Slim and O\'{z} Cinne\'{z}Ide, Mel and Deb, Kalyanmoy},
title = {On the use of many quality attributes for software refactoring: a many-objective search-based software engineering approach},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9414-4},
doi = {10.1007/s10664-015-9414-4},
abstract = {Search-based software engineering (SBSE) solutions are still not scalable enough to handle high-dimensional objectives space. The majority of existing work treats software engineering problems from a single or bi-objective point of view, where the main goal is to maximize or minimize one or two objectives. However, most software engineering problems are naturally complex in which many conflicting objectives need to be optimized. Software refactoring is one of these problems involving finding a compromise between several quality attributes to improve the quality of the system while preserving the behavior. To this end, we propose a novel representation of the refactoring problem as a many-objective one where every quality attribute to improve is considered as an independent objective to be optimized. In our approach based on the recent NSGA-III algorithm, the refactoring solutions are evaluated using a set of 8 distinct objectives. We evaluated this approach on one industrial project and seven open source systems. We compared our findings to: several other many-objective techniques (IBEA, MOEA/D, GrEA, and DBEA-Eps), an existing multi-objective approach a mono-objective technique and an existing refactoring technique not based on heuristic search. Statistical analysis of our experiments over 31 runs shows the efficiency of our approach.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {2503–2545},
numpages = {43},
keywords = {Software quality, Search-based software engineering, Refactoring, Many-objective optimization}
}

@inproceedings{10.1145/503209.503266,
author = {Mannion, Mike and Kaindl, Hermann},
title = {Requirements-based product line engineering},
year = {2001},
isbn = {1581133901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/503209.503266},
doi = {10.1145/503209.503266},
abstract = {Reuse and requirements are very important for efficient and successful systems development. This tutorial presents the experiences of requirements reuse using a Method for Requirements Authoring and Management (MRAM). MRAM is a method for establishing and selecting from product line requirements. A product line is a group of products within the same market segment e.g. mobile phones. TRAM (Tool for Requirements Authoring and Management) is a software tool to support MRAM that utilises current proven office technology (MS-Word, MS-Access). The tutorial presents the results of MRAM/TRAM as it has been applied to product line engineering of a real-world application.},
booktitle = {Proceedings of the 8th European Software Engineering Conference Held Jointly with 9th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {322–323},
numpages = {2},
keywords = {variability, reuse, requirements, product line engineering},
location = {Vienna, Austria},
series = {ESEC/FSE-9}
}

@inproceedings{10.5555/1939399.1939424,
author = {Kim, Chang Hwan Peter and Bodden, Eric and Batory, Don and Khurshid, Sarfraz},
title = {Reducing configurations to monitor in a software product line},
year = {2010},
isbn = {3642166113},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A software product line is a family of programs where each program is defined by a unique combination of features. Product lines, like conventional programs, can be checked for safety properties through execution monitoring. However, because a product line induces a number of programs that is potentially exponential in the number of features, it would be very expensive to use existing monitoring techniques: one would have to apply those techniques to every single program. Doing so would also be wasteful because many programs can provably never violate the stated property. We introduce a monitoring technique dedicated to product lines that, given a safety property, statically determines the feature combinations that cannot possibly violate the property, thus reducing the number of programs to monitor. Experiments show that our technique is effective, particularly for safety properties that crosscut many optional features.},
booktitle = {Proceedings of the First International Conference on Runtime Verification},
pages = {285–299},
numpages = {15},
location = {St. Julians, Malta},
series = {RV'10}
}

@inproceedings{10.1145/1629716.1629729,
author = {Liebig, J\"{o}rg and Apel, Sven and Lengauer, Christian and Leich, Thomas},
title = {RobbyDBMS: a case study on hardware/software product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629729},
doi = {10.1145/1629716.1629729},
abstract = {The development of a highly configurable data management system is a challenging task, especially if it is to be implemented on an embedded system that provides limited resources. We present a case study of such a data management system, called RobbyDBMS, and give it a feature-oriented design. In our case study, we evaluate the system's efficiency and variability. We pay particular attention to the interaction between the features of the data management system and the components of the underlying embedded platform. We also propose an integrated development process covering both hardware and software.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {63–68},
numpages = {6},
keywords = {FeatureC++, domain engineering, feature oriented software development, hardware product lines, software product lines},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1145/1808920.1808928,
author = {Pereira, Tha\'{\i}s Alves Burity and dos Santos, Vinicius Souza and Ribeiro, Bruno Luna and Elias, Gl\^{e}dson},
title = {A recommendation framework for allocating global software teams in software product line projects},
year = {2010},
isbn = {9781605589749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808920.1808928},
doi = {10.1145/1808920.1808928},
abstract = {In order to improve software quality and reduce costs and deadlines, many companies are adopting Software Product Line approaches. As a consequence of globalization, another common practice is the adoption of Global Software Development approaches, which seek to find more qualified workforce and more attractive costs in companies distributed around the world. Taking into account the benefits of both approaches, the ramework proposed in this paper has the goal of aiding the management of global software teams involved in the implementation phase of an SPL project, providing recommendations on how to allocate the teams to the set of software components, which are initially specified in the SPL architecture and must be subsequently implemented.},
booktitle = {Proceedings of the 2nd International Workshop on Recommendation Systems for Software Engineering},
pages = {36–40},
numpages = {5},
keywords = {software product line, recommendation systems, global software teams, global software development},
location = {Cape Town, South Africa},
series = {RSSE '10}
}

@inproceedings{10.1007/978-3-642-31095-9_40,
author = {Ensan, Faezeh and Bagheri, Ebrahim and Ga\v{s}evi\'{c}, Dragan},
title = {Evolutionary search-based test generation for software product line feature models},
year = {2012},
isbn = {9783642310942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31095-9_40},
doi = {10.1007/978-3-642-31095-9_40},
abstract = {Product line-based software engineering is a paradigm that models the commonalities and variabilities of different applications of a given domain of interest within a unique framework and enhances rapid and low cost development of new applications based on reuse engineering principles. Despite the numerous advantages of software product lines, it is quite challenging to comprehensively test them. This is due to the fact that a product line can potentially represent many different applications; therefore, testing a single product line requires the test of its various applications. Theoretically, a product line with n software features can be a source for the development of 2n application. This requires the test of 2n applications if a brute-force comprehensive testing strategy is adopted. In this paper, we propose an evolutionary testing approach based on Genetic Algorithms to explore the configuration space of a software product line feature model in order to automatically generate test suites. We will show through the use of several publicly-available product line feature models that the proposed approach is able to generate test suites of O(n) size complexity as opposed to O(2n) while at the same time form a suitable tradeoff balance between error coverage and feature coverage in its generated test suites.},
booktitle = {Proceedings of the 24th International Conference on Advanced Information Systems Engineering},
pages = {613–628},
numpages = {16},
keywords = {software product lines, feature models, evolutionary testing},
location = {Gda\'{n}sk, Poland},
series = {CAiSE'12}
}

@inproceedings{10.1145/1595808.1595819,
author = {Anastasopoulos, Michail},
title = {Increasing efficiency and effectiveness of software product line evolution: an infrastructure on top of configuration management},
year = {2009},
isbn = {9781605586786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1595808.1595819},
doi = {10.1145/1595808.1595819},
abstract = {Software Product Line Engineering entails the strategic development of software assets that are to be reused many times across the members of a product line. Assuring that the investment in reuse holds over time is an important requirement in this case. To that end it is necessary that evolution is carefully managed: Changes in reusable assets and their customized instances need to be tracked and propagated efficiently. Configuration Management is a mature discipline for that purpose. However traditional configuration management does not address product line evolution scenarios explicitly. Over time this can lead to great evolution management effort. This paper presents an infrastructure - in particular its validation - that sits on top of traditional configuration management and is tailored to evolution scenarios in Product Line Engineering. The result is a reduction of effort and an increase of correctness},
booktitle = {Proceedings of the Joint International and Annual ERCIM Workshops on Principles of Software Evolution (IWPSE) and Software Evolution (Evol) Workshops},
pages = {47–56},
numpages = {10},
keywords = {software product lines, evolution},
location = {Amsterdam, The Netherlands},
series = {IWPSE-Evol '09}
}

@inproceedings{10.5555/2394450.2394487,
author = {Nonaka, Makoto and Zhu, Liming and Ali Babar, Muhammad and Staples, Mark},
title = {Project cost overrun simulation in software product line development},
year = {2007},
isbn = {3540734597},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The cost of a Software Product Line (SPL) development project sometimes exceeds the initially planned cost, because of requirements volatility and poor quality. In this paper, we propose a cost overrun simulation model for time-boxed SPL development. The model is an enhancement of a previous model, specifically now including: consideration of requirements volatility, consideration of unplanned work for defect correction during product projects, and nominal project cost overrun estimation. The model has been validated through stochastic simulations with fictional SPL project data, by comparing generated unplanned work effort to actual change effort, and by sensitivity analysis. The result shows that the proposed model has reasonable validity to estimate nominal project cost overruns and its variability. Analysis indicates that poor management of requirements and quality will almost double estimation error, for the studied simulation settings.},
booktitle = {Proceedings of the 8th International Conference on Product-Focused Software Process Improvement},
pages = {330–344},
numpages = {15},
keywords = {software product line development, process simulation, cost overrun estimation},
location = {Riga, Latvia},
series = {PROFES'07}
}

@inproceedings{10.1145/3106195.3106212,
author = {Marimuthu, C. and Chandrasekaran, K.},
title = {Systematic Studies in Software Product Lines: A Tertiary Study},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106212},
doi = {10.1145/3106195.3106212},
abstract = {Software product lines are widely used in the software industries to increase the re-usability and to decrease maintenance cost. On the other hand, systematic reviews are widely used in the software engineering research community to provide the overview of the research field and practitioners guidelines. Researchers have conducted many systematic studies on the different aspects of SPLs. To the best of our knowledge, till now there is no tertiary study conducted on systematic studies of SPL related research topics. In this paper, we aim at conducting a systematic mapping study of existing systematic studies to report the overview of the findings for researchers and practitioners. We performed snowballing and automated search to find out the relevant systematic studies. As a result, we analyzed 60 relevant studies to answer 5 research questions. The main focus of this tertiary study is to highlight the research topics, type of published reviews, active researchers and publication forums. Additionally, we highlight some of the limitations of the systematic studies. The important finding of this study is that the research field is well matured as the systematic studies covered a wide range of research topics. Another important finding is that many studies provided information for practitioners as well as researchers which is a notable improvement in the systematic reviews. However, many studies failed to assess the quality of the primary studies which is the major limitation of the existing systematic studies.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {143–152},
numpages = {10},
keywords = {tertiary study, systematic review, software product line},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/1842752.1842809,
author = {Helleboogh, Alexander and Avgeriou, Paris and Bouck\'{e}, Nelis and Heymans, Patrick},
title = {Workshop on Variability in Software Product Line Architectures (VARI-ARCH 2010)},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842809},
doi = {10.1145/1842752.1842809},
abstract = {The objective of this workshop is to bring together researchers from the software product line community and software architecture community to identify critical challenges and progress the state-of-the-art on variability in software product line architectures.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {309–311},
numpages = {3},
keywords = {viewpoint, view, variability, software architecture, product lines, product line architecture, model, concern, assets},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/3461001.3473059,
author = {Azanza, Maider and Montalvillo, Leticia and D\'{\i}az, Oscar},
title = {20 years of industrial experience at SPLC: a systematic mapping study},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473059},
doi = {10.1145/3461001.3473059},
abstract = {Software Product Lines (SPLs) have been around since the late 1970s and have established themselves as a way to deal with product variability. Tens of companies around the globe can pay testament to their advantages. Practitioners, however, have lamented the lack of data on other practitioners' experiences that would help them in the SPL journey. This work intends to analyze the application of SPLs in industry in the last 20 years. We departed from 194 industrial studies that were published at the Software Product Line Conference, the premier venue for SPL research. After the filtering process we selected 66 primary studies, from 43 different companies and 15 countries. The studies were classified to answer three research questions: (i) which contexts have SPLs been applied in?, (ii) what phenomena have been reported? and, (iii) what evidences have been collected in terms of obtained benefits, encountered issues and lessons learned? Regarding the context, SPLs have mainly been reported in USA and Germany (50%) and are used to develop embedded systems (76%). The most cited reason to adopt SPLs is the need to increase product variants (42.42%). As for the phenomena, the most reported problem area is adoption (39.39%). Last, as for evidences the most cited benefit is a cost reduction (53.03%), the issue is evolution (13.13%) and the learned lesson is that architecture is essential (24.24%). We believe the findings will be of interest to the community as a whole in quest to bridge the gap between industry and academia while balancing rigor, authenticity and relevance.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {172–183},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461001.3473058,
author = {Ngo, Kien-Tuan and Nguyen, Thu-Trang and Nguyen, Son and Vo, Hieu Dinh},
title = {Variability fault localization: a benchmark},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473058},
doi = {10.1145/3461001.3473058},
abstract = {Software fault localization is one of the most expensive, tedious, and time-consuming activities in program debugging. This activity becomes even much more challenging in Software Product Line (SPL) systems due to the variability of failures in SPL systems. These unexpected behaviors are caused by variability faults which can only be exposed under some combinations of system features. Although localizing bugs in non-configurable code has been investigated in-depth, variability fault localization in SPL systems still remains mostly unexplored. To approach this challenge, we propose a benchmark for variability fault localization with a large set of 1,570 buggy versions of six SPL systems and baseline variability fault localization performance results. Our hope is to engage the community to propose new and better approaches to the problem of variability fault localization in SPL systems.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {120–125},
numpages = {6},
keywords = {variability fault localization, variability bug, benchmark},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.5555/1763239.1763269,
author = {Nonaka, Makoto and Zhu, Liming and Babar, Muhammad Ali and Staples, Mark},
title = {Project delay variability simulation in software product line development},
year = {2007},
isbn = {9783540724254},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The possible variability of project delay is useful information to understand and mitigate the project delay risk. However, it is not sufficiently considered in the literature concerning effort estimation and simulation in software product line development. In this paper, we propose a project delay simulation model by introducing a random variable to represent the variability of adaptive rework. The model has been validated through stochastic simulations by comparing generated adaptive rework to an actual change effort distribution, and by sensitivity analysis. The result shows that the proposed model is capable of producing reasonable variability of adaptive rework, and consequently, variability of project delay. Analysis of our model indicates that the strength of dependency has a larger impact than the number of residual defects, for the studied simulation settings. However, high levels of adaptive rework variability did not have great impact on overall project delay.},
booktitle = {Proceedings of the 2007 International Conference on Software Process},
pages = {283–294},
numpages = {12},
keywords = {software product line development, project planning, product quality, process simulation},
location = {Minneapolis, MN, USA},
series = {ICSP'07}
}

@inproceedings{10.1145/3461002.3473942,
author = {Kahraman, G\"{o}khan and Cleophas, Loek},
title = {Automated derivation of variants in manufacturing systems design},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473942},
doi = {10.1145/3461002.3473942},
abstract = {The Logistics Specification and Analysis Tool (LSAT) is a modelbased engineering tool used for design-space exploration of flexible manufacturing systems. LSAT provides domain specific languages to model a manufacturing system and means to analyze the productivity characteristics of such a system. In LSAT, developers can specify a system and model its deterministic operations as a set of activities. Given a set of activities, it is possible to construct an individual activity sequence that represents one valid system execution, and with minor variations in the specification individual systems can be obtained. To avoid modeling each variant separately, which means cloning and maintaining the common parts, new functionality is needed to deal with the variability of system specifications. In this study, we aim to establish integration between LSAT and product line engineering techniques. Specifically, we provide a realization of a toolchain including variability representation of LSAT realization artifacts and automated variant derivation for the LSAT model variants. Delta modeling, a transformational variability realization mechanism, is employed to model the variability within LSAT realization artifacts. Using the toolchain, we develop an industry-related case for a product line, the so called Extended Twilight System, a Cyber Physical System (CPS) inspired by the CPSs of our industrial partner.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {45–50},
numpages = {6},
keywords = {variability modeling, product lines, model-based engineering, manufacturing systems, delta modeling},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3236405.3236426,
author = {Belarbi, Maouaheb},
title = {A methodological framework to enable the generation of code from DSML in SPL},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236426},
doi = {10.1145/3236405.3236426},
abstract = {Software Product Line has acquired a significant momentum at the end of the 1990ies since it allows the production of variable software systems corresponding to the same domain portfolio. The effectiveness of the derivation process depends on how well variability is defined and implemented which is a crucial topic area that was addressed among two essential trends: On the one hand, starting from Domain Specific Modelling Language to express domain requirements and automate the code generation with Model-Driven Engineering techniques and on the second hand, exploiting the soar of variability mechanisms.In this context, the current research presents a method that unifies the two aforementioned approaches to cover the overall strategies by defining a framework that allows a better code generation in terms of documentation, maintainability, rapidity,etc. The starting point is the usage of the Domain Specific Modelling Language to represent the stakeholders requirements. Then, the resulting meta-model will be converted into one our several Feature Diagrams on which variability mechanisms can be applied to generate all the family products.A preliminary experiment has been undertaken to design the methodology of the proposed software factory in a meta-model. The validation task was evaluated with an academic use case called HandiWeb developed to facilitate handicap persons access to the internet. The first results allow us to put the hand on the key challenges that must be resolved by the proposed methodology.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {64–71},
numpages = {8},
keywords = {variability, software factory, methodology, SPL, DSML},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/1985793.1986009,
author = {Xue, Yinxing},
title = {Reengineering legacy software products into software product line based on automatic variability analysis},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1986009},
doi = {10.1145/1985793.1986009},
abstract = {In order to deliver the various and short time-to-market software products to customers, the paradigm of Software Product Line (SPL) represents a new endeavor to the software development. To migrate a family of legacy software products into SPL for effective reuse, one has to understand commonality and variability among existing products variants. The existing techniques rely on manual identification and modeling of variability, and the analysis based on those techniques is performed at several mutually independent levels of abstraction. We propose a sandwich approach that consolidates feature knowledge from top-down domain analysis with bottom-up analysis of code similarities in subject software products. Our proposed method integrates model differencing, clone detection, and information retrieval techniques, which can provide a systematic means to reengineer the legacy software products into SPL based on automatic variability analysis.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {1114–1117},
numpages = {4},
keywords = {variability analysis, spl, legacy software},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2648511.2648546,
author = {Van Landuyt, Dimitri and Op de beeck, Steven and Hovsepyan, Aram and Michiels, Sam and Joosen, Wouter and Meynckens, Sven and de Jong, Gjalt and Barais, Olivier and Acher, Mathieu},
title = {Towards managing variability in the safety design of an automotive hall effect sensor},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648546},
doi = {10.1145/2648511.2648546},
abstract = {This paper discusses the merits and challenges of adopting software product line engineering (SPLE) as the main development process for an automotive Hall Effect sensor. This versatile component is integrated into a number of automotive applications with varying safety requirements (e.g., windshield wipers and brake pedals).This paper provides a detailed explanation as to why the process of safety assessment and verification of the Hall Effect sensor is currently cumbersome and repetitive: it must be repeated entirely for every automotive application in which the sensor is to be used. In addition, no support is given to the engineer to select and configure the appropriate safety solutions and to explain the safety implications of his decisions.To address these problems, we present a tailored SPLE-based approach that combines model-driven development with advanced model composition techniques for applying and reasoning about specific safety solutions. In addition, we provide insights about how this approach can reduce the overall complexity, improve reusability, and facilitate safety assessment of the Hall Effect sensor.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {304–309},
numpages = {6},
keywords = {software product line engineering, safety patterns, hardware/software co-design, automotive, ASIL validation},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2791060.2791086,
author = {Martinez, Jabier and Ziadi, Tewfik and Bissyand\'{e}, Tegawend\'{e} F. and Klein, Jacques and Le Traon, Yves},
title = {Bottom-up adoption of software product lines: a generic and extensible approach},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791086},
doi = {10.1145/2791060.2791086},
abstract = {Although Software Product Lines are recurrently praised as an efficient paradigm for systematic reuse, practical adoption remains challenging. For bottom-up Software Product Line adoption, where a set of artefact variants already exists, practitioners lack end-to-end support for chaining (1) feature identification, (2) feature location, (3) feature constraints discovery, as well as (4) reengineering approaches. This challenge can be overcome if there exists a set of principles for building a framework to integrate various algorithms and to support different artefact types. In this paper, we propose the principles of such a framework and we provide insights on how it can be extended with adapters, algorithms and visualisations enabling their use in different scenarios. We describe its realization in BUT4Reuse (Bottom--Up Technologies for Reuse) and we assess its generic and extensible properties by implementing a variety of extensions. We further empirically assess the complexity of integration by reproducing case studies from the literature. Finally, we present an experiment where users realize a bottom-up Software Product Line adoption building on the case study of Eclipse variants.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {101–110},
numpages = {10},
keywords = {software product line engineering, reverse engineering, mining existing assets},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3382025.3414952,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Gasca, Rafael M. and Carmona-Fombella, Jose Antonio and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa},
title = {AMADEUS: towards the AutoMAteD secUrity teSting},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414952},
doi = {10.1145/3382025.3414952},
abstract = {The proper configuration of systems has become a fundamental factor to avoid cybersecurity risks. Thereby, the analysis of cybersecurity vulnerabilities is a mandatory task, but the number of vulnerabilities and system configurations that can be threatened is extremely high. In this paper, we propose a method that uses software product line techniques to analyse the vulnerable configuration of the systems. We propose a solution, entitled AMADEUS, to enable and support the automatic analysis and testing of cybersecurity vulnerabilities of configuration systems based on feature models. AMADEUS is a holistic solution that is able to automate the analysis of the specific infrastructures in the organisations, the existing vulnerabilities, and the possible configurations extracted from the vulnerability repositories. By using this information, AMADEUS generates automatically the feature models, that are used for reasoning capabilities to extract knowledge, such as to determine attack vectors with certain features. AMADEUS has been validated by demonstrating the capacities of feature models to support the threat scenario, in which a wide variety of vulnerabilities extracted from a real repository are involved. Furthermore, we open the door to new applications where software product line engineering and cybersecurity can be empowered.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {11},
numpages = {12},
keywords = {vulnerable configuration, vulnerabilities, testing, reasoning, pentesting, feature model, cybersecurity},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1016/j.infsof.2012.04.009,
author = {Engstr\"{o}M, Emelie and Runeson, Per},
title = {Test overlay in an emerging software product line - An industrial case study},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.04.009},
doi = {10.1016/j.infsof.2012.04.009},
abstract = {Context: In large software organizations with a product line development approach, system test planning and scope selection is a complex task. Due to repeated testing: across different testing levels, over time (test for regression) as well as of different variants, the risk of redundant testing is large as well as the risk of overlooking important tests, hidden by the huge amount of possible tests. Aims: This study assesses the amount and type of overlaid manual testing across feature, integration and system test in such context, it explores the causes of potential redundancy and elaborates on how to provide decision support in terms of visualization for the purpose of avoiding redundancy. Method: An in-depth case study was launched including both qualitative and quantitative observations. Results: A high degree of test overlay is identified originating from distributed test responsibilities, poor documentation and structure of test cases, parallel work and insufficient delta analysis. The amount of test overlay depends on which level of abstraction is studied. Conclusions: Avoiding redundancy requires tool support, e.g. visualization of test design coverage, test execution progress, priorities of coverage items as well as visualized priorities of variants to support test case selection.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {581–594},
numpages = {14},
keywords = {Software testing, Redundancy, Product-line, Overlay, Efficiency, Case study}
}

@inproceedings{10.1145/1244002.1244266,
author = {Inoki, Mari and Fukazawa, Yoshiaki},
title = {Software product line evolution method based on kaizen approach},
year = {2007},
isbn = {1595934804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1244002.1244266},
doi = {10.1145/1244002.1244266},
abstract = {Continuing optimal product line development needs to evolve core assets in response to market, technology or organization changes. In this paper, we propose a product line evolution method based on the kaizen approach. Kaizen is a continuous improvement method that is adopted in Japanese industry. The important points of the kaizen are to prepare a work standard and continue to improve processes by correcting the differences between the standard and actual results. Our core asset kaizen method provides a standard that includes core asset types based on simple metrics, kaizen patterns representing expertise, and kaizen processes for continuous improvement.},
booktitle = {Proceedings of the 2007 ACM Symposium on Applied Computing},
pages = {1207–1214},
numpages = {8},
keywords = {software product line, pattern, evolution, core asset, kaizen},
location = {Seoul, Korea},
series = {SAC '07}
}

@inproceedings{10.1145/1062455.1062551,
author = {Verlage, Martin and Kiesgen, Thomas},
title = {Five years of product line engineering in a small company},
year = {2005},
isbn = {1581139632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1062455.1062551},
doi = {10.1145/1062455.1062551},
abstract = {In 1999, a new team at MARKET MAKER Software AG began to develop a software product line for managing and displaying stock market data and financial market news. The basic idea was to use web technology in all applications for delivering services to customers. It soon turned out that the company had to change both the processes and the organization. This report summarizes the changes made and the lessons learned over the past five years, when the product line idea was introduced into a small company which faced the pressure to quickly market the first product line instances.},
booktitle = {Proceedings of the 27th International Conference on Software Engineering},
pages = {534–543},
numpages = {10},
keywords = {project management, product line engineering, experience report, SME},
location = {St. Louis, MO, USA},
series = {ICSE '05}
}

@inproceedings{10.1145/3307630.3342416,
author = {Rodriguez, Germania and P\'{e}rez, Jennifer and Benavides, David},
title = {Accessibility Variability Model: The UTPL MOOC Case Study},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342416},
doi = {10.1145/3307630.3342416},
abstract = {Several approaches to define Variability Models (VM) of non-functional requirements or quality attributes have been proposed. However, these approaches have focused on specific quality attributes rather than more general non-functional aspects established by standards such as ISO/IEC 25010 for software evaluation and quality. Thus, developing specific software products by selecting features and at the same time measuring the level of compliance with a standard/guideline is a challenge. In this work, we present the definition of an accessibility VM based on the web content accessibility guides (WCAG) 2.1 W3C recommendation, to obtain a quantitative measure to improve or construct specific SPL products that require to be accessibility-aware. This paper is specially focused on illustrating the experience of measuring the accessibility in a software product line (SPL) in order to check if it is viable measuring products and recommending improvements in terms of features before addressing the construction of accessibility-aware products. The adoption of the VM accessibility has been putted into practice through a pilot case study, the MOOC (Massive Open Online Course) initiative of the Universidad T\'{e}cnica Particular de Loja. The conduction of this pilot case study has allowed us to illustrate how it is possible to model and measure the accessibility in SPL using accessibility VM, as well as to recommend accessibility configuration improvements for the construction of new or updated MOOC platforms.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {114–121},
numpages = {8},
keywords = {software product lines, software development techniques, software creation and management, software and its engineering, reusability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1007/978-3-642-28714-5_13,
author = {Adam, Sebastian},
title = {Providing software product line knowledge to requirements engineers --- a template for elicitation instructions},
year = {2012},
isbn = {9783642287138},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-28714-5_13},
doi = {10.1007/978-3-642-28714-5_13},
abstract = {[Context &amp; Motivation] Developing new software systems based on a software product line (SPL) in so-called application engineering (AE) projects is still a time-consuming and expensive task. Especially when a large number of customer-specific requirements exists, there is still no systematic support for efficiently aligning these non-anticipated requirements with SPL characteristics early on. [Question/problem] In order to improve this process significantly, sound knowledge about an SPL must be available when guiding the requirements elicitation during AE. Thus, an appropriate reflection of SPL characteristics in process-supporting artifacts is indispensable for actually supporting a requirements engineer in this task. [Principal ideas/results] In this paper, a validated template for elicitation instructions that aims at providing a requirements engineer with knowledge about an underlying SPL in an appropriate manner is presented. This template consists of predefined text blocks and algorithms that explain how SPL-relevant product and process knowledge can be systematically reflected into capability-aware elicitation instructions. [Contribution] By using such elicitation instructions, requirements engineers are enabled to elicit requirements in an AE project more effectively.},
booktitle = {Proceedings of the 18th International Conference on Requirements Engineering: Foundation for Software Quality},
pages = {147–164},
numpages = {18},
location = {Essen, Germany},
series = {REFSQ'12}
}

@inproceedings{10.1145/3382026.3431247,
author = {Meixner, Kristof},
title = {Integrating Variability Modeling of Products, Processes, and Resources in Cyber-Physical Production Systems Engineering},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431247},
doi = {10.1145/3382026.3431247},
abstract = {The Industry 4.0 initiative envisions the flexible and optimized production of customized products on Cyber-Physical Production Systems (CPPSs) that consist of subsystems coordinated to conduct complex production processes. Hence, accurate CPPS modeling requires integrating the modeling of variability for Product-Process-Resource (PPR) aspects. Yet, current variability modeling approaches treat structural and behavioral variability separately, leading to inaccurate CPPS production models that impede CPPS engineering and optimization. This paper proposes a PhD project for integrated variability modeling of PPR aspects to improve the accuracy of production models with variability for CPPS engineers and production optimizers. The research project follows the Design Science approach aiming for the iterative design and evaluation of (a) a framework to categorize currently incomplete and scattered models and methods for PPR variability modeling as a foundation for an integrated model; and (b) a modeling approach for more accurate integrated PPR variability modeling. The planned research will provide the Software Product Line (SPL) and CPPS engineering research communities with (a) novel models, methods, and insights on integrated PPR variability modeling, (b) open data from CPPS engineering use cases for common modeling, and (c) empirical data from field studies for shared analysis and evaluation.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {96–103},
numpages = {8},
keywords = {Variability Modelling, Product-Process-Resource, Cyber-Physical Production System},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382025.3414725,
author = {Ferreira, Fischer and Viggiato, Markos and Souza, Maur\'{\i}cio and Figueiredo, Eduardo},
title = {Testing configurable software systems: the failure observation challenge},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414725},
doi = {10.1145/3382025.3414725},
abstract = {Configurable software systems can be adapted or configured according to a set of features to increase reuse and productivity. The testing process is essential because configurations that fail may potentially hurt user experience and degrade the reputation of a project. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. To encourage the research area on testing configurable systems, researchers and practitioners should be able to try out their solutions in common datasets. In this paper, we propose a dataset with 22 configurable software systems and an extensive test suite. Moreover, we report failures found in these systems and source code metrics to allow evaluating candidate solutions. We hope to engage the community and stimulate new and existing approaches to the problem of testing configurable systems.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {28},
numpages = {6},
keywords = {testing configurable systems, software product line},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3307630.3342403,
author = {Berger, Thorsten and Collet, Philippe},
title = {Usage Scenarios for a Common Feature Modeling Language},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342403},
doi = {10.1145/3307630.3342403},
abstract = {Feature models are recognized as a de facto standard for variability modeling. Presented almost three decades ago, dozens of different variations and extensions to the original feature-modeling notation have been proposed, together with hundreds of variability management techniques building upon feature models. Unfortunately, despite several attempts to establish a unified language, there is still no emerging consensus on a feature-modeling language that is both intuitive and simple, but also expressive enough to cover a range of important usage scenarios. There is not even a documented and commonly agreed set of such scenarios.Following an initiative among product-line engineering researchers in September 2018, we present 14 usage scenarios together with examples and requirements detailing each scenario. The scenario descriptions are the result of a systematic process, where members of the initiative authored original descriptions, which received feedback via a survey, and which we then refined and extended based on the survey results, reviewers' comments, and our own expertise. We also report the relevance of supporting each usage scenario for the language, as perceived by the initiative's members, prioritizing each scenario. We present a roadmap to build and implement a first version of the envisaged common language.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {174–181},
numpages = {8},
keywords = {unified language, software product lines, feature models},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2491627.2491631,
author = {Myll\"{a}rniemi, Varvana and Savolainen, Juha and M\"{a}nnist\"{o}, Tomi},
title = {Performance variability in software product lines: a case study in the telecommunication domain},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491631},
doi = {10.1145/2491627.2491631},
abstract = {In the research on software product lines, product variants typically differ by their functionality, and quality attributes are more or less similar across products. To accumulate empirical evidence, this paper presents a descriptive case study of performance variability in a software product line of mobile network base stations. The goal is to study the motivation to vary performance, and the strategy for realizing performance variability in the product line architecture. The results highlight that the evolution of customer needs motivates performance variability; performance variability can be realized either with software or hardware variability strategy, with the latter often being prevailing; and the software strategy can be kept focused by downgrading performance.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {32–41},
numpages = {10},
keywords = {variability, software product line, case study, architecture},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3106195.3106217,
author = {Kr\"{u}ger, Jacob and Nielebock, Sebastian and Krieter, Sebastian and Diedrich, Christian and Leich, Thomas and Saake, Gunter and Zug, Sebastian and Ortmeier, Frank},
title = {Beyond Software Product Lines: Variability Modeling in Cyber-Physical Systems},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106217},
doi = {10.1145/3106195.3106217},
abstract = {Smart IT has an increasing influence on the control of daily life. For instance, smart grids manage power supply, autonomous automobiles take part in traffic, and assistive robotics support humans in production cells. We denote such systems as Cyber-physical Systems (CPSs), where cyber addresses the controlling software, while physical describes the controlled hardware. One key aspect of CPSs is their capability to adapt to new situations autonomously or with minimal human intervention. To achieve this, CPSs reuse, reorganize and reconfigure their components during runtime. Some components may even serve in different CPSs and different situations simultaneously. The hardware of a CPS usually consists of a heterogeneous set of variable components. While each component can be designed as a software product line (SPL), which is a well established approach to describe software and hardware variability, it is not possible to describe CPSs' variability solely on a set of separate, non-interacting product lines. To properly manage variability, a CPS must specify dependencies and interactions of its separate components and cope with variable environments, changing requirements, and differing safety properties. In this paper, we i) propose a classification of variability aspects, ii) point out current challenges in variability modeling, and iii) sketch open research questions. Overall, we aim to initiate new research directions for variable CPSs based on existing product-line techniques.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {237–241},
numpages = {5},
keywords = {Software product line, Modeling, Cyber-physical system},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/1383559.1383571,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Towards automatic derivation of a product performance model from a UML software product line model},
year = {2008},
isbn = {9781595938732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1383559.1383571},
doi = {10.1145/1383559.1383571},
abstract = {Software Product Line (SPL) engineering is a software development approach that takes advantage of the commonality and variability between products from a family, and supports the generation of specific products by reusing a set of core family assets. This paper proposes a UML model transformation approach for software product lines to derive a performance model for a specific product. The input to the proposed technique, the "source model", is a UML model of a SPL with performance annotations, which uses two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The source model is generic and therefore its performance annotations must be parameterized. The proposed derivation of a performance model for a concrete product requires two steps: a) the transformation of a SPL model to a UML model with performance annotations for a given product, and b) the transformation of the outcome of the first step into a performance model. This paper focuses on the first step, whereas the second step will use the PUMA transformation approach of annotated UML models to performance models, developed in previous work. The output of the first step, named "target model", is a UML model with MARTE annotations, where the variability expressed in the SPL model has been analyzed and bound to a specific product, and the generic performance annotations have been bound to concrete values for the product. The proposed technique is illustrated with an e-commerce case study.},
booktitle = {Proceedings of the 7th International Workshop on Software and Performance},
pages = {91–102},
numpages = {12},
keywords = {uml, software product line, software performance engineering, model transformation, marte},
location = {Princeton, NJ, USA},
series = {WOSP '08}
}

@article{10.1007/s11334-011-0174-z,
author = {Polzer, Andreas and Merschen, Daniel and Botterweck, Goetz and Pleuss, Andreas and Thomas, Jacques and Hedenetz, Bernd and Kowalewski, Stefan},
title = {Managing complexity and variability of a model-based embedded software product line},
year = {2012},
issue_date = {March     2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {8},
number = {1},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-011-0174-z},
doi = {10.1007/s11334-011-0174-z},
abstract = {This paper presents a framework for model-based product lines of embedded systems. We show how to integrate model-based product line techniques into a consistent framework that can deal with large product lines as they are common in industry. The framework demonstrates the strengths of model-based techniques like abstraction, support for customised representations, and a high degree of automation. In particular, we provide the following contributions: (1) to shift existing product lines towards a model-based approach, we support the (semi-) automated extraction of models from existing requirement, test, and implementation artefacts; (2) to cope with the complexity of artefacts and their interrelations in industrial product lines, we support the generation of context-specific views. These views support developers, e.g., in analysing complex dependencies between different artefacts; (3) finally, we support automated product derivation based on an integrated hardware abstraction layer. Most of the presented concepts have been inspired by challenges arising in the industrial application of product line techniques in the model-based engineering of embedded systems. We report on experiences gathered during the application of the techniques to a prototypical product line (on a rapid prototyping platform in the university lab) and to industrial sample cases (at the industry partner).},
journal = {Innov. Syst. Softw. Eng.},
month = mar,
pages = {35–49},
numpages = {15},
keywords = {Variability modelling, Traceability, Software product lines, Model transformation, Complexity}
}

@article{10.1016/S0164-1212(02)00081-X,
author = {Lutz, Robyn R. and Gannod, Gerald C.},
title = {Analysis of a software product line architecture: an experience report},
year = {2003},
issue_date = {15 June 2003},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {66},
number = {3},
issn = {0164-1212},
url = {https://doi.org/10.1016/S0164-1212(02)00081-X},
doi = {10.1016/S0164-1212(02)00081-X},
abstract = {This paper describes experiences with the architectural specification and tool-assisted architectural analysis of a mission-critical, high-performance software product line. The approach used defines a "good" product line architecture in terms of those quality attributes required by the particular product line under development. Architectures are analyzed against several criteria by both manual and tool-supported methods. The approach described in this paper provides a structured analysis of an existing product line architecture using (1) architecture recovery and specification, (2) architecture evaluation, and (3) model checking of behavior to determine the level of robustness and fault tolerance at the architectural level that are required for all systems in the product line. Results of an application to a software product line of spaceborne telescopes are used to explain the approach and describe lessons learned.},
journal = {J. Syst. Softw.},
month = jun,
pages = {253–267},
numpages = {15}
}

@inproceedings{10.1145/2815782.2815799,
author = {Schaefer, Ina and Seidl, Christoph and Cleophas, Loek and Watson, Bruce W.},
title = {SPLicing TABASCO: Custom-Tailored Software Product Line Variants from Taxonomy-Based Toolkits},
year = {2015},
isbn = {9781450336833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815782.2815799},
doi = {10.1145/2815782.2815799},
abstract = {Taxonomy-Based Software Construction (TABASCO) applies extensive domain analyses to create conceptual hierarchies of algorithmic domains. Those are used as basis for the implementation of software toolkits. The monolithic structure of TABASCO-based toolkits restricts their adoption on resource-constrained or special-purpose devices. In this paper, we address this problem by applying Software Product Line (SPL) techniques to TABASCO-based toolkits: We use software taxonomies as input to creating a conceptual representation of variability as feature models of an SPL. We apply the variability realization mechanism delta modeling to transform realization artifacts, such as source code, to only contain elements for a particular selection of features. Our method is suitable for proactive, reactive and extractive SPL development so that it supports a seamless adoption and evolution of an SPL approach for TABASCO-based toolkits. We demonstrate the feasibility of the method with three case studies by proactively, reactively and extractively transforming TABASCO-based toolkits to SPLs, which allow derivation of variants with custom-tailored functionality.},
booktitle = {Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists},
articleno = {34},
numpages = {10},
keywords = {Taxonomy-Based Software Construction (TABASCO) toolkit, Software Product Line (SPL) adoption},
location = {Stellenbosch, South Africa},
series = {SAICSIT '15}
}

@inproceedings{10.1145/3382025.3414967,
author = {Lima, Jackson A. Prado and Mendon\c{c}a, Willian D. F. and Vergilio, Silvia R. and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Learning-based prioritization of test cases in continuous integration of highly-configurable software},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414967},
doi = {10.1145/3382025.3414967},
abstract = {Continuous Integration (CI) is a practice widely adopted in the industry to allow frequent integration of code changes. During the CI process, many test cases are executed multiple times a day, subject to time constraints. In this scenario, a learning-based approach, named COLEMAN, has been successfully applied. COLEMAN allows earlier execution of the most promising test cases to reveal faults. This approach considers CI particularities such as time budget and volatility of test cases, related to the fact that test cases can be added/removed along the CI cycles. In the CI of Highly Configuration System (HCS), many product variants must be tested, each one with different configuration options, but having test cases that are common to or reused from other variants. In this context, we found, by analogy, another particularity, the volatility of variants, that is, some variants can be included/discontinued along CI cycles. Considering this context, this work introduces two strategies for the application of COLEMAN in the CI of HCS: the Variant Test Set Strategy (VTS) that relies on the test set specific for each variant, and the Whole Test Set Strategy (WST) that prioritizes the test set composed by the union of the test cases of all variants. Both strategies are evaluated in a real-world HCS, considering three test budgets. The results show that the proposed strategies are applicable regarding the time spent for prioritization. They perform similarly regarding early fault detection, but WTS better mitigates the problem of beginning without knowledge, and is more suitable when a new variant to be tested is added.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {31},
numpages = {11},
keywords = {test case prioritization, software product line, family of products, continuous integration},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.5555/2022115.2022120,
author = {Alf\'{e}rez, Mauricio and Lopez-Herrejon, Roberto E. and Moreira, Ana and Amaral, Vasco and Egyed, Alexander},
title = {Supporting consistency checking between features and software product line use scenarios},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A key aspect for effective variability modeling of Software Product Lines (SPL) is to harmonize the need to achieve separation of concerns with the need to satisfy consistency of requirements and constraints. Techniques for variability modeling such as feature models used together with use scenarios help to achieve separation of stakeholders' concerns but ensuring their joint consistency is largely unsupported. Therefore, inconsistent assumptions about system's expected use scenarios and the way in which they vary according to the presence or absence of features reduce the models usefulness and possibly renders invalid SPL systems. In this paper we propose an approach to check consistency -- the verification of semantic relationships among the models -- between features and use scenarios that realize them. The novelty of this approach is that it is specially tailored for the SPL domain and considers complex composition situations where the customization of use scenarios for specific products depends on the presence or absence of sets of features. We illustrate our approach and supporting tools using variant constructs that specify how the inclusion of sets of variable features (that refer to uncommon requirements between products of a SPL) adapt use scenarios related to other features.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {20–35},
numpages = {16},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1145/2934466.2962728,
author = {Santos, Alcemir Rodrigues and Machado, Ivan do Carmo and de Almeida, Eduardo Santana},
title = {RiPLE-HC: visual support for features scattering and interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2962728},
doi = {10.1145/2934466.2962728},
abstract = {With the ever increasing popularity of JavaScript in different domains to build bigger and more complex software systems, variability management may be deemed as an affordable strategy. In this sense, Software Product Lines (SPL) engineering is one of the most successful paradigms to accomplish the necessary modularity and systematic reuse of code artifacts for that purpose. In previous work, we present tool support to hybrid composition of JavaScript-based product lines, called RiPLE-HC, which we now extend to incorporate a means to deal with feature interactions and feature annotation scattering in a more smooth way. The proposed tool support may provide practitioners with an easy-to-use approach to implement crosscutting features by increasing the awareness of the developers about the features implementation.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {320–323},
numpages = {4},
keywords = {software product line engineering, javascript, featureide, feature scattering visualization, eclipse plugin},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2020390.2020397,
author = {Krishnan, Sandeep and Strasburg, Chris and Lutz, Robyn R. and Go\v{s}eva-Popstojanova, Katerina},
title = {Are change metrics good predictors for an evolving software product line?},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020397},
doi = {10.1145/2020390.2020397},
abstract = {Background: Previous research on three years of early data for an Eclipse product identified some predictors of failure-prone files that work well for that data set. Additionally, Eclipse has been used to explore characteristics of product line software in previous research.Aims: To assess whether change metrics are good predictors of failure-prone files over time for the family of products in the evolving Eclipse product line.Method: We repeat, to the extent possible, the decision tree portion of the prior study to assess our ability to replicate the method, and then extend it by including four more recent years of data. We compare the most prominent predictors with the previous study's results. We then look at the data for three additional Eclipse products as they evolved over time. We explore whether the set of good predictors change over time for one product and whether the set differs among products.Results: We find that change metrics are consistently good and incrementally better predictors across the evolving products in Eclipse. There is also some consistency regarding which change metrics are the best predictors.Conclusion: Change metrics are good predictors for failure-prone files for the Eclipse product line. A small subset of these change metrics is fairly stable and consistent across products and releases.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {7},
numpages = {10},
keywords = {change metrics, failure-prone files, post-release defects, prediction, reuse, software product lines},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/3233027.3236395,
author = {Pereira, Juliana Alves and Maciel, Lucas and Noronha, Thiago F. and Figueiredo, Eduardo},
title = {Heuristic and exact algorithms for product configuration in software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236395},
doi = {10.1145/3233027.3236395},
abstract = {The Software Product Line (SPL) configuration field is an active area of research and has attracted both practitioners and researchers attention in the last years. A key part of an SPL configuration is a feature model that represents features and their dependencies (i.e., SPL configuration rules). This model can be extended by adding Non-Functional Properties (NFPs) as feature attributes resulting in Extended Feature Models (EFMs). Configuring products from an EFM requires considering the configuration rules of the model and satisfying the product functional and non-functional requirements. Although the configuration of a product arising from EFMs may reduce the space of valid configurations, selecting the most appropriate set of features is still an overwhelming task due to many factors including technical limitations and diversity of contexts. Consequently, configuring large and complex SPLs by using configurators is often beyond the users' capabilities of identifying valid combinations of features that match their (non-functional) requirements. To overcome this limitation, several approaches have modeled the product configuration task as a combinatorial optimization problem and proposed constraint programming algorithms to automatically derive a configuration. Although these approaches do not require any user intervention to guarantee the optimality of the generated configuration, due to the NP-hard computational complexity of finding an optimal variant, exact approaches have inefficient exponential time. Thus, to improve scalability and performance issues, we introduced the adoption of a greedy heuristic algorithm and a biased random-key genetic algorithm (BRKGA). Our experiment results show that our proposed heuristics found optimal solutions for all instances where those are known. For the instances where optimal solutions are not known, the greedy heuristic outperformed the best solution obtained by a one-hour run of the exact algorithm by up to 67.89%. Although the BRKGA heuristic slightly outperformed the greedy heuristic, it has shown larger running times (especially on the largest instances). Therefore, to ensure a good user experience and enable a very fast configuration task, we extended a state-of-the-art configurator with the proposed greedy heuristic approach.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {247},
numpages = {1},
keywords = {software product lines, software product line configuration, search-based software engineering, configuration optimization},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3382025.3414943,
author = {Th\"{u}m, Thomas},
title = {A BDD for Linux? the knowledge compilation challenge for variability},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414943},
doi = {10.1145/3382025.3414943},
abstract = {What is the number of valid configurations for Linux? How to generate uniform random samples for Linux? Can we create a binary decision diagram for Linux? It seems that the product-line community tries hard to answer such questions for Linux and other configurable systems. However, attempts are often not published due to the publication bias (i.e., unsuccessful attempts are not published). As a consequence, researchers keep trying by potentially spending redundant effort. The goal of this challenge is to guide research on these computationally complex problems and to foster the exchange between researchers and practitioners.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {16},
numpages = {6},
keywords = {software product line, software configuration, satisfiability solving, product configuration, knownledge compilation, feature models, decision models, configurable system, binary decision diagrams, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1016/j.scico.2004.10.006,
author = {Coallier, Fran\c{c}ois and Champagne, Roger},
title = {A product line engineering practices model},
year = {2005},
issue_date = {July 2005},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {57},
number = {1},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2004.10.006},
doi = {10.1016/j.scico.2004.10.006},
abstract = {This paper describes work in progress towards the elaboration of a Product Line practices model that combines concepts proposed by various authors. The strengths of existing Product Line flameworks and models are summarized and a new model is proposed in the form of 31 Product Line practice areas, grouped in five categories. An important objeclive of this Product Line practices model is that it should be easily incorporated into existing development methodologies, while remaining aligned with existing systems engineering standards.},
journal = {Sci. Comput. Program.},
month = jul,
pages = {73–87},
numpages = {15},
keywords = {system analysis and design, software engineering, product lines, modeling}
}

@inproceedings{10.1145/3461001.3471142,
author = {Gu\'{e}gain, \'{E}douard and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {On reducing the energy consumption of software product lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471142},
doi = {10.1145/3461001.3471142},
abstract = {Along the last decade, several studies considered green software design as a key development concern to improve the energy efficiency of software. Yet, few techniques address this concern for Software Product Lines (SPL). In this paper, we therefore introduce two approaches to measure and reduce the energy consumption of a SPL by analyzing a limited set of products sampled from this SPL. While the first approach relies on the analysis of individual feature consumptions, the second one takes feature interactions into account to better mitigate energy consumption of resulting products.Our experimental results on a real-world SPL indicate that both approaches succeed to produce significant energy improvements on a large number of products, while consumption data was modeled from a small set of sampled products. Furthermore, we show that taking feature interactions into account leads to more products improved with higher energy savings per product.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {89–99},
numpages = {11},
keywords = {software product lines, mitigation, measurement, energy, consumption},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1109/HICSS.2016.717,
author = {Preuveneers, Davy and Heyman, Thomas and Berbers, Yolande and Joosen, Wouter},
title = {Feature-Based Variability Management for Scalable Enterprise Applications: Experiences with an E-Payment Case},
year = {2016},
isbn = {9780769556703},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2016.717},
doi = {10.1109/HICSS.2016.717},
abstract = {In today's world of electronic payments, which includes credit cards, gift cards, stored value accounts, and micro payments on mobile devices, successful payment services need to be sufficiently scalable and support diverging use cases to be successful. However, the interaction between horizontal scalability, feature variability and stringent performance and security concerns for these heterogeneous payment applications and stakeholders is not always clear, which creates tension (and sometimes interference) in the successful development of these services. In this work, we identify crucial non-functional requirements for payment services and present a simple framework to map these requirements to existing approaches to achieve both horizontal and vertical scalability. We report on experiences with applying a service line engineering (SLE) approach towards payment services that combines cloud computing and SPL to support feature customization in a multi tenant payment service. We conclude with practical experiences and several lessons learned after applying this SPL engineering methodology on our industrial e-payment use case.},
booktitle = {Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS)},
pages = {5793–5802},
numpages = {10},
series = {HICSS '16}
}

@inproceedings{10.1007/978-3-642-02351-4_12,
author = {Koziolek, Heiko and Weiss, Roland and Doppelhamer, Jens},
title = {Evolving Industrial Software Architectures into a Software Product Line: A Case Study},
year = {2009},
isbn = {9783642023507},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02351-4_12},
doi = {10.1007/978-3-642-02351-4_12},
abstract = {Industrial software applications have high requirements on performance, availability, and maintainability. Additionally, diverse application landscapes of large corporate companies require systematic planning for reuse, which can be fostered by a software product-line approach. Analyses at the software architecture level can help improving the structure of the systems to account for extra-functional requirements and reuse. This paper reports a case study of product-line development for ABB's robotics PC software. We analysed the software architectures of three existing robotics applications and identified their core assets. As a result, we designed a new product-line architecture, which targets at fulfilling various extra-functional requirements. This paper describes experiences and lessons learned during the project.},
booktitle = {Proceedings of the 5th International Conference on the Quality of Software Architectures: Architectures for Adaptive Software Systems},
pages = {177–193},
numpages = {17},
location = {East Stroudsburg, PA, USA},
series = {QoSA '09}
}

@inproceedings{10.1145/3336294.3336298,
author = {Cashman, Mikaela and Firestone, Justin and Cohen, Myra B. and Thianniwet, Thammasak and Niu, Wei},
title = {DNA as Features: Organic Software Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336298},
doi = {10.1145/3336294.3336298},
abstract = {Software product line engineering is a best practice for managing reuse in families of software systems. In this work, we explore the use of product line engineering in the emerging programming domain of synthetic biology. In synthetic biology, living organisms are programmed to perform new functions or improve existing functions. These programs are designed and constructed using small building blocks made out of DNA. We conjecture that there are families of products that consist of common and variable DNA parts, and we can leverage product line engineering to help synthetic biologists build, evolve, and reuse these programs. As a first step towards this goal, we perform a domain engineering case study that leverages an open-source repository of more than 45,000 reusable DNA parts. We are able to identify features and their related artifacts, all of which can be composed to make different programs. We demonstrate that we can successfully build feature models representing families for two commonly engineered functions. We then analyze an existing synthetic biology case study and demonstrate how product line engineering can be beneficial in this domain.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {108–118},
numpages = {11},
keywords = {synthetic biology, software product lines, BioBricks},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1109/TPDS.2017.2766151,
author = {Fraternali, Francesco and Bartolini, Andrea and Cavazzoni, Carlo and Benini, Luca},
title = {Quantifying the Impact of Variability and Heterogeneity on the Energy Efficiency for a Next-Generation Ultra-Green Supercomputer},
year = {2018},
issue_date = {July 2018},
publisher = {IEEE Press},
volume = {29},
number = {7},
issn = {1045-9219},
url = {https://doi.org/10.1109/TPDS.2017.2766151},
doi = {10.1109/TPDS.2017.2766151},
abstract = {Supercomputers, nowadays, aggregate a large number of nodes featuring the same nominal HW components (e.g., processors and GPGPUS). In real-life machines, the chips populating each node are subject to a wide range of variability sources, related to performance and temperature operating points (i.e., ACPI p-states) as well as process variations and die binning. Eurora is a fully operational supercomputer prototype that topped July 2013 Green500 and it represents a unique ’living lab’ for next-generation ultra-green supercomputers. In this paper we evaluate and quantify the impact of variability on Eurora's energy-performance tradeoffs under a wide range of workloads intensity. Our experiments demonstrate that variability comes from hardware component mismatches as well as from the interplay between run-time energy management and workload variations. Thus, variability has a significant impact on energy efficiency even at the moderate scale of the Eurora machine, thereby substantiating the critical importance of variability management in future green supercomputers.},
journal = {IEEE Trans. Parallel Distrib. Syst.},
month = jul,
pages = {1575–1588},
numpages = {14}
}

@inproceedings{10.1145/3382025.3414959,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Extensible and modular abstract syntax for feature modeling based on language constructs},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414959},
doi = {10.1145/3382025.3414959},
abstract = {Since the definition of feature models in 1990, a large number of language constructs have emerged. Each language construct usually comes with its own abstract and concrete syntax, its semantics, and even its complete language dialect and tool support. Nowadays, there is a consensus in the Software Product Line community about a need for defining a common variability modeling language. But the fact of the matter is that it is very complex to achieve a good compromise between how expressive the language should be and the effort of developing practical tools for a language with all possible language constructs. In this paper, we propose an extensible model-driven engineering approach for defining the abstract syntax of feature modeling language constructs that could be tailored to different needs and domains. We formalize our approach as a set of modular and reusable metamodels that allows practitioners to decide which subset of language constructs to use through: (1) generating a new variability language; and (2) managing feature models with different level of expressiveness. We provide an instantiation and implementation of our approach.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {10},
numpages = {7},
keywords = {model-driven engineering, metamodeling, language level, language construct, feature modeling, abstract syntax, SPL},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382025.3414973,
author = {Schlie, Alexander and Kn\"{u}ppel, Alexander and Seidl, Christoph and Schaefer, Ina},
title = {Incremental feature model synthesis for clone-and-own software systems in MATLAB/Simulink},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414973},
doi = {10.1145/3382025.3414973},
abstract = {Families of related MATLAB/Simulink systems commonly emerge ad hoc using clone-and-own practices. Extractively migrating systems towards a software product line (SPL) can be a remedy. A feature model (FM) represents all potential configurations of an SPL, ideally, in non-technical domain terms. However, yielding a sensible FM from automated synthesis remains a major challenge due to domain knowledge being a prerequisite for features to be adequate abstractions. In incremental reverse engineering, subsequent generation of FMs may further overwrite changes and design decisions made during previous manual FM refinement.In this paper, we propose an approach to largely automate the synthesis of a suitable FM from a set of cloned MATLAB/Simulink models as part of reverse engineering an SPL. We fully automate the extraction of an initial, i.e., a technical, FM that closely aligns with realization artifacts and their variability, and further provide operations to manually refine it to incorporate domain knowledge. Most importantly, we provide concepts to capture such operations and to replay them on a structurally different technical FM stemming from a subsequent reverse engineering increment that included further systems of the portfolio. We further provide an implementation and demonstrate the feasibility of our approach using two MATLAB/Simulink data sets from the automotive domain.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {7},
numpages = {12},
keywords = {variability, synthesis, refinement, mapping, individual, incremental, feature model, clone-and-own, MATLAB/Simulink, 150% model},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/MEMCOD.2007.371243,
author = {Oh, Youngseok and Lee, Dan Hyung and Kang, Sungwon and Lee, Ji Hyun},
title = {Extended Architecture Analysis Description Language for Software Product Line Approach in Embedded Systems},
year = {2007},
isbn = {1424410509},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MEMCOD.2007.371243},
doi = {10.1109/MEMCOD.2007.371243},
abstract = {Describing architecture variabilities explicitly and precisely is important in the software product line approach for software development since it helps product derivation as well as modeling and managing the variabilities. The SAE AADL is an industry standard architecture analysis and design language for the automotive community, which originally was not intended to be used for software product line. In this paper, we propose EAADL a software product line architecture description language for the automotive domain that extends the SAE AADL. By incorporating orthogonal variability model into it, EAADL offers traceability with requirement engineering as well as the implementation process that is essential in software product line engineering.},
booktitle = {Proceedings of the 5th IEEE/ACM International Conference on Formal Methods and Models for Codesign},
pages = {87–88},
numpages = {2},
series = {MEMOCODE '07}
}

@inproceedings{10.1145/3109729.3109749,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Extending the Common Variability Language (CVL) Engine: A practical tool},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109749},
doi = {10.1145/3109729.3109749},
abstract = {The Common Variability Language (CVL) has become a reference in the specification and resolution of variability in the last few years. Despite the multiple advantages of CVL (orthogonal variability, architecture variability resolution, MOF-compliant, standard proposed,...), several approaches require extending and/or modifying the CVL approach in different ways in order to fulfill the industrial needs for variability modeling in Software Product Lines. However, the community lacks a tool that would enable proposed extensions and the integration of novel approaches to be put into practice. Existing tools that provide support for CVL are incomplete or are mainly focused on the variability model's editor, instead of executing the resolution of the variability over the base models. Moreover, there is no API that allows direct interaction with the CVL engine to extend or use it in an independent application. In this paper, we identify the extension points of the CVL approach with the goal of making the CVL engine more flexible, and to help software architects in the task of resolving the variability of their products. The practical tool presented here is a working implementation of the CVL engine, that can be extended through a proposed API.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {32–37},
numpages = {6},
keywords = {Variability, Software Product Line, CVL},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3461001.3473065,
author = {Michelon, Gabriela K. and Sotto-Mayor, Bruno and Martinez, Jabier and Arrieta, Aitor and Abreu, Rui and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Spectrum-based feature localization: a case study using ArgoUML},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473065},
doi = {10.1145/3461001.3473065},
abstract = {Feature localization (FL) is a basic activity in re-engineering legacy systems into software product lines. In this work, we explore the use of the Spectrum-based localization technique for this task. This technique is traditionally used for fault localization but with practical applications in other tasks like the dynamic FL approach that we propose. The ArgoUML SPL benchmark is used as a case study and we compare it with a previous hybrid (static and dynamic) approach from which we reuse the manual and testing execution traces of the features. We conclude that it is feasible and sound to use the Spectrum-based approach providing promising results in the benchmark metrics.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {126–130},
numpages = {5},
keywords = {spectrum-based localization, dynamic feature localization, ArgoUML SPL benchmark},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2866614.2866621,
author = {Capilla, Rafael and Bosch, Jan},
title = {Dynamic Variability Management Supporting Operational Modes of a Power Plant Product Line},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866621},
doi = {10.1145/2866614.2866621},
abstract = {Runtime variability is becoming an attractive technique to support those runtime scenarios for systems that demand some kind of autonomous reconfiguration or adaptive behavior. Nowadays, the challenge of many critical systems that need to handle different operational modes, often in an unattended mode, require specific solutions for which runtime variability mechanisms become relevant. This research describes the challenges of runtime variability to support multiple binding modes for handling the diversity of different operational modes and runtime reconfiguration needs. We validate our approach in a power plant control product line at Toshiba which advances previous work making the transition between the power plant operational modes more automatic and dynamic.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {49–56},
numpages = {8},
keywords = {runtime reconfiguration, multiple binding times, dynamic software product lines, Runtime variability},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@inproceedings{10.1109/HICSS.2009.472,
title = {Towards Tool Support for the Configuration of Non-Functional Properties in SPLs},
year = {2009},
isbn = {9780769534503},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2009.472},
doi = {10.1109/HICSS.2009.472},
abstract = {The configuration of NFPs (non-functional properties) is a crucial problem in the development of software-intensive systems. Most of the approaches currently available tackle this problem during software design. However, at this stage, NFPs cannot be properly predicted. As a solution for this problem we present the new extensions of the Feedback approach which aims at improving the configuration of NFPs in SPLs. We introduce our set of tools that are used to support the approach and show how to use them by applying it to the well-known SPL (The Graph Product Line) that was suggested as a platform for evaluating SPL technologies.},
booktitle = {Proceedings of the 42nd Hawaii International Conference on System Sciences},
pages = {1–7},
numpages = {7},
series = {HICSS '09}
}

@inproceedings{10.1145/2420942.2420944,
author = {Olaechea, Rafael and Stewart, Steven and Czarnecki, Krzysztof and Rayside, Derek},
title = {Modelling and multi-objective optimization of quality attributes in variability-rich software},
year = {2012},
isbn = {9781450318075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420942.2420944},
doi = {10.1145/2420942.2420944},
abstract = {Variability-rich software, such as software product lines, offers optional and alternative features to accommodate varying needs of users. Designers of variability-rich software face the challenge of reasoning about the impact of selecting such features on the quality attributes of the resulting software variant. Attributed feature models have been proposed to model such features and their impact on quality attributes, but existing variability modelling languages and tools have limited or no support for such models and the complex multi-objective optimization problem that arises. This paper presents ClaferMoo, a language and tool that addresses these shortcomings. ClaferMoo uses type inheritance to modularize the attribution of features in feature models and allows specifying multiple optimization goals. We evaluate an implementation of the language on a set of attributed feature models from the literature, showing that the optimization infrastructure can handle small-scale feature models with about a dozen features within seconds.},
booktitle = {Proceedings of the Fourth International Workshop on Nonfunctional System Properties in Domain Specific Modeling Languages},
articleno = {2},
numpages = {6},
keywords = {software product lines, multi-objective optimization},
location = {Innsbruck, Austria},
series = {NFPinDSML '12}
}

@inproceedings{10.1145/2934466.2934486,
author = {Santos, Alcemir Rodrigues and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {RiPLE-HC: javascript systems meets spl composition},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934486},
doi = {10.1145/2934466.2934486},
abstract = {Context. Software Product Lines (SPL) engineering is increasingly being applied to handle variability in industrial software systems. Problem. The research community has pointed out a series of benefits which modularity brings to software composition, a key aspect in SPL engineering. However, in practice, the reuse in Javascript-based systems relies on the use of package managers (e.g., npm, jam, bower, requireJS), but these approaches do not allow the management of project features. Method. This paper presents the RiPLE-HC, a strategy aimed at blending compositional and annotative approaches to implement variability in Javascript-based systems. Results. We applied the approach in an industrial environment and conducted an academic case study with six open-source systems to evaluate its robustness and scalability. Additionally, we carried a controlled experiment to analyze the impact of the RiPLE-HC code organization on the feature location maintenance tasks. Conclusion. The empirical evaluations yielded evidence of reduced effort in feature location, and positive benefits when introducing systematic reuse aspects in Javascript-based systems.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {154–163},
numpages = {10},
keywords = {web systems domain, software product line engineering, featureIDE, feature composition, eclipse plugin},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3461001.3474452,
author = {He\ss{}, Tobias and Sundermann, Chico and Th\"{u}m, Thomas},
title = {On the scalability of building binary decision diagrams for current feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3474452},
doi = {10.1145/3461001.3474452},
abstract = {Binary decision diagrams (BDD) have been proposed for numerous product-line analyses. These analyses typically exploit properties unique to decision diagrams, such as negation in constant time and space. Furthermore, the existence of a BDD representing the configuration space of a product line removes the need to employ SAT or #SAT solvers for their analysis. Recent work has shown that the performance of state-of-the-art BDD libraries is significantly lower than previously reported and hypothesized. In this work, we provide an assessment of the state-of-the-art of BDD scalability in this domain and explain why previous results on the scalability of BDDs do not apply to more recent product-line instances.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {131–135},
numpages = {5},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2000259.2000264,
author = {Kavimandan, Amogh and Gokhale, Aniruddha and Karsai, Gabor and Gray, Jeff},
title = {Managing the quality of software product line architectures through reusable model transformations},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000264},
doi = {10.1145/2000259.2000264},
abstract = {In model-driven engineering of applications, the quality of the software architecture is realized and preserved in the successive stages of its lifecycle through model transformations. However, limited support for reuse in contemporary model transformation techniques forces developers of product line architectures to reinvent transformation rules for every variant of the product line, which can adversely impact developer productivity and in turn degrade the quality of the resulting software architecture for the variant. To overcome these challenges, this paper presents the MTS (Model-transformation Templatization and Specialization generative transformation process, which promotes reuse in model transformations through parameterization and specialization of transformation rules. MTS defines two higher order transformations to capture the variability in transformation rules and to specialize them across product variants. The core idea behind MTS is realized within a graphical model transformation tool in a way that is minimally intrusive to the underlying tool's implementation. The paper uses two product line case studies to evaluate MTS in terms of reduction in efforts to define model transformation rules as new variants are added to the product line, and the overhead in executing the higher order transformations. These metrics provide an indirect measure of how potential degradation in the quality of software architectures of product lines caused due to lack of reuse can be alleviated by MTS.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {13–22},
numpages = {10},
keywords = {software quality, reuse, model transformations},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@inproceedings{10.1145/3461001.3471155,
author = {Martin, Hugo and Acher, Mathieu and Pereira, Juliana Alves and J\'{e}z\'{e}quel, Jean-Marc},
title = {A comparison of performance specialization learning for configurable systems},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471155},
doi = {10.1145/3461001.3471155},
abstract = {The specialization of the configuration space of a software system has been considered for targeting specific configuration profiles, usages, deployment scenarios, or hardware settings. The challenge is to find constraints among options' values that only retain configurations meeting a performance objective. Since the exponential nature of configurable systems makes a manual specialization unpractical, several approaches have considered its automation using machine learning, i.e., measuring a sample of configurations and then learning what options' values should be constrained. Even focusing on learning techniques based on decision trees for their built-in explainability, there is still a wide range of possible approaches that need to be evaluated, i.e., how accurate is the specialization with regards to sampling size, performance thresholds, and kinds of configurable systems. In this paper, we compare six learning techniques: three variants of decision trees (including a novel algorithm) with and without the use of model-based feature selection. We first perform a study on 8 configurable systems considered in previous related works and show that the accuracy reaches more than 90% and that feature selection can improve the results in the majority of cases. We then perform a study on the Linux kernel and show that these techniques performs as well as on the other systems. Overall, our results show that there is no one-size-fits-all learning variant (though high accuracy can be achieved): we present guidelines and discuss tradeoffs.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {46–57},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382025.3414961,
author = {Favalli, Luca and K\"{u}hn, Thomas and Cazzola, Walter},
title = {Neverlang and FeatureIDE just married: integrated language product line development environment},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414961},
doi = {10.1145/3382025.3414961},
abstract = {Language development is inherently complex. With the support of a suitable language development environment most computer scientists could develop their own domain-specific language (DSL) with relative ease. Yet, when the DSL is the result of a configuration over a language product line (LPL)---a special software product line (SPL) of compilers/interpreters and corresponding IDE services---they fail to provide adequate support. An environment for LPL engineering should facilitate the underlying process involving three distinct roles: a language engineer developing the LPL, a language deployer configuring a language product, and a language user using the language product. Neither IDEs nor SPLE environments can cater all three roles and fully support the LPL engineering process with distributed, incremental development, configuration, and deployment of language variants. In this paper, we present an LPL engineering process for the distributed, incremental development of LPLs and an integrated language product line development environment supporting this process, catering the three roles, and ensuring the consistency among all artifacts of the LPL: language components implementing a language feature, the feature model, language configurations and the resulting language products. To create such an environment, we married the Neverlang language workbench and AiDE its LPL engineering environment with the FeatureIDE SPL engineering environment. While Neverlang supports the development of LPLs and deployment of language products, AiDE generates the feature model for the LPL under development, whereas FeatureIDE handles the feature configuration. We illustrate the applicability of the LPL engineering process and the suitability of our development environment for the three roles by showcasing its application for teaching programming with a growable language. In there, an LPL for Javascript was developed/refactored, 15 increasingly complex language products were configured/updated and finally deployed.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {33},
numpages = {11},
keywords = {neverlang, language product lines, domain specific languages},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3233027.3236399,
author = {Kuiter, Elias and Krieter, Sebastian and Kr\"{u}ger, Jacob and Ludwig, Kai and Leich, Thomas and Saake, Gunter},
title = {PClocator: a tool suite to automatically identify configurations for code locations},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236399},
doi = {10.1145/3233027.3236399},
abstract = {The source code of highly-configurable software is challenging to comprehend, analyze, and test. In particular, it is hard to identify all configurations that comprise a certain code location. We contribute PCLocator, a tool suite that solves this problem by utilizing static analysis tools for compile-time variability. Using BusyBox and the Variability Bugs Database (VBDb), we evaluate the correctness and performance of PCLocator. The results show that we are able to analyze files in a matter of seconds and derive correct configurations in 95% of all cases.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {284–288},
numpages = {5},
keywords = {static source code analysis, software product line, preprocessor, configuration, build system},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3382025.3414964,
author = {Hoff, Adrian and Nieke, Michael and Seidl, Christoph and S\ae{}ther, Eirik Halvard and Motzfeldt, Ida Sandberg and Din, Crystal Chang and Yu, Ingrid Chieh and Schaefer, Ina},
title = {Consistency-preserving evolution planning on feature models},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414964},
doi = {10.1145/3382025.3414964},
abstract = {A software product line (SPL) enables large-scale reuse in a family of related software systems through configurable features. SPLs represent a long-term investment so that their ongoing evolution becomes paramount and requires careful planning. While existing approaches enable to create an evolution plan for an SPL on feature-model (FM) level, they assume the plan to be rigid and do not support retroactive changes. In this paper, we present a method that enables to create and retroactively adapt an FM evolution plan while preventing undesired impacts on its structural and logical consistency. This method is founded in structural operational semantics and linear temporal logic. We implement our method using rewriting logic, integrate it within an FM tool suite and perform an evaluation using a collection of existing FM evolution scenarios.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {8},
numpages = {12},
keywords = {structural operational semantics, software product lines, software evolution, rewriting logic, linear temporal logic, formal semantics, feature models, feature model evolution},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3236405.3237201,
author = {Nieke, Michael and Seidl, Christoph and Th\"{u}m, Thomas},
title = {Back to the future: avoiding paradoxes in feature-model evolution},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237201},
doi = {10.1145/3236405.3237201},
abstract = {A Software Product Line (SPL) captures families of software products and its functionality is captured as features in a feature model. Similar to other software systems, SPLs and their feature models are subject to evolution. Temporal Feature Models (TFMs) are an extension to feature models that allow for engineers to model past feature-model evolution and plan future evolution. When planning future evolution of feature models, multiple evolution steps may be planned upfront but changed requirements may lead to retroactively introducing evolution steps into the planned evolution or changing already planned steps. As a consequence, inconsistencies, which we denote as evolution paradoxes, may arise leading to invalidity of already modeled future evolution steps. In this paper, we present first steps towards allowing to introduce intermediate evolution steps into planned evolution while preserving consistency of all future evolution steps. To this end, we outline a method to define and check model evolution consistency rules. Using this method, engineers are allowed to introduce intermediate feature-model evolution steps whenever these changes preserve the evolution consistency rules.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {48–51},
numpages = {4},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3307630.3342413,
author = {Arcaini, Paolo and Gargantini, Angelo and Radavelli, Marco},
title = {A Process for Fault-Driven Repair of Constraints Among Features},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342413},
doi = {10.1145/3307630.3342413},
abstract = {The variability of a Software Product Line is usually both described in the problem space (by using a variability model) and in the solution space (i.e., the system implementation). If the two spaces are not aligned, wrong decisions can be done regarding the system configuration. In this work, we consider the case in which the variability model is not aligned with the solution space, and we propose an approach to automatically repair (possibly) faulty constraints in variability models. The approach takes as input a variability model and a set of combinations of features that trigger conformance faults between the model and the real system, and produces the repaired set of constraints as output. The approach consists of three major phases. First, it generates a test suite and identifies the condition triggering the faults. Then, it modifies the constraints of the variability model according to the type of faults. Lastly, it uses a logic minimization method to simplify the modified constraints. We evaluate the process on variability models of 7 applications of various sizes. An empirical analysis on these models shows that our approach can effectively repair constraints among features in an automated way.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {73–81},
numpages = {9},
keywords = {variability model, system evolution, fault, automatic repair},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461002.3473070,
author = {Acher, Mathieu and Perrouin, Gilles and Cordy, Maxime},
title = {BURST: a benchmarking platform for uniform random sampling techniques},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473070},
doi = {10.1145/3461002.3473070},
abstract = {We present BURST, a benchmarking platform for uniform random sampling techniques. With BURST, researchers have a flexible, controlled environment in which they can evaluate the scalability and uniformity of their sampling. BURST comes with an extensive --- and extensible --- benchmark dataset comprising 128 feature models, including challenging, real-world models of the Linux kernel. BURST takes as inputs a sampling tool, a set of feature models and a sampling budget. It automatically translates any feature model of the set in DIMACS and invokes the sampling tool to generate the budgeted number of samples. To evaluate the scalability of the sampling tool, BURST measures the time the tool needs to produce the requested sample. To evaluate the uniformity of the produced sample, BURST integrates the state-of-the-art and proven statistical test Barbarik. We envision BURST to become the starting point of a standardisation initiative of sampling tool evaluation. Given the huge interest of research for sampling algorithms and tools, this initiative would have the potential to reach and crosscut multiple research communities including AI, ML, SAT and SPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {36–40},
numpages = {5},
keywords = {variability model, software product lines, sampling, configurable systems, benchmark, SAT},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461001.3471149,
author = {Lesoil, Luc and Acher, Mathieu and T\'{e}rnava, Xhevahire and Blouin, Arnaud and J\'{e}z\'{e}quel, Jean-Marc},
title = {The interplay of compile-time and run-time options for performance prediction},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471149},
doi = {10.1145/3461001.3471149},
abstract = {Many software projects are configurable through compile-time options (e.g., using ./configure) and also through run-time options (e.g., command-line parameters, fed to the software at execution time). Several works have shown how to predict the effect of run-time options on performance. However it is yet to be studied how these prediction models behave when the software is built with different compile-time options. For instance, is the best run-time configuration always the best w.r.t. the chosen compilation options? In this paper, we investigate the effect of compile-time options on the performance distributions of 4 software systems. There are cases where the compiler layer effect is linear which is an opportunity to generalize performance models or to tune and measure runtime performance at lower cost. We also prove there can exist an interplay by exhibiting a case where compile-time options significantly alter the performance distributions of a configurable system.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {100–111},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3307630.3342387,
author = {Baum, David and Sixtus, Christina and Vogelsberg, Lisa and Eisenecker, Ulrich},
title = {Understanding Conditional Compilation through Integrated Representation of Variability and Source Code},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342387},
doi = {10.1145/3307630.3342387},
abstract = {The C preprocessor (CPP) is a standard tool for introducing variability into source programs and is often applied either implicitly or explicitly for implementing a Software Product Line (SPL). Despite its practical relevance, CPP has many drawbacks. Because of that it is very difficult to understand the variability implemented using CPP. To facilitate this task we provide an innovative analytics tool which bridges the gap between feature models as more abstract representations of variability and its concrete implementation with the means of CPP. It allows to interactively explore the entities of a source program with respect to the variability realized by conditional compilation. Thus, it simplifies tracing and understanding the effect of enabling or disabling feature flags.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {21–24},
numpages = {4},
keywords = {visual analytics, variablity, software visualization, software prodect line, preprocessor, getaviz, conditional compilation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461001.3473061,
author = {Tomashchuk, Oleksandr and Van Landuyt, Dimitri and Joosen, Wouter},
title = {The architectural divergence problem in security and privacy of eHealth IoT product lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473061},
doi = {10.1145/3461001.3473061},
abstract = {The Internet of Things (IoT) seamlessly becomes integrated into many aspects of daily life, and in the case of healthcare, it arises in the shape of eHealth IoT systems. Evidently, the design of such systems must apply best practices when it comes to security and privacy, in addition to ensuring compliance with various national and international regulations. When it comes to the required functionality, commonalities and variations can effectively be managed in a product line approach that involves deriving specific application architecture variants from a common reference architecture.This paper illustrates and discusses a specific problem encountered in the establishment of a software product-line in this specific context: the adoption of systematic security and privacy threat modeling and risk assessment approaches introduces a variation space that is very difficult to capture in a proactive product-line approach. One of the main causes for this is that threat assessment itself suffers from the problem of threat explosion, i.e. combinatorial explosions of threats that have to be investigated and systematically mitigated. The highlighted divergence of the security and privacy threats across architectural variants is illustrated in the specific case of an industry IoT-based e-health software product line.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {114–119},
numpages = {6},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2499777.2500723,
author = {Alsawalqah, Hamad and Kang, Sungwon and Lee, Danhyung},
title = {A method for software product platform design based on features},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500723},
doi = {10.1145/2499777.2500723},
abstract = {Due to the increased competition and the advent of mass customization, software firms are applying the Software Product Line Engineering (SPLE) approach to provide product variety in a cost-effective manner. Although the key to designing a successful software product family is the product platform, yet there is lack of measures and methods that are useful to optimize the product platform design. This paper proposes a method to provide decision support to determine the optimized product platform design. The method targets at identifying the optimized product platform design in order to maximize the cost savings and the amount of commonality while meeting the goals and needs of the envisioned customers' segments. It generates, validates, and evaluates alternative product platform designs while considering market concerns (e.g., customer preferences) and technical product platform concerns (e.g., decisions regarding shared features, economic benefit). We demonstrate its applicability with an example of platform design problem in smart phones domain.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {18–25},
numpages = {8},
keywords = {software product line, product platform design, commonality index, Kano scheme},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3461002.3473073,
author = {Pett, Tobias and Krieter, Sebastian and Th\"{u}m, Thomas and Lochau, Malte and Schaefer, Ina},
title = {AutoSMP: an evaluation platform for sampling algorithms},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473073},
doi = {10.1145/3461002.3473073},
abstract = {Testing configurable systems is a challenging task due to the combinatorial explosion problem. Sampling is a promising approach to reduce the testing effort for product-based systems by finding a small but still representative subset (i.e., a sample) of all configurations for testing. The quality of a generated sample wrt. evaluation criteria such as run time of sample generation, feature coverage, sample size, and sampling stability depends on the subject systems and the sampling algorithm. Choosing the right sampling algorithm for practical applications is challenging because each sampling algorithm fulfills the evaluation criteria to a different degree. Researchers keep developing new sampling algorithms with improved performance or unique properties to satisfy application-specific requirements. Comparing sampling algorithms is therefore a necessary task for researchers. However, this task needs a lot of effort because of missing accessibility of existing algorithm implementations and benchmarks. Our platform AutoSMP eases practitioners and researchers lifes by automatically executing sampling algorithms on predefined benchmarks and evaluating the sampling results wrt. specific user requirements. In this paper, we introduce the open-source application of AutoSMP and a set of predefined benchmarks as well as a set of T-wise sampling algorithms as examples.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {41–44},
numpages = {4},
keywords = {sampling evalutaion, sampling, product lines},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3383219.3383229,
author = {Li, Yang and Schulze, Sandro and Xu, Jiahua},
title = {Feature Terms Prediction: A Feasible Way to Indicate the Notion of Features in Software Product Line},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383229},
doi = {10.1145/3383219.3383229},
abstract = {In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way. Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature. Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature. Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis. In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms. To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset. Subsequently, we apply seven commonly used machine algorithms to train prediction models on the labeled dataset. We then use these prediction models to predict feature terms from the requirements belonging to the other two different domains. Our results show that (1) feature terms can be predicted with high accuracy of ≈ 90% within a domain (2) prediction across domains leads to a decreased but still good accuracy (≈ 80%), and (3) machine learning algorithms perform differently.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {90–99},
numpages = {10},
keywords = {Software Product Lines, Requirement Documents, Feature Terms Identification, Feature Extraction},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/3461002.3473944,
author = {Ballesteros, Joaqu\'{\i}n and Fuentes, Lidia},
title = {Transfer learning for multiobjective optimization algorithms supporting dynamic software product lines},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473944},
doi = {10.1145/3461002.3473944},
abstract = {Dynamic Software Product Lines (DSPLs) are a well-accepted approach for self-adapting Cyber-Physical Systems (CPSs) at run-time. The DSPL approaches make decisions supported by performance models, which capture system features' contribution to one or more optimization goals. Combining performance models with Multi-Objectives Evolutionary Algorithms (MOEAs) as decision-making mechanisms is common in DSPLs. However, MOEAs algorithms start solving the optimization problem from a randomly selected population, not finding good configurations fast enough after a context change, requiring too many resources so scarce in CPSs. Also, the DSPL engineer must deal with the hardware and software particularities of the target platform in each CPS deployment. And although each system instantiation has to solve a similar optimization problem of the DSPL, it does not take advantage of experiences gained in similar CPS. Transfer learning aims at improving the efficiency of systems by sharing the previously acquired knowledge and applying it to similar systems. In this work, we analyze the benefits of transfer learning in the context of DSPL and MOEAs testing on 8 feature models with synthetic performance models. Results are good enough, showing that transfer learning solutions dominate up to 71% of the non-transfer learning ones for similar DSPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {51–59},
numpages = {9},
keywords = {transfer learning, self-adaptation, multiobjective optimization algorithms, dynamic software product lines, cyber-physical systems},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3336294.3342358,
author = {M\"{u}ller, Richard and Eisenecker, Ulrich},
title = {A Graph-Based Feature Location Approach Using Set Theory},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342358},
doi = {10.1145/3336294.3342358},
abstract = {The ArgoUML SPL benchmark addresses feature location in Software Product Lines (SPLs), where single features as well as feature combinations and feature negations have to be identified. We present a solution for this challenge using a graph-based approach and set theory. The results are promising. Set theory allows to exactly define which parts of feature locations can be computed and which precision and which recall can be achieved. This has to be complemented by a reliable identification of feature-dependent class and method traces as well as refinements. The application of our solution to one scenario of the benchmark supports this claim.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {88–92},
numpages = {5},
keywords = {static analysis, software product lines, set theory, reverse engineering, jQAssistant, graph database, feature location, extractive software product line adoption, cypher, benchmark, Neo4j, ArgoUML},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461002.3473074,
author = {Fantechi, Alessandro and Gnesi, Stefania and Livi, Samuele and Semini, Laura},
title = {A spaCy-based tool for extracting variability from NL requirements},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473074},
doi = {10.1145/3461002.3473074},
abstract = {In previous work, we have shown that ambiguity detection in requirements can also be used as a way to capture latent aspects of variability. Natural Language Processing (NLP) tools have been used for a lexical analysis aimed at ambiguity indicators detection, and we have studied the necessary adaptations to those tools for pointing at potential variability, essentially by adding specific dictionaries for variability. We have identified also some syntactic rules able to detect potential variability, such as disjunction between nouns or pairs of indicators in a subordinate proposition. This paper describes a new prototype NLP tool, based on the spaCy library, specifically designed to detect variability. The prototype is shown to preserve the same recall exhibited by previously used lexical tools, with a higher precision.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {32–35},
numpages = {4},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.procs.2019.11.105,
author = {Komarudin, Oman and Adianto, Daya and Azurat, Ade},
title = {Modeling Requirements of Multiple Single Products to Feature Model},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {161},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.11.105},
doi = {10.1016/j.procs.2019.11.105},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {107–114},
numpages = {8},
keywords = {domain engineering, feature model, software product line engineering}
}

@inproceedings{10.1145/3382026.3425772,
author = {Ca\~{n}ete, Angel and Amor, Mercedes and Fuentes, Lidia},
title = {Supporting the evolution of applications deployed on edge-based infrastructures using multi-layer feature models},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425772},
doi = {10.1145/3382026.3425772},
abstract = {The proliferation of cyber-physical systems has encouraged the emergence of new technologies and paradigms to improve the performance of IoT-based applications. Edge Computing proposes using the nearby devices in the frontier/Edge of the access network for deploying application tasks. However, the functionality of cyberphysical systems, which is usually distributed in several devices and computers, imposes specific requirements on the infrastructure to run properly. The evolution of an application to meet new user requirements and the high diversity of hardware and software technologies in the edge can complicate the deployment of evolved applications.The aim of our approach is to apply Multi Layer Feature Models, which capture the variability of applications and the infrastructure, to support the deployment in edge-based environments of cyber-physical systems applications. This separation can support the evolution of application and infrastructure. Considering that IoT/Edge/Cloud infrastructures are usually shared by many applications, the SPL deployment process has to assure that there will be enough resources for all of them, informing developers about the alternatives of deployment. Prior to its deployment and leaning on the infrastructure feature models, the developer can calculate what is the configuration of minimal set of devices supporting application requirements of the evolved application. In addition, the developer can find which is the application configuration that can be hosted in the current evolved infrastructure.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {79–87},
numpages = {9},
keywords = {Software Product Line, Software Evolution, Multi Layer Feature Models, Internet of Things, Edge Computing},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3109729.3109751,
author = {Krieter, Sebastian and Pinnecke, Marcus and Kr\"{u}ger, Jacob and Sprey, Joshua and Sontag, Christopher and Th\"{u}m, Thomas and Leich, Thomas and Saake, Gunter},
title = {FeatureIDE: Empowering Third-Party Developers},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109751},
doi = {10.1145/3109729.3109751},
abstract = {FeatureIDE is a popular open-source tool for modeling, implementing, configuring, and analyzing software product lines. However, FeatureIDE's initial design was lacking mechanisms that facilitate extension and reuse of core implementations. In current releases, we improve these traits by providing a modular concept for core data structures and functionalities. As a result, we are facilitating the usage of external implementations for feature models and file formats within FeatureIDE. Additionally, we provide a Java library containing FeatureIDE's core functionalities, including feature modeling and configuration. This allows developers to use these functionalities in their own tools without relying on external dependencies, such as the Eclipse framework.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {42–45},
numpages = {4},
keywords = {feature-oriented software development, feature modeling, configuration, Software product line},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.5555/1885639.1885642,
author = {Bagheri, Ebrahim and Di Noia, Tommaso and Ragone, Azzurra and Gasevic, Dragan},
title = {Configuring software product line feature models based on Stakeholders' soft and hard requirements},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling is a technique for capturing commonality and variability. Feature models symbolize a representation of the possible application configuration space, and can be customized based on specific domain requirements and stakeholder goals. Most feature model configuration processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called P(N). Furthermore, we formalize the representation of soft constraints in fuzzy P(N) and explain how semi-automated feature model configuration is performed. The model configuration derivation process that we propose respects the soundness and completeness properties.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {16–31},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/2499777.2500725,
author = {Varshosaz, Mahsa and Khosravi, Ramtin},
title = {Discrete time Markov chain families: modeling and verification of probabilistic software product lines},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500725},
doi = {10.1145/2499777.2500725},
abstract = {Software product line engineering (SPLE) enables systematic reuse in development of a family of related software systems by explicitly defining commonalities and variabilities among the individual products in the family. Nowadays, SPLE is used in a variety of complex domains such as avionics and automotive. As such domains include safety critical systems which exhibit probabilistic behavior, there is a major need for modeling and verification approaches dealing with probabilistic aspects of systems in the presence of variabilities. In this paper, we introduce a mathematical model, Discrete Time Markov Chain Family (DTMCF), which compactly represents the probabilistic behavior of all the products in the product line. We also provide a probabilistic model checking method to verify DTMCFs against Probabilistic Computation Tree Logic (PCTL) properties. This way, instead of verifying each product individually, the whole family is model checked at once, resulting in the set of products satisfying the desired property. This reduces the required cost for model checking by eliminating redundant processing caused by the commonalities among the products.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {34–41},
numpages = {8},
keywords = {variable discrete time Markov chains, software product line, probabilistic model checking},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3106195.3106215,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Self-healing in Service Mashups Through Feature Adaptation},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106215},
doi = {10.1145/3106195.3106215},
abstract = {The composition of the functionality of multiple services into a single unique service mashup has received wide interest in the recent years. Given the distributed nature of these mashups where the constituent services can be located on different servers, it is possible that a change in the functionality or availability of a constituent service result in the failure of the service mashup. In this paper, we propose a novel method based on the Software Product Line Engineering (SPLE) paradigm which is able to find an alternate valid service mashup which has maximum possible number of original service mashup features in order to mitigate a service failure when complete recovery is not possible. This method also has an advantage that it can recover or mitigate the failure automatically without requiring the user to specify any adaptation rule or strategy. We show the practicality of our proposed approach through extensive experiments.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {94–103},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1016/j.scico.2012.04.009,
author = {Marinho, Fabiana G. and Andrade, Rossana M. C. and Werner, Cl\'{a}udia and Viana, Windson and Maia, Marcio E. F. and Rocha, Lincoln S. and Teixeira, Eld\'{\i}nae and Filho, Jo\~{a}o B. Ferreira and Dantas, Val\'{e}ria L. L. and Lima, Fabr\'{\i}cio and Aguiar, Saulo},
title = {MobiLine: A Nested Software Product Line for the domain of mobile and context-aware applications},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.04.009},
doi = {10.1016/j.scico.2012.04.009},
abstract = {Mobile devices are multipurpose and multi-sensor equipments supporting applications able to adapt their behavior according to changes in the user's context (device, location, time, etc.). Meanwhile, the development of mobile and context-aware software is not a simple task, mostly due to the peculiar characteristics of these devices. Although several solutions have been proposed to facilitate their development, reuse is not systematically used throughout the software development life-cycle. In this paper, we discuss an approach for the development of mobile and context-aware software using the Software Product Line (SPL) paradigm. Furthermore, a Nested SPL for the domain of mobile and context-aware applications is presented, lessons learned in the SPL development are discussed and a product for a context-aware visit guide is shown.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2381–2398},
numpages = {18},
keywords = {Software product line, Mobility, Context-awareness}
}

@inproceedings{10.1145/3336294.3336317,
author = {Duszynski, Slawomir and Dhar, Saura Jyoti and Beichter, Tobias},
title = {Using Relation Graphs for Improved Understanding of Feature Models in Software Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336317},
doi = {10.1145/3336294.3336317},
abstract = {Feature models are widely used for describing the variability of a software product line. A feature model contains a tree of features and a set of constraints over these features, which define valid feature combinations. In the industrial practice, large feature models containing hundreds of features and constraints are common. Furthermore, in a hierarchical product line a feature model can be related to other feature models through inter-model constraints. Due to the model size and complexity, understanding industrial feature models is a challenging task.In this paper, we describe the feature model understanding challenges reported by feature model developers at Robert Bosch GmbH. To support the developers in model understanding, we extend the idea of a feature implication graph to feature relation graph by abstracting groups of implications to feature relations. A transitively closed relation graph shows all modeled and implicit feature relations and spans all related feature models. The graph is also used to identify modeling problems, such as false optional or dead features, and to show the derivation of any implicit relation or problem from the modeled constraints. In a case study at Bosch, we evaluate the use of feature relation graph for model understanding. We propose further use cases of the graph, supporting model maintenance, evolution and configuration.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {309–319},
numpages = {11},
keywords = {model understanding, implication graph, feature model},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3336294.3342376,
author = {Lanna, Andre and Castro, Thiago and Alves, Vander and Rodrigues, Genaina and Schobbens, Pierre-Yves and Apel, Sven},
title = {Feature-Family-Based Reliability Analysis of Software Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342376},
doi = {10.1145/3336294.3342376},
abstract = {Context: Verification techniques such as model checking are being applied to ensure that software systems achieve desired quality levels and fulfill their functional and non-functional specification. However, applying these techniques to software product lines is a twofold challenge, given the exponential blowup of the number of products and the state-explosion problem inherent to model checking. Current product-line verification techniques leverage symbolic model checking and variability information to optimize the analysis but still face limitations that make them costly or infeasible. In particular, state-of-the-art verification techniques for product-line reliability analysis are enumerative which hinders their applicability, given the latent blowup of the configuration space.Objective: Our objectives are the following: (a) we present a method to efficiently compute the reliability of all configurations of a compositional or annotation-based software product line from its UML behavioral models, (b) we provide a tool that implements the proposed method, and (c) we report on an empirical study comparing the performance of different reliability analysis strategies for software product lines.Method: We present a novel feature-family-based analysis strategy to compute the reliability of all products of a (compositional or annotation-based) software product line. The strategy employs a divide-and-conquer approach over UML behavioral models endowed with probabilistic and variability information. The feature-based step of our strategy divides the behavioral models into smaller feature-dependent fragments that can be analyzed more efficiently. Such analysis consists of creating a probabilistic model for each behavioral fragment and analyzing such model using a parametric model checker that returns an expression denoting its reliability. Parameters in such expression represent the reliabilities of fragments on which it depends at runtime. The family-based step performs the reliability computation for all configurations at once (conquer) by evaluating reliability expressions in terms of a suitable variational data structure. This step solves the expression computed for each behavioral fragment taking into account (a) the fragment's variability information and (b) the reliability values already computed for the fragments on which it depends. The result is an Algebraic Decision Diagram (ADD) whose terminals different than zero represent the reliability value of valid (partial) configurations for the fragment. Therefore, the ADD computed for the last evaluated fragment contains the reliability values for all valid configurations of the software product line.Results: We performed an experiment to compare our feature-family-based and other four state-of-the-art evaluation strategies (product-based, family-based, feature-product-based and family-product-based). The subjects were variations of six publicly available product lines, whose configuration spaces were progressively increased. The empirical results show that our feature-family-based strategy outperforms, in terms of time and space, the other four state-of-the-art strategies. In addition, it is the only one that could be scaled to a 220-fold increase in the size of the configuration space.Conclusion: Our feature-family-based strategy leverages both feature-based and family-based strategies by taming the size of the models to be analyzed (due to the decomposition of behavioral models into fragments) and by avoiding the products enumeration inherent to some state-of-the-art analysis methods by using ADDs to represent both variability and reliability values.Journal paper: This paper was published at the Information and Software Technology Journal. It is available at https://doi.org/10.1016/j.infsof.2017.10.001.Supplementary material: Additional material to the IST submission is available at https://splmc.github.io/scalabilityAnalysis/. This material comprises experiments data, the tool implementing the feature-family-based reliability analysis strategy and the environment for experiment replication.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {64},
numpages = {1},
keywords = {software reliability analysis, software product lines, parametric verification},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2648511.2648542,
author = {Hellebrand, Robert and Silva, Adeline and Becker, Martin and Zhang, Bo and Sierszecki, Krzysztof and Savolainen, Juha},
title = {Coevolution of variability models and code: an industrial case study},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648542},
doi = {10.1145/2648511.2648542},
abstract = {In Software Engineering, reuse of artifacts is essential for high productivity. Different studies have shown that efficient reuse needs systematic planning and realization. Variability Management plays a key role in Software Product Line Engineering. We investigate code artifacts and variability models of a real-world Software Product Line over time in order to clarify whether code and variability model evolve congeneric. Furthermore, we suggest and test metrics that would allow detecting variability erosion in the code based on changes in the variability model.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {274–283},
numpages = {10},
keywords = {product line evolution, metrics, feature models, coevolution},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3461001.3471144,
author = {Uta, Mathias and Felfernig, Alexander and Le, Viet-Man and Popescu, Andrei and Tran, Thi Ngoc Trang and Helic, Denis},
title = {Evaluating recommender systems in feature model configuration},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471144},
doi = {10.1145/3461001.3471144},
abstract = {Configurators can be evaluated in various ways such as efficiency and completeness of solution search, optimality of the proposed solutions, usability of configurator user interfaces, and configuration consistency. Due to the increasing size and complexity of feature models, the integration of recommendation algorithms with feature model configurators becomes relevant. In this paper, we show how the output of a recommender system can be evaluated within the scope of feature model configuration scenarios. Overall, we argue that the discussed ways of measuring recommendation quality help developers to gain a broader view on evaluation techniques in constraint-based recommendation domains.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {58–63},
numpages = {6},
keywords = {recommender systems, feature models, evaluation, configuration},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2364412.2364419,
author = {Asadi, Mohsen and Bagheri, Ebrahim and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {Requirements engineering in feature oriented software product lines: an initial analytical study},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364419},
doi = {10.1145/2364412.2364419},
abstract = {Requirements engineering is recognized as a critical stage in software development lifecycle. Given the nature of Software Product Lines (SPL), the importance of requirements engineering is more pronounced as SPLs pose more complex challenges than development of a 'single' product. Several methods have been proposed in the literature, which encompass activities for capturing requirements, their variability and commonality. To investigate the maturity and effectiveness of the current requirements engineering approaches in software product lines, we develop an evaluation framework containing a set of evaluation criteria and assess feature oriented requirements engineering methods based on the proposed criteria. As a result of this initial study, we find out the majority of approaches lacks proper techniques for supporting the validation of family requirements models as well as dealing with delta requirements. Additionally, capturing stakeholders' preferences and applying them during the course of software feature configuration have not been taken into account and addressed in the proposed approaches.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {36–44},
numpages = {9},
keywords = {software product line engineering, software engineering, requirements engineering, evaluation criteria},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/11767718_28,
author = {Chang, Soo Ho and Kim, Soo Dong and Rhew, Sung Yul},
title = {A variability-centric approach to instantiating core assets in product line engineering},
year = {2006},
isbn = {3540346821},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11767718_28},
doi = {10.1007/11767718_28},
abstract = {As a key activity in product line engineering (PLE), instantiation is a task to generate target applications by resolving variability embedded in core assets. However, instantiation is often conducted in manual and ad-hoc fashion, largely replying on domain knowledge and experience. Hence, it can easily lead to technical problems in precisely specifying decision model consisting of product-specific variation points and variants, and in handling inter-variant conflicts/dependency. To overcome this difficulty, it is desirable to develop a systematic process which includes a set of systematic activities, detailed instructions, and concrete specification of artifacts. In this paper, we first propose a meta-model of a core asset to specify its key elements. Then, we represent a comprehensive process that defines key instantiation activities, representations of artifacts, and work instructions. With the proposed process, one can instantiate core assets more effectively and systematically.},
booktitle = {Proceedings of the 7th International Conference on Product-Focused Software Process Improvement},
pages = {334–347},
numpages = {14},
location = {Amsterdam, The Netherlands},
series = {PROFES'06}
}

@inproceedings{10.1145/3307630.3342411,
author = {Meixner, Kristof and Rabiser, Rick and Biffl, Stefan},
title = {Towards Modeling Variability of Products, Processes and Resources in Cyber-Physical Production Systems Engineering},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342411},
doi = {10.1145/3307630.3342411},
abstract = {Planning and developing Cyber-Physical Production Systems (CPPS) are multi-disciplinary engineering activities that rely on effective and efficient knowledge exchange for better collaboration between engineers of different disciplines. The Product-Process-Resource (PPR) approach allows modeling products produced by industrial processes using specific production resources. In practice, a CPPS manufactures a portfolio of product type variants, i.e., a product line. Therefore, engineers need to create and maintain several PPR models to cover PPR variants and their evolving versions. In this paper, we detail a representative use case, identify challenges for using Variability Modeling (VM) methods to describe and manage PPR variants, and present a first solution approach based on cooperation with domain experts at an industry partner, a system integrator of automation for high-performance CPPS. We conclude that integrating basic variability concepts into PPR models is a promising first step and describe our further research plans to support PPR VM in CPPS.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {49–56},
numpages = {8},
keywords = {variability modelling, product-process-resource, cyber-physical production system},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3236405.3237202,
author = {Krafczyk, Adam and El-Sharkawy, Sascha and Schmid, Klaus},
title = {Reverse engineering code dependencies: converting integer-based variability to propositional logic},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237202},
doi = {10.1145/3236405.3237202},
abstract = {A number of SAT-based analysis concepts and tools for software product lines exist, that extract code dependencies in propositional logic from the source code assets of the product line. On these extracted conditions, SAT-solvers are used to reason about the variability. However, in practice, a lot of software product lines use integer-based variability. The variability variables hold integer values, and integer operators are used in the conditions. Most existing analysis tools can not handle this kind of variability; they expect pure Boolean conditions.This paper introduces an approach to convert integer-based variability conditions to propositional logic. Running this approach as a preparation on an integer-based product line allows the existing SAT-based analyses to work without any modifications. The pure Boolean formulas, that our approach builds as a replacement for the integer-based conditions, are mostly equivalent to the original conditions with respect to satisfiability. Our approach was motivated by and implemented in the context of a real-world industrial case-study, where such a preparation was necessary to analyze the variability.Our contribution is an approach to convert conditions, that use integer variables, into propositional formulas, to enable easy usage of SAT-solvers on the result. It works well on restricted variables (i.e. variables with a small range of allowed values); unrestricted integer variables are handled less exact, but still retain useful variability information.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {34–41},
numpages = {8},
keywords = {variability management, software product lines, satisfiability, reverse engineering, propositional logic, integer-based expressions},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2648511.2655956,
author = {Chitchyan, Ruzanna and Noppen, Joost and Groher, Iris},
title = {Sustainability in software product lines},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2655956},
doi = {10.1145/2648511.2655956},
abstract = {Sustainability encompasses a wide set of aims: ranging from energy efficient software products (environmental sustainability), reduction of software development and maintenance costs (economic sustainability), to employee wellbeing (social sustainability). This panel brings together researchers and practitioners to explore the role that sustainability will play in software product line engineering. The panel aims to explore how sustainability manifests itself in domain engineering, via study of, for instance, sustainability patterns in domain analysis, architectural decisions motivated by specific sustainability concerns, types of variability that results from sustainability considerations, as well as engineering of sustainability as a domain itself. This panel explores challenges in research and practice for Sustainability in Software Product Line Engineering.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {367},
numpages = {1},
keywords = {sustainability through product liens, sustainability of product lines, sustainability, product line, domain analysis},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3461001.3471154,
author = {Bergel, Alexandre and Ghzouli, Razan and Berger, Thorsten and Chaudron, Michel R. V.},
title = {FeatureVista: interactive feature visualization},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471154},
doi = {10.1145/3461001.3471154},
abstract = {Comprehending and characterizing the spread and interaction of features in a software system is know to be difficult and error-prone. This paper presents FeatureVista, a lightweight tool providing interactive, glyph-based, and iconic visualization concepts designed to visually characterize the feature locations in software assets (source code). FeatureVista supports navigating between software components and features in an equal fashion. Our pilot study indicates that FeatureVista is intuitive and supports comprehending features. It helps to precisely characterize relations among features in large software systems and to contrast explicit software component definitions (e.g., package, class, method) with annotated feature portions---which so far was a largely manual and error-prone activity, albeit essential to get an adequate understanding of a software system. We suggest research directions for true, feature-oriented interfaces that can be used to manage software assets.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {196–201},
numpages = {6},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2648511.2648550,
author = {Dillon, Michael and Rivera, Jorge and Darbin, Rowland},
title = {A methodical approach to product line adoption},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648550},
doi = {10.1145/2648511.2648550},
abstract = {The evolution of the U.S. Army's Live Training Transformation (LT2) product line of combat training systems, including the move by the Army to consolidate management of the product line under a single contracting team, has provided a natural experiment that validates the hypothesis that product line engineering practices are more effective than traditional software engineering practices, and has demonstrated which product line adoption approaches are more successful than others. By analyzing this natural experiment, the product line team has been able to apply a methodical approach to product line adoption across the development organization and successfully adopt second generation product line processes. This paper explores that methodical approach. It will enumerate the steps that led to successes and explore the contributing factors and unintended consequences of failures along the way. Additionally this paper will explore how this approach is being employed to extend the LT2 product line beyond software.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {340–349},
numpages = {10},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line governance, product line engineering, product line adoption, product configurator, product baselines, feature profiles, feature modeling, feature constraints hierarchical product lines, bill-of-features},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3382025.3414976,
author = {Pereira, Juliana Alves and Martin, Hugo and Temple, Paul and Acher, Mathieu},
title = {Machine learning and configurable systems: a gentle introduction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414976},
doi = {10.1145/3382025.3414976},
abstract = {The goal of this tutorial is to give a gentle introduction to how machine learning can be used to support software product line configuration. This is our second practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance and bug prediction) on real-world systems (Linux, VaryLaTeX, x264). The material is designed for academics and practitioners with basic knowledge in software product lines and machine learning.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {40},
numpages = {1},
keywords = {software product lines, machine learning, configurable systems},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3236405.3236427,
author = {Li, Yang},
title = {Feature and variability extraction from natural language software requirements specifications},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236427},
doi = {10.1145/3236405.3236427},
abstract = {Extracting feature and variability from requirement specifications is an indispensable activity to support systematic integration related single software systems into Software Product Line (SPL). Performing variability extraction is time-consuming and inefficient, since massive textual requirements need to be analyzed and classified. Despite the improvement of automatically features and relationships extraction techniques, existing approaches are not able to provide high accuracy and applicability in real-world scenarios. The aim of my doctoral research is to develop an automated technique for extracting features and variability which provides reliable solutions to simplify the work of domain analysis. I carefully analyzed the state of the art and identified main limitations so far: accuracy and automation. Based on these insights, I am developing a methodology to address this challenges by making use of advanced Natural Language Processing (NLP) and machine learning techniques. In addition, I plan to design reasonable case study to evaluate the proposed approaches and empirical study to investigate usability in practice.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {72–78},
numpages = {7},
keywords = {variability extraction, software product lines, reverse engineering, requirement documents, feature identification},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/1094855.1094946,
author = {Liu, Shih-Hsi},
title = {A software product line architecture for distributed real-time and embedded systems: a separation of concerns approach},
year = {2005},
isbn = {1595931937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1094855.1094946},
doi = {10.1145/1094855.1094946},
abstract = {This paper presents a separation of concerns approach to solve the tangling problem of functional and Quality of Service (QoS) concerns in traditional Component-based Software Engineering (CBSE) and Software Product Line (SPL) technologies applied to Distributed Real-time and Embedded (DRE) systems. This problem originates from the interchangeability for fulfilling functional and QoS concerns during composition. The approach utilizes the perspective of QoS to design and analyze a set of software systems represented by a collection of QoS systemic paths, which determine how well functional tasks perform in terms of flows of application-specific and functionality-determined information between components. Our approach not only reserves the virtues of reusability, changeability, productivity and expeditiousness that traditional CBSE and SPL technologies possess, but also dedicates the contributions in terms of separation of concerns, design space exploration, fine-grained commonality and reusability evaluation and less subjective feasibility analyses for a component-based SPL.},
booktitle = {Companion to the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {224–225},
numpages = {2},
keywords = {two-level grammar++, software product line architecture, real-time, quality of service, UniFrame},
location = {San Diego, CA, USA},
series = {OOPSLA '05}
}

@inproceedings{10.1145/3461002.3473949,
author = {Romero, David and Galindo, Jos\'{e} \'{A}. and Horcas, Jose-Miguel and Benavides, David},
title = {A first prototype of a new repository for feature model exchange and knowledge sharing},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473949},
doi = {10.1145/3461002.3473949},
abstract = {Feature models are the "de facto" standard for variability modelling and are used in both academia and industry. The MODEVAR initiative tries to establish a common textual feature modelling language that can be used by different communities and can allow information sharing. Feature model related researches use different models for different purposes such as analysis, sampling, testing, debugging, teaching, etc. Those models are shared in private repositories and there is a risk that all that knowledge is spread across different platforms which hinder collaboration and knowledge reuse. In this paper, we propose a first working version of a new feature model repository that allows to centralise the knowledge generated in the community together with advanced capabilities such as DOI generation, an API, analysis reports, among others. Our solution is a front end interface that uses the popular open science repository Zenodo as an end point to materialise the storage of all the information. Zenodo is enhanced with characteristics that facilitate the management of the models. The idea of our repository is to provide existing but also new features that are not present in other repositories (e.g., SPLOT). We propose to populate our repository with all the existing models of many sources including SPLOT.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {80–85},
numpages = {6},
keywords = {variability, requirements, feature model repository, characteristics},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382025.3414962,
author = {Chrszon, Philipp and Baier, Christel and Dubslaff, Clemens and Kl\"{u}ppelholz, Sascha},
title = {From features to roles},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414962},
doi = {10.1145/3382025.3414962},
abstract = {The detection of interactions is a challenging task present in almost all stages of software development. In feature-oriented system design, this task is mainly investigated for interactions of features within a single system, detected by their emergent behaviors. We propose a formalism to describe interactions in hierarchies of feature-oriented systems (hierarchical interactions) and the actual situations where features interact (active interplays). Based on the observation that such interactions are also crucial in role-based systems, we introduce a compositional modeling framework based on concepts and notions of roles, comprising role-based automata (RBAs). To describe RBAs, we present a modeling language that is close to the input language of the probabilistic model checker Prism. To exemplify the use of RBAs, we implemented a tool that translates RBA models into Prism and thus enables the formal analysis of functional and non-functional properties including system dynamics, contextual changes, and interactions. We carry out two case studies as a proof of concept of such analyses: First, a peer-to-peer protocol case study illustrates how undesired hierarchical interactions can be discovered automatically. Second, a case study on a self-adaptive production cell demonstrates how undesired interactions influence quality-of-service measures such as reliability and throughput.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {19},
numpages = {11},
keywords = {verification, roles, formal methods, feature-oriented systems},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/APSEC.2004.12,
author = {Kim, Soo Dong and Chang, Soo Ho and Chang, Chee Won},
title = {A Systematic Method to Instantiate Core Assets in Product Line Engineering},
year = {2004},
isbn = {0769522459},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2004.12},
doi = {10.1109/APSEC.2004.12},
abstract = {Product line engineering (PLE) is one of the recent and effective reuse approaches, and it consists of two processes; framework engineering and application engineering. Framework engineering is to model and realize a core asset which represents common functionality and quality attributes in a target domain, and application engineering is to generate a target product by instantiating the core asset. Hence, a core asset is a key element of PLE, and the quality of core assets largely determines the overall quality of products. Although numerous PLE methodologies have been introduced, it is still unclear what should be the elements of a core asset and how the core asset should be instantiated for each application. That is, the overall process and instructions of instantiating core assets have not been studied enough. In this paper, we first define a meta-model of core assets, propose a process of instantiation, and define its instructions on how to carry out each activity in practice. We believe that the proposed meta-model and the process framework can effectively be used in developing core asset and applications in practice.},
booktitle = {Proceedings of the 11th Asia-Pacific Software Engineering Conference},
pages = {92–98},
numpages = {7},
series = {APSEC '04}
}

@inproceedings{10.1145/3307630.3342414,
author = {Th\"{u}m, Thomas and Teixeira, Leopoldo and Schmid, Klaus and Walkingshaw, Eric and Mukelabai, Mukelabai and Varshosaz, Mahsa and Botterweck, Goetz and Schaefer, Ina and Kehrer, Timo},
title = {Towards Efficient Analysis of Variation in Time and Space},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342414},
doi = {10.1145/3307630.3342414},
abstract = {Variation is central to today's software development. There are two fundamental dimensions to variation: Variation in time refers to the fact that software exists in numerous revisions that typically replace each other (i.e., a newer version supersedes an older one). Variation in space refers to differences among variants that are designed to coexist in parallel. There are numerous analyses to cope with variation in space (i.e., product-line analyses) and others that cope with variation in time (i.e., regression analyses). The goal of this work is to discuss to which extent product-line analyses can be applied to revisions and, conversely, where regression analyses can be applied to variants. In addition, we discuss challenges related to the combination of product-line and regression analyses. The overall goal is to increase the efficiency of analyses by exploiting the inherent commonality between variants and revisions.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {57–64},
numpages = {8},
keywords = {variability-aware analysis, variability management, software variation, software product lines, software evolution, software configuration management, regression analysis, product-line analysis},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2934466.2934474,
author = {Myll\"{a}rniemi, Varvana and Raatikainen, Mikko and Savolainen, Juha and M\"{a}nnist\"{o}, Tomi},
title = {Purposeful performance variability in software product lines: a comparison of two case studies},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934474},
doi = {10.1145/2934466.2934474},
abstract = {Within software product lines, customers may have different quality needs. To produce products with purposefully different quality attributes, several challenges must be addressed. First, one must be able to distinguish product quality attributes to the customers in a meaningful way. Second, one must create the desired quality attribute differences during product-line architecture design and derivation. To study how performance is varied purposefully in software product lines, we conducted a comparison and re-analysis of two industrial case studies in the telecommunication and mobile game domains. The results show that performance variants must be communicated to the customer in a way that links to customer value and her role. When performance or its adaptation are crucial for the customer, performance differences must be explicitly "designed in" with software or hardware means. Due to the emergent nature of performance, it is important to test performance and manage how other variability affects performance.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {144–153},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3307630.3342397,
author = {Shaaban, Abdelkader Magdy and Gruber, Thomas and Schmittner, Christoph},
title = {Ontology-Based Security Tool for Critical Cyber-Physical Systems},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342397},
doi = {10.1145/3307630.3342397},
abstract = {Industry 4.0 considers as a new advancement concept of the industrial revolution, which introduces a full utilization of Internet technologies. This concept aims to combine diverse technological resources into the industry field, which enables the communication between two worlds: the physical and the cyber one. Cyber-physical Systems are one of the special forces that integrate and build a variety of existing technologies and components. The diversity of components and technologies creates new security threats that can exploit vulnerabilities to attack a critical system. This work introduces an ontology-based security tool-chain able to be integrated with the initial stages of the development process of critical systems. The tool detects the potential threats, and apply the suitable security requirements which can address these threats. Eventually, it uses the ontology approach to ensure that the security requirements are fulfilled.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {207–210},
numpages = {4},
keywords = {threats, security, ontology, cyber-physical system},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3382025.3414963,
author = {Creff, Stephen and Noir, J\'{e}r\^{o}me Le and Lenormand, Eric and Madel\'{e}nat, S\'{e}bastien},
title = {Towards facilities for modeling and synthesis of architectures for resource allocation problem in systems engineering},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414963},
doi = {10.1145/3382025.3414963},
abstract = {Exploring architectural design space is often beyond human capacity and makes architectural design a difficult task. Model-based systems engineering must include assistance to the system designer in identifying candidate architectures to subsequently analyze tradeoffs. Unfortunately, existing languages and approaches do not incorporate this concern, generally favoring solution analysis over exploring a set of candidate architectures.In this paper, we explore the advantages of designing and configuring the variability problem to solve one of the problems of exploring (synthesizing) candidate architectures in systems engineering: the resource allocation problem. More specifically, this work reports on the use of the Clafer modeling language and its gateway to the CSP Choco Solver, on an industrial case study of heterogeneous hardware resource allocation (GPP-GPGPU-FPGA).Based on experiments on the modeling in Clafer, and the impact of its translation into the constraint programming paradigm (performance studies), discussions highlight some issues concerning facilities for modeling and synthesis of architectures and recommendations are proposed towards the use of this variability approach.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {32},
numpages = {11},
keywords = {variability modeling, empirical study, constraint solving, architecture synthesis, allocation problem},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3233027.3233049,
author = {Horcas, Jose-Miguel and Corti\~{n}as, Alejandro and Fuentes, Lidia and Luaces, Miguel R.},
title = {Integrating the common variability language with multilanguage annotations for web engineering},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233049},
doi = {10.1145/3233027.3233049},
abstract = {Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {196–207},
numpages = {12},
keywords = {web engineering, variability, composition, automation, annotations, SPL, CVL},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3382026.3431250,
author = {Tomashchuk, Oleksandr},
title = {Threat and Risk Management Framework for eHealth IoT Applications},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431250},
doi = {10.1145/3382026.3431250},
abstract = {The impact of the Internet of Things (IoT) on the modern industrial and commercial systems is hard to be underestimated. Almost every domain favours from the benefits that IoT brings, and healthcare does not make an exception. This is also clearly demonstrated by a widespread adoption of eHealth systems that often arise from software product lines. Nevertheless, the benefits that IoT brings come together with new threats and risks.An eHealth system that processes many types of sensitive data sets the context for this thesis. Security and privacy gain crucial importance for successful operation and broad user acceptance of the system because of the properties of the data flows that it initiates and operates. However, due to a large number of feature combinations that originate from the software product line nature of the eHealth system in question, a combinatorial explosion of relevant configurations makes reaching security and privacy goals more difficult. Furthermore, another combinatorial explosion of threats and corresponding mitigation strategies for every configuration complicates the situation even further. Nonetheless, configurations that meet specific risk budgets need to be in place.Within this thesis, a new threat and risk management (TRM) framework will be provided. It is based on STRIDE and LINDDUN methodologies, and it will overcome existing limitations by employing components on feature space modelling, risk-driven scoring, configuration decision support, and regulatory compliance. Research outcomes that have been reached so far show promising developments on the vital framework components.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {120–126},
numpages = {7},
keywords = {threats, security, risks, privacy, framework, de-identification},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3336294.3336302,
author = {Str\"{u}ber, Daniel and Mukelabai, Mukelabai and Kr\"{u}ger, Jacob and Fischer, Stefan and Linsbauer, Lukas and Martinez, Jabier and Berger, Thorsten},
title = {Facing the Truth: Benchmarking the Techniques for the Evolution of Variant-Rich Systems},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336302},
doi = {10.1145/3336294.3336302},
abstract = {The evolution of variant-rich systems is a challenging task. To support developers, the research community has proposed a range of different techniques over the last decades. However, many techniques have not been adopted in practice so far. To advance such techniques and to support their adoption, it is crucial to evaluate them against realistic baselines, ideally in the form of generally accessible benchmarks. To this end, we need to improve our empirical understanding of typical evolution scenarios for variant-rich systems and their relevance for benchmarking. In this paper, we establish eleven evolution scenarios in which benchmarks would be beneficial. Our scenarios cover typical lifecycles of variant-rich system, ranging from clone &amp; own to adopting and evolving a configurable product-line platform. For each scenario, we formulate benchmarking requirements and assess its clarity and relevance via a survey with experts in variant-rich systems and software evolution. We also surveyed the existing benchmarking landscape, identifying synergies and gaps. We observed that most scenarios, despite being perceived as important by experts, are only partially or not at all supported by existing benchmarks-a call to arms for building community benchmarks upon our requirements. We hope that our work raises awareness for benchmarking as a means to advance techniques for evolving variant-rich systems, and that it will lead to a benchmarking initiative in our community.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {177–188},
numpages = {12},
keywords = {software variability, software evolution, product lines, benchmark},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461001.3471146,
author = {Horcas, Jose-Miguel and Galindo, Jos\'{e} A. and Heradio, Ruben and Fernandez-Amoros, David and Benavides, David},
title = {Monte Carlo tree search for feature model analyses: a general framework for decision-making},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471146},
doi = {10.1145/3461001.3471146},
abstract = {The colossal solution spaces of most configurable systems make intractable their exhaustive exploration. Accordingly, relevant analyses remain open research problems. There exist analyses alternatives such as SAT solving or constraint programming. However, none of them have explored simulation-based methods. Monte Carlo-based decision making is a simulation-based method for dealing with colossal solution spaces using randomness. This paper proposes a conceptual framework that tackles various of those analyses using Monte Carlo methods, which have proven to succeed in vast search spaces (e.g., game theory). Our general framework is described formally, and its flexibility to cope with a diversity of analysis problems is discussed (e.g., finding defective configurations, feature model reverse engineering or getting optimal performance configurations). Additionally, we present a Python implementation of the framework that shows the feasibility of our proposal. With this contribution, we envision that different problems can be addressed using Monte Carlo simulations and that our framework can be used to advance the state of the art a step forward.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {190–201},
numpages = {12},
keywords = {variability modeling, software product lines, monte carlo tree search, feature models, configurable systems},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/1964138.1964141,
author = {Tang, Antony and Couwenberg, Wim and Scheppink, Erik and de Burgh, Niels Aan and Deelstra, Sybren and van Vliet, Hans},
title = {SPL migration tensions: an industry experience},
year = {2010},
isbn = {9781450305426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1964138.1964141},
doi = {10.1145/1964138.1964141},
abstract = {In a software development environment where legacy software systems have been successfully deployed, there are tensions that deter the organization from moving towards software product line engineering (SPLE). An example is the effort required to develop a product line architecture versus time-to-market pressure or the lack of evidence to justify the benefits of SPLE. In this report we discuss the tensions that exist in Oc\'{e} Technologies. A reactive software reuse approach has not yielded the desired long-term benefits of reusability. A proactive approach requires knowledge exchange and coordination between software management and technical staff. We describe how such knowledge sharing can ease the tensions and facilitate a SPLE migration process.},
booktitle = {Proceedings of the 2010 Workshop on Knowledge-Oriented Product Line Engineering},
articleno = {3},
numpages = {6},
keywords = {software product line engineering, industry case study, architecture management, agile development process},
location = {Reno, Nevada},
series = {KOPLE '10}
}

@article{10.5555/1133105.1133108,
author = {Kolb, Ronny and Muthig, Dirk and Patzke, Thomas and Yamauchi, Kazuyuki},
title = {Refactoring a legacy component for reuse in a software product line: a case study: Practice Articles},
year = {2006},
issue_date = {March 2006},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {18},
number = {2},
issn = {1532-060X},
abstract = {Product lines are a promising approach to improve conceptually the productivity of the software development process and thus to reduce both the cost and time of developing and maintaining increasingly complex systems. An important issue in the adoption of the product-line approach is the migration of legacy software components, which have not been designed for reuse, systematically into reusable product-line components. This article describes activities performed to improve systematically the design and implementation of an existing software component in order to reuse it in a software product line. The activities are embedded in the application of Fraunhofer PuLSE™-DSSA—an approach for defining domain-specific software architectures (DSSA) and product-line architectures. The component under investigation is the so-called Image Memory Handler (IMH), which is used in Ricoh's current products of office appliances such as copier machines, printers, and multi-functional peripherals. It is responsible for controlling memory usage and compressing and decompressing image data. Improvement of both the component's design and implementation are based on a systematic analysis and focused on increasing maintainability and reusability and hence suitability for use in a product line. As a result of the analysis and refactoring activities, the documentation and implementation of the component has been considerably improved as shown by quantitative data collected at the end of the activities. Despite a number of changes to the code, the external behavior of the component has been preserved without significantly affecting the performance. Copyright © 2006 John Wiley &amp; Sons, Ltd.},
journal = {J. Softw. Maint. Evol.},
month = mar,
pages = {109–132},
numpages = {24},
keywords = {variability, software product line, reuse, refactoring, legacy component, code analysis}
}

@inproceedings{10.1145/3461001.3473063,
author = {Arcaini, Paolo and Inverso, Omar and Trubiani, Catia},
title = {Automated model-based performance analysis of software product lines under uncertainty},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473063},
doi = {10.1145/3461001.3473063},
abstract = {In the context of Software Product Lines (SPLs), the performance evaluation of the different products is highly relevant, especially if such products include a set of features that are subject to uncertainties (e.g., the service time of a certain functionality may be subject to fluctuations). To this aim, variability modeling notations have been extended with the capability of assigning to the features some attributes that are defined over numeric domains (i.e., attributed feature models), possibly subject to lower and upper bounds capturing their uncertainties.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {112},
numpages = {1},
keywords = {uncertainty, software product lines, software performance engineering, queueing networks, attributed feature models},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461002.3473066,
author = {Fortz, Sophie},
title = {LIFTS: learning featured transition systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473066},
doi = {10.1145/3461002.3473066},
abstract = {This PhD project aims to automatically learn transition systems capturing the behaviour of a whole family of software-based systems. Reasoning at the family level yields important economies of scale and quality improvements for a broad range of systems such as software product lines, adaptive and configurable systems. Yet, to fully benefit from the above advantages, a model of the system family's behaviour is necessary. Such a model is often prohibitively expensive to create manually due to the number of variants. For large long-lived systems with outdated specifications or for systems that continuously adapt, the modelling cost is even higher. Therefore, this PhD proposes to automate the learning of such models from existing artefacts. To advance research at a fundamental level, our learning target are Featured Transition Systems (FTS), an abstract formalism that can be used to provide a pivot semantics to a range of variability-aware state-based modelling languages. The main research questions addressed by this PhD project are: (1) Can we learn variability-aware models efficiently? (2) Can we learn FTS in a black-box fashion? (i.e., with access to execution logs but not to source code); (3) Can we learn FTS in a white/grey-box testing fashion? (i.e., with access to source code); and (4) How do the proposed techniques scale in practice?},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {1–6},
numpages = {6},
keywords = {variability mining, software product lines, model learning, featured transition systems, active automata learning},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/2491627.2491646,
author = {Marijan, Dusica and Gotlieb, Arnaud and Sen, Sagar and Hervieu, Aymeric},
title = {Practical pairwise testing for software product lines},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491646},
doi = {10.1145/2491627.2491646},
abstract = {One key challenge for software product lines is efficiently managing variability throughout their lifecycle. In this paper, we address the problem of variability in software product lines testing. We (1) identify a set of issues that must be addressed to make software product line testing work in practice and (2) provide a framework that combines a set of techniques to solve these issues. The framework integrates feature modelling, combinatorial interaction testing and constraint programming techniques. First, we extract variability in a software product line as a feature model with specified feature interdependencies. We then employ an algorithm that generates a minimal set of valid test cases covering all 2-way feature interactions for a given time interval. Furthermore, we evaluate the framework on an industrial SPL and show that using the framework saves time and provides better test coverage. In particular, our experiments show that the framework improves industrial testing practice in terms of (i) 17% smaller set of test cases that are (a) valid and (b) guarantee all 2-way feature coverage (as opposite to 19.2% 2-way feature coverage in the hand made test set), and (ii) full flexibility and adjustment of test generation to available testing time.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {227–235},
numpages = {9},
keywords = {variability management, software product lines, feature modelling},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2934466.2934473,
author = {Olaechea, Rafael and Fahrenberg, Uli and Atlee, Joanne M. and Legay, Axel},
title = {Long-term average cost in featured transition systems},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934473},
doi = {10.1145/2934466.2934473},
abstract = {A software product line is a family of software products that share a common set of mandatory features and whose individual products are differentiated by their variable (optional or alternative) features. Family-based analysis of software product lines takes as input a single model of a complete product line and analyzes all its products at the same time. As the number of products in a software product line may be large, this is generally preferable to analyzing each product on its own. Family-based analysis, however, requires that standard algorithms be adapted to accomodate variability.In this paper we adapt the standard algorithm for computing limit average cost of a weighted transition system to software product lines. Limit average is a useful and popular measure for the long-term average behavior of a quality attribute such as performance or energy consumption, but has hitherto not been available for family-based analysis of software product lines. Our algorithm operates on weighted featured transition systems, at a symbolic level, and computes limit average cost for all products in a software product line at the same time. We have implemented the algorithm and evaluated it on several examples.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {109–118},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3307630.3342408,
author = {Schlie, Alexander and Rosiak, Kamil and Urbaniak, Oliver and Schaefer, Ina and Vogel-Heuser, Birgit},
title = {Analyzing Variability in Automation Software with the Variability Analysis Toolkit},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342408},
doi = {10.1145/3307630.3342408},
abstract = {Control software for automated production systems (aPs) becomes increasingly complex as it evolves due to changing requirements. To address varying customer demands or altered regulatory guidelines, it is common practice to create a new system variant by copying and subsequently modifying existing control software. Referred to as clone-and-own, proper documentation is typically not cherished, thereby entailing severe maintenance issues in the long-run. To mitigate such problems and to reinstate sustainable development, respective software systems need to be compared and their variability information needs to be reverse-engineered. However, recent work identified variability management in the domain of aPs to remain a challenging endevour and appropriate tool support to be missing.We bridge this gap and introduce the Variability Analysis Toolkit (VAT), an extensible platform that allows for the customizable definition of metrics to compare IEC61131-3 control software variants as well as providing means to visualize results. The VAT facilitates a working environment that allows for the exchange of produced results between users. By that, we aim to support engineers in re-engineering control software systems by providing them with means to define metrics based on their individual demands. We demonstrate the feasibility of the VAT using 24 software system variants implemented in accordance to the IEC61131-3 standard.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {191–198},
numpages = {8},
keywords = {variability, tooling, software product lines, legacy systems, automation software},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342398,
author = {Beek, Maurice H. ter and Schmid, Klaus and Eichelberger, Holger},
title = {Textual Variability Modeling Languages: An Overview and Considerations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342398},
doi = {10.1145/3307630.3342398},
abstract = {During the three decades since the invention of the first variability modeling approach [28], there have been multiple attempts to introduce advanced variability modeling capabilities. More recently, we have seen increased attention on textual variability modeling languages. In this paper, we summarize the main capabilities of state of the art textual variability modeling languages, based on [23], including updates regarding more recent work. Based on this integrated characterization, we provide a discussion of additional concerns, opportunities and challenges that are relevant for designing future (textual) variability modeling languages. The paper also summarizes relevant contributions by the authors as input to further discussions on future (textual) variability modeling languages.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {151–157},
numpages = {7},
keywords = {variability modeling, textual specification languages, software product lines},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3233027.3233033,
author = {Li, Yang and Schulze, Sandro and Saake, Gunter},
title = {Reverse engineering variability from requirement documents based on probabilistic relevance and word embedding},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233033},
doi = {10.1145/3233027.3233033},
abstract = {Feature and variability extraction from different artifacts is an indispensable activity to support systematic integration of single software systems and Software Product Line (SPL). Beyond manually extracting variability, a variety of approaches, such as feature location in source code and feature extraction in requirements, has been proposed to provide an automatic identification of features and their variation points. Compared with source code, requirements contain more complete variability information and provide traceability links to other artifacts from early development phases. In this paper, we propose a method to automatically extract features and relationships based on a probabilistic relevance and word embedding. In particular, our technique consists of three steps: First, we apply word2vec to obtain a prediction model, which we use to determine the word level similarity of requirements. Second, based on word level similarity and the significance of a word in a domain, we compute the requirements level similarity using probabilistic relevance. Third, we adopt hierarchical clustering to group features and we define four criteria to detect variation points between identified features. We perform a case study to evaluate the usability and robustness of our method and to compare it with the results of other related approaches. Initial results reveal that our approach identifies the majority of features correctly and also extracts variability information with reasonable accuracy.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {121–131},
numpages = {11},
keywords = {variability extraction, software product lines, reverse engineering, requirement documents, feature identification},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2648511.2648523,
author = {Urli, Simon and Blay-Fornarino, Mireille and Collet, Philippe},
title = {Handling complex configurations in software product lines: a tooled approach},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648523},
doi = {10.1145/2648511.2648523},
abstract = {As Software Product Lines (SPLs) are now more widely applied in new application fields such as IT or Web systems, complex and large-scale configurations have to be handled. In these fields, the strong domain orientation leads to the need to manage interrelated SPLs and multiple instances of configured sub-products, resulting in complex configurations that cannot be easily represented by simple sets of features. In this paper we propose a tooled approach to manage such SPLs through a domain model that interrelates several feature models in a consistent way. The approach thus shifts part of the domain knowledge to the problem space and supports the derivation of complex configurations with multiple instantiations and associations of sub-products. We also report on the application of our approach to an industrial-strength software development in the field of digital signage.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {112–121},
numpages = {10},
keywords = {software product line, configuration},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3382026.3431246,
author = {Kenner, Andy},
title = {Model-Based Evaluation of Vulnerabilities in Software Systems},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431246},
doi = {10.1145/3382026.3431246},
abstract = {Vulnerabilities in software systems result from faults, which occur at different stages in a software's life cycle, for example, in the design (i.e., undesired feature-interactions), the development (i.e., buffer overflows), or the operation (i.e., configuration errors). Various databases provide detailed information about vulnerabilities in software systems or the way to exploit it, but face severe limitations. The information is scattered across these databases, fluctuates in quality and granularity, and provides only an insight into a single vulnerability per entry. Even for a single software system it is challenging for any security-related stakeholder to determine the threat level, which consists of all vulnerabilities of the software system and its environment (i.e., operating system). Manual vulnerability management is feasible only to a limited extend if we want to identify all configurations that are affected by vulnerabilities, or determine a system's threat level and the resulting risk we have to deal with. For variant-rich systems, we also have to deal with variability, allowing different stakeholders to understand the threats to their particular setup. To deal with this variability, we propose vulnerability feature models, which offer a homogeneous view on all vulnerabilities of a software system. These models and the resulting analyses offer advantages in many disciplines of the vulnerability management process. In this paper, we report the research plan for our project, in which we focus on the model-based evaluation of vulnerabilities. This includes research objectives that take into account the design of vulnerability feature models, their application in the process of vulnerability management, and the impact of evolution, discovery, and verification of vulnerabilities.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {112–119},
numpages = {8},
keywords = {Vulnerability Analysis and Management, Vulnerability, Variability Model, Feature Model, Exploit},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1007/11681885_3,
author = {Altintas, N. Ilker and Cetin, Semih},
title = {Integrating a software product line with rule-based business process modeling},
year = {2005},
isbn = {3540327347},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11681885_3},
doi = {10.1007/11681885_3},
abstract = {This paper proposes an approach to integrate a software product line (Aurora) with reflective rule-based business process modeling (RUMBA). Aurora is a service-oriented application development and execution platform supporting today's well known “Rich Internet Applications” and “Enterprise Internet Applications” concepts. On the other hand, RUMBA is a rule-based model in which rules and rule-sets can be expressed in terms of dynamic aspects and delegated facts. The proposed approach mainly addresses “Reflective Aspect” and “Reflective Rule” patterns for the seamless integration of Aurora and RUMBA. Both architectural patterns introduce a “generative” approach for developing the basic aspects, dynamic rules and rule-sets so that all can be implemented in the Adaptive Object Model (AOM). The proposed model will be explained in detail and exemplified with existing projects using both Aurora and RUMBA approaches.},
booktitle = {Proceedings of the 31st VLDB Conference on Trends in Enterprise Application Architecture},
pages = {15–28},
numpages = {14},
location = {Trondheim, Norway},
series = {TEAA'05}
}

@inproceedings{10.5555/1308171.1308199,
author = {Kim, Kangtae and Kim, Hyungrok and Kim, Woomok},
title = {Building Software Product Line from the Legacy Systems "Experience in the Digital Audio and Video Domain"},
year = {2007},
isbn = {0769528880},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Most embedded software in the consumer electronics is generally developed through derivation from legacy software. Many new projects are derived from preexisting ones, through modification of functionality, optimization of performance and application new features. Particularly in the digital AV (Audio &amp; Video) domain, the rise of "digital convergence' has lead to a need for the functionality of products to be integrated and unified across different products. In this situation, a product line approach might be more efficient and effective rather than a product-oriented approach. The characteristics of this environment make the product line approach ideal for the digital AV domain.},
booktitle = {Proceedings of the 11th International Software Product Line Conference},
pages = {171–180},
numpages = {10},
series = {SPLC '07}
}

@article{10.1007/s00766-018-0307-0,
author = {Reinhartz-Berger, Iris and Kemelman, Mark},
title = {Extracting core requirements for software product lines},
year = {2020},
issue_date = {Mar 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-018-0307-0},
doi = {10.1007/s00766-018-0307-0},
abstract = {Software Product Line Engineering (SPLE) is a promising paradigm for reusing knowledge and artifacts among similar software products. However, SPLE methods and techniques require a high up-front investment and hence are profitable if several similar software products are developed. Thus in practice adoption of SPLE commonly takes a bottom-up approach, in which analyzing the commonality and variability of existing products and transforming them into reusable ones (termed core assets) are needed. These time-consuming and error-prone tasks call for automation. The literature partially deals with solutions for early software development stages, mainly in the form of variability analysis. We aim for further creation of core requirements—reusable requirements that can be adapted for different software products. To this end, we introduce an automated extractive method, named CoreReq, to generate core requirements from product requirements written in a natural language. The approach clusters similar requirements, captures variable parts utilizing natural language processing techniques, and generates core requirements following an ontological variability framework. Focusing on cloning scenarios, we evaluated CoreReq through examples and a controlled experiment. Based on the results, we claim that core requirements generation with CoreReq is feasible and usable for specifying requirements of new similar products in cloning scenarios.},
journal = {Requir. Eng.},
month = mar,
pages = {47–65},
numpages = {19},
keywords = {Variability analysis, Requirements specification, Systematic reuse, Software Product Line Engineering}
}

@inproceedings{10.1145/2499777.2500719,
author = {Schr\"{o}ter, Reimar and Siegmund, Norbert and Th\"{u}m, Thomas},
title = {Towards modular analysis of multi product lines},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500719},
doi = {10.1145/2499777.2500719},
abstract = {Software product-line engineering enables efficient development of tailor-made software by means of reusable artifacts. As practitioners increasingly develop software systems as product lines, there is a growing potential to reuse product lines in other product lines, which we refer to as multi product line. We identify challenges when developing multi product lines and propose interfaces for different levels of abstraction ranging from variability modeling to functional and non-functional properties. We argue that these interfaces ease the reuse of product lines and identify research questions that need to be solved toward modular analysis of multi product lines.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {96–99},
numpages = {4},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2377816.2377821,
author = {Garcia-Alonso, Jose and Olmeda, Javier Berrocal and Murillo, Juan Manuel},
title = {Architectural variability management in multi-layer web applications through feature models},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377821},
doi = {10.1145/2377816.2377821},
abstract = {The development of large web applications has focused on the use of increasingly complex architectures based on the layer architectural pattern and different development frame-works. Many techniques have been proposed to deal with this increasing complexity, mostly in the field of model-based development which abstracts the architects and designers from the architectural and technological complexities. However, these techniques do not take into account the great variability of these architectures, and therefore limit the architectural options available for their users. We here describe a feature model that captures the architectural and technological variability of multilayer applications. Using this feature model as the core of a model-driven development process, we are able to incorporate architectural and technological variability into the model-based development of multilayer applications. This approach keeps complexity under control whilst flexibility on choosing technologies is not penalized},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {29–36},
numpages = {8},
keywords = {multilayer architectures, model-driven development, feature model, development frameworks, design patterns},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1145/3336294.3342383,
author = {Martin, Hugo and Pereira, Juliana Alves and Acher, Mathieu and Temple, Paul},
title = {Machine Learning and Configurable Systems: A Gentle Introduction},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342383},
doi = {10.1145/3336294.3342383},
abstract = {The goal of this tutorial is to give an introduction to how machine learning can be used to support activities related to the engineering of configurable systems and software product lines. To the best of our knowledge, this is the first practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance prediction) on real-world systems (VaryLaTeX, x264).},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {325–326},
numpages = {2},
keywords = {software product lines, machine learning, configurable systems},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3382025.3414965,
author = {Young, Jeffrey M. and Walkingshaw, Eric and Th\"{u}m, Thomas},
title = {Variational satisfiability solving},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414965},
doi = {10.1145/3382025.3414965},
abstract = {Incremental satisfiability (SAT) solving is an extension of classic SAT solving that allows users to efficiently solve a set of related SAT problems by identifying and exploiting shared terms. However, using incremental solvers effectively is hard since performance is sensitive to a problem's structure and the order sub-terms are fed to the solver, and the burden to track results is placed on the end user. For analyses that generate sets of related SAT problems, such as those in software product lines, incremental SAT solvers are either not used at all, used but not explicitly stated so in the literature, or used but suffer from the aforementioned usability problems. This paper translates the ordering problem to an encoding problem and automates the use of incremental SAT solving. We introduce variational SAT solving, which differs from incremental SAT solving by accepting all related problems as a single variational input and returning all results as a single variational output. Our central idea is to make explicit the operations of incremental SAT solving, thereby encoding differences between related SAT problems as local points of variation. Our approach automates the interaction with the incremental solver and enables methods to automatically optimize sharing of the input. To evaluate our methods we construct a prototype variational SAT solver and perform an empirical analysis on two real-world datasets that applied incremental solvers to software evolution scenarios. We show, assuming a variational input, that the prototype solver scales better for these problems than naive incremental solving while also removing the need to track individual results.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {18},
numpages = {12},
keywords = {variation, software product lines, satisfiability solving, choice calculus},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3106195.3106204,
author = {Luthmann, Lars and Stephan, Andreas and B\"{u}rdek, Johannes and Lochau, Malte},
title = {Modeling and Testing Product Lines with Unbounded Parametric Real-Time Constraints},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106204},
doi = {10.1145/3106195.3106204},
abstract = {Real-time requirements are crucial for embedded software in many modern application domains of software product lines. Hence, techniques for modeling and analyzing time-critical software have to be lifted to software product line engineering, too. Existing approaches extend timed automata (TA) by feature constraints to so-called featured timed automata (FTA) facilitating efficient verification of real-time properties for entire product lines in a single run. In this paper, we propose a novel modeling formalism, called configurable parametric timed automata (CoPTA), extending expressiveness of FTA by supporting freely configurable and therefore a-priori unbounded timing intervals for real-time constraints, which are defined as feature attributes in extended feature models with potentially infinite configuration spaces. We further describe an efficient test-suite generation methodology for CoPTA models, achieving location coverage on every possible model configuration. Finally, we present evaluation results gained from applying our tool implementation to a collection of case studies, demonstrating efficiency improvements compared to a variant-by-variant analysis.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {104–113},
numpages = {10},
keywords = {Timed Automata, Software Product Lines, Real-Time Systems, Model-based Testing},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1007/978-3-319-91563-0_35,
author = {Reinhartz-Berger, Iris and Zamansky, Anna},
title = {A Behavior-Based Framework for Assessing Product Line-Ability},
year = {2018},
isbn = {978-3-319-91562-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-91563-0_35},
doi = {10.1007/978-3-319-91563-0_35},
abstract = {Systems are typically not developed from scratch, so different kinds of similarities between them exist, challenging their maintenance and future development. Software Product Line Engineering (SPLE) proposes methods and techniques for developing reusable artifacts that can be systematically reused in similar systems. Despite the potential benefits of SPLE to decrease time-to-market and increase product quality, it requires a high up-front investment and hence SPLE techniques are commonly adopted in a bottom-up approach, after individual systems have already been developed. Deciding whether to turn existing systems into a product line – referred to as product line-ability – involves many aspects and requires some tooling for analyzing similarities and differences among systems. In this paper we propose a framework for the identification of “similarly behaving” artifacts and analyzing their potential reuse in the context of product lines. This framework provides metrics for calculating behavior similarity and a method for analyzing the product line-ability of a set of products. The framework has been integrated into a tool named VarMeR – Variability Mechanisms Recommender, whose aim is to systematically guide reuse.},
booktitle = {Advanced Information Systems Engineering: 30th International Conference, CAiSE 2018, Tallinn, Estonia, June 11-15, 2018, Proceedings},
pages = {571–586},
numpages = {16},
keywords = {Software product line engineering, Variability analysis, Reuse},
location = {Tallinn, Estonia}
}

@inproceedings{10.5555/1105634.1105651,
author = {de Oliveira, Edson Alves and Gimenes, Itana M. S. and Huzita, Elisa Hatsue Moriya and Maldonado, Jos\'{e} Carlos},
title = {A variability management process for software product lines},
year = {2005},
publisher = {IBM Press},
abstract = {The software product line approach (PL) promotes the generation of specific products from a set of core assets for a given domain. This approach is applicable to domains in which products have well-defined commonalities and variation points. Variability management is concerned with the management of the differences between products throughout the PL lifecycle. This paper presents a UML-based process for variability management that allows identification, representation and delimitation of variabilities as well as identification of mechanisms for variability implementation. The process is illustrated with excerpts of a case study carried out within the context of an existing PL for the Workflow Management System (WfMS) domain. The case study was carried out based on the experimental software engineering concepts. The results have shown that the proposed process has made explicit a higher number of variabilities than does the existing PL process, and it offers better support for variability tracing.},
booktitle = {Proceedings of the 2005 Conference of the Centre for Advanced Studies on Collaborative Research},
pages = {225–241},
numpages = {17},
location = {Toranto, Ontario, Canada},
series = {CASCON '05}
}

@inproceedings{10.1145/2934466.2934478,
author = {Galindo, Jos\'{e} A. and Acher, Mathieu and Tirado, Juan Manuel and Vidal, Cristian and Baudry, Benoit and Benavides, David},
title = {Exploiting the enumeration of all feature model configurations: a new perspective with distributed computing},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934478},
doi = {10.1145/2934466.2934478},
abstract = {Feature models are widely used to encode the configurations of a software product line in terms of mandatory, optional and exclusive features as well as propositional constraints over the features. Numerous computationally expensive procedures have been developed to model check, test, configure, debug, or compute relevant information of feature models. In this paper we explore the possible improvement of relying on the enumeration of all configurations when performing automated analysis operations. We tackle the challenge of how to scale the existing enumeration techniques by relying on distributed computing. We show that the use of distributed computing techniques might offer practical solutions to previously unsolvable problems and opens new perspectives for the automated analysis of software product lines.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {74–78},
numpages = {5},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3233027.3233042,
author = {Mesa, Oslien and Vieira, Reginaldo and Viana, Marx and Durelli, Vinicius H. S. and Cirilo, Elder and Kalinowski, Marcos and Lucena, Carlos},
title = {Understanding vulnerabilities in plugin-based web systems: an exploratory study of wordpress},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233042},
doi = {10.1145/3233027.3233042},
abstract = {A common software product line strategy involves plugin-based web systems that support simple and quick incorporation of custom behaviors. As a result, they have been widely adopted to create web-based applications. Indeed, the popularity of ecosystems that support plugin-based development (e.g., WordPress) is largely due to the number of customization options available as community-contributed plugins. However, plugin-related vulnerabilities tend to be recurrent, exploitable and hard to be detected and may lead to severe consequences for the customized product. Hence, there is a need to further understand such vulnerabilities to enable preventing relevant security threats. Therefore, we conducted an exploratory study to characterize vulnerabilities caused by plugins in web-based systems. To this end, we went over WordPress vulnerability bulletins cataloged by the National Vulnerability Database as well as associated patches maintained by the WordPress plugins repository. We identified the main types of vulnerabilities caused by plugins as well as their impact and the size of the patch to fix the vulnerability. Moreover, we identified the most common security-related topics discussed among WordPress developers. We observed that, while plugin-related vulnerabilities may have severe consequences and might remain unnoticed for years before being fixed, they can commonly be mitigated with small and localized changes to the source code. The characterization helps to provide an understanding on how typical plugin-based vulnerabilities manifest themselves in practice. Such information can be helpful to steer future research on plugin-based vulnerability detection and prevention.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {149–159},
numpages = {11},
keywords = {software product lines, security, plugin-based web systems, exploratory study},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106201,
author = {Kim, Jongwook and Batory, Don and Dig, Danny},
title = {Refactoring Java Software Product Lines},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106201},
doi = {10.1145/3106195.3106201},
abstract = {Refactoring is a staple of Object-Oriented (OO) program development. It should be a staple of OO Software Product Line (SPL) development too. X15 is the first tool to support the refactoring of Java SPL codebases. X15 (1) uses Java custom annotations to encode variability in feature-based Java SPLs, (2) projects a view of an SPL product (a program that corresponds to a legal SPL configuration), and (3) allows programmers to edit and refactor the product, propagating changes back to the SPL codebase. Case studies apply 2316 refactorings in 8 public Java SPLs and show that X15 is as efficient, expressive, and scalable as a state-of-the-art feature-unaware Java refactoring engine.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {59–68},
numpages = {10},
keywords = {software product lines, refactoring},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2362536.2362562,
author = {Mohalik, Swarup and Ramesh, S. and Millo, Jean-Vivien and Krishna, Shankara Narayanan and Narwane, Ganesh Khandu},
title = {Tracing SPLs precisely and efficiently},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362562},
doi = {10.1145/2362536.2362562},
abstract = {In a Software Product Line (SPL), the central notion of implementability provides the requisite connection between specifications (feature sets) and their implementations (component sets), leading to the definition of products. While it appears to be a simple extension (to sets) of the trace-ability relation between components and features, it actually involves several subtle issues which are overlooked in the definitions in existing literature. In this paper, we give a precise and formal definition of implementability over a fairly expressive traceability relation to solve these issues. The consequent definition of products in the given SPL naturally entails a set of useful analysis problems that are either refinements of known problems, or are completely novel. We also propose a new approach to solve these analysis problems by encoding them as Quantified Boolean Formula(QBF) and solving them through Quantified Satisfiability (QSAT) solvers. The methodology scales much better than the SAT-based solutions hinted in the literature and is demonstrated through a prototype tool called SPLANE (SPL Analysis Engine), on a couple of fairly large case studies.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {186–195},
numpages = {10},
keywords = {software product line, formal methods, feature model, QSAT},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2019136.2019149,
author = {Murugesupillai, Esan and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {A preliminary mapping study of approaches bridging software product lines and service-oriented architectures},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019149},
doi = {10.1145/2019136.2019149},
abstract = {Service Oriented Architectures (SOA) and Software Product Lines (SPL) have individually proven to be software engineering concepts that create added value to the development of software systems. Recently, the research community has recognized and investigated potentials for combining these two concepts. However, there have been no mapping study and literature surveys that systematically review the present research results in combining the two. This paper presents results of a preliminary work on a systematic mapping study of research papers that report on combining SOA and SPL. The main goal of a systematic mapping study is to provide a breath overview, classification of approaches and the quantity and type of research as well as available research results, which is complimentary step toward further systematic literature review. This paper, based on selected papers published from 2002 to mid-2010, reports on various aspects of the analyzed literature, including the motivations for combining the two concepts; contributions to specific stages of software engineering lifecycles; types of synergies and characteristics that are accomplished through combinations of the two concepts; and the methods used for and the rigor of the evaluations of the research conducted on the studied topic.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {11},
numpages = {8},
keywords = {variability management, software variability, software product line, service-oriented product line, service-oriented architecture},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2019136.2019170,
author = {Leitner, Andrea and Kreiner, Christian and Mader, Roland and Steger, Christian and Wei\ss{}, Reinhold},
title = {Towards multi-modeling for domain description},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019170},
doi = {10.1145/2019136.2019170},
abstract = {Domain modeling is a key task in the development of a software product line. We identified two popular modeling paradigms: Feature-oriented domain modeling (FODM) and domain specific modeling (DSM). The appropriate choice of the modeling paradigm is a crucial decision for the development of an efficient and easy to use domain model. For complex and heterogeneous domain descriptions, for example embedded system descriptions, different representation techniques can be useful to describe the different parts of the system. We propose a method to combine both representation techniques to realize a domain specific multi modeling approach. This supports not only a more natural domain description, but can as well be seen as a support for knowledge transfer between different stakeholders.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {30},
numpages = {6},
keywords = {software product line engineering, multi modeling, feature oriented domain modeling, feature oriented domain analysis, domain specific modeling, domain modeling},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3233027.3233043,
author = {Masri, Samer AL and Nadi, Sarah and Gaudet, Matthew and Liang, Xiaoli and Young, Robert W.},
title = {Using static analysis to support variability implementation decisions in C++},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233043},
doi = {10.1145/3233027.3233043},
abstract = {Eclipse OMR is an open-source C++ framework for building robust language runtimes. The OMR toolkit includes a dynamic Just-In-Time (JIT) compiler, a garbage collector, a platform abstraction library, and a set of developer tooling capabilities. To support the diverse languages and architectures targeted by the framework, OMR's variability implementation uses a combination of build-system variability and static polymorphism. That is, all implementation classes that depend on the selected language and architecture are decided at compile time. However, OMR developers now realize that the current variability design decision, specifically the static polymorphism implementation, has its drawbacks. They are considering using dynamic polymorphism instead of static polymorphism. Before making such a fundamental design change, however, it is crucial to collect function information and overload/override statistics about the current variability in the code base.In this paper, we present OMRStatistics, a static analysis tool that we built for OMR developers to help them collect this information. Specifically, OMRStatistics (1) visualizes the class hierarchy from OMR's current static polymorphic implementation, (2) visualizes the function overloads and overrides with their respective locations in the source code, (3) collects important information about the classes and functions, and (4) stores all the collected information in a database for further analysis. Our tool OMRStatistics allows OMR developers to make better design decisions on which variability extension points should be switched from static polymorphism to dynamic polymorphism.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {236–245},
numpages = {10},
keywords = {static polymorphism, static analysis, software variability analysis, dynamic polymorphism, clang plugin, build path variability, C++},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3336294.3336322,
author = {Pett, Tobias and Th\"{u}m, Thomas and Runge, Tobias and Krieter, Sebastian and Lochau, Malte and Schaefer, Ina},
title = {Product Sampling for Product Lines: The Scalability Challenge},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336322},
doi = {10.1145/3336294.3336322},
abstract = {Quality assurance for product lines is often infeasible for each product separately. Instead, only a subset of all products (i.e., a sample) is considered during testing such that at least the coverage of certain feature interactions is guaranteed. While pair-wise interaction sampling only covers all interactions between two features, its generalization to t-wise interaction sampling ensures coverage for all interactions among t features. However, sampling large product lines poses a challenge, as today's algorithms tend to run out of memory, do not terminate, or produce samples, which are too large to be tested. To initiate a community effort, we provide a set of large real-world feature models with up-to 19 thousand features, which are supposed to be sampled. The performance of sampling approaches is evaluated based on the CPU time and memory consumed to retrieve a sample, the sample size for a given coverage (i.e. the value of t) and whether the sample achieves full t-wise coverage. A well-performing sampling algorithm achieves full t-wise coverage, while minimizing the other properties as best as possible.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {78–83},
numpages = {6},
keywords = {software product lines, real-world feature models, product sampling, product line testing},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342404,
author = {Th\"{u}m, Thomas and Seidl, Christoph and Schaefer, Ina},
title = {On Language Levels for Feature Modeling Notations},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342404},
doi = {10.1145/3307630.3342404},
abstract = {Configuration is a key enabling technology for the engineering of systems and software as wells as physical goods. A selection of configuration options (aka. features) is often enough to automatically generate a product tailored to the needs of a customer. It is common that not all combinations of features are possible in a given domain. Feature modeling is the de-facto standard for specifying features and their valid combinations. However, a pivotal hurdle for practitioners, researchers, and teachers in applying feature modeling is that there are hundreds of tools and languages available. While there have been first attempts to define a standard feature modeling language, they still struggle with finding an appropriate level of expressiveness. If the expressiveness is too high, the language will not be adopted, as it is too much effort to support all language constructs. If the expressiveness is too low, the language will not be adopted, as many interesting domains cannot be modeled in such a language. Towards a standard feature modeling notation, we propose the use of language levels with different expressiveness each and discuss criteria to be used to define such language levels. We aim to raise the awareness on the expressiveness and eventually contribute to a standard feature modeling notation.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {158–161},
numpages = {4},
keywords = {variability modeling, product lines, language design, feature model, expressiveness, automated analysis},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2791060.2791106,
author = {Smiley, Karen and Schmidt, Werner and Dagnino, Aldo},
title = {Evolving an industrial analytics product line architecture},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791106},
doi = {10.1145/2791060.2791106},
abstract = {This paper focuses on an industrial experience with software product lines of analytics-enabled solutions, specifically the evolution of the software product line architecture for a Subject Matter Expert Workbench toolset which supports analytic plugins for multiple software product lines. As context, the toolset product line was intended for integration of expert knowledge into a family of industrial asset health applications at runtime. The toolset architecture is now being evolved to build and manage plugins for multiple Industrial Analytics solutions (software systems and services) beyond asset health. This evolution is driving changes in the desired architecture qualities of the toolset; widening the stakeholder pool and influencing priorities; affecting the architecture tradeoffs and decisions; and triggering updates to the product line architecture, the guidance for applying it, and the current prototype of the toolset. We describe our experiences in handling this evolution, assess lessons learned, and discuss potential relevance to other product line scenarios.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {263–272},
numpages = {10},
keywords = {software product line, reusability, performance, knowledge, interoperability, industrial analytics, extensibility, asset health},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2019136.2019168,
author = {Nakagawa, Elisa Yumi and Antonino, Pablo Oliveira and Becker, Martin},
title = {Exploring the use of reference architectures in the development of product line artifacts},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019168},
doi = {10.1145/2019136.2019168},
abstract = {Software Product Line (SPL) has arisen as an approach for developing a family of software-intensive systems at lower costs, within shorter time, and with higher quality. In particular, SPL is supported by a product line architecture (sometimes also referred to as reference architecture) that captures the architectures of a product family. In another context, a special type of architecture that contains knowledge about a specific domain has been increasingly investigated, resulting in the Reference Architecture research area. In spite of the positive impact of this type of architecture on reuse and productivity, the use of existing domain-specific reference architectures as basis of SPL has not been widely explored. The main contribution of this paper is to present how and when elements contained in existing reference architectures could contribute to the building of SPL artifacts during development of an SPL. We have observed that, in fact, reference architectures could make an important contribution to improving reuse and productivity, which are also important concerns in SPL.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {28},
numpages = {8},
keywords = {software product line, reference architecture, SPL design method},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3382025.3414972,
author = {Schulthei\ss{}, Alexander and Bittner, Paul Maximilian and Kehrer, Timo and Th\"{u}m, Thomas},
title = {On the use of product-line variants as experimental subjects for clone-and-own research: a case study},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414972},
doi = {10.1145/3382025.3414972},
abstract = {Software is often released in multiple variants to address the needs of different customers or application scenarios. One frequent approach to create new variants is clone-and-own, whose systematic support has gained considerable research interest in the last decade. However, only few techniques have been evaluated in a realistic setting, due to a substantial lack of publicly available clone-and-own projects which could be used as experimental subjects. Instead, many studies use variants generated from software product lines for their evaluation. Unfortunately, the results might be biased, because variants generated from a single code base lack unintentional divergences that would have been introduced by clone-and-own. In this paper, we report about ongoing work towards a more systematic investigation of threats to the external validity of such experimental results. Using n-way model matching as a representative technique for supporting clone-and-own, we assess the performance of state-of-the-art algorithms on variant sets exposing increasing degrees of divergence. We compile our observations into four hypotheses which are meant to serve as a basis for discussion and which need to be investigated in more detail in future research.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {27},
numpages = {6},
keywords = {model matching, experimental evaluation, clone-and-own},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3336294.3336306,
author = {Ghamizi, Salah and Cordy, Maxime and Papadakis, Mike and Traon, Yves Le},
title = {Automated Search for Configurations of Convolutional Neural Network Architectures},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336306},
doi = {10.1145/3336294.3336306},
abstract = {Convolutional Neural Networks (CNNs) are intensively used to solve a wide variety of complex problems. Although powerful, such systems require manual configuration and tuning. To this end, we view CNNs as configurable systems and propose an end-to-end framework that allows the configuration, evaluation and automated search for CNN architectures. Therefore, our contribution is threefold. First, we model the variability of CNN architectures with a Feature Model (FM) that generalizes over existing architectures. Each valid configuration of the FM corresponds to a valid CNN model that can be built and trained. Second, we implement, on top of Tensorflow, an automated procedure to deploy, train and evaluate the performance of a configured model. Third, we propose a method to search for configurations and demonstrate that it leads to good CNN models. We evaluate our method by applying it on image classification tasks (MNIST, CIFAR-10) and show that, with limited amount of computation and training, our method can identify high-performing architectures (with high accuracy). We also demonstrate that we outperform existing state-of-the-art architectures handcrafted by ML researchers. Our FM and framework have been released to support replication and future research.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {119–130},
numpages = {12},
keywords = {neural architecture search, feature model, configuration search, NAS, AutoML},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2934466.2934468,
author = {Kehrbusch, Philipp and Richenhagen, Johannes and Rumpe, Bernhard and Schlo\ss{}er, Axel and Schulze, Christoph},
title = {Interface-based similarity analysis of software components for the automotive industry},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934468},
doi = {10.1145/2934466.2934468},
abstract = {In a software product line similar products are derived based on a common foundation. With traditional methods a number of similar products exist independently. To derive a maintainable, reusable set of software components it is necessary to understand similarities and differences. However, an adequate similarity analysis involving several products is a cost-intensive and difficult task, compromising the pursued benefit. In this paper an automated syntactical similarity analysis for software component interfaces is proposed to support the software product line extraction and maintenance. We apply this general approach specifically to the automotive domain, as the static nature of the architecture and the high number of well-defined signals makes the interfaces especially expressive. The analysis supports three use cases: the identification of similarities between two interfaces, the automated extraction of a common interface for a set of interfaces and the evaluation of interface changes during the evolution history of a software component. In addition the syntactical analysis provides the foundation for further semantical examinations. Its applicability is indicated by a case study on different variants and versions of interfaces defined in an industrial context.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {99–108},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382025.3414989,
author = {Krieter, Sebastian},
title = {Large-scale T-wise interaction sampling using YASA},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414989},
doi = {10.1145/3382025.3414989},
abstract = {Testing highly-configurable software systems (i.e., software product lines) is challenging due to their large configuration space. T-wise sampling is one method of finding a representative subset of configurations for a system, which can then be tested. However, for large-scale systems, such as Linux, existing t-wise sampling algorithms do not scale well. To this end, Pett et al. proposed the sampling challenge for large-scale systems at SPLC 2019. In this paper, we attempt to solve the proposed challenge using our sampling algorithm YASA. We report our experience for all three of the given systems FinancialServices01, Automotive02, and Linux. In addition, we present the results for computing samples for all versions of the system FinancialServices01.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {29},
numpages = {4},
keywords = {software product lines, configurable system, T-wise sampling},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/1217935.1217955,
author = {Krishna, Arvind S. and Gokhale, Aniruddha S. and Schmidt, Douglas C.},
title = {Context-specific middleware specialization techniques for optimizing software product-line architectures},
year = {2006},
isbn = {1595933220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1217935.1217955},
doi = {10.1145/1217935.1217955},
abstract = {Product-line architectures (PLAs) are an emerging paradigm for developing software families for distributed real-time and embedded (DRE) systems by customizing reusable artifacts, rather than hand-crafting software from scratch. To reduce the effort of developing software PLAs and product variants for DRE systems, developers are applying general-purpose -- ideally standard -- middleware platforms whose reusable services and mechanisms support a range of application quality of service (QoS) requirements, such as low latency and jitter. The generality and flexibility of standard middleware, however, often results in excessive time/space overhead for DRE systems, due to lack of optimizations tailored to meet the specific QoS requirements of different product variants in a PLA.This paper provides the following contributions to the study of middleware specialization techniques for PLA-based DRE systems. First, we identify key dimensions of generality in standard middleware stemming from framework implementations, deployment platforms, and middleware standards. Second, we illustrate how context-specific specialization techniques can be automated and used to tailor standard middleware to better meet the QoS needs of different PLA product variants. Third, we quantify the benefits of applying automated tools to specialize a standard Realtime CORBA middleware implementation. When applied together, these middleware specializations improved our application product variant throughput by ~65%, average- and worst-case end-to-end latency measures by ~43% and ~45%, respectively, and predictability by a factor of two over an already optimized middleware implementation, with little or no effect on portability, standard middleware APIs, or application software implementations, and interoperability.},
booktitle = {Proceedings of the 1st ACM SIGOPS/EuroSys European Conference on Computer Systems 2006},
pages = {205–218},
numpages = {14},
keywords = {specializations, product lines, middleware},
location = {Leuven, Belgium},
series = {EuroSys '06}
}

@inproceedings{10.1145/3307630.3342396,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {White-Box and Black-Box Test Quality Metrics for Configurable Simulation Models},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342396},
doi = {10.1145/3307630.3342396},
abstract = {Simulation models are widely employed to model and simulate complex systems from different domains, such as automotive. These systems are becoming highly configurable to support different users' demands. Testing all of them is impracticable, and thus, cost-effective techniques are mandatory. Costs are usually attributed either to the time it takes to test a configurable system or to its monetary value. Nevertheless, for the case of test effectiveness several quality metrics can be found in the literature. This paper aims at proposing both black-box and white-box test quality metrics for configurable simulation models relying on 150% variability modeling approaches.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {211–214},
numpages = {4},
keywords = {test quality metrics, simulation models, product lines},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.5555/998675.999419,
author = {Matinlassi, Mari},
title = {Comparison of Software Product Line Architecture Design Methods: COPA, FAST, FORM, KobrA and QADA},
year = {2004},
isbn = {0769521630},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Product line architectures (PLAs) have been undercontinuous attention in the software research communityduring the past few years. Although several methods havebeen established to create PLAs there are not availablestudies comparing PLA methods. Five methods are knownto answer the needs of software product lines: COPA,FAST, FORM, KobrA and QADA. In this paper, anevaluation framework is introduced for comparing PLAdesign methods. The framework considers the methodsfrom the points of view of method context, user, structureand validation. Comparison revealed distinguishableideologies between the methods. Therefore, methods donot overlap even though they all are PLA design methods.All the methods have been validated on various domains.The most common domains are telecommunicationinfrastructure and information domains. Some of themethods apply software standards; at least OMG\'{y}s MDAfor method structures, UML for language and IEEE Std-1471-2000 for viewpoint definitions.},
booktitle = {Proceedings of the 26th International Conference on Software Engineering},
pages = {127–136},
numpages = {10},
series = {ICSE '04}
}

@inproceedings{10.1145/3382025.3414945,
author = {G\"{o}ttmann, Hendrik and Luthmann, Lars and Lochau, Malte and Sch\"{u}rr, Andy},
title = {Real-time-aware reconfiguration decisions for dynamic software product lines},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414945},
doi = {10.1145/3382025.3414945},
abstract = {Dynamic Software Product Lines (DSPL) have recently shown promising potentials as integrated engineering methodology for (self-)adaptive software systems. Based on the software-configuration principles of software product lines, DSPL additionally foster reconfiguration capabilities to continuously adapt software products to ever-changing environmental contexts. However, in most recent works concerned with finding near-optimal reconfiguration decisions, real-time aspects of reconfiguration processes are usually out of scope. In this paper, we present a model-based methodology for specifying and automatically analyzing real-time constraints of reconfiguration decisions in a feature-oriented and compositional way. Those real-time aware DSPL specifications are internally translated into timed automata, a well-founded formalism for real-time behaviors. This representation allows for formally reasoning about consistency and worst-case/best-case execution-time behaviors of sequences of reconfiguration decisions. The technique is implemented in a prototype tool and experimentally evaluated with respect to a set of case studies1.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {13},
numpages = {11},
keywords = {timed automata, reconfiguration decisions, dynamic software product lines},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2499777.2500710,
author = {Gabillon, Yoann and Biri, Nicolas and Otjacques, Beno\^{\i}t},
title = {Methodology to integrate multi-context UI variations into a feature model},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500710},
doi = {10.1145/2499777.2500710},
abstract = {Software product line (SPL) paradigm aims to explore commonalities and variabilities in a set of applications for developing an efficient derivation of products. One of the most common ways to model variability in this paradigm is to use a Feature Model. However, variability in SPL is often limited to functional features. The User Interface (UI) variations are modeled as entire UIs and thus these variations are not reusable and inspectable. Research in the Human Computer Interaction (HCI) field has proven the importance of variability for non functional, purely UI centric features. The HCI community has proposed several levels of abstraction for multi-context UI design. Indeed, new variations can be introduced at each abstraction level. UI designers are used to them and they usually introduce variability at each step of the UI definition without using SPL. To build usable softwares that take into account UI, we propose to merge functional concerns and UI concerns, providing a methodology to integrate variability of both aspects into a single Feature Model.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {74–81},
numpages = {8},
keywords = {variability, user interface, usability, software product line, multi-context, feature model, abstraction levels},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2791060.2791108,
author = {Berger, Thorsten and Lettner, Daniela and Rubin, Julia and Gr\"{u}nbacher, Paul and Silva, Adeline and Becker, Martin and Chechik, Marsha and Czarnecki, Krzysztof},
title = {What is a feature? a qualitative study of features in industrial software product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791108},
doi = {10.1145/2791060.2791108},
abstract = {The notion of features is commonly used to describe the functional and non-functional characteristics of a system. In software product line engineering, features often become the prime entities of software reuse and are used to distinguish the individual products of a product line. Properly decomposing a product line into features, and correctly using features in all engineering phases, is core to the immediate and long-term success of such a system. Yet, although more than ten different definitions of the term feature exist, it is still a very abstract concept. Definitions lack concrete guidelines on how to use the notion of features in practice.To address this gap, we present a qualitative empirical study on actual feature usage in industry. Our study covers three large companies and an in-depth, contextualized analysis of 23 features, perceived by the interviewees as typical, atypical (outlier), good, or bad representatives of features. Using structured interviews, we investigate the rationales that lead to a feature's perception, and identify and analyze core characteristics (facets) of these features. Among others, we find that good features precisely describe customer-relevant functionality, while bad features primarily arise from rashly executed processes. Outlier features, serving unusual purposes, are necessary, but do not require the full engineering process of typical features.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {16–25},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3307630.3342417,
author = {Achtaich, Asmaa and Roudies, Ounsa and Souissi, Nissrine and Salinesi, Camille and Mazo, Ra\'{u}l},
title = {Evaluation of the State-Constraint Transition Modelling Language: A Goal Question Metric Approach},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342417},
doi = {10.1145/3307630.3342417},
abstract = {Self-adaptive systems (SAS) are exceptional systems, on account of their versatile composition, dynamic behavior and evolutive nature. Existing formal languages for the specification of SAS focus on adapting system elements to achieve a target goal, following specific rules, without much attention on the adaptation of requirements themselves. The State-Constraint Transition (SCT) modeling language enables the specification of dynamic requirements, both at the domain and application level, as a result of space or time variability. This language, evaluated in this paper, enables the specification of a variety of requirement types, for SASs from different domains, while generating a configuration, all configurations, and number of possible configurations, in milliseconds. This paper presents these results, namely; expressiveness, domain independence and scalability, from the viewpoint of designers and domain engineers, following a goal-question-metric approach. However, being primarily based on constraint programming (CP), the language suffers from drawbacks inherited from this paradigm, specifically time related requirements, like (e.g. order, frequency and staged requirements).},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {106–113},
numpages = {8},
keywords = {state machine, modeling language, dynamic software product lines, constraint programming, IoT},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1145/1279711.1279715,
author = {Krishna, Arvind S. and Gokhale, Aniruddha and Schmidt, Douglas C. and Ranganath, Venkatesh Prasad and Hatcliff, John},
title = {Towards highly optimized real-time middleware for software product-line architectures},
year = {2006},
issue_date = {January 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/1279711.1279715},
doi = {10.1145/1279711.1279715},
abstract = {This paper provides the following contributions to the study of middleware optimization techniques for product line architectures in real-time systems. First, we identify different dimensions of generality in standards based middleware implementations. Second, we describe how specialization approaches used in other domains including OS, compiler and programming languages can be applied to address middleware generality challenges. Third, we present preliminary results from the application of our specialization techniques. Our results illustrate that specialization techniques represent a promising approach for minimizing time/space overheads in middleware.},
journal = {SIGBED Rev.},
month = jan,
pages = {13–16},
numpages = {4}
}

@inproceedings{10.1145/2364412.2364429,
author = {Parra, Carlos and Giral, Leonardo and Infante, Alvaro and Cort\'{e}s, Camilo},
title = {Extractive SPL adoption using multi-level variability modeling},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364429},
doi = {10.1145/2364412.2364429},
abstract = {Software Product Line engineering aims at reusing and automating software development to reduce costs, have shorter development cycles, and maintain quality. However, for organizations with settled development processes and a large code base, adopting an SPL approach may prove to be a daunting task. In this paper we present an industrial experimentation and a proposal for an SPL adoption in Heinsohn Business Technology (HBT), a software development company specialized in financial, transportation, mortgage-backed securities, and pension-fund solutions. We start by identifying and modeling multiple levels of variability inherent to the kind of developments undertaken by HBT. Next, we define restrictions inside every level as well as between the levels to fully characterize an HBT software product. To limit the impact on the organization development process, we use an extractive approach. This allows us to design core assets starting from current software artifacts. The overall approach is based on real-world software artifacts developed over the years by HBT, whose combinations result in approximately 4.88e11 possible product configurations.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {99–106},
numpages = {8},
keywords = {software product lines, model-driven engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2491627.2491641,
author = {Koziolek, Heiko and Goldschmidt, Thomas and de Gooijer, Thijmen and Domis, Dominik and Sehestedt, Stephan},
title = {Experiences from identifying software reuse opportunities by domain analysis},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491641},
doi = {10.1145/2491627.2491641},
abstract = {In a large corporate organization there are sometimes similar software products in certain subdomains with a perceived functional overlap. This promises to be an opportunity for systematic reuse to reduce software development and maintenance costs. In such situations companies have used different domain analysis approaches (e.g., SEI Technical Probe) that helped to assess technical and organizational potential for a software product line approach. We applied existing domain analysis approaches for software product line engineering and tailored them to include a feature analysis as well as architecture evaluation. In this paper, we report our experiences from applying the approach in two subdomains of industrial automation.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {208–217},
numpages = {10},
keywords = {software product lines, domain analysis, business case},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3307630.3342401,
author = {Villota, Angela and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {The High-Level Variability Language: An Ontological Approach},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342401},
doi = {10.1145/3307630.3342401},
abstract = {Given its relevance, there is an extensive body of research for modeling variability in diverse domains. Regretfully, the community still faces issues and challenges to port or share variability models among tools and methodological approaches. There are researchers, for instance, implementing the same algorithms and analyses again because they use a specific modeling language and cannot use some existing tool. This paper introduces the High-Level Variability Language (HLVL), an expressive and extensible textual language that can be used as a modeling and an intermediate language for variability. HLVL was designed following an ontological approach, i.e., by defining their elements considering the meaning of the concepts existing on different variability languages. Our proposal not only provides a unified language based on a comprehensive analysis of the existing ones but also sets foundations to build tools that support different notations and their combination.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {162–169},
numpages = {8},
keywords = {variability specification, variability language, domain specific language},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3109729.3109758,
author = {Ben Snaiba, Ziad and de Vink, Erik P. and Willemse, Tim A.C.},
title = {Family-Based Model Checking of SPL based on mCRL2},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109758},
doi = {10.1145/3109729.3109758},
abstract = {We discuss how the general-purpose model checker mCRL2 can be used for family-based verification of behavioral properties of software product lines. This is achieved by exploiting a feature-oriented extension of the modal μ-calculus for the specification of SPL properties, and for its model checking by encoding it back into the logic of mCRL2. Using the example of the well-known minepump SPL an illustration of the possibilities of the approach is given.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {13–16},
numpages = {4},
keywords = {mCRL2, Software Product Lines, Family-based model checking},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1016/j.jss.2006.05.034,
author = {Ajila, Samuel A. and Dumitrescu, Razvan T.},
title = {Experimental use of code delta, code churn, and rate of change to understand software product line evolution},
year = {2007},
issue_date = {January, 2007},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {80},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2006.05.034},
doi = {10.1016/j.jss.2006.05.034},
abstract = {This research is a longitudinal study of change processes. It links changes in the product line architecture of a large telecommunications equipment supplier with the company's customers, inner context, and eight line card products over six-year period. There are three important time related constructs in this study: the time it takes to develop a new product line release; the frequency in which a metric is collected; and the frequency at which financial results and metrics related to the customer layer are collected and made available. Data collection has been organized by product release. The original goal of this research is to study the economic impact of market reposition on the product line and identify metrics that can be used to records changes in product line. We later look at the product line evolution vis-a-vis the changes in the products that form the product line. Our results show that there is no relationship between the size of the code added to the product line and the number of designers required to develop and test it; and there is a positive relationship between designer turnover and impact of change.},
journal = {J. Syst. Softw.},
month = jan,
pages = {74–91},
numpages = {18},
keywords = {Software product line, Software metric, Software evolution, Rate of change, Impact analysis, Code delta, Code churn}
}

@inproceedings{10.1145/2491627.2491642,
author = {Martini, Antonio and Pareto, Lars and Bosch, Jan},
title = {Communication factors for speed and reuse in large-scale agile software development},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491642},
doi = {10.1145/2491627.2491642},
abstract = {An open issue in industry is the combination of software reuse in the context of large scale Agile Software Development. The speed offered by Agile Software Development is needed for short time to market, while reuse strategies such as Software Product Line Engineering are needed for long-term productivity, efficiency, and profit. The paper investigates, through a survey, communication factors affecting both speed and reuse in 3 large companies developing embedded systems and employing Agile Software Development and Software Product Line Engineering. Our results include a prioritized list of communication related factors obtained by statistical analysis and the recognition and spread of the factors in the companies. We have recognized 5 interfaces with the Agile development team that need to be improved: system engineers (architects), product management, distributed teams, inter-project teams and sales unit. Few factors (involving inter-project communication) depend on the business drivers for the company. We also reveal that Agile teams need strategic and architectural inputs in order to be implanted in a large company employing Software Product Line Engineering. Academic and industrial training as well as different tactics for co-location would improve the communication skills of engineers. There is also a need for solutions, in the reference architecture, for fostering Agile Software Development: the goal is the combination of the focus on customer value of the teams, reusability, system requirements and avoidance of organizational dependencies.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {42–51},
numpages = {10},
keywords = {speed, software reuse, software process improvement (SPI), factors, embedded systems, development speed, communication, agile software development},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2934466.2934490,
author = {Iida, Takahiro and Matsubara, Masahiro and Yoshimura, Kentaro and Kojima, Hideyuki and Nishino, Kimio},
title = {PLE for automotive braking system with management of impacts from equipment interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934490},
doi = {10.1145/2934466.2934490},
abstract = {We report here an industrial application of the Product Line Engineering (PLE) for the development of electronic braking systems.The cost of software engineering in automotive control systems is increasing as new functions for safety, comfort, and improved fuel efficiency are integrated into electronic control units.Therefore, Component suppliers for automotive control systems adapt their products to the requirements of car manufacturers by modifying the software specifications, such that it makes minimal changes to the mechanical structure and the electrical and electronic (E/E) components hence reduces the cost. PLE is an effective approach to manage or even reduce the software variations resulting from these modifications.However, one problem is that the software specifications of automotive control systems need to be redesigned after system testing with vehicles. This is because vehicles consist of many mechanical parts manufactured by different suppliers, and the characteristics of the parts can interact with each other. This problem makes it difficult to reap the full benefits of PLE.We propose an approach to analyze the potential impact from such interactions by using a system model that expresses the system architecture that includes the parts of different suppliers. Based on this model, the software architecture was designed to localize the impact to several software components. Additionally, a feature model was designed to the enable management of the localized impact by expressing it as variability. This method helps software engineers specify the software components that can have an effect on the actual equipment, and determine which modifications to the software specifications are necessary.We applied PLE with the proposed method in the development of electronic brake control system. We confirmed that our approach greatly increased the efficiency of PLE for the development of such automotive control systems.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {232–241},
numpages = {10},
keywords = {system modeling, software modification, software engineering, product lines engineering, feature modeling, control system},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382025.3414951,
author = {Heradio, Ruben and Fernandez-Amoros, David and Galindo, Jos\'{e} A. and Benavides, David},
title = {Uniform and scalable SAT-sampling for configurable systems},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414951},
doi = {10.1145/3382025.3414951},
abstract = {Several relevant analyses on configurable software systems remain intractable because they require examining vast and highly-constrained configuration spaces. Those analyses could be addressed through statistical inference, i.e., working with a much more tractable sample that later supports generalizing the results obtained to the entire configuration space. To make this possible, the laws of statistical inference impose an indispensable requirement: each member of the population must be equally likely to be included in the sample, i.e., the sampling process needs to be "uniform". Various SAT-samplers have been developed for generating uniform random samples at a reasonable computational cost. Unfortunately, there is a lack of experimental validation over large configuration models to show whether the samplers indeed produce genuine uniform samples or not. This paper (i) presents a new statistical test to verify to what extent samplers accomplish uniformity and (ii) reports the evaluation of four state-of-the-art samplers: Spur, QuickSampler, Unigen2, and Smarch. According to our experimental results, only Spur satisfies both scalability and uniformity.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {17},
numpages = {11},
keywords = {variability modeling, uniform sampling, software product lines, configurable systems, SAT},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.5555/645882.672260,
author = {Voget, Stefan and Becker, Martin},
title = {Establishing a Software Product Line in an Immature Domain},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Often product lines are applied to "stable domains" (i.e., a set of common features is identifiable in advance and the evolution of the domain is manageable during the lifetime of the product line). These prerequisites are not always given. But there may be market pressure that requires developing products with systematic and preplanned reuse in a domain that is difficult to grasp. In such a case the product line approach also offers a set of methods that helps to overcome the risks of an immature domain.In this paper we discuss some risks in context of immature domains. For some challenges we present approaches to manage them. The considerations are substantiated by experiences in the domain of entertainment and infotainment systems in an automotive context. The development is deeply influenced by technological changes (e.g., Internet, MP3-player, UMTS) that challenge the successful deployment of product line technology.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {60–67},
numpages = {8},
series = {SPLC 2}
}

@inproceedings{10.1145/3382026.3425773,
author = {Galindo, Jos\'{e} A. and Benavides, David},
title = {A Python framework for the automated analysis of feature models: A first step to integrate community efforts},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425773},
doi = {10.1145/3382026.3425773},
abstract = {Feature modeling is the "de facto" standard to describe the common and variant parts of software product lines. Different tools, approaches, and operations for the automated analysis of feature models (AAFM) have been proposed in the last 20 years. The increasing popularity of languages such as Python made the usage of AAFM techniques require lots of integration efforts with exiting Java-based tools. In this paper, we present a design for a Python-based framework to analyze feature models. This framework implements the most common operations while enabling support for multiple solvers and backends.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {52–55},
numpages = {4},
keywords = {Variability Models, Python, Feature Models, Automated Analysis},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3382025.3414966,
author = {Basile, Davide and Beek, Maurice H. ter and Cordy, Maxime and Legay, Axel},
title = {Tackling the equivalent mutant problem in real-time systems: the 12 commandments of model-based mutation testing},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414966},
doi = {10.1145/3382025.3414966},
abstract = {Mutation testing can effectively drive test generation to reveal faults in software systems. However, it faces a typical efficiency issue as it can produce many mutants that are equivalent to the original system, making it impossible to generate test cases from them.We consider this problem when model-based mutation testing is applied to real-time system product lines, represented as timed automata. We define novel, time-specific mutation operators and formulate the equivalent mutant problem in the frame of timed refinement relations.Further, we study in which cases a mutation yields an equivalent mutant. Our theoretical results provide guidance to system engineers, allowing them to eliminate mutations from which no test case can be produced. Our evaluation, based on a proof-of-concept tool and an industrial case from the automotive domain, confirms the validity of our theory and demonstrates that our approach can eliminate many of the equivalent mutants (88% in our case study).},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {30},
numpages = {11},
keywords = {software product lines, real-time systems, mutation-based testing},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3106195.3106209,
author = {T\"{e}rnava, Xhevahire and Collet, Philippe},
title = {Early Consistency Checking between Specification and Implementation Variabilities},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106209},
doi = {10.1145/3106195.3106209},
abstract = {In a software product line (SPL) engineering approach, the addressed variability in core-code assets must be consistent with the specified domain variability, usually captured in a variability model, e.g., a feature model. Currently, the support for checking such consistency is limited, mostly when a single variability implementation technique is used, e.g., preprocessors in C. In realistic SPLs, variability is implemented using a combined set of traditional techniques, e.g., inheritance, overloading, design patterns. An inappropriate choice and combination of such techniques become the source of variability inconsistencies. In this paper, we present a tooled approach to check the consistency of variability between the specification and implementation levels, when several variability implementation techniques are used together. The proposed method models the implemented variability in terms of variation points and variants, in a forest-like structure, and uses slicing to partially check the resulting propositional formulas at both levels. As a result, it offers an early and automatic detection of inconsistencies when the mapping of variability between both levels is ideal, and with a possible extension to 1 -- to -- m mapping. We implemented and successfully applied the approach in four case studies. Our implementation, publicly available, detects inconsistencies in a very short time, which makes possible to ensure consistency earlier in the development process.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {29–38},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2364412.2364430,
author = {Creff, Stephen and Champeau, Jo\"{e}l and J\'{e}z\'{e}quel, Jean-Marc and Mon\'{e}gier, Arnaud},
title = {Model-based product line evolution: an incremental growing by extension},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364430},
doi = {10.1145/2364412.2364430},
abstract = {Model-Based Engineering (MBE) and Product Line Engineering (PLE) have been combined, to handle new system development constraints like: increasing complexity, higher product quality, faster time-to-market and cost reduction. As observed by some authors, the derivation of a product from product line shared core assets has been insufficiently addressed and can remain tedious in practice. We cope with this issue focusing on having a flexible and reactive model-based derivation, and propose an incremental evolution by extension of the product line coupled with this derivation activity. Process and tools bridge the gap between Application and Domain Engineering introducing a semi-automatic feedback to benefits from the developments made in the Application Engineering. The approach is applied to a model-based product line dedicated to Class diagrams, and is tooled within the Eclipse environment.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {107–114},
numpages = {8},
keywords = {product line engineering, product derivation, model based engineering, methodology, evolution by extension, design tools},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791095,
author = {Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire},
title = {Test control algorithms for the validation of cyber-physical systems product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791095},
doi = {10.1145/2791060.2791095},
abstract = {Cyber-Physical Systems (CPSs) product lines appear in a wide range of applications of different domains (e.g., car's doors' windows, doors of a lift, etc.). The variability of these systems is large and as a result they can be configured into plenty of configurations. Testing each of the configurations can be time consuming as not only software has to be simulated, but also the hardware and the physical layer of the CPS, which is often modelled with complex mathematical models. Choosing the adequate test control strategy is critical when testing CPSs product lines. This paper presents a set of test control algorithms organized in an architecture of three layers (domain, application and simulation) for testing CPSs product lines. An illustrative example of a CPS product line is presented and three experiments are conducted to measure the performance of the proposed test control algorithms. We conclude that test scheduling and test suite minimization significantly help to reduce the overall test costs while preserving the test quality in CPSs product lines. In addition, we conclude that knowing the results of the previously tested configurations permits reducing the time for the detection of anomalous designs.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {273–282},
numpages = {10},
keywords = {validation, testing, product line engineering, cyber-physical systems product lines},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2019136.2019161,
author = {Pleuss, Andreas and Rabiser, Rick and Botterweck, Goetz},
title = {Visualization techniques for application in interactive product configuration},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019161},
doi = {10.1145/2019136.2019161},
abstract = {In product line engineering (PLE) a major challenge is the complexity of artifacts that have to be handled. In real-world product lines, variability models can become large and complex comprising thousands of elements with hundreds of non-trivial dependencies. Visual and interactive techniques aim to reduce the (cognitive) complexity and support the user during challenging PLE tasks like product configuration. There are many visualization techniques described in the literature -- e.g., in Software Visualization -- and some isolated techniques have been applied in PLE tools. Nevertheless, the full potential of visualization in the context of PLE has not been exploited so far. This paper provides an overview of (1) available visualization techniques and criteria to judge their benefits and drawbacks for product configuration, (2) which have been applied in product configuration in PLE, and (3) which could be beneficial to support product configuration. We propose a research agenda for future work in visual and interactive PLE techniques.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {22},
numpages = {8},
keywords = {software visualization, product line engineering, product configuration},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {prediction, feature, defect, classification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3233027.3233039,
author = {Pereira, Juliana Alves and Schulze, Sandro and Figueiredo, Eduardo and Saake, Gunter},
title = {N-dimensional tensor factorization for self-configuration of software product lines at runtime},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233039},
doi = {10.1145/3233027.3233039},
abstract = {Dynamic software product lines demand self-adaptation of their behavior to deal with runtime contextual changes in their environment and offer a personalized product to the user. However, taking user preferences and context into account impedes the manual configuration process, and thus, an efficient and automated procedure is required. To automate the configuration process, context-aware recommendation techniques have been acknowledged as an effective mean to provide suggestions to a user based on their recognized context. In this work, we propose a collaborative filtering method based on tensor factorization that allows an integration of contextual data by modeling an N-dimensional tensor User-Feature-Context instead of the traditional two-dimensional User-Feature matrix. In the proposed approach, different types of non-functional properties are considered as additional contextual dimensions. Moreover, we show how to self-configure software product lines by applying our N-dimensional tensor factorization recommendation approach. We evaluate our approach by means of an empirical study using two datasets of configurations derived for medium-sized product lines. Our results reveal significant improvements in the predictive accuracy of the configuration over a state-of-the-art non-contextual matrix factorization approach. Moreover, it can scale up to a 7-dimensional tensor containing hundred of configurations in a couple of milliseconds.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {87–97},
numpages = {11},
keywords = {software product lines, self-configuration, runtime decision-making, recommender systems},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@phdthesis{10.5555/1415166,
author = {Liu, Shih-Hsi},
advisor = {Bryant, Barrett R.},
title = {Qospl: a quality of service-driven software product line engineering framework for design and analysis of component-based distributed real-time and embedded systems},
year = {2007},
isbn = {9780549467847},
publisher = {University of Alabama at Birmingham},
address = {USA},
abstract = {Software complexity may be reduced and productivity may be increased by the synergy of Component-Based Software Engineering and Software Product Line Engineering. The synergistic techniques decrease complexity by uplifting software artifacts to a higher abstraction level, namely the component level, and defining the interfaces, interactions, and contexts of such artifacts for composing software systems. Such synergistic techniques also facilitate productivity increase by promoting feature reusability, leveraging component replacement and offering selectivity among product variants. When applied to Distributed Real-time and Embedded (DRE) systems, however, these technologies must fulfill such systems' time-critical missions and numerous functional and Quality of Service (QoS) requirements. New critical challenges to be solved are QoS sensitivity that influences functional validity and performance quality, tangled requirements that increase the complexity of requirements evaluation and abundant unsatisfactory design artifacts that introduce unnecessary development workload. With an aim to answer the QoS sensitivity problem and alleviate the requirements evaluation complexity and development workload in the analysis and design workflows of a DRE software product line construction, this dissertation introduces a Quality of Service-driven software Product Line engineering framework (QoSPL). Such a framework consists of domain engineering, application engineering and quantitative analysis processes. The domain engineering process analyzes QoS requirements, represented as the execution flows of application-specific and functionality-determined tasks, and their common and variable features by means of a grammar-oriented specification language. The application engineering process models a set of execution flows to describe the behavioral characteristics of a DRE system by means of formalism with concurrent and asynchronous behaviors in a timely manner. A DRE software product line can be realized by varying different components and/or execution flows. The quantitative analysis process utilizes evolutionary algorithms to simulate the influence factors of the deployment environment and to search the optimal simulation results. Less probable design artifacts in terms of their QoS requirements can be eliminated by means of programs written in a domain-specific language. Adaptive approaches written in the domain-specific language hasten the convergence rates and/or obtain better optimal results for the quantitative analysis process. This dissertation provides two case studies and a number of experimental results to show the benefits of using QoSPL for a DRE software product line construction.},
note = {AAI3301390}
}

@inproceedings{10.1145/2791060.2791099,
author = {Filho, Jo\~{a}o Bosco Ferreira and Allier, Simon and Barais, Olivier and Acher, Mathieu and Baudry, Benoit},
title = {Assessing product line derivation operators applied to Java source code: an empirical study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791099},
doi = {10.1145/2791060.2791099},
abstract = {Product Derivation is a key activity in Software Product Line Engineering. During this process, derivation operators modify or create core assets (e.g., model elements, source code instructions, components) by adding, removing or substituting them according to a given configuration. The result is a derived product that generally needs to conform to a programming or modeling language. Some operators lead to invalid products when applied to certain assets, some others do not; knowing this in advance can help to better use them, however this is challenging, specially if we consider assets expressed in extensive and complex languages such as Java. In this paper, we empirically answer the following question: which product line operators, applied to which program elements, can synthesize variants of programs that are incorrect, correct or perhaps even conforming to test suites? We implement source code transformations, based on the derivation operators of the Common Variability Language. We automatically synthesize more than 370,000 program variants from a set of 8 real large Java projects (up to 85,000 lines of code), obtaining an extensive panorama of the sanity of the operations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {36–45},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2791060.2791069,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Empirical comparison of regression methods for variability-aware performance prediction},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791069},
doi = {10.1145/2791060.2791069},
abstract = {Product line engineering derives product variants by selecting features. Understanding the correlation between feature selection and performance is important for stakeholders to acquire a desirable product variant. We infer such a correlation using four regression methods based on small samples of measured configurations, without additional effort to detect feature interactions. We conduct experiments on six real-world case studies to evaluate the prediction accuracy of the regression methods. A key finding in our empirical study is that one regression method, called Bagging, is identified as the best to make accurate and robust predictions for the studied systems.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {186–190},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3307630.3342419,
author = {Ghofrani, Javad and Kozegar, Ehsan and Bozorgmehr, Arezoo and Soorati, Mohammad Divband},
title = {Reusability in Artificial Neural Networks: An Empirical Study},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342419},
doi = {10.1145/3307630.3342419},
abstract = {Machine learning, especially deep learning has aroused interests of researchers and practitioners for the last few years in development of intelligent systems such as speech, natural language, and image processing. Software solutions based on machine learning techniques attract more attention as alternatives to conventional software systems. In this paper, we investigate how reusability techniques are applied in implementation of artificial neural networks (ANNs). We conducted an empirical study with an online survey among experts with experience in developing solutions with ANNs. We analyze the feedback of more than 100 experts to our survey. The results show existing challenges and some of the applied solutions in an intersection between reusability and ANNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {122–129},
numpages = {8},
keywords = {systematic reuse, survey, reusability, empirical study, artificial neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3336294.3342370,
author = {Li, Yan and Yue, Tao and Ali, Shaukat and Zhang, Li},
title = {Enabling Automated Requirements Reuse and Configuration},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342370},
doi = {10.1145/3336294.3342370},
abstract = {Software-intensive systems belonging to a product line (PL) often have their shared architecture design available before they are developed. Therefore, the PL often has a large number of reusable and configurable requirements, which are naturally organized hierarchically based on the architecture of the PL. To enable reuse of requirements through configuration at the requirements engineering phase, it is important to provide a methodology (with tool support) to help practitioners to systematically and automatically develop structured and configuration-ready PL requirements repositories. Such a repository can cost-effectively facilitate the development of requirement repositories specific to individual products, i.e., individual systems. In addition, configurations to the repository at the requirements engineering phase of developing a system are part of its complete configurations and can be naturally carried on to downstream product configuration phases such as the design level configuration phase. A complete set system configurations can then be systematically obtained and managed. In this paper, we propose a methodology with tool support, named as Zen-ReqConfig, which is built on existing model-based technologies, natural language processing, and similarity measure techniques, for developing PL requirement repositories and facilitating requirements configuration. Zen-ReqConfig first automatically devises a hierarchical structure for a PL requirements repository. Then, it automatically identifies variabilities in textual requirements. Based on the developed configuration-ready PL requirements repository, it can then facilitate the configuration of products/systems at the requirements level. Zen-ReqConfig relies on two types of variability modeling techniques: cardinality-based feature modeling (CBFM) and a UML-based variability modeling methodology (named as SimPL). Both CBFM and SimPL have been used to address real-world variability modelling problems. To gain insights on the performance of Zen-ReqConfig, we evaluated it with five case studies and experimented with two different similarity measures and two different modelling methods: SimPL and CBFM. Results show that Zen-ReqConfig performed better when it is combined with the Jaro similarity measure. When Zen- ReqConfig is integrated with Jaro, it can (1) structure PL textual requirements under the most fit match criterion with high precision and recall, over 95% for both CBFM and SimPL; (2) identify variabilities in textual requirements under the most fit match criterion, with the average precision over 97% for SimPL and CBFM, and with the average recall over 94% for both SimPL and CBFM; and (3) generate repository structures within 1 second; 4) and allocate a requirement to the repository within 2 seconds on average. When looking into the impact of the two modelling methods on the performance of Zen-ReqConfig, we did not observe practical differences between SimPL and CBFM, implying that Zen-ReqConfig works well with both SimPL and CBFM.Pointer to the original paper: https://link.springer.com/article/10.1007/s10270-017-0641-6},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {206},
numpages = {1},
keywords = {software product lines, requirements engineering, model-based engineering},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2934466.2934471,
author = {Th\"{u}m, Thomas and Ribeiro, M\'{a}rcio and Schr\"{o}ter, Reimar and Siegmund, Janet and Dalton, Francisco},
title = {Product-line maintenance with emergent contract interfaces},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934471},
doi = {10.1145/2934466.2934471},
abstract = {A software product line evolves whenever one of its products need to evolve. Maintenance of preprocessor-based product lines is a difficult task, as changes to the code base may unintentionally influence the behavior of uninvolved products. Hence, developers should be supported during maintenance. We present emergent contract interfaces to make product-line development more efficient and less error-prone. The key idea is that for a given maintenance point (i.e., an assignment), we calculate (a) features in the source code that may be affected and (b) assertions based on contracts defined in the code base. By means of a controlled experiment, we provide empirical evidence regarding efficiency and error-avoidance with emergent contract interfaces.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {134–143},
numpages = {10},
keywords = {weakest precondition, software product lines, preprocessor variability, maintenance, evolution, design by contract},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1016/j.infsof.2009.10.009,
author = {Th\"{o}rn, Christer},
title = {Current state and potential of variability management practices in software-intensive SMEs: Results from a regional industrial survey},
year = {2010},
issue_date = {April, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {4},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.10.009},
doi = {10.1016/j.infsof.2009.10.009},
abstract = {Context: More and more, small and medium-sized enterprises (SMEs) are using software to augment the functionality of their products and offerings. Variability management of software is becoming an interesting topic for SMEs with expanding portfolios and increasingly complex product structures. While the use of software product lines to resolve high variability is well known in larger organizations, there is less known about the practices in SMEs. Objective: This paper presents results from a survey of software developing SMEs. The purpose of the paper is to provide a snapshot of the current awareness and practices of variability modeling in organizations that are developing software with the constraints present in SMEs. Method: A survey with questions regarding the variability practices was distributed to software developing organizations in a region of Sweden that has many SMEs. The response rate was 13% and 25 responses are used in this analysis. Results: We find that, although there are SMEs that develop implicit software product lines and have relatively sophisticated variability structures for their solution space, the structures of the problem space and the product space have room for improvement. Conclusions: The answers in the survey indicate that SMEs are in situations where they can benefit from more structured variability management, but the awareness need to be raised. Even though the problem space similarity is high, there is little reuse and traceability activities performed. The existence of SMEs with qualified variability management and product line practices indicates that small organizations are capable to apply such practices.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {411–421},
numpages = {11},
keywords = {Variability, Survey, Software engineering, SME}
}

@inproceedings{10.1145/3382025.3414954,
author = {Michelon, Gabriela Karoline and Obermann, David and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley Klewerton G. and Gr\"{u}nbacher, Paul and Egyed, Alexander},
title = {Locating feature revisions in software systems evolving in space and time},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414954},
doi = {10.1145/3382025.3414954},
abstract = {Software companies encounter variability in space as variants of software systems need to be produced for different customers. At the same time, companies need to handle evolution in time because the customized variants need to be revised and kept up-to-date. This leads to a predicament in practice with many system variants significantly diverging from each other. Maintaining these variants consistently is difficult, as they diverge across space, i.e., different feature combinations, and over time, i.e., revisions of features. This work presents an automated feature revision location technique that traces feature revisions to their implementation. To assess the correctness of our technique, we used variants and revisions from three open source highly configurable software systems. In particular, we compared the original artifacts of the variants with the composed artifacts that were located by our technique. The results show that our technique can properly trace feature revisions to their implementation, reaching traces with 100% precision and 98% recall on average for the three analyzed subject systems, taking on average around 50 seconds for locating feature revisions per variant used as input.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {14},
numpages = {11},
keywords = {variants, repository mining, feature revisions, feature location},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2499777.2500711,
author = {Ciolfi Felice, Marianela and Filho, Joao Bosco Ferreira and Acher, Mathieu and Blouin, Arnaud and Barais, Olivier},
title = {Interactive visualisation of products in online configurators: a case study for variability modelling technologies},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500711},
doi = {10.1145/2499777.2500711},
abstract = {Numerous companies develop interactive environments to assist users in customising sales products through the selection of configuration options. A visual representation of these products is an important factor in terms of user experience. However, an analysis of 100+ existing configurators highlights that not all provide visual representations of configured products. One of the current challenges is the trade-off developers face between either the memory consuming use of pregenerated images of all the combinations of options, or rendering products on the fly, which is non trivial to implement efficiently. We believe that a new approach to associate product configurations to visual representations is needed to compose and render them dynamically. In this paper we present a formal statement of the problem and a model-driven perspective for addressing it as well as our ongoing work and further challenges.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {82–85},
numpages = {4},
keywords = {variability modelling, user interface, software product line, configurator},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3233027.3233035,
author = {Varshosaz, Mahsa and Al-Hajjaji, Mustafa and Th\"{u}m, Thomas and Runge, Tobias and Mousavi, Mohammad Reza and Schaefer, Ina},
title = {A classification of product sampling for software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233035},
doi = {10.1145/3233027.3233035},
abstract = {The analysis of software product lines is challenging due to the potentially large number of products, which grow exponentially in terms of the number of features. Product sampling is a technique used to avoid exhaustive testing, which is often infeasible. In this paper, we propose a classification for product sampling techniques and classify the existing literature accordingly. We distinguish the important characteristics of such approaches based on the information used for sampling, the kind of algorithm, and the achieved coverage criteria. Furthermore, we give an overview on existing tools and evaluations of product sampling techniques. We share our insights on the state-of-the-art of product sampling and discuss potential future work.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {1–13},
numpages = {13},
keywords = {testing, software product lines, sampling algorithms, feature interaction, domain models},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2491627.2491636,
author = {Kato, Tadahisa and Kawakami, Masumi and Myojin, Tomoyuki and Ogawa, Hideto and Hirono, Koji and Hasegawa, Takashi},
title = {Case study of applying SPLE to development of network switch products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491636},
doi = {10.1145/2491627.2491636},
abstract = {Software product line engineering has spread as a technique for promoting the efficient development of embedded products with many product line-ups. During the development of network switch products at Hitachi Metals, Ltd., the number of development man-months increased as the number of product line-ups increased. Therefore, we shifted our development paradigm to product line development for efficient product development. We classified software assets as implementation assets, test assets, and design assets, and from these three assets, we extracted common objects and integrated them as reusable elements. By doing so, we promoted the efficient development of software assets and reduced the contradictions between the contents of the software assets. As a result, we reduced the amount of the source code by 53.1%. In this paper, we discuss the details of our technique and the effect of applying it. In addition, we discuss how you can apply our technique in the development of other products.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {198–207},
numpages = {10},
keywords = {test automation, software reuse, software maintenance, software integration, document integration},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3336294.3342359,
author = {Oh, Jeho and Gazzillo, Paul and Batory, Don},
title = {t-wise Coverage by Uniform Sampling},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342359},
doi = {10.1145/3336294.3342359},
abstract = {Efficiently testing large configuration spaces of Software Product Lines (SPLs) needs a sampling algorithm that is both scalable and provides good t-wise coverage. The 2019 SPLC Sampling Challenge provides large real-world feature models and asks for a t-wise sampling algorithm that can work for those models.We evaluated t-wise coverage by uniform sampling (US) the configurations of one of the provided feature models. US means that every (legal) configuration is equally likely to be selected. US yields statistically representative samples of a configuration space and can be used as a baseline to compare other sampling algorithms.We used existing algorithm called Smarch to uniformly sample SPL configurations. While uniform sampling alone was not enough to produce 100% 1-wise and 2-wise coverage, we used standard probabilistic analysis to explain our experimental results and to conjecture how uniform sampling may enhance the scalability of existing t-wise sampling algorithms.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {84–87},
numpages = {4},
keywords = {uniform sampling, software product lines, t-wise coverage},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2362536.2362567,
author = {Savolainen, Juha and Mannion, Mike and Kuusela, Juha},
title = {Developing platforms for multiple software product lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362567},
doi = {10.1145/2362536.2362567},
abstract = {Many approaches to software product line engineering have been founded on the development of a single product line platform. However as customer requirements change and new products are added to the product line, software producers recognize that the platform cannot be "stretched" indefinitely and a significant problem is striking a balance between development efficiency by increasing platform commonality and customer dissatisfaction from products with additional undesirable features and properties.One alternative is to develop multiple product lines (MPLs). However the challenge remains about what to include in a multiple product line platform. Drawing upon industrial experience of working with 4 companies, this paper explores the characteristics of the contexts in which MPLs are a viable alternative development strategy and then proposes a framework of approaches to platform development.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {220–228},
numpages = {9},
keywords = {software reuse, multiple product lines, industrial experience},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3236405.3236407,
author = {Ghofrani, Javad and Fehlhaber, Anna Lena},
title = {ProductlinRE: online management tool for requirements engineering of software product lines},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236407},
doi = {10.1145/3236405.3236407},
abstract = {The lack of online tools for managing various artifacts of software product lines is problematic, and stands in contradiction to findings about the need to support collaboration. In this paper, we present ProductLinRE, a web application allowing product line engineers to work cooperatively on artifacts of requirements engineering for software product lines. Our proposed online tool allows distributed teamwork, using a tracking mechanism for projects, artifacts and features while tailoring the requirements artifacts according to the selected features.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {17–22},
numpages = {6},
keywords = {software product lines, requirements engineering, online tools},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2362536.2362546,
author = {Myll\"{a}rniemi, Varvana and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi},
title = {A systematically conducted literature review: quality attribute variability in software product lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362546},
doi = {10.1145/2362536.2362546},
abstract = {Typically, products in a software product line differ by their functionality, and quality attributes are not intentionally varied. Why, how, and which quality attributes to vary has remained an open issue. A systematically conducted literature review on quality attribute variability is presented, where primary studies are selected by reading all content of full studies in Software Product Line Conference. The results indicate that the success of feature modeling influences the proposed approaches, different approaches suit specific quality attributes differently, and empirical evidence on industrial quality variability is lacking.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {41–45},
numpages = {5},
keywords = {variability, systematic literature review, quality attribute},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3106195.3106202,
author = {Wille, David and Wehling, Kenny and Seidl, Christoph and Pluchator, Martin and Schaefer, Ina},
title = {Variability Mining of Technical Architectures},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106202},
doi = {10.1145/3106195.3106202},
abstract = {Technical architectures (TAs) represent the computing infrastructure of a company with all its hardware and software components. Over the course of time, the number of TAs grows with the companies' requirements and usually a large variety of TAs has to be maintained. Core challenge is the missing information on relations between the existing variants of TAs, which complicates reuse of solutions across systems. However, identifying these relations is an expensive task as architects have to manually analyze each TA individually. Restructuring the existing TAs poses severe risks as often sufficient information is not available (e.g., due to time constraints). To avoid failures in productive systems and resulting loss of profit, companies continue to create new solutions without restructuring existing ones. This increased variability in TAs represents technical debt. In this paper, we adapt the idea of variability mining from the software product line domain and present an efficient and automatic mining algorithm to identify the common and varying parts of TAs by analyzing a potentially arbitrary number of TAs in parallel. Using the identified variability information, architects are capable of analyzing the relations of TAs, identifying reuse potential, and making well-founded maintenance decisions. We show the feasibility and scalability of our approach by applying it to a real-world industrial case study with large sets of TAs.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {39–48},
numpages = {10},
keywords = {variability mining, technical architecture, enterprise architecture},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2791060.2791066,
author = {Dhungana, Deepak and Falkner, Andreas and Haselb\"{o}ck, Alois and Schreiner, Herwig},
title = {Smart factory product lines: a configuration perspective on smart production ecosystems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791066},
doi = {10.1145/2791060.2791066},
abstract = {Smart production aims to increase the flexibility of the production processes and be more efficient in the use of resources. Two important pillars of this initiative are "smart products" and "smart factories". From the perspective of product line engineering, these can be seen as two product lines (product line of factories and product line of goods) that need to be integrated for a common systems engineering approach. In this paper, we look at this problem from the perspective of configuration technologies, outline the research challenges in this area and illustrate our vision using an industrial example. The factory product line goes hand-in-hand with the product line of the products to be manufactured. Future research in product line engineering needs to consider an ecosystem of a multitude of stakeholders - e.g., factory component vendors, product designers, factory owners/operators and end-consumers.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {201–210},
numpages = {10},
keywords = {smart production, smart product, smart factory, product line of factories, product and production configuration},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3233027.3233031,
author = {Kaindl, Hermann and Kramer, Stefan and Hoch, Ralph},
title = {An inductive learning perspective on automated generation of feature models from given product specifications},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233031},
doi = {10.1145/3233027.3233031},
abstract = {For explicit representation of commonality and variability of a product line, a feature model is mostly used. An open question is how a feature model can be inductively learned in an automated way from a limited number of given product specifications in terms of features.We propose to address this problem through machine learning, more precisely inductive generalization from examples. However, no counter-examples are assumed to exist. Basically, a feature model needs to be complete with respect to all the given example specifications. First results indicate the feasibility of this approach, even for generating hierarchies, but many open challenges remain.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {25–30},
numpages = {6},
keywords = {machine learning, inductive generalization from examples, generating feature models},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106210,
author = {Markiegi, Urtzi and Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire},
title = {Search-based product line fault detection allocating test cases iteratively},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106210},
doi = {10.1145/3106195.3106210},
abstract = {The large number of possible configurations makes it unfeasible to test every single system variant in a product line. Consequently, a small subset of the product line products must be selected, typically following combinatorial interaction testing approaches. Recently, many product line engineering approaches have considered the selection and prioritization of relevant products within the product line. In a further step, these products are thoroughly tested individually. However, the test cases that must be executed in each of the products are not always insignificant, and in systems such as Cyber-Physical System Product Lines (CPSPLs), their test execution time can vary from tens to thousands of seconds. This issue leads to spending a lot of time testing each individual product. To solve this problem we propose a search-based approach to perform the testing of product lines by allocating small number of test cases in each of the products. This approach increases the probability of detecting faults faster. Specifically, our search-based approach obtains a set of products, which are derived from using any state-of-the-art approach as inputs, and a set of attributed test cases. As an output a list of allocated test cases for each product is obtained. We also define a novel fitness function to guide the search and we propose corresponding crossover and mutation operators. The search and test process is iteratively repeated until the time budget is consumed. We performed an evaluation with a CPSPL as a case study. Results suggest that our approach can reduce the fault detection time by 61% and 65% on average when compared with the traditional test process and the Random Search algorithm respectively.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {123–132},
numpages = {10},
keywords = {Search-based Software Engineering, Product Line Testing, Fault Detection},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3336294.3336301,
author = {K\"{u}hn, Thomas and Cazzola, Walter and Giampietro, Nicola Pirritano and Poggi, Massimiliano},
title = {Piggyback IDE Support for Language Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336301},
doi = {10.1145/3336294.3336301},
abstract = {The idea to treat domain-specific languages (DSL) as software product lines (SPL) of compilers/interpreters led to the introduction of language product lines (LPL). Although there exist various methodologies and tools for designing LPLs, they fail to provide basic IDE services for language variants-such as, syntax highlighting, auto completion, and debugging support-that programmers normally expect. While state-of-the-art language development tools permit the generation of basic IDE services for a specific language variant, most tools fail to consider and support reuse of basic IDE services of families of DSLs. Consequently, to provide basic IDE services for an LPL, one either generates them for the many language variants or designs a separate SPL of IDEs scattering language concerns. In contrast, we aim to piggyback basic IDE services on language features and provide an IDE for LPLs, which fosters their reuse when generating language variants. In detail, we extended the Neverlang language workbench to permit piggybacking syntax highlighting and debugging support on language components. Moreover, we developed an LPL-driven Eclipse-based plugin that includes a syntax highlighting editor and debugger for an LPL with piggybacked basic IDE services, i.e., where modular language features include the definition for syntax highlighting and debugging. Within this work, we introduce a general mechanism for fostering the basic IDE services' reuse and demonstrate its feasibility by realizing context-aware syntax highlighting for a Java-based family of role-oriented programming languages and providing debugging support for the family of JavaScript-based languages.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {131–142},
numpages = {12},
keywords = {neverlang, language product lines, integrated development environment, feature modularity, domain specific languages},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342410,
author = {Rosiak, Kamil and Urbaniak, Oliver and Schlie, Alexander and Seidl, Christoph and Schaefer, Ina},
title = {Analyzing Variability in 25 Years of Industrial Legacy Software: An Experience Report},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342410},
doi = {10.1145/3307630.3342410},
abstract = {In certain domains, safety-critical software systems may remain operational for decades. To comply with changing requirements, new system variants are commonly created by copying and modifying existing ones. Typically denoted clone-and-own, software quality and overall maintainability are adversely affected in the long-run. With safety being pivotal, a fault in one variant may require the entire portfolio to be assessed. Thus, engineers need to maintain legacy systems dating back decades, implemented in programming languages such as Pascal. Software product lines (SPLs) can be a remedy but migrating legacy systems requires their prior analysis and comparison. For industrial software systems, this remains a challenge.In this paper, we introduce a comparison procedure and customizable metrics to allow for a fine-grained comparison of Pascal modules to the level of individual expressions. By that, we identify common parts of while also capturing different parts between modules as a basis for a transition towards anSPLs practice. Moreover, we demonstrate the feasibility of our approach using a case study with seven Pascal modules totaling 13,271 lines of code with an evolution-history of 25 years and show our procedure to be fast and precise. Furthermore, we elaborate on the case study and detail peculiarities of the Pascal modules, which are characteristic for an evolution-history of a quarter century.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {65–72},
numpages = {8},
keywords = {variability, software prodct line, legacy software, clone-and-own},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2647648.2647649,
author = {Raschke, Wolfgang and Zilli, Massimiliano and Loinig, Johannes and Weiss, Reinhold and Steger, Christian and Kreiner, Christian},
title = {Embedding research in the industrial field: a case of a transition to a software product line},
year = {2014},
isbn = {9781450330459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647648.2647649},
doi = {10.1145/2647648.2647649},
abstract = {Java Cards [4, 5] are small resource-constrained embedded systems that have to fulfill rigorous security requirements. Multiple application scenarios demand diverse product performance profiles which are targeted towards markets such as banking applications and mobile applications. In order to tailor the products to the customer's needs we implemented a Software Product Line (SPL). This paper reports on the industrial case of an adoption to a SPL during the development of a highly-secure software system. In order to provide a scientific method which allows the description of research in the field, we apply Action Research (AR). The rationale of AR is to foster the transition of knowledge from a mature research field to practical problems encountered in the daily routine. Thus, AR is capable of providing insights which might be overlooked in a traditional research approach. In this paper we follow the iterative AR process, and report on the successful transfer of knowledge from a research project to a real industrial application.},
booktitle = {Proceedings of the 2014 International Workshop on Long-Term Industrial Collaboration on Software Engineering},
pages = {3–8},
numpages = {6},
keywords = {software reuse, knowledge transfer, action research},
location = {Vasteras, Sweden},
series = {WISE '14}
}

@inproceedings{10.1145/3233027.3233036,
author = {Hamza, Mostafa and Walker, Robert J. and Elaasar, Maged},
title = {CIAhelper: towards change impact analysis in delta-oriented software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233036},
doi = {10.1145/3233027.3233036},
abstract = {Change is inevitable for software systems to deal with the evolving environment surrounding them, and applying changes requires careful design and implementation not to break existing functionalities. Evolution in software product lines (SPLs) is more complex compared to evolution for individual products: a change applied to a single feature might affect all the products in the whole product family. In this paper we present an approach for change impact analysis in delta-oriented programming (DOP), an existing language aimed at supporting SPLs. We propose the CIAHelper tool to identify dependencies within a DOP program, by analyzing the semantics of both the code artifacts and variability models to construct a directed dependency graph. We also consider how the source code history could be used to enhance the recall of detecting the affected artifacts given a change proposal. We evaluate our approach by means of five case studies on two different DOP SPLs.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {31–42},
numpages = {12},
keywords = {variability model, feature model, delta-oriented programming, code assets, change impact analysis},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2791060.2791080,
author = {Van Landuyt, Dimitri and Walraven, Stefan and Joosen, Wouter},
title = {Variability middleware for multi-tenant SaaS applications: a research roadmap for service lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791080},
doi = {10.1145/2791060.2791080},
abstract = {Software product line engineering (SPLE) and variability enforcement techniques have been applied to run-time adaptive systems for quite some years, also in the context of multi-tenant Software-as-a-Service (SaaS) applications. The focus has been mainly on (1) the pre-deployment phases of the development life cycle and (2) fine-grained (tenant-level), run-time activation of specific variants. However, with upcoming trends such as DevOps and continuous delivery and deployment, operational aspects become increasingly important.In this paper, we present our integrated vision on the positive interplay between SPLE and adaptive middleware for multi-tenant SaaS applications, focusing on the operational aspects of running and maintaining a successful SaaS offering. This vision, called Service Lines, is based on and motivated by our experience and frequent interactions with a number of Belgian SaaS providers.We concretely highlight and motivate a number of operational use cases that require advanced variability support in middleware and have promising added value for the economic feasibility of SaaS offerings. In addition, we provide a gap analysis of what is currently lacking from the perspectives of variability modeling and management techniques and middleware support, and as such sketch a concrete roadmap for continued research in this area.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {211–215},
numpages = {5},
keywords = {variability middleware, service lines, run-time variability, operational support, multi-tenant SaaS, models at run time},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2364412.2364456,
author = {Roos-Frantz, Fabricia and Galindo, Jos\'{e} A. and Benavides, David and Ruiz-Cort\'{e}s, Antonio},
title = {FaMa-OVM: a tool for the automated analysis of OVMs},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364456},
doi = {10.1145/2364412.2364456},
abstract = {Orthogonal Variability Model (OVM) is a modelling language for representing variability in Software Product Line Engineering. The automated analysis of OVMs is defined as the computer-aided extraction of information from such models. In this paper, we present FaMa-OVM, which is a pioneer tool for the automated analysis of OVMs. FaMa-OVM is easy to extend or integrate in other tools. It has been developed as part of the FaMa ecosystem enabling the benefits coming from other tools of that ecosystem as FaMaFW and BeTTy.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {250–254},
numpages = {5},
keywords = {tools, software products lines, OVMs},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3493244.3493274,
author = {Silva, Leandro F. and OliveiraJr, Edson},
title = {SMartyModeling: an instance of VMTools-RA for Engineering UML-based Software Product Lines},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493274},
doi = {10.1145/3493244.3493274},
abstract = {Software Product Line (SPL) life cycle comprises a set of essential activities. Variability Management (VM) is one of its most important activities to the success of an SPL, especially those based on UML, as the solution space encompasses different diagrams and perspectives on variability. However, the lack of tools to support UML-based SPLs reflects difficulties in adopting this approach. This scenario motivated the development of SMartyModeling, an environment for engineering UML-based SPL. The SMartyModeling architecture was instantiated based on VMTools-RA, an existing reference architecture for software variability tools. VMTools-RA describes architectural requirements, elements and views on software variability, which aid one to instantiate variability tool architectures. The instantiation process started from the identification of requirements, selection of elements, modules, and visions of VMTools-RA, planning and design of the architectural solutions, implementation of modules and organization of features. We then analyzed the feasibility of adopting VMTools-RA for instantiating an specific tool architecture. In this sense, such instantiation is part of the development process of SMartyModeling, which includes the main activities related to VM. We also empirically evaluated SMartyModeling in three ways: (i) a field study to analyze the instantiation process and the decisions taken; (ii) a comparative experiment analyzing efficiency and effectiveness of SMartyModeling in relation to a general purpose UML tool; and (iii) an evaluation of aspects related to perceived ease of use and perceived usability. The results of such evaluations provide initial evidence VMTools-RA is feasible to instantiate specific architectures and SMartyModeling is feasible to support to VM for UML-based SPLs.},
booktitle = {Proceedings of the XX Brazilian Symposium on Software Quality},
articleno = {33},
numpages = {10},
keywords = {Software Product Line. SMartyModeling. Environment for Modeling Software Product Line. VMTools-RA. UML. Empirical studies.},
location = {Virtual Event, Brazil},
series = {SBQS '21}
}

@inproceedings{10.1145/3336294.3336316,
author = {Tolvanen, Juha-Pekka and Kelly, Steven},
title = {How Domain-Specific Modeling Languages Address Variability in Product Line Development: Investigation of 23 Cases},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336316},
doi = {10.1145/3336294.3336316},
abstract = {Domain-Specific Modeling raises the level of abstraction beyond programming by specifying the solution directly with domain concepts. Within product lines domain-specific approaches are applied to specify variability and then generate final products together with commonality. Such automated product derivation is possible because both the modeling language and generator are made for a particular product line --- often inside a single company. In this paper we examine which kinds of reuse and product line approaches are applied in industry with domain-specific modeling. Our work is based on empirical analysis of 23 cases and the languages and models created there. The analysis reveals a wide variety and some commonalities in the size of languages and in the ways they apply reuse and product line approaches.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {155–163},
numpages = {9},
keywords = {product line variability, product derivation, domain-specific modeling, domain-specific language, code generation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2364412.2364426,
author = {Villela, Karina and Arif, Taslim and Zanardini, Damiano},
title = {Towards product configuration taking into account quality concerns},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364426},
doi = {10.1145/2364412.2364426},
abstract = {The configuration of concrete products from a product line infrastructure is the process of resolving the variability captured in the product line according to a company's market strategy or specific customer's requirements. Several aspects influence the selection of features for a concrete product, such as dependencies and constraints between features, the different stakeholders involved in the process, the desired degree of quality, and cost constraints. This paper presents the vision of a configurator that will focus on providing indicators of security and performance for features and empowering its users to interactively observe the effect of the selected set of features on these two quality characteristics. We propose the use of reusable expert knowledge and static analysis for obtaining the indicators of security and performance, respectively. The two main issues to be investigated are: (1) to which degree the configuration process should be automated; and (2) how exactly to obtain indicators of security and performance for features that can be used to predict the security and performance of whole configurations.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {82–90},
numpages = {9},
keywords = {static analysis, quality concerns, product line engineering, product configuration, feature models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s10664-004-6190-y,
author = {Svahnberg, Mikael and Wohlin, Claes},
title = {An Investigation of a Method for Identifying a Software Architecture Candidate with Respect to Quality Attributes},
year = {2005},
issue_date = {April     2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {10},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-004-6190-y},
doi = {10.1007/s10664-004-6190-y},
abstract = {To sustain the qualities of a software system during evolution, and to adapt the quality attributes as the requirements evolve, it is necessary to have a clear software architecture that is understood by all developers and to which all changes to the system adheres. This software architecture can be created beforehand, but must also be updated to reflect changes in the domain, and hence the requirements of the software. The choice of which software architecture to use is typically based on informal decisions. There exist, to the best of our knowledge, little factual knowledge of which quality attributes are supported or obstructed by different architecture approaches. In this paper we present an empirical study of a method that enables quantification of the perceived support different software architectures give for different quality attributes. This in turn enables an informed decision of which architecture candidate best fit the mixture of quality attributes required by a system being designed.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {149–181},
numpages = {33},
keywords = {quality attributes, analytic hierarchy process, Software architectures}
}

@inproceedings{10.1145/3233027.3233041,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar and Fogdal, Thomas},
title = {Reducing coordination overhead in SPLs: peering in on peers},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233041},
doi = {10.1145/3233027.3233041},
abstract = {SPL product customers might not always wait for the next core asset release. When an organization aims to react to market events, quick bug fixes or urgent customer requests, strategies are needed to support fast adaptation, e.g. with product-specific extensions, which are later propagated into the SPL. This leads to the grow-and-prune model where quick reaction to changes often requires copying and specialization (grow) to be later cleaned up by merging and refactoring (prune). This paper focuses on the grow stage. Here, application engineers branch off the core-asset Master branch to account for their products' specifics within the times and priorities of their customers without having to wait for the next release of the core assets. However, this practice might end up in the so-called "integration hell". When long-living branches are merged back into the Master, the amount of code to be integrated might cause build failures or requires complex troubleshooting. On these premises, we advocate for making application engineers aware of potential coordination problems right during coding rather than deferring it until merge time. To this end, we introduce the notion of "peering bar" for Version Control Systems, i.e. visual bars that reflect whether your product's features are being upgraded in other product branches. In this way, engineers are aware of what their peers are doing on the other SPL's products. Being products from the same SPL, they are based on the very same core assets, and hence, bug ixes or functional enhancements undertaken for a product might well serve other products. This work introduces design principles for peering bars. These principles are fleshed out for GitHub as the Version Control System, and pure::variants as the SPL framework.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {110–120},
numpages = {11},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3461001.3473064,
author = {Ayala, Inmaculada and Papadopoulos, Alessandro V. and Amor, Mercedes and Fuentes, Lidia},
title = {ProDSPL: proactive self-adaptation based on dynamic software product lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473064},
doi = {10.1145/3461001.3473064},
abstract = {This is an extended abstract of the article: Inmaculada Ayala, Alessandro V. Papadopoulos, Mercedes Amor, Lidia Fuentes, ProDSPL: Proactive self-adaptation based on Dynamic Software Product Lines, Journal of Systems and Software, Volume 175, 2021, 110909, ISSN 0164-1212, https://doi.org/10.1016/j.jss.2021.110909.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {81},
numpages = {1},
keywords = {self-adaptation, proactive control, optimization, linear constraint, dynamic software product lines},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3233027.3236404,
author = {Gazzillo, Paul and Koc, Ugur and Nguyen, ThanhVu and Wei, Shiyi},
title = {Localizing configurations in highly-configurable systems},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236404},
doi = {10.1145/3233027.3236404},
abstract = {The complexity of configurable systems has grown immensely, and it is only getting more complex. Such systems are a challenge for software testing and maintenance, because bugs and other defects can and do appear in any configuration. One common requirement for many development tasks is to identify the configurations that lead to a given defect or some other program behavior. We distill this requirement down to a challenge question: given a program location in a source file, what are valid configurations that include the location? The key obstacle is scalability. When there are thousands of configuration options, enumerating all combinations is exponential and infeasible. We provide a set of target programs of increasing difficulty and variations on the challenge question so that submitters of all experience levels can try out solutions. Our hope is to engage the community and stimulate new and interesting approaches to the problem of analyzing configurations.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {269–273},
numpages = {5},
keywords = {variability, testing, program analysis, configurations},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106225,
author = {Schlie, Alexander and Wille, David and Schulze, Sandro and Cleophas, Loek and Schaefer, Ina},
title = {Detecting Variability in MATLAB/Simulink Models: An Industry-Inspired Technique and its Evaluation},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106225},
doi = {10.1145/3106195.3106225},
abstract = {Model-based languages such as MATLAB/Simulink play an essential role in the model-driven development of software systems. To comply with new requirements, it is common practice to create new variants by copying existing systems and modifying them. Commonly referred to as clone-and-own, severe problems arise in the long-run when no dedicated variability management is installed. To allow for a documented and structured reuse of systems, their variability information needs to be reverse-engineered. In this paper, we propose an advanced comparison procedure, the Matching Window Technique, and a customizable metric. Both allow us to overcome structural alterations commonly performed during clone-and-own. We analyze related MATLAB/Simulink models and determine, classify and represent their variability information in an understandable way. With our technique, we assist model engineers in maintaining and evolving existing variants. We provide three feasibility studies with real-world models from the automotive domain and show our technique to be fast and precise. Furthermore, we perform semi-structured interviews with domain experts to assess the potential applicability of our technique in practice.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {215–224},
numpages = {10},
keywords = {variability mining, software maintainability, MATLAB/Simulink},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3233027.3233030,
author = {Weckesser, Markus and Kluge, Roland and Pfannem\"{u}ller, Martin and Matth\'{e}, Michael and Sch\"{u}rr, Andy and Becker, Christian},
title = {Optimal reconfiguration of dynamic software product lines based on performance-influence models},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233030},
doi = {10.1145/3233027.3233030},
abstract = {Today's adaptive software systems (i) are often highly configurable product lines, exhibiting hundreds of potentially conflicting configuration options; (ii) are context dependent, forcing the system to reconfigure to ever-changing contextual situations at runtime; (iii) need to fulfill context-dependent performance goals by optimizing measurable nonfunctional properties. Usually, a large number of consistent configurations exists for a given context, and each consistent configuration may perform differently with regard to the current context and performance goal(s). Therefore, it is crucial to consider nonfunctional properties for identifying an appropriate configuration. Existing black-box approaches for estimating the performance of configurations provide no means for determining context-sensitive reconfiguration decisions at runtime that are both consistent and optimal, and hardly allow for combining multiple context-dependent quality goals. In this paper, we propose a comprehensive approach based on Dynamic Software Product Lines (DSPL) for obtaining consistent and optimal reconfiguration decisions. We use training data obtained from simulations to learn performance-influence models. A novel integrated runtime representation captures both consistency properties and the learned performance-influence models. Our solution provides the flexibility to define multiple context-dependent performance goals. We have implemented our approach as a standalone component. Based on an Internet-of-Things case study using adaptive wireless sensor networks, we evaluate our approach with regard to effectiveness, efficiency, and applicability.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {98–109},
numpages = {12},
keywords = {performance-influence models, machine learning, dynamic software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2934466.2934492,
author = {Groher, Iris and Weinreich, Rainer and Buchgeher, Georg and Schossleitner, Robert},
title = {Reusable architecture variants for customer-specific automation solutions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934492},
doi = {10.1145/2934466.2934492},
abstract = {Manufacturing execution systems (MES) are key elements of industrial automation systems. MES can be deployed at different levels of scale from a single site or plant to a company with globally distributed production sites all over the world. Establishing or extending an MES is a complex process, which requires taking the already existing software and system architecture into account in addition to the desired MES features. We developed an approach and an associated tool to support the process of creating offers for customer-specific MES solutions based on a vendor-specific automation platform. We define architecture variants for selecting a specific MES feature set and for supporting different MES expansion stages. Additionally, we provide an architecture modeling approach to explore the integration with existing software and system infrastructures. The approach has been applied at the STIWA Group, a vendor of MES for industrial production lines.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {242–251},
numpages = {10},
keywords = {manufacturing execution system (MES), feature set, customer-specific offer, automation platform, architecture variants},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2362536.2362543,
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
title = {A comparison of strategies for tolerating inconsistencies during decision-making},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362543},
doi = {10.1145/2362536.2362543},
abstract = {Tolerating inconsistencies is well accepted in design modeling because it is often neither obvious how to fix an inconsistency nor important to do so right away. However, there are technical reasons why inconsistencies are not tolerated in many areas of software engineering. The most obvious being that common reasoning engines are rendered (partially) useless in the presence of inconsistencies. This paper investigates automated strategies for tolerating inconsistencies during decision-making in product line engineering, based on isolating parts from reasoning that cause inconsistencies. We compare trade offs concerning incorrect and incomplete reasoning and demonstrate that it is even possible to fully eliminate incorrect reasoning in the presence of inconsistencies at the expense of marginally less complete reasoning. Our evaluation is based on seven medium-to-large size software product line case studies. It is important to note that our mechanism for tolerating inconsistencies can be applied to arbitrary SAT problems and thus the basic principles of this approach are applicable to other domains also.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {11–20},
numpages = {10},
keywords = {user guidance, inconsistencies, formal reasoning},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2647908.2655972,
author = {Meinicke, Jens and Th\"{u}m, Thomas and Schr\"{o}ter, Reimar and Benduhn, Fabian and Saake, Gunter},
title = {An overview on analysis tools for software product lines},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655972},
doi = {10.1145/2647908.2655972},
abstract = {A software product line is a set of different software products that share commonalities. For a selection of features, specialized products of one domain can be generated automatically from domain artifacts. However, analyses of software product lines need to handle a large number of products that can be exponential in the number of features. In the last decade, many approaches have been proposed to analyze software product lines efficiently. For some of these approaches tool support is available. Based on a recent survey on analysis for software product lines, we provide a first overview on such tools. While our discussion is limited to analysis tools, we provide an accompanying website covering further tools for product-line development. We compare tools according to their analysis and implementation strategy to identify underrepresented areas. In addition, we want to ease the reuse of existing tools for researchers and students, and to simplify research transfer to practice.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {94–101},
numpages = {8},
keywords = {type checking, tool support, theorem proving, testing, static analysis, software product lines, sampling, non-functional properties, model checking, code metrics},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3129790.3129818,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Green software development and research with the HADAS toolkit},
year = {2017},
isbn = {9781450352178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3129790.3129818},
doi = {10.1145/3129790.3129818},
abstract = {Energy is a critical resource, and designing a sustainable software architecture is a non-trivial task. Developers require energy metrics that support sustainable software architectures reflecting quality attributes such as security, reliability, performance, etc., identifying what are the concerns that impact more in the energy consumption. A variability model of different designs and implementations of an energy model should exist for this task, as well as a service that stores and compares the experimentation results of energy and time consumption of each concern, finding out what is the most eco-efficient solution. The experimental measurements are performed by energy experts and researchers that share the energy model and metrics in a collaborative repository. HADAS confronts these tasks modelling and reasoning with the variability of energy consuming concerns for different energy contexts, connecting HADAS variability model with its energy efficiency collaborative repository, establishing a Software Product Line (SPL) service. Our main goal is to help developers to perform sustainability analyses finding out the eco-friendliest architecture configurations. A HADAS toolkit prototype is implemented based on a Clafer model and Choco solver, and it has been tested with several case studies.},
booktitle = {Proceedings of the 11th European Conference on Software Architecture: Companion Proceedings},
pages = {205–211},
numpages = {7},
keywords = {variability, software product line, repository, optimisation, metrics, energy efficiency, clafer, CVL},
location = {Canterbury, United Kingdom},
series = {ECSA '17}
}

@inproceedings{10.1145/2934466.2946045,
author = {Noir, J\'{e}rome Le and Madel\'{e}nat, S\'{e}bastien and Gailliard, Gr\'{e}gory and Labreuche, Christophe and Acher, Mathieu and Barais, Olivier and Constant, Olivier},
title = {A decision-making process for exploring architectural variants in systems engineering},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2946045},
doi = {10.1145/2934466.2946045},
abstract = {In systems engineering, practitioners shall explore numerous architectural alternatives until choosing the most adequate variant. The decision-making process is most of the time a manual, time-consuming, and error-prone activity. The exploration and justification of architectural solutions is ad-hoc and mainly consists in a series of tries and errors on the modeling assets. In this paper, we report on an industrial case study in which we apply variability modeling techniques to automate the assessment and comparison of several candidate architectures (variants). We first describe how we can use a model-based approach such as the Common Variability Language (CVL) to specify the architectural variability. We show that the selection of an architectural variant is a multi-criteria decision problem in which there are numerous interactions (veto, favor, complementary) between criteria.We present a tooled process for exploring architectural variants integrating both CVL and the MYRIAD method for assessing and comparing variants based on an explicit preference model coming from the elicitation of stakeholders' concerns. This solution allows understanding differences among variants and their satisfactions with respect to criteria. Beyond variant selection automation improvement, this experiment results highlight that the approach improves rationality in the assessment and provides decision arguments when selecting the preferred variants.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {277–286},
numpages = {10},
keywords = {systems engineering, multi-criteria decision analysis, model-driven engineering, design exploration, decision-making, architecture},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2934466.2934469,
author = {Zhang, Yi and Guo, Jianmei and Blais, Eric and Czarnecki, Krzysztof and Yu, Huiqun},
title = {A mathematical model of performance-relevant feature interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934469},
doi = {10.1145/2934466.2934469},
abstract = {Modern software systems have grown significantly in their size and complexity, therefore understanding how software systems behave when there are many configuration options, also called features, is no longer a trivial task. This is primarily due to the potentially complex interactions among the features. In this paper, we propose a novel mathematical model for performance-relevant, or quantitative in general, feature interactions, based on the theory of Boolean functions. Moreover, we provide two algorithms for detecting all such interactions with little measurement effort and potentially guaranteed accuracy and confidence level. Empirical results on real-world configurable systems demonstrated the feasibility and effectiveness of our approach.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {25–34},
numpages = {10},
keywords = {performance, fourier transform, feature interactions, boolean functions},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2934466.2962732,
author = {Lape\~{n}a, Ra\'{u}l and Font, Jaime and P\'{e}rez, Francisca and Cetina, Carlos},
title = {Improving feature location by transforming the query from natural language into requirements},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2962732},
doi = {10.1145/2934466.2962732},
abstract = {Software maintenance and evolution activities are responsible for the emergence of a great demand of feature location approaches that search relevant code in a large codebase. However, this search is usually performed manually and relies heavily on developers. In this paper, we propose a feature location approach that, instead of searching directly into code from a natural language query as other approaches do, transforms a natural language query to a query that is made up of the requirements that are located as relevant. Furthermore, our approach limits the scope of the code search space by selecting only the code of those products that hold relevant requirements. We evaluate the overall effectiveness of our approach in the industrial domain of train control software. Our results show that our approach improves in 18.1% the results of precision with regard to searching directly into code, which encourages further research in this direction.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {362–369},
numpages = {8},
keywords = {software maintenance and evolution, feature location, families of software products},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3109729.3109747,
author = {Silva, Cristian Vidal},
title = {Exploring efficient analysis alternatives on feature models},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109747},
doi = {10.1145/3109729.3109747},
abstract = {The automated analysis of feature models is used to extract useful information from the description of variant and common parts in software product lines. The complexity and large-scale of real feature models makes the manual analysis a tedious or even in-feasible task. For example, feature models from different domains such as operating systems or mobile ecosystems are available with thousands of features and complex relationships among them. The analysis of this kind of models requires efficient techniques and some have been explored in the past. In this thesis we propose to explore different efficient analysis alternatives. This research work will first explore parallel solutions for the Automated Analysis of Feature Models (AAFM). We review current solutions for the AAFM and, based on their efficiency and quality results, choose a few algorithmic solutions to analyze their availability of being parallelizable and propose their parallel version, to finally evaluate their results quality, performance and improvements respecting their sequential versions. We plan to explore later other efficient alternatives and summarize the advances to provide efficient ready-to-use tools for analysis purposes.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {150–155},
numpages = {6},
keywords = {Parallel, Inconsistencies, FaMa, Explanations, Automated Analysis of Feature Models, AAFM},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2791060.2791118,
author = {ter Beek, Maurice H. and Fantechi, Alessandro and Gnesi, Stefania and Mazzanti, Franco},
title = {Using FMC for family-based analysis of software product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791118},
doi = {10.1145/2791060.2791118},
abstract = {We show how the FMC model checker can successfully be used to model and analyze behavioural variability in Software Product Lines. FMC accepts parameterized specifications in a process-algebraic input language and allows the verification of properties of such models by means of efficient on-the-fly model checking. The properties can be expressed in a logic that allows to correlate the parameters of different actions within the same formula. We show how this feature can be used to tailor formulas to the verification of only a specific subset of products of a Software Product Line, thus allowing for scalable family-based analyses with FMC. We present a proof-of-concept that shows the application of FMC to an illustrative Featured Transition System from the literature.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {432–439},
numpages = {8},
keywords = {variability, process algebra, model transformation, features, featured transition systems},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1145/1183236.1183261,
author = {Clements, Paul C. and Jones, Lawrence G. and McGregor, John D. and Northrop, Linda M.},
title = {Getting there from here: a roadmap for software product line adoption},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183261},
doi = {10.1145/1183236.1183261},
abstract = {Mapping the technical and business activities and steps required for successful organizational adoption.},
journal = {Commun. ACM},
month = dec,
pages = {33–36},
numpages = {4}
}

@inproceedings{10.1145/3109729.3109746,
author = {Estrada-Torres, Bedilia},
title = {Improve Performance Management in Flexible Business Processes},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109746},
doi = {10.1145/3109729.3109746},
abstract = {The performance of business processes is evaluated and monitored with the aim of identifying whether strategic and operational goals are being achieved. Most approaches about performance measurement have been defined over traditional highly repetitive and well-structured processes. However, current organizational and business needs have encouraged the appearance of customizable processes to manage collections of process variants derived from a process, and loosely specified processes to manage non-repeatable and unpredictable processes. However, current techniques of performance measurement have not evolved to the same pace that business processes, thus generating a gap between processes and the measurement of their performance. The thesis introduced in this paper, is focused on enhancing the performance measurement of business processes by means of the improvement of existing techniques for the definition of process performance indicators and their applicability to different types of processes. With this purpose a set of artifacts, including a metamodel, notations, tools and methodologies will be developed. They will be validated by means of case studies based on real scenarios.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {145–149},
numpages = {5},
keywords = {performance indicators, flexible processes, Business process management},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3236405.3236428,
author = {Mukelabai, Mukelabai},
title = {Verification of migrated product lines},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236428},
doi = {10.1145/3236405.3236428},
abstract = {Maintaining several code bases (e.g., clones) of software variants in an application domain remains a widespread development practice, though costly and error-prone. Despite the many benefits that come with using the product-line approach, many companies are hesitant to migrate to an integrated platform for their product variants because such a migration is considered challenging and risky. Often this perception is because the migration is seen as a drastic change that is not easy to verify and assure developers that the migrated products still operate as before. In this research we propose to develop a language structure (or abstract representation) of artifacts in a software asset base that would facilitate an incremental migration of several code bases to an integrated platform. We further seek to propose and evaluate techniques for verifying the migrated product line with respect to its original code bases.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {87–89},
numpages = {3},
keywords = {verification, software product lines, migration, clone-and-own},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/1842752.1842814,
author = {Geertsema, Bas and Jansen, Slinger},
title = {Increasing software product reusability and variability using active components: a software product line infrastructure},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842814},
doi = {10.1145/1842752.1842814},
abstract = {Software Product Lines are typically used to support development of a software product family and not a software product population, which denotes a broader and more diverse range of software products. We present a Software Product Line Infrastructure (SPLI) that has been designed to increase the reuse of software efforts in product populations. The SPLI takes a bottom-up approach by structuring product features in highly reusable software components called Active Components which contain different types of artefacts. Variability is expressed using domain-specific models and formal variability models. Variability is bound during product derivation by executing model-to-artefact transformations. Components are active because they are invoked during the derivation process, thereby empowering the component. The SPLI enables step-wise refinements of applications by allowing specialization and composition of models before variability is bound. A prototype of the SPLI has been created that was used to develop and evaluate an experimental software product line. It is concluded that within the context of our experimental software product line the SPLI improves software reuse in software product populations.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {336–343},
numpages = {8},
keywords = {variability, software product lines, model-driven development, components, active components},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using machine learning to infer constraints for product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {variability modeling, software testing, software product lines, machine learning, constraints and variability mining},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2019136.2019158,
author = {Guana, Victor and Correal, Dario},
title = {Variability quality evaluation on component-based software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019158},
doi = {10.1145/2019136.2019158},
abstract = {Quality assurance and evaluation in Model Driven Software Product Lines (MD-SPLs) are pivotal points for the growing and solidification of the generative software factories. They are framed as one of the future fact methodologies for the construction of software systems. Although several approximations address the problem of generative environments, software product line scope expression, and core asset definition, not many of them try to solve, as a fundamental step, the automation of the quality attribute evaluation in the MD-SPL development cycle. This paper presents a model-driven engineering method and a tool for the quality evaluation of product line configurations through a cross architectural view analysis.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {19},
numpages = {8},
keywords = {sensitivity point, quality attribute, model-driven software product line, model composition, domain specific modeling},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3474624.3474626,
author = {Bettin, Giovanna and OliveiraJr, Edson},
title = {SMartyPerspective: a perspective-based inspection technique for software product lines},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3474626},
doi = {10.1145/3474624.3474626},
abstract = {Software Product Line (SPL) is an approach for reusing software artifacts for a specific domain. To improve products quality, verification and validation activities for SPL artifacts are necessary, thus defects are not propagated to derived products. The lack of techniques to exploit the inherited SPL reuse characteristics, mainly in early phases, provides an opportunity to investigate how to improve SPL quality. Perspective-Based Reading (PBR) has proven to be a feasible inspection technique, as it considers different scenarios and perspectives of reviewers of software artifacts. Therefore, in this paper, we specify and evaluate SMartyPerspective, a PBR technique to inspect UML-based SPL diagrams (use case, class, sequence, and component) and feature diagrams. SMartyPerspective comprises Domain Engineering perspectives: Product Manager, Domain Requirements Engineer, Domain Architect, Domain Developer, and Domain Asset Manager. We evaluated it by carrying out a TAM-based qualitative study with 19 participants with experience in SPL and software inspections. We also used coding to analyze the open questions. Obtained results provide initial evidence SMartyPerspective is feasible for inspecting its supported diagrams.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {90–94},
numpages = {5},
keywords = {UML, TAM, Software Product Line, SPL Inspections, SMarty, Perspective-Based Reading, Defects},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.1145/2364412.2364439,
author = {Vale, Tassio and Figueiredo, Gustavo Bittencourt and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero},
title = {A study on service identification methods for software product lines},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364439},
doi = {10.1145/2364412.2364439},
abstract = {The combination of service-orientation and software product line engineering, called Service-Oriented Product Line Engineering (SOPLE) have received attention by researchers and practitioners in the last years, and these areas can address issues of each other. One service-orientation issue is service identification. It consists of determining candidate services to a service-oriented environment based on pre-existing software artifacts, e.g., business process, source code, and so on. In order to provide a systematic identification of services, there are many available service identification methods in the literature, regarding different understanding of services, goals, and techniques. Due to this heterogeneity, this paper presents an in-depth comparison of service identification methods as well as a recommendation of the most suitable ones in the SOPLE context. This work can help the decision making of the most suitable method according to stakeholders' needs.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {156–163},
numpages = {8},
keywords = {software product lines, service-oriented product lines, service-oriented computing, service identification},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3336294.3342360,
author = {Michelon, Gabriela Karoline and Linsbauer, Lukas and Assun\c{c}\~{a}o, Wesley K. G. and Egyed, Alexander},
title = {Comparison-Based Feature Location in ArgoUML Variants},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342360},
doi = {10.1145/3336294.3342360},
abstract = {Identifying and extracting parts of a system's implementation for reuse is an important task for re-engineering system variants into Software Product Lines (SPLs). An SPL is an approach that enables systematic reuse of existing assets across related product variants. The re-engineering process to adopt an SPL from a set of individual variants starts with the location of features and their implementation, to be extracted and migrated into an SPL and reused in new variants. Therefore, feature location is of fundamental importance to the success in the adoption of SPLs. Despite its importance, existing feature location techniques struggle with huge, complex, and numerous system artifacts. This is the scenario of ArgoUML-SPL, which stands out as the most used case study for the validation of feature location approaches. In this paper we use an automated feature location technique and apply it to the ArgoUML feature location challenge posed.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {93–97},
numpages = {5},
keywords = {variants, traceability, software product lines, reuse, feature location, clones},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2934466.2934475,
author = {Sousa, Gustavo and Rudametkin, Walter and Duchien, Laurence},
title = {Extending feature models with relative cardinalities},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934475},
doi = {10.1145/2934466.2934475},
abstract = {Feature modeling is widely used to capture and manage commonalities and variabilities in software product lines. Cardinality-based feature models are used when variability applies not only to the selection or exclusion of features but also to the number of times a feature can be included in a product. Feature cardinalities are usually considered to apply in either a local or global scope. However, we have identified that these interpretations are insufficient to capture the variability of cloud environments. In this paper, we redefine cardinality-based feature models to allow multiple relative cardinalities between features and we discuss the effects of relative cardinalities on feature modeling semantics, consistency and cross-tree constraints. To evaluate our approach we conducted an analysis of relative cardinalities in four cloud computing providers. In addition, we developed tools for reasoning on feature models with relative cardinalities and performed experiments to verify the performance and scalability of the approach. The results from our study indicate that extending feature models with relative cardinalities is feasible and improves variability modeling, particularly in the case of cloud environments.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {79–88},
numpages = {10},
keywords = {feature model, constraints, cardinality},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3493244.3493250,
author = {Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley Klewerton Guez and Martinez, Jabier},
title = {Variability Debt: Characterization, Causes and Consequences},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493250},
doi = {10.1145/3493244.3493250},
abstract = {Variability is an inherent property of software systems to create families of products dealing with needs of different customers and environments. However, some practices to manage variability may incur technical debt. For example, the use of opportunistic reuse strategies, e.g., clone-and-own, harms maintenance and evolution activities; or deciding to abandon variability management and deriving a single product with all the features might threaten system usability. These examples are common problems found in practice but, to the best of or knowledge, not properly investigated from the perspective of technical debt. To expand the knowledge on the research and practice of technical debt in the perspective of variability management, we report results of this phenomenon, which we defined as variability debt. Our work is based on 52 industrial case studies that report problems observed in the use of opportunistic reuse. The results show that variability debt is caused by business, operational and technical aspects; leads to complex maintenance, creates difficulties to customize and create new products, misuse of human resources, usability problems; and impacts artifacts along the whole life-cycle. Although some of these issues are investigated in the field of systematic variability management, e.g., software product lines, our contribution is to present them from a technical debt perspective to enrich and create synergies between the two fields. As additional contribution, we present a catalog of variability debts in the light of technical debts found in the literature.},
booktitle = {Proceedings of the XX Brazilian Symposium on Software Quality},
articleno = {17},
numpages = {10},
keywords = {Variability management, Variability Debt, Technical Debt, Software Product Lines},
location = {Virtual Event, Brazil},
series = {SBQS '21}
}

@inproceedings{10.1145/2934466.2934476,
author = {Eichelberger, Holger and Qin, Cui and Sizonenko, Roman and Schmid, Klaus},
title = {Using IVML to model the topology of big data processing pipelines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934476},
doi = {10.1145/2934466.2934476},
abstract = {Creating product lines of Big Data stream processing applications introduces a number of novel challenges to variability modeling. In this paper, we discuss these challenges and demonstrate how advanced variability modeling capabilities can be used to directly model the topology of processing pipelines as well as their variability. We also show how such processing pipelines can be modeled, configured and validated using the Integrated Variability Modeling Language (IVML).},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {204–208},
numpages = {5},
keywords = {variability modeling, topologies, software product lines},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3106195.3106207,
author = {Li, Yang and Schulze, Sandro and Saake, Gunter},
title = {Reverse Engineering Variability from Natural Language Documents: A Systematic Literature Review},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106207},
doi = {10.1145/3106195.3106207},
abstract = {Identifying features and their relations (i.e., variation points) is crucial in the process of migrating single software systems to software product lines (SPL). Various approaches have been proposed to perform feature extraction automatically from different artifacts, for instance, feature location in legacy code. Usually such approaches a) omit variability information and b) rely on artifacts that reside in advanced phases of the development process, thus, being only of limited usefulness in the context of SPLs. In contrast, feature and variability extraction from natural language (NL) documents is more favorable, because a mapping to several other artifacts is usually established from the very beginning. In this paper, we provide a multi-dimensional overview of approaches for feature and variability extraction from NL documents by means of a systematic literature review (SLR). We selected 25 primary studies and carefully evaluated them regarding different aspects such as techniques used, tool support, or accuracy of the results. In a nutshell, our key insights are that i) standard NLP techniques are commonly used, ii) post-processing often includes clustering &amp; machine learning algorithms, iii) only in rare cases, the approaches support variability extraction, iv) tool support, apart from text pre-processing is often not available, and v) many approaches lack a comprehensive evaluation. Based on these observations, we derive future challenges, arguing that more effort need to be invested for making such approaches applicable in practice.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {133–142},
numpages = {10},
keywords = {Variability Extraction, Systematic Literature Review, Software Product Lines, Reverse Engineering, Natural Language Documents, Feature Identification},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1109/MODELS-C.2019.00045,
author = {Bilic, Damir and Brosse, Etienne and Sadovykh, Andrey and Truscan, Dragos and Bruneliere, Hugo and Ryssel, Uwe},
title = {An integrated model-based tool chain for managing variability in complex system design},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00045},
doi = {10.1109/MODELS-C.2019.00045},
abstract = {Software-intensive systems in the automotive domain are often built in different variants, notably in order to support different market segments and legislation regions. Model-based concepts are frequently applied to manage complexity in such variable systems. However, the considered approaches are often focused on single-product development. In order to support variable products in a model-based systems engineering environment, we describe a tool-supported approach that allows us to annotate SysML models with variability data. Such variability information is exchanged between the system modeling tool and variability management tools through the Variability Exchange Language. The contribution of the paper includes the introduction of the model-based product line engineering tool chain and its application on a practical case study at Volvo Construction Equipment. Initial results suggest an improved efficiency in developing such a variable system.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems Companion},
pages = {288–293},
numpages = {6},
keywords = {integrated tool chain, model-based systems engineering, product line engineering},
location = {Munich, Germany},
series = {MODELS '19 Companion}
}

@inproceedings{10.1145/2934466.2934494,
author = {Mannion, Mike and Savolainen, Juha},
title = {Choosing reusable software strategies},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934494},
doi = {10.1145/2934466.2934494},
abstract = {For many organisations, choosing a reusable software strategy such as whether to be developing products, platforms or components, or some combination of these is not straightforward. The appropriateness of the choice can also change as an organisation's internal and external business environment context changes. In this paper we provide a management tool to help guide that decision making. We set out four broad types of business strategy and map these against four different types of reusable software development strategy. The four types of business strategy correspond to different business environments which are in turn characterised by different combinations of market predictability (low to high) and an organisation's ability to influence it (low to high). To demonstrate the framework as an analytical tool we have mapped examples of different organisations reusable software strategies and explained some circumstances in which that organisation's strategy may change.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {227–231},
numpages = {5},
keywords = {strategy, reuse},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2364412.2364437,
author = {Derakhshanmanesh, Mahdi and Salehie, Mazeiar and Ebert, J\"{u}rgen},
title = {Towards model-centric engineering of a dynamic access control product line},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364437},
doi = {10.1145/2364412.2364437},
abstract = {Access control systems are deployed in organizations to protect critical cyber-physical assets. These systems need to be adjustable to cope with different contextual factors like changes in resources or requirements. Still, adaptation is often performed manually. In addition, different product variants of access control systems need to developed together systematically. These characteristics demand a product line engineering approach for enhanced reuse. Moreover, to cope with uncertainty at runtime, adaptivity, i.e., switching between variations in a cyber-physical domain (reconfiguration) and adjusting access policies (behavior adaptation), needs to be supported.In this position paper, we sketch an approach for engineering dynamic access control systems based on core concepts from dynamic software product lines and executable runtime models. The proposed solution is presented and first experiences are discussed along a sample dynamic software product line in the role-based access control domain.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {151–155},
numpages = {5},
keywords = {runtime models, dynamic software product lines, adaptive software, access control systems},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3336294.3336297,
author = {Munoz, Daniel-Jesus and Oh, Jeho and Pinto, M\'{o}nica and Fuentes, Lidia and Batory, Don},
title = {Uniform Random Sampling Product Configurations of Feature Models That Have Numerical Features},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336297},
doi = {10.1145/3336294.3336297},
abstract = {Analyses of Software Product Lines (SPLs) rely on automated solvers to navigate complex dependencies among features and find legal configurations. Often these analyses do not support numerical features with constraints because propositional formulas use only Boolean variables. Some automated solvers can represent numerical features natively, but are limited in their ability to count and Uniform Random Sample (URS) configurations, which are key operations to derive unbiased statistics on configuration spaces.Bit-blasting is a technique to encode numerical constraints as propositional formulas. We use bit-blasting to encode Boolean and numerical constraints so that we can exploit existing #SAT solvers to count and URS configurations. Compared to state-of-art Satisfiability Modulo Theory and Constraint Programming solvers, our approach has two advantages: 1) faster and more scalable configuration counting and 2) reliable URS of SPL configurations. We also show that our work can be used to extend prior SAT-based SPL analyses to support numerical features and constraints.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {289–301},
numpages = {13},
keywords = {software product lines, propositional formula, numerical features, model counting, feature model, bit-blasting},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2934466.2934485,
author = {Lape\~{n}a, Ra\'{u}l and Ballarin, Manuel and Cetina, Carlos},
title = {Towards clone-and-own support: locating relevant methods in legacy products},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934485},
doi = {10.1145/2934466.2934485},
abstract = {Clone-and-Own (CAO) is a common practice in families of software products consisting of reusing code from methods in legacy products in new developments. In industrial scenarios, CAO consumes high amounts of time and effort without guaranteeing good results. We propose a novel approach, Computer Assisted CAO (CACAO), that given the natural language requirements of a new product, and the legacy products from that family, ranks the legacy methods in the family for each of the new product requirements according to their relevancy to the new development. We evaluated our approach in the industrial domain of train control software. Without CACAO, software engineers tasked with the development of a new product had to manually review a total of 2200 methods in the family. Results show that CACAO can reduce the number of methods to be reviewed, and guide software engineers towards the identification of relevant legacy methods to be reused in the new product.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {194–203},
numpages = {10},
keywords = {software reuse, families of software products, clone and own},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2934466.2946046,
author = {Arrieta, Aitor and Wang, Shuai and Sagardui, Goiuria and Etxeberria, Leire},
title = {Search-based test case selection of cyber-physical system product lines for simulation-based validation},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2946046},
doi = {10.1145/2934466.2946046},
abstract = {Cyber-Physical Systems (CPSs) are often tested at different test levels following "X-in-the-Loop" configurations: Model-, Software- and Hardware-in-the-loop (MiL, SiL and HiL). While MiL and SiL test levels aim at testing functional requirements at the system level, the HiL test level tests functional as well as non-functional requirements by performing a real-time simulation. As testing CPS product line configurations is costly due to the fact that there are many variants to test, test cases are long, the physical layer has to be simulated and co-simulation is often necessary. It is therefore extremely important to select the appropriate test cases that cover the objectives of each level in an allowable amount of time. We propose an efficient test case selection approach adapted to the "X-in-the-Loop" test levels. Search algorithms are employed to reduce the amount of time required to test configurations of CPS product lines while achieving the test objectives of each level. We empirically evaluate three commonly-used search algorithms, i.e., Genetic Algorithm (GA), Alternating Variable Method (AVM) and Greedy (Random Search (RS) is used as a baseline) by employing two case studies with the aim of integrating the best algorithm into our approach. Results suggest that as compared with RS, our approach can reduce the costs of testing CPS product line configurations by approximately 80% while improving the overall test quality.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {297–306},
numpages = {10},
keywords = {test case selection, search-based software engineering, cyber-physical system product lines},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3106195.3106208,
author = {El-Sharkawy, Sascha and Krafczyk, Adam and Schmid, Klaus},
title = {An Empirical Study of Configuration Mismatches in Linux},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106208},
doi = {10.1145/3106195.3106208},
abstract = {Ideally the variability of a product line is represented completely and correctly by its variability model. However, in practice additional variability is often represented on the level of the build system or in the code. Such a situation may lead to inconsistencies, where the actually realized variability does not fully correspond to the one described by the variability model. In this paper we focus on configuration mismatches, i.e., cases where the effective variability differs from the variability as it is represented by the variability model. While previous research has already shown that these situations still exist even today in well-analyzed product lines like Linux, so far it was unclear under what circumstances such issues occur in reality. In particular, it is open what types of configuration mismatches occur and how severe they are. Here, our contribution is to close this gap by presenting a detailed manual analysis of 80 configuration mismatches in the Linux 4.4.1 kernel and assess their criticality. We identify various categories of configuration issues and show that about two-thirds of the configuration mismatches may actually lead to kernel misconfigurations.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {19–28},
numpages = {10},
keywords = {variability modeling, static analysis, empirical software engineering, configuration mismatches, Software product lines, Linux, Kconfig},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2791060.2791075,
author = {Fang, Miao and Leyh, Georg and Doerr, Joerg and Elsner, Christoph and Zhao, Jingjing},
title = {Towards model-based derivation of systems in the industrial automation domain},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791075},
doi = {10.1145/2791060.2791075},
abstract = {Many systems in the industrial automation domain include information systems. They manage manufacturing processes and control numerous distributed hardware and software components. In current practice, the development and reuse of such systems is costly and time-consuming, due to the variability of systems' topology and processes. Up to now, product line approaches for systematic modeling and management of variability have not been well established for such complex domains.In this paper, we present a model-based approach to support the derivation of systems in the target domain. The proposed architecture of the derivation infrastructure enables feature-, topology- and process configuration to be integrated into the multi-staged derivation process. We have developed a prototype to prove feasibility and improvement of derivation efficiency. We report the evaluation results that we collected through semi-structured interviews from domain stakeholders. The results show high potential to improve derivation efficiency by adopting the approach in practice. Finally, we report the lessons learned that raise the opportunities and challenges for future research.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {283–292},
numpages = {10},
keywords = {variability modeling, product line, model-based engineering, derivation},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3236405.3236411,
author = {Raatikainen, Mikko and Tiihonen, Juha and M\"{a}nnist\"{o}, Tomi and Felfernig, Alexander and Stettinger, Martin and Samer, Ralph},
title = {Using a feature model configurator for release planning},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236411},
doi = {10.1145/3236405.3236411},
abstract = {The requirements for a system have many dependencies that can be expressed in the individual requirements managed in an issue tracker or a requirements management system. However, managing the entire body of requirements taking into account all complex dependencies is not well supported. We describe how a feature model based configurator can be used as a tool to help manage requirements data. Data transfer and constructing the needed requirements model can be carried out automatically by relying on a model generator. We implemented a prototype tool for requirements and release management that utilizes a knowledge-based configurator.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {29–33},
numpages = {5},
keywords = {requirements engineering, release management, feature modeling},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s10664-014-9353-5,
author = {Asadi, Mohsen and Soltani, Samaneh and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek},
title = {The effects of visualization and interaction techniques on feature model configuration},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9353-5},
doi = {10.1007/s10664-014-9353-5},
abstract = {A Software Product Line is a set of software systems of a domain, which share some common features but also have significant variability. A feature model is a variability modeling artifact which represents differences among software products with respect to variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by selecting features in the feature model (referred to as the configuration process) and by instantiating the reference model. However, feature model configuration can be a cumbersome task because: 1) feature models may consist of a large number of features, which are hard to comprehend and maintain; and 2) many factors including technical limitations, implementation costs, stakeholders' requirements and expectations must be considered in the configuration process. Recognizing these issues, a significant amount of research efforts has been dedicated to different aspects of feature model configuration such as automating the configuration process. Several approaches have been proposed to alleviate the feature model configuration challenges through applying visualization and interaction techniques. However, there have been limited empirical insights available into the impact of visualization and interaction techniques on the feature model configuration process. In this paper, we present a set of visualization and interaction interventions for representing and configuring feature models, which are then empirically validated to measure the impact of the proposed interventions. An empirical study was conducted by following the principles of control experiments in software engineering and by applying the well-known software quality standard ISO 9126 to operationalize the variables investigated in the experiment. The results of the empirical study revealed that the employed visualization and interaction interventions significantly improved completion time of comprehension and changing of the feature model configuration. Additionally, according to results, the proposed interventions are easy-to-use and easy-to-learn for the participants.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1706–1743},
numpages = {38},
keywords = {Tools, Software product line engineering, Controlled experiment}
}

@inproceedings{10.1145/2934466.2966352,
author = {Javed, Muhammad},
title = {A framework for enhanced feature models based on mathematical analysis},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2966352},
doi = {10.1145/2934466.2966352},
abstract = {A Feature Model is a tree like structure that represents the commonality and variability in Software Product Lines. During analysis required information is extracted from a feature model. In the literature a number of techniques have been presented for the analysis of feature models.Quality of a Feature Model is of prime significance because it is used for the development of families of software. The quality of feature models is affected by the presence of errors. There is a need for a mechanism that could enhance the quality of a feature model by removing all inconsistency, anomaly and redundancy based errors. I am proposing a mathematical technique for the analysis of Feature Models that will lead towards their quality enhancement.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {338–339},
numpages = {2},
keywords = {redundancy, quality of feature model, quality enhancement, mathematical analysis, inconsistency, error removal, anomaly, analysis of feature model},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2019136.2019152,
author = {Kozuka, Nobuaki and Ishida, Yuzo},
title = {Building a product line architecture for variant-rich enterprise applications using a data-oriented approach},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019152},
doi = {10.1145/2019136.2019152},
abstract = {IT industry in Japan has grown by providing specific made-to-order enterprise applications for various industries. Most of enterprise applications are built upon relational database management system (RDBMS), which takes the responsibility of keeping data integrity and data manipulation. However, data explosion in recent years especially in retail and telecommunication industries makes IT industry difficult to satisfy quality attributes such as scalability, availability and data consistency with traditional development techniques. From the beginning of this century, NRI has built and refined product line architecture as a primary core asset for such data intensive industries, which have very rich variations in functional and nonfunctional requirements of their enterprise applications. This paper summarizes key criteria to build such an architecture based on our ten years experience in developing dozens of mission critical IT systems as product families for those industries.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {14},
numpages = {6},
keywords = {relational database management system, quality attributes, product line architecture, enterprise applications, data oriented approach, data intensiveness, core asset development},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2362536.2362570,
author = {Braga, Rosana T. V. and Trindade, Onofre and Branco, Kalinka R. L. J. Castelo and Lee, Jaejoon},
title = {Incorporating certification in feature modelling of an unmanned aerial vehicle product line},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362570},
doi = {10.1145/2362536.2362570},
abstract = {Safety critical systems (e.g., an avionics control system for safe flight) are often required to achieve certification under pre-established standards (e.g., DO-178B for software considerations in airborne systems and equipment certification). We have been working with our industrial partner for the last three years to develop product line assets for their avionics software product line (SPL) and, recently, we encountered two major challenges regarding certification. Firstly, an individual product must be certified, but each may require a different certification level: there might be variations in the certification requirements according to specific system usage contexts. Secondly, certification involves not only product but also process, as standards such as DO-178B also assess the quality of the development process. In this paper, we propose to include a certification view during feature modelling to provide a better understanding of the relationships between features and a certification level required for each product. The experience of introducing certification into the design model of an Unmanned Aerial Vehicle (UAV) SPL is presented to illustrate some key ideas. We also describe the lessons we have learned from this experience.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {249–258},
numpages = {10},
keywords = {software product lines, software certification, feature modelling, critical software development},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791093,
author = {Souto, Sabrina and Gopinath, Divya and d'Amorim, Marcelo and Marinov, Darko and Khurshid, Sarfraz and Batory, Don},
title = {Faster bug detection for software product lines with incomplete feature models},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791093},
doi = {10.1145/2791060.2791093},
abstract = {A software product line (SPL) is a family of programs that are differentiated by features --- increments in functionality. Systematically testing an SPL is challenging because it requires running each test of a test suite against a combinatorial number of programs. Feature models capture dependencies among features and can (1) reduce the space of programs to test and (2) enable accurate categorization of failing tests as failures of programs or the tests themselves, not as failures due to illegal combinations of features. In practice, sadly, feature models are not always available.We introduce SPLif, the first approach for testing SPLs that does not require the a priori availability of feature models. Our insight is to use a profile of passing and failing test runs to quickly identify failures that are indicative of real problems in test or code rather than specious failures due to illegal feature combinations.Experimental results on five SPLs and one large configurable system (GCC) demonstrate the effectiveness of our approach. SPLif enabled the discovery of five news bugs in GCC, three of which have already been fixed.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {151–160},
numpages = {10},
keywords = {software testing, feature models, GCC},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2791060.2791100,
author = {ter Beek, Maurice H. and Fantechi, Alessandro and Gnesi, Stefania},
title = {Applying the product lines paradigm to the quantitative analysis of collective adaptive systems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791100},
doi = {10.1145/2791060.2791100},
abstract = {Engineering a Collective Adaptive System (CAS) requires the support of a framework for quantitative modeling and analysis of the system. In order to jointly address variability and quantitative analysis, we apply the Product Lines paradigm, considered at the level of system engineering, to a case study of the European project QUANTICOL, by first defining a reference feature model and then adding feature attributes and global quantitative constraints, in the form of a Clafer attributed feature model. ClaferMOOVisualizer is subsequently used for quantitative analyses and multi-objective optimization of the resulting attributed feature model.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {321–326},
numpages = {6},
keywords = {variability analysis, quantitative modeling, quantitative analysis, multi-objective optimization, collective adaptive systems, ClaferMOO},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3106195.3106214,
author = {Couto, Marco and Borba, Paulo and Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and Pereira, Rui and Saraiva, Jo\~{a}o},
title = {Products go Green: Worst-Case Energy Consumption in Software Product Lines},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106214},
doi = {10.1145/3106195.3106214},
abstract = {The optimization of software to be (more) energy efficient is becoming a major concern for the software industry. Although several techniques have been presented to measure energy consumption for software, none has addressed software product lines (SPLs). Thus, to measure energy consumption of a SPL, the products must be generated and measured individually, which is too costly.In this paper, we present a technique and a prototype tool to statically estimate the worst case energy consumption for SPL. The goal is to provide developers with techniques and tools to reason about the energy consumption of all products in a SPL, without having to produce, run and measure the energy in all of them.Our technique combines static program analysis techniques and worst case execution time prediction with energy consumption analysis. This technique analyzes all products in a feature-sensitive manner, that is, a feature used in several products is analyzed only once, while the energy consumption is estimated once per product.We implemented our technique in a tool called Serapis. We did a preliminary evaluation using a product line for image processing implemented in C. Our experiments considered 7 products from such line and our initial results show that the tool was able to estimate the worst-case energy consumption with a mean error percentage of 9.4% and standard deviation of 6.2% when compared with the energy measured when running the products.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {84–93},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2791060.2791111,
author = {Cordy, Maxime and Davril, Jean-Marc and Greenyer, Joel and Gressi, Erika and Heymans, Patrick},
title = {All-at-once-synthesis of controllers from scenario-based product line specifications},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791111},
doi = {10.1145/2791060.2791111},
abstract = {Software-intensive systems often consist of multiple components that interact to realize complex requirements. An additional dimension of complexity arises when one designs many variants of a system at once, that is, a software product line (SPL). We propose a scenario-based approach to design SPLs, based on a combination of Modal Sequence Diagrams (MSDs) and a feature model. It consists in associating every MSD to the set of variants that have to satisfy its specification. Variability constitutes a new source of complexity, which can lead to inconsistencies in the specification of one or multiple variants. It is therefore crucial to detect these inconsistencies, and to produce a controller for each variant that makes it behave so that it satisfies its specification. We present a new controller synthesis technique that checks the absence of inconsistencies in all variants at once, thereby more radically exploiting the similarities between them. Our method first translates the MSD specification into a variability-aware B\"{u}chi game, and then solves this game for all variants in a single execution. We implemented the approach in ScenarioTools, a software tool which we use to evaluate our algorithms against competing methods.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {26–35},
numpages = {10},
keywords = {message sequence diagrams, features, controller synthesis},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2934466.2934493,
author = {Beuche, Danilo and Schulze, Michael and Duvigneau, Maurice},
title = {When 150% is too much: supporting product centric viewpoints in an industrial product line},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934493},
doi = {10.1145/2934466.2934493},
abstract = {Use of product lines promises easier production of varying products from a common base using the concepts of variation points and binding of these. This paper describes a successful industrial application of product line concepts based on the superset approach (aka 150%), where the success provided strong improvements in many aspects (e.g. product quality, amount of code to be maintained, time to delivery of new variants) but also introduced new challenges in the production of certain required product assets such as documentation or source code. We focus on the latter in this paper. We'll discuss the challenges which arose in the industrial use case from using the 150% superset approach with standard engineering programming languages and workflows and how the challenges have been solved. We evaluate our approach in a real industrial product line setting and the results show the effectiveness as well as the efficiency of the realized solution.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {262–269},
numpages = {8},
keywords = {variant management, transformation, product lines, industry use case},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3109729.3109734,
author = {Marc\'{e}n, Ana C. and Font, Jaime and Pastor, \'{O}scar and Cetina, Carlos},
title = {Towards Feature Location in Models through a Learning to Rank Approach},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109734},
doi = {10.1145/3109729.3109734},
abstract = {In this work, we propose a feature location approach to discover software artifacts that implement the feature functionality in a model. Given a model and a feature description, model fragments extracted from the model and the feature description are encoded based on a domain ontology. Then, a Learning to Rank algorithm is used to train a classifier that is based on the model fragments and feature description encoded. Finally, the classifier assesses the similarity between a population of model fragments and the target feature being located to find the set of most suitable feature realizations. We have evaluated the approach with an industrial case study, locating features with mean precision and recall values of around 73.75% and 73.31%, respectively (the sanity check obtains less than 35%).},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {57–64},
numpages = {8},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2648511.2648540,
author = {Kodama, Ryuichiro and Shimabukuro, Jun and Takagi, Yoshimitsu and Koizumi, Shinobu and Tano, Shun'ichi},
title = {Experiences with commonality control procedures to develop clinical instrument system},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648540},
doi = {10.1145/2648511.2648540},
abstract = {This paper reports our experience with software development based on the Software Product Line (SPL) approach employed for Clinical Instrument Integration Management Software (CIIMS). CIIMS is the system software which systemizes heterogeneous clinical instruments. These instruments require their particular management so that various parts of CIIMS are forced to be changed. This makes it difficult to create development plans to connect new instruments to CIIMS. In this paper we summarize a new estimate method called the Architecture Domain Matrix (ADM) method which effectively solved this problem in our experience. In ADM each architectural element is further decomposed into clinical operation flow elements and core assets of software are extracted from these elements. This method estimates the CIIMS commonality with precision and finally enables to successfully connect new instruments. In addition this method provides a Work Breakdown Structure (WBS) and supports development team building. WBS is generated by collecting all the changes for each operational flow element. A development team suitable for change is organized by taking into consideration all the changes for each architecture element. We integrated three different instruments into CIIMS in 18 months after applying this method to a real project and achieved 2.5 times greater productivity with the embedded software than that with our previous non-SPL process.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {254–263},
numpages = {10},
keywords = {software product lines, domain analysis, cost estimation, architectures},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3302333.3302336,
author = {Galster, Matthias},
title = {Variability-intensive Software Systems: Product Lines and Beyond},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302336},
doi = {10.1145/3302333.3302336},
abstract = {Product line engineering emerged from the software reuse and generative programming movements of the 70s. However, in today's competitive and fast-paced markets where users expect software to adapt to their specific needs, most modern software-intensive products and services are variability-intensive, regardless of whether they are part of a product line or not. In this talk, we explore how building variability-intensive software systems influences the various software product lifecycle stages. Furthermore, we look beyond variability in functional features: We explore the role of quality attributes in the design of variability-intensive software systems and discuss how to address the challenge of identifying and managing variability in quality attributes. Finally, based on the example of software product line research, we explore how research on variability has been changing over time and if research trends in industry and academia have diverged.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {3},
numpages = {1},
keywords = {software quality attributes, research and practice, product lines and families, Variability-intensive software systems},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1145/2019136.2019187,
author = {Abbas, Nadeem},
title = {Towards autonomic software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019187},
doi = {10.1145/2019136.2019187},
abstract = {We envision an Autonomic Software Product Line (ASPL). The ASPL is a dynamic software product line that supports self adaptable products. We plan to use reflective architecture to model and develop ASPL. To evaluate the approach, we have implemented three autonomic product lines which show promising results. The ASPL approach is at initial stages, and require additional work. We plan to exploit online learning to realize more dynamic software product lines to cope with the problem of product line evolution. We propose on-line knowledge sharing among products in a product line to achieve continuous improvement of quality in product line products.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {44},
numpages = {8},
keywords = {self-adaptation, on-line learning, knowledge},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2648511.2648549,
author = {Berger, Thorsten and St\u{a}nciulescu, \c{S}tefan and \O{}g\r{a}rd, Ommund and Haugen, \O{}ystein and Larsen, Bo and W\k{a}sowski, Andrzej},
title = {To connect or not to connect: experiences from modeling topological variability},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648549},
doi = {10.1145/2648511.2648549},
abstract = {Variability management aims at taming variability in large and complex software product lines. To efficiently manage variability, it has to be modeled using formal representations, such as feature or decision models. Such models are efficient in many domains, where variability is about switching on and off features, or using parameters to customize products of the product line. However, variability can be represented in the form of a topology in domains where variability is about connecting components in a certain order, in specific interconnected hierarchies, or in different quantities.In this experience report, we explore topological variability within a case study of large-scale fire alarm systems. We identify core characteristics of the variability, derive modeling requirements, model the variability using UML2 class diagrams, and discuss the applicability of further variability modeling languages. We show that, although challenging, class diagrams can suffice to represent topological variability in order to generate a configurator tool. In contrast, modeling parallel and recursive structures, cycles, informal constraints, and orthogonal hierarchies were among the main experienced challenges that require further research.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {330–339},
numpages = {10},
keywords = {variability modeling, topology, software product lines, experience report, configuration, class diagrams},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2791060.2791087,
author = {ter Beek, M. H. and Legay, A. and Lafuente, A. Lluch and Vandin, A.},
title = {Statistical analysis of probabilistic models of software product lines with quantitative constraints},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791087},
doi = {10.1145/2791060.2791087},
abstract = {We investigate the suitability of statistical model checking for the analysis of probabilistic models of software product lines with complex quantitative constraints and advanced feature installation options. Such models are specified in the feature-oriented language QFLan, a rich process algebra whose operational behaviour interacts with a store of constraints, neatly separating product configuration from product behaviour. The resulting probabilistic configurations and behaviour converge seamlessly in a semantics based on DTMCs, thus enabling quantitative analyses ranging from the likelihood of certain behaviour to the expected average cost of products. This is supported by a Maude implementation of QFLan, integrated with the SMT solver Z3 and the distributed statistical model checker MultiVeStA. Our approach is illustrated with a bikes product line case study.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {11–15},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2362536.2362549,
author = {Cordy, Maxime and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel},
title = {Behavioural modelling and verification of real-time software product lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362549},
doi = {10.1145/2362536.2362549},
abstract = {In Software Product Line (SPL) engineering, software products are build in families rather than individually. Many critical software are nowadays build as SPLs and most of them obey hard real-time requirements. Formal methods for verifying SPLs are thus crucial and actively studied. The verification problem for SPL is, however, more complicated than for individual systems; the large number of different software products multiplies the complexity of SPL model-checking. Recently, promising model-checking approaches have been developed specifically for SPLs. They leverage the commonality between the products to reduce the verification effort. However, none of them considers real time.In this paper, we combine existing SPL verification methods with established model-checking procedures for real-time systems. We introduce Featured Timed Automata (FTA), a formalism that extends the classical Timed Automata with constructs for modelling variability. We show that FTA model-checking can be achieved through a smart combination of real-time and SPL model checking.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {66–75},
numpages = {10},
keywords = {software product lines, real-time, model checking, features},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2491627.2491630,
author = {Linsbauer, Lukas and Lopez-Herrejon, E. Roberto and Egyed, Alexander},
title = {Recovering traceability between features and code in product variants},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491630},
doi = {10.1145/2491627.2491630},
abstract = {Many companies offer a palette of similar software products though they do not necessarily have a Software Product Line (SPL). Rather, they start building and selling individual products which they then adapt, customize and extend for different customers. As the number of product variants increases, these companies then face the severe problem of having to maintain them all. Software Product Lines can be helpful here - not so much as a platform for creating new products but as a means of maintaining the existing ones with their shared features. Here, an important first step is to determine where features are implemented in the source code and in what product variants. To this end, this paper presents a novel technique for deriving the traceability between features and code in product variants by matching code overlaps and feature overlaps. This is a difficult problem because a feature's implementation not only covers its basic functionality (which does not change across product variants) but may include code that deals with feature interaction issues and thus changes depending on the combination of features present in a product variant. We empirically evaluated the approach on three non-trivial case studies of different sizes and domains and found that our approach correctly identifies feature to code traces except for code that traces to multiple disjunctive features, a rare case involving less than 1% of the code.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {131–140},
numpages = {10},
keywords = {traceability, product variants, features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2648511.2648521,
author = {Olaechea, Rafael and Rayside, Derek and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Comparison of exact and approximate multi-objective optimization for software product lines},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648521},
doi = {10.1145/2648511.2648521},
abstract = {Software product lines (SPLs) allow stakeholders to manage product variants in a systematical way and derive variants by selecting features. Finding a desirable variant is often difficult, due to the huge configuration space and usually conflicting objectives (e.g., lower cost and higher performance). This scenario can be characterized as a multi-objective optimization problem applied to SPLs. We address the problem using an exact and an approximate algorithm and compare their accuracy, time consumption, scalability, parameter setting requirements on five case studies with increasing complexity. Our empirical results show that (1) it is feasible to use exact techniques for small SPL multi-objective optimization problems, and (2) approximate methods can be used for large problems but require substantial effort to find the best parameter setting for acceptable approximation which can be ameliorated with known good parameter ranges. Finally, we discuss the tradeoff between accuracy and time consumption when using exact and approximate techniques for SPL multi-objective optimization and guide stakeholders to choose one or the other in practice.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {92–101},
numpages = {10},
keywords = {software product lines, multi-objective optimization},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2648511.2648516,
author = {Reinhartz-Berger, Iris and Figl, Kathrin},
title = {Comprehensibility of orthogonal variability modeling languages: the cases of CVL and OVM},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648516},
doi = {10.1145/2648511.2648516},
abstract = {As the complexity and variety of systems and software products have increased, the ability to manage their variability effectively and efficiently became crucial. To this end, variability can be specified either as an integral part of the development artifacts or in a separate orthogonal variability model. Lately, orthogonal variability models attract a lot of attention due to the fact that they do not require changing the complexity of the development artifacts and can be used in conjunction with different development artifacts. Despite this attention and to the best of our knowledge, no empirical study examined the comprehensibility of orthogonal variability models.In this work, we conducted an exploratory experiment to examine potential comprehension problems in two common orthogonal variability modeling languages, namely, Common Variability Language (CVL) and Orthogonal Variability Model (OVM). We examined the comprehensibility of the variability models and their relations to the development artifacts for novice users. To measure comprehensibility we used comprehension score (i.e., percentage of correct solution), time spent to complete tasks, and participants' perception of difficulty of different model constructs. The results showed high comprehensibility of the variability models, but low comprehensibility of the relations between the variability models and the development artifacts. Although the comprehensibility of CVL and OVM was similar in terms of comprehension score and time spent to complete tasks, novice users perceived OVM as more difficult to comprehend.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {42–51},
numpages = {10},
keywords = {variability analysis, model comprehension, empirical study, OVM, CVL},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5220/0006137803620373,
author = {Greiner, Sandra and Schw\"{a}gerl, Felix and Westfechtel, Bernhard},
title = {Realizing Multi-variant Model Transformations on Top of Reused ATL Specifications},
year = {2017},
isbn = {9789897582103},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0006137803620373},
doi = {10.5220/0006137803620373},
abstract = {Model transformations are crucial in model-driven software engineering (MDSE). While combining MDSE and software product line engineering (SPLE) techniques, summarized as model-driven product line engineering (MDPLE), promises increased productivity by relying on organized reuse, the benefits are impeded by transformation specifications designed exclusively for single-variant models. Applying single-variant model transformations to multi-variant input models results in output models lacking the variability information. Multi-variant model transformations (MVMT), which preserve variability information, have only recently been understood as an explicit research problem. In this paper, we propose an a posteriori approach towards MVMT. Following the paradigm of organized reuse, we propose to employ single-variant model transformations without modifications in a first step, and to transfer variability information afterwards based on the artifacts provided by the single-variant transformation specification. In particular, we implemented this approach for the well-known model-to-model transformation language ATL. To deduce variability information, the execution artifacts (trace and execution model) are analyzed. Then, variability annotations are transfered to the target model automatically. The implementation is evaluated based on a practically example of a Graph product line. Results exhibit that our approach outperforms the conventional solution with respect to user effort, accuracy and performance.},
booktitle = {Proceedings of the 5th International Conference on Model-Driven Engineering and Software Development},
pages = {362–373},
numpages = {12},
keywords = {Variability, Software Product Line Engineering, Organized Reuse., Model-Driven Software Engineering, Model Transformations},
location = {Porto, Portugal},
series = {MODELSWARD 2017}
}

@inproceedings{10.1145/2647908.2655977,
author = {El Yamany, Ahmed Eid and Shaheen, Mohamed and Sayyad, Abdel Salam},
title = {OPTI-SELECT: an interactive tool for user-in-the-loop feature selection in software product lines},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655977},
doi = {10.1145/2647908.2655977},
abstract = {Opti-Select is an Interactive Multi-objective feature analysis and optimization tool for software product lines configuration and feature models optimization based on an innovative UIL (User-In-the-loop) idea. In this tool, the experience of system analysts and stakeholders are merged with optimization techniques and algorithms.Opti-Select interactive tool is an integrated set of techniques providing step by step feature model and attribute configuration, selecting and excluding features, solution set optimization, and user interaction utilities that can all together reach satisfactory set of solutions that fits stakeholder preferences.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {126–129},
numpages = {4},
keywords = {user-in-the-loop (UIL), software product lines, search-based software engineering, product line engineering, optimal variant, optimal feature selection, multi-objective optimization, modeling, features, feature models, feature modeling, exploration, Pareto front visualization},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2791060.2791085,
author = {Font, Jaime and Arcega, Lorena and Haugen, \O{}ystein and Cetina, Carlos},
title = {Building software product lines from conceptualized model patterns},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791085},
doi = {10.1145/2791060.2791085},
abstract = {Software Product Lines (SPLs) can be established from a set of similar models. Establishing the Product Line by mechanically finding model differences may not be the best approach. The identified model fragments may not be seen as recognizable units by the application engineers. We propose to identify model patterns by human-in-the-loop and conceptualize them as reusable model fragments. The approach provides the means to identify and extract those model patterns and further apply them to existing product models. Model fragments obtained by applying our approach seem to perform better than mechanically found ones. It turns out that the repetition of a fragment does not guarantee its relevance as reusable asset for the SPL engineers and vice versa, a fragment that has not been repeated yet, may be relevant as a reusable asset. We have validated these ideas with our industrial partner BSH, an induction hobs manufacturer that generates the firmware of their products from a model-driven SPL.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {46–55},
numpages = {10},
keywords = {variability identification, reverse engineering, model-based software product lines, human-in-the-loop},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2791060.2791072,
author = {Patel, Sachin and Shah, Vipul},
title = {Automated testing of software-as-a-service configurations using a variability language},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791072},
doi = {10.1145/2791060.2791072},
abstract = {The benefits offered by cloud technologies have compelled enterprises to adopt the Software-as-a-Service (SaaS) model for their enterprise software needs. A SaaS has to be configured or customized to suit the specific requirements of every enterprise that subscribes to it. IT service providers have to deal with the problem of testing many such configurations created for different enterprises. The software gets upgraded periodically and the configurations need to be tested on an ongoing basis to ensure business continuity. In order to run the testing organization efficiently, it is imperative that the test cycle is automated. Developing automated test scripts for a large number of configurations is a non-trivial task because differences across them may range from a few user interface changes to business process level changes. We propose an approach that combines the benefits of model driven engineering and variability modeling to address this issue. The approach comprises of the Enterprise Software Test Modeling Language to model the test cases. We use the Common Variability Language to model variability in the test cases and apply model transformations on a base model to generate a test model for each configuration. These models are used to generate automated test scripts for all the configurations. We describe the test modelling language and an experiment which shows that the approach can be used to automatically generate variations in automated test scripts.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {253–262},
numpages = {10},
keywords = {variability specification, test automation, software-as-a-service, model based testing, enterprise software testing},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/1858996.1859064,
author = {Boucher, Quentin and Classen, Andreas and Heymans, Patrick and Bourdoux, Arnaud and Demonceau, Laurent},
title = {Tag and prune: a pragmatic approach to software product line implementation},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859064},
doi = {10.1145/1858996.1859064},
abstract = {To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for the developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations.These concerns were the motivation for the industry-university collaboration described in this paper where we develop a minimally intrusive coding technique based on tags. It is supported by a toolchain and is now in use in the partner company for the development of flight grade satellite communication software libraries.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {333–336},
numpages = {4},
keywords = {feature diagram, code tagging},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1145/2362536.2362553,
author = {Andersen, Nele and Czarnecki, Krzysztof and She, Steven and W\k{a}sowski, Andrzej},
title = {Efficient synthesis of feature models},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362553},
doi = {10.1145/2362536.2362553},
abstract = {Variability modeling, and in particular feature modeling, is a central element of model-driven software product line architectures. Such architectures often emerge from legacy code, but, unfortunately creating feature models from large, legacy systems is a long and arduous task.We address the problem of automatic synthesis of feature models from propositional constraints. We show that this problem is NP-hard. We design efficient techniques for synthesis of models from respectively CNF and DNF formulas, showing a 10- to 1000-fold performance improvement over known techniques for realistic benchmarks.Our algorithms are the first known techniques that are efficient enough to be applied to dependencies extracted from real systems, opening new possibilities of creating reverse engineering and model management tools for variability models. We discuss several such scenarios in the paper.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {106–115},
numpages = {10},
keywords = {variability models, software product lines, feature models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2934466.2934488,
author = {Plakidas, Konstantinos and Stevanetic, Srdjan and Schall, Daniel and Ionescu, Tudor B. and Zdun, Uwe},
title = {How do software ecosystems evolve? a quantitative assessment of the r ecosystem.},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934488},
doi = {10.1145/2934466.2934488},
abstract = {In this work we advance the understanding of software eco-systems research by examining the structure and evolution of the R statistical computing open-source ecosystem. Our research attempts to shed light on the following intriguing question: what makes software ecosystems successful? The approach we follow is to perform a quantitative analysis of the R ecosystem. R is a well-established and popular ecosystem, whose community and marketplace are steadily growing. We assess and quantify the ecosystem throughout its history, and derive metrics on its core software components, the marketplace as well as its community. We use our insights to make observations that are applicable to ecosystems in general, validate existing theories from the literature, and propose a predictive model for the evolution of software packages. Our results show that the success of the ecosystem relies on a strong commitment by a small core of users who support a large and growing community.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {89–98},
numpages = {10},
keywords = {software ecosystems, predictive model, empirical study, R},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1007/s11219-013-9197-z,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Quality attribute modeling and quality aware product configuration in software product lines},
year = {2014},
issue_date = {September 2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-013-9197-z},
doi = {10.1007/s11219-013-9197-z},
abstract = {In software product line engineering, the customers mostly concentrate on the functionalities of the target product during product configuration. The quality attributes of a target product, such as security and performance, are often assessed until the final product is generated. However, it might be very costly to fix the problem if it is found that the generated product cannot satisfy the customers' quality requirements. Although the quality of a generated product will be affected by all the life cycles of product development, feature-based product configuration is the first stage where the estimation or prediction of the quality attributes should be considered. As we know, the key issue of predicting the quality attributes for a product configured from feature models is to measure the interdependencies between functional features and quality attributes. The current existing approaches have several limitations on this issue, such as requiring real products for the measurement or involving domain experts' efforts. To overcome these limitations, we propose a systematic approach of modeling quality attributes in feature models based on domain experts' judgments using the analytic hierarchical process (AHP) and conducting quality aware product configuration based on the captured quality knowledge. Domain experts' judgments are adapted to avoid generating the real products for quality evaluation, and AHP is used to reduce domain experts' efforts involved in the judgments. A prototype tool is developed to implement the concepts of the proposed approach, and a formal evaluation is carried out based on a large-scale case study.},
journal = {Software Quality Journal},
month = sep,
pages = {365–401},
numpages = {37},
keywords = {Software product line, Quality attributes assessment, Product configuration, Non-functional requirement (NFR) framework, Feature model, Analytic hierarchical process (AHP)}
}

@inproceedings{10.1145/3233027.3233046,
author = {Beek, Maurice H. ter and Fantechi, Alessandro and Gnesi, Stefania},
title = {Product line models of large cyber-physical systems: the case of ERTMS/ETCS},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233046},
doi = {10.1145/3233027.3233046},
abstract = {A product line perspective may help to understand the possible variants in interactions between the subsystems of a large, cyber-physical system. This observation is exemplified in this paper by proposing a feature model of the family of ERTMS/ETCS train control systems and their foreseen extensions. This model not only shows the different components that have to be installed when deploying the system at the different levels established by the ERTMS/ETCS standards, but it also helps to identify and discuss specific issues, such as the borders between onboard and wayside equipment, different manufacturers of the subsystems, interoperability among systems developed at different levels, backward compatibility of trains equipped with higher level equipment running on lines equipped with lower level equipment, and evolution towards future trends of railway signalling. The feature model forms the basis for formal modelling of the behaviour of the critical components of the system and for evaluating the overall cost, effectiveness and sustainability, for example by adding cost and performance attributes to the feature model.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {208–214},
numpages = {7},
keywords = {variability, product lines, feature models, cyber-physical systems, ERTMS/ETCS train control systems},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2362536.2362560,
author = {Lettner, Daniela and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Supporting end users with business calculations in product configuration},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362560},
doi = {10.1145/2362536.2362560},
abstract = {Business calculations like break-even, return on investment, or cost are essential in many domains to support decision making while configuring products. For instance, customers and sales people need to estimate and compare the business value of different product variants. Some product line approaches provide initial support, e.g., by defining quality attributes in relation to features. However, an approach that allows domain engineers to easily define business calculations together with variability models is still lacking. In product configuration, calculation results need to be instantly presented to end users after making configuration choices. Further, due to the often high number of calculations, the presentation of calculation results to end users can be challenging. These challenges cannot be addressed by integrating off-the-shelf applications performing the calculations with product line tools. We thus present an approach based on dedicated calculation models that are related to variability models. Our approach seamlessly integrates business calculations with product configuration and provides support for formatting calculations and calculation results. We use the DOPLER tool suite to deploy calculations together with variability models to end users in product configuration. We evaluate the expressiveness and practical relevance of the approach by investigating the development of business calculations for 15 product lines from the domain of industrial automation.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {171–180},
numpages = {10},
keywords = {variability models, product configuration, business calculations},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791068,
author = {B\'{e}can, Guillaume and Behjati, Razieh and Gotlieb, Arnaud and Acher, Mathieu},
title = {Synthesis of attributed feature models from product descriptions},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791068},
doi = {10.1145/2791060.2791068},
abstract = {Many real-world product lines are only represented as nonhierarchical collections of distinct products, described by their configuration values. As the manual preparation of feature models is a tedious and labour-intensive activity, some techniques have been proposed to automatically generate boolean feature models from product descriptions. However, none of these techniques is capable of synthesizing feature attributes and relations among attributes, despite the huge relevance of attributes for documenting software product lines. In this paper, we introduce for the first time an algorithmic and parametrizable approach for computing a legal and appropriate hierarchy of features, including feature groups, typed feature attributes, domain values and relations among these attributes. We have performed an empirical evaluation by using both randomized configuration matrices and real-world examples. The initial results of our evaluation show that our approach can scale up to matrices containing 2,000 attributed features, and 200,000 distinct configurations in a couple of minutes.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {1–10},
numpages = {10},
keywords = {product descriptions, attributed feature models},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2648511.2648533,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Generation, composition, and verification of families of human-intensive systems},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648533},
doi = {10.1145/2648511.2648533},
abstract = {Software products are rarely developed without providing different sets of features to better meet varying user needs, whether through tiered products as part of a product line or different subscription levels for software as a service (SaaS). Software product line approaches for generating and maintaining a family of different variants of software products address such needs for variation quite well. Real-world human-intensive systems (HISs) display similar needs for families of variants. A key contribution of this paper is to show how many of these needs can be rigorously and systematically addressed by adapting established techniques from system and software product line engineering (SPLE).In this paper, we present an approach for creating such families by explicitly modeling variation in HISs. We focus on two kinds of variation we have previously described in other work---functional detail variation and service variation. We describe a prototype system that is able to meet the need for these kinds of variation within an existing modeling framework and present a case study of the application of our prototype system to generate a family in an HIS from the domain of elections. Our approach also demonstrates how to perform model-checking of this family to discover whether any variants in the family may violate specified system requirements.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {207–216},
numpages = {10},
keywords = {system variation, software product lines, process families},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2934466.2934477,
author = {Krieter, Sebastian and Schr\"{o}ter, Reimar and Th\"{u}m, Thomas and Fenske, Wolfram and Saake, Gunter},
title = {Comparing algorithms for efficient feature-model slicing},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934477},
doi = {10.1145/2934466.2934477},
abstract = {Feature models are a well-known concept to represent variability in software product lines by defining features and their dependencies. During feature-model evolution, for information hiding, and for feature-model analyses, it is often necessary to remove certain features from a model. As the crude deletion of features can have undesirable effects on their dependencies, dependency-preserving algorithms, known as feature-model slicing, have been proposed. However, current algorithms do not perform well when removing a high number of features from large feature models. Therefore, we propose an efficient algorithm for feature-model slicing based on logical resolution and the minimization of logical formulas. We empirically evaluate the scalability of our algorithm on a number of feature models and find that our algorithm generally outperforms existing algorithms.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {60–64},
numpages = {5},
keywords = {software product lines, feature-model evolution, feature-model analyses},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1145/2853073.2853082,
author = {Soujanya, K. L.S. and AnandaRao, A.},
title = {A Generic Framework for Configuration Management of SPL and Controlling Evolution of Complex Software Products},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853082},
doi = {10.1145/2853073.2853082},
abstract = {Efficient configuration management system is crucial for the success of any software product line (SPL). Due to ever changing needs of customers, SPL undergoes constant changes that are to be tracked in real time. In the context of customer-driven development, anticipation and change management are to be given paramount importance. It demands implementation of software variability that drives home changed, extended and customized configurations besides economy at scale. Moreover, the emergence of distributed technologies, the unprecedented growth of component based, serviceoriented systems throw ever increasing challenges to software product line configuration management. Derivation of a new product is a dynamic process in software product line that should consider functionality and quality attributes. Very few approaches are found on configuration management (CM) of SPL though CM is enough matured for traditional products. They are tailor made and inadequate to provide a general solution. Stated differently, a comprehensive approach for SPL configuration management and product derivation is still to be desired. In this paper, we proposed a framework that guides in doing so besides helping in SPL definitions in generic way. Our framework facilitates SPL configuration management and product derivation based on critical path analysis, weight computation and feedback. We proposed two algorithms namely Quality Driven Product Derivation (QDPD) and Composition Analysis algorithm for generating satisfied compositions and to find best possible composition respectively. The usage of weights and critical path analysis improves quality of product derivation. The framework is extensible and flexible thus it can be leveraged with variability-aware design patterns and ontology. We built a prototype that demonstrates the proof of concept. We tested our approach with Dr. School product line. The results reveal that the framework supports configuration management of SPL and derivation of high quality product in the product line. We evaluated results with ground truth to establish significance of our implementation},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–10},
numpages = {10},
keywords = {weighted approach, product derivation, critical path analysis, configuration management, Software product line}
}

@inproceedings{10.1145/2362536.2362557,
author = {Elsner, Christoph},
title = {Light-weight tool support for staged product derivation},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362557},
doi = {10.1145/2362536.2362557},
abstract = {Tool support that checks for configuration errors and generates product parts from configurations can significantly improve on product derivation in product line engineering. Up to now, however, derivation tools commonly disregard the staged derivation process. They do not restrict configuration consistency checks to process entities such as configuration stages, stakeholders, or build tasks. As a result, constraints that are only valid for certain process entities must either be checked permanently, leading to false positive errors, or one must refrain from defining them at all.This paper contributes a light-weight approach to provide tailored tool support for staged product derivation. Compared to previous approaches, it is not tied to a single configuration mechanism (e.g., feature modeling), and also accounts for the stakeholders involved and the build tasks that generate product parts. First, the product line engineer describes the derivation process in a concise model. Then, based on constraint checks on the configuration (e.g., a feature model configuration) that are linked to the modeled entities, comprehensive tool support can be provided: Configuration actions can be guided and restricted depending on the configuring stakeholder in a fine-grained manner, and constraints attached to a build task will only be checked if it actually shall be executed. Finally, in combination with previous work, the paper provides evidence that the approach is applicable to legacy product lines in a light-weight manner and that it technically scales to thousands of constraint checks.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {146–155},
numpages = {10},
keywords = {tool support, staged product derivation, product line},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753255,
author = {Sun, Hongyu and Lutz, Robyn R. and Basu, Samik},
title = {Product-line-based requirements customization for web service compositions},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Customizing web services according to users' individual functional and non-functional requirements has become increasingly difficult as the number of users increases. This paper introduces a new way to customize and verify composite web services by incorporating a software product-line engineering approach into web-service composition. The approach uses a partitioning similar to that between domain engineering and application engineering in the product-line context. It specifies the options that the user can select and constructs the resulting web-service compositions. By first creating a web-service composition search space that satisfies the common requirements and then querying the search space as the user selects values for the parameters of variation, we provide a more efficient way to customize web services. A decision model, illustrated with examples from an emergency-response application, is created to interact with the customers and ensure the consistency of their specifications. The capability to reuse the composition search space may also help improve the quality and reliability of the composite services and reduce the cost of re-verifying the same compositions.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {141–150},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2362536.2362547,
author = {Johansen, Martin Fagereng and Haugen, \O{}ystein and Fleurey, Franck},
title = {An algorithm for generating t-wise covering arrays from large feature models},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362547},
doi = {10.1145/2362536.2362547},
abstract = {A scalable approach for software product line testing is required due to the size and complexity of industrial product lines. In this paper, we present a specialized algorithm (called ICPL) for generating covering arrays from feature models. ICPL makes it possible to apply combinatorial interaction testing to software product lines of the size and complexity found in industry. For example, ICPL allows pair-wise testing to be readily applied to projects of about 7,000 features and 200,000 constraints, the Linux Kernel, one of the largest product lines where the feature model is available. ICPL is compared to three of the leading algorithms for t-wise covering array generation. Based on a corpus of 19 feature models, data was collected for each algorithm and feature model when the algorithm could finish 100 runs within three days. These data are used for comparing the four algorithms. In addition to supporting large feature models, ICPL is quick, produces small covering arrays and, even though it is non-deterministic, produces a covering array of a similar size within approximately the same time each time it is run with the same feature model.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {46–55},
numpages = {10},
keywords = {testing, product lines, feature models, combinatorial interaction testing},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/978-3-642-31095-9_12,
author = {Ghaddar, Ali and Tamzalit, Dalila and Assaf, Ali and Bitar, Abdalla},
title = {Variability as a service: outsourcing variability management in multi-tenant saas applications},
year = {2012},
isbn = {9783642310942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31095-9_12},
doi = {10.1007/978-3-642-31095-9_12},
abstract = {In order to reduce the overall application expenses and time to market, SaaS (Software as a Service) providers tend to outsource several parts of their IT resources to other services providers. Such outsourcing helps SaaS providers in reducing costs and concentrating on their core competences: software domain expertises, business-processes modeling, implementation technologies and frameworks etc. However, when a SaaS provider offers a single application instance for multiple customers following the multi-tenant model, these customers (or tenants) requirements may differ, generating an important variability management concern. We believe that variability management should also be outsourced and considered as a service. The novelty of our work is to introduce the new concept of Variability as a Service (VaaS) model. It induces the appearance of VaaS providers. The objective is to relieve the SaaS providers looking forward to adopt such attractive multi-tenant solution, from developing a completely new and expensive variability solution beforehand. We present in this paper the first stage of our work: the VaaS meta-model and the VariaS component.},
booktitle = {Proceedings of the 24th International Conference on Advanced Information Systems Engineering},
pages = {175–189},
numpages = {15},
keywords = {variability, multi-tenant, SaaS},
location = {Gda\'{n}sk, Poland},
series = {CAiSE'12}
}

@inproceedings{10.1145/2791060.2791077,
author = {Rumpe, Bernhard and Schulze, Christoph and von Wenckstern, Michael and Ringert, Jan Oliver and Manhart, Peter},
title = {Behavioral compatibility of simulink models for product line maintenance and evolution},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791077},
doi = {10.1145/2791060.2791077},
abstract = {Embedded software systems, e.g. automotive, robotic or automation systems are highly configurable and consist of many software components being available in different variants and versions. To identify the degree of reusability between these different occurrences of a component, it is necessary to determine the functional backward and forward compatibility between them. Based on this information it is possible to identify in which system context a component can be replaced safely by another version, e.g. exchanging an older component, or variant, e.g. introducing new features, to achieve the same functionality.This paper presents a model checking approach to determine behavioral compatibility of Simulink models, obtained from different component variants or during evolution. A prototype for automated compatibility checking demonstrates its feasibility. In addition implemented optimizations make the analysis more efficient, when the compared variants or versions are structurally similar.A case study on a driver assistance system provided by Daimler AG shows the effectiveness of the approach to automatically compare Simulink components.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {141–150},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3218585.3218670,
author = {Martins, Luana Almeida and Parreira, Paulo Afonso and Freire, Andr\'{e} Pimenta and Costa, Heitor},
title = {Exploratory Study on the Use of Software Product Lines in the Development of Quality Assistive Technology Software},
year = {2018},
isbn = {9781450364676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3218585.3218670},
doi = {10.1145/3218585.3218670},
abstract = {The use of Software Product Line for the development of Assistive Technologies has not been widely explored yet. However, some studies point to the viability of using this approach to develop Assistive Technology software. Through this approach, important limiting factors to use Assistive Technologies can be overcome. These factors are related to the acquisition costs and difficulty to find products corresponding to specific and varying user needs. Considering that Software Product Line approach provides mass customization of software products, the specific needs of each user can be more easily satisfied by software developers. Furthermore, the reuse of code artifacts to development provides a fall in the acquisition cost of these software products. We present in this paper a literature review that aims to investigate how this approach has been applied to the development of Assistive Technology software. Also, we present some quality factors that should be considered to develop Assistive Technologies using Software Product Lines. Thus, the main findings of the review are grouped in order to find the main gaps to be explored in future work.},
booktitle = {Proceedings of the 8th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion},
pages = {262–269},
numpages = {8},
keywords = {Software Quality, Software Product Line, Assistive Technology},
location = {Thessaloniki, Greece},
series = {DSAI '18}
}

@inproceedings{10.1145/2791060.2791102,
author = {Mu\~{n}oz-Fern\'{a}ndez, Juan C. and Tamura, Gabriel and Raicu, Irina and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {REFAS: a PLE approach for simulation of self-adaptive systems requirements},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791102},
doi = {10.1145/2791060.2791102},
abstract = {Model simulation has demonstrated its usefulness in evaluation and decision-making for improving preliminary versions of artefacts before production. Particularly, one of the main goals of simulation is to verify model properties based on data collected from its execution. In this paper, we present the simulation capabilities of our REFAS framework for specifying requirements models for dynamic software products lines and self-adaptive systems. The simulation is controlled by a feedback loop and a reasoning engine that operates on the functional and non-functional requirements. The paper contribution is threefold. First, REFAS allows developers to evaluate and improve requirements models through their simulation capabilities. Second, REFAS provides rich feedback in its interactive simulations for the human modeller to make informed decisions to improve her model. Third, REFAS automates the generation of simulation scenarios required to verify the model adequacy and correctness. We evaluate our contribution by comparing the application of REFAS to a case study used in other approaches.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {121–125},
numpages = {5},
keywords = {simulation, requirements engineering, dynamic software product lines, dynamic adaptation, MAPE-K loops},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.infsof.2010.08.007,
author = {Tizzei, Leonardo P. and Dias, Marcelo and Rubira, Cec\'{\i}lia M. F. and Garcia, Alessandro and Lee, Jaejoon},
title = {Components meet aspects: Assessing design stability of a software product line},
year = {2011},
issue_date = {February, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.08.007},
doi = {10.1016/j.infsof.2010.08.007},
abstract = {Context: It is important for Product Line Architectures (PLA) to remain stable accommodating evolutionary changes of stakeholder's requirements. Otherwise, architectural modifications may have to be propagated to products of a product line, thereby increasing maintenance costs. A key challenge is that several features are likely to exert a crosscutting impact on the PLA decomposition, thereby making it more difficult to preserve its stability in the presence of changes. Some researchers claim that the use of aspects can ameliorate instabilities caused by changes in crosscutting features. Hence, it is important to understand which aspect-oriented (AO) and non-aspect-oriented techniques better cope with PLA stability through evolution. Objective: This paper evaluates the positive and negative change impact of component and aspect based design on PLAs. The objective of the evaluation is to assess how aspects and components promote PLA stability in the presence of various types of evolutionary change. To support a broader analysis, we also evaluate the PLA stability of a hybrid approach (i.e. combined use of aspects and components) against the isolated use of component-based, OO, and AO approaches. Method: An quantitative and qualitative analysis of PLA stability which involved four different implementations of a PLA: (i) an OO implementation, (ii) an AO implementation, (iii) a component-based implementation, and (iv) a hybrid implementation where both components and aspects are employed. Each implementation has eight releases and they are functionally equivalent. We used conventional metrics suites for change impact and modularity to measure the architecture stability evaluation of the 4 implementations. Results: The combination of aspects and components promotes superior PLA resilience than the other PLAs in most of the circumstances. Conclusion: It is concluded that the combination of aspects and components supports the design of high cohesive and loosely coupled PLAs. It also contributes to improve modularity by untangling feature implementation.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {121–136},
numpages = {16},
keywords = {Product Line Architecture, Design stability, Component-based Development, Aspect-Oriented Software Development}
}

@inproceedings{10.1145/2499777.2500718,
author = {Abbas, Nadeem and Andersson, Jesper},
title = {Architectural reasoning for dynamic software product lines},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500718},
doi = {10.1145/2499777.2500718},
abstract = {Software quality is critical in today's software systems. A challenge is the trade-off situation architects face in the design process. Designers often have two or more alternatives, which must be compared and put into context before a decision is made. The challenge becomes even more complex for dynamic software product lines, where domain designers have to take runtime variations into consideration as well. To address the problem we propose extensions to an architectural reasoning framework with constructs/artifacts to define and model a domain's scope and dynamic variability. The extended reasoning framework encapsulates knowledge to understand and reason about domain quality behavior and self-adaptation as a primary variability mechanism. The framework is demonstrated for a self-configuration property, self-upgradability on an educational product-line.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {117–124},
numpages = {8},
keywords = {variability, software product lines, architectural reasoning, adaptation},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2791060.2791078,
author = {Vale, Gustavo and Albuquerque, Danyllo and Figueiredo, Eduardo and Garcia, Alessandro},
title = {Defining metric thresholds for software product lines: a comparative study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791078},
doi = {10.1145/2791060.2791078},
abstract = {A software product line (SPL) is a set of software systems that share a common and variable set of features. Software metrics provide basic means to quantify several modularity aspects of SPLs. However, the effectiveness of the SPL measurement process is directly dependent on the definition of reliable thresholds. If thresholds are not properly defined, it is difficult to actually know whether a given metric value indicates a potential problem in the feature implementation. There are several methods to derive thresholds for software metrics. However, there is little understanding about their appropriateness for the SPL context. This paper aims at comparing three methods to derive thresholds based on a benchmark of 33 SPLs. We assess to what extent these methods derive appropriate values for four metrics used in product-line engineering. These thresholds were used for guiding the identification of a typical anomaly found in features' implementation, named God Class. We also discuss the lessons learned on using such methods to derive thresholds for SPLs.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {176–185},
numpages = {10},
keywords = {thresholds, software product lines, metrics},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2362536.2362563,
author = {Heider, Wolfgang and Rabiser, Rick and Gr\"{u}nbacher, Paul and Lettner, Daniela},
title = {Using regression testing to analyze the impact of changes to variability models on products},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362563},
doi = {10.1145/2362536.2362563},
abstract = {Industrial product lines are typically maintained for a long time and evolve continuously to address changing requirements and new technologies. Already derived products often have to be re-derived after such changes to benefit from new and updated features. Product line engineers thus frequently need to analyze the impact of changes to variability models to prevent unexpected changes of re-derived products. In this paper we present a tool-supported approach that informs engineers about the impacts of variability model changes on existing products. Regression tests are used to determine whether existing product configurations and generated product outputs can be re-derived without unexpected effects. We evaluate the feasibility of the approach based on changes observed in a real-world software product line. More specifically, we show how our approach helps engineers performing specific evolution tasks to analyze the change impacts on existing products. We also evaluate the performance and scalability of our approach. Our results show that variability change impact analyses can be automated using model regression testing and can help reducing the gap between domain engineering and application engineering.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {196–205},
numpages = {10},
keywords = {variability models, regression testing, product line evolution},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2019136.2019177,
author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
title = {Knowledge evolution in autonomic software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019177},
doi = {10.1145/2019136.2019177},
abstract = {We describe ongoing work in knowledge evolution management for autonomic software product lines. We explore how an autonomic product line may benefit from new knowledge originating from different source activities and artifacts at run time. The motivation for sharing run-time knowledge is that products may self-optimize at run time and thus improve quality faster compared to traditional software product line evolution. We propose two mechanisms that support knowledge evolution in product lines: online learning and knowledge sharing. We describe two basic scenarios for runtime knowledge evolution that involves these mechanisms. We evaluate online learning and knowledge sharing in a small product line setting that shows promising results.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {36},
numpages = {8},
keywords = {software product-lines, software design, self-adaptation, product-line management, online learning, knowledge sharing},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2362536.2362552,
author = {G\'{o}mez, Abel and Penad\'{e}s, M. Carmen and Can\'{o}s, Jos\'{e} H. and Borges, Marcos R. S. and Llavador, Manuel},
title = {DPLfw: a framework for variable content document generation},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362552},
doi = {10.1145/2362536.2362552},
abstract = {Variable Data Printing solutions provide means to generate documents whose content varies according to some criteria. Since the early Mail Merge-like applications that generated letters with destination data taken from databases, different languages and frameworks have been developed with increasing levels of sophistication. Current tools allow the generation of highly customized documents that are variable not only in content, but also in layout. However, most frameworks are technology-oriented, and their use requires high skills in implementation-related tools (XML, XPATH, and others), which do not include support for domain-related tasks like identification of document content variability.In this paper, we introduce DPLfw, a framework for variable content document generation based on Software Product Line Engineering principles. It is an implementation of the Document Product Lines (DPL) approach, which was defined with the aim of supporting variable content document generation from a domain-oriented point of view. DPL models document content variability in terms of features, and product line-like processes support the generation of documents. We define the DPLfw architecture, and illustrate its use in the definition of variable-content emergency plans.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {96–105},
numpages = {10},
keywords = {variable data printing, model driven engineering, feature modeling, document product line, DITA},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2491627.2492152,
author = {Taylor, Richard N.},
title = {The role of architectural styles in successful software ecosystems},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2492152},
doi = {10.1145/2491627.2492152},
abstract = {Software ecosystems are complex systems composed of multiple independent elements interacting with the system as a whole and with each other. "Success" for an ecosystem may be judged primarily in economic terms, but may alternatively be assessed with regard to other qualities, such as reduced time-to-market, widespread use, or adaptability. Example successful ecosystems include iOS apps, Photoshop Lightroom plug-ins, RESTful web services, and numerous e-commerce systems. This talk will examine the critical role that architectural styles play in making and sustaining successful ecosystems. Architectural styles are sets of design decisions applicable to a particular context, constraining development within that context, and yielding beneficial qualities. Styles carry lessons learned through experience, aid communication, provide vocabulary, and speed design. Most importantly, they can be key elements in maintaining conceptual integrity. After examining the role of styles in several ecosystems, the talk will focus on the particular problems of ecosystems in which some participants may be malicious, or where high degrees of customization or adaptability are required.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {2–4},
numpages = {3},
keywords = {software ecosystems, architectural styles, REST, COAST},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2648511.2648517,
author = {Angerer, Florian and Pr\"{a}hofer, Herbert and Lettner, Daniela and Grimmer, Andreas and Gr\"{u}nbacher, Paul},
title = {Identifying inactive code in product lines with configuration-aware system dependence graphs},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648517},
doi = {10.1145/2648511.2648517},
abstract = {Application engineers frequently create customer-specific products in two stages: the required software components are first selected to create an initial product which is then evolved by refining the selected features and adapting the code to meet the customers' requirements. For instance, developers frequently set configuration options in the code to adjust the product. However, given that such changes are often necessary in the entire code base it is hard to know which part of the code is still relevant for the chosen configuration options. This means that engineers need to understand and maintain a lot of code that is potentially inactive in a particular product variant. Existing approaches provide only partial solutions: for instance, feature-to-code mappings do not adequately consider complex code dependencies of the implemented features. Static analysis techniques provide better results but usually do not consider variability aspects. We present an approach to automatically identify inactive code in product variants using a configuration-aware code analysis technique. We demonstrate the flexibility of our approach by customizing it to a product line of an industry partner in the domain of industrial automation. We further evaluate the approach to demonstrate its effectiveness, accuracy, and performance.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {52–61},
numpages = {10},
keywords = {static analysis, maintenance, configuration, clone-and-own product lines, application engineering},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2491627.2491635,
author = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Traon, Yves Le},
title = {Multi-objective test generation for software product lines},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491635},
doi = {10.1145/2491627.2491635},
abstract = {Software Products Lines (SPLs) are families of products sharing common assets representing code or functionalities of a software product. These assets are represented as features, usually organized into Feature Models (FMs) from which the user can configure software products. Generally, few features are sufficient to allow configuring millions of software products. As a result, selecting the products matching given testing objectives is a difficult problem.The testing process usually involves multiple and potentially conflicting testing objectives to fulfill, e.g. maximizing the number of optional features to test while at the same time both minimizing the number of products and minimizing the cost of testing them. However, most approaches for generating products usually target a single objective, like testing the maximum amount of feature interactions. While focusing on one objective may be sufficient in certain cases, this practice does not reflect real-life testing situations.The present paper proposes a genetic algorithm to handle multiple conflicting objectives in test generation for SPLs. Experiments conducted on FMs of different sizes demonstrate the effectiveness, feasibility and practicality of the introduced approach.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {62–71},
numpages = {10},
keywords = {test generation, software product lines, multi-objective optimization, genetic algorithms, feature models},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2791060.2791070,
author = {Liang, Jia Hui and Ganesh, Vijay and Czarnecki, Krzysztof and Raman, Venkatesh},
title = {SAT-based analysis of large real-world feature models is easy},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791070},
doi = {10.1145/2791060.2791070},
abstract = {Modern conflict-driven clause-learning (CDCL) Boolean SAT solvers provide efficient automatic analysis of real-world feature models (FM) of systems ranging from cars to operating systems. It is well-known that solver-based analysis of real-world FMs scale very well even though SAT instances obtained from such FMs are large, and the corresponding analysis problems are known to be NP-complete. To better understand why SAT solvers are so effective, we systematically studied many syntactic and semantic characteristics of a representative set of large real-world FMs. We discovered that a key reason why large real-world FMs are easy-to-analyze is that the vast majority of the variables in these models are unrestricted, i.e., the models are satisfiable for both true and false assignments to such variables under the current partial assignment. Given this discovery and our understanding of CDCL SAT solvers, we show that solvers can easily find satisfying assignments for such models without too many backtracks relative to the model size, explaining why solvers scale so well. Further analysis showed that the presence of unrestricted variables in these real-world models can be attributed to their high-degree of variability. Additionally, we experimented with a series of well-known nonbacktracking simplifications that are particularly effective in solving FMs. The remaining variables/clauses after simplifications, called the core, are so few that they are easily solved even with backtracking, further strengthening our conclusions. We explain the connection between our findings and backdoors, an idea posited by theorists to explain the power of SAT solvers. This connection strengthens our hypothesis that SAT-based analysis of FMs is easy. In contrast to our findings, previous research characterizes the difficulty of analyzing randomly-generated FMs in terms of treewidth. Our experiments suggest that the difficulty of analyzing real-world FMs cannot be explained in terms of treewidth.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {91–100},
numpages = {10},
keywords = {feature model, SAT-based analysis},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.asoc.2016.07.040,
author = {Xue, Yinxing and Zhong, Jinghui and Tan, Tian Huat and Liu, Yang and Cai, Wentong and Chen, Manman and Sun, Jun},
title = {IBED},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.07.040},
doi = {10.1016/j.asoc.2016.07.040},
abstract = {Graphical abstractDisplay Omitted HighlightsWe propose to combine IBEA and DE for the optimal feature selection in SPLE.We propose a feedback-directed method into EAs to improve the correctness of results.Our IBED with the seeding method has significantly shortened the search time.In most cases, IBED finds more unique and non-dominated solutions than IBEA. Software configuration, which aims to customize the software for different users (e.g., Linux kernel configuration), is an important and complicated task. In software product line engineering (SPLE), feature oriented domain analysis is adopted and feature model is used to guide the configuration of new product variants. In SPLE, product configuration is an optimal feature selection problem, which needs to find a set of features that have no conflicts and meanwhile achieve multiple design objectives (e.g., minimizing cost and maximizing the number of features). In previous studies, several multi-objective evolutionary algorithms (MOEAs) were used for the optimal feature selection problem and indicator-based evolutionary algorithm (IBEA) was proven to be the best MOEA for this problem. However, IBEA still suffers from the issues of correctness and diversity of found solutions. In this paper, we propose a dual-population evolutionary algorithm, named IBED, to achieve both correctness and diversity of solutions. In IBED, two populations are individually evolved with two different types of evolutionary operators, i.e., IBEA operators and differential evolution (DE) operators. Furthermore, we propose two enhancement techniques for existing MOEAs, namely the feedback-directed mechanism to fast find the correct solutions (e.g., solutions that satisfy the feature model constraints) and the preprocessing method to reduce the search space. Our empirical results have shown that IBED with the enhancement techniques can outperform several state-of-the-art MOEAs on most case studies in terms of correctness and diversity of found solutions.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1215–1231},
numpages = {17},
keywords = {Software product line engineering, Optimal feature selection, Indicator-based evolutionary algorithm (IBEA), Differential evolutionary algorithm (DE)}
}

@inproceedings{10.1145/2648511.2648528,
author = {Barreiros, Jorge and Moreira, Ana},
title = {A cover-based approach for configuration repair},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648528},
doi = {10.1145/2648511.2648528},
abstract = {Feature models are often used to describe variability and commonality in Software Product Lines, specifying admissible configurations of valid products. However, invalid configurations may arise in some scenarios. These include feature model evolution that invalidates pre-existing products or collaborative configuration by multiple stakeholders with conflicting goals, among others. This problem has been acknowledged in the literature and some techniques for configuration repair have already been proposed. However, common optimization criteria such as proximity between original and repaired configurations can result in a significant number of alternative repair possibilities, easily attaining thousands of alternatives for models of practical dimension. Consequently, rather than just efficiently providing an exhaustive list of possibilities, an approach that specifically addresses this issue should be able to offer the user a manageable and comprehensible view of the configuration problems and potential repair options. We offer a novel approach for configuration repair, based on partitioning and cover analysis, with high performance and generating high quality solutions, which allows efficient identification and presentation of multiple competing repairs.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {157–166},
numpages = {10},
keywords = {software product lines, feature modeling, configuration repair, configuration diagnosis, configuration},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5555/776816.776947,
author = {Knauber, Peter and Bosch, Jan},
title = {ICSE workshop on: Software Variability Management},
year = {2003},
isbn = {076951877X},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {During recent years, the amount of variability that has to be supported by a software artifact is growing considerably and its management is developing as a main challenge during development, usage, and evolution of software artifacts. Successful management of variability in software artifacts leads to better customizable software products that are in turn likely to result in higher market success.The aim of this workshop is to study software variability management both from a 'problems' and from a 'solutions' perspective by bringing together people from industrial practice and from applied research in academia to present and discuss their respective experience.Issues to be addressed include, but are not limited to, technological, process, and organizational aspects as well as notation, assessment, design, and evolution aspects.},
booktitle = {Proceedings of the 25th International Conference on Software Engineering},
pages = {779–780},
numpages = {2},
keywords = {variability management, software variability, software customization, software configuration, software adaptation},
location = {Portland, Oregon},
series = {ICSE '03}
}

@inproceedings{10.1007/978-3-030-21290-2_42,
author = {Reinhartz-Berger, Iris and Shimshoni, Ilan and Abdal, Aviva},
title = {Behavior-Derived Variability Analysis: Mining Views for Comparison and Evaluation},
year = {2019},
isbn = {978-3-030-21289-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-21290-2_42},
doi = {10.1007/978-3-030-21290-2_42},
abstract = {The large variety of computerized solutions (software and information systems) calls for a systematic approach to their comparison and evaluation. Different methods have been proposed over the years for analyzing the similarity and variability of systems. These methods get artifacts, such as requirements, design models, or code, of different systems (commonly in the same domain), identify and calculate their similarities, and represent the variability in models, such as feature diagrams. Most methods rely on implementation considerations of the input systems and generate outcomes based on predefined, fixed strategies of comparison (referred to as variability views). In this paper, we introduce an approach for mining relevant views for comparison and evaluation, based on the input artifacts. Particularly, we equip SOVA – a Semantic and Ontological Variability Analysis method – with data mining techniques in order to identify relevant views that highlight variability or similarity of the input artifacts (natural language requirement documents). The comparison is done using entropy and Rand index measures. The method and its outcomes are evaluated on a case of three photo sharing applications.},
booktitle = {Advanced Information Systems Engineering: 31st International Conference, CAiSE 2019, Rome, Italy, June 3–7, 2019, Proceedings},
pages = {675–690},
numpages = {16},
keywords = {Software Product Line Engineering, Variability analysis, Requirements specifications, Feature diagrams},
location = {Rome, Italy}
}

@article{10.1002/smr.1568,
author = {Belategi, Lorea and Sagardui, Goiuria and Etxeberria, Leire and Azanza, Maider},
title = {Embedded software product lines: domain and application engineering model‐based analysis processes},
year = {2014},
issue_date = {April 2014},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {26},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.1568},
doi = {10.1002/smr.1568},
abstract = {Nowadays, embedded systems are gaining importance. At the same time, the development of their software is increasing its complexity, having to deal with quality, cost, and time‐to‐market issues among others. With stringent quality requirements such as performance, early verification and validation become critical in these systems. In this regard, advanced development paradigms such as model‐driven engineering and software product line engineering bring considerable benefits to the development and validation of embedded system software. However, these benefits come at the cost of increasing process complexity. This work presents a process based on UML and MARTE for the analysis of embedded model‐driven product lines. It specifies the tasks, the involved roles, and the workproducts that form the process and how it is integrated in the more general development process. Existing tools that support the tasks to be performed in the process are also described. A classification of such tools and a study of traceability among them are provided, allowing engineering teams to choose the most adequate chain of tools to support the process. Copyright © 2012 John Wiley &amp; Sons, Ltd.Embedded systems are becoming ubiquitous, and software running on them is fundamental for them to function. At the same time, the development of their software is increasing its complexity, dealing with cost, time to market, and quality, among others. With stringent quality requirements such as performance, early verification and validation of their software is essential for assuring software quality. In this setting, this work presents a process that supports model‐based analysis of an embedded software product line to assure temporal requirements.  


image
image},
journal = {J. Softw. Evol. Process},
month = apr,
pages = {419–433},
numpages = {14},
keywords = {performance, quality attributes, model‐driven development, model‐based analysis process, software product line}
}

@inproceedings{10.1145/2364412.2364414,
author = {Derakhshanmanesh, Mahdi and Fox, Joachim and Ebert, J\"{u}rgen},
title = {Adopting feature-centric reuse of requirements assets: an industrial experience report},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364414},
doi = {10.1145/2364412.2364414},
abstract = {In this paper, we share practical experiences from an ongoing effort towards adopting a feature-centric method that enhances reuse of requirements at TRW Automotive's slip control system department (based in Koblenz, Germany). After introducing identified challenges in detail, key solution factors and a technical reuse concept for managing and deriving product-specific requirements are presented. Then, we demonstrate one way of implementing this solution approach based on industry-standard tools. In addition, identified pitfalls and lessons learned are discussed.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {2–9},
numpages = {8},
keywords = {software product lines, reuse, requirements, features},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2019136.2019178,
author = {Brataas, Gunnar and Jiang, Shanshan and Reichle, Roland and Geihs, Kurt},
title = {Performance property prediction supporting variability for adaptive mobile systems},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019178},
doi = {10.1145/2019136.2019178},
abstract = {A performance property prediction (PPP) method for component-based self-adaptive applications is presented. Such performance properties are required by an adaptation middleware for reasoning about adaptation activities. Our PPP method is based on the Structure and Performance (SP) framework, a conceptually simple, yet powerful performance modelling framework based on matrices. The main contribution of this paper are the integration of SP-based PPP into a comprehensive model- and variability-based adaptation framework for context-aware mobile applications. A meta model for the SP method is described. The framework is demonstrated using a practical example.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {37},
numpages = {8},
keywords = {mobile systems, autonomic computing},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2647908.2655957,
author = {Murguzur, Aitor and Capilla, Rafael and Trujillo, Salvador and Ortiz, \'{O}scar and Lopez-Herrejon, Roberto E.},
title = {Context variability modeling for runtime configuration of service-based dynamic software product lines},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655957},
doi = {10.1145/2647908.2655957},
abstract = {In emerging domains such as Cloud-based Industrial Control Systems (ICSs) and SCADA systems where data-intensive and high performance computing are needed, a higher degree of flexibility is being demanded to meet new stakeholder requirements, context changes and intrinsic complexity. In this light, Dynamic Software Product Lines (DSPLs) provide a way to build self-managing systems exploiting traditional product line engineering concepts at runtime. Although context-awareness is widely perceived to be a first-class concern in such runtime variability mechanisms, existing approaches do not provide the necessary level of formalization to model and enact context variability for DSPLs. This is crucial for operational analytics processes since variant configuration could differ from context to context depending on diverse data values linked to context features and cross-tree constraints in a feature model. In this paper, we propose a context variability modeling approach, demonstrate its applicability and usability via a wind farm use case, and present the fundamental building blocks of a framework for enabling context variability in service-based DSPLs which provide Workflow as a Service (WFaaS).},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {2–9},
numpages = {8},
keywords = {process variability, data-aware systems, context variability, context awareness},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2647908.2655973,
author = {Cordy, Maxime and Willemart, Marco and Dawagne, Bruno and Heymans, Patrick and Schobbens, Pierre-Yves},
title = {An extensible platform for product-line behavioural analysis},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655973},
doi = {10.1145/2647908.2655973},
abstract = {Software Product-Line (SPL) model checking has reached an adequate level of efficiency and expressiveness to be applied on real-world cases. Yet a major challenge remains: model checkers should consist of black-box tools that do not require in-depth expertise to be used. In particular, it is essential to provide engineers with easy-to-learn languages to model both the behaviour of their SPL and the properties to check. In this paper, we propose a framework to build customized product-line verifiers modularly. Our extensible architecture allows one to plug new modelling languages or verifications algorithms without modifying other parts of it. It also provides means of representing and reasoning on variability that can facilitate the development of other SPL quality assurance techniques. We illustrate the benefits of our approach by detailing how we created a new domain-specific SPL modelling language and linked it to our tool.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {102–109},
numpages = {8},
keywords = {tool, software product lines, model checking, features},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2019136.2019159,
author = {Otsuka, Jun and Kawarabata, Kouichi and Iwasaki, Takashi and Uchiba, Makoto and Nakanishi, Tsuneo and Hisazumi, Kenji},
title = {Small inexpensive core asset construction for large gainful product line development: developing a communication system firmware product line},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019159},
doi = {10.1145/2019136.2019159},
abstract = {Product line development of communication system firmware with more than 2,000 features was performed in a large-scale project that involved more than 300 engineers (at a maximum) across four distributed sites. However, since intense demands to reduce development costs and time made it prohibitive to construct core assets for all those identified features, the project screened a limited number of the features, for which core assets were constructed, and then performed partial application of product line engineering. Nevertheless, when compared with previously engineered derivative developments, when the second product of the product line was released, it was clear that the project had achieved significant improvements in quality, as well as reductions in development costs and time requirements. Automatic code generation also contributed to those improvements.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {20},
numpages = {5},
keywords = {product line, feature modeling, core assets, case study},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2019136.2019150,
author = {Serajzadeh, Hadi and Shams, Fereidoon},
title = {The application of swarm intelligence in service-oriented product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019150},
doi = {10.1145/2019136.2019150},
abstract = {Changing markets and environments has made the ability to rapidly adapt to these changes a necessity in software systems. However the costs of changing and adapting systems to new requirements still remains an unsolved issue. In this context service-oriented software product lines were introduced with the aim to combine the reusability of software product line with the flexibility of service-oriented architecture. Although this approach helps build flexible software systems with high levels of reuse, certain issues are raised. The main issue is the complexity that a service-oriented product line will face. Developing systems from internal and external assets, taking into consideration the variety and number of these assets, can cause problems in deciding which asset is best suited for the system. To help solve these issues we propose the use of approaches based on artificial intelligence. In this paper we show how swarm intelligence can be used in service-oriented product lines to reduce complexity and find optimal solutions for the development of software systems. We also present an example of the application of swarm intelligence in finding the optimal product for a service-oriented product line.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {12},
numpages = {7},
keywords = {swarm intelligence, service-oriented product line, optimization},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2648511.2648524,
author = {Quinton, Cl\'{e}ment and Pleuss, Andreas and Berre, Daniel Le and Duchien, Laurence and Botterweck, Goetz},
title = {Consistency checking for the evolution of cardinality-based feature models},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648524},
doi = {10.1145/2648511.2648524},
abstract = {Feature-models (fms) are a widely used approach to specify the commonalities and variability in variable systems and software product lines. Various works have addressed edits to fms for fm evolution and tool support to ensure consistency of fms. An important extension to fms are feature cardinalities and related constraints, as extensively used e.g., when modeling variability of cloud computing environments. Since cardinality-based fms pose additional complexity, additional support for evolution and consistency checking with respect to feature cardinalities would be desirable, but has not been addressed yet. In this paper, we discuss common cardinality-based fm edits and resulting inconsistencies based on experiences with fms in cloud domain. We introduce tool-support for automated inconsistency detection and explanation based on an off-the-shelf solver. We demonstrate the feasibility of the approach by an empirical evaluation showing the performance of the tool.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {122–131},
numpages = {10},
keywords = {feature model, edit, consistency, cardinality},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5555/2663370.2663379,
author = {Remmel, Hanna and Paech, Barbara and Engwer, Christian and Bastian, Peter},
title = {Design and rationale of a quality assurance process for a scientific framework},
year = {2013},
isbn = {9781467362610},
publisher = {IEEE Press},
abstract = {The testing of scientific frameworks is a challenging task. The special characteristics of scientific software e.g. missing test oracle, the need for high performance parallel computing, and high priority of non-functional requirements, need to be accounted for as well as the large variability in a framework. In our previous research, we have shown how software product line engineering can be applied to support the testing of scientific frameworks. We developed a process for handling the variability of a framework using software product line (SPL) variability modeling. From the variability models, we derive test applications and use them for system tests for the framework. In this paper we examine the overall quality assurance for a scientific framework. First, we propose a SPL test strategy for scientific frameworks called Variable test Application strategy for Frameworks (VAF). This test strategy tests both, commonality and variability, of the framework and supports the framework's users in testing their applications by creating reusable test artifacts. We operationalize VAF with test activities that are combined with other quality assurance activities to form the design of a quality assurance process for scientific frameworks. We introduce a list of special characteristics for scientific software that we use as rationale for the design of this process.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering for Computational Science and Engineering},
pages = {58–67},
numpages = {10},
keywords = {test strategy, software product line engineering, scientific software development, quality assurance process},
location = {San Francisco, California},
series = {SE-CSE '13}
}

@inproceedings{10.1145/2362536.2362569,
author = {Patzke, Thomas and Becker, Martin and Steffens, Michaela and Sierszecki, Krzysztof and Savolainen, Juha Erik and Fogdal, Thomas},
title = {Identifying improvement potential in evolving product line infrastructures: 3 case studies},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362569},
doi = {10.1145/2362536.2362569},
abstract = {Successful software products evolve continuously to meet the changing stakeholder requirements. For software product lines, an additional challenge is that variabilities, characteristics that vary among products, change as well over time. That challenge must be carefully tackled during the evolution of the product line infrastructure. This is a significant problem for many software development organizations, as practical guidelines on how to evolve core assets, and especially source code, are missing.This paper investigates how to achieve "good enough" variability management during the evolution of variation in software design and implementation assets. As a first contribution, we present a customizable goal-based approach which helps to identify improvement potential in existing core assets to ease evolution. To find concrete ways to improve the product line infrastructure, we list the typical symptoms of variability "code smells" and show how to refine them to root causes, questions, and finally to metrics that can be extracted from large code bases.As a second main contribution, we show how this method was applied to evaluate the reuse quality of three industrial embedded systems. These systems are implemented in C or C++ and use Conditional Compilation as the main variability mechanism. We also introduce the analysis and refactoring tool set that was used in the case studies and discuss the lessons learnt.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {239–248},
numpages = {10},
keywords = {variability code smells, product line code evolution, industrial case study, goal-based product line measurement, PuLSE-E},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/978-3-319-23781-7_27,
author = {Bouarar, Selma and Jean, St\'{e}phane and Siegmund, Norbert},
title = {SPL Driven Approach for Variability in Database Design},
year = {2015},
isbn = {9783319237800},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-23781-7_27},
doi = {10.1007/978-3-319-23781-7_27},
abstract = {The evolution of computer technology has strongly impacted the database design. No phase was spared: several conceptual formalisms e.g. ER, UML, ontological, various logical models e.g. relational, object, key-value, a wide panoply of physical optimization structures and deployment platforms have been proposed. As a result, the database design process has become more complex involving more tasks and even more actors as database architect or analyst. Getting inspired from software engineering in dealing with variable similar systems, we propose a methodological framework for a variability-aware design of databases, whereby this latter is henceforth devised as a Software Product Line. Doing so guarantees a high reuse, automation, and customizability in generating ready-to-be implemented databases. We also propose a solution to help users make a suitable choice among the wide panoply. Finally, a case study is presented.},
booktitle = {Proceedings of the 5th International Conference on Model and Data Engineering - Volume 9344},
pages = {332–342},
numpages = {11},
keywords = {Variability, Software Product Line, Database design},
location = {Rhodes, Greece},
series = {MEDI 2015}
}

@inproceedings{10.1145/2791060.2791082,
author = {Hotz, Lothar and Wang, Yibo and Riebisch, Matthias and G\"{o}tz, Olaf and Lackhove, Josef},
title = {Evaluation across multiple views for variable automation systems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791082},
doi = {10.1145/2791060.2791082},
abstract = {Automation systems in industry are often software-intensive systems consisting of software and hardware components. During their development several engineers of different disciplines are involved, such as mechanical, electrical and software engineering. Each engineer focuses on specific system aspects to be developed. To enable an efficient development, product lines especially with feature models for variability modeling are promising technologies. In order to reduce the complexity of both feature models and development process, views on feature models can be applied. The use of views for filtering purposes constitutes an established method. However, views also enable further options missing in current approaches, such as evaluations regarding requirements, including non-functional ones. This paper presents an approach for evaluation across multiple views to enable collaborative development for developers who focus on different system aspects. We validate our approach by applying it in an industrial project for the planning of flying saws.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {311–315},
numpages = {5},
keywords = {product lines, multi-criteria evaluation, feature model, consistency check, configuration, automation systems},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s10664-014-9359-z,
author = {Myll\"{a}rniemi, Varvana and Savolainen, Juha and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi},
title = {Performance variability in software product lines: proposing theories from a case study},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9359-z},
doi = {10.1007/s10664-014-9359-z},
abstract = {In the software product line research, product variants typically differ by their functionality and quality attributes are not purposefully varied. The goal is to study purposeful performance variability in software product lines, in particular, the motivation to vary performance, and the strategy for realizing performance variability in the product line architecture. The research method was a theory-building case study that was augmented with a systematic literature review. The case was a mobile network base station product line with capacity variability. The data collection, analysis and theorizing were conducted in several stages: the initial case study results were augmented with accounts from the literature. We constructed three theoretical models to explain and characterize performance variability in software product lines: the models aim to be generalizable beyond the single case. The results describe capacity variability in a base station product line. Thereafter, theoretical models of performance variability in software product lines in general are proposed. Performance variability is motivated by customer needs and characteristics, by trade-offs and by varying operating environment constraints. Performance variability can be realized by hardware or software means; moreover, the software can either realize performance differences in an emergent way through impacts from other variability or by utilizing purposeful varying design tactics. The results point out two differences compared with the prevailing literature. Firstly, when the customer needs and characteristics enable price differentiation, performance may be varied even with no trade-offs or production cost differences involved. Secondly, due to the dominance of feature modeling, the literature focuses on the impact management realization. However, performance variability can be realized through purposeful design tactics to downgrade the available software resources and by having more efficient hardware.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1623–1669},
numpages = {47},
keywords = {Variability, Software product line, Software architecture, Case study}
}

@inproceedings{10.1145/2491627.2491651,
author = {Nakagawa, Elisa Yumi and Becker, Martin and Maldonado, Jos\'{e} Carlos},
title = {Towards a process to design product line architectures based on reference architectures},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491651},
doi = {10.1145/2491627.2491651},
abstract = {Software Product Line (SPL) has arisen as an approach for developing a family of software-intensive systems at lower costs, within shorter time, and with higher quality. In particular, SPL is supported by a product line architecture (sometimes also referred to as reference architecture) that captures the architectures of a product family. From another perspective, a special type of architecture that contains knowledge about a specific domain has been increasingly investigated, resulting in the research area of Reference Architecture. In spite of the positive impact of this type of architecture on reuse and productivity, the use of the knowledge contained in existing reference architectures in order to develop SPL has not been widely explored yet. The main contribution of this paper is to present a process, named ProSA-RA2PLA, that systematizes the use of reference architectures for building product line architectures. To illustrate the application of this process, we have built a product line architecture for an SPL of software testing tools using a reference architecture of that domain. Based on initial results, we have observed that benefits can be achieved, mainly regarding improvement in reuse and productivity to develop SPL.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {157–161},
numpages = {5},
keywords = {reference architecture, knowledge sharing},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2791060.2791096,
author = {F\'{e}derle, \'{E}dipo Luis and do Nascimento Ferreira, Thiago and Colanzi, Thelma Elita and Vergilio, Silvia Regina},
title = {OPLA-tool: a support tool for search-based product line architecture design},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791096},
doi = {10.1145/2791060.2791096},
abstract = {The Product Line Architecture (PLA) design is a complex task, influenced by many factors such as feature modularization and PLA extensibility, which are usually evaluated according to different metrics. Hence, the PLA design is an optimization problem and problems like that have been successfully solved in the Search-Based Software Engineering (SBSE) area, by using metaheuristics such as Genetic Algorithm. Considering this fact, this paper introduces a tool named OPLA-Tool, conceived to provide computer support to a search-based approach for PLA design. OPLA-Tool implements all the steps necessary to use multi-objective optimization algorithms, including PLA transformations and visualization through a graphical interface. OPLA-Tool receives as input a PLA at the class diagram level, and produces a set of good alternative diagrams in terms of cohesion, feature modularization and reduction of crosscutting concerns.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {370–373},
numpages = {4},
keywords = {search-based software engineering, product line architecture design, multi-objective evolutionary algorithms},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s00766-014-0203-1,
author = {D\'{\i}az, Jessica and P\'{e}rez, Jennifer and Garbajosa, Juan},
title = {A model for tracing variability from features to product-line architectures: a case study in smart grids},
year = {2015},
issue_date = {September 2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-014-0203-1},
doi = {10.1007/s00766-014-0203-1},
abstract = {In current software systems with highly volatile requirements, traceability plays a key role to maintain the consistency between requirements and code. Traceability between artifacts involved in the development of software product line (SPL) is still more critical because it is necessary to guarantee that the selection of variants that realize the different SPL products meet the requirements. Current SPL traceability mechanisms trace from variability in features to variations in the configuration of product-line architecture (PLA) in terms of adding and removing components. However, it is not always possible to materialize the variable features of a SPL through adding or removing components, since sometimes they are materialized inside components, i.e., in part of their functionality: a class, a service, and/or an interface. Additionally, variations that happen inside components may crosscut several components of architecture. These kinds of variations are still challenging and their traceability is not currently well supported. Therefore, it is not possible to guarantee that those SPL products with these kinds of variations meet the requirements. This paper presents a solution for tracing variability from features to PLA by taking these kinds of variations into account. This solution is based on models and traceability between models in order to automate SPL configuration by selecting the variants and realizing the product application. The FPLA modeling framework supports this solution which has been deployed in a software factory. Validation has consisted in putting the solution into practice to develop a product line of power metering management applications for smart grids.},
journal = {Requir. Eng.},
month = sep,
pages = {323–343},
numpages = {21},
keywords = {Variability, Traceability modeling, Software product line engineering, Product-line architecture}
}

@inproceedings{10.1145/2648511.2648525,
author = {Stein, Jacob and Nunes, Ingrid and Cirilo, Elder},
title = {Preference-based feature model configuration with multiple stakeholders},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648525},
doi = {10.1145/2648511.2648525},
abstract = {Feature model configuration is known to be a hard, error-prone and time-consuming activity. This activity gets even more complicated when it involves multiple stakeholders in the configuration process. Research work has proposed approaches to aid multi-stakeholder feature model configuration, but they rely on systematic processes that constraint decisions of some of the stakeholders. In this paper, we propose a novel approach to improve the multi-stakeholder configuration process, considering stakeholders' preferences expressed through both hard and soft constraints. Based on such preferences, we recommend different product configurations using different strategies from the social choice theory. We conducted an empirical study to evaluate the effectiveness of our strategies with respect to individual stakeholder satisfaction and fairness among all stakeholders. Results indicate that particular strategies perform best with respect to these aspects.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {132–141},
numpages = {10},
keywords = {social choice, preferences, feature model configuration},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.5555/1753235.1753242,
author = {Fernandez-Amoros, David and Gil, Ruben Heradio and Somolinos, Jose Cerrada},
title = {Inferring information from feature diagrams to product line economic models},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Existing economic models support the estimation of the costs and benefits of developing and evolving a Software Product Line (SPL) as compared to undertaking traditional software development approaches. In addition, Feature Diagrams (FDs) are a valuable tool to scope the domain of a SPL. This paper proposes an algorithm to calculate, from a FD, the following information for economic models: the total number of products of a SPL, the SPL homogeneity and the commonality of the SPL requirements. The algorithm running time belongs to the complexity class O(f42c). In contrast to related work, the algorithm is free of dependencies on off-the-self tools and is generally specified for an abstract FD notation, that works as a pivot language for most of the available notations for feature modeling.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {41–50},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1016/j.jss.2011.04.020,
author = {Hanssen, Geir K.},
title = {A longitudinal case study of an emerging software ecosystem: Implications for practice and theory},
year = {2012},
issue_date = {July, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {85},
number = {7},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.04.020},
doi = {10.1016/j.jss.2011.04.020},
abstract = {Software ecosystems is an emerging trend within the software industry, implying a shift from closed organizations and processes towards open structures, where actors external to the software development organization are becoming increasingly involved in development. This forms an ecosystem of organizations that are related through the shared interest in a software product, leading to new opportunities and new challenges to the industry and its organizational environment. To understand why and how this change occurs, we have followed the development of a software product line organization for a period of approximately five years. We have studied their change from a waterfall-like approach, via agile software product line engineering, towards an emerging software ecosystem. We discuss implications for practice, and propose a nascent theory on software ecosystems. We conclude that the observed change has led to an increase in collaboration across (previously closed) organizational borders, and to the development of a shared value consisting of two components: the technology (the product line, as an extensible platform), and the business domain it supports. Opening up both the technical interface of the product and the organizational interfaces are key enablers of such a change.},
journal = {J. Syst. Softw.},
month = jul,
pages = {1455–1466},
numpages = {12},
keywords = {Software product line engineering, Software ecosystems, Longitudinal case study, Agile software development}
}

@inproceedings{10.1145/2362536.2362573,
author = {Bartholdt, J\"{o}rg and Becker, Detlef},
title = {Scope extension of an existing product line},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362573},
doi = {10.1145/2362536.2362573},
abstract = {At the beginning, creating a product line needs a well defined and narrow scope to meet short time to market demands. When established, there is a tendency to broaden the scope and to cover more domains and products.We have undergone a scope extension of our medical diagnostic platform that was implemented while the platform and (existing) products were evolving. In this paper, we list best practices for the migration process and how to come to a sustainable solution without cannibalizing the existing platform and products.In particular, we describe our way of identification beneficial sub-domains using C/V analysis and give an example scenario with alignments in order to increase commonality. We explain the maturity considerations for deciding on reuse of existing implementations and a carve-out strategy to split existing assets into common modules and product-line specific extensions. Furthermore, we describe our best practices for making the scope extension sustainable in a long term, using various types of governance means. We briefly complement these experiences with further insights gained during execution of this endeavor.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {275–282},
numpages = {8},
keywords = {scope extension, hierarchical product-line, governance, C/V analysis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s10270-011-0220-1,
author = {Hubaux, Arnaud and Heymans, Patrick and Schobbens, Pierre-Yves and Deridder, Dirk and Abbasi, Ebrahim Khalil},
title = {Supporting multiple perspectives in feature-based configuration},
year = {2013},
issue_date = {July      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-011-0220-1},
doi = {10.1007/s10270-011-0220-1},
abstract = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {641–663},
numpages = {23},
keywords = {Software product line engineering, Separation of concerns, Multi-view, Feature-based configuration, Feature diagram}
}

@inproceedings{10.1145/3409334.3452048,
author = {Shatnawi, Hazim and Cunningham, H. Conrad},
title = {Encoding feature models using mainstream JSON technologies},
year = {2021},
isbn = {9781450380683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409334.3452048},
doi = {10.1145/3409334.3452048},
abstract = {Feature modeling is a process for identifying the common and variable parts of a software product line and recording them in a tree-structured feature model. However, feature models can be difficult for mainstream developers to specify and maintain because most tools rely on specialized theories, notations, or technologies. To address this issue, we propose a design that uses mainstream JSON-related technologies to encode and manipulate feature models and then uses the models to generate Web forms for product configuration. This JSON-based design can form part of a comprehensive, interactive environment that enables mainstream developers to specify, store, update, and exchange feature models and use them to configure members of product families.},
booktitle = {Proceedings of the 2021 ACM Southeast Conference},
pages = {146–153},
numpages = {8},
keywords = {JSON, MongoDB, feature, feature diagram, feature model, software engineering, software product line, software reuse},
location = {Virtual Event, USA},
series = {ACMSE '21}
}

@inproceedings{10.1145/3077286.3077325,
author = {Shatnawi, Hazim and Cunningham, H. Conrad},
title = {Mapping SPL Feature Models to a Relational Database},
year = {2017},
isbn = {9781450350242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077286.3077325},
doi = {10.1145/3077286.3077325},
abstract = {Building a software product line (SPL) is a systematic strategy for reusing software within a family of related systems from some application domain. To define an SPL, domain analysts must identify the common and variable aspects of systems in the family and capture this information so that it can be used effectively to construct specific products. Often analysts record this information using a feature model expressed visually as a feature diagram. The overall goal of this project is to enable wider use of SPLs by identifying relevant concepts, defining systematic methods, and developing practical tools that leverage familiar web programming technologies. This paper presents a novel approach to specification of feature models: capture the details using automatically generated user interfaces, encode the models in a relational database, and then validate the models and construct specific products using SQL.},
booktitle = {Proceedings of the 2017 ACM Southeast Conference},
pages = {42–49},
numpages = {8},
keywords = {Software product line, domain analysis, domain design, feature model, feature selection, relational database},
location = {Kennesaw, GA, USA},
series = {ACMSE '17}
}

@inproceedings{10.1145/2648511.2648530,
author = {Th\"{u}m, Thomas and Meinicke, Jens and Benduhn, Fabian and Hentschel, Martin and von Rhein, Alexander and Saake, Gunter},
title = {Potential synergies of theorem proving and model checking for software product lines},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648530},
doi = {10.1145/2648511.2648530},
abstract = {The verification of software product lines is an active research area. A challenge is to efficiently verify similar products without the need to generate and verify them individually. As solution, researchers suggest family-based verification approaches, which either transform compile-time into runtime variability or make verification tools variability-aware. Existing approaches either focus on theorem proving, model checking, or other verification techniques. For the first time, we combine theorem proving and model checking to evaluate their synergies for product-line verification. We provide tool support by connecting five existing tools, namely FeatureIDE and FeatureHouse for product-line development, as well as KeY, JPF, and OpenJML for verification of Java programs. In an experiment, we found the synergy of improved effectiveness and efficiency, especially for product lines with few defects. Further, we experienced that model checking and theorem proving are more efficient and effective if the product line contains more defects.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {177–186},
numpages = {10},
keywords = {variability encoding, theorem proving, software product lines, model checking, feature-oriented contracts, feature-based specification, family-based verification, design by contract},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2491627.2491645,
author = {Zhang, Bo and Becker, Martin and Patzke, Thomas and Sierszecki, Krzysztof and Savolainen, Juha Erik},
title = {Variability evolution and erosion in industrial product lines: a case study},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491645},
doi = {10.1145/2491627.2491645},
abstract = {Successful software products evolve continuously to meet the changing stakeholder requirements. For software product lines, modifying variability is an additional challenge that must be carefully tackled during the evolution of the product line. This bears considerable challenges for industry as understanding on how variability realizations advance over time is not trivial. Moreover, it may lead to an erosion of variability, which needs an investigation of techniques on how to identify the variability erosion in practice, especially in the source code. To address various erosion symptoms, we have investigated the evolution of a large-scale industrial product line over a period of four years. Along improvement goals, we have researched a set of appropriate metrics and measurement approaches in a goal-oriented way, applied them in this case study with tool support, and interpreted the results including identified erosion symptoms.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {168–177},
numpages = {10},
keywords = {variability erosion, static code analysis, product line evolution, industrial case study},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2362536.2362556,
author = {Nunes, Camila and Garcia, Alessandro and Lucena, Carlos and Lee, Jaejoon},
title = {History-sensitive heuristics for recovery of features in code of evolving program families},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362556},
doi = {10.1145/2362536.2362556},
abstract = {A program family might degenerate due to unplanned changes in its implementation, thus hindering the maintenance of family members. This degeneration is often induced by feature code that is changed individually in each member without considering other family members. Hence, as a program family evolves over time, it might no longer be possible to distinguish between common and variable features. One of the imminent activities to address this problem is the history-sensitive recovery of program family's features in the code. This recovery process encompasses the analysis of the evolution history of each family member in order to classify the implementation elements according to their variability nature. In this context, this paper proposes history-sensitive heuristics for the recovery of features in code of degenerate program families. Once the analysis of the family history is carried out, the feature elements are structured as Java project packages; they are intended to separate those elements in terms of their variability degree. The proposed heuristics are supported by a prototype tool called RecFeat. We evaluated the accuracy of the heuristics in the context of 33 versions of 2 industry program families. They presented encouraging results regarding recall measures that ranged from 85% to 100%; whereas the precision measures ranged from 71% to 99%.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {136–145},
numpages = {10},
keywords = {software evolution, program families, heuristics, feature recovery},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791110,
author = {McVoy, Larry},
title = {Preliminary product line support in BitKeeper},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791110},
doi = {10.1145/2791060.2791110},
abstract = {One of the challenges of implementing a product line process is finding the appropriate tools for automation. One of our larger customers was implementing a product line process by-hand in a labor intensive and fragile way. We collaborated with them to evolve our distributed version control system, BitKeeper, into a tool that could handle their performance and product line requirements. The resulting product line generated several complex CPUs (around a billion transistors each).In this paper, we describe their by-hand process for producing different variations of a computer processor; we'll provide some background on the distributed version control system they were using; we'll describe the architectural changes implemented in BitKeeper for supporting product line work flows; we'll describe some of the changes we did to increase performance and provide some benchmark results comparing BitKeeper to Git, and we'll describe the work flow resulting from using the new architecture to replace their by-hand process.In the final section we'll discuss the current limitations of the existing tool, and describe how we plan on evolving it to overcome those limitations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {245–252},
numpages = {8},
keywords = {version control, software product lines, configuration management, code reuse},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3377930.3390215,
author = {Silva, Diego Fernandes da and Okada, Luiz Fernando and Colanzi, Thelma Elita and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Enhancing search-based product line design with crossover operators},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377930.3390215},
doi = {10.1145/3377930.3390215},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line. PLA designing has been formulated as a multi-objective optimization problem and successfully solved by a state-of-the-art search-based approach. However, the majority of empirical studies optimize PLA designs without applying one of the fundamental genetic operators: the crossover. An operator for PLA design, named Feature-driven Crossover, was proposed in a previous study. In spite of the promising results, this operator occasionally generated incomplete solutions. To overcome these limitations, this paper aims to enhance the search-based PLA design optimization by improving the Feature-driven Crossover and introducing a novel crossover operator specific for PLA design. The proposed operators were evaluated in two well-studied PLA designs, using three experimental configurations of NSGA-II in comparison with a baseline that uses only mutation operators. Empirical results show the usefulness and efficiency of the presented operators on reaching consistent solutions. We also observed that the two operators complement each other, leading to PLA design solutions with better feature modularization than the baseline experiment.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {1250–1258},
numpages = {9},
keywords = {software product line, software architecture, recombination operators, multi-objective evolutionary algorithm},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1145/2364412.2364449,
author = {Helvensteijn, Michiel},
title = {Abstract delta modeling: my research plan},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364449},
doi = {10.1145/2364412.2364449},
abstract = {Software product lines are sets of software programs with well defined commonalities and variabilities that are distinguished by which features they support. There is need of a way to organize the underlying code to clearly link features on the feature modeling level to code artifacts on the implementation level, without code duplication or overspecification, so we can support automated product derivation. Existing approaches are still lacking in one way or another. My answer to this problem is delta modeling. My thesis will approach delta modeling from an abstract algebraic perspective called Abstract Delta Modeling. It will give a thorough formal treatment of the subject and extend it in several directions. A workflow for building a product line from scratch, a way to model dynamic product lines as well as plenty of practical examples and case studies.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {217–224},
numpages = {8},
keywords = {type systems, product lines, modal logic, dynamic product lines, development workflow, delta modeling, PhD thesis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/2666064.2666069,
author = {Quinton, Cl\'{e}ment and Duchien, Laurence and Heymans, Patrick and Mouton, St\'{e}phane and Charlier, Etienne},
title = {Using feature modelling and automations to select among cloud solutions},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {Cloud computing is a major trend in distributed computing environments. Resources are accessed on demand by customers and are delivered as services by cloud providers in a pay-per-use model. Companies provide their applications as services and rely on cloud providers to provision, host and manage such applications on top of their infrastructure. However, the wide range of cloud solutions and the lack of knowledge in this domain is a real problem for companies when facing the cloud solution choice. In this paper, we propose to use Software Product Line Engineering (SPLE) and Feature Model (FM) configuration to develop a decision-supporting tool. Using such modelling techniques and automations, this tool takes into consideration the application technical requirements as well as the user quality requirements to provide an accurate result among cloud solutions that best fits both requirements.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {17–20},
numpages = {4},
keywords = {software product line engineering, separation of concerns, feature modelling, cloud computing},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@article{10.1016/j.procs.2019.12.173,
author = {Chemingui, Houssem and Gam, Ines and Mazo, Ra\'{u}l and Salinesi, Camille and Ghezala, Henda Ben},
title = {Product Line Configuration Meets Process Mining},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {164},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.12.173},
doi = {10.1016/j.procs.2019.12.173},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {199–210},
numpages = {12},
keywords = {configuration difficulties, enhancing, process mining, configuration process, Product line engineering}
}

@inproceedings{10.1145/2364412.2364431,
author = {Kumaki, Kentaro and Tsuchiya, Ryosuke and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Supporting commonality and variability analysis of requirements and structural models},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364431},
doi = {10.1145/2364412.2364431},
abstract = {The commonality and variability analysis of legacy software assets requires high costs in terms of personnel and time in extractive core asset development. We propose a technique for supporting the commonality and variability analysis, targeting the requirements and structural models of legacy software assets for the development of a feature diagram and a product line architecture (PLA). We analyze the commonality and variability of the sentences as requirements and classes as structural models by calculating similarities based on a vector space model. By using our technique, the costs in terms of personnel and time required for the analysis of legacy software assets can be reduced.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {115–118},
numpages = {4},
keywords = {traceability, product line architecture, feature diagram},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791119,
author = {Dimovski, Aleksandar S. and Al-Sibahi, Ahmad Salim and Brabrand, Claus and W\k{a}sowski, Andrzej},
title = {Family-based model checking using off-the-shelf model checkers: extended abstract},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791119},
doi = {10.1145/2791060.2791119},
abstract = {Model checking provides a convenient way to check whether a given software system is correct with respect to a set of relevant semantic properties. To use a model checker like SPIN [5], the software system must be modelled as a transition system (TS). Afterwards, the model checker can check the correctness of the translated TS by exhaustively exploring all possible transitions.For families of software systems Classen et al. [1] present a lifted model checker SNIP, where each family is modelled as a Featured TS [2] that has transitions guarded by feature expressions. SNIP is highly specialized and uses heuristics to avoid na\"{\i}vely iterating through all possible variations; however, the number of configurations is still exponential in size and thus the model checker can only feasibly handle systems of a limited size.We adapt our previous work on applying variability abstraction to lifted data-flow analysis [3] to the setting of lifted model checking. We present a calculus of variability abstractions that trade precision for speed while preserving correctness [4]. The abstractions work symbiotically with the lifted model checker SNIP, but can also work with the classical and efficient off-the-shelf model checker SPIN without requiring any knowledge of variability. We prove semantically how each abstraction operation in the calculus forms a Galois collection, and therefore is suitable to use in abstract interpretation of Featured TS. Furthermore, we present an equivalent lightweight syntactic transformation tool that works directly on the input text files and does not require explicitly constructing the corresponding Featured TS in memory.Our results show that there are orders of magnitudes to be gained in performance compared to performing lifted analysis alone; we show how our tool scales better than the existing tools and makes analysing some previously infeasible models feasible. Furthermore, we also show that many models could be verified swiftly using the abstracted analysis without requiring all of the precision that a concrete analysis provides.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {397},
numpages = {1},
keywords = {software product lines, model checking, abstract interpretation},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1145/3361146,
author = {Hierons, Robert M. and Li, Miqing and Liu, Xiaohui and Parejo, Jose Antonio and Segura, Sergio and Yao, Xin},
title = {Many-Objective Test Suite Generation for Software Product Lines},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3361146},
doi = {10.1145/3361146},
abstract = {A Software Product Line (SPL) is a set of products built from a number of features, the set of valid products being defined by a feature model. Typically, it does not make sense to test all products defined by an SPL and one instead chooses a set of products to test (test selection) and, ideally, derives a good order in which to test them (test prioritisation). Since one cannot know in advance which products will reveal faults, test selection and prioritisation are normally based on objective functions that are known to relate to likely effectiveness or cost. This article introduces a new technique, the grid-based evolution strategy (GrES), which considers several objective functions that assess a selection or prioritisation and aims to optimise on all of these. The problem is thus a many-objective optimisation problem. We use a new approach, in which all of the objective functions are considered but one (pairwise coverage) is seen as the most important. We also derive a novel evolution strategy based on domain knowledge. The results of the evaluation, on randomly generated and realistic feature models, were promising, with GrES outperforming previously proposed techniques and a range of many-objective optimisation algorithms.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {2},
numpages = {46},
keywords = {test selection, test prioritisation, multi-objective optimisation, Software product line}
}

@inproceedings{10.1145/2791060.2791073,
author = {Lachmann, Remo and Lity, Sascha and Lischke, Sabrina and Beddig, Simon and Schulze, Sandro and Schaefer, Ina},
title = {Delta-oriented test case prioritization for integration testing of software product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791073},
doi = {10.1145/2791060.2791073},
abstract = {Software product lines have potential to allow for mass customization of products. Unfortunately, the resulting, vast amount of possible product variants with commonalities and differences leads to new challenges in software testing. Ideally, every product variant should be tested, especially in safety-critical systems. However, due to the exponentially increasing number of product variants, testing every product variant is not feasible. Thus, new concepts and techniques are required to provide efficient SPL testing strategies exploiting the commonalities of software artifacts between product variants to reduce redundancy in testing. In this paper, we present an efficient integration testing approach for SPLs based on delta modeling. We focus on test case prioritization. As a result, only the most important test cases for every product variant are tested, reducing the number of executed test cases significantly, as testing can stop at any given point because of resource constraints while ensuring that the most important test cases have been covered. We present the general concept and our evaluation results. The results show a measurable reduction of executed test cases compared to single-software testing approaches.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {81–90},
numpages = {10},
keywords = {test case prioritization, regression testing, delta-oriented software product lines, architecture-based testing},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Quality assurance, Machine learning, Software testing, Software variability, Configurable system, Software product line}
}

@inproceedings{10.1145/2364412.2364434,
author = {Helvensteijn, Michiel},
title = {Dynamic delta modeling},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364434},
doi = {10.1145/2364412.2364434},
abstract = {Abstract Delta Modeling (ADM) offers an algebraic description of how a (software) product line may be built so that every product can be automatically derived by structured reuse of code. In traditional application engineering a single valid feature configuration is chosen, which does not change during the lifetime of the product. However, there are many useful applications for product lines that change their configuration at run time. We present a new technique for generating efficient dynamic product lines from their static counterparts. We use Mealy machines for their dynamic reconfiguration. Furthermore, we posit that monitoring some features will be more expensive than monitoring others, and present techniques for minimizing the cost of monitoring the system. We stay in the abstract setting of ADM but the techniques can be instantiated to any concrete domain. We illustrate them through the example of a mobile application for Android, which dynamically reconfigures a devices operating profile based on environmental factors.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {127–134},
numpages = {8},
keywords = {profile management, optimization, mealy machines, dynamic product lines, delta modeling},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2362536.2362568,
author = {Hofman, Peter and Stenzel, Tobias and Pohley, Thomas and Kircher, Michael and Bermann, Andreas},
title = {Domain specific feature modeling for software product lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362568},
doi = {10.1145/2362536.2362568},
abstract = {This paper summarizes our experience with introducing feature modeling into a product line for imaging and therapy systems in the Siemens Healthcare Sector. Determining and negotiating the scope in a product line that spans several business units with their own economic goals is challenging. Feature modeling offers a good way to do variability/commonality analysis for complex product lines. A precondition for feature modeling is the identification of all features supporting the product line. To identify these features, we developed a method for systematically deriving a feature model top down based on domain know-how. We call this method domain specific feature modeling. As the primary artifact to describe the problem space, a domain specific feature model additionally improves the requirement understanding for all stakeholders by considerably improving the scoping, traceability, testing, efficiency and transparency of planning activities and making the development efforts easier to estimate. In this paper, we share our experience with domain specific feature modeling in a large platform project and describe the lessons learned. We describe our general approach that can also be used for other domains.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {229–238},
numpages = {10},
keywords = {variability analysis, product line, feature modeling, feature dependency diagram, domain specific feature model, commonality analysis, agile, Scrum},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2648511.2648519,
author = {Moens, Hendrik and De Turck, Filip},
title = {Feature-based application development and management of multi-tenant applications in clouds},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648519},
doi = {10.1145/2648511.2648519},
abstract = {In recent years, there has been a rising interest in cloud computing, which is often used to offer Software as a Service (SaaS) over the Internet. SaaS applications can be offered to clients at a lower cost as they are usually multi-tenant: many end users make use of a single application instance, even when they are from different organisations. It is difficult to offer highly customizable SaaS applications that are still multi-tenant, which is why these SaaS applications are often offered in a one size fits all approach.In some application domains applications must be highly customizable, making it more difficult to migrate them to a cloud environment, and losing the benefits of multi-tenancy. In this paper we compare multiple approaches for the development and management of highly customizable multitenant SaaS applications, and present a methodology for developing and managing these applications. We compare two approaches, an application-based approach focusing on deploying multiple multi-tenant applications variants, and a feature-based approach where applications are composed out of multi-tenant services using a service oriented architecture. In addition, we also discuss a hybrid approach combining properties of both. We conclude that the feature-based approach results in the fewest application instances at runtime resulting in more multi-tenancy.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {72–81},
numpages = {10},
keywords = {multi-tenancy, feature modeling, cloud computing},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/302405.302409,
author = {DeBaud, Jean-Marc and Schmid, Klaus},
title = {A systematic approach to derive the scope of software product lines},
year = {1999},
isbn = {1581130740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302405.302409},
doi = {10.1145/302405.302409},
booktitle = {Proceedings of the 21st International Conference on Software Engineering},
pages = {34–43},
numpages = {10},
keywords = {software product line, reuse economic models, product line scoping, domain engineering},
location = {Los Angeles, California, USA},
series = {ICSE '99}
}

@inproceedings{10.1007/978-3-030-64694-3_17,
author = {Benmerzoug, Amine and Yessad, Lamia and Ziadi, Tewfik},
title = {Analyzing the Impact of Refactoring Variants on Feature Location},
year = {2020},
isbn = {978-3-030-64693-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64694-3_17},
doi = {10.1007/978-3-030-64694-3_17},
abstract = {Due to the increasing importance of feature location process, several studies evaluate the performance of different techniques based on IR strategies and a set of software variants as input artifacts. The proposed techniques attempt to improve the results obtained but it is often a difficult task. None of the existing feature location techniques considers the changing nature of the input artifacts, which may undergo series of refactoring changes. In this paper, we investigate the impact of refactoring variants on the feature location techniques. We first evaluate the performance of two techniques through the ArgoUML SPL benchmark when the variants are refactored. We then discuss the degraded results and the possibility of restoring them. Finally, we outline a process of variant alignment that aims to preserve the performance of the feature location.},
booktitle = {Reuse in Emerging Software Engineering Practices: 19th International Conference on Software and Systems Reuse, ICSR 2020, Hammamet, Tunisia, December 2–4, 2020, Proceedings},
pages = {279–291},
numpages = {13},
keywords = {Refactoring, Feature location, Software Product Line},
location = {Hammamet, Tunisia}
}

@inproceedings{10.1145/941350.941369,
author = {Li, Li (Erran) and Sinha, Prasun},
title = {Throughput and energy efficiency in topology-controlled multi-hop wireless sensor networks},
year = {2003},
isbn = {1581137648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/941350.941369},
doi = {10.1145/941350.941369},
abstract = {In the context of multi-hop wireless networks, various topology control algorithms have been proposed to adapt the transmission range of nodes based on local information while maintaining a connected topology. These algorithms are particularly suited for deployment in sensor networks which typically consist of energy constrained sensors. Sensor nodes should support power adaptation in order to use the benefits of topology control for energy conservation. In this paper, we design a framework for evaluating the performance of topology control algorithms using overall network throughput, and total energy consumption per packet delivered, as the metrics. Our goal is to identify the scenarios in which topology control improves the network performance. We supplement our analysis with ns2 simulations using the cone-based topology control algorithm [10, 19].Based on our analysis and simulations, we find that link layer retransmissions are essential with topology control to avoid throughput degradation due to increase in number of hops in lightly loaded networks. In heavily loaded networks, the throughput can be improved by a factor up to k2, where k is the average factor of reduction in transmission range using topology control. Studies of energy consumption reveal that improvements of up to $k^4$ can be obtained using topology control. However, these improvements decrease as the traffic pattern shifts from local (few hop connections) to non-local (hop lengths of the order of the diameter of the network). These results can be used to guide the deployment of topology control algorithms in sensor networks.},
booktitle = {Proceedings of the 2nd ACM International Conference on Wireless Sensor Networks and Applications},
pages = {132–140},
numpages = {9},
keywords = {wireless networks, topology control, sensor networks, ad-hoc networks},
location = {San Diego, CA, USA},
series = {WSNA '03}
}

@article{10.1109/92.863617,
author = {Hegde, Rajamohana and Shanbhag, Naresh R.},
title = {Toward achieving energy efficiency in presence of deep submicron noise},
year = {2000},
issue_date = {Aug. 2000},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {8},
number = {4},
issn = {1063-8210},
url = {https://doi.org/10.1109/92.863617},
doi = {10.1109/92.863617},
abstract = {Presented in this paper are: 1) information-theoretic lower bounds on energy consumption of noisy digital gates and 2) the concept of noise tolerance via coding for achieving energy efficiency in the presence of noise. In particular, lower bounds on a) circuit speed f/sub c/ and supply voltage V/sub dd/; b) transition activity t in presence of noise; c) dynamic energy dissipation; and d) total (dynamic and static) energy dissipation are derived. A surprising result is that in a scenario where dynamic component of power dissipation dominates, the supply voltage for minimum energy operation (V/sub dd, opt/) is greater than the minimum supply voltage (V/sub dd, min/)for reliable operation. We then propose noise tolerance via coding to approach the lower bounds on energy dissipation. We show that the lower bounds on energy for an off-chip I/O signaling example are a factor of 24/spl times/ below present day systems. A very simple Hamming code can reduce the energy consumption by a factor of 3/spl times/, while Reed-Muller (RM) codes give a 4/spl times/ reduction in energy dissipation.},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
month = aug,
pages = {379–391},
numpages = {13},
keywords = {noise-tolerant computing, noise, lower bound, gate capacity, energy dissipation, coding}
}

@inproceedings{10.1145/2499777.2500716,
author = {Saller, Karsten and Lochau, Malte and Reimund, Ingo},
title = {Context-aware DSPLs: model-based runtime adaptation for resource-constrained systems},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500716},
doi = {10.1145/2499777.2500716},
abstract = {Dynamic Software Product Lines (DSPLs) provide a promising approach for planning and applying runtime reconfiguration scenarios to adaptive software systems. However, applying DSPLs in the vital domain of highly context-aware systems, e.g., mobile devices, is obstructed by the inherently limited resources being insufficient to handle large, constrained (re-)configurations spaces. To tackle these drawbacks, we propose a novel model-based approach for designing DSPLs in a way that allows for a trade-off between precomputation of reconfiguration scenarios at development time and on-demand evolution at runtime. Therefore, we (1) enrich feature models with context information to reason about potential context changes, and (2) specify context-aware reconfiguration processes on the basis of a scalable transition system incorporating state space abstractions and incremental refinement at runtime. We illustrate our concepts by means of a smartphone case study and present an implementation and evaluation considering different trade-off metrics.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {106–113},
numpages = {8},
keywords = {state space reduction, feature models, contexts, adaptive systems, DSPL},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2866614.2866627,
author = {Devroey, Xavier and Perrouin, Gilles and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Search-based Similarity-driven Behavioural SPL Testing},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866627},
doi = {10.1145/2866614.2866627},
abstract = {Dissimilar test cases have been proven to be effective to reveal faults in software systems. In the Software Product Line (SPL) context, this criterion has been applied successfully to mimic combinatorial interaction testing in an efficient and scalable manner by selecting and prioritising most dissimilar configurations of feature models using evolutionary algorithms. In this paper, we extend dissimilarity to behavioural SPL models (FTS) in a search-based approach, and evaluate its effectiveness in terms of product and fault coverage. We investigate different distances as well as as single-objective algorithms, (dissimilarity on actions, random, all-actions). Our results on four case studies show the relevance of dissimilarity-based test generation for behavioural SPL models, especially on the largest case-study where no other approach can match it.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {89–96},
numpages = {8},
keywords = {Software Product Line Testing, Featured Transition System, Dissimilarity Testing},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@article{10.1007/s10664-021-09940-0,
author = {Cashman, Mikaela and Firestone, Justin and Cohen, Myra B. and Thianniwet, Thammasak and Niu, Wei},
title = {An empirical investigation of organic software product lines},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09940-0},
doi = {10.1007/s10664-021-09940-0},
abstract = {Software product line engineering is a best practice for managing reuse in families of software systems that is increasingly being applied to novel and emerging domains. In this work we investigate the use of software product line engineering in one of these new domains, synthetic biology. In synthetic biology living organisms are programmed to perform new functions or improve existing functions. These programs are designed and constructed using small building blocks made out of DNA. We conjecture that there are families of products that consist of common and variable DNA parts, and we can leverage product line engineering to help synthetic biologists build, evolve, and reuse DNA parts. In this paper we perform an investigation of domain engineering that leverages an open-source repository of more than 45,000 reusable DNA parts. We show the feasibility of these new types of product line models by identifying features and related artifacts in up to 93.5% of products, and that there is indeed both commonality and variability. We then construct feature models for four commonly engineered functions leading to product lines ranging from 10 to 7.5 \texttimes{} 1020 products. In a case study we demonstrate how we can use the feature models to help guide new experimentation in aspects of application engineering. Finally, in an empirical study we demonstrate the effectiveness and efficiency of automated reverse engineering on both complete and incomplete sets of products. In the process of these studies, we highlight key challenges and uncovered limitations of existing SPL techniques and tools which provide a roadmap for making SPL engineering applicable to new and emerging domains.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {43},
keywords = {BioBricks, Reverse engineering, Synthetic biology, Software product lines}
}

@article{10.1007/s42979-021-00541-8,
author = {Saber, Takfarinas and Brevet, David and Botterweck, Goetz and Ventresque, Anthony},
title = {Reparation in Evolutionary Algorithms for Multi-objective Feature Selection in Large Software Product Lines},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00541-8},
doi = {10.1007/s42979-021-00541-8},
abstract = {Software Product Lines Engineering is the area of software engineering that aims to systematise the modelling, creation and improvement of groups of interconnected software systems by formally expressing possible alternative products in the form of Feature Models. Deriving a software product/system from a feature model is called Feature Configuration. Engineers select the subset of features (software components) from a feature model that suits their needs, while respecting the underlying relationships/constraints of the system–which is challenging on its own. Since there exist several (and often antagonistic) perspectives on which the quality of software could be assessed, the problem is even more challenging as it becomes a multi-objective optimisation problem. Current multi-objective feature selection in software product line approaches (e.g., SATIBEA) combine the scalability of a genetic algorithm (IBEA) with a solution reparation approach based on a SAT solver or one of its derivatives. In this paper, we propose MILPIBEA, a novel hybrid algorithm which combines IBEA with the accuracy of a mixed-integer linear programming (MILP) reparation. We show that the MILP reparation modifies fewer features from the original infeasible solutions than the SAT reparation and in a shorter time. We also demonstrate that MILPIBEA outperforms SATIBEA on average on various multi-objective performance metrics, especially on the largest feature models. The other major challenge in software engineering in general and in software product lines, in particular, is evolution. While the change in software components is common in the software engineering industry, the particular case of multi-objective optimisation of evolving software product lines is not well-tackled yet. We show that MILPIBEA is not only able to better take advantage of the evolution than SATIBEA, but it is also the one that continues to improve the quality of the solutions when SATIBEA stagnates. Overall, IBEA performs better when combined with MILP instead of SAT reparation when optimising the multi-objective feature selection in large and evolving software product lines.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {14},
keywords = {Mixed-integer linear programming, Reparation, Evolutionary algorithm, Multi-objective optimisation, Feature selection, Software product line}
}

@inproceedings{10.1145/2364412.2364435,
author = {Saller, Karsten and Oster, Sebastian and Sch\"{u}rr, Andy and Schroeter, Julia and Lochau, Malte},
title = {Reducing feature models to improve runtime adaptivity on resource limited devices},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364435},
doi = {10.1145/2364412.2364435},
abstract = {Mobile devices like smartphones are getting increasingly important in our daily lifes. They are used in various environments and have to dynamically adapt themselves accordingly in order to provide an optimal runtime behavior. Naturally, adapting to continuously changing environmental conditions is a challenging task because mobile devices are always limited in their resources and have to adapt in real-time. In this paper, we introduce an approach that enables resource limited devices to adapt to changing conditions using dynamic software product lines techniques. Therefore, feature models are reduced to a specific hardware context before installing the adaptive mobile application on the device. This reduces the amount of possible configurations that are compatible with the device and, thereby, minimizes the costs and the duration of an adaptation during runtime.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {135–142},
numpages = {8},
keywords = {feature models, dynamic software product lines, context-awareness, adaptive systems},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s00766-014-0201-3,
author = {Lung, Chung-Horng and Balasubramaniam, Balasangar and Selvarajah, Kamalachelva and Elankeswaran, Poopalasingham and Gopalasundaram, Umatharan},
title = {On building architecture-centric product line architecture},
year = {2015},
issue_date = {September 2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-014-0201-3},
doi = {10.1007/s00766-014-0201-3},
abstract = {Software architects typically spend a great deal of time and effort exploring uncertainties, evaluating alternatives, and balancing the concerns of stakeholders. Selecting the best architecture to meet both the functional and non-functional requirements is a critical but difficult task, especially at the early stage of software development when there may be many uncertainties. For example, how will a technology match the operational or performance expectations in reality? This paper presents an approach to building architecture-centric product line. The main objective of the proposed approach is to support effective requirements validation and architectural prototyping for the application-level software. Architectural prototyping is practically essential to architecture design and evaluation. However, architectural prototyping practiced in the field mostly is not used to explore alternatives. Effective construction and evaluation of multiple architecture alternatives is one of the critically challenging tasks. The product line architecture advocated in this paper consists of multiple software architecture alternatives, from which the architect can select and rapidly generate a working application prototype. The paper presents a case study of developing a framework that is primarily built with robust architecture patterns in distributed and concurrent computing and includes variation mechanisms to support various applications even in different domains. The development process of the framework is an application of software product line engineering with an aim to effectively facilitate upfront requirements analysis for an application and rapid architectural prototyping to explore and evaluate architecture alternatives.},
journal = {Requir. Eng.},
month = sep,
pages = {301–321},
numpages = {21},
keywords = {Software product line, Software performance, Requirements validation, Patterns, Architecture evaluation, Architectural prototyping}
}

@inproceedings{10.1145/3350768.3351299,
author = {de Oliveira, Davi Cedraz S. and Bezerra, Carla I. M.},
title = {Development of the Maintainability Index for SPLs Feature Models Using Fuzzy Logic},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3351299},
doi = {10.1145/3350768.3351299},
abstract = {The variability of the common features in an Software Product Line (SPL) can be managed by an feature model, an artifact that consist of a tree-shaped diagram, that describe the features identified in the products and the possible relationships between them. Guarantee the quality of the feature model may be essential to ensure that errors do not propagate across all products. The process of evaluating the quality of a product or artifact can be done using measures, which may reflect the characteristics, sub-characteristics or attributes of quality. However, the isolated values of each measure do not allow access to a whole quality of the feature model, since most of the measures cover several specific aspects that are not correlated. In this context, this paper proposes the aggregation of measures in order to evaluate the maintainability of the feature model in SPL. We aim to investigate how to aggregate these measures and access the respective sub-characteristics by means of a single aggregate value that has the same available information as a set of measures. For this, we have used the theory of Fuzzy Logic as a technique for aggregation of these measures. The new aggregate measure represents the maintainability index of a feature models (MIFM) was obtained. Moreover, to evaluate the MIFM, we applied it to a set of models. It was verified that the aggregate measure obtained allows to measure if a feature models has a high or low maintainability index, supporting the domain engineer in the evaluation of the maintenance of the feature model in a faster and more precise way.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {357–366},
numpages = {10},
keywords = {Software Product Line, Quality Evaluation, Measures, Fuzzy Logic, Feature Models},
location = {Salvador, Brazil},
series = {SBES '19}
}

@article{10.1016/j.infsof.2012.07.010,
author = {Buchmann, Thomas and Dotor, Alexander and Westfechtel, Bernhard},
title = {MOD2-SCM: A model-driven product line for software configuration management systems},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.010},
doi = {10.1016/j.infsof.2012.07.010},
abstract = {Context: Software Configuration Management (SCM) is the discipline of controlling the evolution of large and complex software systems. Over the years many different SCM systems sharing similar concepts have been implemented from scratch. Since these concepts usually are hard-wired into the respective program code, reuse is hardly possible. Objective: Our objective is to create a model-driven product line for SCM systems. By explicitly describing the different concepts using models, reuse can be performed on the modeling level. Since models are executable, the need for manual programming is eliminated. Furthermore, by providing a library of loosely coupled modules, we intend to support flexible composition of SCM systems. Method: We developed a method and a tool set for model-driven software product line engineering which we applied to the SCM domain. For domain analysis, we applied the FORM method, resulting in a layered feature model for SCM systems. Furthermore, we developed an executable object-oriented domain model which was annotated with features from the feature model. A specific SCM system is configured by selecting features from the feature model and elements of the domain model realizing these features. Results: Due to the orthogonality of both feature model and domain model, a very large number of SCM systems may be configured. We tested our approach by creating instances of the product line which mimic wide-spread systems such as CVS, GIT, Mercurial, and Subversion. Conclusion: The experiences gained from this project demonstrate the feasibility of our approach to model-driven software product line engineering. Furthermore, our work advances the state of the art in the domain of SCM systems since it support the modular composition of SCM systems at the model rather than the code level.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {630–650},
numpages = {21},
keywords = {Software product line engineering, Software configuration management, Model-driven software engineering, Model transformation, Feature models, Executable models, Code generation}
}

@inproceedings{10.1145/3425174.3425211,
author = {Ferreira, Thiago do Nascimento and Vergilio, Silvia Regina and Kessentini, Marouane},
title = {Applying Many-objective Algorithms to the Variability Test of Software Product Lines},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425211},
doi = {10.1145/3425174.3425211},
abstract = {The problem known as Variability Test of Software Product Line (VTSPL) is related to the selection of the most representative products for the SPL testing. This is an optimization problem because a possible exponential number of products can be derived from the SPL variability model, such as the Feature Model (FM). In the literature many works are dedicated to this research subject, each one applying a different search-based algorithm and using distinct criteria. However, there is no study encompassing all these criteria at the same time. To this end, this paper investigates the use of two Many-Objective Evolutionary Algorithms (MaOEAs). We apply the algorithm NSGA-III, widely used for many-objective algorithms, and the algorithm PCA-NSGA-II, a reduction dimensionality algorithm, which uses the Principal-Component Analysis (PCA) in combination with NSGA-II, to evaluate the objectives used in the literature for the VTSPL problem. PCA-NSGA-II reduces the search space dimensionality by eliminating the redundant objectives. The analysis shows the importance of some objectives such as the number of alive mutants, similarity between products, and unselected features. NSGA-III reaches the best results regarding the quality indicators for all instances, but taking a longer time. Besides, PCA-NSGA-II can find different solutions in the search space that are not found by NSGA-III.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {11–20},
numpages = {10},
keywords = {many-objective problems, dimensionality reduction, Software product line testing},
location = {Natal, Brazil},
series = {SAST '20}
}

@inproceedings{10.5555/1753235.1753267,
author = {Mendonca, Marcilio and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof},
title = {SAT-based analysis of feature models is easy},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Feature models are a popular variability modeling notation used in product line engineering. Automated analyses of feature models, such as consistency checking and interactive or offline product selection, often rely on translating models to propositional logic and using satisfiability (SAT) solvers.Efficiency of individual satisfiability-based analyses has been reported previously. We generalize and quantify these studies with a series of independent experiments. We show that previously reported efficiency is not incidental. Unlike with the general SAT instances, which fall into easy and hard classes, the instances induced by feature modeling are easy throughout the spectrum of realistic models. In particular, the phenomenon of phase transition is not observed for realistic feature models.Our main practical conclusion is a general encouragement for researchers to continued development of SAT-based methods to further exploit this efficiency in future.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {231–240},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1007/978-3-642-25535-9_29,
author = {Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Asadi, Mohsen and Bagheri, Ebrahim and Bo\v{s}kovi\'{c}, Marko},
title = {A quality aggregation model for service-oriented software product lines based on variability and composition patterns},
year = {2011},
isbn = {9783642255342},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25535-9_29},
doi = {10.1007/978-3-642-25535-9_29},
abstract = {Quality evaluation is a challenging task in monolithic software systems. It is even more complex when it comes to Service-Oriented Software Product Lines (SOSPL), as it needs to analyze the attributes of a family of SOA systems. In SOSPL, variability can be planned and managed at the architectural level to develop a software product with the same set of functionalities but different degrees of non-functional quality attribute satisfaction. Therefore, architectural quality evaluation becomes crucial due to the fact that it allows for the examination of whether or not the final product satisfies and guarantees all the ranges of quality requirements within the envisioned scope. This paper addresses the open research problem of aggregating QoS attribute ranges with respect to architectural variability. Previous solutions for quality aggregation do not consider architectural variability for composite services. Our approach introduces variability patterns that can possibly occur at the architectural level of an SOSPL. We propose an aggregation model for QoS computation which takes both variability and composition patterns into account.},
booktitle = {Proceedings of the 9th International Conference on Service-Oriented Computing},
pages = {436–451},
numpages = {16},
keywords = {variability management, software product line (SPL), service-oriented architecture (SOA), service variability, process family, non-functional properties, feature modeling, QoS aggregation},
location = {Paphos, Cyprus},
series = {ICSOC'11}
}

@inproceedings{10.1145/3229345.3229349,
author = {Martins, Gev\~{a} and Veiga, Welington and Campos, Fernanda and Str\"{o}ele, Victor and David, Jos\'{e} Maria N. and Braga, Regina},
title = {Building Educational Games from a Feature Model},
year = {2018},
isbn = {9781450365598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229345.3229349},
doi = {10.1145/3229345.3229349},
abstract = {We present BROAD-PLG, a Software Product Line to support the construction of educational games, with a set of features that will integrate the artefact to be developed. The evaluation was based on the development of the infrastructure and the generation of new products. It followed two steps: the development of a game for teaching Logic using the defined features and, in the second step, we describe the game in use in two virtual learning environments - the Moodle (free platform) and youKnow (private platform). For evaluation in a real learning environment the game was wrapped as a service. The results point to the feasibility of using the solution and the set of features for automatic or semi automatic generation of educational games.},
booktitle = {Proceedings of the XIV Brazilian Symposium on Information Systems},
articleno = {3},
numpages = {7},
keywords = {virtual learning environments, software product line, Educational games},
location = {Caxias do Sul, Brazil},
series = {SBSI '18}
}

@inproceedings{10.1145/1987875.1987886,
author = {Belategi, Lorea and Sagardui, Goiuria and Etxeberria, Leire},
title = {Model based analysis process for embedded software product lines},
year = {2011},
isbn = {9781450307307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987875.1987886},
doi = {10.1145/1987875.1987886},
abstract = {Nowadays, embedded system development is increasing its complexity dealing with quality, cost and time-to-market among others. Quality attributes are an important issue to consider in embedded software development where time issues may be critical. Development paradigms such as Model Driven Development and Software Product Lines can be an adequate alternative to traditional software development and validation methods due to the characteristics of embedded systems. But for a proper validation and verification based on MARTE model analysis, all variability issues and critical quality attributes that take part in analysis must be properly modelled and managed. Therefore, a model analysis process for Model Driven Embedded Software Product Lines has been defined as some process lacks have been found.},
booktitle = {Proceedings of the 2011 International Conference on Software and Systems Process},
pages = {53–62},
numpages = {10},
keywords = {software product line, schedulability, quality attributes, performance, model driven development, model based analysis process},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSSP '11}
}

@article{10.1007/s10664-020-09853-4,
author = {Hajri, Ines and Goknil, Arda and Pastore, Fabrizio and Briand, Lionel C.},
title = {Automating system test case classification and prioritization for use case-driven testing in product lines},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09853-4},
doi = {10.1007/s10664-020-09853-4},
abstract = {Product Line Engineering (PLE) is a crucial practice in many software development environments where software systems are complex and developed for multiple customers with varying needs. At the same time, many development processes are use case-driven and this strongly influences their requirements engineering and system testing practices. In this paper, we propose, apply, and assess an automated system test case classification and prioritization approach specifically targeting system testing in the context of use case-driven development of product families. Our approach provides: (i) automated support to classify, for a new product in a product family, relevant and valid system test cases associated with previous products, and (ii) automated prioritization of system test cases using multiple risk factors such as fault-proneness of requirements and requirements volatility in a product family. Our evaluation was performed in the context of an industrial product family in the automotive domain. Results provide empirical evidence that we propose a practical and beneficial way to classify and prioritize system test cases for industrial product lines.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3711–3769},
numpages = {59},
keywords = {Requirements engineering, Automotive, Test case selection and prioritization, Regression testing, Use case driven development, Product Line Engineering}
}

@inproceedings{10.1145/2019136.2019141,
author = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
title = {Extraction of feature models from formal contexts},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019141},
doi = {10.1145/2019136.2019141},
abstract = {For economical reasons, the creation of feature oriented software should include previously created products and should not be done from scratch. To speed up this migration process, feature models have to be generated automatically from existing product variants. This work presents an approach based on formal concept analysis that analyzes incidence matrices containing matching relations as input and creates feature models as output. The resulting feature models describe exactly the given input variants. The introduced novel optimized approach performs this transformation in reasonable time even for large product libraries.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {4},
numpages = {8},
keywords = {formal concept analysis, feature models},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1007/s11219-017-9400-8,
author = {Alf\'{e}rez, Mauricio and Acher, Mathieu and Galindo, Jos\'{e} A. and Baudry, Benoit and Benavides, David},
title = {Modeling variability in the video domain: language and experience report},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-017-9400-8},
doi = {10.1007/s11219-017-9400-8},
abstract = {In an industrial project, we addressed the challenge of developing a software-based video generator such that consumers and providers of video processing algorithms can benchmark them on a wide range of video variants. This article aims to report on our positive experience in modeling, controlling, and implementing software variability in the video domain. We describe how we have designed and developed a variability modeling language, called VM, resulting from the close collaboration with industrial partners during 2 years. We expose the specific requirements and advanced variability constructs; we developed and used to characterize and derive variations of video sequences. The results of our experiments and industrial experience show that our solution is effective to model complex variability information and supports the synthesis of hundreds of realistic video variants. From the software language perspective, we learned that basic variability mechanisms are useful but not enough; attributes and multi-features are of prior importance; meta-information and specific constructs are relevant for scalable and purposeful reasoning over variability models. From the video domain and software perspective, we report on the practical benefits of a variability approach. With more automation and control, practitioners can now envision benchmarking video algorithms over large, diverse, controlled, yet realistic datasets (videos that mimic real recorded videos)--something impossible at the beginning of the project.},
journal = {Software Quality Journal},
month = mar,
pages = {307–347},
numpages = {41},
keywords = {Video testing, Variability modeling, Software product line engineering, Feature modeling, Domain-specific languages, Configuration, Automated reasoning}
}

@inproceedings{10.5220/0004745201110118,
author = {Oliveira Jr., Edson and M. S. Gimenes, Itana},
title = {Empirical Validation of Product-line Architecture Extensibility Metrics},
year = {2014},
isbn = {9789897580284},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0004745201110118},
doi = {10.5220/0004745201110118},
abstract = {The software product line (PL) approach has been applied as a successful software reuse technique for specificdomains. The SPL architecture (PLA) is one of the most important SPL core assets as it is the abstraction ofthe products that can be generated, and it represents similarities and variabilities of a PL. Its quality attributesanalysis and evaluation can serve as a basis for analyzing the managerial and economical values of a PL. Thisanalysis can be quantitatively supported by metrics. Thus, we proposed metrics for the PLA extensibilityquality attribute. This paper is concerned with the empirical validation of such metrics. As a result of the experimentalwork we can provide evidence that the proposed metrics serve as relevant indicators of extensibilityof PLA by presenting a correlation analysis.},
booktitle = {Proceedings of the 16th International Conference on Enterprise Information Systems - Volume 2},
pages = {111–118},
numpages = {8},
keywords = {Variability Management., Software Product Line Architecture, Metrics, Extensibility, Empirical Validation},
location = {Lisbon, Portugal},
series = {ICEIS 2014}
}

@inproceedings{10.1145/2362536.2362544,
author = {Dietrich, Christian and Tartler, Reinhard and Schr\"{o}der-Preikschat, Wolfgang and Lohmann, Daniel},
title = {A robust approach for variability extraction from the Linux build system},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362544},
doi = {10.1145/2362536.2362544},
abstract = {With more than 11,000 optional and alternative features, the Linux kernel is a highly configurable piece of software. Linux is generally perceived as a textbook example for preprocessor-based product derivation, but more than 65 percent of all features are actually handled by the build system. Hence, variability-aware static analysis tools have to take the build system into account.However, extracting variability information from the build system is difficult due to the declarative and turing-complete make language. Existing approaches based on text processing do not cover this challenges and tend to be tailored to a specific Linux version and architecture. This renders them practically unusable as a basis for variability-aware tool support -- Linux is a moving target!We describe a robust approach for extracting implementation variability from the Linux build system. Instead of extracting the variability information by a text-based analysis of all build scripts, our approach exploits the build system itself to produce this information. As our results show, our approach is robust and works for all versions and architectures from the (git-)history of Linux.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {21–30},
numpages = {10},
keywords = {static analysis, maintenance, kbuild, configurability, build systems, VAMOS, Linux},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753249,
author = {Montagud, Sonia and Abrah\~{a}o, Silvia},
title = {Gathering current knowledge about quality evaluation in software product lines},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Recently, a number of methods and techniques for assessing the quality of software product lines have been proposed. However, to the best of our knowledge, there is no study which summarizes all the existing evidence about them. This paper presents a systematic review that investigates what methods and techniques have been employed (in the last 10 years) to evaluate the quality of software product lines and how they were employed. A total of 39 research papers have been reviewed from an initial set of 1388 papers. The results show that 25% of the papers reported evaluations at the Design phase of the Domain Engineering phase. The most widely used mechanism for modeling quality attributes was extended feature models and the most evaluated artifact was the base architecture. In addition, the results of the review have identified several research gaps. Specifically, 77% of the papers employed case studies as a "proof of concept" whereas 23% of the papers did not perform any type of validation. Our results are particularly relevant in positioning new research activities and in the selection of quality evaluation methods or techniques that best fit a given purpose.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {91–100},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2019136.2019175,
author = {Damiani, Ferruccio and Schaefer, Ina},
title = {Dynamic delta-oriented programming},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019175},
doi = {10.1145/2019136.2019175},
abstract = {Modern software systems should be designed to dynamically adapt to changing user requirements or resource constraints. Delta-oriented programming (DOP) is a compositional approach to flexibly implement software product lines. In DOP, a product line is represented by a code base and a product line declaration. The code base consists of a set of delta modules specifying modifications to object-oriented programs. The product line declaration provides the connection of the delta modules with the product features and describes how the product for a particular feature configuration is generated. DOP has so far only been used for static variability. In this paper, we present dynamic DOP, an extension of DOP that supports changing the feature configuration of a product at runtime. A dynamic DOP product line is a standard DOP product line with a reconfiguration automaton that specifies how to switch between different feature configurations. The type system of our dynamic DOP language ensures that any reconfiguration leads to a type safe product. Dynamic DOP is an approach for realizing dynamic product lines which also supports (unanticipated) software evolution.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {34},
numpages = {8},
keywords = {runtime reconfiguration, programming languages, evolution, dynamic software product lines},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.4018/ijkss.2014100103,
author = {Bashari, Mahdi and Noorian, Mahdi and Bagheri, Ebrahim},
title = {Product Line Stakeholder Preference Elicitation via Decision Processes},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100103},
doi = {10.4018/ijkss.2014100103},
abstract = {In the software product line configuration process, certain features are selected based on the stakeholders' needs and preferences regarding the available functional and quality properties. This book chapter presents how a product configuration can be modeled as a decision process and how an optimal strategy representing the stakeholders' desirable configuration can be found. In the decision process model of product configuration, the product is configured by making decisions at a number of decision points. The decisions at each of these decision points contribute to functional and quality attributes of the final product. In order to find an optimal strategy for the decision process, a utility-based approach can be adopted, through which, the strategy with the highest utility is selected as the optimal strategy. In order to define utility for each strategy, a multi-attribute utility function is defined over functional and quality properties of a configured product and a utility elicitation process is then introduced for finding this utility function. The utility elicitation process works based on asking gamble queries over functional and quality requirement from the stakeholder. Using this utility function, the optimal strategy and therefore optimal product configuration is determined.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {35–51},
numpages = {17},
keywords = {Utility Elicitation, Software Product Line, Economic Value, Decision Process, Configuration Process}
}

@inproceedings{10.1145/1985484.1985490,
author = {Stallinger, Fritz and Neumann, Robert and Schossleitner, Robert and Kriener, Stephan},
title = {Migrating towards evolving software product lines: challenges of an SME in a core customer-driven industrial systems engineering context},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985490},
doi = {10.1145/1985484.1985490},
abstract = {In this paper we identify key challenges a medium-sized software organization is facing in migrating towards Software Product Line Engineering (SPLE). The software engineering context of the company is characterized by a two-fold access to the market - core customer driven product enhancement and product development for a broader, anonymous market - and the embedding of software engineering in multi-disciplinary systems and solutions engineering.Based on a characterization of the business, the software product subject to migration towards SPLE, and the goals and background of the SPLE initiative, seven key challenges with respect to the migration are identified. These challenges relate to process diversity in the face of multiple reuse approaches; the management of requirements and variability; the integration of requirements traceability and variability management; legacy software and discipline vs. software-specific modularization; integration with systems engineering; costing and pricing models; and project vs. product documentation.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {20–24},
numpages = {5},
keywords = {systems engineering, software product migration, software product line, software engineering, sme},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@article{10.5555/2590467.2590469,
author = {Kaya, Ozgur and Hashemikhabir, Seyedsasan and Togay, Cengiz and Dogru, Ali Hikmet},
title = {A RULE-BASED DOMAIN SPECIFIC LANGUAGE FOR FAULT MANAGEMENT},
year = {2010},
issue_date = {July 2010},
publisher = {IOS Press},
address = {NLD},
volume = {14},
number = {3},
issn = {1092-0617},
abstract = {In this article, we propose a domain specific language for the "fault management for mission critical systems" domain that also supports rule-based operation. Variability management for a software product line, hence configuration of specific products will be achieved by programming various nodes in a "Software Factory Automation" based architecture, through this language. The architecture suggests a distributed set of interconnected "Domain Specific Engines" that interpret specific languages. Those engines and their corresponding languages assume different fault management capabilities, therefore suggest the design of different languages for fault monitoring, detection, prevention, diagnosis, and repair. The overall fault management capabilities should be supported by the composition of those languages. A high-level definition of the language is presented. The objective of the study is to provide an infrastructure that is more predictable for the development success of fault management systems for families of complex embedded mission critical applications.},
journal = {J. Integr. Des. Process Sci.},
month = jul,
pages = {13–23},
numpages = {11},
keywords = {Software Product Line Engineering, Rule Based Languages, Fault Management, Domain Specific Languages}
}

@article{10.1016/j.jss.2018.05.069,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Self-adaptation of service compositions through product line reconfiguration},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.05.069},
doi = {10.1016/j.jss.2018.05.069},
journal = {J. Syst. Softw.},
month = oct,
pages = {84–105},
numpages = {22},
keywords = {Self adaptation, Software product lines, Feature model, Service composition}
}

@inproceedings{10.1007/11554844_7,
author = {Zhang, Weishan and Jarzabek, Stan},
title = {Reuse without compromising performance: industrial experience from RPG software product line for mobile devices},
year = {2005},
isbn = {3540289364},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11554844_7},
doi = {10.1007/11554844_7},
abstract = {It is often believed that reusable solutions, being generic, must necessarily compromise performance. In this paper, we consider a family of Role-Playing Games (RPGs). We analyzed similarities and differences among four RPGs. By applying a reuse technique of XVCL, we built an RPG product line architecture (RPG-PLA) from which we could derive any of the four RPGs. We built into the RPG-PLA a number of performance optimization strategies that could benefit any of the four (and possibly other similar) RPGs. By comparing the original vs. the new RPGs derived from the RPG-PLA, we demonstrated that reuse allowed us to achieve improved performance, both speed and memory utilization, as compared to each game developed individually. At the same time, our solution facilitated rapid development of new games, for new mobile devices, as well as ease of evolving with new features the RPG-PLA and custom games already in use.},
booktitle = {Proceedings of the 9th International Conference on Software Product Lines},
pages = {57–69},
numpages = {13},
location = {Rennes, France},
series = {SPLC'05}
}

@article{10.1145/3088440,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {Teaching Software Product Lines: A Snapshot of Current Practices and Challenges},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
url = {https://doi.org/10.1145/3088440},
doi = {10.1145/3088440},
abstract = {Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving, as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, and what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. In this article, we report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, that is, an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {31},
keywords = {variability modeling, software product line teaching, software engineering teaching, Software product lines}
}

@article{10.1016/j.jss.2019.04.026,
author = {Gacit\'{u}a, Ricardo and Sep\'{u}lveda, Samuel and Mazo, Ra\'{u}l},
title = {FM-CF: A framework for classifying feature model building approaches},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.026},
doi = {10.1016/j.jss.2019.04.026},
journal = {J. Syst. Softw.},
month = aug,
pages = {1–21},
numpages = {21},
keywords = {Models, Classification, Framework, Software product lines, Feature model}
}

@article{10.1007/s10270-020-00803-8,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming},
title = {A framework for automated multi-stage and multi-step product configuration of cyber-physical systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00803-8},
doi = {10.1007/s10270-020-00803-8},
abstract = {Product line engineering (PLE) has been employed to large-scale cyber-physical systems (CPSs) to provide customization based on users’ needs. A PLE methodology can be characterized by its support for capturing and managing the abstractions as commonalities and variabilities and the automation of the configuration process for effective selection and customization of reusable artifacts. The automation of a configuration process heavily relies on the captured abstractions and formally specified constraints using a well-defined modeling methodology. Based on the results of our previous work and a thorough literature review, in this paper, we propose a conceptual framework to support multi-stage and multi-step automated product configuration of CPSs, including a comprehensive classification of constraints and a list of automated functionalities of a CPS configuration solution. Such a framework can serve as a guide for researchers and practitioners to evaluate an existing CPS PLE solution or devise a novel CPS PLE solution. To validate the framework, we conducted three real-world case studies. Results show that the framework fulfills all the requirements of the case studies in terms of capturing and managing variabilities and constraints. Results of the literature review indicate that the framework covers all the functionalities concerned by the literature, suggesting that the framework is complete for enabling the maximum automation of configuration in CPS PLE.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {211–265},
numpages = {55},
keywords = {Real-world case studies, Variability modeling, Constraint classification, Multi-stage and multi-step configuration process, Automated configuration, Product line engineering, Cyber-physical systems}
}

@inproceedings{10.5555/1753235.1753263,
author = {Than Tun, Thein and Boucher, Quentin and Classen, Andreas and Hubaux, Arnaud and Heymans, Patrick},
title = {Relating requirements and feature configurations: a systematic approach},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {A feature model captures various possible configurations of products within a product family. When configuring a product, several features are selected and composed. Selecting features at the program level has a general limitation of not being able to relate the resulting configuration to its requirements. As a result, it is difficult to decide whether a given configuration of features is optimal. An optimal configuration satisfies all stakeholder requirements and quantitative constraints, while ensuring that there is no extraneous feature in it. In relating requirements and feature configurations, we use the description of the problem world context in which the software is designed to operate as the intermediate description between them. The advantage of our approach is that feature selection can be done at the requirements level, and an optimal program level configuration can be generated from the requirements selected. Our approach is illustrated with a real-life problem of configuring a satellite communication software. The use of an existing tool to support our approach is also discussed.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {201–210},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1007/s10009-019-00528-0,
author = {Dimovski, Aleksandar S.},
title = {CTL⋆ family-based model checking using variability abstractions and modal transition systems},
year = {2020},
issue_date = {Feb 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {1},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-019-00528-0},
doi = {10.1007/s10009-019-00528-0},
abstract = {Variational systems can produce a (potentially huge) number of related systems, known as products or variants, by using features (configuration options) to mark the variable functionality. In many of the application domains, their rigorous verification and analysis are very important, yet the appropriate tools rarely are able to analyse variational systems. Recently, this problem was addressed by designing specialized so-called family-based model checking algorithms, which allow simultaneous verification of all variants in a single run by exploiting the commonalities between the variants. Yet, their computational cost still greatly depends on the number of variants (the size of configuration space), which is often huge. Moreover, their implementation and maintenance represent a costly research and development task. One of the most promising approaches to fighting the configuration space explosion problem is variability abstractions, which simplify variability away from variational systems. In this work, we show how to achieve efficient family-based model checking of CTL⋆ temporal properties using variability abstractions and off-the-shelf (single-system) tools. We use variability abstractions for deriving abstract family-based model checking, where the variability model of a variational system is replaced with an abstract (smaller) version of it, called modal transition system, which preserves the satisfaction of both universal and existential temporal properties, as expressible in CTL⋆. Modal transition systems contain two kinds of transitions, termed may- and must-transitions, which are defined by the conservative (over-approximating) abstractions and their dual (under-approximating) abstractions, respectively. The variability abstractions can be combined with different partitionings of the configuration space to infer suitable divide-and-conquer verification plans for the given variational system. We illustrate the practicality of this approach for several variational systems using the standard version of (single-system) NuSMV model checker.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = feb,
pages = {35–55},
numpages = {21},
keywords = {CTL* temporal logic, Featured transition systems, Modal transition systems, Abstract interpretation, Family-based model checking, Software product line engineering}
}

@inproceedings{10.1145/2556624.2556637,
author = {Machado, Ivan do Carmo and Santos, Alcemir Rodrigues and Cavalcanti, Yguarat\~{a} Cerqueira and Trzan, Eduardo Gomes and de Souza, Marcio Magalh\~{a}es and de Almeida, Eduardo Santana},
title = {Low-level variability support for web-based software product lines},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556637},
doi = {10.1145/2556624.2556637},
abstract = {The Web systems domain has faced an increasing number of devices, browsers, and platforms to cope with, driving software systems to be more flexible to accomodate them. Software product line (SPL) engineering can be used as a strategy to implement systems capable of handling such a diversity. To this end, automated tool support is almost indispensable. However, current tool support gives more emphasis to modeling variability in the problem domain, over the support of variability at the solution domain. There is a need for mapping the variability between both abstraction levels, so as to determine what implementation impact a certain variability has. In this paper, we propose the FeatureJS, a FeatureIDE extension aiming at Javascript and HTML support for SPL engineering. The tool combines feature-oriented programming and preprocessors, as a strategy to map variability at source code with the variability modeled at a higher level of abstraction. We carried out a preliminary evaluation with an industrial project, aiming to characterize the capability of the tool to handle SPL engineering in the Web systems domain.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {8},
keywords = {web systems domain, software product line engineering, feature oriented software development, feature composition, FeatureIDE, Eclipse plugin},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/2737182.2737183,
author = {Myll\"{a}rniemi, Varvana and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi},
title = {Representing and Configuring Security Variability in Software Product Lines},
year = {2015},
isbn = {9781450334709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2737182.2737183},
doi = {10.1145/2737182.2737183},
abstract = {In a software product line, security may need to be varied. Consequently, security variability must be managed both from the customer and product line architecture point of view. We utilize design science to build an artifact and a generalized design theory for representing and configuring security and functional variability from the requirements to the architecture in a configurable software product line. An open source web shop product line, Magento, is used as a case example to instantiate and evaluate the contribution. The results indicate that security variability can be represented and distinguished as countermeasures; and that a configurator tool is able to find consistent products as stable models of answer set programs.},
booktitle = {Proceedings of the 11th International ACM SIGSOFT Conference on Quality of Software Architectures},
pages = {1–10},
numpages = {10},
keywords = {variability, software product line, software architecture, security},
location = {Montr\'{e}al, QC, Canada},
series = {QoSA '15}
}

@inproceedings{10.1145/3141848.3141851,
author = {Assis, Guilherme and Vale, Gustavo and Figueiredo, Eduardo},
title = {Feature oriented programming in Groovy},
year = {2017},
isbn = {9781450355186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141848.3141851},
doi = {10.1145/3141848.3141851},
abstract = {Software Product Line (SPL) aims to reuse code and other artifacts in order to reduce costs and gain agility. Feature Oriented Programming (FOP) is a technique to develop SPLs that aims to improve the modularity and flexibility of feature code. The basic idea of FOP is to decompose software into smaller pieces, called features, so they can be composed according to the needs of each customer. Currently, Groovy programming language has no tool or framework that supports the implementation of FOP-SPLs. Groovy is a programming language that has been growing in popularity in recent years. Given this scenario, this work proposes and evaluates G4FOP, a light way to develop SPLs using Groovy. G4FOP extends FeatureHouse which is a framework for software composition and FOP. A preliminary evaluation shows that G4FOP covers Groovy grammar. We also demonstrate by an example that G4FOP is suitable to develop SPLs. G4FOP is currently integrated to the official FeatureHouse repository.},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Workshop on Feature-Oriented Software Development},
pages = {21–30},
numpages = {10},
keywords = {Software Product Line, Groovy, FeatureHouse, Feature Oriented Programming},
location = {Vancouver, BC, Canada},
series = {FOSD 2017}
}

@inproceedings{10.1145/2647908.2655969,
author = {ter Beek, Maurice H. and Mazzanti, Franco},
title = {VMC: recent advances and challenges ahead},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655969},
doi = {10.1145/2647908.2655969},
abstract = {The variability model checker VMC accepts a product family specified as a Modal Transition System (MTS) with additional variability constraints. Consequently, it offers behavioral variability analyses over both the family and its valid product behavior. This ranges from product derivation and simulation to efficient on-the-fly model checking of logical properties expressed in a variability-aware version of action-based CTL. In this paper, we first explain the reasons and assumptions underlying the choice for a modeling and analysis framework based on MTSs. Subsequently, we present recent advances on proving inheritance of behavioral analysis properties from a product family to its valid products. Finally, we illustrate challenges remaining for the future.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {70–77},
numpages = {8},
keywords = {product families, model checking, behavioral variability},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3474624.3476016,
author = {Bezerra, Carla and Lima, Rafael and Silva, Publio},
title = {DyMMer 2.0: A Tool for Dynamic Modeling and Evaluation of Feature Model},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3476016},
doi = {10.1145/3474624.3476016},
abstract = {Managing dynamic variability has motivated several researchers to combine Dynamic Software Product Lines (DSPLs) practices with runtime variability mechanisms. By combining these approaches, a DSPL acquires important features, ranging from the ability to reconfigure by changing the context, adding or removing features, crash recovery, and re-adaptation based on changes in the model’s features. Feature model (FM) is an important artifact of a DPSL and there is a lack of tools that support the modeling of this artifact. We have extended the DyMMer tool for modeling FM of DSPLs from an adaptation mechanism based on MAPE-K to solve this problem. We migrated the DyMMer tool to a web version and incorporated new features: (i) modeling of FMs from SPLs and DSPLs, (ii) development of an adaptation mechanism for FM of DSPLs, (iii) repository of FMs, (iv) inclusion of thresholds for measures, and (v) user authentication. We believe that this tool is useful for research in the area of DSPLs, and also for dynamic domain modeling and evaluation. Video: https://youtu.be/WVHW6bI8ois},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {121–126},
numpages = {6},
keywords = {Modeling, Feature Model, Dynamic Software Product Line},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.5555/1753235.1753245,
author = {Cetina, Carlos and Haugen, \O{}ystein and Zhang, Xiaorui and Fleurey, Franck and Pelechano, Vicente},
title = {Strategies for variability transformation at run-time},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {More and more approaches propose to use Software Product Lines (SPLs) modelling techniques to implement dynamic adaptive systems. The resulting Dynamic Software Product Lines (DSPLs) present new challenges since the variability transformations used to derive alternative configurations have to be intensively used at runtime. This paper proposes to use the Common Variability Language (CVL) for modelling runtime variability and evaluates a set of alternative strategies for implementing the associated variability transformations. All the proposed strategies have been implemented and evaluated on the case-study of a smart-home system. Results show that the proposed strategies provide the same reconfiguration service with significant differences in quality-of-service.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {61–70},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1016/j.jss.2008.07.046,
author = {Eriksson, Magnus and B\"{o}rstler, J\"{u}rgen and Borg, Kjell},
title = {Managing requirements specifications for product lines - An approach and industry case study},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {3},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2008.07.046},
doi = {10.1016/j.jss.2008.07.046},
abstract = {Software product line development has emerged as a leading approach for software reuse. This paper describes an approach to manage natural-language requirements specifications in a software product line context. Variability in such product line specifications is modeled and managed using a feature model. The proposed approach has been introduced in the Swedish defense industry. We present a multiple-case study covering two different product lines with in total eight product instances. These were compared to experiences from previous projects in the organization employing clone-and-own reuse. We conclude that the proposed product line approach performs better than clone-and-own reuse of requirements specifications in this particular industrial context.},
journal = {J. Syst. Softw.},
month = mar,
pages = {435–447},
numpages = {13},
keywords = {Variability management, Software product line, Natural-language requirements specification, Feature model}
}

@inproceedings{10.1145/2364412.2364441,
author = {Schroeter, Julia and Mucha, Peter and Muth, Marcel and Jugel, Kay and Lochau, Malte},
title = {Dynamic configuration management of cloud-based applications},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364441},
doi = {10.1145/2364412.2364441},
abstract = {Cloud-based applications are multi-tenant aware, whereas customers (i.e., tenants) share hardware and software resources. Offering highly configurable applications to thousands of tenants in a shared cloud environment demands for scalable configuration management. Based on an example scenario taken from the Indenica project, we identify requirements for applying methods from software product line (SPL) engineering to configure cloud-based multi-tenant aware applications. Using an extended feature model (EFM) to express variability of functionality and service qualities, we propose a concept for dynamic configuration management to address the identified requirements. Our proposed configuration management includes an adaptive staged configuration process that is capable of adding and removing stakeholders dynamically and that allows for reconfiguration of variants as stakeholders' objectives change.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {171–178},
numpages = {8},
keywords = {staged configuration, software engineering, software configuration management, software, multi-tenancy, extended feature model, cloud computing},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753270,
author = {Slegers, Walter J.},
title = {Building automotive product lines around managed interfaces},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {TomTom is extending its current business of portable navigation devices into the embedded automotive navigation domain. Portable navigation devices have a high pace of innovation and moderate diversity. Automotive devices traditionally have a slower pace of innovation and high diversity. Their integration in the vehicle needs to comply with formal and intrusive automotive requirements.How can both worlds be combined, offering an increased innovation and reduced lead time in the automotive domain? We introduced an architectural decoupling with explicit management of interfaces to support a product line approach with systematic reuse across business units enabling an increase of diversity in these different market segments.This paper describes business, architecture, organization, and process aspects of this approach with special attention to the architecture and the management of interfaces.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {257–264},
numpages = {8},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1016/j.jss.2014.08.034,
author = {Alsawalqah, Hamad I. and Kang, Sungwon and Lee, Jihyun},
title = {A method to optimize the scope of a software product platform based on end-user features},
year = {2014},
issue_date = {December 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.08.034},
doi = {10.1016/j.jss.2014.08.034},
abstract = {A novel method to optimize the scope of a software product platform is proposed.The method is supported with a mathematical formulation and an optimization solver.Depending on the input parameters and the objectives, competing scopes can exist.The method shows how trade-off analysis can be performed among competing scopes.The results of the method were validated as "satisfiable" to "very satisfiable". ContextDue to increased competition and the advent of mass customization, many software firms are utilizing product families - groups of related products derived from a product platform - to provide product variety in a cost-effective manner. The key to designing a successful software product family is the product platform, so it is important to determine the most appropriate product platform scope related to business objectives, for product line development. AimThis paper proposes a novel method to find the optimized scope of a software product platform based on end-user features. MethodThe proposed method, PPSMS (Product Platform Scoping Method for Software Product Lines), mathematically formulates the product platform scope selection as an optimization problem. The problem formulation targets identification of an optimized product platform scope that will maximize life cycle cost savings and the amount of commonality, while meeting the goals and needs of the envisioned customers' segments. A simulated annealing based algorithm that can solve problems heuristically is then used to help the decision maker in selecting a scope for the product platform, by performing tradeoff analysis of the commonality and cost savings objectives. ResultsIn a case study, PPSMS helped in identifying 5 non-dominated solutions considered to be of highest preference for decision making, taking into account both cost savings and commonality objectives. A quantitative and qualitative analysis indicated that human experts perceived value in adopting the method in practice, and that it was effective in identifying appropriate product platform scope.},
journal = {J. Syst. Softw.},
month = dec,
pages = {79–106},
numpages = {28},
keywords = {Software product line engineering, Product platform scope, Commonality decision}
}

@article{10.1016/j.cl.2016.09.004,
author = {M\'{e}ndez-Acu\~{n}a, David and Galindo, Jos\'{e} A. and Degueule, Thomas and Combemale, Beno\^{\i}t and Baudry, Beno\^{\i}t},
title = {Leveraging Software Product Lines Engineering in the development of external DSLs},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2016.09.004},
doi = {10.1016/j.cl.2016.09.004},
abstract = {The use of domain-specific languages (DSLs) has become a successful technique in the development of complex systems. Consequently, nowadays we can find a large variety of DSLs for diverse purposes. However, not all these DSLs are completely different; many of them share certain commonalities coming from similar modeling patterns - such as state machines or petri nets - used for several purposes. In this scenario, the challenge for language designers is to take advantage of the commonalities existing among similar DSLs by reusing, as much as possible, formerly defined language constructs. The objective is to leverage previous engineering efforts to minimize implementation from scratch. To this end, recent research in software language engineering proposes the use of product line engineering, thus introducing the notion of language product lines. Nowadays, there are several approaches that result useful in the construction of language product lines. In this article, we report on an effort for organizing the literature on language product line engineering. More precisely, we propose a definition for the life-cycle of language product lines, and we use it to analyze the capabilities of current approaches. In addition, we provide a mapping between each approach and the technological space it supports. HighlightsSurvey on the applicability of software product lines in the construction of DSLs.General life-cycle for language product lines.Mapping current approaches on language product lines and technological spaces.Research map in language product lines engineering.},
journal = {Comput. Lang. Syst. Struct.},
month = nov,
pages = {206–235},
numpages = {30},
keywords = {Variability management, Software language engineering, Software Product Lines Engineering, Domain-specific languages}
}

@article{10.1145/2853073.2853095,
author = {Alebrahim, Azadeh and Fa\ss{}bender, Stephan and Filipczyk, Martin and Goedicke, Michael and Heisel, Maritta and Zdun, Uwe},
title = {Variability for Qualities in Software Architecture},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853095},
doi = {10.1145/2853073.2853095},
abstract = {Variability is a key factor of most systems. While there are many works covering variability in functionality, there is a research gap regarding variability in software qualities. There is an obvious imbalance between the importance of variability in the context of quality attributes, and the intensity of research in this area. To improve this situation, the First International Workshop on VAri- ability for QUalIties in SofTware Architecture (VAQUITA) was held jointly with ECSA 2015 in Cavtat/Dubrovnik, Croatia as a one-day workshop. The goal of VAQUITA was to investigate and stimulate the discourse about the matter of variability, qualities, and software architectures. The workshop featured three research paper presentations, one keynote talk, and two working group discussions. In this workshop report, we summarize the keynote talk and the presented papers. Additionally, we present the results of the working group discussions},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {32–35},
numpages = {4},
keywords = {variability, quality attributes, Software architecture}
}

@article{10.1145/2580950,
author = {Th\"{u}m, Thomas and Apel, Sven and K\"{a}stner, Christian and Schaefer, Ina and Saake, Gunter},
title = {A Classification and Survey of Analysis Strategies for Software Product Lines},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2580950},
doi = {10.1145/2580950},
abstract = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {6},
numpages = {45},
keywords = {type checking, theorem proving, static analysis, software product line, software analysis, program family, model checking, Product-line analysis}
}

@article{10.1145/2501654.2501665,
author = {Hubaux, Arnaud and Tun, Thein Than and Heymans, Patrick},
title = {Separation of concerns in feature diagram languages: A systematic survey},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501665},
doi = {10.1145/2501654.2501665},
abstract = {The need for flexible customization of large feature-rich software systems, according to requirements of various stakeholders, has become an important problem in software development. Among the many software engineering approaches dealing with variability management, the notion of Software Product Line (SPL) has emerged as a major unifying concept. Drawing from established disciplines of manufacturing, SPL approaches aim to design repertoires of software artifacts, from which customized software systems for specific stakeholder requirements can be developed. A major difficulty SPL approaches attempt to address is the modularization of software artifacts, which reconciles the user's needs for certain features and the development and technical constraints. Towards this end, many SPL approaches use feature diagrams to describe possible configurations of a feature set. There have been several proposals for feature diagram languages with varying degrees of expressiveness, intuitiveness, and precision. However, these feature diagram languages have limited scalability when applied to realistic software systems. This article provides a systematic survey of various concerns of feature diagrams and ways in which concerns have been separated. The survey shows how the uncertainty in the purpose of feature diagram languages creates both conceptual and practical limitations to scalability of those languages.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {51},
numpages = {23},
keywords = {variability, separation of concerns, feature diagram, Software product line}
}

@inproceedings{10.1007/978-3-030-64694-3_11,
author = {Abbas, Muhammad and Saadatmand, Mehrdad and Enoiu, Eduard and Sundamark, Daniel and Lindskog, Claes},
title = {Automated Reuse Recommendation of Product Line Assets Based on Natural Language Requirements},
year = {2020},
isbn = {978-3-030-64693-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64694-3_11},
doi = {10.1007/978-3-030-64694-3_11},
abstract = {Software product lines (SPLs) are based on reuse rationale to aid quick and quality delivery of complex products at scale. Deriving a new product from a product line requires reuse analysis to avoid redundancy and support a high degree of assets reuse. In this paper, we propose and evaluate automated support for recommending SPL assets that can be reused to realize new customer requirements. Using the existing customer requirements as input, the approach applies natural language processing and clustering to generate reuse recommendations for unseen customer requirements in new projects. The approach is evaluated both quantitatively and qualitatively in the railway industry. Results show that our approach can recommend reuse with 74% accuracy and 57.4% exact match. The evaluation further indicates that the recommendations are relevant to engineers and can support the product derivation and feasibility analysis phase of the projects. The results encourage further study on automated reuse analysis on other levels of abstractions.},
booktitle = {Reuse in Emerging Software Engineering Practices: 19th International Conference on Software and Systems Reuse, ICSR 2020, Hammamet, Tunisia, December 2–4, 2020, Proceedings},
pages = {173–189},
numpages = {17},
keywords = {Word embedding, Natural language processing, Reuse recommender, Software product line},
location = {Hammamet, Tunisia}
}

@inproceedings{10.5220/0006791403830391,
author = {Aouzal, Khadija and Hafiddi, Hatim and Dahchour, Mohamed},
title = {Handling Tenant-Specific Non-Functional Requirements through a Generic SLA},
year = {2018},
isbn = {9789897583001},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0006791403830391},
doi = {10.5220/0006791403830391},
abstract = {In a multi-tenant architecture of a Software as a Service (SaaS) application, one single instance is shared amongdifferent tenants. However, this architectural style supports only the commonalities among tenants and doesnot cope with the variations and the specific context of each tenant. These variations concern either functionalor non-functional properties. In this paper, we deal with non-functional variability in SaaS services in orderto support the different quality levels that a service may have. For that purpose, we propose an approachthat considers Service Level Agreements (SLAs) as Families in terms of Software Product Line Engineering.We define two metamodels: NFVariability metamodel and VariableSLA metamodel. The first one modelsand captures variability in quality attributes of services. The second one models a dynamic and variableSLA. Model-to-model transformations are performed to transform Feature Model (NFVariability metamodelinstance) to Generic SLA (VariableSLA instance) in order to dynamically deal with the tenant-specific nonfunctionalrequirements.},
booktitle = {Proceedings of the 13th International Conference on Evaluation of Novel Approaches to Software Engineering},
pages = {383–391},
numpages = {9},
keywords = {SaaS, SPLE, SLA., QoS Characteristics, Non-Functional Variability, MDE},
location = {Funchal, Madeira, Portugal},
series = {ENASE 2018}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00123,
author = {Le, Viet-Man},
title = {Group recommendation techniques for feature modeling and configuration},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00123},
doi = {10.1109/ICSE-Companion52605.2021.00123},
abstract = {In large-scale feature models, feature modeling and configuration processes are highly expected to be done by a group of stakeholders. In this context, recommendation techniques can increase the efficiency of feature-model design and find optimal configurations for groups of stakeholders. Existing studies show plenty of issues concerning feature model navigation support, group members' satisfaction, and conflict resolution. This study proposes group recommendation techniques for feature modeling and configuration on the basis of addressing the mentioned issues.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {266–268},
numpages = {3},
keywords = {software product line, group-based recommendation, group decision making, feature models, configuration},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/2019136.2019144,
author = {Scholz, Wolfgang and Th\"{u}m, Thomas and Apel, Sven and Lengauer, Christian},
title = {Automatic detection of feature interactions using the Java modeling language: an experience report},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019144},
doi = {10.1145/2019136.2019144},
abstract = {In the development of complex software systems, interactions between different program features increase the design complexity. Feature-oriented software development focuses on the representation and compositions of features. The implementation of features often cuts across object-oriented module boundaries and hence comprises interactions. The manual detection and treatment of feature interactions requires a deep knowledge of the implementation details of the features involved. Our goal is to detect interactions automatically using specifications by means of design by contract and automated theorem proving. We provide a software tool that operates on programs in Java and the Java Modeling Language (JML). We discuss which kinds of feature interactions can be detected automatically with our tool and how to detect other kinds of interactions.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {7},
numpages = {8},
keywords = {software product lines, feature interaction, JML, FeatureHouse},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2019136.2019146,
author = {Gerlach, Simon},
title = {Improving efficiency when deriving numerous products from software product lines simultaneously},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019146},
doi = {10.1145/2019136.2019146},
abstract = {In-car infotainment systems must allow for product differentiation and the adaption to the needs of different markets. Product line approaches are applied because large numbers of different product variants need to be developed simultaneously. During development, updated versions of each projected product variant need to be derived from the product line assets repeatedly. Current build tools create each of the numerous product variants one after another. Accordingly, the creation process can take much time. This paper presents an approach to abbreviate this creation process based on the fact that multiple product variants created at once can have parts in common. To benefit from this optimization potential the workflow that creates an individual product variant is subdivided into multiple fragments. Whenever a set of such product variants needs to be created, an optimization algorithm then calculates an individual execution order of the fragments for this set. This order minimizes the total execution time by a systematic reuse of workflow fragment's results for the creation of multiple different product variants.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {9},
numpages = {4},
keywords = {software product lines, product derivation, product configuration, automotive, application engineering},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2647908.2655981,
author = {Acher, Mathieu and Alf\'{e}rez, Mauricio and Galindo, Jos\'{e} A. and Romenteau, Pierre and Baudry, Benoit},
title = {ViViD: a variability-based tool for synthesizing video sequences},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655981},
doi = {10.1145/2647908.2655981},
abstract = {We present ViViD, a variability-based tool to synthesize variants of video sequences. ViViD is developed and used in the context of an industrial project involving consumers and providers of video processing algorithms. The goal is to synthesize synthetic video variants with a wide range of characteristics to then test the algorithms. We describe the key components of ViViD (1) a variability language and an environment to model what can vary within a video sequence; (2) a reasoning back-end to generate relevant testing configurations; (3) a video synthesizer in charge of producing variants of video sequences corresponding to configurations. We show how ViViD can synthesize realistic videos with different characteristics such as luminances, vehicles and persons that cover a diversity of testing scenarios.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {143–147},
numpages = {5},
keywords = {video generation, variability modeling, prioritization, multimedia, combinatorial interaction testing, T-wise},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/1621607.1621633,
author = {Sanen, Frans and Truyen, Eddy and Joosen, Wouter},
title = {Mapping problem-space to solution-space features: a feature interaction approach},
year = {2009},
isbn = {9781605584942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1621607.1621633},
doi = {10.1145/1621607.1621633},
abstract = {Mapping problem-space features into solution-space features is a fundamental configuration problem in software product line engineering. A configuration problem is defined as generating the most optimal combination of software features given a requirements specification and given a set of configuration rules. Current approaches however provide little support for expressing complex configuration rules between problem and solution space that support incomplete requirements specifications. In this paper, we propose an approach to model complex configuration rules based on a generalization of the concept of problem-solution feature interactions. These are interactions between solution-space features that only arise in specific problem contexts. The use of an existing tool to support our approach is also discussed: we use the DLV answer set solver to express a particular configuration problem as a logic program whose answer set corresponds to the optimal combinations of solution-space features. We motivate and illustrate our approach with a case study in the field of managing dynamic adaptations in distributed software, where the goal is to generate an optimal protocol for accommodating a given adaptation.},
booktitle = {Proceedings of the Eighth International Conference on Generative Programming and Component Engineering},
pages = {167–176},
numpages = {10},
keywords = {software product line engineering, problem-solution feature interactions, distributed runtime adaptation, default logic, configuration knowledge, DLV},
location = {Denver, Colorado, USA},
series = {GPCE '09}
}

@inproceedings{10.5555/1753235.1753269,
author = {Stoll, Pia and Bass, Len and Golden, Elspeth and John, Bonnie E.},
title = {Supporting usability in product line architectures},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {This paper addresses the problem of supporting usability in the early stages of a product line architecture design. The product line used as an example is intended to support a variety of different products each with a radically different user interface. The development cycles for new products varies between three years and five years and usability is valued as an important quality attribute for each product in the line.Traditionally, usability is achieved in a product by designing according to specific usability guidelines, and then performing user tests. User interface design can be performed separately from software architecture design and prototyping, but user tests cannot be performed before detailed UI design and prototyping. If the user tests discover usability problems leading to required architectural changes, the company would not know about this until two years after the architecture design was complete. This problem was addressed by identifying a collection of 19 well known usability scenarios that require architectural support. In our example, the stakeholders for the product line prioritized three of these scenarios as key product-line scenarios for improving usability. For each of these three chosen product-line scenarios we developed an architectural responsibility pattern that provided support for the scenario. The responsibilities are expressed in terms of architectural requirements with implementation details and rationales. The responsibilities were embodied in a web based tool for the architects.The two architects for the product line developed a preliminary design and then reviewed their design against the responsibilities supporting the scenarios. The process of review took a day and the architects conservatively estimated that it saved them five weeks of effort later in the project.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {241–248},
numpages = {8},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3442391.3442407,
author = {Sree-Kumar, Anjali and Planas, Elena and Claris\'{o}, Robert},
title = {Validating Feature Models With Respect to Textual Product Line Specifications},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442407},
doi = {10.1145/3442391.3442407},
abstract = {Feature models (FM) are a valuable resource in the analysis of software product lines (SPL). They provide a visual abstraction of the variation points in a family of related software products. FMs can be manually created by domain experts or extracted (semi-) automatically from textual documents such as product descriptions or requirements specifications. Nevertheless, there is no way to measure the accuracy of a FM with respect to the information described in the source documents. This paper proposes a method to quantify and visualize whether the elements in a FM (features and relationships) conform to the information available in a set of specification documents. Both the correctness (choice of representative elements) and completeness (no missing elements) of the FM are considered. Designers can use this feedback to fix defects in the FM or to detect incomplete or inconsistent information in the source documents.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {10},
keywords = {Software Product Line, Requirements Engineering, Natural Language Processing, Machine Learning, Feature Model Validation},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.1145/3483899.3483905,
author = {Freire, Willian and Tonh\~{a}o, Simone and Bonetti, Tiago and Shigenaga, Marcelo and Cadette, William and Felizardo, Fernando and Amaral, Aline and OliveiraJr, Edson and Colanzi, Thelma},
title = {On the configuration of multi-objective evolutionary algorithms for PLA design optimization},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483905},
doi = {10.1145/3483899.3483905},
abstract = {Search-based algorithms have been successfully applied in the Product Line Architecture (PLA) optimization using the seminal approach called Multi-Objective Approach for Product-Line Architecture Design (MOA4PLA). This approach produces a set of alternative PLA designs intending to improve the different factors being optimized. Currently, the MOA4PLA uses the NSGA-II algorithm, a multi-objective evolutionary algorithm (MOEA) that can optimize several architectural properties simultaneously. Despite the promising results, studying the best values for the algorithm parameters is essential to obtain even better results. This is also crucial to ease the adoption of MOA4PLA by newcomers or non-expert companies willing to start using search-based software engineering to PLA design. Three crossover operators for the PLA design optimization were proposed recently. However, reference values for parameters have not been defined for PLA design optimization using crossover operators. In this context, the objective of this work is conducting an experimental study to discover which are the most effective crossover operators and the best values to configure the MOEA parameters, such as population size, number of generations, and mutation and crossover rates. A quantitative analysis based on quality indicators and statistical tests was performed using four PLA designs to determine the most suitable parameter values to the search-based algorithm. Empirical results pointed out the best combination of crossover operators and the most suitable values to configure MOA4PLA.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {11–20},
numpages = {10},
keywords = {software product line, software architecture, recombination operators, Multi-objective evolutionary algorithm},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/2771783.2771808,
author = {Tan, Tian Huat and Xue, Yinxing and Chen, Manman and Sun, Jun and Liu, Yang and Dong, Jin Song},
title = {Optimizing selection of competing features via feedback-directed evolutionary algorithms},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771808},
doi = {10.1145/2771783.2771808},
abstract = {Software that support various groups of customers usually require complicated configurations to attain different functionalities. To model the configuration options, feature model is proposed to capture the commonalities and competing variabilities of the product variants in software family or Software Product Line (SPL). A key challenge for deriving a new product is to find a set of features that do not have inconsistencies or conflicts, yet optimize multiple objectives (e.g., minimizing cost and maximizing number of features), which are often competing with each other. Existing works have attempted to make use of evolutionary algorithms (EAs) to address this problem. In this work, we incorporated a novel feedback-directed mechanism into existing EAs. Our empirical results have shown that our method has improved noticeably over all unguided version of EAs on the optimal feature selection. In particular, for case studies in SPLOT and LVAT repositories, the feedback-directed Indicator-Based EA (IBEA) has increased the number of correct solutions found by 72.33% and 75%, compared to unguided IBEA. In addition, by leveraging a pre-computed solution, we have found 34 sound solutions for Linux X86, which contains 6888 features, in less than 40 seconds.},
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {246–256},
numpages = {11},
keywords = {evolutionary algorithms, Software product line, SAT solvers},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@inproceedings{10.5220/0004973404600465,
author = {Florencio da Silva, Jackson Raniel and Soares de Melo Filho, Aloisio and Cardoso Garcia, Vinicius},
title = {Toward a QoS Based Run-time Reconfiguration in Service-oriented Dynamic Software Product Lines},
year = {2014},
isbn = {9789897580284},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0004973404600465},
doi = {10.5220/0004973404600465},
abstract = {Ford invented the product line that makes possible to mass produce by reducing the delivery time and production costs. Regarding the software industry, this, roughly presents both a manufacturing and mass production that generates products that are denoted as individual software and standard software (Pohl et al., 2005): a clear influence of Fordism in the development paradigm of Software Product Lines (SPL). However, this development paradigm was not designed to support user requirements changes at run-time. Faced with this problem, the academy has developed and proposed the Dynamic Software Product Lines (DSPL) (Hallsteinsen et al., 2008) paradigm. Considering this scenario, we objective contribute to DSPL field presenting a new way of thinking which DSPL features should be connected at run-time to a product based on an analysis of quality attributes in service levels specified by the user. In order to validate the proposed approach we tested it on a context-aware DSPL. At the end of the exploratory validation we can observe the effectiveness of the proposed approach in the DSPL which it was applied. However, it is necessary to perform another studies in order to achieve statistical evidences of this effectiveness.},
booktitle = {Proceedings of the 16th International Conference on Enterprise Information Systems - Volume 2},
pages = {460–465},
numpages = {6},
keywords = {Software Product Line, SPL, SOA, Dynamic Software Product Line., DSPL},
location = {Lisbon, Portugal},
series = {ICEIS 2014}
}

@inproceedings{10.5555/1753235.1753261,
author = {K\"{a}stner, Christian and Apel, Sven and ur Rahman, Syed Saif and Rosenm\"{u}ller, Marko and Batory, Don and Saake, Gunter},
title = {On the impact of the optional feature problem: analysis and case studies},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {A software product line is a family of related programs that are distinguished in terms of features. A feature implements a stakeholders' requirement. Different program variants specified by distinct feature selections are produced from a common code base. The optional feature problem describes a common mismatch between variability intended in the domain and dependencies in the implementation. When this situation occurs, some variants that are valid in the domain cannot be produced due to implementation issues. There are many different solutions to the optional feature problem, but they all suffer from drawbacks such as reduced variability, increased development effort, reduced efficiency, or reduced source code quality. We examine the impact of the optional feature problem in two case studies from the domain of embedded database systems, and we survey different state-of-the-art solutions and their trade-offs. Our intension is to raise awareness of the problem, to guide developers in selecting an appropriate solution for their product line, and to identify opportunities for future research.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {181–190},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1016/j.jss.2018.07.054,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Juliana, Alves Pereira and Castro, Harold and Saake, Gunter},
title = {A systematic literature review on the semi-automatic configuration of extended product lines},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.07.054},
doi = {10.1016/j.jss.2018.07.054},
journal = {J. Syst. Softw.},
month = oct,
pages = {511–532},
numpages = {22},
keywords = {Systematic literature review, Product configuration, Extended product line}
}

@article{10.1145/3389397,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Pattern-based Interactive Configuration Derivation for Cyber-physical System Product Lines},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {2378-962X},
url = {https://doi.org/10.1145/3389397},
doi = {10.1145/3389397},
abstract = {Deriving a Cyber-Physical System (CPS) product from a product line requires configuring hundreds to thousands of configurable parameters of components and devices from multiple domains, e.g., computing, control, and communication. A fully automated configuration process for a CPS product line is seldom possible in practice, and a dynamic and interactive process is expected. Therefore, some configurable parameters are to be configured manually, and the rest can be configured either automatically or manually, depending on pre-defined constraints, the order of configuration steps, and previous configuration data in such a dynamic and interactive configuration process. In this article, we propose a pattern-based, interactive configuration derivation methodology (named as Pi-CD) to maximize opportunities of automatically deriving correct configurations of CPSs by benefiting from pre-defined constraints and configuration data of previous configuration steps. Pi-CD requires architectures of CPS product lines modeled with Unified Modeling Language extended with four types of variabilities, along with constraints specified in Object Constraint Language (OCL). Pi-CD is equipped with 324 configuration derivation patterns that we defined by systematically analyzing the OCL constructs and semantics. We evaluated Pi-CD by configuring 20 CPS products of varying complexity from two real-world CPS product lines. Results show that Pi-CD can achieve up to 72% automation degree with a negligible time cost. Moreover, its time performance remains stable with the increase in the number of configuration parameters as well as constraints.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jun,
articleno = {44},
numpages = {24},
keywords = {product configuration, object constraint language, configuration derivation, Product line engineering}
}

@inproceedings{10.1145/2647908.2655958,
author = {Eichelberger, Holger and Schmid, Klaus},
title = {Resource-optimizing adaptation for big data applications},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655958},
doi = {10.1145/2647908.2655958},
abstract = {The resource requirements of Big Data applications may vary dramatically over time, depending on changes in the context. If resources should not be defined for the maximum case, but available resources are mostly static, there is a need to adapt resource usage by modifying the processing behavior. The QualiMaster project researches such an approach for the analysis of systemic risks in the financial markets.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {10–11},
numpages = {2},
keywords = {systematic-risks, stream-processing, resource adaptation, financial markets, adaptive systems, QualiMaster},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/1985484.1985486,
author = {Kulkarni, Vinay},
title = {Use of SPLE to deliver custom solutions at product cost: challenges and a way forward},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985486},
doi = {10.1145/1985484.1985486},
abstract = {Need for adaptiveness of business applications is on the rise with continued increase in business dynamics. Ground-up development techniques neither deliver nor can scale in this dynamic situation. Software Product Line Engineering (SPLE) aims to increase adaptiveness by capturing commonality and variability up front to suitably configure the application from its parts. Code-centric SPLE techniques show unacceptable responsiveness when business applications are subjected to changes along multiple simultaneously evolving dimensions. Using clear separation of functional concerns from implementation platform, model driven approaches enable easy delivery of the same functionality into multiple technology platforms. However, business applications exhibit variability in several dimensions such as functionality, business process, design decisions, architecture, and technology platform. We argue that SPLE techniques need to be elevated to a higher level of abstraction to enable them to work in unison with model-driven techniques in order to realize the desired adaptiveness along all these dimensions. We have been delivering large business applications using model-driven techniques for past 15 years. In this paper, we have outlined several key challenges that we faced in adopting SPLE and presented tenets of a solution that is likely to have greater acceptance by industry practice.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {1–5},
numpages = {5},
keywords = {software product line, model-driven engineering},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@inproceedings{10.1109/SPLC.2008.37,
author = {Etxeberria, Leire and Sagardui, Goiuria},
title = {Variability Driven Quality Evaluation in Software Product Lines},
year = {2008},
isbn = {9780769533032},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2008.37},
doi = {10.1109/SPLC.2008.37},
abstract = {Variability is a key aspect in software product lines. Functional variability has been largely studied as a way to obtain all the desired products for a line. Quality variability, less understood and more complex, has not received so much attention by researchers. However, different members of the line may require different levels of a quality attribute. The design phase is a good point to assure that quality attributes requirements are met within the product line so this means paying attention to software architecture evaluation during Domain Engineering. The quality evaluation in software product lines is much more complicated than in single-systems as products can require different quality levels and the product line can have variability on design that in turn affects quality. The evaluation of all the products of a line is very expensive. Thus, ways of reducing the evaluation efforts are necessary. Herein is presented a method for facilitating cost-effective quality evaluation of a product line taking into consideration variability on quality attributes.},
booktitle = {Proceedings of the 2008 12th International Software Product Line Conference},
pages = {243–252},
numpages = {10},
keywords = {variability, evaluation, Quality attributes},
series = {SPLC '08}
}

@inproceedings{10.1145/2361999.2362028,
author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
title = {Modeling variability in product lines using domain quality attribute scenarios},
year = {2012},
isbn = {9781450315685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2361999.2362028},
doi = {10.1145/2361999.2362028},
abstract = {The concept of variability is fundamental in software product lines and a successful implementation of a product line largely depends on how well domain requirements and their variability are specified, managed, and realized. While developing an educational software product line, we identified a lack of support to specify variability in quality concerns. To address this problem we propose an approach to model variability in quality concerns, which is an extension of quality attribute scenarios. In particular, we propose domain quality attribute scenarios, which extend standard quality attribute scenarios with additional information to support specification of variability and deriving product specific scenarios. We demonstrate the approach with scenarios for robustness and upgradability requirements in the educational software product line.},
booktitle = {Proceedings of the WICSA/ECSA 2012 Companion Volume},
pages = {135–142},
numpages = {8},
keywords = {variability, software product lines, scenarios, quality attributes},
location = {Helsinki, Finland},
series = {WICSA/ECSA '12}
}

@article{10.1016/j.jksuci.2016.01.005,
author = {Ma\^{a}zoun, Jihen and Bouassida, Nadia and Ben-Abdallah, Han\^{e}ne},
title = {Change impact analysis for software product lines},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {28},
number = {4},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2016.01.005},
doi = {10.1016/j.jksuci.2016.01.005},
abstract = {A software product line (SPL) represents a family of products in a given application domain. Each SPL is constructed to provide for the derivation of new products by covering a wide range of features in its domain. Nevertheless, over time, some domain features may become obsolete with the apparition of new features while others may become refined. Accordingly, the SPL must be maintained to account for the domain evolution. Such evolution requires a means for managing the impact of changes on the SPL models, including the feature model and design. This paper presents an automated method that analyzes feature model evolution, traces their impact on the SPL design, and offers a set of recommendations to ensure the consistency of both models. The proposed method defines a set of new metrics adapted to SPL evolution to identify the effort needed to maintain the SPL models consistently and with a quality as good as the original models. The method and its tool are illustrated through an example of an SPL in the Text Editing domain. In addition, they are experimentally evaluated in terms of both the quality of the maintained SPL models and the precision of the impact change management.},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = oct,
pages = {364–380},
numpages = {17},
keywords = {Software product line, Model evolution, Feature model, Change impact management}
}

@inproceedings{10.1145/3425269.3425276,
author = {Silva, Publio and Bezerra, Carla I. M. and Lima, Rafael and Machado, Ivan},
title = {Classifying Feature Models Maintainability based on Machine Learning Algorithms},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425276},
doi = {10.1145/3425269.3425276},
abstract = {Maintenance in the context of SPLs is a topic of interest, and that still needs further investigation. There are several ways to evaluate the maintainability of a feature model (FM), one of which is a manual or automated analysis of quality measures. However, the use of measures does not allow to evaluate the FM quality as a whole, as each measure considers a specific characteristic of FM. In general, the measures have wide ranges of values and do not have a clear definition of what is appropriate and inappropriate. In this context, the goal of this work is to investigate the use of machine learning techniques to classify the feature model maintainability. The research questions investigated in the study were: (i) how could machine learning techniques aid to classify FMs maintainability; and, (ii) which FM classification model has the best accuracy and precision. In this work, we proposed an approach for FM maintainability classification using machine learning technics. For that, we used a dataset of 15 FM maintainability measures calculated for 326 FMs, and we used machine learning algorithms to clustering. After this, we used thresholds to evaluate the general maintainability of each cluster. With this, we built 5 maintainability classification models that have been evaluated with the accuracy and precision metrics.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@inproceedings{10.1145/2110147.2110157,
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
title = {Managing SAT inconsistencies with HUMUS},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110157},
doi = {10.1145/2110147.2110157},
abstract = {In Product Line Engineering, as in any other modeling domain, designers and end users are prone to making inconsistent assumptions (errors) because of complexity and lack of system knowledge. We previously envisioned a way of allowing inconsistencies during product configuration and in this paper we present a solution on how to realize this vision. We introduce HUMUS (High-level Union of Minimal Unsatisfiable Sets), which enables correct reasoning in product line engineering (encoded in SAT) despite the presence of errors. We focus mainly on tolerating inconsistencies during product configuration, to make it possible to resolve inconsistencies later without misguiding the human user along the way. We also provide a discussion of other applications in product line engineering and beyond. The main advantage of using HUMUS is, that it is possible to isolate erroneous parts of a product line model such that existing automations continue to be useful. The applications of HUMUS are thus likely beyond product line engineering.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {83–91},
numpages = {9},
keywords = {user guidance, product line engineering, formal reasoning},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@article{10.4018/jismd.2012100101,
author = {Asadi, Mohsen and Mohabbati, Bardia and Ga\v{s}evic, Dragan and Bagheri, Ebrahim and Hatala, Marek},
title = {Developing Semantically-Enabled Families of Method-Oriented Architectures},
year = {2012},
issue_date = {October 2012},
publisher = {IGI Global},
address = {USA},
volume = {3},
number = {4},
issn = {1947-8186},
url = {https://doi.org/10.4018/jismd.2012100101},
doi = {10.4018/jismd.2012100101},
abstract = {Method Engineering ME aims to improve software development methods by creating and proposing adaptation frameworks whereby methods are created to provide suitable matches with the requirements of the organization and address project concerns and fit specific situations. Therefore, methods are defined and modularized into components stored in method repositories. The assembly of appropriate methods depends on the particularities of each project, and rapid method construction is inevitable in the reuse and management of existing methods. The ME discipline aims at providing engineering capability for optimizing, reusing, and ensuring flexibility and adaptability of methods; there are three key research challenges which can be observed in the literature: 1 the lack of standards and tooling support for defining, publishing, discovering, and retrieving methods which are only locally used by their providers without been largely adapted by other organizations; 2 dynamic adaptation and assembly of methods with respect to imposed continuous changes or evolutions of the project lifecycle; and 3 variability management in software methods in order to enable rapid and effective construction, assembly and adaptation of existing methods with respect to particular situations. The authors propose semantically-enabled families of method-oriented architecture by applying service-oriented product line engineering principles and employing Semantic Web technologies.},
journal = {Int. J. Inf. Syst. Model. Des.},
month = oct,
pages = {1–26},
numpages = {26},
keywords = {Software Product Line, Software Development, Semantic Web, Method Oriented Architecture MOA, Method Engineering}
}

@inproceedings{10.1109/SPLC.2011.18,
author = {Muller, Johannes},
title = {Value-Based Portfolio Optimization for Software Product Lines},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.18},
doi = {10.1109/SPLC.2011.18},
abstract = {Software Product Lines are a mean to improve the economic performance of firms that offer several products to a market by systematically reusing software artifacts. In most cases the definitive company goal is profit maximization. That can be reached by increasing revenue or by reducing cost. Revenue is increased by offering products with a wide variety of features to an audience willing to pay. However, the fewer features are realized the fewer cost incur. Hence, a firm may ask what features are most important to realize. We approach this question by introducing Value-Based Portfolio Optimization as an addition to common Product Portfolio Scoping approaches that helps deciding on this question.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {15–24},
numpages = {10},
keywords = {Software Product Line, Scoping, Portfolio, Optimization, Economic Model},
series = {SPLC '11}
}

@article{10.1016/j.jss.2010.01.048,
author = {Lee, Jaejoon and Muthig, Dirk and Naab, Matthias},
title = {A feature-oriented approach for developing reusable product line assets of service-based systems},
year = {2010},
issue_date = {July, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {7},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2010.01.048},
doi = {10.1016/j.jss.2010.01.048},
abstract = {Service orientation (SO) is a relevant promising candidate for accommodating rapidly changing user needs and expectations. One of the goals of adopting SO is the improvement of reusability, however, the development of service-based system in practice has uncovered several challenging issues, such as how to identify reusable services, how to determine configurations of services that are relevant to users' current product configuration and context, and how to maintain service validity after configuration changes. In this paper, we propose a method that addresses these issues by adapting a feature-oriented product line engineering approach. The method is notable in that it guides developers to identify reusable services at the right level of granularity and to map users' context to relevant service configuration, and it also provides a means to check the validity of services at runtime in terms of invariants and pre/post-conditions of services. Moreover, we propose a heterogeneous style based architecture model for developing such systems.},
journal = {J. Syst. Softw.},
month = jul,
pages = {1123–1136},
numpages = {14},
keywords = {Software product line engineering, Software architecture styles, Software architecture, Service-based systems, Feature-oriented}
}

@inproceedings{10.1145/2499777.2500722,
author = {ter Beek, Maurice H. and Lafuente, Alberto Lluch and Petrocchi, Marinella},
title = {Combining declarative and procedural views in the specification and analysis of product families},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500722},
doi = {10.1145/2499777.2500722},
abstract = {We introduce the feature-oriented language FLan as a proof of concept for specifying both declarative aspects of product families, namely constraints on their features, and procedural aspects, namely feature configuration and run-time behaviour. FLan is inspired by the concurrent constraint programming paradigm. A store of constraints allows one to specify in a declarative way all common constraints on features, including inter-feature constraints. A standard yet rich set of process-algebraic operators allows one to specify in a procedural way the configuration and behaviour of products. There is a close interaction between both views: (i) the execution of a process is constrained by its store to forbid undesired configurations; (ii) a process can query a store to resolve design and behavioural choices; (iii) a process can update the store by adding new features. An implementation in the Maude framework allows for a variety of formal automated analyses of product families specified in FLan, ranging from consistency checking to model checking.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {10–17},
numpages = {8},
keywords = {variability, product families, process algebra, concurrent constraint programming, behavioural analyses, Maude},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2814251.2814263,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Th\"{u}m, Thomas},
title = {Using decision rules for solving conflicts in extended feature models},
year = {2015},
isbn = {9781450336864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814251.2814263},
doi = {10.1145/2814251.2814263},
abstract = {Software Product Line Engineering has introduced feature modeling as a domain analysis technique used to represent the variability of software products and decision-making scenarios. We present a model-based transformation approach to solve conflicts among configurations performed by different stakeholders on feature models. We propose the usage of a domain-specific language named CoCo to specify attributes as non-functional properties of features, and to describe business-related decision rules in terms of costs, time, and human resources. These specifications along with the stakeholders' configurations and the feature model are transformed into a constraint programming problem, on which decision rules are executed to find a non-conflicting set of solution configurations that are aligned to business objectives. We evaluate CoCo's compositionality and model complexity simplification while using a set of motivating decision scenarios.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {149–160},
numpages = {12},
keywords = {model transformation chain, extended feature model, domain-specific language, constraint satisfaction problem, conflicting configurations, Domain engineering},
location = {Pittsburgh, PA, USA},
series = {SLE 2015}
}

@article{10.1016/j.eswa.2015.02.020,
author = {Dermeval, Diego and Ten\'{o}rio, Thyago and Bittencourt, Ig Ibert and Silva, Alan and Isotani, Seiji and Ribeiro, M\'{a}rcio},
title = {Ontology-based feature modeling},
year = {2015},
issue_date = {July 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {11},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.02.020},
doi = {10.1016/j.eswa.2015.02.020},
abstract = {We compare two ontology-based feature modeling styles by conducting an experiment.The results show that ontology factor has statistical significance in all metrics.The results show that the ontology based on instances is more flexible.The results show that the ontology based on instances demands less time to change. A software product line (SPL) is a set of software systems that have a particular set of common features and that satisfy the needs of a particular market segment or mission. Feature modeling is one of the key activities involved in the design of SPLs. The feature diagram produced in this activity captures the commonalities and variabilities of SPLs. In some complex domains (e.g., ubiquitous computing, autonomic systems and context-aware computing), it is difficult to foresee all functionalities and variabilities a specific SPL may require. Thus, Dynamic Software Product Lines (DSPLs) bind variation points at runtime to adapt to fluctuations in user needs as well as to adapt to changes in the environment. In this context, relying on formal representations of feature models is important to allow them to be automatically analyzed during system execution. Among the mechanisms used for representing and analyzing feature models, description logic (DL) based approaches demand to be better investigated in DSPLs since it provides capabilities, such as automated inconsistency detection, reasoning efficiency, scalability and expressivity. Ontology is the most common way to represent feature models knowledge based on DL reasoners. Previous works conceived ontologies for feature modeling either based on OWL classes and properties or based on OWL individuals. However, considering change or evolution scenarios of feature models, we need to compare whether a class-based or an individual-based feature modeling style is recommended to describe feature models to support SPLs, and especially its capabilities to deal with changes in feature models, as required by DSPLs. In this paper, we conduct a controlled experiment to empirically compare two approaches based on each one of these modeling styles in several changing scenarios (e.g., add/remove mandatory feature, add/remove optional feature and so on). We measure time to perform changes, structural impact of changes (flexibility) and correctness for performing changes in our experiment. Our results indicate that using OWL individuals requires less time to change and is more flexible than using OWL classes and properties. These results provide insightful assumptions towards the definition of an approach relying on reasoning capabilities of ontologies that can effectively support products reconfiguration in the context of DSPL.},
journal = {Expert Syst. Appl.},
month = jul,
pages = {4950–4964},
numpages = {15},
keywords = {Software product line, Ontology, Feature modeling, Empirical software engineering}
}

@inproceedings{10.1007/978-3-030-39197-3_14,
author = {Shahin, Ramy and Chechik, Marsha},
title = {Variability-Aware Datalog},
year = {2020},
isbn = {978-3-030-39196-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39197-3_14},
doi = {10.1007/978-3-030-39197-3_14},
abstract = {Variability-aware computing is the efficient application of programs to different sets of inputs that exhibit some variability. One example is program analyses applied to Software Product Lines (SPLs). In this paper we present the design and development of a variability-aware version of the Souffl\'{e} Datalog engine. The engine can take facts annotated with Presence Conditions (PCs) as input, and compute the PCs of its inferred facts, eliminating facts that do not exist in any valid configuration. We evaluate our variability-aware Souffl\'{e} implementation on several fact sets annotated with PCs to measure the associated overhead in terms of processing time and database size.},
booktitle = {Practical Aspects of Declarative Languages: 22nd International Symposium, PADL 2020, New Orleans, LA, USA, January 20–21, 2020, Proceedings},
pages = {213–221},
numpages = {9},
keywords = {Souffl\'{e}, Product-line engineering, Variability-aware programming},
location = {New Orleans, LA, USA}
}

@inproceedings{10.1109/HICSS.2015.632,
author = {Kolassa, Carsten and Rendel, Holger and Rumpe, Bernhard},
title = {Evaluation of Variability Concepts for Simulink in the Automotive Domain},
year = {2015},
isbn = {9781479973675},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2015.632},
doi = {10.1109/HICSS.2015.632},
abstract = {Modeling variability in Matlab/Simulink becomes more and more important. We took the two variability modeling concepts already included in Matlab/Simulink and our own one and evaluated them to find out which one is suited best for modeling variability in the automotive domain. We conducted a controlled experiment with developers at Volkswagen AG to decide which concept is preferred by developers and if their preference aligns with measurable performance factors. We found out that all existing concepts are viable approaches and that the delta approach is both the preferred concept as well as the objectively most efficient one, which makes ?Simulink a good solution to model variability in the automotive domain.},
booktitle = {Proceedings of the 2015 48th Hawaii International Conference on System Sciences},
pages = {5373–5382},
numpages = {10},
keywords = {Software Product Line Engineering, Software Engineering, Simulink, Delta Modeling, Automotive},
series = {HICSS '15}
}

@inproceedings{10.1007/978-3-030-79382-1_24,
author = {Munoz, Daniel-Jesus and Gurov, Dilian and Pinto, Monica and Fuentes, Lidia},
title = {Category Theory Framework for Variability Models with Non-functional Requirements},
year = {2021},
isbn = {978-3-030-79381-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79382-1_24},
doi = {10.1007/978-3-030-79382-1_24},
abstract = {In Software Product Line (SPL) engineering one uses Variability Models (VMs) as input to automated reasoners to generate optimal products according to certain Quality Attributes (QAs). Variability models, however, and more specifically those including numerical features (i.e., NVMs), do not natively support QAs, and consequently, neither do automated reasoners commonly used for variability resolution. However, those satisfiability and optimisation problems have been covered and refined in other relational models such as databases.Category Theory (CT) is an abstract mathematical theory typically used to capture the common aspects of seemingly dissimilar algebraic structures. We propose a unified relational modelling framework subsuming the structured objects of VMs and QAs and their relationships into algebraic categories. This abstraction allows a combination of automated reasoners over different domains to analyse SPLs. The solutions’ optimisation can now be natively performed by a combination of automated theorem proving, hashing, balanced-trees and chasing algorithms. We validate this approach by means of the edge computing SPL tool HADAS.},
booktitle = {Advanced Information Systems Engineering: 33rd International Conference, CAiSE 2021, Melbourne, VIC, Australia, June 28 – July 2, 2021, Proceedings},
pages = {397–413},
numpages = {17},
keywords = {Category theory, Quality attribute, Non-functional requirement, Feature, Numerical variability model},
location = {Melbourne, VIC, Australia}
}

@article{10.1016/j.infsof.2013.02.007,
author = {Santos Rocha, Roberto dos and Fantinato, Marcelo},
title = {The use of software product lines for business process management},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.02.007},
doi = {10.1016/j.infsof.2013.02.007},
abstract = {ContextBusiness Process Management (BPM) is a potential domain in which Software Product Line (PL) can be successfully applied. Including the support of Service-oriented Architecture (SOA), BPM and PL may help companies achieve strategic alignment between business and IT. ObjectivePresenting the results of a study undertaken to seek and assess PL approaches for BPM through a Systematic Literature Review (SLR). Moreover, identifying the existence of dynamic PL approaches for BPM. MethodA SLR was conducted with four research questions formulated to evaluate PL approaches for BPM. Results63 papers were selected as primary studies according to the criteria established. From these primary studies, only 15 papers address the specific dynamic aspects in the context evaluated. Moreover, it was found that PLs only partially address the BPM lifecycle since the last business process phase is not a current concern on the found approaches. ConclusionsThe found PL approaches for BPM only cover partially the BPM lifecycle, not taking into account the last phase which restarts the lifecycle. Moreover, no wide dynamic PL proposal was found for BPM, but only the treatment of specific dynamic aspects. The results indicate that PL approaches for BPM are still at an early stage and gaining maturity.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1355–1373},
numpages = {19},
keywords = {Software product line, PL, Business process management, BPM}
}

@inproceedings{10.1145/3368089.3409684,
author = {Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {An empirical analysis of the costs of clone- and platform-oriented software reuse},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409684},
doi = {10.1145/3368089.3409684},
abstract = {Software reuse lowers development costs and improves the quality of software systems. Two strategies are common: clone &amp; own (copying and adapting a system) and platform-oriented reuse (building a configurable platform). The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs. The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility. As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures. Deciding for one strategy is a core decision with long-term impact on an organization’s software development. Unfortunately, the strategies’ costs are not well-understood - not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect. We present an empirical study of the development activities, costs, cost factors, and benefits associated with either reuse strategy. For this purpose, we combine quantitative and qualitative data that we triangulated from 26 interviews at a large organization and a systematic literature review covering 57 publications. Our study both confirms and refutes common hypotheses on software reuse. For instance, we confirm that developing for platform-oriented reuse is more expensive, but simultaneously reduces reuse costs; and that platform-orientation results in higher code quality compared to clone &amp; own. Surprisingly, refuting common hypotheses, we find that change propagation can be more expensive in a platform, that platforms can facilitate the advancement into innovative markets, and that there is no strict distinction of clone &amp; own and platform-oriented reuse in practice.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {432–444},
numpages = {13},
keywords = {software reuse, software product line, platform engineering, empirical study, economics, clone &amp; own},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1016/j.jss.2019.01.057,
author = {Kr\"{u}ger, Jacob and Mukelabai, Mukelabai and Gu, Wanzi and Shen, Hui and Hebig, Regina and Berger, Thorsten},
title = {Where is my feature and what is it about? A case study on recovering feature facets},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.01.057},
doi = {10.1016/j.jss.2019.01.057},
journal = {J. Syst. Softw.},
month = jun,
pages = {239–253},
numpages = {15},
keywords = {Software product line, Feature facets, Case study, Bitcoin-wallet, Marlin, Feature location}
}

@inproceedings{10.1145/3194078.3194082,
author = {Pukhkaiev, Dmytro and G\"{o}tz, Sebastian},
title = {BRISE: energy-efficient benchmark reduction},
year = {2018},
isbn = {9781450357326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194078.3194082},
doi = {10.1145/3194078.3194082},
abstract = {A considerable portion of research activities in computer science heavily relies on the process of benchmarking, e.g., to evaluate a hypothesis in an empirical study. The goal is to reveal how a set of independent variables (factors) influences one or more dependent variables. With a vast number of factors or a high amount of factors' values (levels), this process becomes time- and energy-consuming. Current approaches to lower the benchmarking effort suffer from two deficiencies: (1) they focus on reducing the number of factors and, hence, are inapplicable to experiments with only two factors, but a vast number of levels and (2) being adopted from, e.g., combinatorial optimization they are designed for a different search space structure and, thus, can be very wasteful. This paper provides an approach for benchmark reduction, based on adaptive instance selection and multiple linear regression. We evaluate our approach using four empirical studies, which investigate the effect made by dynamic voltage and frequency scaling in combination with dynamic concurrency throttling on the energy consumption of a computing system (parallel compression, sorting, and encryption algorithms as well as database query processing). Our findings show the effectiveness of the approach. We can save 78% of benchmarking effort, while the result's quality decreases only by 3 pp, due to using only a near-optimal configuration.},
booktitle = {Proceedings of the 6th International Workshop on Green and Sustainable Software},
pages = {23–30},
numpages = {8},
keywords = {non-functional properties, fractional factorial design, benchmarking, adaptive instance selection, active learning},
location = {Gothenburg, Sweden},
series = {GREENS '18}
}

@inproceedings{10.1007/978-3-030-45234-6_12,
author = {ter Beek, Maurice H. and van Loo, Sjef and de Vink, Erik P. and Willemse, Tim A. C.},
title = {Family-Based SPL Model Checking Using Parity Games with Variability},
year = {2020},
isbn = {978-3-030-45233-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-45234-6_12},
doi = {10.1007/978-3-030-45234-6_12},
abstract = {Family-based SPL model checking concerns the simultaneous verification of multiple product models, aiming to improve on enumerative product-based verification, by capitalising on the common features and behaviour of products in a software product line (SPL), typically modelled as a featured transition system (FTS). We propose efficient family-based SPL model checking of modal -calculus formulae on FTSs based on variability parity games, which extend parity games with conditional edges labelled with feature configurations, by reducing the SPL model checking problem for the modal -calculus on FTSs to the variability parity game solving problem, based on an encoding of FTSs as variability parity games. We validate our contribution by experiments on SPL benchmark models, which demonstrate that a novel family-based algorithm to collectively solve variability parity games, using symbolic representations of the configuration sets, outperforms the product-based method of solving the standard parity games obtained by projection with classical algorithms.},
booktitle = {Fundamental Approaches to Software Engineering: 23rd International Conference, FASE 2020, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2020, Dublin, Ireland, April 25–30, 2020, Proceedings},
pages = {245–265},
numpages = {21},
location = {Dublin, Ireland}
}

@article{10.1007/s10270-017-0610-0,
author = {Guo, Jianmei and Liang, Jia Hui and Shi, Kai and Yang, Dingyu and Zhang, Jingsong and Czarnecki, Krzysztof and Ganesh, Vijay and Yu, Huiqun},
title = {SMTIBEA: a hybrid multi-objective optimization algorithm for configuring large constrained software product lines},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {2},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0610-0},
doi = {10.1007/s10270-017-0610-0},
abstract = {A key challenge to software product line engineering is to explore a huge space of various products and to find optimal or near-optimal solutions that satisfy all predefined constraints and balance multiple often competing objectives. To address this challenge, we propose a hybrid multi-objective optimization algorithm called SMTIBEA that combines the indicator-based evolutionary algorithm (IBEA) with the satisfiability modulo theories (SMT) solving. We evaluated the proposed algorithm on five large, constrained, real-world SPLs. Compared to the state-of-the-art, our approach significantly extends the expressiveness of constraints and simultaneously achieves a comparable performance. Furthermore, we investigate the performance influence of the SMT solving on two evolutionary operators of the IBEA.},
journal = {Softw. Syst. Model.},
month = apr,
pages = {1447–1466},
numpages = {20},
keywords = {Software product lines, Search-based software engineering, Multi-objective evolutionary algorithms, Feature models, Constraint solving}
}

@article{10.1016/j.infsof.2017.01.012,
author = {Reinhartz-Berger, Iris and Figl, Kathrin and Haugen, ystein},
title = {Investigating styles in variability modeling},
year = {2017},
issue_date = {July 2017},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {87},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.01.012},
doi = {10.1016/j.infsof.2017.01.012},
abstract = {ContextA common way to represent product lines is with variability modeling. Yet, there are different ways to extract and organize relevant characteristics of variability. Comprehensibility of these models and the ease of creating models are important for the efficiency of any variability management approach. ObjectiveThe goal of this paper is to investigate the comprehensibility of two common styles to organize variability into models hierarchical and constrained where the dependencies between choices are specified either through the hierarchy of the model or as cross-cutting constraints, respectively. MethodWe conducted a controlled experiment with a sample of 90 participants who were students with prior training in modeling. Each participant was provided with two variability models specified in Common Variability Language (CVL) and was asked to answer questions requiring interpretation of provided models. The models included 920 nodes and 819 edges and used the main variability elements. After answering the questions, the participants were asked to create a model based on a textual description. ResultsThe results indicate that the hierarchical modeling style was easier to comprehend from a subjective point of view, but there was also a significant interaction effect with the degree of dependency in the models, that influenced objective comprehension. With respect to model creation, we found that the use of a constrained modeling style resulted in higher correctness of variability models. ConclusionsPrior exposure to modeling style and the degree of dependency among elements in the model determine what modeling style a participant chose when creating the model from natural language descriptions. Participants tended to choose a hierarchical style for modeling situations with high dependency and a constrained style for situations with low dependency. Furthermore, the degree of dependency also influences the comprehension of the variability model.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {81–102},
numpages = {22},
keywords = {Variability modeling, Textual constraints, Product line engineering, Hierarchical modeling, Feature modeling, Empirical research, Comprehensibility, Cognitive aspects}
}

@inproceedings{10.1145/3180155.3180159,
author = {Krieter, Sebastian and Th\"{u}m, Thomas and Schulze, Sandro and Schr\"{o}ter, Reimar and Saake, Gunter},
title = {Propagating configuration decisions with modal implication graphs},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180159},
doi = {10.1145/3180155.3180159},
abstract = {Highly-configurable systems encompass thousands of interdependent configuration options, which require a non-trivial configuration process. Decision propagation enables a backtracking-free configuration process by computing values implied by user decisions. However, employing decision propagation for large-scale systems is a time-consuming task and, thus, can be a bottleneck in interactive configuration processes and analyses alike. We propose modal implication graphs to improve the performance of decision propagation by precomputing intermediate values used in the process. Our evaluation results show a significant improvement over state-of-the-art algorithms for 120 real-world systems.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {898–909},
numpages = {12},
keywords = {configuration, decision propagation, software product line},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.entcs.2016.02.007,
author = {Zela Ruiz, Jael and Rubira, Cec\'{\i}lia M.},
title = {Quality of Service Conflict During Web Service Monitoring},
year = {2016},
issue_date = {March 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {321},
number = {C},
issn = {1571-0661},
url = {https://doi.org/10.1016/j.entcs.2016.02.007},
doi = {10.1016/j.entcs.2016.02.007},
abstract = {Web services have become one of the most used technologies in service-oriented systems. Its popularity is due to its property to adapt to any context. As a consequence of the increasing number of Web services on the Internet and its important role in many applications today, Web service quality has become a crucial requirement and demanded by service consumers. Terms of quality levels are written between service providers and service consumers to ensure a degree of quality. The use of monitoring tools to control service quality levels is very important. Quality attributes suffer variations in their values during runtime, this is produced by many factors such as a memory leak, deadlock, race data, inconsistent data, etc. However, sometimes monitoring tools can impact negatively affecting the quality of service when they are not properly used and configured, producing possible conflicts between quality attributes. This paper aims to show the impact of monitoring tools over service quality, two of the most important quality attributes - performance and accuracy - were chosen to be monitored. A case study is conducted to present and evaluate the relationship between performance and accuracy over a Web service. As a result, conflict is found between performance and accuracy, where performance was the most affected, because it presented a degradation in its quality level during monitoring.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = mar,
pages = {113–127},
numpages = {15},
keywords = {Web Services, SOA, Quality of Service, Quality Attributes, Performance, Monitoring Tools, Conflict, Accuracy}
}

@inproceedings{10.1145/1878450.1878475,
author = {Lobato, Luanna Lopes and O'Leary, P\'{a}draig and de Almeida, Eduardo Santana and de Lemos Meira, S\'{\i}lvio Romero},
title = {The importance of documentation, design and reuse in risk management for SPL},
year = {2010},
isbn = {9781450304030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878450.1878475},
doi = {10.1145/1878450.1878475},
abstract = {Software Product Lines (SPL) is a methodology focusing on systematic software reuse, multiple benefits have been reported as a result of this type of software development. However, establishing a SPL is not a simple task. It is a challenging activity raising many challenges for engineering and management. This research aims to manage the risks during SPL development to provide traceability among them. For this, it is important that the risks are documented and there is a common design related to them. As solution, we identified the strengths and weakness in SPL development and the importance in designing of communication for risk documentation.},
booktitle = {Proceedings of the 28th ACM International Conference on Design of Communication},
pages = {143–150},
numpages = {8},
keywords = {web products, software product line, documentation},
location = {S\~{a}o Carlos, S\~{a}o Paulo, Brazil},
series = {SIGDOC '10}
}

@inproceedings{10.1145/3168365.3168375,
author = {Bezerra, Carla I. M. and Andrade, Rossana M. C. and Monteiro, Jos\'{e} M. S. and Cedraz, Davi},
title = {Aggregating Measures using Fuzzy Logic for Evaluating Feature Models},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168375},
doi = {10.1145/3168365.3168375},
abstract = {In the context of Software Product Lines (SPLs), evaluating the quality of a feature model is essential to ensure that errors in the early stages do not spread throughout the SPL. One way to evaluate a feature model is to use measures. However, measures alone are not enough to characterize the feature model quality, because most of them cover specific aspects, such as the number of features. So, there is a need for methods to aggregate measures at the level of quality sub-characteristic or characteristic. In this paper, we aim to investigate how to aggregate measures that have been proposed to evaluate the quality of feature models in SPL. We have used the fuzzy logic theory in order to aggregate these measures. The new aggregated measures can be applied to evaluate different and complex aspects of a feature model, such as: size, stability, flexibility and dynamicity. Moreover, to evaluate the use of the new aggregate measures, we applied them in different feature models. Our findings suggest that aggregate measures can assist the domain engineer in evaluating the maintainability of feature models.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {35–42},
numpages = {8},
keywords = {Software Product Line, Measures, Fuzzy Logic, Feature Models},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/2857546.2857608,
author = {Rahmat, Azizah and Kassim, Suzana and Selamat, Mohd Hasan and Hassan, Sa'adah},
title = {Actor in Multi Product Line},
year = {2016},
isbn = {9781450341424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2857546.2857608},
doi = {10.1145/2857546.2857608},
abstract = {Software product line (SPL) involved variability modeling in domain engineering that will be matched to the respected application engineering. Several researches existed within the scope of mapping from reference architecture (RA) in domain engineering to system architecture in application engineering within the same domain. However, the mapping of cross domain RA or Multi Product Line (MPL) required more systematic mapping due to the several participating product line architecture (PLA) that will further instantiated to specific system architecture. The objective of this paper was to propose an actor-oriented approach in the mapping process of reference architecture, product line architecture and system architecture of MPL. Since the reference architecture consisted of several components, the scope of this research was within the functional decomposition or source code level. The experiment was involving the runtime behavior of the java code. The code with actor-oriented approach had shown the least amount of time taken to complete the main method compared to the non-actor-oriented approach. In conclusion, actor-oriented approach performs better performance in the mapping of reference architecture to product line architecture and system architecture. For future work, the consistency of the mapping will be evaluated.},
booktitle = {Proceedings of the 10th International Conference on Ubiquitous Information Management and Communication},
articleno = {61},
numpages = {8},
keywords = {reference architecture, multi product line, cross-domain reference architecture, actor, Software product line},
location = {Danang, Viet Nam},
series = {IMCOM '16}
}

@inproceedings{10.5555/2075202.2075248,
author = {Reinhartz-Berger, Iris and Tsoury, Arava},
title = {Specification and utilization of core assets: feature-oriented vs. UML-based methods},
year = {2011},
isbn = {9783642245732},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Core assets are reusable artifacts built to be used in different software products in the same family. As such, core assets need to capture both commonality that exists and variability that is allowed in the product family (line). These assets are later utilized for guiding the creation of particular valid products in the family. Feature-oriented and UML-based methods have been proposed for modeling core assets. In this work, we suggest a framework for analyzing and evaluating core assets modeling methods. We use this framework for comparing two specific methods: feature-oriented CBFM and UML-based ADOM. We found similar performance in modifying core assets in the two methods and some interesting differences in core assets utilization.},
booktitle = {Proceedings of the 30th International Conference on Advances in Conceptual Modeling: Recent Developments and New Directions},
pages = {302–311},
numpages = {10},
keywords = {variability, software product line engineering, feature-orientation, domain analysis, UML},
location = {Brussels, Belgium},
series = {ER'11}
}

@article{10.1016/j.jss.2019.110422,
author = {Edded, Sabrine and Sassi, Sihem Ben and Mazo, Ra\'{u}l and Salinesi, Camille and Ghezala, Henda Ben},
title = {Collaborative configuration approaches in software product lines engineering: A systematic mapping study},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110422},
doi = {10.1016/j.jss.2019.110422},
journal = {J. Syst. Softw.},
month = dec,
numpages = {17},
keywords = {Framework, Systematic mapping study, Collaborative configuration, Product lines}
}

@inproceedings{10.1145/1842752.1842813,
author = {Galv\~{a}o, Ism\^{e}nia and van den Broek, Pim and Ak\c{s}it, Mehmet},
title = {A model for variability design rationale in SPL},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842813},
doi = {10.1145/1842752.1842813},
abstract = {The management of variability in software product lines goes beyond the definition of variations, traceability and configurations. It involves a lot of assumptions about the variability and related models, which are made by the stakeholders all over the product line but almost never handled explicitly. In order to better manage the design with variability, we must consider the rationale behind its specification. In this paper we present a model for the specification of variability design rationale and its application to the modelling of architectural variability in software product lines.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {332–335},
numpages = {4},
keywords = {variability, software product line, software architecture, design rationale},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.5555/2666064.2666077,
author = {Leitner, Andrea and Wei\ss{}, Reinhold and Kreiner, Christian},
title = {Optimizing problem space representations through domain multi-modeling},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {This work states that there is a need for an optimized problem space representation for heterogeneous domains. We identify two modeling paradigms widely used in practice: Domain-Specific Modeling (DSM) and Feature-Oriented Domain Modeling (FODM). Each modeling paradigm favors different domain characteristics. Especially the fact that software often is embedded either in a system or in a process and, therefore, is strongly influenced by its environment enforces the demand for a combined representation.We propose a concept for a multi-modeling approach based on existing technology. Multi-modeling means the combination of the two main modeling paradigms to represent a heterogeneous domain. The major benefit of the approach is the reduction of representation complexity by optimizing the representation of single subdomains. This will be shown on one representative case study from the automotive domain. Another advantage is the improved stakeholder communication because of familiar notations. A discussion of limitations shows potential for future work.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {49–52},
numpages = {4},
keywords = {variant-rich component model, software product line engineering, model-based development, domain modeling, binding times, automotive software product line},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@article{10.1016/j.jss.2013.10.010,
author = {White, Jules and Galindo, Jos\'{e} A. and Saxena, Tripti and Dougherty, Brian and Benavides, David and Schmidt, Douglas C.},
title = {Evolving feature model configurations in software product lines},
year = {2014},
issue_date = {January, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {87},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.10.010},
doi = {10.1016/j.jss.2013.10.010},
abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of reusing software components across development projects. One approach to increasing software reusability is to develop a software product-line (SPL), which is a software architecture that can be reconfigured and reused across projects. Rather than developing software from scratch for a new project, a new configuration of the SPL is produced. It is hard, however, to find a configuration of an SPL that meets an arbitrary requirement set and does not violate any configuration constraints in the SPL. Existing research has focused on techniques that produce a configuration of an SPL in a single step. Budgetary constraints or other restrictions, however, may require multi-step configuration processes. For example, an aircraft manufacturer may want to produce a series of configurations of a plane over a span of years without exceeding a yearly budget to add features. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these SPL configuration problems can be automatically derived with a constraint solver by mapping them to CSPs. Moreover, we show how feature model changes can be mapped to our approach in a multi-step scenario by using feature model drift. Third, we present empirical results demonstrating that our CSP-based reasoning technique can scale to SPL models with hundreds of features and multiple configuration steps.},
journal = {J. Syst. Softw.},
month = jan,
pages = {119–136},
numpages = {18},
keywords = {Software product line, Multi-step configuration, Feature model}
}

@inproceedings{10.1145/2892664.2892700,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia and Zschaler, Steffen},
title = {Towards contractual interfaces for reusable functional quality attribute operationalisations},
year = {2016},
isbn = {9781450340335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2892664.2892700},
doi = {10.1145/2892664.2892700},
abstract = {The quality of a software system can be measured by the extent to which it possesses a desired combination of quality attributes (QAs). While some QAs are achieved implicitly through the interaction of various functional components of the system, others (e.g., security) can be encapsulated in dedicated software components. These QAs are known as functional quality attributes (FQAs). As applications may require different FQAs, and each FQA can be composed of many concerns (e.g., access control and authentication), integrating FQAs is very complex and requires dedicated expertise. Software architects are required to manually define FQA components, identify appropriate points in their architecture where to weave them, and verify that the composition of these FQA components with the other components is correct. This is a complex and error prone process. In our previous work we defined reusable FQAs by encapsulating them as aspectual architecture models that can be woven into a base architecture. So far, the joinpoints for weaving had to be identified manually. This made it difficult for software architects to verify that they have woven all the necessary FQAs into all the right places. In this paper, we address this problem by introducing a notion of contract for FQAs so that the correct application of an FQA (or one of its concerns) can be checked or, alternatively, appropriate binding points can be identified and proposed to the software architect automatically.},
booktitle = {Companion Proceedings of the 15th International Conference on Modularity},
pages = {201–205},
numpages = {5},
keywords = {Weaving Patterns, Quality Attributes, Model-Driven Development, Aspect-Orientation},
location = {M\'{a}laga, Spain},
series = {MODULARITY Companion 2016}
}

@inproceedings{10.1145/1985484.1985493,
author = {Chastek, Gary and Donohoe, Patrick and McGregor, John D.},
title = {Commonality and variability analysis for resource constrained organizations},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985493},
doi = {10.1145/1985484.1985493},
abstract = {This position paper describes our current work in adapting a software product line technique to the constraints of a development organization. We report on applying a commonality and variability analysis with an organization adopting a software product line approach while facing sever resource constraints because of current product development commitments. The immediate focus of the paper is on blending commonality and variability analysis into the organization's existing requirements development process. The longer-term goal of this work is to facilitate the transition to product lines in a minimally intrusive way. The paper describes how the approach was introduced and implemented, and summarizes the benefits achieved and the issues arising from the work to date.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {31–34},
numpages = {4},
keywords = {software product line, commonality and variability analysis},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@inproceedings{10.1145/3321408.3326676,
author = {Yan, Liu and Hu, Wenxin and Han, Longzhe},
title = {Optimize SPL test cases with adaptive simulated annealing genetic algorithm},
year = {2019},
isbn = {9781450371582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321408.3326676},
doi = {10.1145/3321408.3326676},
abstract = {In Software Product Line (SPL) testing, reduced test suite with high coverage is useful for early features interaction detection. sGA (simplified genetic algorithm) and SAGA(simulated annealing genetic algorithm) can generate high coverage test suite. However, small probability mutations in updating test suite may reduce search efficiency and thus miss better solutions. An improved test cases generation method based on ASAGA (Adaptive simulated annealing genetic algorithm) is proposed. Experiments on SPLOT (Software Product Lines Online Tools) feature models show that the proposed hybrid ASAGA method can ensure local optimization accuracy and achieve smaller-size test suite with higher coverage.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
articleno = {148},
numpages = {7},
keywords = {test case, software test, similarity measurement, feature model, ASAGA},
location = {Chengdu, China},
series = {ACM TURC '19}
}

@inproceedings{10.1145/3183399.3183425,
author = {Krieter, Sebastian and Kr\"{u}ger, Jacob and Weichbrodt, Nico and Sartakov, Vasily A. and Kapitza, R\"{u}diger and Leich, Thomas},
title = {Towards secure dynamic product lines in the cloud},
year = {2018},
isbn = {9781450356626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183399.3183425},
doi = {10.1145/3183399.3183425},
abstract = {Cloud-based technologies play an increasing role in software engineering because of their scalability, availability, and cost efficiency. However, due to privacy issues, developers and organizations still hesitate to host applications that handle sensitive data on servers of external cloud providers. Modern hardware extensions, such as Intel's Software Guard Extensions (SGX), are an attempt to provide confidentiality and integrity for applications running on external hardware. Still, enabling SGX in cloud systems poses new challenges considering scalability and flexibility. In this paper, we propose an approach to address these issues by employing concepts from the domain of Dynamic Software Product Lines (DSPLs). We aim to enable applications running on SGX-based cloud systems to be securely reconfigurable and extendable during runtime. In particular, we describe properties that such an approach should fulfill and discuss corresponding challenges.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {5–8},
numpages = {4},
keywords = {software product line, security, cloud computing, SGX},
location = {Gothenburg, Sweden},
series = {ICSE-NIER '18}
}

@article{10.1016/j.compind.2021.103524,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Rosado, David G. and S\'{a}nchez, Luis E. and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Gasca, Rafael M. and Fern\'{a}ndez-Medina, Eduardo},
title = {CARMEN: A framework for the verification and diagnosis of the specification of security requirements in cyber-physical systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103524},
doi = {10.1016/j.compind.2021.103524},
journal = {Comput. Ind.},
month = nov,
numpages = {14},
keywords = {Diagnosis, Security verification, Security requirements, Configuration models, Security, Cybersecurity, Cyber-physical system}
}

@article{10.5555/3288338.3288341,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Finding correlations of features affecting energy consumption and performance of web servers using the HADAS eco-assistant},
year = {2018},
issue_date = {November  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {100},
number = {11},
issn = {0010-485X},
abstract = {The impact of energy consumption on the environment and the economy is raising awareness of "green" software engineering. HADAS is an eco-assistant that makes developers aware of the influence of their designs and implementations on the energy consumption and performance of the final product. In this paper, we extend HADAS to better support the requirements of users: researchers, automatically dumping the energy-consumption of different software solutions; and developers, who want to perform a sustainability analysis of different software solutions. This analysis has been extended by adding Pearson's chi-squared differentials and Bootstrapping statistics, to automatically check the significance of correlations of the energy consumption, or the execution time, with any other variable (e.g., the number of users) that can influence the selection of a particular eco-efficient configuration. We have evaluated our approach by performing a sustainability analysis of the most common web servers (i.e. PHP servers) using the time and energy data measured with the Watts Up? Pro tool previously dumped in HADAS. We show how HADAS helps web server providers to make a trade-off between energy consumption and execution time, allowing them to sell different server configurations with different costs without modifying the hardware.},
journal = {Computing},
month = nov,
pages = {1155–1173},
numpages = {19},
keywords = {Web servers, Performance, Linux, Energy efficiency, 97K80, 68U35, 68N30, 68M20}
}

@article{10.1007/s10664-020-09892-x,
author = {Kuiter, Elias and Krieter, Sebastian and Kr\"{u}ger, Jacob and Saake, Gunter and Leich, Thomas},
title = {variED: an editor for collaborative, real-time feature modeling},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09892-x},
doi = {10.1007/s10664-020-09892-x},
abstract = {Feature models are a helpful means to document, manage, maintain, and configure the variability of a software system, and thus are a core artifact in software product-line engineering. Due to the various purposes of feature models, they can be a cross-cutting concern in an organization, integrating technical and business aspects. For this reason, various stakeholders (e.g., developers and consultants) may get involved into modeling the features of a software product line. Currently, collaboration in such a scenario can only be done with face-to-face meetings or by combining single-user feature-model editors with additional communication and version-control systems. While face-to-face meetings are often costly and impractical, using version-control systems can cause merge conflicts and inconsistency within a model, due to the different intentions of the involved stakeholders. Advanced tools that solve these problems by enabling collaborative, real-time feature modeling, analogous to Google Docs or Overleaf for text editing, are missing. In this article, we build on a previous paper and describe (1) the extended formal foundations of collaborative, real-time feature modeling, (2) our conflict resolution algorithm in more detail, (3) proofs that our formalization converges and preserves causality as well as user intentions, (4) the implementation of our prototype, and (5) the results of an empirical evaluation to assess the prototype’s usability. Our contributions provide the basis for advancing existing feature-modeling tools and practices to support collaborative feature modeling. The results of our evaluation show that our prototype is considered helpful and valuable by 17 users, also indicating potential for extending our tool and opportunities for new research directions.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {47},
keywords = {Collaboration, Consistency maintenance, Variability, Feature modeling, Groupware, Software product lines}
}

@article{10.1016/j.scico.2012.04.004,
author = {Hartmann, Herman and Keren, Mila and Matsinger, Aart and Rubin, Julia and Trew, Tim and Yatzkar-Haham, Tali},
title = {Using MDA for integration of heterogeneous components in software supply chains},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.04.004},
doi = {10.1016/j.scico.2012.04.004},
abstract = {Software product lines are increasingly built using components from specialized suppliers. A company that is in the middle of a supply chain has to integrate components from its suppliers and offer (partially configured) products to its customers. To satisfy both the variability required by each customer and the variability required to satisfy different customers' needs, it may be necessary for such a company to use components from different suppliers, partly offering the same feature set. This leads to a product line with alternative components, possibly using different mechanisms for interfacing, binding and variability, which commonly occurs in embedded software development. In this paper, we describe the limitations of the current practice of combining heterogeneous components in a product line and describe the challenges that arise from software supply chains. We introduce a model-driven approach for automating the integration between components that can generate a partially or fully configured variant, including glue between mismatched components. We analyze the consequences of using this approach in an industrial context, using a case study derived from an existing supply chain and describe the process and roles associated with this approach.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2313–2330},
numpages = {18},
keywords = {Software supply chains, Software product line engineering, Software integration, Resource constrained products, Model driven engineering, Component technology}
}

@article{10.1016/j.neucom.2019.06.075,
author = {Xue, Yani and Li, Miqing and Shepperd, Martin and Lauria, Stasha and Liu, Xiaohui},
title = {A novel aggregation-based dominance for Pareto-based evolutionary algorithms to configure software product lines},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {364},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.06.075},
doi = {10.1016/j.neucom.2019.06.075},
journal = {Neurocomput.},
month = oct,
pages = {32–48},
numpages = {17},
keywords = {Multi-objective optimization, Evolutionary algorithm, Software product line, Optimal feature selection}
}

@article{10.1016/j.infsof.2015.12.004,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat and Zhang, Li},
title = {Model-based incremental conformance checking to enable interactive product configuration},
year = {2016},
issue_date = {April 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {72},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.12.004},
doi = {10.1016/j.infsof.2015.12.004},
abstract = {ContextModel-based product line engineering (PLE) is a paradigm that can enable automated product configuration of large-scale software systems, in which models are used as an abstract specification of commonalities and variabilities of products of a product line. ObjectiveIn the context of PLE, providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. MethodIn an existing work, a UML-based variability modeling methodology named as SimPL and an interactive configuration process was proposed. Based on the existing work, we propose an automated, incremental and efficient conformance checking approach to ensure that the manual configuration of a variation point conforms to a set of pre-defined conformance rules specified in the Object Constraint Language (OCL). The proposed approach, named as Zen-CC, has been implemented as an integrated part of our product configuration and derivation tool: Zen-Configurator. ResultsThe performance and scalability of Zen-CC have been evaluated with a real-world case study. Results show that Zen-CC significantly outperformed two baseline engines in terms of performance. Besides, the performance of Zen-CC remains stable during the configuration of all the 10 products of the product line and its efficiency also remains un-impacted even with the growing product complexity, which is not the case for both of the baseline engines. ConclusionThe results suggest that Zen-CC performs practically well and is much more scalable than the two baseline engines and is scalable for configuring products with a larger number of variation points.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {68–89},
numpages = {22},
keywords = {Variation point, Product line engineering, Model based engineering, Interactive product configuration, Incremental conformance checking}
}

@inproceedings{10.1145/2556624.2556634,
author = {Lytra, Ioanna and Eichelberger, Holger and Tran, Huy and Leyh, Georg and Schmid, Klaus and Zdun, Uwe},
title = {On the interdependence and integration of variability and architectural decisions},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556634},
doi = {10.1145/2556624.2556634},
abstract = {In software product line engineering, the design of assets for reuse and the derivation of software products entails low-level and high-level decision making. In this process, two major types of decisions must be addressed: variability decisions, i.e., decisions made as part of variability management, and architectural decisions, i.e., fundamental decisions to be made during the design of the architecture of the product line or the products. In practice, variability decisions often overlap with or influence architectural decisions. For instance, resolving a variability may enable or prevent some architectural options. This inherent interdependence has not been explicitly and systematically targeted in the literature, and therefore, is mainly resolved in an ad hoc and informal manner today. In this paper, we discuss possible ways how variability and architectural decisions interact, as well as their management and integration in a systematic manner. We demonstrate the integration between the two types of decisions in a motivating case and leverage existing tools for implementing our proposal.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {8},
keywords = {variability decisions, software product lines, product derivation, architectural decisions},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1007/s10009-013-0298-6,
author = {Ferrari, Alessio and Spagnolo, Giorgio O. and Martelli, Giacomo and Menabeni, Simone},
title = {From commercial documents to system requirements: an approach for the engineering of novel CBTC solutions},
year = {2014},
issue_date = {November  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {6},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-013-0298-6},
doi = {10.1007/s10009-013-0298-6},
abstract = {Communications-based train control (CBTC) systems are the new frontier of automated train control and operation. Currently developed CBTC platforms are actually very complex systems including several functionalities, and every installed system, developed by a different company, varies in extent, scope, number, and even names of the implemented functionalities. International standards have emerged, but they remain at a quite abstract level, mostly setting terminology. This paper presents the results of an experience in defining a global model of CBTC, by mixing semi-formal modelling and product line engineering. The effort has been based on an in-depth market analysis, not limiting to particular aspects but considering as far as possible the whole picture. The paper also describes a methodology to derive novel CBTC products from the global model, and to define system requirements for the individual CBTC components. To this end, the proposed methodology employs scenario-based requirements elicitation aided with rapid prototyping. To enhance the quality of the requirements, these are written in a constrained natural language (CNL), and evaluated with natural language processing (NLP) techniques. The final goal is to go toward a formal representation of the requirements for CBTC systems. The overall approach is discussed, and the current experience with the implementation of the method is presented. In particular, we show how the presented methodology has been used in practice to derive a novel CBTC architecture.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = nov,
pages = {647–667},
numpages = {21},
keywords = {Product line engineering, Formal methods, Experience report, Constrained natural language, CENELEC, CBTC}
}

@inproceedings{10.1145/2961111.2962635,
author = {Echeverr\'{\i}a, Jorge and P\'{e}rez, Francisca and Abellanas, Andr\'{e}s and Panach, Jose Ignacio and Cetina, Carlos and Pastor, \'{O}scar},
title = {Evaluating Bug-Fixing in Software Product Lines: an Industrial Case Study},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962635},
doi = {10.1145/2961111.2962635},
abstract = {[Background] Bug-fixing could be complex in industrial practice since thousands of products share features in their configuration. Despite the importance and complexity of bug-fixing, there is still a lack of empirical data about the difficulties found in industrial Software Product Lines (SPLs). [Aims] This paper aims to evaluate engineers' performance fixing errors and propagating the fixes to other configured products in the context of an industrial SPL. [Method] We designed and conducted an empirical study to collect data with regard to bug-fixing tasks within the context of a Induction Hob SPL in the BSH group, the largest manufacturer of home appliances in Europe. [Results] We found that effectiveness, efficiency and satisfaction got reached good values. Through interviews we also found difficulties related to unused features, cloning features unintentionally, detecting modified features, and propagating the fix when the source of the bug is the interaction between features. [Conclusions] The identified difficulties are relevant to know how to better apply SPLs in industry in the future.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {24},
numpages = {6},
keywords = {Variability Modeling, Usability, Software Product Line},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/3278122.3278123,
author = {Nieke, Michael and Mauro, Jacopo and Seidl, Christoph and Th\"{u}m, Thomas and Yu, Ingrid Chieh and Franzke, Felix},
title = {Anomaly analyses for feature-model evolution},
year = {2018},
isbn = {9781450360456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278122.3278123},
doi = {10.1145/3278122.3278123},
abstract = {Software Product Lines (SPLs) are a common technique to capture families of software products in terms of commonalities and variabilities. On a conceptual level, functionality of an SPL is modeled in terms of features in Feature Models (FMs). As other software systems, SPLs and their FMs are subject to evolution that may lead to the introduction of anomalies (e.g., non-selectable features). To fix such anomalies, developers need to understand the cause for them. However, for large evolution histories and large SPLs, explanations may become very long and, as a consequence, hard to understand. In this paper, we present a method for anomaly detection and explanation that, by encoding the entire evolution history, identifies the evolution step of anomaly introduction and explains which of the performed evolution operations lead to it. In our evaluation, we show that our method significantly reduces the complexity of generated explanations.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {188–201},
numpages = {14},
keywords = {Software Product Line, Feature Model, Explanation, Evolution Operation, Evolution, Anomalies},
location = {Boston, MA, USA},
series = {GPCE 2018}
}

@inproceedings{10.1109/ISSRE.2014.13,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming and Zhang, Li},
title = {Zen-CC: An Automated and Incremental Conformance Checking Solution to Support Interactive Product Configuration},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.13},
doi = {10.1109/ISSRE.2014.13},
abstract = {In the context of product line engineering (PLE), providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. Model-based PLE has brought opportunities to enable automated product configuration and derivation for large-scale systems/software, in which models are used as the abstract specification of commonalities and variabilities of products of a product line. In our previous work, we have proposed a UML-based variability modeling methodology and an interactive configuration process. Based on these work, in this paper, we propose an automated and incremental conformance checking approach to ensure that the manual configuration to each variation point conforms to a set of pre-defined conformance rules specified in OCL. The proposed approach, called Zen-CC is implemented as a component of our product configuration and derivation tool, named as Zen-Configurator. The proposed approach is evaluated with two real-world case studies and results showed that the performance of Zen-CC is significantly better than a baseline algorithm checking all the conformance rules at each configuration step. Moreover, the performance of Zen-CC rarely varies during the configuration process, suggesting that our approach is scalable for configuring products with a large number of configuration points.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {13–22},
numpages = {10},
keywords = {Variation Point, Product Line Engineering, Product Configuration, Conformance Checking},
series = {ISSRE '14}
}

@inproceedings{10.1145/2701319.2701324,
author = {Ommen, J\"{u}rgen and Rock, Georg},
title = {Visualization of Variability in Complex Development Structures},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701324},
doi = {10.1145/2701319.2701324},
abstract = {Mass customization in modern industries leads to an increased complexity in product line engineering due to the high level of variability. Real-world industry-sized product lines can easily end up with thousands of features and constraints. Using sophisticated information visualization techniques is one important component in handling this complexity successfully as they provide a higher level of cognitive support and make the comprehension of the underlying structures easier and faster. However, it is still an unresolved problem to handle the occurring variability in a satisfactory way. This means that we need visualization mechanisms able to cope with the requirements of engineers as well as with the needs of the responsible managers. This paper addresses the issue of visualizing large product lines and discusses different techniques which can be used towards an efficient visualization of variability. Furthermore, it presents alternative methods to visualize complex constraints and group cardinalities. These techniques will then be illustrated with the help of a prototypical implementation.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {109–116},
numpages = {8},
keywords = {Visualization, Variability Management, Product line, Feature diagram, Complex development structures},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@article{10.1016/j.infsof.2012.02.002,
author = {Holl, Gerald and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {A systematic review and an expert survey on capabilities supporting multi product lines},
year = {2012},
issue_date = {August, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.02.002},
doi = {10.1016/j.infsof.2012.02.002},
abstract = {Context: Complex software-intensive systems comprise many subsystems that are often based on heterogeneous technological platforms and managed by different organizational units. Multi product lines (MPLs) are an emerging area of research addressing variability management for such large-scale or ultra-large-scale systems. Despite the increasing number of publications addressing MPLs the research area is still quite fragmented. Objective: The aims of this paper are thus to identify, describe, and classify existing approaches supporting MPLs and to increase the understanding of the underlying research issues. Furthermore, the paper aims at defining success-critical capabilities of infrastructures supporting MPLs. Method: Using a systematic literature review we identify and analyze existing approaches and research issues regarding MPLs. Approaches described in the literature support capabilities needed to define and operate MPLs. We derive capabilities supporting MPLs from the results of the systematic literature review. We validate and refine these capabilities based on a survey among experts from academia and industry. Results: The paper discusses key research issues in MPLs and presents basic and advanced capabilities supporting MPLs. We also show examples from research approaches that demonstrate how these capabilities can be realized. Conclusions: We conclude that approaches supporting MPLs need to consider both technical aspects like structuring large models and defining dependencies between product lines as well as organizational aspects such as distributed modeling and product derivation by multiple stakeholders. The identified capabilities can help to build, enhance, and evaluate MPL approaches.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {828–852},
numpages = {25},
keywords = {Systematic literature review, Product line engineering, Multi product lines, Large-scale systems}
}

@inproceedings{10.1145/3131473.3131486,
author = {Kazdaridis, Giannis and Keranidis, Stratos and Symeonidis, Polychronis and Dias, Paulo Sousa and Gon\c{c}alves, Pedro and Loureiro, Bruno and Gjanci, Petrika and Petrioli, Chiara},
title = {EVERUN: Enabling Power Consumption Monitoring in Underwater Networking Platforms},
year = {2017},
isbn = {9781450351478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131473.3131486},
doi = {10.1145/3131473.3131486},
abstract = {The energy restricted nature of underwater sensor networks directly affects the expected lifetime of autonomous deployments and limits the capabilities for long term underwater monitoring. Towards the goal of developing energy-efficient protocols and algorithms, researchers and equipment vendors require in-depth understanding of the power consumption characteristics of underwater hardware when deployed in-field. In this work, we introduce the EVERUN power monitoring framework, consisting of hardware and software components that were integrated with real equipment of the SUNRISE testbed facilities. Through the execution of a wide set of experiments under realistic conditions, we highlighted the limitations of model-based energy evaluation tools and characterized the energy efficiency performance of key protocols and mechanisms. The accuracy of the collected power data, along with the interesting derived findings, verified the applicability of our approach in evaluating the energy efficiency performance of proposed solutions.},
booktitle = {Proceedings of the 11th Workshop on Wireless Network Testbeds, Experimental Evaluation &amp; CHaracterization},
pages = {83–90},
numpages = {8},
keywords = {underwater networking, testbed experimentation, power consumption monitorin, energy efficiency},
location = {Snowbird, Utah, USA},
series = {WiNTECH '17}
}

@article{10.1016/j.procs.2017.08.206,
author = {Mani, Neel and Helfert, Markus and Pahl, Claus},
title = {A Domain-specific Rule Generation Using Model-Driven Architecture in Controlled Variability Model},
year = {2017},
issue_date = {September 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {112},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.08.206},
doi = {10.1016/j.procs.2017.08.206},
abstract = {The business environment changes rapidly and needs to adapt to the enterprise business systems must be considered for new types of requirements to accept changes in the business strategies and processes. This raises new challenges that the traditional development approaches cannot always provide a complete solution in an efficient way. However, most of the current proposals for automatic generation are not devised to cope with rapid integration of the changes in the business requirement of end user (stakeholders and customers) resource. Domain-specific Rules constitute a key element for domain specific enterprise application, allowing configuration of changes, and management of the domain constraint within a domain. In this paper, we propose an approach to the development of an automatic generation of the domain-specific rules by using variability feature model and ontology definition of domain model concepts coming from Software product line engineering and Model Driven Architecture. We provide a process approach to generate a domain-specific rule based on the end user requirement.},
journal = {Procedia Comput. Sci.},
month = sep,
pages = {2354–2362},
numpages = {9},
keywords = {Variability Model, Rule Generation, Model Driven Architecture, Domain-specific rules, Business Process Model}
}

@inproceedings{10.1145/3168365.3168377,
author = {Ananieva, Sofia and Klare, Heiko and Burger, Erik and Reussner, Ralf},
title = {Variants and Versions Management for Models with Integrated Consistency Preservation},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168377},
doi = {10.1145/3168365.3168377},
abstract = {Modern software systems are often developed and maintained by describing them in several modeling and programming languages. To reduce complexity and improve understandability of such systems, models represent specific views on the system. These views have semantic interrelations (e.g., by sharing common or dependent information) that need to be kept consistent during evolution of the system. Apart from that, modern systems need to run in many different contexts and be highly configurable to satisfy the demand for fully customizable products. Such variable systems often comprise various dependencies from which inconsistencies may arise. Combining solutions for consistency management with variants and versions management, however, comes with many challenges.In this research-in-progress paper, we introduce the VaVe approach which makes variants and versions management aware of automated consistency preservation in the context of multi-view modeling. We explain core features of the approach and reason about its benefits and limitations.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {3–10},
numpages = {8},
keywords = {Variability Management, Software Product Lines, Delta-Based Consistency Preservation},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/3364641.3364656,
author = {Sousa, Amanda and Uch\^{o}a, Anderson and Fernandes, Eduardo and Bezerra, Carla I. M. and Monteiro, Jos\'{e} Maria and Andrade, Rossana M. C.},
title = {REM4DSPL: A Requirements Engineering Method for Dynamic Software Product Lines},
year = {2019},
isbn = {9781450372824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364641.3364656},
doi = {10.1145/3364641.3364656},
abstract = {Context: Dynamic Software Product Line (DSPL) is a set of software products capable of self-adapt and configure in runtime. DSPL products have common features (commonalities) and varying features (managed in runtime according to context changes). Objective: DSPL requirements engineering is challenging. Requirements engineers have to carefully plan self-adaptation while eliciting, modeling, and managing variability requirements. This paper introduces a method for DSPL requirements engineering. Method: We relied on empirically-derived activities of DSPL requirements engineering to build our method. We selected techniques and templates used in other domains such as SPL for refinement and incorporation into the method. We asked DSPL experts via a survey on the method applicability. Result: We introduced the Requirements Engineering Method for DSPL (REM4DSPL). Elicitation is guided by supervised discussions. Modeling relies on feature models. Variability Management is tool-assisted and validated via feature model inspection. DSPL experts agreed on the method applicability and suggested improvements. Conclusion: REM4DSPL relies on empirically-derived activities, techniques that have been successfully used by previous work, and templates adapted to the DSPL context. We expect our method to guide requirements engineers in practice.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Software Quality},
pages = {129–138},
numpages = {10},
keywords = {Requirements Engineering, Dynamic Software Product Lines},
location = {Fortaleza, Brazil},
series = {SBQS '19}
}

@article{10.1016/j.infsof.2015.01.008,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
title = {A systematic mapping study of search-based software engineering for software product lines},
year = {2015},
issue_date = {May 2015},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {61},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.01.008},
doi = {10.1016/j.infsof.2015.01.008},
abstract = {ContextSearch-Based Software Engineering (SBSE) is an emerging discipline that focuses on the application of search-based optimization techniques to software engineering problems. Software Product Lines (SPLs) are families of related software systems whose members are distinguished by the set of features each one provides. SPL development practices have proven benefits such as improved software reuse, better customization, and faster time to market. A typical SPL usually involves a large number of systems and features, a fact that makes them attractive for the application of SBSE techniques which are able to tackle problems that involve large search spaces. ObjectiveThe main objective of our work is to identify the quantity and the type of research on the application of SBSE techniques to SPL problems. More concretely, the SBSE techniques that have been used and at what stage of the SPL life cycle, the type of case studies employed and their empirical analysis, and the fora where the research has been published. MethodA systematic mapping study was conducted with five research questions and assessed 77 publications from 2001, when the term SBSE was coined, until 2014. ResultsThe most common application of SBSE techniques found was testing followed by product configuration, with genetic algorithms and multi-objective evolutionary algorithms being the two most commonly used techniques. Our study identified the need to improve the robustness of the empirical evaluation of existing research, a lack of extensive and robust tool support, and multiple avenues worthy of further investigation. ConclusionsOur study attested the great synergy existing between both fields, corroborated the increasing and ongoing interest in research on the subject, and revealed challenging open research questions.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {33–51},
numpages = {19},
keywords = {Systematic mapping study, Software product line, Search based software engineering, Metaheuristics, Evolutionary algorithm}
}

@inproceedings{10.5555/1753235.1753246,
author = {Hendrickson, Scott A. and Wang, Yang and van der Hoek, Andr\'{e} and Taylor, Richard N. and Kobsa, Alfred},
title = {Modeling PLA variation of privacy-enhancing personalized systems},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Privacy-enhancing personalized (PEP) systems address individual users' privacy preferences as well as privacy laws and regulations. Building such systems entails modeling two different domains: (a) privacy constraints as mandated by law, voluntary self-regulation, or users' individual privacy preferences, and modeled by legal professionals, and (b) software architectures as dictated by available software components and modeled by software architects. Both can evolve independently, e.g., as new laws go into effect or new components become available. In prior work, we proposed modeling PEP systems using a product line architecture (PLA). However, with an extensional PLA, these domain models became strongly entangled making it difficult to modify one without inadvertently affecting the other. This paper evaluates an approach towards modeling both domains within an intensional PLA. We find evidence that this results in a clearer separation between the two domain models, making each easier to evolve and maintain.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {71–80},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1109/ECBS.2008.14,
author = {Etxeberria, Leire and Sagardui, Goiuria},
title = {Evaluation of Quality Attribute Variability in Software Product Families},
year = {2008},
isbn = {9780769531410},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ECBS.2008.14},
doi = {10.1109/ECBS.2008.14},
abstract = {Software product family or line is a software engineering paradigm that systematizes reuse. In Software Product Line Engineering, two phases are distinguished: Domain Engineering which is in charge of developing a common infrastructure and assets and Application Engineering which makes use of those assets to generate the products. One of the key aspects of product lines is variability and its management. However, the main focus has been on functional variability and quality variability in software product lines has not received so much attention by researchers. In a product line different members of the line may require different levels of a quality requirement, for instance they could differ in terms of their availability, security, reliability, etc. Due to this variability, quality evaluation in software product lines is much more complicated that in single-systems. One alternative is to evaluate all the products of a line but it is very expensive and ways of reducing evaluation efforts are necessary. In this direction, the paper presents a method for facilitating cost-effective quality evaluation of a product line taking into consideration variability on quality attributes.},
booktitle = {Proceedings of the 15th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems},
pages = {255–264},
numpages = {10},
keywords = {variability, quality attributes, evaluation, Software product lines},
series = {ECBS '08}
}

@inproceedings{10.1145/3417113.3423000,
author = {de Macedo, Jo\~{a}o and Alo\'{\i}sio, Jo\~{a}o and Gon\c{c}alves, Nelson and Pereira, Rui and Saraiva, Jo\~{a}o},
title = {Energy wars - Chrome vs. Firefox: which browser is more energy efficient?},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3423000},
doi = {10.1145/3417113.3423000},
abstract = {This paper presents a preliminary study on the energy consumption of two popular web browsers. In order to properly measure the energy consumption of both environments, we simulate the usage of various applications, which the goal to mimic typical user interactions and usage.Our preliminary results show interesting findings based on observation, such as what type of interactions generate high peaks of energy consumption, and which browser is overall the most efficient. Our goal with this preliminary study is to show to users how very different the efficiency of web browsers can be, and may serve with advances in this area of study.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {159–165},
numpages = {7},
keywords = {web browsers, green software, energy efficiency},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1007/978-3-642-41533-3_23,
author = {Nie, Kunming and Yue, Tao and Ali, Shaukat and Zhang, Li and Fan, Zhiqiang},
title = {Constraints: The Core of Supporting Automated Product Configuration of Cyber-Physical Systems},
year = {2013},
isbn = {9783642415326},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-41533-3_23},
doi = {10.1007/978-3-642-41533-3_23},
abstract = {In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration solution, based on our experience of studying three industrial product lines.},
booktitle = {Proceedings of the 16th International Conference on Model-Driven Engineering Languages and Systems - Volume 8107},
pages = {370–387},
numpages = {18},
keywords = {Product Line Engineering, Industrial Case Studies, Cyber-Physical Systems, Constraints, Configuration, Classification}
}

@article{10.1016/j.asoc.2016.07.059,
author = {Strickler, Andrei and Prado Lima, Jackson A. and Vergilio, Silvia R. and Pozo, Aurora T.R.},
title = {Deriving products for variability test of Feature Models with a hyper-heuristic approach},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.07.059},
doi = {10.1016/j.asoc.2016.07.059},
abstract = {Graphical abstractDisplay Omitted HighlightsThis paper introduces a hyper-heuristic approach to automatically derive products to variability testing of Software Product Lines.The approach works with Multi-Objective Evolutionary Algorithms.Two hyper-heuristic selection methods are analyzed random and based on FRR-MAB (Fitness Rate Rank based Multi-Armed Bandit).The approach was evaluated with real Feature Models and the results show that the proposed approach outperforms the traditional algorithms used in the literature. Deriving products from a Feature Model (FM) for testing Software Product Lines (SPLs) is a hard task. It is important to select a minimum number of products but, at the same time, to consider the coverage of testing criteria such as pairwise, among other factors. To solve such problems Multi-Objective Evolutionary Algorithms (MOEAs) have been successfully applied. However, to design a solution for this and other software engineering problems can be very difficult, because it is necessary to choose among different search operators and parameters. Hyper-heuristics can help in this task, and have raised interest in the Search-Based Software Engineering (SBSE) field. Considering the growing adoption of SPL in the industry and crescent demand for SPL testing approaches, this paper introduces a hyper-heuristic approach to automatically derive products to variability testing of SPLs. The approach works with MOEAs and two selection methods, random and based on FRR-MAB (Fitness Rate Rank based Multi-Armed Bandit). It was evaluated with real FMs and the results show that the proposed approach outperforms the traditional algorithms used in the literature, and that both selection methods present similar performance.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1232–1242},
numpages = {11},
keywords = {Software testing, Software Product Line, Hyper-heuristic}
}

@inproceedings{10.1145/3023956.3023970,
author = {Legay, Axel and Perrouin, Gilles},
title = {On quantitative requirements for product lines},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023970},
doi = {10.1145/3023956.3023970},
abstract = {Software Product Line Engineering (SPLE) aims at developing a large number of software systems that share a common and managed set of features [5]. In the past years, it has been an active area in both research and industry. SPLE aims at improving productivity and reducing the time, effort, and cost required to develop a family of products (also called variants). The key point to achieve this goal is to manage the variability among various products of a Software Product Line (SPL). Variability is commonly expressed in terms of features, i.e., units of difference between software products. A product can thus be viewed as a set of features. Dependencies between features are typically represented in a Feature Model (FM) [11], whose ultimate purpose is to define which combinations of features (that is, which products) are valid [16]. Behavior of both the features and the core behavior (i.e., the behavior shared by all products in the line) may be represented by (variants of) state machines [3, 13].},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {2–4},
numpages = {3},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1145/2797433.2797455,
author = {Alebrahim, Azadeh and Fa\ss{}bender, Stephan and Filipczyk, Martin and Goedicke, Michael and Heisel, Maritta and Zdun, Uwe},
title = {1st Workshop on VAriability for QUalIties in SofTware Architecture (VAQUITA): Workshop Introduction},
year = {2015},
isbn = {9781450333931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2797433.2797455},
doi = {10.1145/2797433.2797455},
booktitle = {Proceedings of the 2015 European Conference on Software Architecture Workshops},
articleno = {22},
numpages = {2},
keywords = {variability, quality attributes, Software architecture},
location = {Dubrovnik, Cavtat, Croatia},
series = {ECSAW '15}
}

@inproceedings{10.1007/978-3-642-41533-3_24,
author = {Gonz\'{a}lez-Huerta, Javier and Insfr\'{a}n, Emilio and Abrah\~{a}o, Silvia},
title = {Defining and Validating a Multimodel Approach for Product Architecture Derivation and Improvement},
year = {2013},
isbn = {9783642415326},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-41533-3_24},
doi = {10.1007/978-3-642-41533-3_24},
abstract = {Software architectures are the key to achieving the non-functional requirements NFRs in any software project. In software product line SPL development, it is crucial to identify whether the NFRs for a specific product can be attained with the built-in architectural variation mechanisms of the product line architecture, or whether additional architectural transformations are required. This paper presents a multimodel approach for quality-driven product architecture derivation and improvement QuaDAI. A controlled experiment is also presented with the objective of comparing the effectiveness, efficiency, perceived ease of use, intention to use and perceived usefulness with regard to participants using QuaDAI as opposed to the Architecture Tradeoff Analysis Method ATAM. The results show that QuaDAI is more efficient and perceived as easier to use than ATAM, from the perspective of novice software architecture evaluators. However, the other variables were not found to be statistically significant. Further replications are needed to obtain more conclusive results.},
booktitle = {Proceedings of the 16th International Conference on Model-Driven Engineering Languages and Systems - Volume 8107},
pages = {388–404},
numpages = {17},
keywords = {Software Product Lines, Quality Attributes, Model Transformations, Controlled Experiment, Architectural Patterns}
}

@inproceedings{10.5555/2662593.2662594,
author = {Albassam, Emad and Gomaa, Hassan},
title = {Applying software product lines to multiplatform video games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {In this paper, we explore the application of Software Product Line (SPL) technology in the video games domain by exploiting differences in various video game platforms to design a variable component-based software product line architecture for a multiplatform video game. Our approach consists of constructing a feature dependency model for describing variability in multiplatform video games. We explored variability in the user interface, input devices, output devices, CPU, as well as other variability in various video game platforms. Then, we designed a variable component-based SPL that is tailored to every video game in the product line. We validated our approach by implementing a SPL of a combat flight-simulator game and by deriving two versions of the game: a Windows desktop version and a Windows Phone version. The derivation process of each version is done by selecting features from the feature dependency model and the corresponding software components and SPL parameters that relate to those features.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {1–7},
numpages = {7},
keywords = {video games, software product line design, multiplatform variability, feature modeling},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.5555/2666064.2666070,
author = {Sozen, Neset and Merlo, Ettore},
title = {Adapting software product lines for complex certifiable avionics software},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {In avionics, the size and complexity of software-intensive systems increased considerably during recent years. Besides the size and the complexity, certification constraints also had negative impact on the cost and schedule of avionics software projects. Model-Driven Development (MDD) and Software Product Lines Engineering (SPLE) offer an opportunity to improve the avionics software development process, reduce the cost and improve the time to market.Complexity of avionics software and certification constraints pose several challenges to SPLE adoption. Software Product Lines (SPL) framework must provide bi-directional traceability between requirements and low level software assets (e.g. code and test), facilitate production of certification deliverables, allow validation on the target platform and provide code coverage. Also, SPL offer a scheme to manage the complexity of avionics software systems through variability management tools.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {21–24},
numpages = {4},
keywords = {software product line, model-driven development, certifiable software, avionics software, DO-178C},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@article{10.1016/j.vlsi.2018.02.013,
author = {Stamelakos, Ioannis and Xydis, Sotirios and Palermo, Gianluca and Silvano, Cristina},
title = {Workload- and process-variation aware voltage/frequency tuning for energy efficient performance sustainability of NTC manycores},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {65},
number = {C},
issn = {0167-9260},
url = {https://doi.org/10.1016/j.vlsi.2018.02.013},
doi = {10.1016/j.vlsi.2018.02.013},
journal = {Integr. VLSI J.},
month = mar,
pages = {252–262},
numpages = {11},
keywords = {Variability, Energy efficiency, Low power, Manycore architectures, Near-threshold computing}
}

@inproceedings{10.1145/3302333.3302344,
author = {Ferreira, Fischer and Diniz, Jo\~{a}o P. and Silva, Cleiton and Figueiredo, Eduardo},
title = {Testing Tools for Configurable Software Systems: A Review-based Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302344},
doi = {10.1145/3302333.3302344},
abstract = {Configurable software systems are software systems that can be adapted or configured according to a set of features with the goal of increasing reuse and productivity. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. The lack of studies to explore the tools that apply those techniques motivated us to investigate the literature to find testing tools for configurable software systems and to understand how they work. In this paper, we conducted a systematic mapping and identified 34 testing tools for configurable software systems. We first summarized and discussed their main characteristics. We then designed and performed a comparative empirical study of the main sound testing tools found: VarexJ and SPLat. They are considered sound testing techniques because they explore all reachable configurations from a given test. Overall, we observed that VarexJ and SPLat presented distinct results for efficiency while testing the target systems and that, although VarexJ found more errors than SPLat for the majority of the target systems, such result deserves a more in-depth investigation because we expected a higher intersection of errors encountered by them.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {10},
keywords = {Testing Configurable Software Systems, Systematic Mapping Study, Software Product Line},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.5220/0005679102800287,
author = {Diedrich, Alexander and B\"{o}ttcher, Bj\"{o}rn and Niggemann, Oliver},
title = {Exposing Design Mistakes During Requirements Engineering by Solving Constraint Satisfaction Problems to Obtain Minimum Correction Subsets},
year = {2016},
isbn = {9789897581724},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005679102800287},
doi = {10.5220/0005679102800287},
abstract = {In recent years, the complexity of production plants and therefore of the underlying automation systems has grown significantly. This makes the manual design of automation systems increasingly difficult. As a result, errors are found only during production, plant modifications are hindered by not maintainable automation solutions and criteria such as energy efficiency or cost are often not optimized. This work shows how utilizing Minimum Correction Subsets (MCS) of a Constraint Satisfaction Problem improves the collaboration of automation system designers and prevents inconsistent requirements and thus subsequent errors in the design. This opens up a new field of application for constraint satisfaction techniques. As a use case, an example from the field of automation system design is presented. To meet the automation industry\^{a} s requirement for standardised solutions that assure reliability, the calculation of MCS is formulated in such a way that most constraint solvers can be used without any extensions. Experimental results with typical problems demonstrate the practicalness concerning runtime and hardware resources.},
booktitle = {Proceedings of the 8th International Conference on Agents and Artificial Intelligence},
pages = {280–287},
numpages = {8},
keywords = {Product Line Engineering, Minimum Correction Subsets., Feature Models, Constraint Satisfaction},
location = {Rome, Italy},
series = {ICAART 2016}
}

@inproceedings{10.5555/3172795.3172831,
author = {Masri, Samer Al and Bhuiyan, Nazim Uddin and Nadi, Sarah and Gaudet, Matthew},
title = {Software variability through C++ static polymorphism: a case study of challenges and open problems in eclipse OMR},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software Product Line Engineering (SPLE) creates configurable platforms that can be used to efficiently produce similar, and yet different, product variants. SPLs are typically modular such that it is easy to connect different blocks of code together, creating different variations of the product. There are many variability implementation mechanisms to achieve an SPL. This paper shows how static polymorphism can be used to implement variability, through a case study of IBM's open-source Eclipse OMR project. We discuss the current open problems and challenges this variability implementation mechanism raises and highlight technology gaps for reasoning about variability in OMR. We then suggest steps to close these gaps.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {285–291},
numpages = {7},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@article{10.1016/j.micpro.2021.103964,
author = {Gokilavani, N. and Bharathi, B.},
title = {Multi-Objective based test case selection and prioritization for distributed cloud environment},
year = {2021},
issue_date = {Apr 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {82},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2021.103964},
doi = {10.1016/j.micpro.2021.103964},
journal = {Microprocess. Microsyst.},
month = apr,
numpages = {6},
keywords = {Cloud environment, Software testing, Similarity-based clustering, Test case prioritization, Test case selection, Particle swarm optimization, Software product line}
}

@article{10.1016/j.jss.2013.01.038,
author = {Thurimella, Anil Kumar and Br\"{u}Gge, Bernd},
title = {A mixed-method approach for the empirical evaluation of the issue-based variability modeling},
year = {2013},
issue_date = {July, 2013},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {86},
number = {7},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.01.038},
doi = {10.1016/j.jss.2013.01.038},
abstract = {Background: Variability management is the fundamental part of software product line engineering, which deals with customization and reuse of artifacts for developing a family of systems. Rationale approaches structure decision-making by managing the tacit-knowledge behind decisions. This paper reports a quasi-experiment for evaluating a rationale enriched collaborative variability management methodology called issue-based variability modeling. Objective: We studied the interaction of stakeholders with issue-based modeling to evaluate its applicability in requirements engineering teams. Furthermore, we evaluated the reuse of rationale while instantiating and changing variability. Approach: We enriched a quasi-experimental design with a variety of methods found in case study research. A sample of 258 students was employed with data collection and analysis based on a mix of qualitative and quantitative methods. Our study was performed in two phases: the first phase focused on variability identification and instantiation, while the second phase included tasks on variability evolution. Results: We obtained strong empirical evidence on reuse patterns for rationale during instantiation and evolution of variability. The tabular representations used by rationale modeling are learnable and usable in teams of diverse backgrounds.},
journal = {J. Syst. Softw.},
month = jul,
pages = {1831–1849},
numpages = {19},
keywords = {Variability, Software product lines, Requirements engineering, Rationale management, Mixed-methods, Empirical software engineering}
}

@inproceedings{10.1145/2000259.2000286,
author = {Cavalcanti, Ricardo de Oliveira and de Almeida, Eduardo Santana and Meira, Silvio R.L.},
title = {Extending the RiPLE-DE process with quality attribute variability realization},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000286},
doi = {10.1145/2000259.2000286},
abstract = {Software product lines engineering is a viable way to achieve the productivity gains desired by companies. Product line architecture must benefit from commonalities among products in the family and enable the variability among them. The aspect of variability in quality attributes has been neglected or ignored by most of the researchers as attention has been mainly put in functional variability. This paper describes an architecture and design process for software product lines that can properly deal with quality attribute variability. The proposed approach enhances the RiPLE-DE process for software product line engineering with activities and guidelines for quality attribute variability. An initial experimental study is presented to characterize and evaluate the proposed process enhancements.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {159–164},
numpages = {6},
keywords = {software reuse, software product lines (spl), software architecture, quality attribute variability},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@inproceedings{10.1145/2684200.2684314,
author = {Murwantara, I Made and Bordbar, Behzad and Minku, Leandro L.},
title = {Measuring Energy Consumption for Web Service Product Configuration},
year = {2014},
isbn = {9781450330015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2684200.2684314},
doi = {10.1145/2684200.2684314},
abstract = {Because of the economies of scale that Cloud provides, there is great interest in hosting web services on the Cloud. Web services are created from components such as Database Management Systems and HTTP servers. There is a wide variety of components that can be used to configure a web service. The choice of components influences the performance and energy consumption. Most current research in the web service technologies focuses on system performance, and only small number of researchers give attention to energy consumption. In this paper, we propose a method to select the web service configurations which reduce energy consumption. Our method has capabilities to manage feature configuration and predict energy consumption of web service systems. To validate, we developed a technique to measure energy consumption of several web service configurations running in a Virtualized environment. Our approach allows Cloud companies to provide choices of web service technology that consumes less energy.},
booktitle = {Proceedings of the 16th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {224–228},
numpages = {5},
keywords = {Web System, Software Product Line, Machine Learning, Energy Aware},
location = {Hanoi, Viet Nam},
series = {iiWAS '14}
}

@inproceedings{10.5555/2820656.2820662,
author = {Chitchyan, Ruzanna and Noppen, Joost and Groher, Iris},
title = {What can software engineering do for sustainability: case of software product lines},
year = {2015},
publisher = {IEEE Press},
abstract = {Sustainable living, i.e., living within the bounds of the available environmental, social, and economic resources, is the focus of many present-day social and scientific discussions. But what does sustainability mean within the context of Software Product Line Engineering (SPLE)? And what does SPLE do for sustainable living? In this paper we take the first step towards identification of the sustainability-related characteristics relevant to SPLE. The paper also discusses how the key areas of interest to the current SPL community (as reflected by what is measured and optimised in SPLs today) relate to these sustainability characteristics.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {11–14},
numpages = {4},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1145/2851613.2851959,
author = {Noorian, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Quality-centric feature model configuration using goal models},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851959},
doi = {10.1145/2851613.2851959},
abstract = {In software product line engineering, a feature model represents the possible configuration space and can be customized based on the stakeholders' needs. Considering the complexity of feature models in addition to the diversity of the stake-holders' expectations, the configuration process is viewed as a complex optimization problem. In this paper, we propose a holistic approach for the configuration process that seeks to satisfy the stakeholders' requirements as well as the feature models' structural and integrity constraints. Here, we model stakeholders' functional and non-functional needs and their preferences using requirement engineering goal models. We formalize the structure of the feature model, the stake-holders' objectives, and their preferences in the form of an integer linear program to automatically perform feature selection.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1296–1299},
numpages = {4},
keywords = {configuration process, feature model, goal model},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1007/978-3-030-65310-1_20,
author = {Metzger, Andreas and Quinton, Cl\'{e}ment and Mann, Zolt\'{a}n \'{A}d\'{a}m and Baresi, Luciano and Pohl, Klaus},
title = {Feature Model-Guided Online Reinforcement Learning for Self-Adaptive Services},
year = {2020},
isbn = {978-3-030-65309-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-65310-1_20},
doi = {10.1007/978-3-030-65310-1_20},
abstract = {A self-adaptive service can maintain its QoS requirements in the presence of dynamic environment changes. To develop a self-adaptive service, service engineers have to create self-adaptation logic encoding when the service should execute which adaptation actions. However, developing self-adaptation logic may be difficult due to design time uncertainty; e.g., anticipating all potential environment changes at design time is in most cases infeasible. Online reinforcement learning addresses design time uncertainty by learning suitable adaptation actions through interactions with the environment at runtime. To learn more about its environment, reinforcement learning has to select actions that were not selected before, which is known as exploration. How exploration happens has an impact on the performance of the learning process. We focus on two problems related to how a service’s adaptation actions are explored: (1) Existing solutions randomly explore adaptation actions and thus may exhibit slow learning if there are many possible adaptation actions to choose from. (2) Existing solutions are unaware of service evolution, and thus may explore new adaptation actions introduced during such evolution rather late. We propose novel exploration strategies that use feature models (from software product line engineering) to guide exploration in the presence of many adaptation actions and in the presence of service evolution. Experimental results for a self-adaptive cloud management service indicate an average speed-up of the learning process of 58.8% in the presence of many adaptation actions, and of 61.3% in the presence of service evolution. The improved learning performance in turn led to an average QoS improvement of 7.8% and 23.7% respectively
.},
booktitle = {Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {269–286},
numpages = {18},
keywords = {Cloud service, Feature model, Reinforcement learning, Adaptation},
location = {Dubai, United Arab Emirates}
}

@article{10.1007/s10664-020-09911-x,
author = {Ramos-Guti\'{e}rrez, Bel\'{e}n and Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Discovering configuration workflows from existing logs using process mining},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09911-x},
doi = {10.1007/s10664-020-09911-x},
abstract = {Variability models are used to build configurators, for guiding users through the configuration process to reach the desired setting that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the design options that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suits stakeholders according to previous configurations. For example, when configuring a Linux distribution the configuration process starts by choosing the network or the graphic card and then, other packages concerning a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), a framework that can automatically assist determining the configuration workflow that better fits the configuration logs generated by user activities given a set of logs of previous configurations and a variability model. COLOSSI is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Derived from the possible complexity of both logs and the discovered processes, often, it is necessary to divide the traces into small ones. This provides an easier configuration workflow to be understood and followed by the user during the configuration process. In this paper, we apply and compare four different techniques for the traces clustering: greedy, backtracking, genetic and hierarchical algorithms. Our proposal is validated in three different scenarios, to show its feasibility, an ERP configuration, a Smart Farming, and a Computer Configuration. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering along with the necessity to apply clustering techniques for the trace preparation in the context of configuration workflows.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {41},
keywords = {Clustering, Process discovery, Process mining, Configuration workflow, Variability}
}

@inproceedings{10.5555/2820656.2820661,
author = {Segura, Vin\'{\i}cius C. V. B. and Tizzei, Leonardo P. and de F. Ramirez, Jo\~{a}o Paulo and dos Santos, Marcelo N. and Azevedo, Leonardo G. and de G. Cerqueira, Renato F.},
title = {WISE-SPL: bringing multi-tenancy to the weather InSights environment system},
year = {2015},
publisher = {IEEE Press},
abstract = {Weather conditions affect many cities and companies. The WISE (Weather InSights Environment) system serves as a central place to gather and present weather related information for decision makers. It was initially developed to fit a single tenant. Due to a multi-tenant opportunity, WISE is evolving to be deployed on a Cloud environment to support on-demand computing resources and multiple clients. Software product line techniques were applied to model common and variable features of tenants. WISE-SPL enables the derivation of products for each client and also the deployment on Cloud infrastructure. The contribution of this work is a demonstration and discussion of benefits and limitations in applying SPL techniques, following a extractive approach, to build a multi-tenant Cloud application.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {7–10},
numpages = {4},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1145/2465478.2465495,
author = {Klatt, Benjamin and K\"{u}ster, Martin},
title = {Improving product copy consolidation by architecture-aware difference analysis},
year = {2013},
isbn = {9781450321266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465478.2465495},
doi = {10.1145/2465478.2465495},
abstract = {Software product lines (SPL) are a well-known concept to efficiently develop product variants. However, migrating customised product copies to a product line is still a labour-intensive challenge due to the required comprehension of differences among the implementations and SPL design decisions. Most existing SPL approaches are focused on forward engineering. Only few aim to handle SPL evolution, but even those lack support of variability reverse engineering, which is necessary for migrating product copies to a product line. In this paper, we present our continued concept on using component architecture information to enhance a variability reverse engineering process. Including this information particularly improves the difference identification as well as the variation point analysis and -aggregation steps. We show how the concept can be applied by providing an illustrating example.},
booktitle = {Proceedings of the 9th International ACM Sigsoft Conference on Quality of Software Architectures},
pages = {117–122},
numpages = {6},
keywords = {software product line, reverse engineering, component architecture},
location = {Vancouver, British Columbia, Canada},
series = {QoSA '13}
}

@inproceedings{10.1145/1988676.1988684,
author = {Weyns, Danny and Michalik, Bartosz},
title = {Codifying architecture knowledge to support online evolution of software product lines},
year = {2011},
isbn = {9781450305969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1988676.1988684},
doi = {10.1145/1988676.1988684},
abstract = {A company's architecture knowledge is often personalized across specific people that share experience and knowledge in the field. However, this knowledge may be important for other stakeholders. Omitting the codification of the architecture knowledge may result in ad-hoc practices, which is particularly relevant for software evolution. In a collaboration with Egemin, an industrial manufacturer of logistic systems, we faced the problem with a lack of codified architecture knowledge in the context of the evolution of a software product line (SPL). In particular, maintainers lack the architecture knowledge that is needed to perform the evolution tasks of deployed products correctly and efficiently. Ad-hoc updates increase costs and harm the company's reputation. To address this problem, we developed an automated approach for evolving deployed systems of a SPL. Central in this approach are (1) a meta-model that codifies the architecture knowledge required to support evolution of a SPL, and (2) and algorithm that uses the architecture knowledge harvested from a deployed system based on the meta-model to generate the list of tasks maintainers have to perform to evolve the system. Evaluation of the approach demonstrates a significant improvement of the quality of system updates with respect to the correct execution of updates and the availability of services during the updates.},
booktitle = {Proceedings of the 6th International Workshop on SHAring and Reusing Architectural Knowledge},
pages = {37–44},
numpages = {8},
keywords = {software product line, runtime updates, architecture knowledge},
location = {Waikiki, Honolulu, HI, USA},
series = {SHARK '11}
}

@inproceedings{10.1145/2556624.2556628,
author = {Lengauer, Philipp and Bitto, Verena and Angerer, Florian and Gr\"{u}nbacher, Paul and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Where has all my memory gone? determining memory characteristics of product variants using virtual-machine-level monitoring},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556628},
doi = {10.1145/2556624.2556628},
abstract = {Non-functional properties such as memory footprint have recently gained importance in software product line research. However, determining the memory characteristics of individual features and product variants is extremely challenging. We present an approach that supports the monitoring of memory characteristics of individual features at the level of Java virtual machines. Our approach provides extensions to Java virtual machines to track memory allocations and deal-locations of individual features based on a feature-to-code mapping. The approach enables continuous monitoring at the level of features to detect anomalies such as memory leaks, excessive memory consumption, or abnormal garbage collection times in product variants. We provide an evaluation of our approach based on different product variants of the DesktopSearcher product line. Our experiment with different program inputs demonstrates the feasibility of our technique.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {13},
numpages = {8},
keywords = {monitoring, memory footprint, feature-oriented software development, Java},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1016/j.jss.2019.02.028,
author = {Jakubovski Filho, Helson Luiz and Ferreira, Thiago Nascimento and Vergilio, Silvia Regina},
title = {Preference based multi-objective algorithms applied to the variability testing of software product lines},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {151},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.02.028},
doi = {10.1016/j.jss.2019.02.028},
journal = {J. Syst. Softw.},
month = may,
pages = {194–209},
numpages = {16},
keywords = {Preference-Based algorithms, Search-Based software engineering, Software product line testing}
}

@inproceedings{10.1145/3302333.3302343,
author = {Cruz, Daniel and Figueiredo, Eduardo and Martinez, Jabier},
title = {A Literature Review and Comparison of Three Feature Location Techniques using ArgoUML-SPL},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302343},
doi = {10.1145/3302333.3302343},
abstract = {Over the last decades, the adoption of Software Product Line (SPL) engineering for supporting software reuse has increased. An SPL can be extracted from one single product or from a family of related software products, and feature location strategies are widely used for variability mining. Several feature location strategies have been proposed in the literature and they usually aim to map a feature to its source code implementation. In this paper, we present a systematic literature review that identifies and characterizes existing feature location strategies. We also evaluated three different strategies based on textual information retrieval in the context of the ArgoUML-SPL feature location case study. In this evaluation, we compare the strategies based on their ability to correctly identify the source code of several features from ArgoUML-SPL ground truth. We then discuss the strengths and weaknesses of each feature location strategy.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {16},
numpages = {10},
keywords = {variability mining, software product lines, reverse engineering, feature location, benchmark},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@article{10.1016/j.infsof.2015.11.004,
author = {Heradio, Ruben and Perez-Morago, Hector and Fernandez-Amoros, David and Javier Cabrerizo, Francisco and Herrera-Viedma, Enrique},
title = {A bibliometric analysis of 20 years of research on software product lines},
year = {2016},
issue_date = {April 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {72},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.11.004},
doi = {10.1016/j.infsof.2015.11.004},
abstract = {Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality.Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way.Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis.Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations.Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {1–15},
numpages = {15},
keywords = {Software product lines, Science mapping, Performance analysis, Bibliometrics}
}

@inproceedings{10.1145/1944892.1944895,
author = {Holl, Gerald and Vierhauser, Michael and Heider, Wolfgang and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {Product line bundles for tool support in multi product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944895},
doi = {10.1145/1944892.1944895},
abstract = {Many organizations adopt a product line approach to increase the degree of reuse in software development and to deal with the variability of their systems. Large-scale systems are often composed of multiple heterogeneous subsystems that are based on diverse technological platforms. Providing product line engineering tools for such multi product line environments is challenging as tool requirements of stakeholders can differ significantly. In this paper we present product line bundles (PLiBs), an approach that supports developers in tailoring and extending product line tools in a multi product line context. Based on an industrial example, we examine the specific requirements and challenges of using PLiBs to manage tool extensions in multi product lines and to simplify the integration and deployment of system-specific tool features.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {21–27},
numpages = {7},
keywords = {tool support, product line engineering, product line bundles, multi product lines},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/1529282.1529388,
author = {Bure\v{s}, Tom\'{a}\v{s} and Hn\v{e}tynka, Petr and Malohlava, Michal},
title = {Using a product line for creating component systems},
year = {2009},
isbn = {9781605581668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1529282.1529388},
doi = {10.1145/1529282.1529388},
abstract = {Component systems have become a wide-spread technology and found their place in several application domains. Each component system has its specifics and particularities that reflect its focus and the application domain it is intended for. Although important, the diversity of component systems leads to a number of problems including having different tools for each systems, unnecessary duplication of functionality and problems with integration when several domains are to be targeted. Based on categorization of component application domains, we propose a "meta-component system", which provides a software product line for creating custom component systems. We focus especially on the deployment and execution environment, which is where most diversities are found. We demonstrate the usage of the "meta-component system" and propose how it is to be realized by two core concepts of SOFA 2, namely connector generator and microcomponents.},
booktitle = {Proceedings of the 2009 ACM Symposium on Applied Computing},
pages = {501–508},
numpages = {8},
keywords = {runtime environment, product line engineering, generative programming, component systems},
location = {Honolulu, Hawaii},
series = {SAC '09}
}

@inproceedings{10.1145/3136040.3136054,
author = {Linsbauer, Lukas and Berger, Thorsten and Gr\"{u}nbacher, Paul},
title = {A classification of variation control systems},
year = {2017},
isbn = {9781450355247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136040.3136054},
doi = {10.1145/3136040.3136054},
abstract = {Version control systems are an integral part of today's software and systems development processes. They facilitate the management of revisions (sequential versions) and variants (concurrent versions) of a system under development and enable collaboration between developers. Revisions are commonly maintained either per file or for the whole system. Variants are supported via branching or forking mechanisms that conceptually clone the whole system under development. It is known that such cloning practices come with disadvantages. In fact, while short-lived branches for isolated development of new functionality (a.k.a. feature branches) are well supported, dealing with long-term and fine-grained system variants currently requires employing additional mechanisms, such as preprocessors, build systems or custom configuration tools. Interestingly, the literature describes a number of variation control systems, which provide a richer set of capabilities for handling fine-grained system variants compared to the version control systems widely used today. In this paper we present a classification and comparison of selected variation control systems to get an understanding of their capabilities and the advantages they can offer. We discuss problems of variation control systems, which may explain their comparably low popularity. We also propose research activities we regard as important to change this situation.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {49–62},
numpages = {14},
keywords = {software repositories, software product lines, configuration management, Variability management},
location = {Vancouver, BC, Canada},
series = {GPCE 2017}
}

@inproceedings{10.1145/1147249.1147252,
author = {Kolb, Ronny and Muthig, Dirk},
title = {Making testing product lines more efficient by improving the testability of product line architectures},
year = {2006},
isbn = {1595934596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1147249.1147252},
doi = {10.1145/1147249.1147252},
abstract = {Product line engineering is a recent approach to software development that has shown to enable organizations to achieve significant reductions in development and maintenance cost as well as time-to-market of increasingly complex software systems. Yet, the testing process has not kept up with these reductions and the relative cost for testing product lines is actually becoming higher than in traditional single system development. Also, testing often cannot keep pace with accelerated development in product line engineering due to technical and organizational issues. This paper advocates that testing of product lines can be made more efficient and effective by considering testability already during architectural design. It explores the relationship between testability and product line architecture and discusses the importance of high testability for reducing product line testing effort and achieving required coverage criteria. The paper also outlines a systematic approach that will support product line organizations in improving and evaluating testability of product lines at the architectural level.},
booktitle = {Proceedings of the ISSTA 2006 Workshop on Role of Software Architecture for Testing and Analysis},
pages = {22–27},
numpages = {6},
keywords = {testing, testability, software product line, evaluation, design, architecture},
location = {Portland, Maine},
series = {ROSATEA '06}
}

@inproceedings{10.1145/3023956.3023968,
author = {Mjeda, Anila and Wasala, Asanka and Botterweck, Goetz},
title = {Decision spaces in product lines, decision analysis, and design exploration: an interdisciplinary exploratory study},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023968},
doi = {10.1145/3023956.3023968},
abstract = {Context. From recent works on product properties resulting from configurations and the optimisation of these properties, one comes quickly to more complex challenges such as multi-objective optimisation, conflicting objectives, multiple stakeholders, and conflict resolution. The intuition is that Software Product Line Engineering (SPLE) can draw from other disciplines that deal with decision spaces and complex decision scenarios.Objectives. We aim to (1) explore links to such disciplines, (2) systematise and compare concepts, and (3) identify opportunities, where SPLE approaches can be enriched.Method. We undertake an exploratory study: Starting from common SPLE activities and artefacts, we identify aspects where we expect to find corresponding counterparts in other disciplines. We focus on Multiple Criteria Decision Analysis (MCDA), Multi-Objective Optimisation (MOO), and Design Space Exploration (DSE), and perform a comparison of the key concepts.Results. The resulting comparison relates SPLE activities and artefacts to concepts from MCDA, MOO, and DSE and identifies areas where SPLE approaches can be enriched. We also provide examples of existing work at the intersections of SPLE with the other fields. These findings are aimed to foster the conversation on research opportunities where SPLE can draw techniques from other disciplines dealing with complex decision scenarios.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {68–75},
numpages = {8},
keywords = {multi-objective optimisation, multi-criteria decision analysis, design-space exploration, decision modelling},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1007/978-3-642-33666-9_46,
author = {Ali, Shaukat and Yue, Tao and Briand, Lionel and Walawege, Suneth},
title = {A product line modeling and configuration methodology to support model-based testing: an industrial case study},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_46},
doi = {10.1007/978-3-642-33666-9_46},
abstract = {Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behavioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {726–742},
numpages = {17},
keywords = {product line engineering, model-based testing, behavioral variability, aspect-oriented modeling, UML state machine},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1109/ECBS.2008.53,
author = {Thao, Cheng and Munson, Ethan V. and Nguyen, Tien N.},
title = {Software Configuration Management for Product Derivation in Software Product Families},
year = {2008},
isbn = {9780769531410},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ECBS.2008.53},
doi = {10.1109/ECBS.2008.53},
abstract = {A key process in software product line (SPL) engineering is product derivation, which is the process of building software products from a base set of core assets. During product derivation, the components in both core assets and derived software products are modified to meet needs for different functionality, platforms, quality attributes, etc. However, existing software configuration management (SCM) systems do not sufficiently support the derivation process in SPL. In this paper, we introduce a novel SCM system that is well-suited for product derivation in SPL. Our tool, MoSPL handles version management at the component level via its product versioning and data models. It explicitly manages logical constraints and derivation relations among components in both core assets and derived products, thus enabling the automatic propagation of changes in the core assets to their copies in derived products and vice versa. The system can also detect conflicting changes to different copies of components in software product lines.},
booktitle = {Proceedings of the 15th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems},
pages = {265–274},
numpages = {10},
keywords = {Software Product Line, Software Configuration Management, Product Derivation},
series = {ECBS '08}
}

@inproceedings{10.1145/1944892.1944913,
author = {Nguyen, Tuan and Colman, Alan and Talib, Muhammad Adeel and Han, Jun},
title = {Managing service variability: state of the art and open issues},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944913},
doi = {10.1145/1944892.1944913},
abstract = {In addition to inherited characteristics from software variability, service variability exposes two distinct characteristics that impose certain challenges in variability management. These characteristics are: i) Different types of variability and their inter-relationships; and ii) Dynamic and recursive variability communication among different stakeholders. This paper elaborates these distinct characteristics in detail with a case study. The challenges brought about by these distinct characteristics in managing variability also are highlighted. We present a review of related work in service variability management and briefly propose our ongoing approach to addressing these challenges.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {165–173},
numpages = {9},
keywords = {web services, variability management, variability communication, service variability, service oriented computing},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@article{10.1016/j.cageo.2014.09.004,
author = {Buccella, Agustina and Cechich, Alejandra and Pol'la, Matias and Arias, Maximiliano and del Socorro Doldan, Maria and Morsan, Enrique},
title = {Marine ecology service reuse through taxonomy-oriented SPL development},
year = {2014},
issue_date = {December 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {73},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2014.09.004},
doi = {10.1016/j.cageo.2014.09.004},
abstract = {Nowadays, reusing software applications encourages researchers and industrials to collaborate in order to increase software quality and to reduce software development costs. However, effective reuse is not easy and only a limited portion of reusable models actually offers effective evidence regarding their appropriateness, usability and/or effectiveness. Focusing reuse on a particular domain, such as marine ecology, allows us to narrow the scope; and along with a systematic approach such as software product line development, helps us to potentially improving reuse. From our experiences developing a subdomain-oriented software product line (SPL for the marine ecology subdomain), in this paper we describe semantic resources created for assisting this development and thus promoting systematic software reuse. The main contributions of our work are focused on the definition of a standard conceptual model for marine ecology applications together with a set of services and guides which assist the process of product derivation. The services are structured in a service taxonomy (as a specialization of the ISO 19119 std) in which we create a new set of categories and services built over a conceptual model for marine ecology applications. We also define and exemplify a set of guides for composing the services of the taxonomy in order to fulfill different functionalities of particular systems in the subdomain. HighlightsSolutions for software reuse for GIS domains by using standard information.Domain-specific taxonomy for supporting the generation of software artifacts.Guides for using geographic services in order to fulfill different GIS functionalities of systems in the domain.Evaluation of the effectiveness of the taxonomy and guides when building an SPL and two derived products.Improvements on time and costs of new GIS products being developed.},
journal = {Comput. Geosci.},
month = dec,
pages = {108–121},
numpages = {14},
keywords = {Software reuse, ISO 19100 standards, Geographic information systems, Domain-specific taxonomies, Domain engineering}
}

@inproceedings{10.1145/1808937.1808939,
author = {Hartmann, Herman and Keren, Mila and Matsinger, Aart and Rubin, Julia and Trew, Tim and Yatzkar-Haham, Tali},
title = {Integrating heterogeneous components in software supply chains},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808939},
doi = {10.1145/1808937.1808939},
abstract = {Numerous software product lines today are built from components supplied by different vendors. Companies situated in the middle of a software supply chain must configure and integrate components from their suppliers and offer (partially configured) variants for their customers, who can then complete the configuration and use these components in product lines or products that they develop. Covering the entire product line often involves using components from multiple suppliers, many of which providing overlapping functionality. This leads to a product line with different possible alternatives for components. These components may use mismatched interfaces and therefore require glue for integration.In this paper we analyze the consequences of combining heterogeneous components -- components that are not designed using a common architecture -- in a product line. We describe the limitations of the current practice and the challenges that arise from combining such components and delivering partially configured products. We introduce a new variability pattern that allows us to deal with heterogeneous components implementing overlapping functionality. This pattern consists of a reference architectural model, as well as transformations that generate a partially configured application including artifacts for gluing mismatched components.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {8–15},
numpages = {8},
keywords = {variability, software supply chains, software product line engineering, software integration, resource constraint products, model driven engineering, component technology},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@inproceedings{10.1145/1409720.1409748,
author = {Nestor, Daren and Thiel, Steffen and Botterweck, Goetz and Cawley, Ciar\'{a}n and Healy, Patrick},
title = {Applying visualisation techniques in software product lines},
year = {2008},
isbn = {9781605581125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1409720.1409748},
doi = {10.1145/1409720.1409748},
abstract = {Software product lines of industrial size can easily incorporate thousands of variation points. This scale of variability can become extremely complex to manage resulting in a product development process that bears significant costs. One technique that can be applied beneficially in this context is visualisation. Visualisation is widely used in software engineering and has proven useful to amplify human cognition in data intensive applications. Adopting this technique in software product line engineering can help stakeholders in supporting essential work tasks and in enhancing their understanding of large and complex product lines.The research presented in this paper describes an integrated meta-model and research tool that employs visualisation techniques to address significant software product line tasks such as variability management and product derivation. Examples of the tasks are described and the ways in which these tasks can be further supported by utilising visualisation techniques are explained.},
booktitle = {Proceedings of the 4th ACM Symposium on Software Visualization},
pages = {175–184},
numpages = {10},
keywords = {visualisation, software product lines, interaction, feature configuration},
location = {Ammersee, Germany},
series = {SoftVis '08}
}

@article{10.1007/s10270-015-0459-z,
author = {S\'{a}nchez, Ana B. and Segura, Sergio and Parejo, Jos\'{e} A. and Ruiz-Cort\'{e}s, Antonio},
title = {Variability testing in the wild: the Drupal case study},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0459-z},
doi = {10.1007/s10270-015-0459-z},
abstract = {Variability testing techniques search for effective and manageable test suites that lead to the rapid detection of faults in systems with high variability. Evaluating the effectiveness of these techniques in realistic settings is a must, but challenging due to the lack of variability-intensive systems with available code, automated tests and fault reports. In this article, we propose using the Drupal framework as a case study to evaluate variability testing techniques. First, we represent the framework variability using a feature model. Then, we report on extensive non-functional data extracted from the Drupal Git repository and the Drupal issue tracking system. Among other results, we identified 3392 faults in single features and 160 faults triggered by the interaction of up to four features in Drupal v7.23. We also found positive correlations relating the number of bugs in Drupal features to their size, cyclomatic complexity, number of changes and fault history. To show the feasibility of our work, we evaluated the effectiveness of non-functional data for test case prioritization in Drupal. Results show that non-functional attributes are effective at accelerating the detection of faults, outperforming related prioritization criteria as test case similarity.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {173–194},
numpages = {22},
keywords = {Variability-intensive systems, Variability testing, Test case selection, Test case prioritization, Non-functional properties, Automated testing}
}

@inproceedings{10.1145/1509239.1509259,
author = {Niu, Nan and Easterbrook, Steve},
title = {Concept analysis for product line requirements},
year = {2009},
isbn = {9781605584423},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1509239.1509259},
doi = {10.1145/1509239.1509259},
abstract = {Traditional methods characterize a software product line's requirements using either functional or quality criteria. This appears to be inadequate to assess modularity, detect interferences, and analyze trade-offs. We take advantage of both symmetric and asymmetric views of aspects, and perform formal concept analysis to examine the functional and quality requirements of an evolving product line. The resulting concept lattice provides a rich notion which allows remarkable insights into the modularity and interactions of requirements. We formulate a number of problems that aspect-oriented product line requirements engineering should address, and present our solutions according to the concept lattice. We describe a case study applying our approach to analyze a mobile game product line's requirements, and review lessons learned.},
booktitle = {Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development},
pages = {137–148},
numpages = {12},
keywords = {quality attribute scenarios, product line engineering, functional requirements profiles, formal concept analysis},
location = {Charlottesville, Virginia, USA},
series = {AOSD '09}
}

@inproceedings{10.5555/2075806.2075908,
author = {Moreno-Rivera, Juan Manuel and Navarro, Elena and Cuesta, Carlos E.},
title = {Evolving KobrA to support SPL for WebGIS development},
year = {2011},
isbn = {9783642251252},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {SIGTel is a SME aimed at developing WebGIS application. It has a portfolio of products which are a combination of Open GIS components and its own developed components. Although most of these products share a common architecture and common features, they have to be customized according to the user requirements. Now, this SME is working at the improvement of the software development process by introducing a Software Product Line (SPL) approach to automate the process of development and deployment based on that common architecture, as well as reduce time to market and improve quality. The first step has been taken, and KobrA approach has been chosen as the basic methodology to start working. Now, the on-going work is to perform the Domain Engineering, being the management of variability one of the first issues to be resolved. Here, we present a combination of KobrA containment tree and Orthogonal Variation Model (OVM), as the selected alternative to model the variability by using the architecture of our WebGIS SPL.},
booktitle = {Proceedings of the 2011th Confederated International Conference on On the Move to Meaningful Internet Systems},
pages = {622–631},
numpages = {10},
keywords = {open GIS, component-based development, WebGIS, SPL, KobrA},
location = {Crete, Greece},
series = {OTM'11}
}

@inproceedings{10.5555/2820656.2820667,
author = {Buchmann, Thomas and Baumgartl, Johannes and Henrich, Dominik and Westfechtel, Bernhard},
title = {Robots and their variability: a societal challenge and a potential solution},
year = {2015},
publisher = {IEEE Press},
abstract = {A robot is essentially a real-time, distributed embedded system operating in a physical environment. Often, control and communication paths within the system are tightly coupled to the actual hardware configuration of the robot. Furthermore, the domain contains a high amount of variability on different levels, ranging from hardware, over software to the environment in which the robot is operated. Today, special robots are used in households to perform monotonous and recurring tasks like vacuuming or mowing the lawn. In the future there may be robots that can be configured and programmed for more complicated tasks, like washing dishes or cleaning up or to assist elderly people. Nowadays, programming a robot is a highly complex and challenging task, which can be carried out only by programmers with dedicated background in robotics. Societal acceptance of robots can only be achieved, if they are easy to program. In this paper we present our approach to provide customized programming environments enabling programmers without background knowledge in robotics to specify robot programs. Our solution was realized using product line techniques.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {27–30},
numpages = {4},
keywords = {software product line, robot, model-driven development, code generation, DSL},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1007/978-3-662-45234-9_20,
author = {Collet, Philippe},
title = {Domain Specific Languages for Managing Feature Models: Advances and Challenges},
year = {2014},
isbn = {9783662452332},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-45234-9_20},
doi = {10.1007/978-3-662-45234-9_20},
abstract = {Managing multiple and complex feature models is a tedious and error-prone activity in software product line engineering. Despite many advances in formal methods and analysis techniques, the supporting tools and APIs are not easily usable together, nor unified. In this paper, we report on the development and evolution of the Familiar Domain-Specific Language DSL. Its toolset is dedicated to the large scale management of feature models through a good support for separating concerns, composing feature models and scripting manipulations. We overview various applications of Familiar and discuss both advantages and identified drawbacks. We then devise salient challenges to improve such DSL support in the near future.},
booktitle = {Part I of the Proceedings of the 6th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change - Volume 8802},
pages = {273–288},
numpages = {16}
}

@article{10.1145/1183236.1183260,
author = {Sugumaran, Vijayan and Park, Sooyong and Kang, Kyo C.},
title = {Introduction},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183260},
doi = {10.1145/1183236.1183260},
journal = {Commun. ACM},
month = dec,
pages = {28–32},
numpages = {5}
}

@article{10.1016/j.csi.2019.04.011,
author = {Barros-Justo, Jos\'{e} L. and Benitti, Fabiane B.V. and Matalonga, Santiago},
title = {Trends in software reuse research: A tertiary study},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {66},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2019.04.011},
doi = {10.1016/j.csi.2019.04.011},
journal = {Comput. Stand. Interfaces},
month = oct,
numpages = {18},
keywords = {Tertiary study, Systematic literature review, Trends in software reuse, Software reuse}
}

@inproceedings{10.1145/3238147.3240466,
author = {Cashman, Mikaela and Cohen, Myra B. and Ranjan, Priya and Cottingham, Robert W.},
title = {Navigating the maze: the impact of configurability in bioinformatics software},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240466},
doi = {10.1145/3238147.3240466},
abstract = {The bioinformatics software domain contains thousands of applications for automating tasks such as the pairwise alignment of DNA sequences, building and reasoning about metabolic models or simulating growth of an organism. Its end users range from sophisticated developers to those with little computational experience. In response to their needs, developers provide many options to customize the way their algorithms are tuned. Yet there is little or no automated help for the user in determining the consequences or impact of the options they choose. In this paper we describe our experience working with configurable bioinformatics tools. We find limited documentation and help for combining and selecting options along with variation in both functionality and performance. We also find previously undetected faults. We summarize our findings with a set of lessons learned, and present a roadmap for creating automated techniques to interact with bioinformatics software. We believe these will generalize to other types of scientific software.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {757–767},
numpages = {11},
keywords = {software testing, configurability, bioinformatics},
location = {Montpellier, France},
series = {ASE '18}
}

@inproceedings{10.5555/1948805.1948817,
author = {Donko, Dzenana and Sabeta, Sead},
title = {Specific modeling of the business processes},
year = {2010},
isbn = {9789604742455},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {The paper describes a specific problem - the process of damage claim processing in insurance companies that is reported for earlier underwritten risk. During the analysis of this problem the model has been created that can be used in similar cases for the transfer of knowledge and facts from the real system in the information system model. These processes are normatively regulated to a feasible extent. Analysis of the implementation of the proposed model shows that the model may offer beside the transactional level also a component of intelligent systems, namely a component of monitoring activities. This model is based on domain modeling and it can be used in the context of the software product line - SPL because its characteristics fit into the setting of this approach in the development of the system.},
booktitle = {Proceedings of the 9th WSEAS International Conference on Data Networks, Communications, Computers},
pages = {62–66},
numpages = {5},
keywords = {software product line - SPL, intelligent systems, domain modeling, business processes},
location = {Faro, Portugal},
series = {DNCOCO'10}
}

@article{10.1016/j.jss.2019.02.027,
author = {Carbonnel, Jessie and Huchard, Marianne and Nebut, Cl\'{e}mentine},
title = {Modelling equivalence classes of feature models with concept lattices to assist their extraction from product descriptions},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.02.027},
doi = {10.1016/j.jss.2019.02.027},
journal = {J. Syst. Softw.},
month = jun,
pages = {1–23},
numpages = {23},
keywords = {Feature models, Variability modelling, Formal concept analysis, Reverse engineering, Software product lines}
}

@inproceedings{10.1145/1593105.1593152,
author = {Im, Kyungsoo and Im, Tacksoo and McGregor, John D.},
title = {Automating test case definition using a domain specific language},
year = {2008},
isbn = {9781605581057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1593105.1593152},
doi = {10.1145/1593105.1593152},
abstract = {Effective test cases are critical to the success of a development effort but their creation requires large amounts of critical resources such as domain expertise. This study explores an approach to automating test case definition in the context of applying a model driven approach to the development of a software product line. In this study, test cases are automatically extracted from use cases, which are specified using a domain specific language (DSL). DSLs are easier for domain experts to use than formal specification languages and are more narrowly focused than natural languages making it easier to build tools. The task is further simplified by restricting the DSL to the scope of the software product line under development. The structure of the DSL and proven patterns of test design provide the clues necessary to be able to automatically extract the test cases. A chain of model-driven tools is used to automate the system test process, which begins with a use case model and ends with automatic execution of system tests.},
booktitle = {Proceedings of the 46th Annual ACM Southeast Conference},
pages = {180–185},
numpages = {6},
keywords = {domain specific language, ontology, software product line, software testing},
location = {Auburn, Alabama},
series = {ACMSE '08}
}

@inproceedings{10.5555/2022115.2022139,
author = {Jarzabek, Stan and Pettersson, Ulf and Zhang, Hongyu},
title = {University-industry collaboration journey towards product lines},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product Lines for mission critical Command and Control systems was a starting point for a long lasting research collaboration between National University of Singapore (NUS) and ST Electronics (Info-Software Systems) Pte Ltd (STEE-InfoSoft). Collaboration was intensified by a joint research project, also involving University of Waterloo and Netron Inc. that led to development of reuse technology called XVCL. The contribution of this paper is twofold: First, we describe collaboration modes, factors that were critical to sustain collaboration, and benefits for university and industry gained over years. Among the main benefits, STEE-InfoSoft advanced its reuse practice by applying XVCL in several software Product Line projects, while NUS team received early feedback from STEE-InfoSoft which helped refine XVCL reuse methods and keep academic research in sync with industrial realities. Academic findings and industrial pilots have opened new unexpected research directions. Second, we draw lessons learned from many projects, to explain the general nature and significance of problems addressed with the XVCL approach.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {223–237},
numpages = {15},
keywords = {variability management, software product lines, industry collaboration, generative technique},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.5555/1885639.1885675,
author = {Clements, Paul and McGregor, John D. and Bass, Len},
title = {Eliciting and capturing business goals to inform a product line's business case and architecture},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Business goals constitute an important kind of knowledge for a software product line. They inform the product line's business case and they inform its architecture and quality attribute requirements. This paper establishes the connection between business goals and a product line's business case and architecture. It then presents a set of common business goal categories, gleaned from a systematic search of the business literature that can be used to elicit an organization's business goals from key stakeholders. Finally, it presents a well-defined method, which we have tried out in practice, for eliciting and capturing business goals and tying them to quality attribute requirements.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {393–405},
numpages = {13},
keywords = {software product line, quality attribute requirements, product line architecture, business goals, business goal scenario, business case, architecture},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1007/978-3-642-33119-0_13,
author = {Lopez-Herrejon, Roberto Erick and Galindo, Jos\'{e} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
title = {Reverse engineering feature models with evolutionary algorithms: an exploratory study},
year = {2012},
isbn = {9783642331183},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33119-0_13},
doi = {10.1007/978-3-642-33119-0_13},
abstract = {Successful software evolves, more and more commonly, from a single system to a set of system variants tailored to meet the similiar and yet different functionality required by the distinct clients and users. Software Product Line Engineering (SPLE) is a software development paradigm that has proven effective for coping with this scenario. At the core of SPLE is variability modeling which employs Feature Models (FMs) as the de facto standard to represent the combinations of features that distinguish the systems variants. Reverse engineering FMs consist in constructing a feature model from a set of products descriptions. This research area is becoming increasingly active within the SPLE community, where the problem has been addressed with different perspectives and approaches ranging from analysis of configuration scripts, use of propositional logic or natural language techniques, to ad hoc algorithms. In this paper, we explore the feasibility of using Evolutionary Algorithms (EAs) to synthesize FMs from the feature sets that describe the system variants. We analyzed 59 representative case studies of different characteristics and complexity. Our exploratory study found that FMs that denote proper supersets of the desired feature sets can be obtained with a small number of generations. However, reducing the differences between these two sets with an effective and scalable fitness function remains an open question. We believe that this work is a first step towards leveraging the extensive wealth of Search-Based Software Engineering techniques to address this and other variability management challenges.},
booktitle = {Proceedings of the 4th International Conference on Search Based Software Engineering},
pages = {168–182},
numpages = {15},
location = {Riva del Garda, Italy},
series = {SSBSE'12}
}

@article{10.1016/j.scico.2017.10.013,
author = {Castro, Thiago and Lanna, Andr and Alves, Vander and Teixeira, Leopoldo and Apel, Sven and Schobbens, Pierre-Yves},
title = {All roads lead to Rome},
year = {2018},
issue_date = {January 2018},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2017.10.013},
doi = {10.1016/j.scico.2017.10.013},
abstract = {The formalization of seven strategies for product-line reliability analysis.The first feature-family-product-based strategy for product-line model checking.A general principle for lifting analyses to product lines using ADDs.Proofs that the formalized strategies commute.All strategies proven sound with respect to single-product reliability analysis. Software product line engineering is a means to systematically manage variability and commonality in software systems, enabling the automated synthesis of related programs (products) from a set of reusable assets. However, the number of products in a software product line may grow exponentially with the number of features, so it is practically infeasible to quality-check each of these products in isolation. There is a number of variability-aware approaches to product-line analysis that adapt single-product analysis techniques to cope with variability in an efficient way. Such approaches can be classified along three analysis dimensions (product-based, family-based, and feature-based), but, particularly in the context of reliability analysis, there is no theory comprising both (a) a formal specification of the three dimensions and resulting analysis strategies and (b) proof that such analyses are equivalent to one another. The lack of such a theory hinders formal reasoning on the relationship between the analysis dimensions and derived analysis techniques. We formalize seven approaches to reliability analysis of product lines, including the first instance of a feature-family-product-based analysis in the literature. We prove the formalized analysis strategies to be sound with respect to the probabilistic approach to reliability analysis of a single product. Furthermore, we present a commuting diagram of intermediate analysis steps, which relates different strategies and enables the reuse of soundness proofs between them.},
journal = {Sci. Comput. Program.},
month = jan,
pages = {116–160},
numpages = {45},
keywords = {Verification, Software product lines, Reliability analysis, Product-line analysis, Model checking}
}

@article{10.1007/s00165-017-0432-4,
author = {Chrszon, Philipp and Dubslaff, Clemens and Kl\"{u}ppelholz, Sascha and Baier, Christel},
title = {ProFeat: feature-oriented engineering for family-based probabilistic model checking},
year = {2018},
issue_date = {Jan 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {1},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-017-0432-4},
doi = {10.1007/s00165-017-0432-4},
abstract = {The concept of features provides an elegant way to specify families of systems. Given a base system, features encapsulate additional functionalities that can be activated or deactivated to enhance or restrict the base system’s behaviors. Features can also facilitate the analysis of families of systems by exploiting commonalities of the family members and performing an all-in-one analysis, where all systems of the family are analyzed at once on a single family model instead of one-by-one. Most prominent, the concept of features has been successfully applied to describe and analyze (software) product lines. We present the tool ProFeat that supports the feature-oriented engineering process for stochastic systems by probabilistic model checking. To describe families of stochastic systems, ProFeat extends models for the prominent probabilistic model checker Prism by feature-oriented concepts, including support for probabilistic product lines with dynamic feature switches, multi-features and feature attributes. ProFeat provides a compact symbolic representation of the analysis results for each family member obtained by Prism to support, e.g., model repair or refinement during feature-oriented development. By means of several case studies we show how ProFeat eases family-based quantitative analysis and compare one-by-one and all-in-one analysis approaches.},
journal = {Form. Asp. Comput.},
month = jan,
pages = {45–75},
numpages = {31},
keywords = {Software product line analysis, Probabilistic model checking, Feature-oriented systems}
}

@inproceedings{10.1145/3183440.3183480,
author = {Kr\"{o}her, Christian and El-Sharkawy, Sascha and Schmid, Klaus},
title = {KernelHaven: an experimentation workbench for analyzing software product lines},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183480},
doi = {10.1145/3183440.3183480},
abstract = {Systematic exploration of hypotheses is a major part of any empirical research. In software engineering, we often produce unique tools for experiments and evaluate them independently on different data sets. In this paper, we present KernelHaven as an experimentation workbench supporting a significant number of experiments in the domain of static product line analysis and verification. It addresses the need for extracting information from a variety of artifacts in this domain by means of an open plug-in infrastructure. Available plug-ins encapsulate existing tools, which can now be combined efficiently to yield new analyses. As an experimentation workbench, it provides configuration-based definitions of experiments, their documentation, and technical services, like parallelization and caching. Hence, researchers can abstract from technical details and focus on the algorithmic core of their research problem.KernelHaven supports different types of analyses, like correctness checks, metrics, etc., in its specific domain. The concepts presented in this paper can also be transferred to support researchers of other software engineering domains. The infrastructure is available under Apache 2.0: https://github.com/KernelHaven. The plug-ins are available under their individual licenses.Video: https://youtu.be/IbNc-H1NoZU},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {73–76},
numpages = {4},
keywords = {empirical software engineering, software product line analysis, static analysis, variability extraction},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.5555/2748144.2748397,
author = {Classen, Andreas and Cordy, Maxime and Heymans, Patrick and Legay, Axel and Schobbens, Pierre-Yves},
title = {Formal semantics, modular specification, and symbolic verification of product-line behaviour},
year = {2014},
issue_date = {February 2014},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {80},
number = {PB},
issn = {0167-6423},
abstract = {Formal techniques for specifying and verifying Software Product Lines (SPL) are actively studied. While the foundations of this domain recently made significant progress with the introduction of Featured Transition Systems (FTSs) and associated algorithms, SPL model checking still faces the well-known state explosion problem. Moreover, there is a need for high-level specification languages usable in industry. We address the state explosion problem by applying the principles of symbolic model checking to FTS-based verification of SPLs. In order to specify properties on specific products only, we extend the temporal logic CTL with feature quantifiers. Next, we show how SPL behaviour can be specified with fSMV, a variant of SMV, the specification language of the industry-strength model checker NuSMV. fSMV is a feature-oriented extension of SMV originally introduced by Plath and Ryan. We prove that fSMV and FTSs are expressively equivalent. Finally, we connect these results to a NuSMV extension we developed for verifying SPLs against CTL properties. We use Featured Transition Systems (FTS) to model Software Product Lines (SPLs).We design symbolic algorithms for checking an FTS against temporal properties.We give a new compositional formal semantics to the fSMV language.We prove the expressiveness equivalence between fSMV and FTS.We evaluate practical implications of our results through our toolset and case study.},
journal = {Sci. Comput. Program.},
month = feb,
pages = {416–439},
numpages = {24},
keywords = {Verification, Specification, Software product line, Language, Feature}
}

@article{10.1007/s10515-010-0076-6,
author = {Dhungana, Deepak and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {The DOPLER meta-tool for decision-oriented variability modeling: a multiple case study},
year = {2011},
issue_date = {March     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-010-0076-6},
doi = {10.1007/s10515-010-0076-6},
abstract = {The variability of a product line is typically defined in models. However, many existing variability modeling approaches are rigid and don't allow sufficient domain-specific adaptations. We have thus been developing a flexible and extensible approach for defining product line variability models. Its main purposes are to guide stakeholders through product derivation and to automatically generate product configurations. Our approach is supported by the DOPLER (  D ecision-  O riented  P roduct  L ine  E ngineering for effective  R euse) meta-tool that allows modelers to specify the types of reusable assets, their attributes, and dependencies for their specific system and context. The aim of this paper is to investigate the suitability of our approach for different domains. More specifically, we explored two research questions regarding the implementation of variability and the utility of DOPLER for variability modeling in different domains. We conducted a multiple case study consisting of four cases in the domains of industrial automation systems and business software. In each of these case studies we analyzed variability implementation techniques. Experts from our industry partners then developed domain-specific meta-models, tool extensions, and variability models for their product lines using DOPLER. The four cases demonstrate the flexibility of the DOPLER approach and the extensibility and adaptability of the supporting meta tool.},
journal = {Automated Software Engg.},
month = mar,
pages = {77–114},
numpages = {38},
keywords = {Product line engineering, Meta-tools, Decision models}
}

@inproceedings{10.1145/1062455.1062552,
author = {Schmid, Klaus and John, Isabel and Kolb, Ronny and Meier, Gerald},
title = {Introducing the puLSE approach to an embedded system population at testo AG},
year = {2005},
isbn = {1581139632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1062455.1062552},
doi = {10.1145/1062455.1062552},
abstract = {Over the last few years, product line engineering has become a major theme in software engineering research, and is increasingly becoming a central topic of software engineering practice in the embedded domain.Migrating towards a product line approach is not an easy feat. It is even less so, if it is done under tight technology constraints in an embedded environment. It becomes even more difficult if the transition directly aims at integrating two product families into a single product population. In this paper, we discuss our experiences with a project where we successfully dealt with these difficulties and achieved a successful product line transition. In our paper we strongly emphasize the role of technology transfer, as many facets of product line know-how had to be transferred to guarantee a complete transition to product line engineering. From the experiences of this project many lessons learned can be deduced, which can be transferred to different environments.},
booktitle = {Proceedings of the 27th International Conference on Software Engineering},
pages = {544–552},
numpages = {9},
keywords = {technology transfer, systematic software reuse, software product line, product line introduction},
location = {St. Louis, MO, USA},
series = {ICSE '05}
}

@inproceedings{10.1007/978-3-642-37057-1_5,
author = {Haslinger, Evelyn Nicole and Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
title = {On extracting feature models from sets of valid feature combinations},
year = {2013},
isbn = {9783642370564},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-37057-1_5},
doi = {10.1007/978-3-642-37057-1_5},
abstract = {Rather than developing individual systems, Software Product Line Engineering develops families of systems. The members of the software family are distinguished by the features they implement and Feature Models (FMs) are the de facto standard for defining which feature combinations are considered valid members. This paper presents an algorithm to automatically extract a feature model from a set of valid feature combinations, an essential development step when companies, for instance, decide to convert their existing product variations portfolio into a Software Product Line. We performed an evaluation on 168 publicly available feature models, with 9 to 38 features and up to 147456 feature combinations. From the generated feature combinations of each of these examples, we reverse engineered an equivalent feature model with a median performance in the low milliseconds.},
booktitle = {Proceedings of the 16th International Conference on Fundamental Approaches to Software Engineering},
pages = {53–67},
numpages = {15},
keywords = {variability modeling, software product lines, reverse engineering, feature set, feature models, feature},
location = {Rome, Italy},
series = {FASE'13}
}

@inproceedings{10.5555/2093889.2093921,
author = {Bagheri, Ebrahim and Asadi, Mohsen and Ensan, Faezeh and Ga\v{s}evi\'{c}, Dragan and Mohabbati, Bardia},
title = {Bringing semantics to feature models with SAFMDL},
year = {2011},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software product line engineering is a paradigm that advocates the reusability of software engineering assets and the rapid development of new applications for a target domain. These objectives are achieved by capturing the commonalities and variabilities between the applications of a target domain and through the development of comprehensive and variability-covering domain models. The domain models developed within the software product line development process need to cover all of the possible features and aspects of the target domain. In other words, the domain models often described using feature models should be elaborate representations of the feature space of that domain. In order to operationalize feature-based representations of a software application, appropriate implementation mechanisms need to be employed. In this paper, we propose a Semantic Web-oriented language, called Semantic Annotations for Feature Modeling Description Language (SAFMDL) that provides the means to semantically describe feature models. We will show that using SAFMDL along with Semantic Web Query techniques, we are able to bridge the gap between software product lines and SOA technology. Our proposed work allows software practitioners to use Semantic Web technology to quickly and rapidly develop new software products based on SOA technology from software product lines.},
booktitle = {Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {287–300},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {CASCON '11}
}

@article{10.1016/j.procs.2019.12.135,
author = {Jamil, Muhammad Abid and Nour, Mohamed K and Alhindi, Ahmad and Awang Abhubakar, Normi Sham and Arif, Muhammad and Aljabri, Tareq Fahad},
title = {Towards Software Product Lines Optimization Using Evolutionary Algorithms},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {163},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.12.135},
doi = {10.1016/j.procs.2019.12.135},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {527–537},
numpages = {11},
keywords = {Multi-objective Algorithms, Feature Models, Software Product Lines, Software Testing, Search Based Software Engineering}
}

@inproceedings{10.5555/1885639.1885685,
author = {Medeiros, Fl\'{a}vio M. and de Almeida, Eduardo S. and Meira, Silvio R. L.},
title = {SOPLE-DE: an approach to design service-oriented product line architectures},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software reuse is crucial for enterprises interested in software quality and productivity gains. In this context, Software Product Line (SPL) and Service-Oriented Architecture (SOA) are two reuse strategies that share common goals and can be used together to increase reuse and produce service-oriented systems faster, cheaper and customizable to specific customers. In this sense, this work investigates the problem of designing software product lines using service-oriented architectures, and presents a systematic approach to design software product lines based on services. The proposed approach provides guidance to identify, design and document architectural components, services, service compositions and their associated flows. In addition, an initial experimental study performed with the intention of validating and refining the approach is also depicted demonstrating that the proposed solution can be viable.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {456–460},
numpages = {5},
keywords = {software product line (SPL), software architecture and software development processes, service-oriented architecture (SOA)},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/2884781.2884823,
author = {Schr\"{o}ter, Reimar and Krieter, Sebastian and Th\"{u}m, Thomas and Benduhn, Fabian and Saake, Gunter},
title = {Feature-model interfaces: the highway to compositional analyses of highly-configurable systems},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884823},
doi = {10.1145/2884781.2884823},
abstract = {Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satisfiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {667–678},
numpages = {12},
keywords = {variability modeling, software product line, modularity, feature model, configurable software, compositionality},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1016/j.infsof.2014.04.002,
author = {Machado, Ivan Do Carmo and Mcgregor, John D. and Cavalcanti, Yguarat\~{a} Cerqueira and De Almeida, Eduardo Santana},
title = {On strategies for testing software product lines: A systematic literature review},
year = {2014},
issue_date = {October, 2014},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {56},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2014.04.002},
doi = {10.1016/j.infsof.2014.04.002},
abstract = {Context: Testing plays an important role in the quality assurance process for software product line engineering. There are many opportunities for economies of scope and scale in the testing activities, but techniques that can take advantage of these opportunities are still needed. Objective: The objective of this study is to identify testing strategies that have the potential to achieve these economies, and to provide a synthesis of available research on SPL testing strategies, to be applied towards reaching higher defect detection rates and reduced quality assurance effort. Method: We performed a literature review of two hundred seventy-six studies published from the year 1998 up to the 1st semester of 2013. We used several filters to focus the review on the most relevant studies and we give detailed analyses of the core set of studies. Results: The analysis of the reported strategies comprised two fundamental aspects for software product line testing: the selection of products for testing, and the actual test of products. Our findings indicate that the literature offers a large number of techniques to cope with such aspects. However, there is a lack of reports on realistic industrial experiences, which limits the inferences that can be drawn. Conclusion: This study showed a number of leveraged strategies that can support both the selection of products, and the actual testing of products. Future research should also benefit from the problems and advantages identified in this study.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1183–1199},
numpages = {17},
keywords = {Systematic literature review, Software testing, Software quality, Software product lines}
}

@inproceedings{10.1109/ASE.2013.6693103,
author = {Pohl, Richard and Stricker, Vanessa and Pohl, Klaus},
title = {Measuring the structural complexity of feature models},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693103},
doi = {10.1109/ASE.2013.6693103},
abstract = {The automated analysis of feature models (FM) is based on SAT, BDD, and CSP - known NP-complete problems. Therefore, the analysis could have an exponential worst-case execution time. However, for many practical relevant analysis cases, state-of-the-art (SOTA) analysis tools quite successfully master the problem of exponential worst-case execution time based on heuristics. So far, however, very little is known about the structure of FMs that cause the cases in which the execution time (hardness) for analyzing a given FM increases unpredictably for SOTA analysis tools. In this paper, we propose to use width measures from graph theory to characterize the structural complexity of FMs as a basis for an estimation of the hardness of analysis operations on FMs with SOTA analysis tools. We present an experiment that we use to analyze the reasonability of graph width measures as metric for the structural complexity of FMs and the hardness of FM analysis. Such a complexity metric can be used as a basis for a unified method to systematically improve SOTA analysis tools.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {454–464},
numpages = {11},
keywords = {software product line, performance measurement, feature model, automated analysis},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1145/1629716.1629735,
author = {Asadi, Mohsen and Mohabbati, Bardia and Kaviani, Nima and Ga\v{s}evi\'{c}, Dragan and Bo\v{s}kovi\'{c}, Marko and Hatala, Marek},
title = {Model-driven development of families of Service-Oriented Architectures},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629735},
doi = {10.1145/1629716.1629735},
abstract = {The paradigms of Service Oriented Architecture (SOA) and Software Product Line Engineering (SPLE) facilitate the development of families of software-intensive products. Software Product Line practices can be leveraged to support the development of service-oriented applications to promote the reusability of assets throughout the iterative and incremental development of software product families. Such an approach enables various service oriented business processes and software products of the same family to be systematically created and integrated. In this paper, we advocate integration of software product line engineering with model driven engineering to enable a model driven specification of software services, capable of creating software products from a family of software services. Using the proposed method, we aim to provide a consistent view of a composed software system from a higher business administration perspective to lower levels of service implementation and deployment. We demonstrate how Model Driven Engineering (MDE) can help with injecting the set of required commonalities and variabilities of a software product from a high level business process design to the lower levels of service use.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {95–102},
numpages = {8},
keywords = {business process management, semantic web, service-oriented architectures, software product lines},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@article{10.4018/IJCAC.2019100105,
author = {Aouzal, Khadija and Hafiddi, Hatim and Dahchour, Mohamed},
title = {Policy-Driven Middleware for Multi-Tenant SaaS Services Configuration},
year = {2019},
issue_date = {Oct 2019},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {4},
issn = {2156-1834},
url = {https://doi.org/10.4018/IJCAC.2019100105},
doi = {10.4018/IJCAC.2019100105},
abstract = {The multi-tenancy architecture allows software-as-a-service applications to serve multiple tenants with a single instance. This is beneficial as it leverages economies of scale. However, it does not cope with the specificities of each tenant and their variability; notably, the variability induced in the required quality levels that differ from a tenant to another. Hence, sharing one single instance hampers the fulfillment of these quality levels for all the tenants and leads to service level agreement violations. In this context, this article proposes a policy-driven middleware that configures the service according to the non-functional requirements of the tenants. The adopted approach combines software product lines engineering and model driven engineering principles. It spans the quality attributes lifecycle, from documenting them to annotating the service components with them as policies, and it enables dynamic configuration according to service level agreements terms of the tenants.},
journal = {Int. J. Cloud Appl. Comput.},
month = oct,
pages = {86–106},
numpages = {21},
keywords = {SPLE, SLA, SaaS, Policy, Non-Functional Variability, Multi-Tenancy, MDE}
}

@article{10.1016/j.jss.2008.08.026,
author = {Lago, Patricia and Muccini, Henry and van Vliet, Hans},
title = {A scoped approach to traceability management},
year = {2009},
issue_date = {January, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2008.08.026},
doi = {10.1016/j.jss.2008.08.026},
abstract = {Traceability is the ability to describe and follow the life of a software artifact and a means for modeling the relations between software artifacts in an explicit way. Traceability has been successfully applied in many software engineering communities and has recently been adopted to document the transition among requirements, architecture and implementation. We present an approach to customize traceability to the situation at hand. Instead of automating tracing, or representing all possible traces, we scope the traces to be maintained to the activities stakeholders must carry out. We define core traceability paths, consisting of essential traceability links required to support the activities. We illustrate the approach through two examples: product derivation in software product lines, and release planning in software process management. By using a running software product line example, we explain why the core traceability paths identified are needed when navigating from feature to structural models and from family to product level and backward between models used in software product derivation. A feasibility study in release planning carried out in an industrial setting further illustrates the use of core traceability paths during production and measures the increase in performance of the development processes supported by our approach. These examples show that our approach can be successfully used to support both product and process traceability in a pragmatic yet efficient way.},
journal = {J. Syst. Softw.},
month = jan,
pages = {168–182},
numpages = {15},
keywords = {Traceability paths, Traceability issues, Software product line, Software process management}
}

@inproceedings{10.1007/978-3-540-68073-4_16,
author = {Etxeberria, Leire and Sagardui, Goiuria},
title = {Quality Assessment in Software Product Lines},
year = {2008},
isbn = {9783540680628},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-68073-4_16},
doi = {10.1007/978-3-540-68073-4_16},
abstract = {In a software product line, quality assessment is especially important because an error or an inadequate design decision can be spread into a lot of products. Moreover, in a product line, different members of the line may require different quality attributes. In this paper, a method for quality aware software product line engineering that takes into account the variability of quality aspects and facilitates quality assessment is presented.},
booktitle = {Proceedings of the 10th International Conference on Software Reuse: High Confidence Software Reuse in Large Systems},
pages = {178–181},
numpages = {4},
location = {Beijing, China},
series = {ICSR '08}
}

@article{10.1007/s00766-013-0184-5,
author = {Alf\'{e}rez, Mauricio and Bonif\'{a}cio, Rodrigo and Teixeira, Leopoldo and Accioly, Paola and Kulesza, Uir\'{a} and Moreira, Ana and Ara\'{u}jo, Jo\~{a}o and Borba, Paulo},
title = {Evaluating scenario-based SPL requirements approaches: the case for modularity, stability and expressiveness},
year = {2014},
issue_date = {November  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0184-5},
doi = {10.1007/s00766-013-0184-5},
abstract = {Software product lines (SPL) provide support for productivity gains through systematic reuse. Among the various quality attributes supporting these goals, modularity,
 stability and expressiveness of feature specifications, their composition and configuration knowledge emerge as strategic values in modern software development paradigms. This paper presents a metric-based evaluation aiming at assessing how well the chosen qualities are supported by scenario-based SPL requirements
approaches. The selected approaches for this study span from type of notation (textual or graphical based), style to support variability (annotation or composition based), and specification expressiveness. They are compared using the metrics developed in a set of releases from an exemplar case study. Our major findings indicate that composition-based approaches have greater potential to support modularity and stability, and that quantification mechanisms simplify and increase expressiveness of configuration knowledge and composition specifications.},
journal = {Requir. Eng.},
month = nov,
pages = {355–376},
numpages = {22},
keywords = {Requirements specification, Software product lines, Use scenarios, Variability modeling}
}

@article{10.1145/2211616.2211617,
author = {K\"{a}stner, Christian and Apel, Sven and Th\"{u}m, Thomas and Saake, Gunter},
title = {Type checking annotation-based product lines},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2211616.2211617},
doi = {10.1145/2211616.2211617},
abstract = {Software product line engineering is an efficient means of generating a family of program variants for a domain from a single code base. However, because of the potentially high number of possible program variants, it is difficult to test them all and ensure properties like type safety for the entire product line. We present a product-line-aware type system that can type check an entire software product line without generating each variant in isolation. Specifically, we extend the Featherweight Java calculus with feature annotations for product-line development and prove formally that all program variants generated from a well typed product line are well typed. Furthermore, we present a solution to the problem of typing mutually exclusive features. We discuss how results from our formalization helped implement our own product-line tool CIDE for full Java and report of our experience with detecting type errors in four existing software product line implementations.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {14},
numpages = {39},
keywords = {type system, software product lines, conditional compilation, Featherweight Java, CIDE, CFJ, #ifdef}
}

@article{10.4018/IJAEC.2015070102,
author = {Benlarabi, Anissa and Khtira, Amal and El Asri, Bouchra},
title = {A Co-Evolution Analysis for Software Product Lines: An Approach based on Evolutionary Trees},
year = {2015},
issue_date = {July 2015},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {3},
issn = {1942-3594},
url = {https://doi.org/10.4018/IJAEC.2015070102},
doi = {10.4018/IJAEC.2015070102},
abstract = {In this rapidly changing world, business strategies continuously evolve to meet customers' wishes. Hence, the ability to cope with the frequent business changes is becoming important criteria of a leading development paradigm. Software product line engineering is a development paradigm based on reuse that builds a common platform from which a set of applications can be derived. Despite its advantage of enhancing time to market and costs, it is exposed to the risk of falling into the aging phenomenon because of the complexity of its evolution. In this paper the authors present a co-evolution based approach for protecting the software product lines from the aging phenomenon. The approach uses cladistics and trees reconciliation that are mainly used in biology to analyze the co-evolution between organisms. The authors' major goal is to find out changes of products that were not propagated to the common platform at the aim of reconsidering them in the platform and thus protecting it from being obsolete.},
journal = {Int. J. Appl. Evol. Comput.},
month = jul,
pages = {9–32},
numpages = {24},
keywords = {Software Product Lines, Evolutionary Trees, Co-Evolution, Cladistics}
}

@inproceedings{10.5555/1885639.1885661,
author = {Stricker, Vanessa and Metzger, Andreas and Pohl, Klaus},
title = {Avoiding redundant testing in application engineering},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Many software product line testing techniques have been presented in the literature. The majority of those techniques address how to define reusable test assets (such as test models or test scenarios) in domain engineering and how to exploit those assets during application engineering. In addition to test case reuse however, the execution of test cases constitutes one important activity during application testing. Without a systematic support for the test execution in application engineering, while considering the specifics of product lines, product line artifacts might be tested redundantly. Redundant testing in application engineering, however, can lead to an increased testing effort without increasing the chance of uncovering failures. In this paper, we propose the model-based ScenTED-DF technique to avoid redundant testing in application engineering. Our technique builds on data flow-based testing techniques for single systems and adapts and extends those techniques to consider product line variability. The paper sketches the prototypical implementation of our technique to show its general feasibility and automation potential, and it describes the results of experiments using an academic product line to demonstrate that ScenTED-DF is capable of avoiding redundant tests in application engineering.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {226–240},
numpages = {15},
keywords = {software product line testing, regression testing, data flow, application engineering},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.5555/2666064.2666079,
author = {Saratxaga, C. L. and Alonso-Montes, C. and Haugen, O. and Ekelin, C. and Mitschke, A.},
title = {Product line tool-chain: variability in critical systems},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {Competitiveness has thrown industries towards adding more features to existent products increasing their inherent complexity. One of the main challenges is to define mechanisms and tools to control the propagation of the dependencies through the different engineering phases, keeping consistency among requirements and the final system design. SPL provide mechanisms to control the evolution and design of product families, based on an exhaustive variant analysis. However, the critical system industry does not adopt them due to the lack of tool support for the complete life-cycle. In this paper, a product line tool chain is presented based on the analysis of current SPL tools and approaches in order to fit the specific needs within industry partners in the CESAR project. The main goal is to show the benefits of a combination of SPL tools in an industrial scenario.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {57–60},
numpages = {4},
keywords = {variability management, product line tool chain, critical systems, SPL, PLUM, CVL, CESAR},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1109/SPLC.2011.38,
author = {Sinha, Subrata and Dasch, Thomas and Ruf, Reinhard},
title = {Governance and Cost Reduction through Multi-tier Preventive Performance Tests in a Large-Scale Product Line Development},
year = {2011},
isbn = {9780769544878},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2011.38},
doi = {10.1109/SPLC.2011.38},
abstract = {Experience has shown that maintaining software system performance in a complex product line development is a constant challenge, already achieved performance is often degraded over time because proper quality gates are rarely defined or implemented. The established practice of performance verification tests on an integrated software baseline is essential to ensure final quality of the delivered products, but is late if performance degradations already crept in. Maintenance of performance in software baselines requires an additional preventive approach. The faulty software changes that degrade performance can be identified (performance quality gates) before these changes can flow into the baseline and subsequently get rejected. This ensures that the software baseline maintains a consistent performance leading to more predictable schedules and development costs. For a complex software family involving parallel and dependent sub-projects of domain platforms and end user applications, these performance quality gates need to be established at multiple levels.},
booktitle = {Proceedings of the 2011 15th International Software Product Line Conference},
pages = {295–302},
numpages = {8},
keywords = {Preventive Test, Performance, Governance},
series = {SPLC '11}
}

@article{10.1016/j.entcs.2014.01.023,
author = {Rinc\'{o}n, L. F. and Giraldo, G. L. and Mazo, R. and Salinesi, C.},
title = {An Ontological Rule-Based Approach for Analyzing Dead and False Optional Features in Feature Models},
year = {2014},
issue_date = {February, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {302},
issn = {1571-0661},
url = {https://doi.org/10.1016/j.entcs.2014.01.023},
doi = {10.1016/j.entcs.2014.01.023},
abstract = {Feature models are a common way to represent variability requirements of software product lines by expressing the set of feature combinations that software products can have. Assuring quality of feature models is thus of paramount importance for assuring quality in software product line engineering. However, feature models can have several types of defects that disminish benefits of software product line engineering.Two of such defects are dead features and false optional features. Several state-of-the-art techniques identify these defects, but only few of them tackle the problem of identifying their causes. Besides, the explanations they provide are cumbersome and hard to understand by humans. In this paper, we propose an ontological rule-based approach to: (a) identify dead and false optional features; (b)identify certain causes of these defects; and (c) explain these causes in natural language helping modelers to correct found defects. We represent our approach with a feature model taken from literature. A preliminary empirical evaluation of our approach over 31 FMs shows that our proposal is effective, accurate and scalable to 150 features.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = feb,
pages = {111–132},
numpages = {22},
keywords = {Software Engineering, Ontologies, Feature Models, Defects}
}

@article{10.1007/s00766-013-0183-6,
author = {Lee, Jaejoon and Kang, Kyo C. and Sawyer, Pete and Lee, Hyesun},
title = {A holistic approach to feature modeling for product line requirements engineering},
year = {2014},
issue_date = {November  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0183-6},
doi = {10.1007/s00766-013-0183-6},
abstract = {Requirements engineering (RE) offers the means to discover, model, and manage the requirements of the products that comprise a product line, while software product line engineering (SPLE) offers the means of realizing the products' requirements from a common base of software assets. In practice, however, RE and SPLE have proven to be less complementary than they should. While some RE techniques, particularly goal modeling, support the exploration of alternative solutions, the appropriate solution is typically conditional on context and a large product line may have many product-defining contexts. Thus, scalability and traceability through into product line features are key challenges for RE. Feature modeling, by contrast, has been widely accepted as a way of modeling commonality and variability of products of a product line that may be very complex. In this paper, we propose a goal-driven feature modeling approach that separates a feature space in terms of problem space and solution space features, and establish explicit mappings between them. This approach contributes to reducing the inherent complexity of a mixed-view feature model, deriving key engineering drivers for developing core assets of a product line, and facilitating the quality-based product configuration.},
journal = {Requir. Eng.},
month = nov,
pages = {377–395},
numpages = {19},
keywords = {Product line requirements engineering, Goal modeling, Feature space, Feature modeling viewpoints, Feature modeling}
}

@inproceedings{10.1145/3131151.3131152,
author = {Filho, Helson L. Jakubovski and Lima, Jackson A. Prado and Vergilio, Silvia R.},
title = {Automatic Generation of Search-Based Algorithms Applied to the Feature Testing of Software Product Lines},
year = {2017},
isbn = {9781450353267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131151.3131152},
doi = {10.1145/3131151.3131152},
abstract = {The selection of products for the variability testing of Feature Models (FMs) is a complex task impacted by many factors. To solve this problem, Multi-Objective Evolutionary Algorithms (MOEAs) have been successfully used in the field known as Search-Based Software Engineering (SBSE). However, the design of a search-based approach is not an easy task for the software engineer, who can find some difficulties such as: the choice and configuration of the best MOEAs, the choice of the best search operators to be implemented, and so on. In addition to this, existing approaches are dependent on the problem domain and do not allow reuse. In this way the use of Hyper-Heuristic (HH) can help to obtain more generic and reusable search-based approaches, and because of this is considered a trend in the SBSE field. Following this trend and to contribute to reduce the software engineer's efforts, this work explores the use of a hyper-heuristic for automatic generation of MOEAs to select test products from the FM, considering three factors: pairwise coverage, mutation score and cost, given by the number of products. The HH is based on a grammar that represents the elements, parameters and components of existing MOEAs and implements evolutionary operators, such as crossover and mutation, suitable for selection problems. In this way, it can be reused for other similar software engineering problems. Evaluation results show that the proposed approach obtains results that are better or statistically equivalent than similar approaches found in the literature.},
booktitle = {Proceedings of the XXXI Brazilian Symposium on Software Engineering},
pages = {114–123},
numpages = {10},
keywords = {Software Product Line Testing, Search-Based Software Engineering, Hyper-Heuristics},
location = {Fortaleza, CE, Brazil},
series = {SBES '17}
}

@inproceedings{10.1007/978-3-642-27142-7_48,
author = {Kim, SeHoon and Choi, SeungYoung},
title = {Construction of online behavior monitoring system},
year = {2011},
isbn = {9783642271410},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-27142-7_48},
doi = {10.1007/978-3-642-27142-7_48},
abstract = {Recently, there is a trend of each school being equipped with class behavior analysis rooms for the improvement of class capability. However, many problems exist in the classroom monitoring system such as high cost, limitation of time and space on demonstrator and analyst, ineffective feedback method or difficulty of post self-analysis. In this paper, a method to reduce the cost of installing physical space and overcome the limitation of time for participation of specialists using class behavior analysis system design.},
booktitle = {Proceedings of the Third International Conference on Future Generation Information Technology},
pages = {406–412},
numpages = {7},
keywords = {software product line, online behavior monitoring, evaluation},
location = {Jeju Island, Korea},
series = {FGIT'11}
}

@inproceedings{10.5555/1885639.1885643,
author = {Lee, Kwanwoo and Kang, Kyo C.},
title = {Usage context as key driver for feature selection},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product derivation in software product line engineering starts with selection of variable features manifested in a feature model. Selection of variable features for a particular product, however, is not made arbitrarily. There are various factors affecting feature selection. We experienced that the usage context of a product is often the primary driver for feature selection. In this paper, we propose a model showing how product usage contexts are related to product features, and present a method for developing such a model during the domain engineering process and utilizing it to derive an optimal product configuration during the application engineering process. An elevator control software example is used to illustrate and validate the concept and the method.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {32–46},
numpages = {15},
keywords = {product usage contexts, product derivation, feature modeling, commonality and variability},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/2635868.2635876,
author = {Schultis, Klaus-Benedikt and Elsner, Christoph and Lohmann, Daniel},
title = {Architecture challenges for internal software ecosystems: a large-scale industry case study},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635876},
doi = {10.1145/2635868.2635876},
abstract = {The idea of software ecosystems encourages organizations to open software projects for external businesses, governing the cross-organizational development by architectural and other measures. Even within a single organization, this paradigm can be of high value for large-scale decentralized software projects that involve various internal, yet self-contained organizational units. However, this intra-organizational decentralization causes architecture challenges that must be understood to reason about suitable architectural measures. We present an in-depth case study on collaboration and architecture challenges in two of these large-scale software projects at Siemens. We performed a total of 46 hours of semi-structured interviews with 17 leading software architects from all involved organizational units. Our major findings are: (1) three collaboration models on a continuum that ranges from high to low coupling, (2) a classification of architecture challenges, together with (3) a qualitative and quantitative exposure of the identified recurring issues along each collaboration model. Our study results provide valuable insights for both industry and academia: Practitioners that find themselves in one of the collaboration models can use empirical evidence on challenges to make informed decisions about counteractive measures. Researchers can focus their attention on challenges faced by practitioners to make software engineering more effective.},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {542–552},
numpages = {11},
keywords = {software product line, software architecture, decentralized software engineering, collaboration, case study, Software ecosystem},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.5555/1887899.1887907,
author = {Lung, Chung-Horng and Balasubramaniam, Balasangar and Selvarajah, Kamalachelva and Elankeswaran, Poopalasinkam and Gopalasundaram, Umatharan},
title = {Towards architecture-centric software generation},
year = {2010},
isbn = {3642151132},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Architecture-centric software generation has the potential to support flexible design and large-scale reuse. This paper describes the development of an architecture-centric framework that consists of multiple architecture alternatives, from which the architect can select and generate a working prototype in a top-down manner through a user interface rather than building it from scratch. The framework is primarily built with well-understood design patterns in distributed and concurrent computing. The development process involves extensive domain analysis, variability management, and bottom-up component engineering effort. The framework enables the architect or designer to effectively conduct upfront software architecture analysis and/or rapid architectural prototyping.},
booktitle = {Proceedings of the 4th European Conference on Software Architecture},
pages = {38–52},
numpages = {15},
keywords = {variability management, patterns, generative technique, domain analysis, concurrency, architecture-centric development},
location = {Copenhagen, Denmark},
series = {ECSA'10}
}

@article{10.1016/j.scico.2013.10.010,
author = {Sousa Ferreira, Gabriel Coutinho and Gaia, Felipe Nunes and Figueiredo, Eduardo and De Almeida Maia, Marcelo},
title = {On the use of feature-oriented programming for evolving software product lines - A comparative study},
year = {2014},
issue_date = {November, 2014},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {93},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2013.10.010},
doi = {10.1016/j.scico.2013.10.010},
abstract = {Feature-oriented programming (FOP) is a programming technique based on composition mechanisms, called refinements. It is often assumed that feature-oriented programming is more suitable than other variability mechanisms for implementing Software Product Lines (SPLs). However, there is no empirical evidence to support this claim. In fact, recent research work found out that some composition mechanisms might degenerate the SPL modularity and stability. However, there is no study investigating these properties focusing on the FOP composition mechanisms. This paper presents quantitative and qualitative analysis of how feature modularity and change propagation behave in the context of two evolving SPLs, namely WebStore and MobileMedia. Quantitative data have been collected from the SPLs developed in three different variability mechanisms: FOP refinements, conditional compilation, and object-oriented design patterns. Our results suggest that FOP requires few changes in source code and a balanced number of added modules, providing better support than other techniques for non-intrusive insertions. Therefore, it adheres closer to the Open-Closed principle. Additionally, FOP seems to be more effective tackling modularity degeneration, by avoiding feature tangling and scattering in source code, than conditional compilation and design patterns. These results are based not only on the variability mechanism itself, but also on careful SPL design. However, the aforementioned results are weaker when the design needs to cope with crosscutting and fine-grained features.},
journal = {Sci. Comput. Program.},
month = nov,
pages = {65–85},
numpages = {21},
keywords = {Variability management, Software product lines, Feature-oriented programming, Design patterns, Conditional compilation}
}

@inproceedings{10.1145/1982185.1982522,
author = {Mohabbati, Bardia and Hatala, Marek and Ga\v{s}evi\'{c}, Dragan and Asadi, Mohsen and Bo\v{s}kovi\'{c}, Marko},
title = {Development and configuration of service-oriented systems families},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982522},
doi = {10.1145/1982185.1982522},
abstract = {Software Product Lines (SPLs) are families of software systems which share a common sets of feature and are developed through common set of core assets in order to promotes software reusability, mass customization, reducing cost, time-to-market and improving the quality of the product. SPLs are sets (i.e., families) of software applications developed as a whole for a specific business domain. Particular applications are derived from software families by selecting the desired features through configuration process. Traditionally, SPLs are implemented with systematically developed components, shared by members of the SPLs and reused every time a new application is derived. In this paper, we propose an approach to the development and configuration of Service-Oriented SPLs in which services are used as reusable assets and building blocks of implementation. Our proposed approach also suggests prioritization of family features according to stakeholder's non-functional requirements (NFRs) and preferences. Priorities of NFRs are used to filter the most important features of the family, which is performed by Stratified Analytic Hierarchical Process (S-AHP). The priorities also are used further for the selection of appropriate services implementation for business processes realizing features. We apply Mixed Integer Linear Programming to find the optimal service selection within the constraints boundaries specified by stakeholders.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {1606–1613},
numpages = {8},
keywords = {software product line, service-oriented architecture, service selection, optimization, feature-oriented development},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Configurable systems, Machine learning, Software product lines, Systematic literature review}
}

@inproceedings{10.1145/1456659.1456662,
author = {Chapman, Mark and van der Merwe, Alta},
title = {Contemplating systematic software reuse in a project-centric company},
year = {2008},
isbn = {9781605582863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1456659.1456662},
doi = {10.1145/1456659.1456662},
abstract = {Systematic software reuse is still the most promising strategy for increasing productivity and improving quality in the software industry. Although it is simple in concept, successful software reuse implementation is difficult in practice. A reason put forward for this is the dependence of software reuse on the context in which it is implemented. This paper describes an interpretive case study aimed at investigating the potential for the implementation of systematic software reuse in a project-centric company. The study confirmed the need for systematic software reuse and identified the reuse issues that could present challenges. The study also revealed a number of problems relating to the project-centric structure for which systematic reuse provides potential solutions.},
booktitle = {Proceedings of the 2008 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries: Riding the Wave of Technology},
pages = {16–26},
numpages = {11},
keywords = {systematic software reuse, software reuse, software product lines, software product line engineering, project-centric, interpretive case study, ethnography, action research},
location = {Wilderness, South Africa},
series = {SAICSIT '08}
}

@inproceedings{10.5555/3291291.3291298,
author = {Islam, Nayreet and Azim, Akramul},
title = {Assuring the runtime behavior of self-adaptive cyber-physical systems using feature modeling},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {A self-adaptive cyber-physical system (SACPS) can adjust its behavior and configurations at runtime in response to varying requirements obtained from the system and the environment. With the increasing use of the SACPS in different application domains, such variations are becoming more common. Users today expect the SACPS to guarantee its functional and timing behavior even in adverse environmental situations. However, uncertainties in the SACPS environment impose challenges on assuring the runtime behavior during system design.Software product line engineering (SPLE) is considered as a useful technique for handling varying requirements. In this paper, we present an approach for assuring the runtime behavior of the SACPS by applying an SPLE technique such as feature modeling. By representing the feature-based model at design time, we characterize the possible adaptation requirements to reusable configurations. The proposed approach aims to model two dynamic variability dimensions: 1) environment variability that describes the conditions under which the SACPS must adapt, and 2) structural variability, that defines the resulting architectural configurations. To validate our approach, the experimental analysis is performed using two case studies: 1) a traffic monitoring SACPS and 2) an automotive SACPS. We demonstrate that the proposed feature-based modeling approach can be used to achieve adaptivity which allows the SACPS to assure functional (defining execution of the correct set of adaptive tasks) and non-functional (defining execution of SACPS in the expected mode) correctness at runtime. The experimental results show that the feature-based SACPS demonstrates significant improvement in terms of self-configuration time, self-adaptation time and scalability with less probability of failure in different environmental situations.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {48–59},
numpages = {12},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1145/2897845.2897856,
author = {Meng, Guozhu and Xue, Yinxing and Mahinthan, Chandramohan and Narayanan, Annamalai and Liu, Yang and Zhang, Jie and Chen, Tieming},
title = {Mystique: Evolving Android Malware for Auditing Anti-Malware Tools},
year = {2016},
isbn = {9781450342339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897845.2897856},
doi = {10.1145/2897845.2897856},
abstract = {In the arms race of attackers and defenders, the defense is usually more challenging than the attack due to the unpredicted vulnerabilities and newly emerging attacks every day. Currently, most of existing malware detection solutions are individually proposed to address certain types of attacks or certain evasion techniques. Thus, it is desired to conduct a systematic investigation and evaluation of anti-malware solutions and tools based on different attacks and evasion techniques. In this paper, we first propose a meta model for Android malware to capture the common attack features and evasion features in the malware. Based on this model, we develop a framework, MYSTIQUE, to automatically generate malware covering four attack features and two evasion features, by adopting the software product line engineering approach. With the help of MYSTIQUE, we conduct experiments to 1) understand Android malware and the associated attack features as well as evasion techniques; 2) evaluate and compare the 57 off-the-shelf anti-malware tools, 9 academic solutions and 4 App market vetting processes in terms of accuracy in detecting attack features and capability in addressing evasion. Last but not least, we provide a benchmark of Android malware with proper labeling of contained attack and evasion features.},
booktitle = {Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security},
pages = {365–376},
numpages = {12},
keywords = {malware generation, evolutionary algorithm, defense capability, android feature model},
location = {Xi'an, China},
series = {ASIA CCS '16}
}

@inproceedings{10.1007/978-3-030-32047-8_26,
author = {Khoshmanesh, Seyedehzahra and Lutz, Robyn R.},
title = {Leveraging Feature Similarity for Earlier Detection of Unwanted Feature Interactions in Evolving Software Product Lines},
year = {2019},
isbn = {978-3-030-32046-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32047-8_26},
doi = {10.1007/978-3-030-32047-8_26},
abstract = {Software product lines enable reuse of shared software across a family of products. As new products are built in the product line, new features are added. The features are units of functionality that provide services to users. Unwanted feature interactions, wherein one feature interferes with another feature’s operation, is a significant problem, especially as large software product lines evolve. Detecting feature interactions is a time-consuming and difficult task for developers. Moreover, feature interactions are often only discovered during testing, at which point costly re-work is needed. This paper proposes a similarity-based method to identify unwanted feature interactions much earlier in the development process. It uses knowledge of prior feature interactions stored with the software product line’s feature model to help find unwanted interactions between a new feature and existing features. The paper describes the framework and algorithms used to detect the feature interactions using three path similarity measures and evaluates the approach on a real-world, evolving software product line. Results show that the approach performs well, with 83% accuracy and 60% to 100% coverage of feature interactions in experiments, and scales to a large number of features.},
booktitle = {Similarity Search and Applications: 12th International Conference, SISAP 2019, Newark, NJ, USA, October 2–4, 2019, Proceedings},
pages = {293–307},
numpages = {15},
keywords = {Feature interaction, Similarity measures, Software product lines},
location = {Newark, NJ, USA}
}

@inproceedings{10.5555/2555523.2555556,
author = {Bagheri, Ebrahim and Ensan, Faezeh},
title = {Light-weight software product lines for small and medium-sized enterprises (SMEs)},
year = {2013},
publisher = {IBM Corp.},
address = {USA},
abstract = {Product line engineering practices promote the idea of systematic reuse of core assets and have been reported to decrease time-to-market and development costs for new products. However, our recent efforts to transfer our product line engineering knowledge to several of our small and medium-size enterprise industrial partner showed that there are challenges that need to be addressed before core product line engineering ideas can be deployed in SME context. These challenges include upfront investment costs, business traceability, levels of abstraction of functional features and semantic distinction between functional and non-functional software aspects. In order to address these challenges within the context of SMEs, we adopt and extend the behavior-driven development methodology in a way to not only offer agility in practice but also to equip software developers with the means to capture and manage software variability within the behavior-driven development process. We introduce the details of the extended methodology and discuss its advantages and disadvantages in detail.},
booktitle = {Proceedings of the 2013 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {311–324},
numpages = {14},
location = {Ontario, Canada},
series = {CASCON '13}
}

@inproceedings{10.1145/2188286.2188304,
author = {Tawhid, Rasha and Petriu, Dorina},
title = {User-friendly approach for handling performance parameters during predictive software performance engineering},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188304},
doi = {10.1145/2188286.2188304},
abstract = {A Software Product Line (SPL) is a set of similar software systems that share a common set of features. Instead of building each product from scratch, SPL development takes advantage of the reusability of the core assets shared among the SPL members. In this work, we integrate performance analysis in the early phases of SPL development process, applying the same reusability concept to the performance annotations. Instead of annotating from scratch the UML model of every derived product, we propose to annotate the SPL model once with generic performance annotations. After deriving the model of a product from the family model by an automatic transformation, the generic performance annotations need to be bound to concrete product-specific values provided by the developer. Dealing manually with a large number of performance annotations, by asking the developer to inspect every diagram in the generated model and to extract these annotations is an error-prone process. In this paper we propose to automate the collection of all generic parameters from the product model and to present them to the developer in a user-friendly format (e.g., a spreadsheet per diagram, indicating each generic parameter together with guiding information that helps the user in providing concrete binding values). There are two kinds of generic parametric annotations handled by our approach: product-specific (corresponding to the set of features selected for the product) and platform-specific (such as device choices, network connections, middleware, and runtime environment). The following model transformations for (a) generating a product model with generic annotations from the SPL model, (b) building the spreadsheet with generic parameters and guiding information, and (c) performing the actual binding are all realized in the Atlas Transformation Language (ATL).},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {109–120},
numpages = {12},
keywords = {uml, spl, performance model, performance completion, model-driven development, marte, atl},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@inproceedings{10.5555/3466184.3466446,
author = {Rodriguez, Brodderick and Yilmaz, Levent},
title = {Learning rule-based explanatory models from exploratory multi-simulation for decision-support under uncertainty},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {Exploratory modeling and simulation is an effective strategy when there are substantial contextual uncertainty and representational ambiguity in problem formulation. However, two significant challenges impede the use of an ensemble of models in exploratory simulation. The first challenge involves streamlining the maintenance and synthesis of multiple models from plausible features that are identified from and subject to the constraints of the research hypothesis. The second challenge is making sense of the data generated by multi-simulation over a model ensemble. To address both challenges, we introduce a computational framework that integrates feature-driven variability management with an anticipatory learning classifier system to generate explanatory rules from multi-simulation data.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2293–2304},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@article{10.1007/s00766-003-0166-0,
author = {Thompson, Jeffrey M. and Heimdahl, Mats P.},
title = {Structuring product family requirements for n-dimensional and hierarchical product lines},
year = {2003},
issue_date = {February  2003},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {8},
number = {1},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-003-0166-0},
doi = {10.1007/s00766-003-0166-0},
abstract = {The software product-line approach (for software product families) is one of the success stories of software reuse. When applied, it can result in cost savings and increases in productivity. In addition, in safety-critical systems the approach has the potential for reuse of analysis and testing results, which can lead to a safer system. Nevertheless, there are times when it seems like a product family approach should work when, in fact, there are difficulties in properly defining the boundaries of the product family. In this paper, we draw on our experiences in applying the software product-line approach to a family of mobile robots, a family of flight guidance systems, and a family of cardiac pacemakers, as well as case studies done by others to (1) illustrate how domain structure can currently limit applicability of product-line approaches to certain domains and (2) demonstrate our progress towards a solution using a set-theoretic approach to reason about domains of what we call n-dimensional and hierarchical product families.},
journal = {Requir. Eng.},
month = feb,
pages = {42–54},
numpages = {13},
keywords = {Requirements structuring, Requirements reuse, Product line modelling, Product line engineering, Domain Engineering}
}

@inproceedings{10.5555/1885639.1885687,
author = {Belategi, Lorea and Sagardui, Goiuria and Etxeberria, Leire},
title = {MARTE mechanisms to model variability when analyzing embedded software product lines},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Nowadays, embedded systems development is increasing its complexity dealing with quality among others. Model Driven Development (MDD) and Software Product Line (SPL) can be adequate paradigms to traditional development and validation methods. MARTE (UML Profile for Modeling and Analysis of Real-Time and Embedded systems) profile facilitates model analysis thus ensuring quality achievement from models. SPL requires taking into account variability like functional, quality attributes, platform and allocation. Therefore, variability mechanisms of MARTE profile have been studied in order to perform embedded SPL model analysis.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {466–470},
numpages = {5},
keywords = {variability, software product lines, model analysis, embedded software, MARTE},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1007/978-3-662-49224-6_22,
author = {Beek, Maurice H. and Gnesi, Stefania and Latella, Diego and Massink, Mieke},
title = {Towards Automatic Decision Support for Bike-Sharing System Design},
year = {2015},
isbn = {9783662492239},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-49224-6_22},
doi = {10.1007/978-3-662-49224-6_22},
abstract = {Public bike-sharing systems are a popular means of sustainable urban mobility, but their successful introduction in a city stands or falls with their specific designs. What kind of bikes and docking stations are needed, how many and where to install them? How to avoid as much as possible that stations are completely empty or full for some period? Hence, a bike-sharing system can be seen both as a highly reconfigurable system and as a collective adaptive system. In this paper, we present two complementary strategies for the evaluation of bike-sharing system designs by means of automated tool support. We use the Clafer toolset to perform multi-objective optimisation of attributed feature models known from software product line engineering and the recently developed mean field model checker FlyFast to assess performance and user satisfaction aspects of variants of large-scale bike-sharing systems. The combined use of these analysis approaches is a preliminary step in the direction of automatic decision support for the initial design of a bike-sharing system as well as its successive adaptations and reconfigurations that considers both qualitative and performance aspects.},
booktitle = {Revised Selected Papers of the SEFM 2015 Collocated Workshops on Software Engineering and Formal Methods - Volume 9509},
pages = {266–280},
numpages = {15}
}

@article{10.1016/j.jss.2009.10.011,
author = {Sun, Chang-ai and Rossing, Rowan and Sinnema, Marco and Bulanov, Pavel and Aiello, Marco},
title = {Modeling and managing the variability of Web service-based systems},
year = {2010},
issue_date = {March, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {3},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.10.011},
doi = {10.1016/j.jss.2009.10.011},
abstract = {Web service-based systems are built orchestrating loosely coupled, standardized, and internetworked programs. If on the one hand, Web services address the interoperability issues of modern information systems, on the other hand, they enable the development of software systems on the basis of reuse, greatly limiting the necessity for reimplementation. Techniques and methodologies to gain the maximum from this emerging computing paradigm are in great need. In particular, a way to explicitly model and manage variability would greatly facilitate the creation and customization of Web service-based systems. By variability we mean the ability of a software system to be extended, changed, customized or configured for use in a specific context. We present a framework and related tool suite for modeling and managing the variability of Web service-based systems for design and run-time, respectively. It is an extension of the COVAMOF framework for the variability management of software product families, which was developed at the University of Groningen. Among the novelties and advantages of the approach are the full modeling of variability via UML diagrams, the run-time support, and the low involvement of the user. All of which leads to a great deal of automation in the management of all kinds of variability.},
journal = {J. Syst. Softw.},
month = mar,
pages = {502–516},
numpages = {15},
keywords = {Web services, Variability modeling, Variability management, Service engineering}
}

@article{10.1145/1163514.1178645,
author = {Sinnema, Marco and van der Ven, Jan Salvador and Deelstra, Sybren},
title = {Using variability modeling principles to capture architectural knowledge},
year = {2006},
issue_date = {September 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1163514.1178645},
doi = {10.1145/1163514.1178645},
abstract = {In the field of software architectures, there is an emerging awareness of the importance of architectural decisions. In this view, the architecting process is explained as a decision process, while the design and eventually the software system are seen as the result of this decision process. However, the effects of different alternatives on the quality of the system often remain implicit. In the field of software product families, the same issues arise when configuring products. We propose to use the proven expertise from COVAMOF, a framework for managing variability, to solve the issues that arise when relating quality attributes to architectural decisions.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {5–es},
numpages = {6},
keywords = {quality attributes, architectural knowledge, architectural decisions}
}

@article{10.1007/s10009-012-0250-1,
author = {Wong, Peter Y. and Albert, Elvira and Muschevici, Radu and Proen\c{c}a, Jos\'{e} and Sch\"{a}fer, Jan and Schlatte, Rudolf},
title = {The ABS tool suite: modelling, executing and analysing distributed adaptable object-oriented systems},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0250-1},
doi = {10.1007/s10009-012-0250-1},
abstract = {Modern software systems must support a high degree of variability to accommodate a wide range of requirements and operating conditions. This paper introduces the Abstract Behavioural Specification (ABS) language and tool suite, a comprehensive platform for developing and analysing highly adaptable distributed concurrent software systems. The ABS language has a hybrid functional and object- oriented core, and comes with extensions that support the development of systems that are adaptable to diversified requirements, yet capable to maintain a high level of trustworthiness. Using ABS, system variability is consistently traceable from the level of requirements engineering down to object behaviour. This facilitates temporal evolution, as changes to the required set of features of a system are automatically reflected by functional adaptation of the system's behaviour. The analysis capabilities of ABS stretch from debugging, observing and simulating to resource analysis of ABS models and help ensure that a system will remain dependable throughout its evolutionary lifetime. We report on the experience of using the ABS language and the ABS tool suite in an industrial case study.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {567–588},
numpages = {22},
keywords = {Variability, Tool support, Software product line, Formal modelling and analysis, Feature modelling, Concurrency}
}

@article{10.1016/j.jss.2014.10.037,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Galindo, Jos\'{e} A. and Parejo, Jos\'{e} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
title = {An assessment of search-based techniques for reverse engineering feature models},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {103},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.10.037},
doi = {10.1016/j.jss.2014.10.037},
abstract = {HighlightsSearch based techniques perform well for reverse engineering feature models.Different algorithms and objectives favour precision and recall differently.The F1 objective function provides a trade-off between precision and recall. Successful software evolves from a single system by adding and changing functionality to keep up with users' demands and to cater to their similar and different requirements. Nowadays it is a common practice to offer a system in many variants such as community, professional, or academic editions. Each variant provides different functionality described in terms of features. Software Product Line Engineering (SPLE) is an effective software development paradigm for this scenario. At the core of SPLE is variability modelling whose goal is to represent the combinations of features that distinguish the system variants using feature models, the de facto standard for such task. As SPLE practices are becoming more pervasive, reverse engineering feature models from the feature descriptions of each individual variant has become an active research subject. In this paper we evaluated, for this reverse engineering task, three standard search based techniques (evolutionary algorithms, hill climbing, and random search) with two objective functions on 74 SPLs. We compared their performance using precision and recall, and found a clear trade-off between these two metrics which we further reified into a third objective function based on Fβ, an information retrieval measure, that showed a clear performance improvement. We believe that this work sheds light on the great potential of search-based techniques for SPLE tasks.},
journal = {J. Syst. Softw.},
month = may,
pages = {353–369},
numpages = {17},
keywords = {Search Based Software Engineering, Reverse engineering, Feature model}
}

@article{10.1007/s11042-020-09956-6,
author = {Yadav, Hitesh and Chhikara, Rita and Kumari, A. Charan},
title = {A novel hybrid approach for feature selection in software product lines},
year = {2021},
issue_date = {Feb 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {4},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09956-6},
doi = {10.1007/s11042-020-09956-6},
abstract = {Software Product Line (SPL) customizes software by combining various existing features of the software with multiple variants. The main challenge is selecting valid features considering the constraints of the feature model. To solve this challenge, a hybrid approach is proposed to optimize the feature selection problem in software product lines. The Hybrid approach ‘Hyper-PSOBBO’ is a combination of Particle Swarm Optimization (PSO), Biogeography-Based Optimization (BBO) and hyper-heuristic algorithms. The proposed algorithm has been compared with Bird Swarm Algorithm (BSA), PSO, BBO, Firefly, Genetic Algorithm (GA) and Hyper-heuristic. All these algorithms are performed in a set of 10 feature models that vary from a small set of 100 to a high-quality data set of 5000. The detailed empirical analysis in terms of performance has been carried out on these feature models. The results of the study indicate that the performance of the proposed method is higher to other state-of-the-art algorithms.},
journal = {Multimedia Tools Appl.},
month = feb,
pages = {4919–4942},
numpages = {24},
keywords = {Feature model (FM), Software product lines (SPL), Bird swarm optimization (BSA), Genetic algorithm (GA), Firefly, Biogeography-based optimization, Hyper-heuristic, Particle swarm optimization}
}

@inproceedings{10.1007/978-3-642-39031-9_10,
author = {Silva, Eduardo and Medeiros, Ana Luisa and Cavalcante, Everton and Batista, Thais},
title = {A lightweight language for software product lines architecture description},
year = {2013},
isbn = {9783642390302},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39031-9_10},
doi = {10.1007/978-3-642-39031-9_10},
abstract = {The architecture description of a software product line (SPL) is essential to make it clear how the architecture realizes the feature model and to represent both the domain and application engineering architectural artefacts. However, most architecture description languages (ADLs) for SPL have limited support regarding variability management and they do not express the relationship between features and the architecture, besides the lack of tools for graphical and textual modelling and a non-clear separation between the domain and application engineering activities. In order to overcome these deficiencies, this paper presents LightPL-ACME, an ADL whose main goal is to be a simple, lightweight language for the SPL architecture description, and enable the association between the architectural specification and the artefacts involved in the SPL development process, including the relationship with the feature model and the representation of both domain and application engineering elements.},
booktitle = {Proceedings of the 7th European Conference on Software Architecture},
pages = {114–121},
numpages = {8},
keywords = {software product lines architectures, architecture description languages, LightPL-ACME, ACME},
location = {Montpellier, France},
series = {ECSA'13}
}

@inproceedings{10.1145/1216262.1216265,
author = {Kabanda, Salah and Adigun, Mathew},
title = {Extending model driven architecture benefits to requirements engineering},
year = {2006},
isbn = {1595935673},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
url = {https://doi.org/10.1145/1216262.1216265},
doi = {10.1145/1216262.1216265},
abstract = {This work focuses on developing a requirement engineering model (RSPL) based on a Model Driven Architecture (MDA) and Web-tier Application Framework (WAF), to support automatic and interactive requirements generation when creating families of systems. In realizing the model, two goals were targeted namely (i) to construct a RE model that support automatic transformation of domain features into actor-specific requirements; and (ii) to design and implement an interactive web based tool for requirements engineering. The result obtained is twofold: (i) adopting MDA during RE for a product line reduced costs and development time; (ii) tool implementation based on WAF ensured that support for different client types was possible. In conclusion, the study is a contribution to a recently advocated idea that requirements generation could be model-driven. The result shows that the idea is promising with respect to requirement reuse and improving communication barriers among members of a system development team.},
booktitle = {Proceedings of the 2006 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {22–30},
numpages = {9},
keywords = {model driven architecture, requirement specification model for product lines, software product line engineering, web-tier application framework},
location = {Somerset West, South Africa},
series = {SAICSIT '06}
}

@inproceedings{10.1145/2973839.2973852,
author = {Santos, Ismayle S. and Rocha, Lincoln S. and Neto, Pedro A. Santos and Andrade, Rossana M. C.},
title = {Model Verification of Dynamic Software Product Lines},
year = {2016},
isbn = {9781450342018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973839.2973852},
doi = {10.1145/2973839.2973852},
abstract = {Dynamic Software Product Lines (DSPLs) extend the concept of Software Product Lines enabling adaptation at runtime according to context changes. Such dynamic behavior is typically designed using adaptation rules, context-triggered actions responsible for features activation and deactivation at runtime. The erroneous specification and the interleaving of adaptation rules (i.e., the parallel execution of adaptation rules) can lead DSPL to reach an undesired (improperly or defective) product configuration at runtime. Thus, in order to improve the reliability of DSPL behavior, design faults must be rigorously identified and eliminated in the early stages of DSPL development. In this paper, we address this issue introducing Dynamic Feature Transition Systems (DFTSs) that allow the modeling and formal verification of the DSPLs adaptive behavior. These transition systems are derived from the adaptation rules and a Context Kripke Structure, which is a context evolution model. Furthermore, we formally define five properties that can be used to identify existing design faults in DSPL design. Aiming to assess the feasibility of our approach, a feasibility study was conducted using two DSPLs, Mobile Visit Guides and Car. In both cases, design faults were automatically detected indicating that our formalism can help in the detection of design faults in the DSPLs adaptive behavior.},
booktitle = {Proceedings of the XXX Brazilian Symposium on Software Engineering},
pages = {113–122},
numpages = {10},
keywords = {Software Verification, Software Reliability, Model Checking, Dynamic Software Product Line},
location = {Maring\'{a}, Brazil},
series = {SBES '16}
}

@article{10.1007/s11219-011-9153-8,
author = {Mussbacher, Gunter and Ara\'{u}jo, Jo\~{a}o and Moreira, Ana and Amyot, Daniel},
title = {AoURN-based modeling and analysis of software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9153-8},
doi = {10.1007/s11219-011-9153-8},
abstract = {Software Product Line Engineering concerns itself with domain engineering and application engineering. During domain engineering, the whole product family is modeled with a preferred flavor of feature models and additional models as required (e.g., domain models or scenario-based models). During application engineering, the focus shifts toward a single family member and the configuration of the member's features. Recently, aspectual concepts have been employed to better encapsulate individual features of a Software Product Line (SPL), but the existing body of SPL work does not include a unified reasoning framework that integrates aspect-oriented feature description artifacts with the capability to reason about stakeholders' goals while taking feature interactions into consideration. Goal-oriented SPL approaches have been proposed, but do not provide analysis capabilities that help modelers meet the needs of the numerous stakeholders involved in an SPL while at the same time considering feature interactions. We present an aspect-oriented SPL approach for the requirements phase that allows modelers (a) to capture features, goals, and scenarios in a unified framework and (b) to reason about stakeholders' needs and perform trade-off analyses while considering undesirable interactions that are not obvious from the feature model. The approach is based on the Aspect-oriented User Requirements Notation (AoURN) and helps identify, prioritize, and choose products based on analysis results provided by AoURN editor and analysis tools. We apply the AoURN-based SPL framework to the Via Verde SPL to demonstrate the feasibility of this approach through the selection of a Via Verde product configuration that satisfies stakeholders' needs and results in a high-level, scenario-based specification that is free from undesirable feature interactions.},
journal = {Software Quality Journal},
month = sep,
pages = {645–687},
numpages = {43},
keywords = {User Requirements Notation, Software product lines, Scenario-based requirements engineering, Goal-based requirements engineering, Feature interactions, Aspect-oriented modeling}
}

@article{10.1007/s00766-014-0216-9,
author = {Karata\c{s}, Ahmet Serkan and O\u{g}uzt\"{u}z\"{u}n, Halit},
title = {Attribute-based variability in feature models},
year = {2016},
issue_date = {June      2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-014-0216-9},
doi = {10.1007/s00766-014-0216-9},
abstract = {Extended feature models enable the expression of complex cross-tree constraints involving feature attributes. The inclusion of attributes in cross-tree relations not only enriches the constraints, but also engenders an extended type of variability that involves attributes. In this article, we elaborate on the effects of this new variability type on feature models. We start by analyzing the nature of the variability involving attributes and extend the definitions of the configuration and the product to suit the emerging requirements. Next, we propose classifications for the features, configurations, and products to identify and formalize the ramifications that arise due to the new type of variability. Then, we provide a semantic foundation grounded on constraint satisfaction for our proposal. We introduce an ordering relation between configurations and show that the set of all the configurations represented by a feature model forms a semilattice. This is followed by a demonstration of how the feature model analyses will be affected using illustrative examples selected from existing and novel analysis operations. Finally, we summarize our experiences, gained from a commercial research and development project that employs an extended feature model.},
journal = {Requir. Eng.},
month = jun,
pages = {185–208},
numpages = {24},
keywords = {Variability management, Variability involving attributes, Software product lines, Extended feature models}
}

@inproceedings{10.5555/1885639.1885681,
author = {Lin, Yuqing and Ye, Huilin and Tang, Jianmin},
title = {An approach to efficient product configuration in software product lines},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling has been widely used in software product line engineering to represent commonality and variabilities among products in a product family. When developing a new software product belonging to a product line, a feature model representing the product line will be used to configure products. The product configuration process is a decision making process, various kinds of constraints and complex relationships among configurable features make the decision making a time consuming and error prone task. In this paper, we present an approach which will improve the efficiency and quality of product configuration.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {435–439},
numpages = {5},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1007/978-3-642-30829-1_6,
author = {Khosravi, Ramtin and Sabouri, Hamideh},
title = {Using coordinated actors to model families of distributed systems},
year = {2012},
isbn = {9783642308284},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-30829-1_6},
doi = {10.1007/978-3-642-30829-1_6},
abstract = {Software product line engineering enables strategic reuse in development of families of related products. In a component-based approach to product line development, components capture functionalities appearing in one or more products in the family and different assemblies of components yield to various products or configurations. In this approach, an interaction model which effectively factors out the logic handling variability from the functionality of the system greatly enhances the reusability of components. We study the problem of variability modeling for a family of distributed systems expressed in actor model. We define a special type of actors called coordinators whose behavior is described as Reo circuits with the aim of encapsulating the variability logic. We have the benefits of Reo language for expressing coordination logic, while modeling the entire system as an actor-based distributed model. We have applied this model to a case study extracted from an industrial software family in the domain of interactive TV.},
booktitle = {Proceedings of the 14th International Conference on Coordination Models and Languages},
pages = {74–88},
numpages = {15},
location = {Stockholm, Sweden},
series = {COORDINATION'12}
}

@inproceedings{10.1145/2430502.2430510,
author = {Lee, Hyesun and Kang, Kyo Chul},
title = {A design feature-based approach to deriving program code from features: a step towards feature-oriented software development},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430510},
doi = {10.1145/2430502.2430510},
abstract = {Feature-oriented software development is a software development paradigm that uses "features" as the first class objects in designing program instead of objects as with the object-orientation. Most of researches on feature-oriented software development attempt to derive program code directly from a feature model, which presents several problems: there is no explicit attempt to embed required quality attributes into code; and features tend to cut across program units and it is difficult to derive program units from the features. To address these problems, a design-feature-based approach is proposed in this paper. Design feature model captures implementation-level design decisions explicitly. It bridges the abstraction gap between features (i.e., functionalities in abstraction) and program units (i.e., concrete implementation). Design features of a design feature model are identified based on required quality attributes. We demonstrated the feasibility of the proposed approach by providing a case study of an arcade game software product line. Initial lessons learned and research agenda are also introduced in the paper.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {5},
numpages = {6},
keywords = {quality attribute, feature-oriented software development, design feature model},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1007/978-3-030-32047-8_32,
author = {Khoshmanesh, Seyedehzahra and Lutz, Robyn R.},
title = {Feature Similarity: A Method to Detect Unwanted Feature Interactions Earlier in Software Product Lines},
year = {2019},
isbn = {978-3-030-32046-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32047-8_32},
doi = {10.1007/978-3-030-32047-8_32},
abstract = {Software product lines enable the reuse of shared software across a family of products. As new products are built in the product line, new features are added. A feature is a unit of functionality. Unwanted feature interactions, wherein one feature hinders another feature’s operation, are a significant problem, especially as large software product lines evolve. Detecting feature interactions is a time-consuming and difficult task for developers. Moreover, feature interactions are often only discovered during testing, at which point costly re-work is needed. The work described here investigates how to discover feature interactions much earlier in the development process. Toward this goal, we propose a similarity-based approach that mines prior feature interactions stored in the software product line’s artifacts to predict unwanted interactions between a new feature and existing features. Initial results show that the planned methodology performs well in terms of accuracy and coverage both in experiments on three small software product lines in the literature and in experiments on one large, real-world software product line.},
booktitle = {Similarity Search and Applications: 12th International Conference, SISAP 2019, Newark, NJ, USA, October 2–4, 2019, Proceedings},
pages = {356–361},
numpages = {6},
keywords = {Feature interaction, Similarity measures, Software product lines},
location = {Newark, NJ, USA}
}

@article{10.1016/j.scico.2012.06.007,
author = {Cetina, Carlos and Giner, Pau and Fons, Joan and Pelechano, Vicente},
title = {Prototyping Dynamic Software Product Lines to evaluate run-time reconfigurations},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.06.007},
doi = {10.1016/j.scico.2012.06.007},
abstract = {Dynamic Software Product Lines (DSPL) encompass systems that are capable of modifying their own behavior with respect to changes in their operating environment by using run-time reconfigurations. A failure in these reconfigurations can directly impact the user experience since the reconfigurations are performed when the system is already under the users control. In this work, we prototype a Smart Hotel DSPL to evaluate the reliability-based risk of the DSPL reconfigurations, specifically, the probability of malfunctioning (Availability) and the consequences of malfunctioning (Severity). This DSPL prototype was performed with the participation of human subjects by means of a Smart Hotel case study which was deployed with real devices. Moreover, we successfully identified and addressed two challenges associated with the involvement of human subjects in DSPL prototyping: enabling participants to (1) trigger the run-time reconfigurations and to (2) understand the effects of the reconfigurations. The evaluation of the case study reveals positive results regarding both Availability and Severity. However, the participant feedback highlights issues with recovering from a failed reconfiguration or a reconfiguration triggered by mistake. To address these issues, we discuss some guidelines learned in the case study. Finally, although the results achieved by the DSPL may be considered satisfactory for its particular domain, DSPL engineers must provide users with more control over the reconfigurations or the users will not be comfortable with DSPLs.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2399–2413},
numpages = {15},
keywords = {Variability modeling, Smart Hotel, Dynamic Software Product Line}
}

@inproceedings{10.1007/11663430_27,
author = {Loughran, Neil and Sampaio, Am\'{e}rico and Rashid, Awais},
title = {From requirements documents to feature models for aspect oriented product line implementation},
year = {2005},
isbn = {3540317805},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11663430_27},
doi = {10.1007/11663430_27},
abstract = {Software product line engineering has emerged as an approach to developing software which targets a given domain. However, the processes involved in developing a software product line can be time consuming and error prone without adequate lifecycle tool support. In this paper we describe our approach, NAPLES, which uses natural language processing and aspect-oriented techniques to facilitate requirements analysis, commonality and variability analysis, concern identification to derive suitable feature oriented models for implementation.},
booktitle = {Proceedings of the 2005 International Conference on Satellite Events at the MoDELS},
pages = {262–271},
numpages = {10},
location = {Montego Bay, Jamaica},
series = {MoDELS'05}
}

@inproceedings{10.1145/2361999.2362017,
author = {Lee, Hyesun and Yang, Jin-seok and Kang, Kyo C.},
title = {VULCAN: architecture-model-based software development workbench},
year = {2012},
isbn = {9781450315685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2361999.2362017},
doi = {10.1145/2361999.2362017},
abstract = {Recently, software developers are faced with a fierce market competition with: diverse market needs, ever increasing number of features, and shortening product life cycle. To survive in this fierce competition, software developers are searching for methods and tools to develop various products with reduced time-to-market and improved quality.In response to these needs, we present a new CASE called VULCAN. VULCAN is a software development workbench comprising various tools for supporting the entire phases of feature-oriented product line software development from feature modeling to asset and product development. Especially, it provides several tools for supporting architecture-model-based software development where: (1) product line architectures can be specified using various architecture patterns, (2) application-specific architectures can be derived from the product line architecture specifications, (3) application-specific control components can be generated from the application architecture specifications, and (4) different deployment architectures can be configured with various component communication mechanisms. Of various tools included in VULCAN, we focus on this tool set for supporting architecture-model-based software development in this paper and demonstration.},
booktitle = {Proceedings of the WICSA/ECSA 2012 Companion Volume},
pages = {86–89},
numpages = {4},
keywords = {software product line, feature-oriented, deployment architecture, component connection mechanism, architecture-model-based},
location = {Helsinki, Finland},
series = {WICSA/ECSA '12}
}

@inproceedings{10.1145/2491411.2491455,
author = {Davril, Jean-Marc and Delfosse, Edouard and Hariri, Negar and Acher, Mathieu and Cleland-Huang, Jane and Heymans, Patrick},
title = {Feature model extraction from large collections of informal product descriptions},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491455},
doi = {10.1145/2491411.2491455},
abstract = {Feature Models (FMs) are used extensively in software product line engineering to help generate and validate individual product configurations and to provide support for domain analysis. As FM construction can be tedious and time-consuming, researchers have previously developed techniques for extracting FMs from sets of formally specified individual configurations, or from software requirements specifications for families of existing products. However, such artifacts are often not available. In this paper we present a novel, automated approach for constructing FMs from publicly available product descriptions found in online product repositories and marketing websites such as SoftPedia and CNET. While each individual product description provides only a partial view of features in the domain, a large set of descriptions can provide fairly comprehensive coverage. Our approach utilizes hundreds of partial product descriptions to construct an FM and is described and evaluated against antivirus product descriptions mined from SoftPedia.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {290–300},
numpages = {11},
keywords = {Product Lines, Feature Models, Domain Analysis},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.5555/2793733.2794040,
author = {Rinc\'{o}n, L. and Giraldo, G. and Mazo, R. and Salinesi, C. and Diaz, D.},
title = {Method to Identify Corrections of Defects on Product Line Models},
year = {2015},
issue_date = {June 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {314},
number = {C},
issn = {1571-0661},
abstract = {Software product line engineering is a promising paradigm for developing software intensive systems. Among their proven benefits are reduced time to market, better asset reuse and improved software quality. To achieve this, the collection of products of the product line are specified by means of product line models. Feature Models (FMs) are a common notation to represent product lines that express the set of feature combinations that software products can have. Experience shows that these models can have defects. Defects in FMs be inherited to the products configured from these models. Consequently, defects must be early identified and corrected. Several works reported in scientific literature, deal with identification of defects in FMs. However, only few of these proposals are able to explain how to fix defects, and only some corrections are suggested. This paper proposes a new method to detect all possible corrections from a defective product line model. The originality of the contribution is that corrections can be found when the method systematically eliminates dependencies from the FMs. The proposed method was applied on 78 distinct FMs with sizes up to 120 dependencies. Evaluation indicates that the method proposed in this paper scale up, is accurate, and sometimes useful in real scenarios.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = jun,
pages = {61–81},
numpages = {21},
keywords = {Software product lines, Software Engineering, Features Models, Defects, Corrections}
}

@article{10.1016/j.future.2015.05.017,
title = {Allocating resources for customizable multi-tenant applications in clouds using dynamic feature placement},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {53},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2015.05.017},
doi = {10.1016/j.future.2015.05.017},
abstract = {Multi-tenancy, where multiple end users make use of the same application instance, is often used in clouds to reduce hosting costs. A disadvantage of multi-tenancy is however that it makes it difficult to create customizable applications, as all end users use the same application instance. In this article, we describe an approach for the development and management of highly customizable multi-tenant cloud applications. We apply software product line engineering techniques to cloud applications, and use an approach where applications are composed of multiple interacting components, referred to as application features. Using this approach, multiple features can be shared between different applications. Allocating resources for these feature-based applications is complex, as relations between components must be taken into account, and is referred to as the feature placement problem.In this article, we describe dynamic feature placement algorithms that minimize migrations between subsequent invocations, and evaluate them in dynamic scenarios where applications are added and removed throughout the evaluation scenario. We find that the developed algorithm achieves a low cost, while resulting in few resource migrations. In our evaluations, we observe that adding migration-awareness to the management algorithms reduces the number of instance migrations by more than 77 % and reduces the load moved between instances by more than 96 % when compared to a static management approach. Despite this reduction in number of migrations, a cost that is on average less than 3 % more than the optimal cost is achieved. We model customizable SaaS applications using feature modeling.A dynamic, migration-aware management approach is presented.Two ILP-based algorithms and a heuristic algorithm are compared.The dynamic algorithms reduce migrations and remain within 3% of the optimal cost.},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {63–76},
numpages = {14}
}

@article{10.1016/j.jss.2013.06.034,
author = {Alf\'{e}rez, G. H. and Pelechano, V. and Mazo, R. and Salinesi, C. and Diaz, D.},
title = {Dynamic adaptation of service compositions with variability models},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.06.034},
doi = {10.1016/j.jss.2013.06.034},
abstract = {Web services run in complex contexts where arising events may compromise the quality of the whole system. Thus, it is desirable to count on autonomic mechanisms to guide the self-adaptation of service compositions according to changes in the computing infrastructure. One way to achieve this goal is by implementing variability constructs at the language level. However, this approach may become tedious, difficult to manage, and error-prone. In this paper, we propose a solution based on a semantically rich variability model to support the dynamic adaptation of service compositions. When a problematic event arises in the context, this model is leveraged for decision-making. The activation and deactivation of features in the variability model result in changes in a composition model that abstracts the underlying service composition. These changes are reflected into the service composition by adding or removing fragments of Business Process Execution Language (WS-BPEL) code, which can be deployed at runtime. In order to reach optimum adaptations, the variability model and its possible configurations are verified at design time using Constraint Programming. An evaluation demonstrates several benefits of our approach, both at design time and at runtime.},
journal = {J. Syst. Softw.},
month = may,
pages = {24–47},
numpages = {24},
keywords = {Web service composition, Verification, Variability, Models at runtime, Dynamic software product line, Dynamic adaptation, Constraint programming, Autonomic computing}
}

@inproceedings{10.1145/1868433.1868445,
author = {Trujillo, Salvador and Perez, Antonio and Gonzalez, David and Hamid, Brahim},
title = {Towards the integration of advanced engineering paradigms into RCES: raising the issues for the safety-critical model-driven product-line case},
year = {2010},
isbn = {9781450303682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868433.1868445},
doi = {10.1145/1868433.1868445},
abstract = {The conception and design of Resource Constrained Embedded Systems is an inherently complex endeavor. In particular, non-functional requirements from security, dependability and variability are exacerbating this complexity. Recent times have seen a paradigm shift in terms of design through the combination of multiple software engineering paradigms together, namely, Model Driven Engineering and Software Product Line Engineering. Such paradigm shift is changing the way systems are developed nowadays, reducing development time significantly. Embedded systems are a case in point where a range of products for assorted domains such as energy, transportation, automotive, and so on are conceived as a family. However, most of the work so far has been focused on functional parts. The purpose of this talk is to foster some discussion during the workshop on the issues that need to be faced for these techniques to be applicable for Resource Constrained Embedded Systems for which security and dependability are primary requirements.},
booktitle = {Proceedings of the International Workshop on Security and Dependability for Resource Constrained Embedded Systems},
articleno = {9},
numpages = {4},
keywords = {software product lines, resource constrained embedded systems, model-driven development, dependability},
location = {Vienna, Austria},
series = {S&amp;D4RCES '10}
}

@inproceedings{10.1145/3302333.3302340,
author = {Krieter, Sebastian and Thiem, Tobias and Leich, Thomas},
title = {Using Dynamic Software Product Lines to Implement Adaptive SGX-enabled Systems},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302340},
doi = {10.1145/3302333.3302340},
abstract = {In the light of computational outsourcing and external data storage, data protection and trusted execution become increasingly important. Novel hardware such as Intel's Software Guard extensions (SGX) attempts to provide a solution to protect data and computations from unauthorized access and manipulation, even against attackers with physical access to a machine. However, the current generation of SGX limits the protected memory space that can be efficiently used to 128 MiB, which must be shared between data and binary code. Thus, we propose to use a software product line approach to tailor an application's binary code in such a way that it can be updated during runtime, with the goal to only store relevant features in the protected memory at a given time. We provide a prototypical implementation that enables basic support for loading and unloading features during runtime and evaluate our prototype in terms of execution times against non-adaptive execution.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {9},
numpages = {9},
keywords = {Software Product Lines, Runtime Adaptation, Intel Software Guard Extensions},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@phdthesis{10.5555/AAI27997977,
author = {McDevitt, Mikaela and Lathrop, James and Lutz, Robyn and Basu, Samik and Dickerson, Julie},
advisor = {B, Cohen, Myra},
title = {Interpretability of Configurable Software in the Biosciences},
year = {2020},
isbn = {9798672106816},
publisher = {Iowa State University},
address = {USA},
abstract = {Users of bioinformatics software tools range from bench scientists with little computational experience, to sophisticated developers.  As the number and types of tools available to this diverse set of users grow, they are also increasing in flexibility. The customization of these tools makes them highly-configurable — where the end user is provided with many customization (configuration) options.  At the same time, biologists and chemists are engineering living organisms by programming their DNA in a process that mimics software development.  As they share their designs and promote re-use, their programs are also emerging as highly-configurable.  As these bioscience systems become mainstream tools for the biology and bioinformatics communities, their dependability, reliability, and reproducibility becomes critical. Scientists are making decisions and drawing conclusions based on the software they use, and the constructs designed by synthetic biologists are being built into living organisms and used in the real world.  Yet there is little help guiding users of bioinformatics tools or those building new synthetic organisms.  As an end user equipped with minimal information, it is hard to predict the effect of changing a particular configuration option, yet the choice of configuration can lead to a large amount of variation in functionality and performance.  Even if the configuration options make sense to an expert user, understanding all options and their interactions is difficult or even impossible to compute due to the exponential number of combinations.  Similarly, synthetic biologists must choose how to combine small DNA segments.  However, there can be millions of ways to combine these pieces, and determining the architecture can require significant domain knowledge.In this dissertation we address these challenges of interpreting the effects of configurability in two areas in the biosciences: (1) bioinformatics software, and (2) synthetic biology.  We highlight the challenges of configurability in these areas and provide approaches to help users navigate their configuration spaces leading to more interpretable configurable software in the biosciences.First, we demonstrate there is variability in both the functional and performance outcomes of highly-configurable bioinformatics tools, and find previously undetected faults.  We discuss the implications of this variability, and provide suggestions for developers.  Second, we develop a user-oriented framework to identify the effect of changing configuration options in software, and communicate these effects to the end user in a simplistic format.  We demonstrate our framework in a large study and compare to a state of the art method for performance-influence modeling in software.Last, we define a mapping of software product line engineering to the domain of synthetic biology resulting in organic software product lines.  We demonstrate the potential reuse and existence of both commonality and variability in an open source synthetic biology repository.   We build feature models for four commonly engineered biological functions and demonstrate how product line engineering can benefit synthetic biologists.},
note = {AAI27997977}
}

@article{10.1016/j.infsof.2021.106674,
author = {Domingo, \'{A}frica and Echeverr\'{\i}a, Jorge and Pastor, \'{O}scar and Cetina, Carlos},
title = {Evaluating the influence of scope on feature location},
year = {2021},
issue_date = {Dec 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {140},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106674},
doi = {10.1016/j.infsof.2021.106674},
journal = {Inf. Softw. Technol.},
month = dec,
numpages = {15},
keywords = {Model-driven engineering, Controlled experiment, Feature location}
}

@inproceedings{10.1145/3338906.3338928,
author = {Shahin, Ramy and Chechik, Marsha and Salay, Rick},
title = {Lifting Datalog-based analyses to software product lines},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338928},
doi = {10.1145/3338906.3338928},
abstract = {Applying program analyses to Software Product Lines (SPLs) has been a fundamental research problem at the intersection of Product Line Engineering and software analysis. Different attempts have been made to ”lift” particular product-level analyses to run on the entire product line. In this paper, we tackle the class of Datalog-based analyses (e.g., pointer and taint analyses), study the theoretical aspects of lifting Datalog inference, and implement a lifted inference algorithm inside the Souffl\'{e} Datalog engine. We evaluate our implementation on a set of benchmark product lines. We show significant savings in processing time and fact database size (billions of times faster on one of the benchmarks) compared to brute-force analysis of each product individually.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {39–49},
numpages = {11},
keywords = {Souffl'{e}, Software Product Lines, Program Analysis, Pointer Analysis, Lifting, Doop, Datalog},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1145/1183236.1183238,
author = {Maamar, Zakaria and Benslimane, Djamal and Narendra, Nanjangud C.},
title = {What can context do for web services?},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183238},
doi = {10.1145/1183236.1183238},
abstract = {Context-aware Web service would significantly benefit the interactions between human, applications, and the environment.},
journal = {Commun. ACM},
month = dec,
pages = {98–103},
numpages = {6}
}

@inproceedings{10.1109/PESOS.2009.5068815,
author = {Mietzner, Ralph and Metzger, Andreas and Leymann, Frank and Pohl, Klaus},
title = {Variability modeling to support customization and deployment of multi-tenant-aware Software as a Service applications},
year = {2009},
isbn = {9781424437160},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/PESOS.2009.5068815},
doi = {10.1109/PESOS.2009.5068815},
abstract = {More and more companies are offering their software by following the Software as a Service (SaaS) model. The promise of the SaaS model is to exploit economies of scale on the provider side by hosting multiple customers (or tenants) on the same hardware and software infrastructure. However, to attract a significant number of tenants, SaaS applications have to be customizable to fulfill the varying functional and quality requirements of individual tenants. In this paper, we describe how variability modeling techniques from software product line engineering can support SaaS providers in managing the variability of SaaS applications and their requirements. Specifically, we propose using explicit variability models to systematically derive customization and deployment information for individual SaaS tenants. We also demonstrate how variability models could be used to systematically consider information about already deployed SaaS applications for efficiently deploying SaaS applications for new tenants. We illustrate our approach by a running example for a meeting planning application.},
booktitle = {Proceedings of the 2009 ICSE Workshop on Principles of Engineering Service Oriented Systems},
pages = {18–25},
numpages = {8},
series = {PESOS '09}
}

@article{10.1145/3039207,
author = {Hirzel, Martin and Schneider, Scott and Gedik, Bu\u{g}ra},
title = {SPL: An Extensible Language for Distributed Stream Processing},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/3039207},
doi = {10.1145/3039207},
abstract = {Big data is revolutionizing how all sectors of our economy do business, including telecommunication, transportation, medical, and finance. Big data comes in two flavors: data at rest and data in motion. Processing data in motion is stream processing. Stream processing for big data analytics often requires scale that can only be delivered by a distributed system, exploiting parallelism on many hosts and many cores. One such distributed stream processing system is IBM Streams. Early customer experience with IBM Streams uncovered that another core requirement is extensibility, since customers want to build high-performance domain-specific operators for use in their streaming applications. Based on these two core requirements of distribution and extensibility, we designed and implemented the Streams Processing Language (SPL). This article describes SPL with an emphasis on the language design, distributed runtime, and extensibility mechanism. SPL is now the gateway for the IBM Streams platform, used by our customers for stream processing in a broad range of application domains.},
journal = {ACM Trans. Program. Lang. Syst.},
month = mar,
articleno = {5},
numpages = {39},
keywords = {Stream processing}
}

@article{10.1016/j.jss.2009.06.048,
author = {Khurum, Mahvish and Gorschek, Tony},
title = {A systematic review of domain analysis solutions for product lines},
year = {2009},
issue_date = {December, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {12},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.048},
doi = {10.1016/j.jss.2009.06.048},
abstract = {Domain analysis is crucial and central to software product line engineering (SPLE) as it is one of the main instruments to decide what to include in a product and how it should fit in to the overall software product line. For this reason many domain analysis solutions have been proposed both by researchers and industry practitioners. Domain analysis comprises various modeling and scoping activities. This paper presents a systematic review of all the domain analysis solutions presented until 2007. The goal of the review is to analyze the level of industrial application and/or empirical validation of the proposed solutions with the purpose of mapping maturity in terms of industrial application, as well as to what extent proposed solutions might have been evaluated in terms of usability and usefulness. The finding of this review indicates that, although many new domain analysis solutions for software product lines have been proposed over the years, the absence of qualitative and quantitative results from empirical application and/or validation makes it hard to evaluate the potential of proposed solutions with respect to their usability and/or usefulness for industry adoption. The detailed results of the systematic review can be used by individual researchers to see large gaps in research that give opportunities for future work, and from a general research perspective lessons can be learned from the absence of validation as well as from good examples presented. From an industry practitioner view, the results can be used to gauge as to what extent solutions have been applied and/or validated and in what manner, both valuable as input prior to industry adoption of a domain analysis solution.},
journal = {J. Syst. Softw.},
month = dec,
pages = {1982–2003},
numpages = {22},
keywords = {Usefulness, Usability, Systematic review, Empirical evidence, Domain scoping, Domain modeling, Domain analysis}
}

@article{10.1145/1183236.1183240,
author = {Montazemi, Ali Reza},
title = {How they manage IT: SMEs in Canada and the U.S.},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183240},
doi = {10.1145/1183236.1183240},
abstract = {Small and medium-sized companies in the U.S. make better use of IT than their Canadian counterparts.},
journal = {Commun. ACM},
month = dec,
pages = {109–112},
numpages = {4}
}

@article{10.1016/j.datak.2010.01.002,
author = {Reinhartz-Berger, Iris},
title = {Towards automatization of domain modeling},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {69},
number = {5},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2010.01.002},
doi = {10.1016/j.datak.2010.01.002},
abstract = {A domain model, which captures the common knowledge and the possible variability allowed among applications in a domain, may assist in the creation of other valid applications in that domain. However, to create such domain models is not a trivial task: it requires expertise in the domain, reaching a very high level of abstraction, and providing flexible, yet formal, artifacts. In this paper an approach, called Semi-automated Domain Modeling (SDM), to create draft domain models from applications in those domains, is presented. SDM takes a repository of application models in a domain and matches, merges, and generalizes them into sound draft domain models that include the commonality and variability allowed in these domains. The similarity of the different elements is measured, with consideration of syntactic, semantic, and structural aspects. Unlike ontology and schema integration, these models capture both structural and behavioral aspects of the domain. Running SDM on small repositories of project management applications and scheduling systems, we found that the approach may provide reasonable draft domain models, whose comprehensibility, correctness, completeness, and consistency levels are satisfactory.},
journal = {Data Knowl. Eng.},
month = may,
pages = {491–515},
numpages = {25},
keywords = {UML, Product line engineering, Metamodeling, Domain engineering, Domain analysis, DSL}
}

@article{10.1145/1183236.1183264,
author = {Batory, Don and Benavides, David and Ruiz-Cortes, Antonio},
title = {Automated analysis of feature models: challenges ahead},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183264},
doi = {10.1145/1183236.1183264},
journal = {Commun. ACM},
month = dec,
pages = {45–47},
numpages = {3}
}

@article{10.1145/1183236.1183250,
author = {Crawford, Diane},
title = {Top 10 downloads from ACM's digital library},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183250},
doi = {10.1145/1183236.1183250},
journal = {Commun. ACM},
month = dec,
pages = {23–24},
numpages = {2}
}

@article{10.1145/1183236.1183252,
author = {Berghel, Hal},
title = {Fungible credentials and next-generation fraud},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183252},
doi = {10.1145/1183236.1183252},
abstract = {Digital technology is easing access and lowering barriers for a new generation of criminal.},
journal = {Commun. ACM},
month = dec,
pages = {15–19},
numpages = {5}
}

@article{10.1016/j.datak.2012.09.005,
author = {Reinhartz-Berger, Iris and Sturm, Arnon and Wand, Yair},
title = {Comparing functionality of software systems: An ontological approach},
year = {2013},
issue_date = {September, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {87},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2012.09.005},
doi = {10.1016/j.datak.2012.09.005},
abstract = {Organizations can reduce the costs and enhance the quality of required software by adapting existing software systems. Software adaptation decisions often involve comparing alternatives on two criteria: (1) how well a system meets users' requirements and (2) the effort required for adapting the system. These criteria reflect two points of view - of users and of developers. Common to both views is the notion of functionality, which software developers have traditionally used for effort estimation utilizing concepts such as function points. However, users involved in selecting systems are not necessarily familiar with such concepts. We propose an approach for comparing software functionality from users' point of view. The approach employs ontological concepts to define functionality in terms of system behaviors. To evaluate whether or not the approach is also usable by software developers, we conducted an exploratory experiment. In the experiment, software engineering students ranked descriptions of software systems on the amount of changes needed to adapt the systems to given requirements. The results demonstrated that the ontological approach was usable after a short training and provided results comparable to ranking done by expert software developers. We also compared the ontological approach to a method which employed function point concepts. The results showed no statistically significant differences in performance, but there seemed to be an advantage to the ontological approach for cases that were difficult to analyze. Moreover, it took less time to apply the ontological approach than the function point-based approach, and the difference was statistically significant.},
journal = {Data Knowl. Eng.},
month = sep,
pages = {320–338},
numpages = {19},
keywords = {Variability management, Software comparison, Requirements engineering, Ontologies, Function point analysis, Development effort estimation}
}

@article{10.1007/s10922-013-9265-5,
author = {Moens, Hendrik and Truyen, Eddy and Walraven, Stefan and Joosen, Wouter and Dhoedt, Bart and De Turck, Filip},
title = {Cost-Effective Feature Placement of Customizable Multi-Tenant Applications in the Cloud},
year = {2014},
issue_date = {October   2014},
publisher = {Plenum Press},
address = {USA},
volume = {22},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-013-9265-5},
doi = {10.1007/s10922-013-9265-5},
abstract = {Cloud computing technologies can be used to more flexibly provision application resources. By exploiting multi-tenancy, instances can be shared between users, lowering the cost of providing applications. A weakness of current cloud offerings however, is the difficulty of creating customizable applications that retain these advantages. In this article, we define a feature-based cloud resource management model, making use of Software Product Line Engineering techniques, where applications are composed of feature instances using a service-oriented architecture. We focus on how resources can be allocated in a cost-effective way within this model, a problem which we refer to as the feature placement problem. A formal description of this problem, that can be used to allocate resources in a cost-effective way, is provided. We take both the cost of failure to place features, and the cost of using servers into account, making it possible to take energy costs or the cost of public cloud infrastructure into consideration during the placement calculation. Four algorithms that can be used to solve the feature placement problem are defined. We evaluate the algorithm solutions, comparing them with the optimal solution determined using an integer linear problem solver, and evaluating the execution times of the algorithms, making use of both generated inputs and a use case based on three applications. We show that, using our approach a higher degree of multi-tenancy can be achieved, and that for the considered scenarios, taking the relationships between features into account and using application-oriented placement performs 25---40 % better than a purely feature-oriented placement.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {517–558},
numpages = {42},
keywords = {SPLE, Distributed computing, Cloud computing, Application placement}
}

@inproceedings{10.1145/3241403.3241426,
author = {Plakidas, Konstantinos and Schall, Daniel and Zdun, Uwe},
title = {Model-based support for decision-making in architecture evolution of complex software systems},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241426},
doi = {10.1145/3241403.3241426},
abstract = {Design decision support for software architects in complex industrial software systems, such as software ecosystems and systems-of-systems, which feature extensive reuse of third-party solutions and a variety of deployment options, is still an open challenge. We describe three industrial use cases involving considerable re-architecting, where on-premises solutions were migrated to a cloud-based IoT platforms. Based on these use cases, we analyse the challenges and derive requirements for an architecture knowledge model supporting this process. The presented methodology builds upon existing approaches and proposes a model for the description of extant software applications and the management of domain knowledge. We demonstrate its use to support the evolution and/or composition of software applications in a migration scenario in a systematic and traceable manner.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {21},
numpages = {7},
keywords = {systems-of-systems composition, software variability management, software migration, software architecture evolution, model-based decision support},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/1551722.1551730,
author = {Laguna, Miguel A. and Finat, Javier and Gonz\'{a}lez, Jos\'{e} A.},
title = {Mobile health monitoring and smart sensors: a product line approach},
year = {2009},
isbn = {9781605583983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1551722.1551730},
doi = {10.1145/1551722.1551730},
abstract = {The evolution of the population pyramid in developed countries, with an increasing proportion of aged people introduces new challenges to the public and private assistance services. A form of improving these services while keeping controlled the associated costs is to use remote continuous assistance. Wireless sensors allow obtaining real-time information of health parameters in a non-intrusive way. The determination of alert values for these parameters and the computing possibilities of the current mobile devices can facilitate a faster intervention which will minimize risks linked to delays in medical assistance. However, the diversity of risk situations is a factor that increases costs as many similar but not exactly identical products will be necessary now and in the future. We aim to solve this problem using an approach of software product lines, as multiple options can be easily incorporated to each final product implementation. This article presents the product line generic architecture and some examples of application, using wireless sensors connected to a central station by means of a smart phone, which is able to detect alarm situations.},
booktitle = {Proceedings of the 2009 Euro American Conference on Telematics and Information Systems: New Opportunities to Increase Digital Citizenship},
articleno = {8},
numpages = {8},
keywords = {software product line, sensor, remote health monitoring},
location = {Prague, Czech Republic},
series = {EATIS '09}
}

@article{10.1016/j.eswa.2014.05.049,
author = {Mizouni, Rabeb and Matar, Mohammad Abu and Mahmoud, Zaid Al and Alzahmi, Salwa and Salah, Aziz},
title = {A framework for context-aware self-adaptive mobile applications SPL},
year = {2014},
issue_date = {November, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {16},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.05.049},
doi = {10.1016/j.eswa.2014.05.049},
abstract = {Mobile Applications are rapidly emerging as a convenient medium for using a variety of services. Over time and with the high penetration of smartphones in society, self-adaptation has become an essential capability required by mobile application users. In an ideal scenario, an application is required to adjust its behavior according to the current context of its use. This raises the challenge in mobile computing towards the design and development of applications that sense and react to contextual changes to provide a value-added user experience. In its general sense, context information can relate to the environment, the user, or the device status. In this paper, we propose a novel framework for building context aware and adaptive mobile applications. Based on feature modeling and Software Product Lines (SPL) concepts, this framework guides the modeling of adaptability at design time and supports context awareness and adaptability at runtime. In the core of the approach, is a feature meta-model that incorporates, in addition to SPL concepts, application feature priorities to drive the adaptability. A tool, based on that feature model, is presented to model the mobile application features and to derive the SPL members. A mobile framework, built on top of OSGI framework to dynamically adapt the application at runtime is also described.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {7549–7564},
numpages = {16},
keywords = {SPL, Runtime adaptability, Multi-view variability model, Mobile devices, Feature priority}
}

@article{10.1016/j.jss.2007.06.002,
author = {Sinnema, Marco and Deelstra, Sybren},
title = {Industrial validation of COVAMOF},
year = {2008},
issue_date = {April, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {4},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.06.002},
doi = {10.1016/j.jss.2007.06.002},
abstract = {COVAMOF is a variability management framework for product families that was developed to reduce the number of iterations required during product derivation and to reduce the dependency on experts. In this paper, we present the results of an experiment with COVAMOF in industry. The results show that with COVAMOF, engineers that are not involved in the product family were now capable of deriving the products in 100% of the cases, compared to 29% of the cases without COVAMOF. For experts, the use of COVAMOF reduced the number of iterations by 42%, and the total derivation time by 38%.},
journal = {J. Syst. Softw.},
month = apr,
pages = {584–600},
numpages = {17},
keywords = {Software Variability Management, Product family engineering, Industrial validation}
}

@inproceedings{10.1007/978-3-642-25271-6_10,
author = {Schaefer, Ina and Gurov, Dilian and Soleimanifard, Siavash},
title = {Compositional algorithmic verification of software product lines},
year = {2010},
isbn = {9783642252709},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25271-6_10},
doi = {10.1007/978-3-642-25271-6_10},
abstract = {Software product line engineering allows large software systems to be developed and adapted for varying customer needs. The products of a software product line can be described by means of a &lt;em&gt;hierarchical variability model&lt;/em&gt; specifying the commonalities and variabilities between the artifacts of the individual products. The number of products generated by a hierarchical model is exponential in its size, which poses a serious challenge to software product line analysis and verification. For an analysis technique to scale, the effort has to be linear in the size of the model rather than linear in the number of products it generates. Hence, efficient product line verification is only possible if &lt;em&gt;compositional&lt;/em&gt; verification techniques are applied that allow the analysis of products to be &lt;em&gt;relativized&lt;/em&gt; on the properties of their variation points. In this paper, we propose simple hierarchical variability models (SHVM) with explicit variation points as a novel way to describe a set of products consisting of sets of methods. SHVMs provide a trade---off between expressiveness and a clean and simple model suitable for compositional verification. We generalize a previously developed compositional technique and tool set for the automatic verification of control---flow based temporal safety properties to product lines defined by SHVMs, and prove soundness of the generalization. The desired property relativization is achieved by introducing variation point specifications. We evaluate the proposed technique on a number of test cases.},
booktitle = {Proceedings of the 9th International Conference on Formal Methods for Components and Objects},
pages = {184–203},
numpages = {20},
location = {Graz, Austria},
series = {FMCO'10}
}

@inproceedings{10.5555/1964571.1964603,
author = {Hubaux, Arnaud and Boucher, Quentin and Hartmann, Herman and Michel, Rapha\"{e}l and Heymans, Patrick},
title = {Evaluating a textual feature modelling language: four industrial case studies},
year = {2010},
isbn = {9783642194399},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature models are commonly used in software product line engineering as a means to document variability. Since their introduction, feature models have been extended and formalised in various ways. The majority of these extensions are variants of the original tree-based graphical notation. But over time, textual dialects have also been proposed. The textual variability language (TVL) was proposed to combine the advantages of both graphical and textual notations. However, its benefits and limitations have not been empirically evaluated up to now. In this paper, we evaluate TVL with four cases from companies of different sizes and application domains. The study shows that practitioners can benefit from TVL. The participants appreciated the notation, the advantages of a textual language and considered the learning curve to be gentle. The study also reveals some limitations of the current version of TVL.},
booktitle = {Proceedings of the Third International Conference on Software Language Engineering},
pages = {337–356},
numpages = {20},
location = {Eindhoven, The Netherlands},
series = {SLE'10}
}

@inproceedings{10.1109/SEAA.2011.26,
author = {Elsner, Christoph and Lohmann, Daniel and Schroder-Preikschat, Wolfgang},
title = {Fixing Configuration Inconsistencies across File Type Boundaries},
year = {2011},
isbn = {9780769544885},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2011.26},
doi = {10.1109/SEAA.2011.26},
abstract = {Creating a valid software configuration often involves multiple configuration file types, such as feature models, domain-specific languages, or C header files with preprocessor defines. Enforcing constraints across file types boundaries already at configuration is necessary to prevent inconsistencies, which otherwise are costly to discover and resolve later on. We present a pragmatic framework to specify and apply inconsistency-resolving fixes on configuration files of arbitrary types. The framework converts each configuration file to a model, checks it for consistency, applies fixes, and serializes it back again. We argue that conventionally programmed fixes and round-trip mechanisms (i.e., converters and serializers) are indispensable for practical applicability and can provide sufficient reliability when following usual development practices. We have developed round-trip mechanisms for seven different configuration file types and two fixing mechanisms. One fixing mechanism extends previous work by combining automatic detection of correct fix locations with a marker mechanism that reduces the number of locations. A tool-supported process for applying the fixes provides user guidance and integrates additional semantic validity checks on serialized configuration files of complex types (e.g., feature models). Evaluations reveal a speed up in inconsistency fixing and that the performance of the currently integrated round-tripping and fixing mechanisms is competitive.},
booktitle = {Proceedings of the 2011 37th EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {116–123},
numpages = {8},
keywords = {Software Product Line, Software Configuration, Model Inconsistency Fixing},
series = {SEAA '11}
}

@article{10.1007/s10664-012-9208-x,
author = {Feigenspan, Janet and K\"{a}stner, Christian and Apel, Sven and Liebig, J\"{o}rg and Schulze, Michael and Dachselt, Raimund and Papendieck, Maria and Leich, Thomas and Saake, Gunter},
title = {Do background colors improve program comprehension in the #ifdef hell?},
year = {2013},
issue_date = {August    2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9208-x},
doi = {10.1007/s10664-012-9208-x},
abstract = {Software-product-line engineering aims at the development of variable and reusable software systems. In practice, software product lines are often implemented with preprocessors. Preprocessor directives are easy to use, and many mature tools are available for practitioners. However, preprocessor directives have been heavily criticized in academia and even referred to as "#ifdef hell", because they introduce threats to program comprehension and correctness. There are many voices that suggest to use other implementation techniques instead, but these voices ignore the fact that a transition from preprocessors to other languages and tools is tedious, erroneous, and expensive in practice. Instead, we and others propose to increase the readability of preprocessor directives by using background colors to highlight source code annotated with ifdef directives. In three controlled experiments with over 70 subjects in total, we evaluate whether and how background colors improve program comprehension in preprocessor-based implementations. Our results demonstrate that background colors have the potential to improve program comprehension, independently of size and programming language of the underlying product. Additionally, we found that subjects generally favor background colors. We integrate these and other findings in a tool called FeatureCommander, which facilitates program comprehension in practice and which can serve as a basis for further research.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {699–745},
numpages = {47},
keywords = {Software visualization, Software product lines, Program comprehension, Preprocessors, FeatureCommander, Empirical software engineering}
}

@inproceedings{10.1145/1629716.1629738,
author = {Alf\'{e}rez, Mauricio and Moreira, Ana and Kulesza, Uir\'{a} and Ara\'{u}jo, Jo\~{a}o and Mateus, Ricardo and Amaral, Vasco},
title = {Detecting feature interactions in SPL requirements analysis models},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629738},
doi = {10.1145/1629716.1629738},
abstract = {The consequences of unwanted feature interactions in a Software Product Line (SPL) can range from minor problems to critical software failures. However, detecting feature interactions in reasonably complex model-based SPLs is a non-trivial task. This is due to the often large number of interdependent models that describe the SPL features and the lack of support for analyzing the relationships inside those models. We believe that the early detection of the points, where two or more features interact --- based on the models that describe the behavior of the features ---, is a starting point for the detection of conflicts and inconsistencies between features, and therefore, take an early corrective action.This vision paper foresees a process to find an initial set of points where it is likely to find potential feature interactions in model-based SPL requirements, by detecting: (i) dependency patterns between features using use case models; and (ii) overlapping between use case scenarios modeled using activity models.We focus on requirements models, which are special, since they do not contain many details about the structural components and the interactions between the higher-level abstraction modules of the system. Therefore, use cases and activity models are the means that help us to analyze the functionality of a complex system looking at it from a high level end-user view to anticipate the places where there are potential feature interactions. We illustrate the approach with a home automation SPL and then discuss about its applicability.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {117–123},
numpages = {7},
keywords = {feature interactions, software product lines requirements},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@article{10.1109/TSE.2015.2449854,
author = {Duran-Limon, Hector A. and Garcia-Rios, Carlos A. and Castillo-Barrera, Francisco E. and Capilla, Rafael},
title = {An Ontology-Based Product Architecture Derivation Approach},
year = {2015},
issue_date = {Dec. 2015},
publisher = {IEEE Press},
volume = {41},
number = {12},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2015.2449854},
doi = {10.1109/TSE.2015.2449854},
abstract = {Software product line (SPL) engineering has proven to improve software quality and shorten development cycles, cost and time. In product line engineering, product derivation is concerned with the realization of the variability at the implementation level. However, the majority of research works focuses on instantiating the variants selected in the final product, while the derivation at the architecture level has been poorly explored. As product line engineers often customize the product architecture by hand during the application engineering phase, the derivation and customization processes of the product line architecture (PLA) might be in some cases error-prone. Consequently, in this research we present an Ontology-based product Architecture Derivation (OntoAD) framework which automates the derivation of product-specific architectures from an SPL architecture. Our solution uses a language-independent model to specify the product line architecture and a model-driven engineering approach for architecture derivation activities. We use an ontology formalism to reason about the automatic generation of model-to-model transformation rules based on the selection of features and we illustrate our approach using a voice over IP motivating example. Finally, we report results about scalability and performance regarding the size of the variability model.},
journal = {IEEE Trans. Softw. Eng.},
month = dec,
pages = {1153–1168},
numpages = {16}
}

@inproceedings{10.1145/1385486.1385495,
author = {Sunkle, Sagar and Kuhlemann, Martin and Siegmund, Norbert and Rosenm\"{u}ller, Marko and Saake, Gunter},
title = {Generating highly customizable SQL parsers},
year = {2008},
isbn = {9781595939647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385486.1385495},
doi = {10.1145/1385486.1385495},
abstract = {Database technology and the Structured Query Language (SQL) have grown enormously in recent years. Applications from different domains have different requirements for using database technology and SQL. The major problem of current standards of SQL is complexity and unmanageability. In this paper we present an approach based on software product line engineering which can be used to create customizable SQL parsers and consequently different SQL dialects. We present an overview of how SQL can be decomposed in terms of features and compose different features to create different parsers for SQL.},
booktitle = {Proceedings of the 2008 EDBT Workshop on Software Engineering for Tailor-Made Data Management},
pages = {29–33},
numpages = {5},
keywords = {tailor-made data management, feature-oriented programming, embedded systems},
location = {Nantes, France},
series = {SETMDM '08}
}

@article{10.1016/j.is.2012.11.010,
author = {Gr\"{o}Ner, Gerd and Bo\v{s}Kovi\'{c}, Marko and Silva Parreiras, Fernando and Ga\v{s}Evi\'{c}, Dragan},
title = {Modeling and validation of business process families},
year = {2013},
issue_date = {July, 2013},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {38},
number = {5},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2012.11.010},
doi = {10.1016/j.is.2012.11.010},
abstract = {Process modeling is an expensive task that needs to encompass requirements of different stakeholders, assure compliance with different standards, and enable the flexible adaptivity to newly emerging requirements in today's dynamic global market. Identifying reusability of process models is a promising direction towards reducing the costs of process modeling. Recent research has offered several solutions. Such solutions promote effective and formally sound methods for variability modeling and configuration management. However, ensuring behavioral validity of reused process models with respect to the original process models (often referred to as reference process models) is still an open research challenge. To address this challenge, in this paper, we propose the notion of business process families by building upon the well-known software engineering discipline-software product line engineering. Business process families comprise (i) a variability modeling perspective, (ii) a process model template (or reference model), and (iii) mappings between (i) and (ii). For business process families, we propose a correct validation algorithm ensuring that each member of a business process family adheres to the core intended behavior that is specified in the process model template. The proposed validation approach is based on the use of Description Logics, variability is represented by using the well-known Feature Models and behavior of process models is considered in terms of control flow patterns. The paper also reports on the experience gained in two external trial cases and results obtained by measuring the tractability of the implementation of the proposed validation approach.},
journal = {Inf. Syst.},
month = jul,
pages = {709–726},
numpages = {18},
keywords = {Validation, Process model variability, Process model configuration, Control flow relations, Business process families}
}

@inproceedings{10.1145/3194133.3194143,
author = {Olaechea, Rafael and Atlee, Joanne and Legay, Axel and Fahrenberg, Uli},
title = {Trace checking for dynamic software product lines},
year = {2018},
isbn = {9781450357159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194133.3194143},
doi = {10.1145/3194133.3194143},
abstract = {A key objective of self-adaptive systems is to continue to provide optimal quality of service when the environment changes. A dynamic software product line (DSPL) can benefit from knowing how its various product variants would have performed (in terms of quality of service) with respect to the recent history of inputs. We propose a family-based analysis that simulates all the product variants of a DSPL simultaneously, at runtime, on recent environmental inputs to obtain an estimate of the quality of service that each one of the product variants would have had, provided it had been executing. We assessed the efficiency of our DSPL analysis compared to the efficiency of analyzing each product individually on three case studies. We obtained mixed results due to the explosion of quality-of-service values for the product variants of a DSPL. After introducing a simple data abstraction on the values of quality-of- service variables, our DSPL analysis is between 1.4 and 7.7 times faster than analyzing the products one at a time.},
booktitle = {Proceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems},
pages = {69–75},
numpages = {7},
location = {Gothenburg, Sweden},
series = {SEAMS '18}
}

@article{10.1016/j.infsof.2010.03.014,
author = {Alves, Vander and Niu, Nan and Alves, Carina and Valen\c{c}a, George},
title = {Requirements engineering for software product lines: A systematic literature review},
year = {2010},
issue_date = {August, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.03.014},
doi = {10.1016/j.infsof.2010.03.014},
abstract = {Context: Software product line engineering (SPLE) is a growing area showing promising results in research and practice. In order to foster its further development and acceptance in industry, it is necessary to assess the quality of the research so that proper evidence for adoption and validity are ensured. This holds in particular for requirements engineering (RE) within SPLE, where a growing number of approaches have been proposed. Objective: This paper focuses on RE within SPLE and has the following goals: assess research quality, synthesize evidence to suggest important implications for practice, and identify research trends, open problems, and areas for improvement. Method: A systematic literature review was conducted with three research questions and assessed 49 studies, dated from 1990 to 2009. Results: The evidence for adoption of the methods is not mature, given the primary focus on toy examples. The proposed approaches still have serious limitations in terms of rigor, credibility, and validity of their findings. Additionally, most approaches still lack tool support addressing the heterogeneity and mostly textual nature of requirements formats as well as address only the proactive SPLE adoption strategy. Conclusions: Further empirical studies should be performed with sufficient rigor to enhance the body of evidence in RE within SPLE. In this context, there is a clear need for conducting studies comparing alternative methods. In order to address scalability and popularization of the approaches, future research should be invested in tool support and in addressing combined SPLE adoption strategies.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {806–820},
numpages = {15},
keywords = {Systematic literature review, Software product lines, Requirements engineering}
}

@article{10.1007/s10664-018-9652-3,
author = {Vale, Tassio and Almeida, Eduardo Santana},
title = {Experimenting with information retrieval methods in the recovery of feature-code SPL traces},
year = {2019},
issue_date = {Jun 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9652-3},
doi = {10.1007/s10664-018-9652-3},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1328–1368},
numpages = {41},
keywords = {Software traceability, Software product lines, Information retrieval, Controlled-experiment}
}

@article{10.1016/j.jss.2017.11.004,
author = {Carvalho, Michelle Larissa Luciano and da Silva, Matheus Lessa Gonalves and Gomes, Gecynalda Soares da Silva and Santos, Alcemir Rodrigues and Machado, Ivan do Carmo and Souza, Magno Lu de Jesus and de Almeida, Eduardo Santana},
title = {On the implementation of dynamic software product lines},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {136},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.11.004},
doi = {10.1016/j.jss.2017.11.004},
abstract = {A set of criteria to characterize mechanisms suitable to implement dynamic variability.A characterization of thirteen DSPL-ready variability mechanisms.Empirical evaluation of OOP and AOP from the perspective of DSPL evolution.Evidence showing that AOP is a feasible strategy to implement DSPL projects. Dynamic Software Product Line (DSPL) engineering is a paradigm aimed at handling adaptations at runtime. An inherent challenge in DSPL engineering is to reduce the design complexity of adaptable software, particularly in terms of evolution. Existing research only recently started to investigate evolution in this field, but does not assess the impact of different implementations under software quality in evolutionary scenarios. This work presents a characterization of thirteen dynamic variability mechanisms. Based on such characterization, we implemented a DSPL using Object-oriented Programming (OOP) mechanisms. From this implementation, we evidenced that DSPL requires changes and extensions to design, in terms of functionality and adaptation capabilities. Since Aspect-oriented Programming (AOP) was well ranked according to characterization and some studies have demonstrated the likely synergies between AOP and DSPL, we decided to compare it with OOP. We empirically evaluated how OOP and AOP could affect source code quality from the viewpoint of an evolving DSPL. As a result, AOP yields better results in terms of size, SoC, cohesion, and coupling measures. Conversely, AOP provides lower change propagation impact. Although the packages in AOP were more susceptible to changes than in OOP, we could indicate that AOP may be a feasible strategy for DSPL implementation.},
journal = {J. Syst. Softw.},
month = feb,
pages = {74–100},
numpages = {27},
keywords = {Variability mechanisms, Software evolution, Evidence-based software engineering, Dynamic software product lines}
}

@article{10.1007/s00766-013-0169-4,
author = {Greenyer, Joel and Molzam Sharifloo, Amir and Cordy, Maxime and Heymans, Patrick},
title = {Features meet scenarios: modeling and consistency-checking scenario-based product line specifications},
year = {2013},
issue_date = {June      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0169-4},
doi = {10.1007/s00766-013-0169-4},
abstract = {Many modern software-intensive systems consist of multiple components interacting together to deliver the intended functionality. Often, these systems come in many variants (products) and are managed together as a software product line. This variability is the source of additional complexity which can cause inconsistencies and offset the economies of scale promised by product line engineering. Engineers thus need intuitive, yet precise means for specifying requirements and require tools for automatically detecting inconsistencies within these requirements. In recent work, we proposed a technique for the scenario-based specification of interactions in product lines by a combination of Modal Sequence Diagrams and Feature Diagrams. Furthermore, we elaborated an efficient consistency-checking technique based on a dedicated model-checking approach especially tailored for product lines. In this paper, we report on further evaluations that underline significant performance benefits of our approach. We describe further optimizations and detail on how we encode the consistency-checking problem for a model-checker.},
journal = {Requir. Eng.},
month = jun,
pages = {175–198},
numpages = {24},
keywords = {Scenario-based specification, Product lines, Feature compositions, Consistency}
}

@inproceedings{10.1007/978-3-540-87875-9_35,
author = {Tawhid, Rasha and Petriu, Dorina},
title = {Integrating Performance Analysis in the Model Driven Development of Software Product Lines},
year = {2008},
isbn = {9783540878742},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-87875-9_35},
doi = {10.1007/978-3-540-87875-9_35},
abstract = {The paper proposes to integrate performance analysis in the early phases of the model-driven development process for Software Product Lines (SPL). We start by adding generic performance annotations to the UML model representing the set of core reusable SPL assets. The annotations are generic and use the MARTE Profile recently adopted by OMG. A first model transformation realized in the Atlas Transformation Language (ATL), which is the focus of this paper, derives the UML model of a specific product with concrete MARTE performance annotations from the SPL model. A second transformation generates a Layered Queueing Network performance model for the given product by applying an existing transformation approach named PUMA, developed in previous work. The proposed technique is illustrated with an e-commerce case study that models the commonality and variability in both structural and behavioural SPL views. A product is derived and the performance of two design alternatives is compared.},
booktitle = {Proceedings of the 11th International Conference on Model Driven Engineering Languages and Systems},
pages = {490–504},
numpages = {15},
keywords = {UML, Software Product Line, Performance Analysis, Model to model Transformation, MARTE, ATL},
location = {Toulouse, France},
series = {MoDELS '08}
}

@inproceedings{10.1007/978-3-030-58545-7_45,
author = {Li, Junbing and Zhang, Changqing and Zhu, Pengfei and Wu, Baoyuan and Chen, Lei and Hu, Qinghua},
title = {SPL-MLL: Selecting Predictable Landmarks for Multi-label Learning},
year = {2020},
isbn = {978-3-030-58544-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58545-7_45},
doi = {10.1007/978-3-030-58545-7_45},
abstract = {Although significant progress achieved, multi-label classification is still challenging due to the complexity of correlations among different labels. Furthermore, modeling the relationships between input and some (dull) classes further increases the difficulty of accurately predicting all possible labels. In this work, we propose to select a small subset of labels as landmarks which are easy to predict according to input (predictable) and can well recover the other possible labels (representative). Different from existing methods which separate the landmark selection and landmark prediction in the 2-step manner, the proposed algorithm, termed Selecting Predictable Landmarks for Multi-Label Learning (SPL-MLL), jointly conducts landmark selection, landmark prediction, and label recovery in a unified framework, to ensure both the representativeness and predictableness for selected landmarks. We employ the Alternating Direction Method (ADM) to solve our problem. Empirical studies on real-world datasets show that our method achieves superior classification performance over other state-of-the-art methods.},
booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part IX},
pages = {783–799},
numpages = {17},
keywords = {Multi-label learning, Predictable landmarks, A unified framework},
location = {Glasgow, United Kingdom}
}

@inproceedings{10.1109/ASE.2011.6100118,
author = {Soltani, Samaneh and Asadi, Mohsen and Hatala, Marek and Gasevic, Dragan and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on stakeholders' business concerns},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100118},
doi = {10.1109/ASE.2011.6100118},
abstract = {In Software Product Line Engineering, concrete products of a family can be generated through a configuration process over a feature model. The configuration process selects features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from all the available features in the feature model is a cumbersome task because 1) the stakeholders may have diverse business concerns and limited resources that they can spend on a product and 2) features may have negative and positive contributions on different business concern. Many configurations techniques have been proposed to facilitate software developers' tasks through automated product derivation. However, most of the current proposals for automatic configuration are not devised to cope with business oriented requirements and stakeholders' resource limitations. We propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy the stakeholders' business concerns and resource limitations. We also provide tooling support to facilitate the use of our framework.},
booktitle = {Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {536–539},
numpages = {4},
series = {ASE '11}
}

@inproceedings{10.1145/2110147.2110158,
author = {Lopez-Herrejon, Roberto E. and Egyed, Alexander},
title = {Towards fixing inconsistencies in models with variability},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110158},
doi = {10.1145/2110147.2110158},
abstract = {Recent years have witnessed a convergence between research in SPL and Model-Driven Engineering (MDE) that leverages the complementary capabilities that both paradigms can offer. A crucial factor for the success of MDE is the availability of effective support for detecting and fixing inconsistencies among model elements. The importance of such support is attested by the extensive literature devoted to the topic. However, when coupled with variability, the research focus has been devoted to inconsistency detection, while leaving the important issue of fixing the inconsistency largely unaddressed. In this research-in-progress paper, we explore one of the issues that variability raises for inconsistency fixing. Namely, in which features to locate the fixes. We compute what is the minimal number of fixes and use it as a baseline to compare fixes obtained with a heuristic based on feature model analysis and random approaches. Our work highlights the pros and cons of both approaches and suggests how they could be addressed.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {93–100},
numpages = {8},
keywords = {variability, software product line, safe composition, model, feature oriented software development, consistency checking, consistency},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@inproceedings{10.1145/2897045.2897047,
author = {da Mota Silveira Neto, Paulo Anselmo and de Santana, Taijara Loiola and de Almeida, Eduardo Santana and Cavalcanti, Yguarata Cerqueira},
title = {RiSE events: a testbed for software product lines experimentation},
year = {2016},
isbn = {9781450341769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897045.2897047},
doi = {10.1145/2897045.2897047},
abstract = {Software Product Lines (SPL) demand mature software engineering, planning and reuse, adequate practices of management and development, and also the ability to deal with organizational issues and architectural complexity. Thus, it is important the development of new techniques, tools and methods to deal with SPL complexity required by the variability management. To address this issue, an SPL has been proposed, where the existing variability was implemented by applying conditional compilation. Moreover, no framework was used to develop it, allowing any researcher to use the SPL without losing time learning some framework. In this work, we implemented an SPL test bed containing 34 functional features has 26.457 lines of code, 1493 methods and 496 classes.},
booktitle = {Proceedings of the 1st International Workshop on Variability and Complexity in Software Design},
pages = {12–13},
numpages = {2},
keywords = {variability, test bed, software product lines, security and availability tacticts},
location = {Austin, Texas},
series = {VACE '16}
}

@inproceedings{10.1145/2897695.2897701,
author = {Abilio, Ramon and Vale, Gustavo and Figueiredo, Eduardo and Costa, Heitor},
title = {Metrics for feature-oriented programming},
year = {2016},
isbn = {9781450341776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897695.2897701},
doi = {10.1145/2897695.2897701},
abstract = {Feature-oriented programming (FOP) is a programming technique to implement software product lines based on composition mechanisms called refinements. A software product line is a set of software systems that share a common, managed set of features satisfying the specific needs of a particular market segment. The literature reports various software metrics for software product lines developed using object-oriented and aspect-oriented programming. However, after a literature review, we observed that we lack the definition of FOP-specific metrics. Based on this observation, this paper proposes a set of eight novel metrics for feature-oriented programming. These metrics were derived both from our experience in FOP and from existing software metrics. We demonstrate the applicability of the proposed metrics by applying them to a software product line.},
booktitle = {Proceedings of the 7th International Workshop on Emerging Trends in Software Metrics},
pages = {36–42},
numpages = {7},
keywords = {software quality, software product lines, software metrics, feature-oriented programming},
location = {Austin, Texas},
series = {WETSoM '16}
}

@article{10.1007/s00766-013-0187-2,
author = {Zdravkovic, Jelena and Svee, Eric-Oluf and Giannoulis, Constantinos},
title = {Capturing consumer preferences as requirements for software product lines},
year = {2015},
issue_date = {March     2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0187-2},
doi = {10.1007/s00766-013-0187-2},
abstract = {Delivering great consumer experiences in competitive market conditions requires software vendors to move away from traditional modes of thinking to an outside-in perspective, one that shifts their business to becoming consumer-centric. Requirements engineers operating in these conditions thus need new means to both capture real preferences of consumers and then relate them to requirements for software customized in different ways to fit anyone. Additionally, because system development models require inputs that are more concrete than abstract, the indistinct values of consumers need to be classified and formalized. To address this challenge, this study aims to establish a conceptual link between preferences of consumers and system requirements, using software product line (SPL) as a means for systematically accommodating the variations within the preferences. The novelty of this study is a conceptual model of consumer preference, which integrates generic value frameworks from both psychology and marketing, and a method for its transformation to requirements for SPL using a goal-oriented RE framework as the mediator. The presented artifacts are grounded in an empirical study related to the development of a system for online education.},
journal = {Requir. Eng.},
month = mar,
pages = {71–90},
numpages = {20},
keywords = {Value modeling, Value, SPL, Requirements, Goal modeling, Features, Consumer value}
}

@article{10.1016/j.is.2010.01.001,
author = {Benavides, David and Segura, Sergio and Ruiz-Cort\'{e}s, Antonio},
title = {Automated analysis of feature models 20 years later: A literature review},
year = {2010},
issue_date = {September, 2010},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {35},
number = {6},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2010.01.001},
doi = {10.1016/j.is.2010.01.001},
abstract = {Software product line engineering is about producing a set of related products that share more commonalities than variabilities. Feature models are widely used for variability and commonality management in software product lines. Feature models are information models where a set of products are represented as a set of features in a single model. The automated analysis of feature models deals with the computer-aided extraction of information from feature models. The literature on this topic has contributed with a set of operations, techniques, tools and empirical results which have not been surveyed until now. This paper provides a comprehensive literature review on the automated analysis of feature models 20 years after of their invention. This paper contributes by bringing together previously disparate streams of work to help shed light on this thriving area. We also present a conceptual framework to understand the different proposals as well as categorise future contributions. We finally discuss the different studies and propose some challenges to be faced in the future.},
journal = {Inf. Syst.},
month = sep,
pages = {615–636},
numpages = {22},
keywords = {Software product lines, Literature review, Feature models, Automated analyses}
}

@inproceedings{10.1145/2973839.2973842,
author = {Lima, Crescencio and Chavez, Christina},
title = {A Systematic Review on Metamodels to Support Product Line Architecture Design},
year = {2016},
isbn = {9781450342018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973839.2973842},
doi = {10.1145/2973839.2973842},
abstract = {Product Line Architecture (PLA) design is a key activity for developing successful Software Product Line (SPL) projects. PLA design is a difficult task, mostly due to the complexity of the software systems that SPLs deal with, and their variabilities. Metamodels have been used to support the representation of assets that compose a PLA, SPL variability and the relationships among them. The goal of this study is to characterize the use of metamodeling on PLA design, aiming to identify the main characteristics of metamodels, the elements used for PLA and variability representation and trace the evolution of metamodels. We conducted a systematic literature review to identify the primary studies on the use of metamodels in PLA Design. Thirty-five studies that proposed metamodels to support PLA design were selected. The review main findings are: (i) it is difficult to identify the existence of research trends because the number of publication varies and metamodels lack standardization; (ii) several metamodels support feature representation; (iii) the majority of studies addressed variability representation with variation points in UML diagrams; and, (iv) five evolution lines that describe how metamodels evolved over the years were identified.},
booktitle = {Proceedings of the XXX Brazilian Symposium on Software Engineering},
pages = {13–22},
numpages = {10},
keywords = {Variability, Systematic Literature Review, Software Product Lines, Product Line Architecture, Metamodels},
location = {Maring\'{a}, Brazil},
series = {SBES '16}
}

@inproceedings{10.1145/3447545.3451177,
author = {Canales, Felipe and Hecht, Geoffrey and Bergel, Alexandre},
title = {Optimization of Java Virtual Machine Flags using Feature Model and Genetic Algorithm},
year = {2021},
isbn = {9781450383318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447545.3451177},
doi = {10.1145/3447545.3451177},
abstract = {Optimizing the Java Virtual Machine (JVM) options in order to get the best performance out of a program for production is a challenging and time-consuming task. HotSpot, the Oracle's open-source Java VM implementation offers more than 500 options, called flags, that can be used to tune the JVM's compiler, garbage collector (GC), heap size and much more. In addition to being numerous, these flags are sometimes poorly documented and create a need of benchmarking to ensure that the flags and their associated values deliver the best performance and stability for a particular program to execute.Auto-tuning approaches have already been proposed in order to mitigate this burden. However, in spite of increasingly sophisticated search techniques allowing for powerful optimizations, these approaches take little account of the underlying complexities of JVM flags. Indeed, dependencies and incompatibilities between flags are non-trivial to express, which if not taken into account may lead to invalid or spurious flag configurations that should not be considered by the auto-tuner.In this paper, we propose a novel model, inspired by the feature model used in Software Product Line, which takes the complexity of JVM's flags into account. We then demonstrate the usefulness of this model, using it as an input of a Genetic Algorithm (GA) to optimize the execution times of DaCapo Benchmarks.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {183–186},
numpages = {4},
keywords = {optimization, java virtual machine, genetic algorithm, feature model, auto-tuning},
location = {Virtual Event, France},
series = {ICPE '21}
}

@inproceedings{10.1145/3030207.3030226,
author = {Stefan, Petr and Horky, Vojtech and Bulej, Lubomir and Tuma, Petr},
title = {Unit Testing Performance in Java Projects: Are We There Yet?},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3030226},
doi = {10.1145/3030207.3030226},
abstract = {Although methods and tools for unit testing of performance exist for over a decade, anecdotal evidence suggests unit testing of performance is not nearly as common as unit testing of functionality. We examine this situation in a study of GitHub projects written in Java, looking for occurrences of performance evaluation code in common performance testing frameworks. We quantify the use of such frameworks, identifying the most relevant performance testing approaches, and describe how we adjust the design of our SPL performance testing framework to follow these conclusions.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {401–412},
numpages = {12},
keywords = {survey, spl, performance unit testing, open source, jmh},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3442391.3442395,
author = {Ataei, Parisa and Li, Qiaoran and Walkingshaw, Eric},
title = {Should Variation Be Encoded Explicitly in Databases?},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442395},
doi = {10.1145/3442391.3442395},
abstract = {Variation occurs in databases in many different forms and contexts. For example, a single database schema evolves over time, data from different sources may be combined, and the various configurations of a software product line (SPL) may have different data needs. While approaches have been developed to deal with many such scenarios, particularly in the fields of database evolution and data integration, there is no solution that treats variation as a general and orthogonal concern in databases. This is a problem when various kinds of variation intersect, such as during the evolution of a SPL. Previously, we have proposed variational databases (VDB) as a general way to represent variation in both the structure and content of databases. Although the model underlying VDB is simple, encoding variation explicitly in databases introduces complexity akin to using preprocessing directives in software. In this paper, we explore the feasibility of VDB and its associated variational query language for encoding different kinds of database variability. We develop two use cases that illustrate how different kinds of variation can be encoded and integrated in VDB, and how the corresponding information needs can be expressed as variational queries. We then use these use cases to discuss the benefits and drawbacks of such a direct encoding of variation in data and queries.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {3},
numpages = {9},
keywords = {variational queries, variability in data, Variational databases},
location = {Krems, Austria},
series = {VaMoS '21}
}

@article{10.1007/s11276-018-1718-z,
author = {Mukhlif, Fadhil and Noordin, Kamarul Ariffin Bin and Mansoor, Ali Mohammed and Kasirun, Zarinah Mohd},
title = {Green transmission for C-RAN based on SWIPT in 5G: a review},
year = {2019},
issue_date = {Jul 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {5},
issn = {1022-0038},
url = {https://doi.org/10.1007/s11276-018-1718-z},
doi = {10.1007/s11276-018-1718-z},
abstract = {C-RAN is a promising new design for the next generation, an important aspect of it in the energy efficiency consideration. Hence, it is considering an innovative candidate to use it as an alternative cellular network instead of the traditional. Investigation green transmission of mobile cloud radio access networks based on SWIPT for 5G cellular networks. Especially, with considering SWIPT as a future solution for increasing the lifetime of end-user battery’s, that’s mean this technique will improving energy efficiency (EE). Addressing SWIPT into C-RAN is a challenging and it is needed to developing a new algorithm to use it on the cellular network with many trying to ensure the success of the system performance. C-RAN as a network and SWIPT as a promising technique with the suggesting green wireless network are discussed besides the importance of energy efficiency for the next generation. Furthermore, there was a study on fifth enabling technologies that can be used for 5G with emphasis on two of them (C-RAN and energy efficiency). Lastly, research challenges and future direction that require substantial research efforts are summarized.},
journal = {Wirel. Netw.},
month = jul,
pages = {2621–2649},
numpages = {29},
keywords = {MIMO, Power splitting, Time switching, Information decoding (ID), Energy harvesting (EH), Cloud radio access network, Power transfer, Green transmission}
}

@article{10.1016/j.jss.2019.06.003,
author = {Capilla, Rafael and Fuentes, Lidia and Lochau, Malte},
title = {Software variability in dynamic environments},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {156},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.06.003},
doi = {10.1016/j.jss.2019.06.003},
journal = {J. Syst. Softw.},
month = oct,
pages = {62–64},
numpages = {3}
}

@inproceedings{10.1145/3168365.3168374,
author = {Arcaini, Paolo and Gargantini, Angelo and Radavelli, Marco},
title = {An evolutionary process for product-driven updates of feature models},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168374},
doi = {10.1145/3168365.3168374},
abstract = {Feature models are a widely used modeling notation for variability and commonality management in software product line (SPL) engineering. In order to keep an SPL and its feature model aligned, feature models must be changed by including/excluding new features and products, either because faults in the model are found or to reflect the normal evolution of the SPL. The modification of the feature model able to satisfy these change requirements can be complex and error-prone. In this paper, we present a method that is able to automatically update a feature model in order to satisfy a given update request. Our method is based on an evolutionary algorithm and it iteratively applies structure-preserving mutations to the original model, until the model is completely updated. We evaluate the process on real-world feature models. Although our approach does not guarantee to completely update all possible feature models, empirical analysis shows that, on average, more than 80% of requested changes are applied.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {67–74},
numpages = {8},
keywords = {software product lines, search-based software engineering, mutation, feature models},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@article{10.1007/s10489-018-01399-9,
author = {Abolpour Mofrad, Asieh and Yazidi, Anis and Lewi Hammer, Hugo},
title = {On solving the SPL problem using the concept of probability flux},
year = {2019},
issue_date = {July      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {7},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-018-01399-9},
doi = {10.1007/s10489-018-01399-9},
abstract = {The Stochastic Point Location (SPL) problem Oommen is a fundamental learning problem that has recently found a lot of research attention. SPL can be summarized as searching for an unknown point in an interval under faulty feedback. The search is performed via a Learning Mechanism (LM) (algorithm) that interacts with a stochastic Environment which in turn informs it about the direction of the search. Since the Environment is stochastic, the guidance for directions could be faulty. The first solution to the SPL problem, which was pioneered two decades ago by Oommen, relies on discretizing the search interval and performing a controlled random walk on it. The state of the random walk at each step is considered to be the estimation of the point location. The convergence of the latter simplistic estimation strategy is proved for an infinite resolution, i.e., infinite memory. However, this strategy yields rather poor accuracy for low discretization resolutions. In this paper, we present two major contributions to the SPL problem. First, we demonstrate that the estimation of the point location can significantly be improved by resorting to the concept of mutual probability flux between neighboring states along the line. Second, we are able to accurately track the position of the optimal point and simultaneously show a method by which we can estimate the error probability characterizing the Environment. Interestingly, learning this error probability of the Environment takes place in tandem with the unknown location estimation. We present and analyze several experiments discussing the weaknesses and strengths of the different methods.},
journal = {Applied Intelligence},
month = jul,
pages = {2699–2722},
numpages = {24},
keywords = {Stochastic Point Location (SPL), Stochastic Learning Weak Estimation (SLWE), Mutual probability flux, Last Transition-based Estimation Solution (LTES), Flux-based Estimation Solution (FES), Estimating environment effectiveness}
}

@inproceedings{10.5555/1885639.1885667,
author = {Bagheri, Ebrahim and Asadi, Mohsen and Gasevic, Dragan and Soltani, Samaneh},
title = {Stratified analytic hierarchy process: prioritization and selection of software features},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product line engineering allows for the rapid development of variants of a domain specific application by using a common set of reusable assets often known as core assets. Variability modeling is a critical issue in product line engineering, where the use of feature modeling is one of most commonly used formalisms. To support an effective and automated derivation of concrete products for a product family, staged configuration has been proposed in the research literature. In this paper, we propose the integration of well-known requirements engineering principles into stage configuration. Being inspired by the well-established Preview requirements engineering framework, we initially propose an extension of feature models with capabilities for capturing business oriented requirements. This representation enables a more effective capturing of stakeholders' preferences over the business requirements and objectives (e.g.,. implementation costs or security) in the form of fuzzy linguistic variables (e.g., high, medium, and low). On top of this extension, we propose a novel method, the Stratified Analytic Hierarchy process, which first helps to rank and select the most relevant high level business objectives for the target stakeholders (e.g., security over implementation costs), and then helps to rank and select the most relevant features from the feature model to be used as the starting point in the staged configuration process. Besides a complete formalization of the process, we define the place of our proposal in existing software product line lifecycles as well as demonstrate the use of our proposal on the widely-used e-Shop case study. Finally, we report on the results of our user study, which indicates a high appreciation of the proposed method by the participating industrial software developers. The tool support for S-AHP is also introduced.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {300–315},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.5555/1759779.1759839,
author = {Moon, Mikyeong and Yeom, Keunhyuk},
title = {Product line architecture for RFID-enabled applications},
year = {2007},
isbn = {9783540720348},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Radio Frequency Identification (RFID) is an established technology and has the potential, in a variety of applications, to significantly reduce cost and improve performance. RFID may dramatically change an organization's capacity to obtain real-time information concerning the location and properties of tagged people or objects. However, simply adding RFID to an existing process is a losing proposition. The entire process should be reconsidered in order to take advantage of real-time inventory data and the near real-time tracking and management of inventory. As RFID-enabled applications will fulfill similar tasks across a range of processes adapted to use the data gained from RFID tags, they can be considered as software products derived from a common infrastructure and assets that capture specific abstractions in the domain. That is, it may be appropriate to design RFID-enabled applications as elements of a product line. This paper discusses product line architecture for RFID-enabled applications. In developing this architecture, common activities are identified among the RFID-enabled applications and the variability in the common activities is analyzed in detail using variation point concepts. A product line architecture explicitly representing commonality and variability is described using UML activity diagrams. Sharing a common architecture and reusing assets to deploy recurrent services may be considered an advantage in terms of economic significance and overall quality.},
booktitle = {Proceedings of the 10th International Conference on Business Information Systems},
pages = {638–651},
numpages = {14},
keywords = {software product line, product line architecture, RFID-enabled application, RFID},
location = {Poznan, Poland},
series = {BIS'07}
}

@article{10.1016/j.infsof.2006.08.001,
author = {Sinnema, Marco and Deelstra, Sybren},
title = {Classifying variability modeling techniques},
year = {2007},
issue_date = {July, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {7},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.08.001},
doi = {10.1016/j.infsof.2006.08.001},
abstract = {Variability modeling is important for managing variability in software product families, especially during product derivation. In the past few years, several variability modeling techniques have been developed, each using its own concepts to model the variability provided by a product family. The publications regarding these techniques were written from different viewpoints, use different examples, and rely on a different technical background. This paper sheds light on the similarities and differences between six variability modeling techniques, by exemplifying the techniques with one running example, and classifying them using a framework of key characteristics for variability modeling. It furthermore discusses the relation between differences among those techniques, and the scope, size, and application domain of product families.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {717–739},
numpages = {23},
keywords = {Variability modeling, Variability management, Software product family, Classification}
}

@inproceedings{10.1145/3297280.3297511,
author = {Allian, Ana Paula and Sena, Bruno and Nakagawa, Elisa Yumi},
title = {Evaluating variability at the software architecture level: an overview},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297511},
doi = {10.1145/3297280.3297511},
abstract = {Software architecture are designed for developing software systems needed for a diverse of business goals. Consequently, architecture has to deal with a significant amount of variability in functionality and quality attributes to create different products. Due to this variability, the evaluation in software architectures is much more complex, as different alternatives of systems might be developed leading to an expensive and time consuming task. Several methods and techniques have been proposed to evaluate product line architectures (PLAs) aiming to asses whether or not the architecture will lead to the desired quality attributes. However, there is little consensus on the existing evaluations methods is most suitable for evaluating variability in software architectures, instead of only considering PLAs. Understanding and explicitly evaluating variations in architectures is a cost-effective way of mitigating substantial risk to organizations and their software systems. Therefore, the main contribution of this research work is to present the state of the art about means for evaluating software architectures (including, PLAs, software architectures, reference and enterprise architectures) that contain variability information. We conducted a Systematic Mapping Study (SMS) to provide an overview and insight to practitioners about the most relevant techniques and methods developed for this evaluation. Results indicate that most evaluation techniques assess variability as a quality attribute in PLAs through scenario-based; however, little is known about their real effectiveness as most studies present gaps and lack of evaluation, which difficult the usage of such techniques in an industrial environment.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2354–2361},
numpages = {8},
keywords = {evaluation, software architecture, software variability, systematic mapping study},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1109/ICN.2010.48,
author = {Morais, Yuri and Elias, Gl\^{e}dson},
title = {Integrating Communication Paradigms in a Mobile Middleware Product Line},
year = {2010},
isbn = {9780769539799},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICN.2010.48},
doi = {10.1109/ICN.2010.48},
abstract = {Several middleware solutions have been proposed for supporting development of networked mobile applications, which are often designed with different distribution requirements and for various application scenarios. In this sense, a middleware that offers only a single communication paradigm (e.g., publish/subscribe) cannot cope with the diversity of applications and its reuse becomes very limited. In this context, this paper goal is to propose a mobile middleware solution which offers a set of communication paradigms, ranging from the traditional synchronous model to different variations of the so-called asynchronous models. In order to optimize memory footprint, common features in distributed communication are shared among all communication paradigms. Additionally, by means of a product line-based design, features can be selected and thus the middleware can be customized to better fit in more constrained devices.},
booktitle = {Proceedings of the 2010 Ninth International Conference on Networks},
pages = {255–261},
numpages = {7},
keywords = {software product line, mobile computing, middleware, messaging model, communication paradigm},
series = {ICN '10}
}

@inproceedings{10.1145/2556624.2556645,
author = {Adelsberger, Stephan and Sobernig, Stefan and Neumann, Gustaf},
title = {Towards assessing the complexity of object migration in dynamic, feature-oriented software product lines},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556645},
doi = {10.1145/2556624.2556645},
abstract = {Dynamic Software Product Lines (DSPLs) implement features of a product family, from which products can be derived and reconfigured at runtime. This way, systems can alternate their configurations without service interruption. The activation and deactivation of features at runtime pose challenges for the implementation of a DSPL, in particular for handling object states such as runtime changes to object-scoped variables, their value assignments, and the variable properties. To quantify the complexity of this object migration, we propose a systematic code-level measurement approach which harvests feature implementations and the corresponding variability models for code introductions responsible for critical changes to object states.We have applied our measurement process tentatively to data sets representing 9 SPLs implemented using Fuji. This way, we arrived at first insights on object-migration complexity in SPLs. For example, we observed that the number of feature-specific object states is distributed very unequally in Fuji SPLs, with a few objects having an overly complex map of potential object states and the majority of objects potentially seeing transitions between 1 and 5 object states. We also evaluated different tactics of applying SAT solvers to analyze variability models in this context.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {17},
numpages = {8},
keywords = {object migration, feature-oriented programming, feature binding, dynamic software product line, constructor anomaly},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.5555/2821357.2821367,
author = {Baresi, Luciano and Quinton, Cl\'{e}ment},
title = {Dynamically evolving the structural variability of dynamic software product lines},
year = {2015},
publisher = {IEEE Press},
abstract = {A Dynamic Software Product Line (dspl) is a widely used approach to handle variability at runtime, e.g., by activating or deactivating features to adapt the running configuration. With the emergence of highly configurable and evolvable systems, dspls have to cope with the evolution of their structural variability, i.e., the Feature Model (fm) used to derive the configuration. So far, little is known about the evolution of the fm while a configuration derived from this fm is running. In particular, such a dynamic evolution changes the dspl configuration space, which is thus unsynchronized with the running configuration and its adaptation capabilities. In this position paper, we propose and describe an initial architecture to manage the dynamic evolution of dspls and their synchronization. In particular, we explain how this architecture supports the evolution of dspls based on fms extended with cardinality and attributes, which, to the best of our knowledge, has never been addressed yet.},
booktitle = {Proceedings of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {57–63},
numpages = {7},
location = {Florence, Italy},
series = {SEAMS '15}
}

@article{10.5555/3163583.3163679,
author = {Lanna, Andr and Castro, Thiago and Alves, Vander and Rodrigues, Genaina and Schobbens, Pierre-Yves and Apel, Sven},
title = {Feature-family-based reliability analysis of software product lines},
year = {2018},
issue_date = {February 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {94},
number = {C},
issn = {0950-5849},
abstract = {ContextVerification techniques are being applied to ensure that software systems achieve desired quality levels and fulfill functional and non-functional requirements. However, applying these techniques to software product lines is challenging, given the exponential blowup of the number of products. Current product-line verification techniques leverage symbolic model checking and variability information to optimize the analysis, but still face limitations that make them costly or infeasible. In particular, state-of-the-art verification techniques for product-line reliability analysis are enumerative which hinders their applicability, given the latent exponential blowup of the configuration space. ObjectiveThe objectives of this paper are the following: (a) we present a method to efficiently compute the reliability of all configurations of a compositional or annotation-based software product line from its UML behavioral models, (b) we provide a tool that implements the proposed method, and (c) we report on an empirical study comparing the performance of different reliability analysis strategies for software product lines. MethodWe present a novel feature-family-based analysis strategy to compute the reliability of all products of a (compositional or annotation-based) software product line. The feature-based step of our strategy divides the behavioral models into smaller units that can be analyzed more efficiently. The family-based step performs the reliability computation for all configurations at once by evaluating reliability expressions in terms of a suitable variational data structure. ResultsOur empirical results show that our feature-family-based strategy for reliability analysis outperforms, in terms of time and space, four state-of-the-art strategies (product-based, family-based, feature-product-based, and family-product-based) for the same property. It is the only one that could be scaled to a 220-fold increase in the size of the configuration space. ConclusionOur feature-family-based strategy leverages both feature- and family-based strategies by taming the size of the models to be analyzed and by avoiding the products enumeration inherent to some state-of-the-art analysis methods.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {59–81},
numpages = {23},
keywords = {Software reliability analysis, Software product lines, Parametric verification}
}

@inproceedings{10.1145/3425269.3425278,
author = {Bindewald, Carlos Vinicius and Freire, Willian M. and Amaral, Aline M. M. Miotto and Colanzi, Thelma Elita},
title = {Supporting user preferences in search-based product line architecture design using Machine Learning},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425278},
doi = {10.1145/3425269.3425278},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line. PLA design requires intensive human effort as it involves several conflicting factors. In order to support this task, an interactive search-based approach, automated by a tool named OPLA-Tool, was proposed in a previous work. Through this tool the software architect evaluates the generated solutions during the optimization process. Considering that evaluating PLA is a complex task and search-based algorithms demand a high number of generations, the evaluation of all solutions in all generations cause human fatigue. In this work, we incorporated in OPLA-Tool a Machine Learning (ML) model to represent the architect in some moments during the optimization process aiming to decrease the architect's effort. Through the execution of a quantiqualitative exploratory study it was possible to demonstrate the reduction of the fatigue problem and that the solutions produced at the end of the process, in most cases, met the architect's needs.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {11–20},
numpages = {10},
keywords = {Product Line Architecture, Machine Learning, Human-computer interaction},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@article{10.1016/j.scico.2010.10.005,
author = {Classen, Andreas and Boucher, Quentin and Heymans, Patrick},
title = {A text-based approach to feature modelling: Syntax and semantics of TVL},
year = {2011},
issue_date = {December, 2011},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {76},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2010.10.005},
doi = {10.1016/j.scico.2010.10.005},
abstract = {In the scientific community, feature models are the de-facto standard for representing variability in software product line engineering. This is different from industrial settings where they appear to be used much less frequently. We and other authors found that in a number of cases, they lack concision, naturalness and expressiveness. This is confirmed by industrial experience. When modelling variability, an efficient tool for making models intuitive and concise are feature attributes. Yet, the semantics of feature models with attributes is not well understood and most existing notations do not support them at all. Furthermore, the graphical nature of feature models' syntax also appears to be a barrier to industrial adoption, both psychological and rational. Existing tool support for graphical feature models is lacking or inadequate, and inferior in many regards to tool support for text-based formats. To overcome these shortcomings, we designed TVL, a text-based feature modelling language. In terms of expressiveness, TVL subsumes most existing dialects. The main goal of designing TVL was to provide engineers with a human-readable language with a rich syntax to make modelling easy and models natural, but also with a formal semantics to avoid ambiguity and allow powerful automation.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {1130–1143},
numpages = {14},
keywords = {Syntax, Software product lines, Semantics, Modelling, Language, Feature models, Code}
}

@inproceedings{10.5555/1885639.1885659,
author = {Ghanam, Yaser and Maurer, Frank},
title = {Linking feature models to code artifacts using executable acceptance tests},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A feature model is a representation of the requirements in a given system abstracted at the feature level. Linking conceptual requirements in feature models to actual implementation artifacts provides for many advantages such as increased program comprehension, implementation completeness assessment, impact analysis, and reuse opportunities. However, in practice, as systems evolve, traceability links between the model and the code artifacts may become broken or outdated. In this paper, we contribute an approach to provide traceability links in a way that ensures consistency between the feature model and the code artifacts, enables the evolution of variability in the feature model, and supports the product derivation process. We do that by using executable acceptance tests as a direct traceability link between feature models and code artifacts. We evaluate our approach and present a brief overview of the tool support we provide.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {211–225},
numpages = {15},
keywords = {variability evolution, traceability, feature models, executable acceptance tests, agile product line engineering},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.5555/3337507.3337510,
title = {Model checking software product lines based on feature slicing},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {4},
issn = {1742-7185},
abstract = {Feature model is a popular formalism for describing the commonality and variability of a software product line in terms of features. Feature models symbolise a presentation of the possible application configuration space, and can be customised based on specific domain requirements and stakeholder goals. As feature models are becoming increasingly complex, it is desired to provide automatic support for customised analysis and verification based on the specific goals and requirements of stakeholders. This paper first presents feature model slicing based on the requirements of the users. We then introduce three-valued abstraction of behaviour models based on the slicing unit. Finally, based on multi-valued model checker, a case study was conducted to illustrate the effectiveness of our approach.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {340–348},
numpages = {9}
}

@inproceedings{10.1109/ASE.2015.16,
author = {Kowal, Matthias and Tschaikowski, Max and Tribastone, Mirco and Schaefer, Ina},
title = {Scaling size and parameter spaces in variability-aware software performance models},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.16},
doi = {10.1109/ASE.2015.16},
abstract = {In software performance engineering, what-if scenarios, architecture optimization, capacity planning, run-time adaptation, and uncertainty management of realistic models typically require the evaluation of many instances. Effective analysis is however hindered by two orthogonal sources of complexity. The first is the infamous problem of state space explosion---the analysis of a single model becomes intractable with its size. The second is due to massive parameter spaces to be explored, but such that computations cannot be reused across model instances. In this paper, we efficiently analyze many queuing models with the distinctive feature of more accurately capturing variability and uncertainty of execution rates by incorporating general (i.e., non-exponential) distributions. Applying product-line engineering methods, we consider a family of models generated by a core that evolves into concrete instances by applying simple delta operations affecting both the topology and the model's parameters. State explosion is tackled by turning to a scalable approximation based on ordinary differential equations. The entire model space is analyzed in a family-based fashion, i.e., at once using an efficient symbolic solution of a super-model that subsumes every concrete instance. Extensive numerical tests show that this is orders of magnitude faster than a naive instance-by-instance analysis.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {407–417},
numpages = {11},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@inproceedings{10.1145/2701319.2701325,
author = {Devroey, Xavier and Perrouin, Gilles and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Covering SPL Behaviour with Sampled Configurations: An Initial Assessment},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701325},
doi = {10.1145/2701319.2701325},
abstract = {Structural approaches to Software Product Lines (SPL) testing (such as pairwise testing) have gained momentum as they are able to scale to larger SPLs described as feature diagrams (FD). However, these methods are agnostic with respect to behaviour: the sampled configurations have thus no reason to satisfy any given behavioural criterion. In this paper, we investigate the behavioural coverage of two structural testing criteria: pairwise and similarity. To do so, we modelled four SPLs in terms of feature diagrams and associated featured transitions systems (FTSs). We then computed state, action and transition coverage for a set of generated configurations. Preliminary results indicate that for relatively small variability models with few cross-tree constraints, structural coverage-driven tools tend to cover large parts of behaviour with less than 8 configurations. Though structural coverage cannot be used directly as a replacement for behavioural driven SPL test generation, opportunities to mix structural and behavioural coverage for efficient and effective SPL testing do exist.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {59–66},
numpages = {8},
keywords = {Structural Coverage, SPL Testing, Featured Transition System},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@article{10.1145/2581376,
author = {Behjati, Razieh and Nejati, Shiva and Briand, Lionel C.},
title = {Architecture-Level Configuration of Large-Scale Embedded Software Systems},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2581376},
doi = {10.1145/2581376},
abstract = {Configuration in the domain of Integrated Control Systems (ICS) is largely manual, laborious, and error prone. In this article, we propose a model-based configuration approach that provides automation support for reducing configuration effort and the likelihood of configuration errors in the ICS domain. We ground our approach on component-based specifications of ICS families. We then develop a configuration algorithm using constraint satisfaction techniques over finite domains to generate products that are consistent with respect to their ICS family specifications. We reason about the termination and consistency of our configuration algorithm analytically. We evaluate the effectiveness of our configuration approach by applying it to a real subsea oil production system. Specifically, we have rebuilt a number of existing verified product configurations of our industry partner. Our experience shows that our approach can automatically infer up to 50% of the configuration decisions, and reduces the complexity of making configuration decisions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {25},
numpages = {43},
keywords = {product configuration, formal specification, constraint satisfaction techniques, consistent configuration, UML/OCL, Model-based product-line engineering}
}

@article{10.1016/j.infsof.2011.11.009,
author = {Angelov, Samuil and Grefen, Paul and Greefhorst, Danny},
title = {A framework for analysis and design of software reference architectures},
year = {2012},
issue_date = {April, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {4},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.11.009},
doi = {10.1016/j.infsof.2011.11.009},
abstract = {Context: A software reference architecture is a generic architecture for a class of systems that is used as a foundation for the design of concrete architectures from this class. The generic nature of reference architectures leads to a less defined architecture design and application contexts, which makes the architecture goal definition and architecture design non-trivial steps, rooted in uncertainty. Objective: The paper presents a structured and comprehensive study on the congruence between context, goals, and design of software reference architectures. It proposes a tool for the design of congruent reference architectures and for the analysis of the level of congruence of existing reference architectures. Method: We define a framework for congruent reference architectures. The framework is based on state of the art results from literature and practice. We validate our framework and its quality as analytical tool by applying it for the analysis of 24 reference architectures. The conclusions from our analysis are compared to the opinions of experts on these reference architectures documented in literature and dedicated communication. Results: Our framework consists of a multi-dimensional classification space and of five types of reference architectures that are formed by combining specific values from the multi-dimensional classification space. Reference architectures that can be classified in one of these types have better chances to become a success. The validation of our framework confirms its quality as a tool for the analysis of the congruence of software reference architectures. Conclusion: This paper facilitates software architects and scientists in the inception, design, and application of congruent software reference architectures. The application of the tool improves the chance for success of a reference architecture.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {417–431},
numpages = {15},
keywords = {Software reference architecture, Software product line architecture, Software domain architecture, Software architecture design}
}

@inproceedings{10.1145/3106237.3106252,
author = {Kn\"{u}ppel, Alexander and Th\"{u}m, Thomas and Mennicke, Stephan and Meinicke, Jens and Schaefer, Ina},
title = {Is there a mismatch between real-world feature models and product-line research?},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106252},
doi = {10.1145/3106237.3106252},
abstract = {Feature modeling has emerged as the de-facto standard to compactly capture the variability of a software product line. Multiple feature modeling languages have been proposed that evolved over the last decades to manage industrial-size product lines. However, less expressive languages, solely permitting require and exclude constraints, are permanently and carelessly used in product-line research. We address the problem whether those less expressive languages are sufficient for industrial product lines. We developed an algorithm to eliminate complex cross-tree constraints in a feature model, enabling the combination of tools and algorithms working with different feature model dialects in a plug-and-play manner. However, the scope of our algorithm is limited. Our evaluation on large feature models, including the Linux kernel, gives evidence that require and exclude constraints are not sufficient to express real-world feature models. Hence, we promote that research on feature models needs to consider arbitrary propositional formulas as cross-tree constraints prospectively.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {291–302},
numpages = {12},
keywords = {require constraints, model transformation, feature modeling, expressiveness, exclude constraints, cross-tree constraints, Software product lines},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@article{10.1007/s11276-018-1837-6,
author = {Yildirim, Ahmet and Zeydan, Engin and Yigit, Ibrahim Onuralp},
title = {A statistical comparative performance analysis of mobile network operators},
year = {2020},
issue_date = {Feb 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1022-0038},
url = {https://doi.org/10.1007/s11276-018-1837-6},
doi = {10.1007/s11276-018-1837-6},
abstract = {Mobile telephony is one of the most widely utilized technologies in the modern world. Records of the usage behaviour of mobile users can provide valuable information for understanding the behaviour of networks for Mobile Network Operators (MNOs). For different reasons, MNOs are interested in knowing how their competitors’ performance varies based on location, phone category, phone Operating System (OS) for various cellular network technology (CNT). This can help MNOs to invest intelligently in locations where they operate with inferior performance. Therefore, Key Performance Indicator (KPI) comparisons among MNOs are of interest for all MNOs. In this article, we investigate cellular network performance statistical comparisons of major Mobile Network Operators (MNOs) in Turkey using a large scale real-world proprietary mobile traffic dataset over a period of 18 months. Focusing our approach on different dimensions of crowd-sourced dataset allows us: (i) to know end-to-end nationwide network performance comparisons of MNOs using real-world measurement data, (ii) to calculate Confidence Intervals (CIs) for the mean difference of KPIs (such as downlink speed, latency, jitter and packet loss) for obtaining useful comparative statistical information of MNO performances and (iii) to observe the existence of significant performance differences between MNOs depending on the region which they are operating, phone category, phone OS as well as CNTs.},
journal = {Wirel. Netw.},
month = feb,
pages = {1105–1124},
numpages = {20},
keywords = {Cellular, KPIs, Comparisons, Performance, MNOs, Data analytics}
}

@inproceedings{10.1145/3180155.3180257,
author = {Xue, Yinxing and Li, Yan-Fu},
title = {Multi-objective integer programming approaches for solving optimal feature selection problem: a new perspective on multi-objective optimization problems in SBSE},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180257},
doi = {10.1145/3180155.3180257},
abstract = {The optimal feature selection problem in software product line is typically addressed by the approaches based on Indicator-based Evolutionary Algorithm (IBEA). In this study we first expose the mathematical nature of this problem --- multi-objective binary integer linear programming. Then, we implement/propose three mathematical programming approaches to solve this problem at different scales. For small-scale problems (roughly less than 100 features), we implement two established approaches to find all exact solutions. For medium-to-large problems (roughly, more than 100 features), we propose one efficient approach that can generate a representation of the entire Pareto front in linear time complexity. The empirical results show that our proposed method can find significantly more non-dominated solutions in similar or less execution time, in comparison with IBEA and its recent enhancement (i.e., IBED that combines IBEA and Differential Evolution).},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1231–1242},
numpages = {12},
keywords = {multi-objective integer programming (MOIP), multi-objective optimization (MOO), optimal feature selection problem},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.5555/2818754.2818819,
author = {Henard, Christopher and Papadakis, Mike and Harman, Mark and Le Traon, Yves},
title = {Combining multi-objective search and constraint solving for configuring large software product lines},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Software Product Line (SPL) feature selection involves the optimization of multiple objectives in a large and highly constrained search space. We introduce SATIBEA, that augments multi-objective search-based optimization with constraint solving to address this problem, evaluating it on five large real-world SPLs, ranging from 1,244 to 6,888 features with respect to three different solution quality indicators and two diversity metrics. The results indicate that SATIBEA statistically significantly outperforms the current state-of-the-art (p &lt; 0.01) for all five SPLs on all three quality indicators and with maximal effect size (\^{A}12 = 1.0). We also present results that demonstrate the importance of combining constraint solving with search-based optimization and the significant improvement SATIBEA produces over pure constraint solving. Finally, we demonstrate the scalability of SATIBEA: within less than half an hour, it finds thousands of constraint-satisfying optimized software products, even for the largest SPL considered in the literature to date.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {517–528},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/1159733.1159762,
author = {Denger, Christian and Kolb, Ronny},
title = {Testing and inspecting reusable product line components: first empirical results},
year = {2006},
isbn = {1595932186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1159733.1159762},
doi = {10.1145/1159733.1159762},
abstract = {In recent years, product line development has increasingly received attention in industry as it enables software-developing organizations to reduce both cost and time of developing and maintaining increasingly complex systems as well as to address the demands for individually customized products. Successful product line development requires high quality of reusable artifacts in order to achieve the promised benefits. The unique issues of quality assurance in the context of systematic reuse, however, have not been quantitatively investigated so far. This paper describes a first empirical study comparing the two defect detection techniques, code inspections and functional testing, in the context of product line development. The primary goal of the study was to initially investigate the defect finding potential of the techniques on reusable software components with common and variant features. The major findings of the study are that the two techniques identified different types of defects on variants of a reusable component. Inspections are on average 66.39% more effective and need on average 36.84% less effort to detect a defect We found that both the testing and inspection techniques applied in the experiment were ineffective in identifying variant-specific defects. Overall, the results indicate that the standard quality assurance techniques seem to be insufficient to address special characteristics of reusable components.},
booktitle = {Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering},
pages = {184–193},
numpages = {10},
keywords = {software product line, reusable components, quality assurance, inspection, functional testing, controlled experiment},
location = {Rio de Janeiro, Brazil},
series = {ISESE '06}
}

@inproceedings{10.1007/978-3-662-45234-9_10,
author = {Bure\v{s}, Tom\'{a}\v{s} and Hork\'{y}, Vojtundefinedch and Kit, Micha\l{} and Marek, Luk\'{a}\v{s} and T\r{u}ma, Petr},
title = {Towards Performance-Aware Engineering of Autonomic Component Ensembles},
year = {2014},
isbn = {9783662452332},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-45234-9_10},
doi = {10.1007/978-3-662-45234-9_10},
abstract = {Ensembles of autonomic components are a novel software engineering paradigm for development of open-ended distributed highly dynamic software systems e.g. smart cyber-physical systems. Recent research centered around the concept of ensemble-based systems resulted in design and development models that aim to systematize and simplify the engineering process of autonomic components and their ensembles. These methods highlight the importance of covering both the functional concepts and the non-functional properties, specifically performance-related aspects of the future systems. In this paper we propose an integration of the emerging techniques for performance assessment and awareness into different stages of the development process. Our goal is to aid both designers and developers of autonomic component ensembles with methods providing performance awareness throughout the entire development life cycle including runtime.},
booktitle = {Part I of the Proceedings of the 6th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change - Volume 8802},
pages = {131–146},
numpages = {16},
keywords = {performance engineering, ensemble-based systems, component systems}
}

@inproceedings{10.1145/1385486.1385488,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Schirmeier, Horst and Sincero, Julio and Apel, Sven and Leich, Thomas and Spinczyk, Olaf and Saake, Gunter},
title = {FAME-DBMS: tailor-made data management solutions for embedded systems},
year = {2008},
isbn = {9781595939647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385486.1385488},
doi = {10.1145/1385486.1385488},
abstract = {Data management functionality is not only needed in large-scale server systems, but also in embedded systems. Resource restrictions and heterogeneity of hardware, however, complicate the development of data management solutions for those systems. In current practice, this typically leads to the redevelopment of data management because existing solutions cannot be reused and adapted appropriately. In this paper, we present our ongoing work on FAME-DBMS, a research project that explores techniques to implement highly customizable data management solutions, and illustrate how such systems can be created with a software product line approach. With this approach a concrete instance of a DBMS is derived by composing features of the DBMS product line that are needed for a specific application scenario. This product derivation process is getting complex if a large number of features is available. Furthermore, in embedded systems also non-functional properties, e.g., memory consumption, have to be considered when creating a DBMS instance. To simplify the derivation process we present approaches for its automation.},
booktitle = {Proceedings of the 2008 EDBT Workshop on Software Engineering for Tailor-Made Data Management},
pages = {1–6},
numpages = {6},
location = {Nantes, France},
series = {SETMDM '08}
}

@inproceedings{10.1007/978-3-642-04211-9_19,
author = {Rossel, Pedro O. and Perovich, Daniel and Bastarrica, Mar\'{\i}a Cecilia},
title = {Reuse of Architectural Knowledge in SPL Development},
year = {2009},
isbn = {9783642042102},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-04211-9_19},
doi = {10.1007/978-3-642-04211-9_19},
abstract = {Software Product Lines (SPL) promote reuse within an application domain in an organized fashion. Preimplemented software components are arranged according to a product line architecture (PLA). Balancing possibly conflicting quality attributes of all potential products makes PLA design a challenging task. Moreover, if quality attributes are part of the variabilities of the SPL, then a unique PLA may result highly inconvenient for particular configurations. We consider the PLA as a set of architectural decisions organized by the features in the Feature Model. A particular product architecture (PA) is defined as the subset of decisions associated to the chosen features for the product. Architectural knowledge is then reused among products and when new features are required in the SPL. Variability at the quality attribute level will impact the style of the resulting architecture, thus choosing different quality features will produce PAs following different styles, even within the same SPL. We use MDE techniques to operationalize this procedure and we illustrate the technique using the case of a Meshing Tool SPL.},
booktitle = {Proceedings of the 11th International Conference on Software Reuse: Formal Foundations of Reuse and Domain Engineering},
pages = {191–200},
numpages = {10},
location = {Falls Church, Virginia},
series = {ICSR '09}
}

@inproceedings{10.1007/11608035_9,
author = {Rombach, Dieter},
title = {Integrated software process and product lines},
year = {2005},
isbn = {3540311122},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11608035_9},
doi = {10.1007/11608035_9},
abstract = {Increasing demands imposed on software-intensive systems will require more rigorous engineering and management of software artifacts and processes. Software product line engineering allows for the effective reuse of software artifacts based on the pro-active organization of similar artifacts according to similarities and variances. Software processes – although also variable across projects – are still not managed in a similar systematic way. This paper motivates the need for Software Process Lines similar to Product Lines. As a result of such organization, processes within an organization could be organized according to similarities and differences, allowing for better tailoring to specific project needs (corresponds to application engineering in product lines). The vision of SPPL (integrated product and process line) engineering is presented, where suitable artifacts and processes can be chosen based on a set of product &amp; process requirements and project constraints. The paper concludes with some resulting challenges for research, practice, and teaching.},
booktitle = {Proceedings of the 2005 International Conference on Unifying the Software Process Spectrum},
pages = {83–90},
numpages = {8},
keywords = {software product lines, software process lines (SPL), reuse of artifacts &amp; processes, integrated software process &amp; product lines (SPPL), experience factory, commonalities and variabilities},
location = {Beijing, China},
series = {SPW'05}
}

@article{10.1145/3428225,
author = {Shahin, Ramy and Chechik, Marsha},
title = {Automatic and efficient variability-aware lifting of functional programs},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428225},
doi = {10.1145/3428225},
abstract = {A software analysis is a computer program that takes some representation of a software product as input and produces some useful information about that product as output. A software product line encompasses many software product variants, and thus existing analyses can be applied to each of the product variations individually, but not to the entire product line as a whole. Enumerating all product variants and analyzing them one by one is usually intractable due to the combinatorial explosion of the number of product variants with respect to product line features. Several software analyses (e.g., type checkers, model checkers, data flow analyses) have been redesigned/re-implemented to support variability. This usually requires a lot of time and effort, and the variability-aware version of the analysis might have new errors/bugs that do not exist in the original one. Given an analysis program written in a functional language based on PCF, in this paper we present two approaches to transforming (lifting) it into a semantically equivalent variability-aware analysis. A light-weight approach (referred to as shallow lifting) wraps the analysis program into a variability-aware version, exploring all combinations of its input arguments. Deep lifting, on the other hand, is a program rewriting mechanism where the syntactic constructs of the input program are rewritten into their variability-aware counterparts. Compositionally this results in an efficient program semantically equivalent to the input program, modulo variability. We present the correctness criteria for functional program lifting, together with correctness proof sketches of shallow lifting. We evaluate our approach on a set of program analyses applied to the BusyBox C-language product line.},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {157},
numpages = {27},
keywords = {Variability-aware Programming, Software Product Lines, Program Rewriting, PCF, Lifting}
}

@inproceedings{10.1109/AST.2017.7,
author = {Al-Hajjaji, Mustafa and Kr\"{u}ger, Jacob and Schulze, Sandro and Leich, Thomas and Saake, Gunter},
title = {Efficient product-line testing using cluster-based product prioritization},
year = {2017},
isbn = {9781538615485},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2017.7},
doi = {10.1109/AST.2017.7},
abstract = {A software product-line comprises a set of products that share a common set of features. These features can be reused to customize a product to satisfy specific needs of certain customers or markets. As the number of possible products increases exponentially for new features, testing all products is infeasible. Existing testing approaches reduce their effort by restricting the number of products (sampling) and improve their effectiveness by considering the order of tests (prioritization). In this paper, we propose a cluster-based prioritization technique to sample similar products with respect to the feature selection. We evaluate our approach using feature models of different sizes and show that cluster-based prioritization can enhance the effectiveness of product-line testing.},
booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
pages = {16–22},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {AST '17}
}

@article{10.1007/s00766-015-0243-1,
author = {Pacheco, C. and Garcia, I. and Calvo-Manzano, J. A. and Arcilla, M.},
title = {Reusing functional software requirements in small-sized software enterprises: a model oriented to the catalog of requirements},
year = {2017},
issue_date = {June      2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-015-0243-1},
doi = {10.1007/s00766-015-0243-1},
abstract = {Software reuse can be defined as the process of creating software products from the existing ones rather than developing software from scratch. Thus, software reuse is normally proposed to increase software productivity and quality and leads to economic benefits. In this sense, the reuse of software requirements has received important attention because it provides a solid support to develop quality software through obtaining and reusing quality software requirements [i.e., software product line (SPL) approach used in large-sized software enterprises]. However, the small-sized enterprises--which represent up to 85 % of all software organizations in many countries around the world--cannot implement a SPL approach because it does not fit with the context, properties, and complexity of their software projects. Moreover, the software engineering community has not adequately explored a more proper approach in the context of small-sized software enterprises. The use of a software requirements catalog could be this proper approach. In this context, the aim of this paper was to introduce the requirements reuse model for software requirements catalog (RRMSRC). Also, a set of guidelines to perform the main activities defined for reusing functional requirements within small-sized software enterprises is provided. As evidence of its feasibility, RRMSRC has been used in an industrial context, and the obtained results and learned lessons are summarized.},
journal = {Requir. Eng.},
month = jun,
pages = {275–287},
numpages = {13},
keywords = {Small-sized software enterprises, Requirements reuse process, Requirements engineering, Functional requirements catalog}
}

@article{10.1016/j.infsof.2006.05.003,
author = {Olumofin, Femi G. and Mi\v{s}i\'{c}, Vojislav B.},
title = {A holistic architecture assessment method for software product lines},
year = {2007},
issue_date = {April, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {4},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.05.003},
doi = {10.1016/j.infsof.2006.05.003},
abstract = {The success of architecture-centric development of software product lines is critically dependent upon the availability of suitable architecture assessment methods. While a number of architecture assessment methods are available and some of them have been widely used in the process of evaluating single product architectures, none of them is equipped to deal with the main challenges of product line development. In this paper we present an adaptation of the Architecture Tradeoff Analysis Method (ATAM) for the task of assessing product line architectures. The new method, labeled Holistic Product Line Architecture Assessment (HoPLAA), uses a holistic approach that focuses on risks and quality attribute tradeoffs - not only for the common product line architecture, but for the individual product architectures as well. In addition, it prescribes a qualitative analytical treatment of variation points using scenarios. The use of the new method is illustrated through a case study.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {309–323},
numpages = {15},
keywords = {Software product line architectures, Software architecture assessment, Architecture Tradeoff Analysis Method (ATAM)}
}

@article{10.1007/s11219-005-4250-1,
author = {Kazman, Rick and Bass, Len and Klein, Mark and Lattanze, Tony and Northrop, Linda},
title = {A Basis for Analyzing Software Architecture Analysis Methods},
year = {2005},
issue_date = {December  2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-005-4250-1},
doi = {10.1007/s11219-005-4250-1},
abstract = {A software architecture is a key asset for any organization that builds complex software-intensive systems. Because of an architecture's central role as a project blueprint, organizations should analyze the architecture before committing resources to it. An analysis helps to ensure that sound architectural decisions are made. Over the past decade a large number of architecture analysis methods have been created, and at least two surveys of these methods have been published. This paper examines the criteria for analyzing architecture analysis methods, and suggests a new set of criteria that focus on the essence of what it means to be an architecture analysis method. These criteria could be used to compare methods, to help understand the suitability of a method, or to improve a method. We then examine two methods--the Architecture Tradeoff Analysis Method and Architecture-level Modifiability Analysis--in light of these criteria, and provide some insight into how these methods can be improved.},
journal = {Software Quality Journal},
month = dec,
pages = {329–355},
numpages = {27},
keywords = {software architecture, quality attributes, architecture analysis, analysis methods}
}

@article{10.1016/j.infsof.2021.106620,
author = {Tran, Huynh Khanh Vi and Unterkalmsteiner, Michael and B\"{o}rstler, J\"{u}rgen and Ali, Nauman bin},
title = {Assessing test artifact quality—A tertiary study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106620},
doi = {10.1016/j.infsof.2021.106620},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {22},
keywords = {Quality assurance, Test artifact quality, Test suite quality, Test case quality, Software testing}
}

@article{10.1016/j.cl.2018.05.004,
author = {Combemale, Benoit and Kienzle, J\"{o}rg and Mussbacher, Gunter and Barais, Olivier and Bousse, Erwan and Cazzola, Walter and Collet, Philippe and Degueule, Thomas and Heinrich, Robert and J\'{e}z\'{e}quel, Jean-Marc and Leduc, Manuel and Mayerhofer, Tanja and Mosser, S\'{e}bastien and Sch\"{o}ttle, Matthias and Strittmatter, Misha and Wortmann, Andreas},
title = {Concern-oriented language development (COLD): Fostering reuse in language engineering},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {54},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2018.05.004},
doi = {10.1016/j.cl.2018.05.004},
journal = {Comput. Lang. Syst. Struct.},
month = dec,
pages = {139–155},
numpages = {17},
keywords = {Language reuse, Language concern, Domain-specific languages}
}

@inproceedings{10.1109/ICSE-C.2017.154,
author = {Pereira, Juliana Alves},
title = {Runtime collaborative-based configuration of software product lines},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.154},
doi = {10.1109/ICSE-C.2017.154},
abstract = {Software Product Line (SPL) configuration practices have been employed by industries as a mass customization process. However, the inherent variability of large SPLs leads to configuration spaces of exponential sizes. Thus, scalability and performance concerns start to be an issue when facing runtime environments, since it is usually infeasible to explore the entire configuration space exhaustively. In this context, the aim of my research is therefore to propose an efficient collaborative-based runtime approach that relies on recommender techniques to provide accurate and scalable configurations to users. To demonstrate the efficiency of the proposed approach, I conduct series of experiments on real-world SPLs. In addition, I plan empirically verify through a user case study the usability of the proposed approach. My expected contribution is to support the adoption of SPL configuration practices in industrial scenarios.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {94–96},
numpages = {3},
keywords = {software product lines, recommender systems, configuration, collaborative-based recommendations},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@article{10.1007/s10270-016-0569-2,
author = {Al-Hajjaji, Mustafa and Th\"{u}m, Thomas and Lochau, Malte and Meinicke, Jens and Saake, Gunter},
title = {Effective product-line testing using similarity-based product prioritization},
year = {2019},
issue_date = {February  2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-016-0569-2},
doi = {10.1007/s10270-016-0569-2},
abstract = {A software product line comprises a family of software products that share a common set of features. Testing an entire product-line product-by-product is infeasible due to the potentially exponential number of products in the number of features. Accordingly, several sampling approaches have been proposed to select a presumably minimal, yet sufficient number of products to be tested. Since the time budget for testing is limited or even a priori unknown, the order in which products are tested is crucial for effective product-line testing. Prioritizing products is required to increase the probability of detecting faults faster. In this article, we propose similarity-based prioritization, which can be efficiently applied on product samples. In our approach, we incrementally select the most diverse product in terms of features to be tested next in order to increase feature interaction coverage as fast as possible during product-by-product testing. We evaluate the gain in the effectiveness of similarity-based prioritization on three product lines with real faults. Furthermore, we compare similarity-based prioritization to random orders, an interaction-based approach, and the default orders produced by existing sampling algorithms considering feature models of various sizes. The results show that our approach potentially increases effectiveness in terms of fault detection ratio concerning faults within real-world product-line implementations as well as synthetically seeded faults. Moreover, we show that the default orders of recent sampling algorithms already show promising results, which, however, can still be improved in many cases using similarity-based prioritization.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {499–521},
numpages = {23},
keywords = {Test-case prioritization, Software product lines, Product-line testing, Model-based testing, Combinatorial interaction testing}
}

@article{10.1007/s11219-014-9258-y,
author = {Galindo, Jos\'{e} A. and Turner, Hamilton and Benavides, David and White, Jules},
title = {Testing variability-intensive systems using automated analysis: an application to Android},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-014-9258-y},
doi = {10.1007/s11219-014-9258-y},
abstract = {Software product lines are used to develop a set of software products that, while being different, share a common set of features. Feature models are used as a compact representation of all the products (e.g., possible configurations) of the product line. The number of products that a feature model encodes may grow exponentially with the number of features. This increases the cost of testing the products within a product line. Some proposals deal with this problem by reducing the testing space using different techniques. However, a daunting challenge is to explore how the cost and value of test cases can be modeled and optimized in order to have lower-cost testing processes. In this paper, we present TESting vAriAbiLity Intensive Systems (TESALIA), an approach that uses automated analysis of feature models to optimize the testing of variability-intensive systems. We model test value and cost as feature attributes, and then we use a constraint satisfaction solver to prune, prioritize and package product line tests complementing prior work in the software product line testing literature. A prototype implementation of TESALIA is used for validation in an Android example showing the benefits of maximizing the mobile market share (the value function) while meeting a budgetary constraint.},
journal = {Software Quality Journal},
month = jun,
pages = {365–405},
numpages = {41},
keywords = {Testing, Software product lines, Feature models, Automated analysis, Android}
}

@inproceedings{10.5555/1722603.1722618,
author = {Moaven, Shahrouz and Habibi, Jafar and Ahmadi, Hamed and Kamandi, Ali},
title = {Towards an architecture-centric approach for method engineering},
year = {2008},
isbn = {9780889867161},
publisher = {ACTA Press},
address = {USA},
abstract = {Due to the extreme use of method engineering and increasing attention to construct methods customized for a specific project, domain, organization or a generic method compatible with the team characteristics and needs, existence of suitable and formalized frameworks and guidelines is one of the challenges method engineers are encountered. In this area, considering method construction as the goal of method engineering brings to the mind the software development process in which the product is a method adapting the method users' needs. This paper, with a new approach of applying software architecture in method engineering and making use of architecture styles, tries to take advantage of software architecture benefits like documentation, reusability, reconstruction and enhancement of development process. Consequently, project teams can handle complexity of large-scale projects. Also by utilizing the existing architecture styles, the collaboration among project members will be enhanced and addressed in a specific framework in order to construct more flexible methods with better quality.},
booktitle = {Proceedings of the IASTED International Conference on Software Engineering},
pages = {74–79},
numpages = {6},
keywords = {software product line, software architecture, situational method engineering, method user, method engineering, architecture style},
location = {Innsbruck, Austria},
series = {SE '08}
}

@inproceedings{10.1109/ICSE.2019.00092,
author = {Lazreg, Sami and Cordy, Maxime and Collet, Philippe and Heymans, Patrick and Mosser, S\'{e}bastien},
title = {Multifaceted automated analyses for variability-intensive embedded systems},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00092},
doi = {10.1109/ICSE.2019.00092},
abstract = {Embedded systems, like those found in the automotive domain, must comply with stringent functional and non-functional requirements. To fulfil these requirements, engineers are confronted with a plethora of design alternatives both at the software and hardware level, out of which they must select the optimal solution wrt. possibly-antagonistic quality attributes (e.g. cost of manufacturing vs. speed of execution). We propose a model-driven framework to assist engineers in this choice. It captures high-level specifications of the system in the form of variable dataflows and configurable hardware platforms. A mapping algorithm then derives the design space, i.e. the set of compatible pairs of application and platform variants, and a variability-aware executable model, which encodes the functional and non-functional behaviour of all viable system variants. Novel verification algorithms then pinpoint the optimal system variants efficiently. The benefits of our approach are evaluated through a real-world case study from the automotive industry.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {854–865},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1007/s10664-014-9336-6,
author = {Sobernig, Stefan and Apel, Sven and Kolesnikov, Sergiy and Siegmund, Norbert},
title = {Quantifying structural attributes of system decompositions in 28 feature-oriented software product lines},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9336-6},
doi = {10.1007/s10664-014-9336-6},
abstract = {A key idea of feature orientation is to decompose a software product line along the features it provides. Feature decomposition is orthogonal to object-oriented decomposition--it crosscuts the underlying package and class structure. It has been argued often that feature decomposition improves system structure by reducing coupling and by increasing cohesion. However, recent empirical findings suggest that this is not necessarily the case. In this exploratory, observational study, we investigate the decompositions of 28 feature-oriented software product lines into classes, features, and feature-specific class fragments. The product lines under investigation are implemented using the feature-oriented programming language Fuji. In particular, we quantify and compare the internal attributes import coupling and cohesion of the different product-line decompositions in a systematic, reproducible manner. For this purpose, we adopt three established software measures (e.g., coupling between units, CBU; internal-ratio unit dependency, IUD) as well as standard concentration statistics (e.g., Gini coefficient). In our study, we found that feature decomposition can be associated with higher levels of structural coupling in a product line than a decomposition into classes. Although coupling can be concentrated in very few features in most feature decompositions, there are not necessarily hot-spot features  in all product lines. Interestingly, feature cohesion is not necessarily higher than class cohesion, whereas features are more equal in serving dependencies internally than classes of a product line. Our empirical study raises critical questions about alleged advantages of feature decomposition. At the same time, we demonstrate how our measurement approach of coupling and cohesion has potential to support static and dynamic analyses of software product lines (i.e., type checking and feature-interaction detection) by facilitating product sampling.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1670–1705},
numpages = {36},
keywords = {Structural coupling, Structural cohesion, Software product lines, Software measurement, Fuji, Feature-oriented programming}
}

@inproceedings{10.1145/3278122.3278126,
author = {Peldszus, Sven and Str\"{u}ber, Daniel and J\"{u}rjens, Jan},
title = {Model-based security analysis of feature-oriented software product lines},
year = {2018},
isbn = {9781450360456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278122.3278126},
doi = {10.1145/3278122.3278126},
abstract = {Today's software systems are too complex to ensure security after the fact – security has to be built into systems by design. To this end, model-based techniques such as UMLsec support the design-time specification and analysis of security requirements by providing custom model annotations and checks. Yet, a particularly challenging type of complexity arises from the variability of software product lines. Analyzing the security of all products separately is generally infeasible. In this work, we propose SecPL, a methodology for ensuring security in a software product line. SecPL allows developers to annotate the system design model with product-line variability and security requirements. To keep the exponentially large configuration space tractable during security checks, SecPL provides a family-based security analysis. In our experiments, this analysis outperforms the naive strategy of checking all products individually. Finally, we present the results of a user study that indicates the usability of our overall methodology.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {93–106},
numpages = {14},
keywords = {UML, Software Product Lines, Security, OCL},
location = {Boston, MA, USA},
series = {GPCE 2018}
}

@inproceedings{10.1145/2739482.2764681,
author = {Martinez, Jabier and Rossi, Gabriele and Ziadi, Tewfik and Bissyand\'{e}, Tegawend\'{e} Fran\c{c}ois D. Assise and Klein, Jacques and Le Traon, Yves},
title = {Estimating and Predicting Average Likability on Computer-Generated Artwork Variants},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2764681},
doi = {10.1145/2739482.2764681},
abstract = {Computer assisted human creativity encodes human design decisions in algorithms allowing machines to produce artwork variants. Based on this automated production, one can leverage collective understanding of beauty to rank computer-generated artworks according to their average likability. We present the use of Software Product Line techniques for computer-generated art systems as a case study on leveraging the feedback of human perception within the boundaries of a variability model. Since it is not feasible to get feedback for all variants because of a combinatorial explosion of possible configurations, we propose an approach that is developed in two phases: 1) the creation of a data set using an interactive genetic algorithm and 2) the application of a data mining technique on this dataset to create a ranking enriched with confidence metrics.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1431–1432},
numpages = {2},
keywords = {software product lines, media arts, gentic algorithms},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.5555/648114.748906,
author = {Bosch, Jan and Florijn, Gert and Greefhorst, Danny and Kuusela, Juha and Obbink, J. Henk and Pohl, Klaus},
title = {Variability Issues in Software Product Lines},
year = {2001},
isbn = {3540436596},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines (or system families) have achieved considerable adoption by the software industry. A software product line captures the commonalities between a set of products while providing for the differences. Differences are managed by delaying design decisions, thereby introducing variation points. The whole of variation points is typically referred to as the variability of the software product line. Variability management is, however, not a trivial activity and several issues exist, both in general as well as specific to individual phases in the lifecycle. This paper identifies and describes several variability issues based on practical experiences and theoretical understanding of the problem domain.},
booktitle = {Revised Papers from the 4th International Workshop on Software Product-Family Engineering},
pages = {13–21},
numpages = {9},
series = {PFE '01}
}

@inproceedings{10.1145/2884781.2884821,
author = {Devroey, Xavier and Perrouin, Gilles and Papadakis, Mike and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Featured model-based mutation analysis},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884821},
doi = {10.1145/2884781.2884821},
abstract = {Model-based mutation analysis is a powerful but expensive testing technique. We tackle its high computation cost by proposing an optimization technique that drastically speeds up the mutant execution process. Central to this approach is the Featured Mutant Model, a modelling framework for mutation analysis inspired by the software product line paradigm. It uses behavioural variability models, viz., Featured Transition Systems, which enable the optimized generation, configuration and execution of mutants. We provide results, based on models with thousands of transitions, suggesting that our technique is fast and scalable. We found that it outperforms previous approaches by several orders of magnitude and that it makes higher-order mutation practically applicable.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {655–666},
numpages = {12},
keywords = {variability, mutation analysis, featured transition systems},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1007/s11219-018-9424-8,
author = {Alkharabsheh, Khalid and Crespo, Yania and Manso, Esperanza and Taboada, Jos\'{e} A.},
title = {Software Design Smell Detection: a systematic mapping study},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9424-8},
doi = {10.1007/s11219-018-9424-8},
abstract = {Design Smells are indicators of situations that negatively affect software quality attributes such as understandability, testability, extensibility, reusability, and maintainability in general. Improving maintainability is one of the cornerstones of making software evolution easier. Hence, Design Smell Detection is important in helping developers when making decisions that can improve software evolution processes. After a long period of research, it is important to organize the knowledge produced so far and to identify current challenges and future trends. In this paper, we analyze 18&nbsp;years of research into Design Smell Detection. There is a wide variety of terms that have been used in the literature to describe concepts which are similar to what we have defined as “Design Smells,” such as design defect, design flaw, anomaly, pitfall, antipattern, and disharmony. The aim of this paper is to analyze all these terms and include them in the study. We have used the standard systematic literature review method based on a comprehensive set of 395 articles published in different proceedings, journals, and book chapters. We present the results in different dimensions of Design Smell Detection, such as the type or scope of smell, detection approaches, tools, applied techniques, validation evidence, type of artifact in which the smell is detected, resources used in evaluation, supported languages, and relation between detected smells and software quality attributes according to a quality model. The main contributions of this paper are, on the one hand, the application of domain modeling techniques to obtain a conceptual model that allows the organization of the knowledge on Design Smell Detection and a collaborative web application built on that knowledge and, on the other, finding how tendencies have moved across different kinds of smell detection, as well as different approaches and techniques. Key findings for future trends include the fact that all automatic detection tools described in the literature identify Design Smells as a binary decision (having the smell or not), which is an opportunity to evolve to fuzzy and prioritized decisions. We also find that there is a lack of human experts and benchmark validation processes, as well as demonstrating that Design Smell Detection positively influences quality attributes.},
journal = {Software Quality Journal},
month = sep,
pages = {1069–1148},
numpages = {80},
keywords = {Systematic mapping study, Quality models, Detection tools, Antipatterns, DesignSmell}
}

@article{10.1007/s10825-021-01681-z,
author = {Echouchene, Fraj and Jemii, Elassaad},
title = {Analysis of the transient Joule heating effect in a conductive-bridge random-access memory (CBRAM) using a single-phase-lag (SPL) model},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {1569-8025},
url = {https://doi.org/10.1007/s10825-021-01681-z},
doi = {10.1007/s10825-021-01681-z},
abstract = {The main objective of this work is to study the transient Joule heating effect in a conductive-bridge random-access memory (CBRAM) using the single-phase-lag heat conduction model to describe the effects of the metallic conductive filament (CF) radius and the reset voltage on the thermal and electric field. The results reveal that the CF geometry plays an important role in the transient Joule heating. The heat wave of fast transient conduction is stronger in the narrow region of the CF during the reset process for a high applied voltage and a small top radius of the CF. It is demonstrated that the presented model can predict the nanoscale heat transfer in the transient state and during the reset process in the CBRAM. Finally, numerical computations are carried out using the finite-element method to solve the nonlinear heat conduction equations.},
journal = {J. Comput. Electron.},
month = jun,
pages = {1422–1429},
numpages = {8},
keywords = {Single-phase-lag (SPL) model, Nanoscale, Heat transfer, Conductive-bridge random-access memory}
}

@inproceedings{10.5555/2492708.2492954,
author = {Benini, Luca and Flamand, Eric and Fuin, Didier and Melpignano, Diego},
title = {P2012: building an ecosystem for a scalable, modular and high-efficiency embedded computing accelerator},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {P2012 is an area- and power-efficient many-core computing fabric based on multiple globally asynchronous, locally synchronous (GALS) clusters supporting aggressive fine-grained power, reliability and variability management. Clusters feature up to 16 processors and one control processor with independent instruction streams sharing a multi-banked L1 data memory, a multi-channel DMA engine, and specialized hardware for synchronization and scheduling. P2012 achieves extreme area and energy efficiency by supporting domain-specific acceleration at the processor and cluster level through the addition of dedicated HW IPs. P2012 can run standard OpenCL and OpenMP parallel codes well as proprietary Native Programming Model (NPM) SW components that provide the highest level of control on application-to-resource mapping. In Q3 2011 the P2012 SW Development Kit (SDK) has been made available to a community of R&amp;D users; it includes full OpenCL and NPM development environments. The first P2012 SoC prototype in 28nm CMOS will sample in Q4 2012, featuring four clusters and delivering 80GOPS (with single precision floating point support) in 15.2mm2 with 2W power consumption.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {983–987},
numpages = {5},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.1145/2915970.2915985,
author = {Wnuk, Krzysztof and Kollu, Ravichandra Kumar},
title = {A systematic mapping study on requirements scoping},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2915985},
doi = {10.1145/2915970.2915985},
abstract = {Context: Requirements scoping is one of the key activities in requirements management but also a major risk for project management. Continuously changing scope may create a congestion state in handling the requirements inflow which causes negative consequences, e.g. delays or scope creep. Objectives: In this paper, we look at requirements scoping literature outside Software Product Line (SPL) by exploring the current literature on the phenomenon, summarizing publication trends, performing thematic analysis and analyzing the strength of the evidence in the light of rigor and relevance assessment. Method: We run a Systematic Mapping Study (SMS) using snowballing procedure, supported by a database search for the start set identification, and identified 21 primary studies and 2 secondary studies. Results: The research interest in this area steadily increases and includes mainly case studies, validation or evaluation studies. The results were categorized into four themes: definitions, negative effects associated with scoping, challenges and identified methods/tools. The identified scope management techniques are also matched against the identified requirements scoping challenges.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {32},
numpages = {11},
keywords = {systematic mapping study, snowballing, requirements scoping},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1007/978-3-319-33693-0_4,
author = {Damiani, Ferruccio and Lienhardt, Michael},
title = {On Type Checking Delta-Oriented Product Lines},
year = {2016},
isbn = {9783319336923},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-33693-0_4},
doi = {10.1007/978-3-319-33693-0_4},
abstract = {A Software Product Line SPL is a set of similar programs generated from a common code base. Delta Oriented Programming DOP is a flexible approach to implement SPLs. Efficiently type checking an SPL i.e., checking that all its programs are well-typed is challenging. This paper proposes a novel type checking approach for DOP. Intrinsic complexity of SPL type checking is addressed by providing early detection of type errors and by reducing type checking to satisfiability of a propositional formula. The approach is tunable to exploit automatically checkable DOP guidelines for making an SPL more comprehensible and type checking more efficient. The approach and guidelines are formalized by means of a core calculus for DOP of product lines of Java programs.},
booktitle = {Proceedings of the 12th International Conference on Integrated Formal Methods - Volume 9681},
pages = {47–62},
numpages = {16},
location = {Reykjavik, Iceland},
series = {IFM 2016}
}

@article{10.4018/JITR.2018010104,
author = {Vegendla, Aparna and Duc, Anh Nguyen and Gao, Shang and Sindre, Guttorm},
title = {A Systematic Mapping Study on Requirements Engineering in Software Ecosystems},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {11},
number = {1},
issn = {1938-7857},
url = {https://doi.org/10.4018/JITR.2018010104},
doi = {10.4018/JITR.2018010104},
abstract = {Software ecosystems SECOs and open innovation processes have been claimed as a way forward for the software industry. A proper understanding of requirements is as important for SECOs as for more traditional ones. This article presents a mapping study on the issues of RE and quality aspects in SECOs. Our findings indicate that among the various phases or subtasks of RE, most of the SECO specific research has been accomplished on elicitation, analysis, and modeling. On the other hand, requirement selection, prioritization, verification, and traceability has attracted few published studies. Among the various quality attributes, most of the SECOs research has been performed on security, performance and testability. On the other hand, reliability, safety, maintainability, transparency, usability attracted few published studies. The article provides a review of the academic literature about SECO-related RE activities, modeling approaches, and quality attributes, positions the source publications in a taxonomy of issues and identifies gaps where there has been little research.},
journal = {J. Inf. Technol. Res.},
month = jan,
pages = {49–69},
numpages = {21},
keywords = {Software Ecosystem, Requirements Engineering, Mapping Study}
}

@inproceedings{10.5555/3432601.3432616,
author = {Podolskiy, Vladimir and Patrou, Maria and Patros, Panos and Gerndt, Michael and Kent, Kenneth B.},
title = {The weakest link: revealing and modeling the architectural patterns of microservice applications},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud microservice applications comprise interconnected services packed into containers. Such applications generate complex communication patterns among their microservices. Studying such patterns can support assuring various quality attributes, such as autoscaling for satisfying performance, availability and scalability, or targeted penetration testing for satisfying security and correctness. We study the structure of containerized microservice applications via providing the methodology and the results of a structural graph-based analysis of 103 Docker Compose deployment files from open-sourced Github repositories. Our findings indicate the dominance of a power-law distribution of microservice interconnections. Further analysis highlights the suitability of the Barab\'{a}si-Albert model for generating large random graphs that model the architecture of real microservice applications. The exhibited structures and their usage for engineering microservice applications are discussed.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {113–122},
numpages = {10},
keywords = {software vulnerability, microservice, cloud-native application, application topology},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.1145/1449913.1449918,
author = {Mendonca, Marcilio and Wasowski, Andrzej and Czarnecki, Krzysztof and Cowan, Donald},
title = {Efficient compilation techniques for large scale feature models},
year = {2008},
isbn = {9781605582672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1449913.1449918},
doi = {10.1145/1449913.1449918},
abstract = {Feature modeling is used in generative programming and software product-line engineering to capture the common and variable properties of programs within an application domain. The translation of feature models to propositional logics enabled the use of reasoning systems, such as BDD engines, for the analysis and transformation of such models and interactive configurations. Unfortunately, the size of a BDD structure is highly sensitive to the variable ordering used in its construction and an inappropriately chosen ordering may prevent the translation of a feature model into a BDD representation of a tractable size. Finding an optimal order is NP-hard and has for long been addressed by using heuristics.We review existing general heuristics and heuristics from the hardware circuits domain and experimentally show that they are not effective in reducing the size of BDDs produced from feature models. Based on that analysis we introduce two new heuristics for compiling feature models to BDDs. We demonstrate the effectiveness of these heuristics using publicly available and automatically generated models. Our results are directly applicable in construction of feature modeling tools.},
booktitle = {Proceedings of the 7th International Conference on Generative Programming and Component Engineering},
pages = {13–22},
numpages = {10},
keywords = {software-product lines, model-driven development, formal verification, feature modeling, configuration},
location = {Nashville, TN, USA},
series = {GPCE '08}
}

@inproceedings{10.1145/2304736.2304757,
author = {Pascual, Gustavo Garc\'{\i}a and Alarc\'{o}n, M\'{o}nica Pinto and Fern\'{a}ndez, Lidia Fuentes},
title = {Component and aspect-based service product line for pervasive systems},
year = {2012},
isbn = {9781450313452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304736.2304757},
doi = {10.1145/2304736.2304757},
abstract = {Pervasive systems have experienced an increase in demand due to the evolution and popularity of mobile devices and embedded systems. The development of applications for these systems imposes new challenges due to the necessity of adapting these applications both to the changes in the environment and to the resource-constrained devices (e.g. limited battery, memory and CPU) in which they run. These challenges are: (1) the same services are required by most applications for pervasive systems, and thus should be modeled as separate, ready-to-use (re)usable solutions; (2) services need to be customized to the requirements of applications, by generating different versions of the same service containing only the required functionality, and (3) the same service needs to be customized to the different devices in which a same application will run (e.g. with different operating systems, different memory and CPU capacities or different communication technologies). In order to consider all of the above challenges, in this paper we present a software product line approach that permits modelling the variability of these services using feature models, automatically generating different configurations of their software architecture depending on the particular requirements of each application. We use this approach to model typical services of pervasive systems, such as context-awareness and communication, and to evaluate the degree of variability, of reuse and of separation of concerns of these services.},
booktitle = {Proceedings of the 15th ACM SIGSOFT Symposium on Component Based Software Engineering},
pages = {115–124},
numpages = {10},
keywords = {spl, pervasive systems, context-awareness, cbse, aosd},
location = {Bertinoro, Italy},
series = {CBSE '12}
}

@article{10.1016/j.jss.2005.02.028,
author = {Feng, Qian and Lutz, Robyn R.},
title = {Bi-directional safety analysis of product lines},
year = {2005},
issue_date = {November 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {78},
number = {2},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2005.02.028},
doi = {10.1016/j.jss.2005.02.028},
abstract = {As product-line engineering becomes more widespread, more safety-critical software product lines are being built. This paper describes a structured method for performing safety analysis on a software product line, building on standard product-line assets: product-line requirements, architecture, and scenarios. The safety-analysis method is bi-directional in that it combines a forward analysis (from failure modes to effects) with a backward analysis (from hazards to contributing causes). Safety-analysis results are converted to XML files to allow automated consistency checking between the forward and backward analysis results and to support reuse of the safety-analysis results throughout the product line. The paper demonstrates and evaluates the method on a safety-critical product-line subsystem, the Door Control System. Results show that the bi-directional safety-analysis method found both missing and incorrect software safety requirements. Some of the new safety requirements affected all the systems in the product line while others affected only some of the systems in the product line. The results demonstrate that the proposed method can handle the challenges to safety analysis posed by variations within a product line.},
journal = {J. Syst. Softw.},
month = nov,
pages = {111–127},
numpages = {17},
keywords = {XML, Software safety, Software architecture, Reuse, Product lines}
}

@inproceedings{10.1145/2568225.2568267,
author = {Salay, Rick and Famelis, Michalis and Rubin, Julia and Di Sandro, Alessio and Chechik, Marsha},
title = {Lifting model transformations to product lines},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568267},
doi = {10.1145/2568225.2568267},
abstract = {Software product lines and model transformations are two techniques used in industry for managing the development of highly complex software. Product line approaches simplify the handling of software variants while model transformations automate software manipulations such as refactoring, optimization, code generation, etc. While these techniques are well understood independently, combining them to get the benefit of both poses a challenge because most model transformations apply to individual models while model-level product lines represent sets of models. In this paper, we address this challenge by providing an approach for automatically ``lifting'' model transformations so that they can be applied to product lines. We illustrate our approach using a case study and evaluate it through a set of experiments.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {117–128},
numpages = {12},
keywords = {Software Product Lines, Model Transformations, Model Driven Engineering},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@article{10.1016/j.datak.2006.06.009,
author = {Kim, Minseong and Park, Sooyong and Sugumaran, Vijayan and Yang, Hwasil},
title = {Managing requirements conflicts in software product lines: A goal and scenario based approach},
year = {2007},
issue_date = {June, 2007},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {61},
number = {3},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2006.06.009},
doi = {10.1016/j.datak.2006.06.009},
abstract = {The product line approach is recognized as a successful approach to reuse in software development. However, in many cases, it has resulted in interactions between requirements and/or features. Interaction detection, especially conflict detection between requirements has become more challenging. Thus, detecting conflicts between requirements is essential for successful product line development. Formal methods have been proposed to address this problem, however, they are hard to understand by non-experts and are limited to restricted domains. In addition, there is no overall process that covers all the steps for managing conflicts. We propose an approach for systematically identifying and managing requirements conflicts, which is based on requirements partition in natural language and supported by a tool. To demonstrate its feasibility, the proposed approach has been applied to the home integration system (HIS) domain and the results are discussed.},
journal = {Data Knowl. Eng.},
month = jun,
pages = {417–432},
numpages = {16},
keywords = {Syntactic and semantic requirements conflict detection, Software product line, Requirements partitioning, Requirements conflicts, Goal and scenario authoring}
}

@inproceedings{10.1109/ASE.2019.00120,
author = {Reuling, Dennis and Kelter, Udo and Ruland, Sebastian and Lochau, Malte},
title = {SiMPOSE: configurable N-way program merging strategies for superimposition-based analysis of variant-rich software},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00120},
doi = {10.1109/ASE.2019.00120},
abstract = {Modern software often exists in many different, yet similar versions and/or variants, usually derived from a common code base (e.g., via clone-and-own). In the context of product-line engineering, family-based analysis has shown very promising potential for improving efficiency in applying quality-assurance techniques to variant-rich software, as compared to a variant-by-variant approach. Unfortunately, these strategies rely on a product-line representation superimposing all program variants in a syntactically well-formed, semantically sound and variant-preserving manner, which is manually hard to obtain in practice. We demonstrate the SiMPOSE methodology for automatically generating superimpositions of N given program versions and/or variants facilitating family-based analysis of variant-rich software. SiMPOSE is based on a novel N-way model-merging technique operating at the level of control-flow automata (CFA) representations of C programs. CFAs constitute a unified program abstraction utilized by many recent software-analysis tools. We illustrate different merging strategies supported by SiMPOSE, namely variant-by-variant, N-way merging, incremental 2-way merging, and partition-based N/2-way merging, and demonstrate how SiMPOSE can be used to systematically compare their impact on efficiency and effectiveness of family-based unit-test generation. The SiMPOSE tool, the demonstration of its usage as well as related artifacts and documentation can be found at http://pi.informatik.uni-siegen.de/projects/variance/simpose.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1134–1137},
numpages = {4},
keywords = {software testing, program merging, model merging, family-based analyses},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1007/978-3-642-33666-9_34,
author = {Vierhauser, Michael and Gr\"{u}nbacher, Paul and Heider, Wolfgang and Holl, Gerald and Lettner, Daniela},
title = {Applying a consistency checking framework for heterogeneous models and artifacts in industrial product lines},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_34},
doi = {10.1007/978-3-642-33666-9_34},
abstract = {Product line engineering relies on heterogeneous models and artifacts to define and implement the product line's reusable assets. The complexity and heterogeneity of product line artifacts as well as their interdependencies make it hard to maintain consistency during development and evolution, regardless of the modeling approaches used. Engineers thus need support for detecting and resolving inconsistencies within and between the various artifacts. In this paper we present a framework for checking and maintaining consistency of arbitrary product line artifacts. Our approach is flexible and extensible regarding the supported artifact types and the definition of constraints. We discuss tool support developed for the DOPLER product line tool suite. We report the results of applying the approach to sales support applications of industrial product lines.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {531–545},
numpages = {15},
keywords = {sales support, model-based product lines, consistency checking},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/375212.375269,
author = {Gacek, Critina and Anastasopoules, Michalis},
title = {Implementing product line variabilities},
year = {2001},
isbn = {1581133588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/375212.375269},
doi = {10.1145/375212.375269},
abstract = {Software product lines have numerous members. Thus, a product line infrastructure must cover various systems. This is the significant difference to usual software systems and the reason for additional requirements on the various assets present during software product line engineering. It is imperative that they support the description of the product line as a whole, as well as its instantiation for the derivation of individual products.Literature has already addressed how to create and instantiate generic product line assets, such as domain models and architectures to generate instance specific ones [1, 2, 3], yet little attention has been given on how to actually deal with this genericity at the code level.This paper addresses the issue of handling product line variability at the code level. To this end various implementation approaches are examined with respect to their use in a product line context.},
booktitle = {Proceedings of the 2001 Symposium on Software Reusability: Putting Software Reuse in Context},
pages = {109–117},
numpages = {9},
keywords = {traceability, software product lines, product line variability, implementing variabilities, implementation approaches},
location = {Toronto, Ontario, Canada},
series = {SSR '01}
}

@inproceedings{10.1007/978-3-030-27544-0_10,
author = {Leiva, Francisco and Cruz, Nicol\'{a}s and Bugue\~{n}o, Ignacio and Ruiz-del-Solar, Javier},
title = {Playing Soccer Without Colors in the SPL: A Convolutional Neural Network Approach},
year = {2018},
isbn = {978-3-030-27543-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27544-0_10},
doi = {10.1007/978-3-030-27544-0_10},
abstract = {The goal of this paper is to propose a vision system for humanoid robotic soccer that does not use any color information. The main features of this system are: (i) real-time operation in the NAO robot, and (ii) the ability to detect the ball, the robots, their orientations, the lines and key field features robustly. Our ball detector, robot detector, and robot’s orientation detector obtain the highest reported detection rates. The proposed vision system is tested in a SPL field with several NAO robots under realistic and highly demanding conditions. The obtained results are: robot detection rate of 94.90%, ball detection rate of 97.10%, and a completely perceived orientation rate of 99.88% when the observed robot is static, and 95.52% when the observed robot is moving.},
booktitle = {RoboCup 2018: Robot World Cup XXII},
pages = {122–134},
numpages = {13},
keywords = {Proposals generation, Orientation detection, Ball detection, Robot detection, Convolutional Neural Network, Deep learning},
location = {Montr\'{e}al, QC, Canada}
}

@article{10.1007/s11219-011-9170-7,
author = {Acher, Mathieu and Collet, Philippe and Gaignard, Alban and Lahire, Philippe and Montagnat, Johan and France, Robert B.},
title = {Composing multiple variability artifacts to assemble coherent workflows},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9170-7},
doi = {10.1007/s11219-011-9170-7},
abstract = {The development of scientific workflows is evolving toward the systematic use of service-oriented architectures, enabling the composition of dedicated and highly parameterized software services into processing pipelines. Building consistent workflows then becomes a cumbersome and error-prone activity as users cannot manage such large-scale variability. This paper presents a rigorous and tooled approach in which techniques from Software Product Line (SPL) engineering are reused and extended to manage variability in service and workflow descriptions. Composition can be facilitated while ensuring consistency. Services are organized in a rich catalog which is organized as a SPL and structured according to the common and variable concerns captured for all services. By relying on sound merging techniques on the feature models that make up the catalog, reasoning about the compatibility between connected services is made possible. Moreover, an entire workflow is then seen as a multiple SPL (i.e., a composition of several SPLs). When services are configured within, the propagation of variability choices is then automated with appropriate techniques and the user is assisted in obtaining a consistent workflow. The approach proposed is completely supported by a combination of dedicated tools and languages. Illustrations and experimental validations are provided using medical imaging pipelines, which are representative of current scientific workflows in many domains.},
journal = {Software Quality Journal},
month = sep,
pages = {689–734},
numpages = {46},
keywords = {Software product lines, Scientific workflows, Feature models, Composition}
}

@inproceedings{10.1145/3276604.3276609,
author = {Guerra, Esther and de Lara, Juan and Chechik, Marsha and Salay, Rick},
title = {Analysing meta-model product lines},
year = {2018},
isbn = {9781450360296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276604.3276609},
doi = {10.1145/3276604.3276609},
abstract = {Model-driven engineering advocates the use of models to describe and automate many software development tasks. The syntax of modelling languages is defined by meta-models, making them essential artefacts. A combination of product line engineering methods and meta-models has been proposed to enable specification of modelling language variants, e.g., to describe a range of systems. However, there is a lack of techniques for ensuring syntactic correctness of all meta-models within a family (including their OCL constraints), and semantic correctness related to properties of individual instances of the different variants. The absence of verification methods at the product-line level can cause synthesis of ill-formed meta-models and problematic feature combinations whose effect at the instance level may go unnoticed.  To attack this problem, we propose an approach to lifting both the meta-model syntax checking and the satisfiability checking of properties of individual meta-model instances, to the product-line level. We validate the approach via a prototype tool called Merlin, and report on several experiments that show the advantages of our method w.r.t. an enumerative analysis approach.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {160–173},
numpages = {14},
keywords = {Product Lines, OCL, Model-Driven Engineering, Model Finding, Meta-Modelling},
location = {Boston, MA, USA},
series = {SLE 2018}
}

@article{10.1016/j.jss.2019.01.044,
author = {Th\"{u}m, Thomas and Kn\"{u}ppel, Alexander and Kr\"{u}ger, Stefan and Bolle, Stefanie and Schaefer, Ina},
title = {Feature-oriented contract composition},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.01.044},
doi = {10.1016/j.jss.2019.01.044},
journal = {J. Syst. Softw.},
month = jun,
pages = {83–107},
numpages = {25},
keywords = {Formal methods, Deductive verification, Design by contract, Software product lines, Feature-oriented programming}
}

@inproceedings{10.1145/2701319.2701335,
author = {Gamez, Nadia and El Haddad, Joyce and Fuentes, Lidia},
title = {Managing the Variability in the Transactional Services Selection},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701335},
doi = {10.1145/2701319.2701335},
abstract = {Web service composition is the capability to recursively construct a value added service by means of picking up existing services. An important step in the composition process is the selection step, which includes choosing services located in repositories. The selection approaches of Web services need to consider their specifics which raises important challenges as the management of the inherent service variability in functionality and implementation and ensuring correct execution termination between others. To realize reliable service compositions, transactional properties of services must be considered during the selection step. We argue that the transactional properties should be considered at the operation level of each service to be composed. However, modelling transactional services composition at the operation level drastically increment the complexity of service selection. In order to overcome this difficulty, in this paper we report on our research in progress on transactional service selection, which follows a Software Product Line approach considering the set of services that provide the same functionality as part of a service family. We model the variable operations of the service families using Feature Models. In this way, the selection process consists of selecting each service from a service family such that the aggregated transactional property satisfies the user preference.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {88–95},
numpages = {8},
keywords = {Transactional Services, Feature Modeling, Discovery and Selection},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@article{10.1016/j.scico.2012.06.002,
author = {Th\"{u}m, Thomas and K\"{a}stner, Christian and Benduhn, Fabian and Meinicke, Jens and Saake, Gunter and Leich, Thomas},
title = {FeatureIDE: An extensible framework for feature-oriented software development},
year = {2014},
issue_date = {January, 2014},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {79},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.06.002},
doi = {10.1016/j.scico.2012.06.002},
abstract = {FeatureIDE is an open-source framework for feature-oriented software development (FOSD) based on Eclipse. FOSD is a paradigm for the construction, customization, and synthesis of software systems. Code artifacts are mapped to features, and a customized software system can be generated given a selection of features. The set of software systems that can be generated is called a software product line (SPL). FeatureIDE supports several FOSD implementation techniques such as feature-oriented programming, aspect-oriented programming, delta-oriented programming, and preprocessors. All phases of FOSD are supported in FeatureIDE, namely domain analysis, requirements analysis, domain implementation, and software generation.},
journal = {Sci. Comput. Program.},
month = jan,
pages = {70–85},
numpages = {16},
keywords = {Tool support, Software product lines, Preprocessors, Feature-oriented software development, Feature-oriented programming, Feature modeling, Delta-oriented programming, Aspect-oriented programming}
}

@inproceedings{10.1109/MODELS.2017.22,
author = {Taentzer, Gabriele and Salay, Rick and Str\"{u}ber, Daniel and Chechik, Marsha},
title = {Transformations of software product lines: a generalizing framework based on category theory},
year = {2017},
isbn = {9781538634929},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS.2017.22},
doi = {10.1109/MODELS.2017.22},
abstract = {Software product lines are used to manage the development of highly complex software with many variants. In the literature, various forms of rule-based product line modifications have been considered. However, when considered in isolation, their expressiveness for specifying combined modifications of feature models and domain models is limited. In this paper, we present a formal framework for product line transformations that is able to combine several kinds of product line modifications presented in the literature. Moreover, it defines new forms of product line modifications supporting various forms of product lines and transformation rules. Our formalization of product line transformations is based on category theory, and concentrates on properties of product line relations instead of their single elements. Our framework provides improved expressiveness and flexibility of software product line transformations while abstracting from the considered type of model.},
booktitle = {Proceedings of the ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems},
pages = {101–111},
numpages = {11},
location = {Austin, Texas},
series = {MODELS '17}
}

@inproceedings{10.5555/2667025.2667027,
author = {Siegmund, Norbert and Mory, Maik and Feigenspan, Janet and Saake, Gunter and Nykolaychuk, Mykhaylo and Schumann, Marco},
title = {Interoperability of non-functional requirements in complex systems},
year = {2012},
isbn = {9781467318532},
publisher = {IEEE Press},
abstract = {Heterogeneity of embedded systems leads to the development of variable software, such as software product lines. From such a family of programs, stakeholders select the specific variant that satisfies their functional requirements. However, different functionality exposes different non-functional properties of these variants. Especially in the embedded-system domain, non-functional requirements are vital, because resources are scarce. Hence, when selecting an appropriate variant, we have to fulfill also non-functional requirements. Since more systems are interconnected, the challenge is to find a variant that additionally satisfies global nonfunctional (or quality) requirements. In this paper, we advert the problem of achieving interoperability of non-functional requirements among multiple interacting systems using a real-world scenario. Furthermore, we show an approach to find optimal variants for multiple systems that reduces computation effort by means of a stepwise configuration process.},
booktitle = {Proceedings of the Second International Workshop on Software Engineering for Embedded Systems},
pages = {2–8},
numpages = {7},
location = {Zurich, Switzerland},
series = {SEES '12}
}

@inproceedings{10.1145/568760.568805,
author = {Johansson, Enrico and H\"{o}st, Martin},
title = {Tracking degradation in software product lines through measurement of design rule violations},
year = {2002},
isbn = {1581135564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/568760.568805},
doi = {10.1145/568760.568805},
abstract = {In order to increase reuse, a number of product versions may be developed based on the same software platform. The platform must, however, be managed and updated according to new requirements if it should be reusable in a series of releases. This means that the platform is constantly changed during its lifecycle, and changes can result in degradation of the platform. In this paper, a measurement approach is proposed as a means of tracking the degradation of a software platform and consequently in the product line. The tracking approach is evaluated in a case study where it is applied to a series of different releases of a product. The result of the case study indicates that the presented approach is feasible.},
booktitle = {Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering},
pages = {249–254},
numpages = {6},
keywords = {software product line, software platform, project tracking, graph, design rules, degradation},
location = {Ischia, Italy},
series = {SEKE '02}
}

@inproceedings{10.1007/978-3-030-27544-0_8,
author = {Szemenyei, Marton and Estivill-Castro, Vladimir},
title = {Real-Time Scene Understanding Using Deep Neural Networks for RoboCup SPL},
year = {2018},
isbn = {978-3-030-27543-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27544-0_8},
doi = {10.1007/978-3-030-27544-0_8},
abstract = {Convolutional neural networks (CNNs) are the state-of-the-art method for most computer vision tasks. But, the deployment of CNNs on mobile or embedded platforms is challenging because of CNNs’ excessive computational requirements. We present an end-to-end neural network solution to scene understanding for robot soccer. We compose two key neural networks: one to perform semantic segmentation on an image, and another to propagate class labels between consecutive frames. We trained our networks on synthetic datasets and fine-tuned them on a set consisting of real images from a Nao robot. Furthermore, we investigate and evaluate several practical methods for increasing the efficiency and performance of our networks. Finally, we present RoboDNN, a C++ neural network library designed for fast inference on the Nao robots.},
booktitle = {RoboCup 2018: Robot World Cup XXII},
pages = {96–108},
numpages = {13},
keywords = {Neural networks, Semantic segmentation, Deep learning, Computer vision},
location = {Montr\'{e}al, QC, Canada}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {rule mining, product line, multi-objective search, machine learning, configuration},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.1007/978-3-030-86130-8_44,
author = {Feng, Zhigang and Song, Xiaoqin and Lei, Lei},
title = {Efficient Concurrent Transmission Scheme for Wireless Ad Hoc Networks: A Joint Optimization Approach},
year = {2021},
isbn = {978-3-030-86129-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86130-8_44},
doi = {10.1007/978-3-030-86130-8_44},
abstract = {In this paper, we focus on the joint optimization of scheduling and power control to achieve effective concurrent transmission. Under constraints, we describe the optimization problem as a scheduling problem based on power control. In order to solve the complexity problem, we have determined the best power control strategy in the large network area. Using the dual-link communication architecture, we decompose the optimization problem into two sub-problems, namely power control and link scheduling. By solving two sub-problems, we have determined the best link scheduling and power control mechanism suitable for the actual network environment. We realize efficient concurrent transmission based on the optimal solution obtained by joint optimization to effectively utilize network resources and improve energy efficiency. The simulation results prove the effectiveness of the scheme. Compared with existing solutions, the joint optimization solution has obvious advantages in terms of network throughput and energy consumption.},
booktitle = {Wireless Algorithms, Systems, and Applications: 16th International Conference, WASA 2021, Nanjing, China, June 25–27, 2021, Proceedings, Part II},
pages = {563–574},
numpages = {12},
keywords = {Dual-link structure, Energy consumption, Link scheduling, Power control, Concurrent transmission},
location = {Nanjing, China}
}

@inproceedings{10.1145/3023956.3023959,
author = {Ochoa, Lina and Pereira, Juliana Alves and Gonz\'{a}lez-Rojas, Oscar and Castro, Harold and Saake, Gunter},
title = {A survey on scalability and performance concerns in extended product lines configuration},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023959},
doi = {10.1145/3023956.3023959},
abstract = {Product lines have been employed as a mass customisation method that reduces production costs and time-to-market. Multiple product variants are represented in a product line, however the selection of a particular configuration depends on stakeholders' functional and non-functional requirements. Methods like constraint programming and evolutionary algorithms have been used to support the configuration process. They consider a set of product requirements like resource constraints, stakeholders' preferences, and optimization objectives. Nevertheless, scalability and performance concerns start to be an issue when facing large-scale product lines and runtime environments. Thus, this paper presents a survey that analyses strengths and drawbacks of 21 approaches that support product line configuration. This survey aims to: i) evidence which product requirements are currently supported by studied methods; ii) how scalability and performance is considered in existing approaches; and iii) point out some challenges to be addressed in future research.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {5–12},
numpages = {8},
keywords = {survey, scalability, product requirements, product line, performance, literature review, configuration},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1007/978-3-319-07317-0_8,
author = {Lochau, Malte and Peldszus, Sven and Kowal, Matthias and Schaefer, Ina},
title = {Model-Based Testing},
year = {2014},
isbn = {9783319073163},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-07317-0_8},
doi = {10.1007/978-3-319-07317-0_8},
abstract = {Software more and more pervades our everyday lives. Hence, we have high requirements towards the trustworthiness of the software. Software testing greatly contributes to the quality assurance of modern software systems. However, as today's software system get more and more complex and exist in many different variants, we need rigorous and systematic approaches towards software testing. In this tutorial, we, first, present model-based testing as an approach for systematic test case generation, test execution and test result evaluation for single system testing. The central idea of model-based testing is to base all testing activities on an executable model-based test specification. Second, we consider model-based testing for variant-rich software systems and review two model-based software product line testing techniques. Sample-based testing generates a set of representative variants for testing, and variability-aware product line testing uses a family-based test model which contains the model-based specification of all considered product variants.},
booktitle = {Advanced Lectures of the 14th International School on Formal Methods for Executable Software Models - Volume 8483},
pages = {310–342},
numpages = {33}
}

@inproceedings{10.5555/645882.672251,
author = {Yacoub, Sherif M.},
title = {Performance Analysis of Component-Based Applications},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Performance analysis is a software engineering activity that involves analyzing a software application with respect to performance quality attributes such as response and execution times. Performance analysis tools provide the necessary support for the analyst to monitor program execution, record and analyze performance data, and locate and understand areas of poor performance. Performance analysis methods and techniques are highly dependent on the properties of the software system to be analyzed. Product line engineering applications possess some special properties that impose constraints on the selection of the performance analysis techniques to be applied and the tools to be used. The development of a component-based reference architecture is crucial to the success of a true product line. The component-based nature facilitates the integration of components and the replacement of a component with another to meet the requirements of an instance application of the product line. In this paper, we discuss performance analysis of component-based software systems and its automation. We discuss how component-based system properties influence the selection of methods and tools used to obtain and analyze performance measures. We use a case study of the document content remastering product line to illustrate the application of a performance analysis method to component-based applications.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {299–315},
numpages = {17},
keywords = {performance analysis, component-based software engineering (CBSE), application and component profiling, and performance tools},
series = {SPLC 2}
}

@article{10.1016/j.infsof.2012.06.012,
author = {Gamez, Nadia and Fuentes, Lidia},
title = {Architectural evolution of FamiWare using cardinality-based feature models},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.06.012},
doi = {10.1016/j.infsof.2012.06.012},
abstract = {Context: Ambient Intelligence systems domain is an outstanding example of modern systems that are in permanent evolution, as new devices, technologies or facilities are continuously appearing. This means it would be desirable to have a mechanism that helps with the propagation of evolution changes in deployed systems. Objective: We present a software product line engineering process to manage the evolution of FamiWare, a family of middleware for ambient intelligence environments. This process drives the evolution of FamiWare middleware configurations using cardinality-based feature models, which are especially well suited to express the structural variability of ambient intelligence systems. Method: FamiWare uses cardinality-based feature models and clonable features to model the structural variability present in ambient intelligence systems, composed of a large variety of heterogeneous devices. Since the management evolution of configurations with clonable features is manually untreatable due to the high number of features, our process automates it and propagates changes made at feature level to the architectural components of the FamiWare middleware. This is a model driven development process as the evolution management, the propagation of evolution changes and the code generation are performed using some kind of model mappings and transformations. Concretely we present a variability modelling language to map the selection of features to the corresponding FamiWare middleware architectural components. Results: Our process is able to manage the evolution of cardinality-based feature models with thousands of features, something which is not possible to tackle manually. Thanks to the use of the variability language and the automatic code generation it is possible to propagate and maintain a correspondence between the FamiWare architectural model and the code. The process is then able to calculate the architectural differences between the evolved configuration and the previous one. Checking these differences, our process helps to calculate the effort needed to perform the evolution changes in the customized products. To perform those tasks we have defined two operators, one to calculate the differences between two feature model configurations and another to create a new configuration from a previous one. Conclusion: Our process automatically propagates the evolution changes of the middleware family into the existing configurations where the middleware is already deployed and also helps us to calculate the effort in performing the changes in every configuration. Finally, we validated our approach, demonstrating the functioning of the defined operators and showing that by using our tool we can generate evolved configurations for FamiWare with thousands of cloned features, for several case studies.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {563–580},
numpages = {18},
keywords = {Software Product Lines, Middleware family, Feature Models, Evolution}
}

@inproceedings{10.5555/1885639.1885676,
author = {Mannion, Mike and Savolainen, Juha},
title = {Aligning business and technical strategies for software product lines},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A successful software product line strategy has business goals, a business strategy, a target market and a technical strategy that is aligned with the business goals and the target market. A common challenge in a number of organizations is for business and engineering units to understand what business and technical strategy alignment actually means in practice and to maintain that alignment as business goals and target markets evolve. If they are misaligned, then at best significant development inefficiencies occur, and at worst there is loss of market share. This paper explains different business and technical strategies, describes commonly used engineering techniques to manage commonality and variability and their deployment under different strategies.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {406–419},
numpages = {14},
keywords = {software architecture, product lines, feature modeling, business strategy, business alignment},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.4108/eai.25-10-2016.2266615,
author = {Distefano, Salvatore and Scarpa, Marco},
title = {Quantitative assessment of workflow performance through PH reduction},
year = {2017},
isbn = {9781631901416},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/eai.25-10-2016.2266615},
doi = {10.4108/eai.25-10-2016.2266615},
abstract = {Workflows are logical abstraction of processes widely adopted in several contexts such as economy and management sciences (business processes), service engineering (service oriented architecture, Web services, BPEL), software engineering (component based systems, UML, flowcharts) distributed computing (Grid, Cloud, Mapreduce). Design and operation of workflows are critical stages in which problems and issues not manifested by the single block arise from compositions. To deal with such issues, proper techniques and tools should be implemented as support for workflow designers and operators. This paper proposes a solution for the evaluation of workflow performance starting from the components’ ones. Based on the stochastic characterization of the workflow tasks, phase type distributions and stochastic workflow reduction rules, the proposed approach allows to overcome the limits of existing solutions, considering general response time distributions while providing parametric analysis on customer usage profiles and design alternatives. To demonstrate the effectiveness of the proposed solution an example taken from literature is evaluated.},
booktitle = {Proceedings of the 10th EAI International Conference on Performance Evaluation Methodologies and Tools on 10th EAI International Conference on Performance Evaluation Methodologies and Tools},
pages = {117–124},
numpages = {8},
keywords = {workflow, usage profile, phase type, performance, non-markovian behaviors, design alternatives},
location = {Taormina, Italy},
series = {VALUETOOLS'16}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00107,
author = {Weber, Max and Apel, Sven and Siegmund, Norbert},
title = {White-box performance-influence models: a profiling and learning approach (replication package)},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00107},
doi = {10.1109/ICSE-Companion52605.2021.00107},
abstract = {These artifacts refer to the study and implementation of the paper 'White-Box Performance-Influence Models: A Profiling and Learning Approach'. In this document, we describe the idea and process of how to build white-box performance models for configurable software systems. Specifically, we describe the general steps and tools that we have used to implement our approach, the data we have obtained, and the evaluation setup. We further list the available artifacts, such as raw measurements, configurations, and scripts at our software heritage repository.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {232–233},
numpages = {2},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/1944892.1944899,
author = {Galster, Matthias and Avgeriou, Paris},
title = {The notion of variability in software architecture: results from a preliminary exploratory study},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944899},
doi = {10.1145/1944892.1944899},
abstract = {Context: In the software product line domain, the concept of variability is well recognized. However, variability in the context of software architecture still seems to be poorly understood. Objective: In this paper, we aim at contributing to the development of a basic understanding of the notion of variability in the software architecture domain, beyond the idea of product lines. Method: We perform a preliminary exploratory study which consists of two parts: an expert survey among 11 subjects, and a mini focus group with 4 participants. For both parts, we collect and analyze mostly qualitative data. Results: Our observations indicate that there seems to be no common understanding of "variability" in the context of software architecture. On the other hand, some challenges related to variability in software architecture are similar to challenges identified in the product line domain. Conclusions: Variability in software architecture might require more theoretical foundations in order to establish "variability" as an architectural key concept and first-class quality attribute.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {59–67},
numpages = {9},
keywords = {variability, software architecture, questionnaire, product lines, mini focus group},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/1814392.1814397,
author = {bin Abid, Saad},
title = {Resolving feature dependency implementations inconsistencies during product derivation},
year = {2010},
isbn = {9781605589930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814392.1814397},
doi = {10.1145/1814392.1814397},
abstract = {Features implementing the functionality in a software product line (SPL) often interact and depend on each other. It is hard to maintain the consistency between feature dependencies on the model level and the actual implementation over time, resulting in inconsistency during product derivation. We describe our initial results when working with feature dependency implementations and the related inconsistencies in actual code. Our aim is to improve consistency checking during product derivation. We have provided tool support for maintaining consistency between feature dependency implementations on both model and code levels in a product line. The tool chain supports the consistency checking on both the domain engineering and the application levels between actual code and models. We report our experience of managing feature dependency consistency in the context of an existing scientific calculator product line.},
booktitle = {Proceedings of the 6th ECMFA Traceability Workshop},
pages = {31–38},
numpages = {8},
keywords = {variability models, tool support, software product lines, product derivation, feature implementation dependencies, consistency checking, aspect-oriented product line, AspectJ programming},
location = {Paris, France},
series = {ECMFA-TW '10}
}

@article{10.1016/j.jss.2016.06.102,
author = {Lung, Chung-Horng and Zhang, Xu and Rajeswaran, Pragash},
title = {Improving software performance and reliability in a distributed and concurrent environment with an architecture-based self-adaptive framework},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.06.102},
doi = {10.1016/j.jss.2016.06.102},
abstract = {We proposed a novel software architecture-level adaptation approach.We adopted known architectural patterns in distributed and concurrent systems.We developed a framework to support the self-adaptive mechanism.We developed and evaluated five adaptive policies.Our approach improved performance and increased reliability in our experiments. More and more, modern software systems in a distributed and parallel environment are becoming highly complex and difficult to manage. A self-adaptive approach that integrates monitoring, analyzing, and actuation functionalities has the potential to accommodate an ever dynamically changing environment. This paper proposes an architecture-level self-adaptive framework with the aim of improving performance and reliability. To meet such a goal, this paper presents a Self-Adaptive Framework for Concurrency Architectures (SAFCA) that consists of multiple well-documented architectural patterns in addition to monitoring and adaptive capabilities. With this framework, a system using an architectural alternative can activate another alternative at runtime to cope with increasing demands or to recover from failure. Five adaptation mechanisms have been developed for concept demonstration and evaluation; four focus on performance improvement and one deals with failover and reliability enhancement. We have performed a number of experiments with this framework. The experimental results demonstrate that the proposed adaptive framework can mitigate the over-provisioning method commonly used in practice. As a result, resource usage becomes more efficient for most normal conditions, while the system is still able to effectively handle bursty or growing demands using an adaptive mechanism. The performance of SAFCA is also better than systems using only standalone architectural alternatives without an adaptation scheme. Moreover, the experimental results show that a fast recovery can be realized in the case of failure by conducting an architecture switchover to maintain the desired service.},
journal = {J. Syst. Softw.},
month = nov,
pages = {311–328},
numpages = {18},
keywords = {Software architecture, Reliability, Performance, Patterns, Elastic computing, Distributed and concurrent architecture, Autonomic computing}
}

@inproceedings{10.1145/3330204.3330251,
author = {Sorgatto, Doglas W. and Paiva, D\'{e}bora M. B. and Cagnin, Maria Istela},
title = {Requirement Reuse in Business Processes Lines: Reutiliza\c{c}\~{a}o de requisitos em linhas de processos de neg\'{o}cio},
year = {2019},
isbn = {9781450372374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330204.3330251},
doi = {10.1145/3330204.3330251},
abstract = {The cost reduction in the Requirement Engineering process finds in business process modeling a way of aligning business goals with software requirements, and for development companies that have development demands in the same domain, greater savings can be found with the adoption of Business Process Lines (BPL). From this perspective, this paper presents the ARReq, which is an approach that allows the elicitation, specification and reuse of requirements from BPLs. It has been defined to provide quality attributes, suggested by ISO/IEC 29.148, to the functional, non-functional requirements and business rules elicited with the support of any elicitation technique applicable to BPMN business process models. A qualitative analysis was carried out and allowed to observe that ARReq is scalable, has low coupling with BPLs management approaches, besides specifying the requirements reused in the formats of user stories and requirements document and to provide a traceability matrix to support the software maintainability.},
booktitle = {Proceedings of the XV Brazilian Symposium on Information Systems},
articleno = {41},
numpages = {8},
keywords = {Requirement reuse, Business Processes Line, BPMN},
location = {Aracaju, Brazil},
series = {SBSI '19}
}

@inproceedings{10.1145/3001867.3001874,
author = {Queiroz, Rodrigo and Berger, Thorsten and Czarnecki, Krzysztof},
title = {Towards predicting feature defects in software product lines},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001874},
doi = {10.1145/3001867.3001874},
abstract = {Defect-prediction techniques can enhance the quality assurance activities for software systems. For instance, they can be used to predict bugs in source files or functions. In the context of a software product line, such techniques could ideally be used for predicting defects in features or combinations of features, which would allow developers to focus quality assurance on the error-prone ones. In this preliminary case study, we investigate how defect prediction models can be used to identify defective features using machine-learning techniques. We adapt process metrics and evaluate and compare three classifiers using an open-source product line. Our results show that the technique can be effective. Our best scenario achieves an accuracy of 73 % for accurately predicting features as defective or clean using a Naive Bayes classifier. Based on the results we discuss directions for future work.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {58–62},
numpages = {5},
keywords = {software product lines, features, defect prediction},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@article{10.1016/j.infsof.2016.08.011,
author = {Tanhaei, Mohammad and Habibi, Jafar and Mirian-Hosseinabadi, Seyed-Hassan},
title = {Automating feature model refactoring},
year = {2016},
issue_date = {December 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {80},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2016.08.011},
doi = {10.1016/j.infsof.2016.08.011},
abstract = {Display Omitted Context: Feature model is an appropriate and indispensable tool for modeling similarities and differences among products of the Software Product Line (SPL). It not only exposes the validity of the products' configurations in an SPL but also changes in the course of time to support new requirements of the SPL. Modifications made on the feature model in the course of time raise a number of issues. Useless enlargements of the feature model, the existence of dead features, and violated constraints in the feature model are some of the key problems that make its maintenance difficult.Objective: The initial approach to dealing with the above-mentioned problems and improving maintainability of the feature model is refactoring. Refactoring modifies software artifacts in a way that their externally visible behavior does not change.Method: We introduce a method for defining refactoring rules and executing them on the feature model. We use the ATL model transformation language to define the refactoring rules. Moreover, we provide an Alloy model to check the feature model and the safety of the refactorings that are performed on it.Results: In this research, we propose a safe framework for refactoring a feature model. This framework enables users to perform automatic and semi-automatic refactoring on the feature model.Conclusions: Automated tool support for refactoring is a key issue for adopting approaches such as utilizing feature models and integrating them into the software development process of companies. In this work, we define some of the important refactoring rules on the feature model and provide tools that enable users to add new rules using the ATL M2M language. Our framework assesses the correctness of the refactorings using the Alloy language.},
journal = {Inf. Softw. Technol.},
month = dec,
pages = {138–157},
numpages = {20},
keywords = {Model transformation &amp; refactoring, Feature model refactoring}
}

@inproceedings{10.1007/978-3-319-27343-3_1,
author = {Braubach, Lars and Pokahr, Alexander and Kalinowski, Julian and Jander, Kai},
title = {Tailoring Agent Platforms with Software Product Lines},
year = {2015},
isbn = {9783319273426},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-27343-3_1},
doi = {10.1007/978-3-319-27343-3_1},
abstract = {Agent platforms have been conceived traditionally as middleware, helping to deal with various application challenges like agent programming models, remote messaging, and coordination protocols. A\"{\i} \'{z}middleware is typically a bundle of functionalities necessary to execute multi-agent applications. In contrast to this traditional view, nowadays different use cases also for selected agent concepts have emerged requiring also different kinds of functionalities. Examples include a platform for conducting multi-agent simulations, intelligent agent behavior models for controlling non-player characters NPCs in games and a lightweight version suited for mobile devices. A one-size-fits-all software bundle often does not sufficiently match these requirements, because customers and developers want solutions specifically tailored to their needs, i.e. a small but focused solution is frequently preferred over bloated software with extraneous functionality. Software product lines are an approach suitable for creating a series of similar products from a common code base. In this paper we will show how software product line modeling and technology can help creating tailor-made products from multi-agent platforms. Concretely, the Jadex platform will be analyzed and a feature model as well as an implementation path will be presented.},
booktitle = {Revised Selected Papers of the 13th German Conference on Multiagent System Technologies - Volume 9433},
pages = {3–21},
numpages = {19},
location = {Cottbus, Germany},
series = {MATES 2015}
}

@article{10.1016/j.jss.2015.08.026,
author = {Vogel-Heuser, Birgit and Fay, Alexander and Schaefer, Ina and Tichy, Matthias},
title = {Evolution of software in automated production systems},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {110},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.08.026},
doi = {10.1016/j.jss.2015.08.026},
abstract = {Automated Production Systems (aPS) impose specific requirements regarding evolution.We present a classification of how Automated Production Systems evolve.We discuss the state of art and research needs for the development phases of aPS.Model-driven engineering and Variability Management are key issues.Cross-discipline analysis of (non)-functional requirements must be improved. Coping with evolution in automated production systems implies a cross-disciplinary challenge along the system's life-cycle for variant-rich systems of high complexity. The authors from computer science and automation provide an interdisciplinary survey on challenges and state of the art in evolution of automated production systems. Selected challenges are illustrated on the case of a simple pick and place unit. In the first part of the paper, we discuss the development process of automated production systems as well as the different type of evolutions during the system's life-cycle on the case of a pick and place unit. In the second part, we survey the challenges associated with evolution in the different development phases and a couple of cross-cutting areas and review existing approaches addressing the challenges. We close with summarizing future research directions to address the challenges of evolution in automated production systems. Display Omitted},
journal = {J. Syst. Softw.},
month = dec,
pages = {54–84},
numpages = {31},
keywords = {Software engineering, Evolution, Automation, Automated production systems}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using multi-objective search and machine learning to infer rules constraining product configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.},
journal = {Automated Software Engg.},
month = jun,
pages = {1–62},
numpages = {62},
keywords = {Interacting products, Machine learning, Multi-objective search, Rule mining, Configuration, Product line}
}

@inproceedings{10.1145/1868688.1868691,
author = {Torres, M\'{a}rio and Kulesza, Uir\'{a} and Sousa, Matheus and Batista, Thais and Teixeira, Leopoldo and Borba, Paulo and Cirilo, Elder and Lucena, Carlos and Braga, Rosana and Masiero, Paulo},
title = {Assessment of product derivation tools in the evolution of software product lines: an empirical study},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868691},
doi = {10.1145/1868688.1868691},
abstract = {Product derivation approaches automate the customization process of software product lines. Over the last years, many tools have been proposed aiming at synthesize and generate products from a set of reusable assets. These tools adopt different techniques and strategies to implement and automate the product derivation activities. In this paper, we analyzed six modern product derivation tools (Captor, CIDE, GenArch, MSVCM, pure::variants, XVCL) in the context of evolution scenarios of a software product line. Our study has adopted several metrics to analyze the modularity, complexity and stability of product derivation artifacts related to configuration knowledge along different releases of a mobile product line. The preliminary results of our study have shown that approaches with a dedicated model or file to represent the CK specification can bring several benefits to the modularization and stability of a software product line.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {10–17},
numpages = {8},
keywords = {product derivation tools, measurement},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/3023956.3023961,
author = {Lity, Sascha and Al-Hajjaji, Mustafa and Th\"{u}m, Thomas and Schaefer, Ina},
title = {Optimizing product orders using graph algorithms for improving incremental product-line analysis},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023961},
doi = {10.1145/3023956.3023961},
abstract = {The individual analysis of each product of a software product line (SPL) leads to redundant analysis steps due to the inherent commonality. Therefore, incremental SPL analyses exploit commonalities and focus on the differences between products to reduce the analysis effort. However, existing techniques are influenced by the order in which products are analyzed. The more similar subsequently analyzed products are, the greater is the potential reduction of the overall analysis effort as similar products imply less differences to be analyzed. Hence, an order of products, where the total number of differences is minimized, facilitates incremental SPL analyses. In this paper, we apply graph algorithms to determine optimized product orders. We capture products as nodes in a graph, where solution-space information defines edge weights between product nodes. We adopt existing heuristics for finding an optimal solution of the traveling salesperson problem to determine a path in the product graph with minimal costs. A path represents an optimized product order w.r.t. minimized differences between all products. We realize a prototype of our approach and evaluate its applicability and performance showing a significant optimization compared to standard and random orders.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {60–67},
numpages = {8},
keywords = {product orders, graph algorithms, delta-oriented software product lines},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1145/1842752.1842815,
author = {Galster, Matthias},
title = {Describing variability in service-oriented software product lines},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842815},
doi = {10.1145/1842752.1842815},
abstract = {Service-oriented architectures are a standard-based and technology-independent distributed computing paradigm for discovering, binding and assembling loosely-coupled software services. Software product lines on the other hand allow a generic architecture to be configured and deployed in different instances. Product lines facilitate systematic reuse through managing variability. In this paper, we combine ideas from the service domain and the product line domain and investigate what types of variability exist in service-oriented software architectures. Moreover, we suggest a way for representing variability in service-oriented architectures by formalizing the notion of variability. To allow different viewpoints on variability, we define stakeholder roles that occur in the context of service-oriented software architectures. By applying the proposed concepts, we hope to improve variability management at the software architecture level of service-oriented systems.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {344–350},
numpages = {7},
keywords = {variability, service-oriented architectures, modeling},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@article{10.1109/MS.2016.78,
author = {de Oliveira, Raphael Pereira and de Almeida, Eduardo Santana},
title = {Evaluating Lehman's Laws of Software Evolution for Software Product Lines},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.78},
doi = {10.1109/MS.2016.78},
abstract = {The evolution of software to maintain its performance and usefulness over time occurs in successful software development processes. To address this, Meir Lehman formulated his well-known software-evolution laws. This article evaluates Lehman's laws in the context of two companies' real-world software-product-line projects to gain useful insights about the evolution process.},
journal = {IEEE Softw.},
month = may,
pages = {90–93},
numpages = {4}
}

@inproceedings{10.1145/2554850.2555054,
author = {Basso, F\'{a}bio Paulo and Oliveira, Toacy Cavalcante and Farias, Kleinner},
title = {Extending JUnit 4 with Java annotations and reflection to test variant model transformation assets},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2555054},
doi = {10.1145/2554850.2555054},
abstract = {Software Product Line (SPL) techniques are widely used to represent variability and commonality in reusable software assets. Similarly, model transformations are also software assets and can be reused with the same techniques. However, their applicability in the model transformations domain demands an extra effort to test the generated/adapted assets. Automated test cases should consider isolated transformations and also their combined use in a model transformation chain, that can vary according to different needs in software projects, e.g. libraries and frameworks. In order to facilitate the specification of automated test cases, this paper presents a JUnit extension to support unit and integration tests that execute dynamic SPL-based model transformation chains.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1601–1608},
numpages = {8},
keywords = {unit tests, software product lines, model transformation chain, integration tests, MDE, Java reflection, Java annotations},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@article{10.1016/j.procs.2018.07.295,
author = {Azouzi, Sameh and Brahmi, Zaki and Ghannouchi, Sonia Ayachi},
title = {Customization of multi-tenant learning process as a service with Business Process Feature Model},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {126},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.07.295},
doi = {10.1016/j.procs.2018.07.295},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {606–615},
numpages = {10},
keywords = {customization, variability, cloud computing, SPL, multi-tenant, BPM, E-learning}
}

@inproceedings{10.1145/2897053.2897058,
author = {Sharifloo, Amir Molzam and Metzger, Andreas and Quinton, Cl\'{e}ment and Baresi, Luciano and Pohl, Klaus},
title = {Learning and evolution in dynamic software product lines},
year = {2016},
isbn = {9781450341875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897053.2897058},
doi = {10.1145/2897053.2897058},
abstract = {A Dynamic Software Product Line (DSPL) aims at managing run-time adaptations of a software system. It is built on the assumption that context changes that require these adaptations at run-time can be anticipated at design-time. Therefore, the set of adaptation rules and the space of configurations in a DSPL are predefined and fixed at design-time. Yet, for large-scale and highly distributed systems, anticipating all relevant context changes during design-time is often not possible due to the uncertainty of how the context may change. Such design-time uncertainty therefore may mean that a DSPL lacks adaptation rules or configurations to properly reconfigure itself at run-time. We propose an adaptive system model to cope with design-time uncertainty in DSPLs. This model combines learning of adaptation rules with evolution of the DSPL configuration space. It takes particular account of the mutual dependencies between evolution and learning, such as using feedback from unsuccessful learning to trigger evolution. We describe concrete steps for learning and evolution to show how such feedback can be exploited. We illustrate the use of such a model with a running example from the cloud computing domain.},
booktitle = {Proceedings of the 11th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {158–164},
numpages = {7},
keywords = {machine learning, evolution, dynamic software product lines, adaptation},
location = {Austin, Texas},
series = {SEAMS '16}
}

@inproceedings{10.1109/ISORCW.2011.18,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Product Model Derivation by Model Transformation in Software Product Lines},
year = {2011},
isbn = {9780769543772},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISORCW.2011.18},
doi = {10.1109/ISORCW.2011.18},
abstract = {Product derivation is an essential part of the Software Product Line (SPL) development process. The paperproposes a model transformation for deriving automatically a UML model of a specific product from the UML model of a product line. This work is a part of a larger project aiming to integrate performance analysis in the SPL model-driven development. The SPL source model is expressed in UML extended with two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The automatic derivation of a concrete product model based on a given feature configuration is enabled through the mapping between features from the feature model and their realizations in the design model. The paper proposes an efficient mapping technique that aims to minimize the amount of explicit feature annotations in the UML design model of SPL. Implicit feature mapping is inferred during product derivation from the relationships between annotated and non-annotated model elements as defined in the UML metamodel and well formedness rules. The transformation is realized in the Atlas Transformation Language (ATL) and illustrated with an ecommerce case study that models structural and behavioural SPL views.},
booktitle = {Proceedings of the 2011 14th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
pages = {72–79},
numpages = {8},
keywords = {UML, SPL, MARTE, Feature Mapping, ATL},
series = {ISORCW '11}
}

@inproceedings{10.1145/3377024.3377031,
author = {El-Sharkawy, Sascha and Krafczyk, Adam and Schmid, Klaus},
title = {Fast static analyses of software product lines: an example with more than 42,000 metrics},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377031},
doi = {10.1145/3377024.3377031},
abstract = {Context: Software metrics, as one form of static analyses, is a commonly used approach in software engineering in order to understand the state of a software system, in particular to identify potential areas prone to defects. Family-based techniques extract variability information from code artifacts in Software Product Lines (SPLs) to perform static analysis for all available variants. Many different types of metrics with numerous variants have been defined in literature. When counting all metrics including such variants, easily thousands of metrics can be defined. Computing all of them for large product lines can be an extremely expensive process in terms of performance and resource consumption.Objective: We address these performance and resource challenges while supporting customizable metric suites, which allow running both, single system and variability-aware code metrics.Method: In this paper, we introduce a partial parsing approach used for the efficient measurement of more than 42,000 code metric variations. The approach covers variability information and restricts parsing to the relevant parts of the Abstract Syntax Tree (AST).Conclusions: This partial parsing approach is designed to cover all relevant information to compute a broad variety of variability-aware code metrics on code artifacts containing annotation-based variability, e.g., realized with C-preprocessor statements. It allows for the flexible combination of single system and variability-aware metrics, which is not supported by existing tools. This is achieved by a novel representation of partially parsed product line code artifacts, which is tailored to the computation of the metrics. Our approach consumes considerably less resources, especially when computing many metric variants in parallel.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {9},
keywords = {variability models, software product lines, metrics, implementation, feature models, abstract syntax trees, SPL, AST},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1109/QUATIC.2012.14,
author = {Gonzalez-Huerta, Javier and Insfran, Emilio and Abrahao, Silvia},
title = {A Multimodel for Integrating Quality Assessment in Model-Driven Engineering},
year = {2012},
isbn = {9780769547770},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QUATIC.2012.14},
doi = {10.1109/QUATIC.2012.14},
abstract = {The development of complex software systems following the Model-Driven Engineering (MDE) approach relies on the use of different models for describing the system (e.g., structure, behavior). These models should be specified first separately but then their inter-relationship must be established since they represent complementary aspects of the system. Besides, MDE development processes are mostly focused on functionality, and do not give proper support to the quality aspects of the system. In this paper, we present a generic multimodel and the process for its construction, allowing the representation of the different viewpoint models of a software system and the relationships among elements on these viewpoints. This multimodel is a means for integrating a quality viewpoint in MDE processes, allowing the quality attributes to become a decision factor in the choice among design decisions in transformation processes. The feasibility of this approach is illustrated through the use of the multimodel in a specific example for Software Product Line development.},
booktitle = {Proceedings of the 2012 Eighth International Conference on the Quality of Information and Communications Technology},
pages = {251–254},
numpages = {4},
keywords = {Software Product Lines, Quality Atttributes, Model Driven Development},
series = {QUATIC '12}
}

@article{10.1007/s00766-014-0211-1,
author = {Djouab, Rachida and Abran, Alain and Seffah, Ahmed},
title = {An ASPIRE-based method for quality requirements identification from business goals},
year = {2016},
issue_date = {March     2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {1},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-014-0211-1},
doi = {10.1007/s00766-014-0211-1},
abstract = {Quality requirements are the main drivers for modeling and evaluating software quality at an early stage, and ASPIRE is an engineering method designed to elicit and document the quality requirements of embedded systems. This paper proposes an extension to ASPIRE to identify quality requirements from the business goals of the organization and ensure their traceability. This extension includes a set of added components created from the main concepts of the SOQUAREM methodology, including the BMM (business motivation model), derivation rules, the quality attribute utility tree, the quality attribute scenario template, the quality attribute documentation template, and ISO 9126. The applicability of the extended method is illustrated with a wireless plant control system as an example.},
journal = {Requir. Eng.},
month = mar,
pages = {87–106},
numpages = {20},
keywords = {Software quality engineering, Quality requirements (QRs), Quality attributes (QAs), QR elicitation method, Non-functional requirements (NFRs), Business goals (BGs), BMM (business motivation model)}
}

@article{10.1016/j.jss.2011.06.026,
author = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
title = {A genetic algorithm for optimized feature selection with resource constraints in software product lines},
year = {2011},
issue_date = {December, 2011},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {12},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.06.026},
doi = {10.1016/j.jss.2011.06.026},
abstract = {Abstract: Software product line (SPL) engineering is a software engineering approach to building configurable software systems. SPLs commonly use a feature model to capture and document the commonalities and variabilities of the underlying software system. A key challenge when using a feature model to derive a new SPL configuration is determining how to find an optimized feature selection that minimizes or maximizes an objective function, such as total cost, subject to resource constraints. To help address the challenges of optimizing feature selection in the face of resource constraints, this paper presents an approach that uses G enetic A lgorithms for optimized FE ature S election (GAFES) in SPLs. Our empirical results show that GAFES can produce solutions with 86-97% of the optimality of other automated feature selection algorithms and in 45-99% less time than existing exact and heuristic feature selection techniques.},
journal = {J. Syst. Softw.},
month = dec,
pages = {2208–2221},
numpages = {14},
keywords = {Software product lines, Product derivation, Optimization, Genetic algorithm, Feature models, Configuration}
}

@phdthesis{10.5555/AAI28492839,
author = {Shatnawi, Hazim and Wilkins, Dawn and Chen, Yixin and Easson, Gregory},
advisor = {Conrad, Cunningham, H.},
title = {Constructing and Validating Feature Models Using Relational, Document, and Graph Databases},
year = {2021},
isbn = {9798516099809},
publisher = {The University of Mississippi},
abstract = {Building a software product line (SPL) is a systematic strategy for reusing software within a family of related systems from some application domain. To define an SPL, a domain analyst must identify the common and variable aspects of a family of systems and capture them for later use in construction of specific products. To do so, Feature-Oriented Domain Analysis (FODA) introduced the feature model as an abstraction to represent the common and variable aspects, using a feature diagram to depict the model visually. However, this abstraction is often difficult for developers to use because most tools rely on specialized theories, notations, or technologies. This dissertation takes a novel approach. It uses mainstream database and Web technologies familiar to most developers. It represents feature models as directed acyclic graphs and encodes them using the relational (MariaDB), document-oriented (MongoDB), and graph (Neo4j) database paradigms. The design integrates these storage mechanisms with a Web interface that enables users to construct syntactically and semantically correct feature models and to configure specific products from the stored model. To enable the exchange of models among databases, the design also enables the models to be encoded as JSON text files. It provides translators from the relational database encoding to the JSON encoding and vice versa and includes algorithms to manipulate the JSON encoding directly. Finally, to determine which database encodings are the say{best} from various perspectives, the dissertation evaluates them experimentally against a set of performance criteria and subjectively against a set of desirable qualities.},
note = {AAI28492839}
}

@inproceedings{10.1145/2480362.2480596,
author = {Ara\'{u}jo, Jo\~{a}o and Goul\~{a}o, Miguel and Moreira, Ana and Sim\~{a}o, In\^{e}s and Amaral, Vasco and Baniassad, Elisa},
title = {Advanced modularity for building SPL feature models: a model-driven approach},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480596},
doi = {10.1145/2480362.2480596},
abstract = {Feature Models are commonly used to specify commonalities and variabilities in Software Product Lines (SPL). Our goal is to enhance feature modeling with traceability and improved support for crosscutting concerns. While traceability will show the features' requirement-origins, providing means to reason about their existence, crosscutting concerns will be handled through advanced modularity mechanisms (e.g. aspects), making the impact of changes to SPL models less difficult to understand and analyze. The result is Theme/SPL, a novel SPL requirements technique based on a concern-driven approach (Theme/Doc). Theme/SPL includes the proposal of a domain-specific language for specifying Theme/Doc models and uses model-driven development to generate automatically feature models from them. We show the applicability of the technique through a case study using a within-group design to evaluate the final results and tools developed.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1246–1253},
numpages = {8},
keywords = {software product lines, model-driven development, advanced modularity},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@article{10.1007/s10664-016-9462-4,
author = {Assun\c{c}\~{a}o, Wesley K. and Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Vergilio, Silvia R. and Egyed, Alexander},
title = {Multi-objective reverse engineering of variability-safe feature models based on code dependencies of system variants},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9462-4},
doi = {10.1007/s10664-016-9462-4},
abstract = {Maintenance of many variants of a software system, developed to supply a wide range of customer-specific demands, is a complex endeavour. The consolidation of such variants into a Software Product Line is a way to effectively cope with this problem. A crucial step for this consolidation is to reverse engineer feature models that represent the desired combinations of features of all the available variants. Many approaches have been proposed for this reverse engineering task but they present two shortcomings. First, they use a single-objective perspective that does not allow software engineers to consider design trade-offs. Second, they do not exploit knowledge from implementation artifacts. To address these limitations, our work takes a multi-objective perspective and uses knowledge from source code dependencies to obtain feature models that not only represent the desired feature combinations but that also check that those combinations are indeed well-formed, i.e. variability safe. We performed an evaluation of our approach with twelve case studies using NSGA-II and SPEA2, and a single-objective algorithm. Our results indicate that the performance of the multi-objective algorithms is similar in most cases and that both clearly outperform the single-objective algorithm. Our work also unveils several avenues for further research.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1763–1794},
numpages = {32},
keywords = {Reverse engineering, Multi-objective evolutionary algorithms, Feature models, Empirical evaluation}
}

@article{10.5555/2873826.2874010,
author = {Saeed, Mazin and Saleh, Faisal and Al-Insaif, Sadiq and El-Attar, Mohamed},
title = {Empirical validating the cognitive effectiveness of a new feature diagrams visual syntax},
year = {2016},
issue_date = {March 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {71},
number = {C},
issn = {0950-5849},
abstract = {ContextFeature models are commonly used to capture and communicate the commonality and variability of features in a Software Product Line. The core component of Feature models is feature diagrams, which graphically depict features in a hierarchical form. In previous work we have proposed a new notation that aims to improve the cognitive effectiveness of feature diagrams. ObjectiveThe objective of this paper is to empirically validate the cognitive effectiveness of the new feature diagrams notation in comparison to its original form. MethodsWe use two distinct empirical user-studies to validate the new notation. The first empirical study uses the survey approach while the second study is a subject-based experiment. The survey study investigates the semantic transparency of the new notation while the second study investigates the speed and accuracy of reading the notation. ResultsThe results of the studies indicate that the proposed changes have significantly improved its cognitive effectiveness. ConclusionsThe cognitive effectiveness of feature diagrams has been improved, however there remains further research for full acceptance of the new notation by its potential user community.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {1–26},
numpages = {26},
keywords = {Visual syntax evaluation, Software product lines, Feature models}
}

@inproceedings{10.5555/1785246.1785323,
author = {Li, Yi-Yuan and Yin, Jian-wei and Li, Yin and Dong, Jin-Xiang},
title = {Configuration modeling based software product development},
year = {2007},
isbn = {354076836X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product line is an effective way to implement software production for mass customization. How to organize and configure the software artifacts in software product line to rapidly produce customized software product meeting individual demands is one of the key problems. Corresponding to the phases of feature selection and software artifact binding in the process of software production, the feature configuration model and software artifact configuration model are constructed to provide a uniform framework of constraint description for feature model and domain application requirement. The results of problem solving are the sets of feature and software artifact meeting feature constraints and application requirements. The proposed method of configuration modeling and problem solving provide a theoretical foundation to rapidly produce software product on the base of configuration of reusable domain assets.},
booktitle = {Proceedings of the 7th International Conference on Advanced Parallel Processing Technologies},
pages = {624–639},
numpages = {16},
keywords = {software artifact configuration, problem solving, feature configuration, configuration rule},
location = {Guangzhou, China},
series = {APPT'07}
}

@inproceedings{10.1145/1837154.1837157,
author = {Siegmund, Norbert and Feigenspan, Janet and Soffner, Michael and Fruth, Jana and K\"{o}ppen, Veit},
title = {Challenges of secure and reliable data management in heterogeneous environments},
year = {2010},
isbn = {9781605589923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837154.1837157},
doi = {10.1145/1837154.1837157},
abstract = {Ubiquitous computing is getting more important since requirements for complex systems grow fast. In these systems, embedded devices have to fulfill different tasks. They have to monitor the environment, store data, communicate with other devices, and react to user input. In addition to this complexity, quality issues such as security and reliability have to be considered, as well, due to their increasing use in life critical application scenarios. Finally, different devices with different application goals are used, which results in interoperability problems. In this paper, we highlight challenges for interoperability, data management, and security, which arise with complex systems. Furthermore, we present approaches to overcome different problems and how an integrated solution can be realized using software product line techniques.},
booktitle = {Proceedings of the First International Workshop on Digital Engineering},
pages = {17–24},
numpages = {8},
keywords = {software product lines, security, digital engineering, data management},
location = {Magdeburg, Germany},
series = {IWDE '10}
}

@inproceedings{10.1109/ITNG.2010.217,
author = {Dabholka, Akshay and Gokhale, Aniruddha},
title = {Middleware Specialization for Product-Lines Using Feature-Oriented Reverse Engineering},
year = {2010},
isbn = {9780769539843},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ITNG.2010.217},
doi = {10.1109/ITNG.2010.217},
abstract = {Supporting the varied software feature requirements of multiple variants of a software product-line while promoting reuse forces product line engineers to use general-purpose, feature-rich middleware platforms. However, each product variant now incurs memory footprint and performance overhead due to the feature-richness of the middleware along with the increased cost of its testing and maintenance. To address this tension, this paper presents FORMS (Feature-Oriented Reverse Engineering for Mmiddleware Specialization), which is a framework to automatically specialize general-purpose middleware for product-line variants. FORMS provides a novel model-based approach to map product-line variant-specific feature requirements to middleware specific features, which in turn are used to reverse engineer middleware source code and transform it to specialized forms resulting in vertical decompositions. Empirical results evaluating memory footprint reductions (40%) are presented along with qualitative evaluations of reduced maintenance efforts and an assessment of discrepancies in modularization of contemporary middleware.},
booktitle = {Proceedings of the 2010 Seventh International Conference on Information Technology: New Generations},
pages = {696–701},
numpages = {6},
keywords = {Specialization, Reverse Engineering, Product-line, Middleware, Footprint, Feature Oriented Programming, Closure},
series = {ITNG '10}
}

@inproceedings{10.5555/645547.658835,
author = {Dobrica, Liliana and Niemel\"{a}, Eila},
title = {Software Architecture Quality Analysis Methods},
year = {2002},
isbn = {3540434836},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The open problem of structural methods is how to take a better advantage of software architectural concepts to analyse software systems for quality attributes in a systematic and repetitive way. Throughout the presentation we try to introduce a way of thinking founded on analysis at the architecture level of the quality attributes with the purpose to initiate and maintain a software product-line considering the quality as the main driver in product line development. This tutorial represents a study that shows the state of the research at this moment, in the quality analysis methods for software architectures, by presenting and discussing the most representative architecture analysis methods. The role of the discussion is to offer guidelines related to the use of the most suitable method for an architecture assessment process.},
booktitle = {Proceedings of the 7th International Conference on Software Reuse: Methods, Techniques, and Tools},
pages = {337–338},
numpages = {2},
series = {ICSR-7}
}

@inproceedings{10.1145/2642937.2642939,
author = {Segura, Sergio and S\'{a}nchez, Ana B. and Ruiz-Cort\'{e}s, Antonio},
title = {Automated variability analysis and testing of an E-commerce site.: an experience report},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2642939},
doi = {10.1145/2642937.2642939},
abstract = {In this paper, we report on our experience on the development of La Hilandera, an e-commerce site selling haberdashery products and craft supplies in Europe. The store has a huge input space where customers can place almost three millions of different orders which made testing an extremely difficult task. To address the challenge, we explored the applicability of some of the practices for variability management in software product lines. First, we used a feature model to represent the store input space which provided us with a variability view easy to understand, share and discuss with all the stakeholders. Second, we used techniques for the automated analysis of feature models for the detection and repair of inconsistent and missing configuration settings. Finally, we used test selection and prioritization techniques for the generation of a manageable and effective set of test cases. Our findings, summarized in a set of lessons learnt, suggest that variability techniques could successfully address many of the challenges found when developing e-commerce sites.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {139–150},
numpages = {12},
keywords = {variability, feature modelling, experience report, e-commerce, automated testing},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@inproceedings{10.1145/3324884.3416620,
author = {Dorn, Johannes and Apel, Sven and Siegmund, Norbert},
title = {Mastering uncertainty in performance estimations of configurable software systems},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416620},
doi = {10.1145/3324884.3416620},
abstract = {Understanding the influence of configuration options on performance is key for finding optimal system configurations, system understanding, and performance debugging. In prior research, a number of performance-influence modeling approaches have been proposed, which model a configuration option's influence and a configuration's performance as a scalar value. However, these point estimates falsely imply a certainty regarding an option's influence that neglects several sources of uncertainty within the assessment process, such as (1) measurement bias, (2) model representation and learning process, and (3) incomplete data. This leads to the situation that different approaches and even different learning runs assign different scalar performance values to options and interactions among them. The true influence is uncertain, though. There is no way to quantify this uncertainty with state-of-the-art performance modeling approaches. We propose a novel approach, P4, based on probabilistic programming that explicitly models uncertainty for option influences and consequently provides a confidence interval for each prediction of a configuration's performance alongside a scalar. This way, we can explain, for the first time, why predictions may cause errors and which option's influences may be unreliable. An evaluation on 12 real-world subject systems shows that P4's accuracy is in line with the state of the art while providing reliable confidence intervals, in addition to scalar predictions.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {684–696},
numpages = {13},
keywords = {P4, configurable software systems, performance-influence modeling, probabilistic programming},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.4018/ijswis.2014010103,
author = {Ermilov, Timofey and Khalili, Ali and Auer, S\"{o}ren},
title = {Ubiquitous Semantic Applications: A Systematic Literature Review},
year = {2014},
issue_date = {January 2014},
publisher = {IGI Global},
address = {USA},
volume = {10},
number = {1},
issn = {1552-6283},
url = {https://doi.org/10.4018/ijswis.2014010103},
doi = {10.4018/ijswis.2014010103},
abstract = {Recently practical approaches for development of ubiquitous semantic applications have made quite some progress. In particular in the area of the ubiquitous access to the semantic data the authors recently observed a large number of approaches, systems and applications being described in the literature. With this survey the authors aim to provide an overview on the rapidly emerging field of Ubiquitous Semantic Applications (UbiSA). The authors conducted a systematic literature review comprising a thorough analysis of 48 primary studies out of 172 initially retrieved papers. The authors obtained a comprehensive set of quality attributes for UbiSA together with corresponding application features suggested for their realization. The quality attributes include aspects such as mobility, usability, heterogeneity, collaboration, customizability and evolvability. The primary studies were surveyed in the light of these quality attributes and the authors performed a thorough analysis of five ubiquitous semantic applications, six frameworks for UbiSA, three UbiSA specific ontologies, five ubiquitous semantic systems and nine general approaches. The proposed quality attributes facilitate the evaluation of existing approaches and the development of novel, more effective and intuitive UbiSA.},
journal = {Int. J. Semant. Web Inf. Syst.},
month = jan,
pages = {66–99},
numpages = {34},
keywords = {Web Applications, Ubiquitous Device, Ubiquitous Applications, Survey, Semantic Web}
}

@inproceedings{10.1109/ICSE.2019.00112,
author = {Kaltenecker, Christian and Grebhahn, Alexander and Siegmund, Norbert and Guo, Jianmei and Apel, Sven},
title = {Distance-based sampling of software configuration spaces},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00112},
doi = {10.1109/ICSE.2019.00112},
abstract = {Configurable software systems provide a multitude of configuration options to adjust and optimize their functional and non-functional properties. For instance, to find the fastest configuration for a given setting, a brute-force strategy measures the performance of all configurations, which is typically intractable. Addressing this challenge, state-of-the-art strategies rely on machine learning, analyzing only a few configurations (i.e., a sample set) to predict the performance of other configurations. However, to obtain accurate performance predictions, a representative sample set of configurations is required. Addressing this task, different sampling strategies have been proposed, which come with different advantages (e.g., covering the configuration space systematically) and disadvantages (e.g., the need to enumerate all configurations). In our experiments, we found that most sampling strategies do not achieve a good coverage of the configuration space with respect to covering relevant performance values. That is, they miss important configurations with distinct performance behavior. Based on this observation, we devise a new sampling strategy, called distance-based sampling, that is based on a distance metric and a probability distribution to spread the configurations of the sample set according to a given probability distribution across the configuration space. This way, we cover different kinds of interactions among configuration options in the sample set. To demonstrate the merits of distance-based sampling, we compare it to state-of-the-art sampling strategies, such as t-wise sampling, on 10 real-world configurable software systems. Our results show that distance-based sampling leads to more accurate performance models for medium to large sample sets.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {1084–1094},
numpages = {11},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1007/11741060_6,
author = {Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang and Spinczyk, Olaf},
title = {The design of application-tailorable operating system product lines},
year = {2005},
isbn = {3540336893},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11741060_6},
doi = {10.1007/11741060_6},
abstract = {System software for deeply embedded devices has to cope with a broad variety of requirements and platforms, but especially with strict resource constraints. To compete against proprietary systems (and thereby to facilitate reuse), an operating system product line for deeply embedded systems has to be highly configurable and tailorable. It is therefore crucial that all selectable and configurable features can be encapsulated into fine-grained, exchangeable and reusable implementation components. However, the encapsulation of non-functional properties is often limited, due to their cross-cutting character. Fundamental system policies, like synchronization or activation points for the scheduler, have typically to be reflected in many points of the operating system component code. The presented approach is based on feature modeling, C++ class composition and overcomes the above mentioned problems by means of aspect-oriented programming (AOP). It facilitates a fine-grained encapsulation and configuration of even non-functional properties in system software.},
booktitle = {Proceedings of the Second International Conference on Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
pages = {99–117},
numpages = {19},
location = {Nice, France},
series = {CASSIS'05}
}

@article{10.1109/TSE.2002.1019479,
author = {Dobrica, Liliana and Niemel\"{a}, Eila},
title = {A survey on software architecture analysis methods},
year = {2002},
issue_date = {July 2002},
publisher = {IEEE Press},
volume = {28},
number = {7},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2002.1019479},
doi = {10.1109/TSE.2002.1019479},
abstract = {The purpose of the architecture evaluation of a software system is to analyze the architecture to identify potential risks and to verify that the quality requirements have been addressed in the design. This survey shows the state of the research at this moment, in this domain, by presenting and discussing eight of the most representative architecture analysis methods. The selection of the studied methods tries to cover as many particular views of objective reflections as possible to be derived from the general goal. The role of the discussion is to offer guidelines related to the use of the most suitable method for an architecture assessment process. We will concentrate on discovering similarities and differences between these eight available methods by making classifications, comparision and appropriateness studies.},
journal = {IEEE Trans. Softw. Eng.},
month = jul,
pages = {638–653},
numpages = {16},
keywords = {software architecture, scenarios, quality attributes, analysis techniques and methods}
}

@article{10.1007/s11219-015-9273-7,
author = {Grbac, Tihana Galinac and Runeson, Per and Huljeni\'{c}, Darko},
title = {A quantitative analysis of the unit verification perspective on fault distributions in complex software systems: an operational replication},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9273-7},
doi = {10.1007/s11219-015-9273-7},
abstract = {Unit verification, including software inspections and unit tests, is usually the first code verification phase in the software development process. However, principles of unit verification are weakly explored, mostly due to the lack of data, since unit verification data are rarely systematically collected and only a few studies have been published with such data from industry. Therefore, we explore the theory of fault distributions, originating in the quantitative analysis by Fenton and Ohlsson, in the weakly explored context of unit verification in large-scale software development. We conduct a quantitative case study on a sequence of four development projects on consecutive releases of the same complex software product line system for telecommunication exchanges. We replicate the operationalization from earlier studies, analyzed hypotheses related to the Pareto principle of fault distribution, persistence of faults, effects of module size, and quality in terms of fault densities, however, now from the perspective of unit verification. The patterns in unit verification results resemble those of later verification phases, e.g., regarding the Pareto principle, and may thus be used for prediction and planning purposes. Using unit verification results as predictors may improve the quality and efficiency of software verification.},
journal = {Software Quality Journal},
month = dec,
pages = {967–995},
numpages = {29},
keywords = {Unit verification, Software metrics, Software fault distributions, Replication, Empirical research}
}

@inproceedings{10.5555/1758398.1758458,
author = {Zhang, Hongyu and Jarzabek, Stan and Yang, Bo},
title = {Quality prediction and assessment for product lines},
year = {2003},
isbn = {3540404422},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In recent years, software product lines have emerged as a promising approach to improve software development productivity in IT industry. In the product line approach, we identify both commonalities and variabilities in a domain, and build generic assets for an organization. Feature diagrams are often used to model common and variant product line requirements and can be considered part of the organizational assets. Despite their importance, quality attributes (or non-functional requirements, NFRs) such as performance and security have not been sufficiently addressed in product line development. A feature diagram alone does not tell us how to select a configuration of variants to achieve desired quality attributes of a product line member. There is a lack of an explicit model that can represent the impact of variants on quality attributes. In this paper, we propose a Bayesian Belief Network (BBN) based approach to quality prediction and assessment for a software product line. A BBN represents domain experts' knowledge and experiences accumulated from the development of similar projects. It helps us capture the impact of variants on quality attributes, and helps us predict and assess the quality of a product line member by performing quantitative analysis over it. For developing specific systems, members of a product line, we reuse the expertise captured by a BBN instead of working from scratch. We use examples from the Computer Aided Dispatch (CAD) product line project to illustrate our approach.},
booktitle = {Proceedings of the 15th International Conference on Advanced Information Systems Engineering},
pages = {681–695},
numpages = {15},
location = {Klagenfurt, Austria},
series = {CAiSE'03}
}

@article{10.1007/s10270-017-0641-6,
author = {Li, Yan and Yue, Tao and Ali, Shaukat and Zhang, Li},
title = {Enabling automated requirements reuse and configuration},
year = {2019},
issue_date = {June      2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0641-6},
doi = {10.1007/s10270-017-0641-6},
abstract = {A system product line (PL) often has a large number of reusable and configurable requirements, which in practice are organized hierarchically based on the architecture of the PL. However, the current literature lacks approaches that can help practitioners to systematically and automatically develop structured and configuration-ready PL requirements repositories. In the context of product line engineering and model-based engineering, automatic requirements structuring can benefit from models. Such a structured PL requirements repository can greatly facilitate the development of product-specific requirements repository, the product configuration at the requirements level, and the smooth transition to downstream product configuration phases (e.g., at the architecture design phase). In this paper, we propose a methodology with tool support, named as Zen-ReqConfig, to tackle the above challenge. Zen-ReqConfig is built on existing model-based technologies, natural language processing, and similarity measure techniques. It automatically devises a hierarchical structure for a PL requirements repository, automatically identifies variabilities in textual requirements, and facilitates the configuration of products at the requirements level, based on two types of variability modeling techniques [i.e., cardinality-based feature modeling (CBFM) and a UML-based variability modeling methodology (named as SimPL)]. We evaluated Zen-ReqConfig with five case studies. Results show that Zen-ReqConfig can achieve a better performance based on the character-based similarity measure Jaro than the term-based similarity measure Jaccard. With Jaro, Zen-ReqConfig can allocate textual requirements with high precision and recall, both over 95% on average and identify variabilities in textual requirements with high precision (over 97% on average) and recall (over 94% on average). Zen-ReqConfig achieved very good time performance: with less than a second for generating a hierarchical structure and less than 2 s on average for allocating a requirement. When comparing SimPL and CBFM, no practically significant difference was observed, and they both performed well when integrated with Zen-ReqConfig.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {2177–2211},
numpages = {35},
keywords = {Reuse, Requirements, Product line, Feature model, Configuration}
}

@article{10.1016/j.specom.2021.06.001,
author = {Akbarzadeh, Sara and Lee, Sungmin and Chen, Fei and Tan, Chin-Tuan},
title = {The effect of speech and noise levels on the quality perceived by cochlear implant and normal hearing listeners},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0167-6393},
url = {https://doi.org/10.1016/j.specom.2021.06.001},
doi = {10.1016/j.specom.2021.06.001},
journal = {Speech Commun.},
month = sep,
pages = {106–113},
numpages = {8},
keywords = {SNR, NR, SPL, CI, NH, Sound quality perception, Noise level, Speech level, Cochlear implant}
}

@inproceedings{10.1145/2168697.2168699,
author = {Quinton, Cl\'{e}ment and Rouvoy, Romain and Duchien, Laurence},
title = {Leveraging feature models to configure virtual appliances},
year = {2012},
isbn = {9781450311618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168697.2168699},
doi = {10.1145/2168697.2168699},
abstract = {Cloud computing is a major trend in distributed computing environments. Software virtualization technologies allow cloud Infrastructure-as-a-Service (IaaS) providers to instantiate and run a large number of virtual appliances. However, one of the major challenges is to reduce the disk space footprint of such virtual appliances to improve their storage and transfer across cloud servers. In this paper, we propose to use a Software Product Line (SPL) approach and describe the virtual appliance as a set of common and variable elements modeled by means of Feature Model (FM). We describe a solution to reverse engineer a FM from a virtual appliance and we show how we take advantage of the SPL configuration mechanisms to significantly reduce the size of a virtual appliance.},
booktitle = {Proceedings of the 2nd International Workshop on Cloud Computing Platforms},
articleno = {2},
numpages = {6},
location = {Bern, Switzerland},
series = {CloudCP '12}
}

@inproceedings{10.5555/1885639.1885651,
author = {Nolan, Andy J. and Abrah\~{a}o, Silvia},
title = {Dealing with cost estimation in software product lines: experiences and future directions},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {After 5 years invested in developing accurate cost estimation tools, Rolls-Royce has learnt about the larger potential of the tools to shape many aspects of the business. A good estimation tool is a "model" of a project and is usually used to estimate cost and schedule, but it can also estimate and validate risks and opportunities. Estimation tools have unified engineering, project and business needs. The presence of good estimation tools has driven higher performance and stability in the business. It was evident we needed this capability to underpin decisions in our new Software Product Line strategy. The objective of this paper is twofold. First, we report the experiences gained in the past on the use of estimation tools. Second, we describe the current efforts and future directions on the development of an estimation tool for Software Product Lines. At the heart of the Product Line estimation tool is a simple representation of the product - represented as the number of Lines Of Code (LOC). The next generation of tool, will need to consider wider aspects of product quality in order to create more accurate estimates and support better decisions about our products.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {121–135},
numpages = {15},
keywords = {software product lines, industrial experiences, cost estimation},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1007/978-3-642-34707-8_16,
author = {Chuong, Dang Thanh and Loi, Vu Duy and Nhat, Vo Viet Minh},
title = {A model for the performance analysis of SPL-OBS core nodes with deflection routing},
year = {2012},
isbn = {9783642347061},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34707-8_16},
doi = {10.1007/978-3-642-34707-8_16},
abstract = {In optical burst switching networks, techniques like wavelength conversion, optical buffer or deflection routing are often applied to resolve a contention problem that may cause data loss. Instead of the planned output port, the contended burst is sent to a new output port, on a new path to its destination by the deflection routing. In the case of wavelength conversion, the arriving burst is conveyed on a new available wavelength, but only partial wavelength conversion is available due to the technology constraint. This article considers a model for the performance evaluation of OBS core nodes with the Share-Per-Link(SPL) architecture where partial wavelength converters are distributed at each output port. A continuous-time Markov chain model is proposed to analyze the performance of OBS core nodes operated with the deflection routing rule.},
booktitle = {Proceedings of the 4th International Conference on Computational Collective Intelligence: Technologies and Applications - Volume Part II},
pages = {152–161},
numpages = {10},
keywords = {state transition rate matrix, deflection probability, continuous-time Markov chain, blocking probability, OBS node},
location = {Ho Chi Minh City, Vietnam},
series = {ICCCI'12}
}

@inproceedings{10.1109/ASE.2011.6100096,
author = {Oster, Zachary J. and Santhanam, Ganesh Ram and Basu, Samik},
title = {Automating analysis of qualitative preferences in goal-oriented requirements engineering},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100096},
doi = {10.1109/ASE.2011.6100096},
abstract = {In goal-oriented requirements engineering, a goal model graphically represents relationships between the required goals (functional requirements), tasks (realizations of goals), and optional goals (non-functional properties) involved in designing a system. It may, however, be impossible to find a design that fulfills all required goals and all optional goals. In such cases, it is useful to find designs that provide the required functionality while satisfying the most preferred set of optional goals under the goal model's constraints. We present an approach that considers expressive qualitative preferences over optional goals, as these can model interacting and/or mutually exclusive subgoals. Our framework employs a model checking-based method for reasoning with qualitative preferences to identify the most preferred alternative(s). We evaluate our approach using existing goal models from the literature.},
booktitle = {Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {448–451},
numpages = {4},
series = {ASE '11}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {regularization, configurable systems, adversarial learning, Software performance prediction},
location = {Bari, Italy},
series = {ESEM '20}
}

@article{10.1145/3011286.3011291,
author = {Galster, Matthias and Zdun, Uwe and Weyns, Danny and Rabiser, Rick and Zhang, Bo and Goedicke, Michael and Perrouin, Gilles},
title = {Variability and Complexity in Software Design: Towards a Research Agenda},
year = {2017},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/3011286.3011291},
doi = {10.1145/3011286.3011291},
abstract = {Many of today's software systems accommodate different usage and deployment scenarios. Intentional and unintentional variability in functionality or quality attributes (e.g., performance) of software significantly increases the complexity of the problem and design space of those systems. The complexity caused by variability becomes increasingly difficult to handle due to the increasing size of software systems, new and emerging application domains, dynamic operating conditions under which software systems have to operate, fast moving and highly competitive markets, and more powerful and versatile hardware. This paper reports results of the first International Workshop on Variability and Complexity in Software Design that brought together researchers and engineers interested in the topic of complexity and variability. It also outlines directions the field might move in the future},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {27–30},
numpages = {4},
keywords = {software design, complexity, Variability}
}

@inproceedings{10.1007/978-3-642-54804-8_1,
author = {Baier, Christel and Dubslaff, Clemens and Kl\"{u}ppelholz, Sascha and Daum, Marcus and Klein, Joachim and M\"{a}rcker, Steffen and Wunderlich, Sascha},
title = {Probabilistic Model Checking and Non-standard Multi-objective Reasoning},
year = {2014},
isbn = {9783642548031},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-54804-8_1},
doi = {10.1007/978-3-642-54804-8_1},
abstract = {Probabilistic model checking is a well-established method for the automated quantitative system analysis. It has been used in various application areas such as coordination algorithms for distributed systems, communication and multimedia protocols, biological systems, resilient systems or security. In this paper, we report on the experiences we made in inter-disciplinary research projects where we contribute with formal methods for the analysis of hardware and software systems. Many performance measures that have been identified as highly relevant by the respective domain experts refer to multiple objectives and require a good balance between two or more cost or reward functions, such as energy and utility. The formalization of these performance measures requires several concepts like quantiles, conditional probabilities and expectations and ratios of cost or reward functions that are not supported by state-ofthe- art probabilistic model checkers. We report on our current work in this direction, including applications in the field of software product line verification.},
booktitle = {Proceedings of the 17th International Conference on Fundamental Approaches to Software Engineering - Volume 8411},
pages = {1–16},
numpages = {16}
}

@article{10.1016/j.jss.2014.12.041,
author = {Pascual, Gustavo G. and Lopez-Herrejon, Roberto E. and Pinto, M\'{o}nica and Fuentes, Lidia and Egyed, Alexander},
title = {Applying multiobjective evolutionary algorithms to dynamic software product lines for reconfiguring mobile applications},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {103},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.12.041},
doi = {10.1016/j.jss.2014.12.041},
abstract = {Mobile applications require to self-adapt their behavior to context changes.We propose a DSPL approach to manage variability at runtime.Configurations are generated using multiobjective evolutionary algorithms.We apply a fix operator to generate only valid configurations at runtime.We demonstrate that this approach is suitable for mobile environments. Mobile applications require dynamic reconfiguration services (DRS) to self-adapt their behavior to the context changes (e.g., scarcity of resources). Dynamic Software Product Lines (DSPL) are a well-accepted approach to manage runtime variability, by means of late binding the variation points at runtime. During the system's execution, the DRS deploys different configurations to satisfy the changing requirements according to a multiobjective criterion (e.g., insufficient battery level, requested quality of service). Search-based software engineering and, in particular, multiobjective evolutionary algorithms (MOEAs), can generate valid configurations of a DSPL at runtime. Several approaches use MOEAs to generate optimum configurations of a Software Product Line, but none of them consider DSPLs for mobile devices. In this paper, we explore the use of MOEAs to generate at runtime optimum configurations of the DSPL according to different criteria. The optimization problem is formalized in terms of a Feature Model (FM), a variability model. We evaluate six existing MOEAs by applying them to 12 different FMs, optimizing three different objectives (usability, battery consumption and memory footprint). The results are discussed according to the particular requirements of a DRS for mobile applications, showing that PAES and NSGA-II are the most suitable algorithms for mobile environments.},
journal = {J. Syst. Softw.},
month = may,
pages = {392–411},
numpages = {20},
keywords = {Evolutionary algorithms, Dynamic reconfiguration, DSPL}
}

@inproceedings{10.1109/SEAMS.2007.13,
author = {Gomaa, Hassan and Hussein, Mohamed},
title = {Model-Based Software Design and Adaptation},
year = {2007},
isbn = {0769529739},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAMS.2007.13},
doi = {10.1109/SEAMS.2007.13},
abstract = {This paper describes a modeling approach to software design and adaptation, in particular the design of evolutionary and dynamically reconfigurable software architectures. The different versions of an evolutionary system are considered a software product line, with each version of the system a product line member. After implementation, the model co-exists with the system and evolves with it. The software architecture is built out of architectural patterns. For each software architectural pattern, there is a corresponding software reconfiguration pattern, which describes how the software architecture can be dynamically adapted.},
booktitle = {Proceedings of the 2007 International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
pages = {7},
series = {SEAMS '07}
}

@inproceedings{10.5555/2050167.2050171,
author = {Nunes, Ingrid and Cowan, Donald and Cirilo, Elder and De Lucena, Carlos J. P.},
title = {A case for new directions in agent-oriented software engineering},
year = {2010},
isbn = {9783642226359},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The state-of-the-art of Agent-oriented Software Engineering (AOSE) is insufficiently reflected in the state-of-practice in developing complex distributed systems. This paper discusses software engineering (SE) areas that have not been widely addressed in the context of AOSE, leading to a lack of mechanisms that support the development of Multiagent Systems (MASs) based on traditional SE principles, such as modularity, reusability and maintainability. This discussion is based on an exploratory study of the development of a family of buyer agents following the belief-desire-intention model and using a Software Product Line architecture. Based on the discussion presented in this paper, we hope to encourage the AOSE community to address particular SE issues on the development of MAS that have not yet been (widely) considered.},
booktitle = {Proceedings of the 11th International Conference on Agent-Oriented Software Engineering},
pages = {37–61},
numpages = {25},
keywords = {software reuse, software product lines, software architectures, multi-agent systems, agent-oriented software engineering},
location = {Toronto, Canada},
series = {AOSE'10}
}

@inproceedings{10.1007/978-3-642-37422-7_26,
author = {Adam, Sebastian and Schmid, Klaus},
title = {Effective requirements elicitation in product line application engineering: an experiment},
year = {2013},
isbn = {9783642374210},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-37422-7_26},
doi = {10.1007/978-3-642-37422-7_26},
abstract = {[Context &amp; Motivation] Developing new software systems based on a software product line (SPL) is still a time-consuming task and the benefits of using such an approach are often smaller than expected. One important reason for this are difficulties in systematically mapping customer requirements to characteristics of the SPL. [Question/problem] Even though it has been recognized that the success of reuse strongly depends on how requirements are treated, it remains unclear how to perform this in an optimal way. [Principal ideas/results] In this paper, we present a controlled experiment performed with 26 students that compared two requirements elicitation approaches when instantiating a given SPL. [Contribution] Our findings indicate that a novel, problem-oriented requirements approach that explicitly integrates the reuse of SPL requirements into the elicitation of customer-specific requirements is more effective than a traditional SPL requirements approach, which distinguishes requirements reuse and additional elicitation customer-specific requirements.},
booktitle = {Proceedings of the 19th International Conference on Requirements Engineering: Foundation for Software Quality},
pages = {362–378},
numpages = {17},
location = {Essen, Germany},
series = {REFSQ'13}
}

@inproceedings{10.5555/2337223.2337468,
author = {Colanzi, Thelma Elita},
title = {Search based design of software product lines architectures},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {The Product-Line Architecture (PLA) is the main artifact of a Software Product Line (SPL). However, obtaining a modular, extensible and reusable PLA is a people-intensive and non-trivial task, related to different and possible conflicting factors. Hence, the PLA design is a hard problem and to find the best architecture can be formulated as an optimization problem with many factors. Similar Software Engineering problems have been efficiently solved by search-based algorithms in the field known as Search-based Software Engineering. The existing approaches used to optimize software architecture are not suitable since they do not encompass specific characteristics of SPL. To easy the SPL development and to automate the PLA design this work introduces a multi-objective optimization approach to the PLA design. The approach is now being implemented by using evolutionary algorithms. Empirical studies will be performed to validate the neighborhood operators, SPL measures and search algorithms chosen. Finally, we intend to compare the results of the proposed approach with PLAs designed by human architects.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {1507–1510},
numpages = {4},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1007/978-3-642-34327-8_33,
author = {Brugali, Davide and Gherardi, Luca and Biziak, A. and Luzzana, Andrea and Zakharov, Alexey},
title = {A reuse-oriented development process for component-based robotic systems},
year = {2012},
isbn = {9783642343261},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34327-8_33},
doi = {10.1007/978-3-642-34327-8_33},
abstract = {State of the art in robot software development mostly relies on class library reuse and only to a limited extent to component-based design. In the BRICS project we have defined a software development process that is based on the two most recent and promising approaches to software reuse, i.e. Software Product Line (SPL) and Model-Driven Engineering (MDE). The aim of this paper is to illustrate the whole software development process that we have defined for developing flexible and reusable component-based robotics libraries, to exemplify it with the case study of robust navigation functionality, and to present the software tools that we have developed for supporting the proposed process.},
booktitle = {Proceedings of the Third International Conference on Simulation, Modeling, and Programming for Autonomous Robots},
pages = {361–374},
numpages = {14},
location = {Tsukuba, Japan},
series = {SIMPAR'12}
}

@article{10.1016/j.eswa.2013.12.028,
author = {Segura, Sergio and Parejo, Jos\'{e} A. and Hierons, Robert M. and Benavides, David and Ruiz-Cort\'{e}s, Antonio},
title = {Automated generation of computationally hard feature models using evolutionary algorithms},
year = {2014},
issue_date = {June, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {8},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2013.12.028},
doi = {10.1016/j.eswa.2013.12.028},
abstract = {A feature model is a compact representation of the products of a software product line. The automated extraction of information from feature models is a thriving topic involving numerous analysis operations, techniques and tools. Performance evaluations in this domain mainly rely on the use of random feature models. However, these only provide a rough idea of the behaviour of the tools with average problems and are not sufficient to reveal their real strengths and weaknesses. In this article, we propose to model the problem of finding computationally hard feature models as an optimization problem and we solve it using a novel evolutionary algorithm for optimized feature models (ETHOM). Given a tool and an analysis operation, ETHOM generates input models of a predefined size maximizing aspects such as the execution time or the memory consumption of the tool when performing the operation over the model. This allows users and developers to know the performance of tools in pessimistic cases providing a better idea of their real power and revealing performance bugs. Experiments using ETHOM on a number of analyses and tools have successfully identified models producing much longer executions times and higher memory consumption than those obtained with random models of identical or even larger size.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {3975–3992},
numpages = {18},
keywords = {Software product lines, Search-based testing, Performance testing, Feature models, Evolutionary algorithms, Automated analysis}
}

@article{10.1007/s10515-015-0185-3,
author = {B\"{u}rdek, Johannes and Kehrer, Timo and Lochau, Malte and Reuling, Dennis and Kelter, Udo and Sch\"{u}rr, Andy},
title = {Reasoning about product-line evolution using complex feature model differences},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0185-3},
doi = {10.1007/s10515-015-0185-3},
abstract = {Features define common and variable parts of the members of a (software) product line. Feature models are used to specify the set of all valid feature combinations. Feature models not only enjoy an intuitive tree-like graphical syntax, but also a precise formal semantics, which can be denoted as propositional formulae over Boolean feature variables. A product line usually constitutes a long-term investment and, therefore, has to undergo continuous evolution to meet ever-changing requirements. First of all, product-line evolution leads to changes of the feature model due to its central role in the product-line paradigm. As a result, product-line engineers are often faced with the problems that (1) feature models are changed in an ad-hoc manner without proper documentation, and (2) the semantic impact of feature diagram changes is unclear. In this article, we propose a comprehensive approach to tackle both challenges. For (1), our approach compares the old and new version of the diagram representation of a feature model and specifies the changes using complex edit operations on feature diagrams. In this way, feature model changes are automatically detected and formally documented. For (2), we propose an approach for reasoning about the semantic impact of diagram changes. We present a set of edit operations on feature diagrams, where complex operations are primarily derived from evolution scenarios observed in a real-world case study, i.e., a product line from the automation engineering domain. We evaluated our approach to demonstrate its applicability with respect to the case study, as well as its scalability concerning experimental data sets.},
journal = {Automated Software Engg.},
month = dec,
pages = {687–733},
numpages = {47},
keywords = {Software product lines, Software evolution, Model-driven engineering, Feature models}
}

@inproceedings{10.1145/1454268.1454275,
author = {Bertoncello, Ivo Augusto and Dias, Marcelo Oliveira and Brito, Patrick H. S. and Rubira, Cec\'{\i}lia M. F.},
title = {Explicit exception handling variability in component-based product line architectures},
year = {2008},
isbn = {9781605582290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1454268.1454275},
doi = {10.1145/1454268.1454275},
abstract = {Separation of concerns is one of the overarching goals of exception handling in order to keep separate normal and exceptional behaviour of a software system. In the context of a software product line (SPL), this separation of concerns is also important for designing software variabilities related to different exception handling strategies, such as the choice of different handlers depending on the set of selected features. This paper presents a method for refactoring object-oriented product line architecture in order to separate explicitly their normal and exceptional behaviour into different software components. The new component-based software architecture includes variation points related to different choices of exception handlers that can be selected during product instantiations, thus facilitating the evolution of the exceptional behaviour. The feasibility of the proposed approach is assessed through a SPL of mobile applications.},
booktitle = {Proceedings of the 4th International Workshop on Exception Handling},
pages = {47–54},
numpages = {8},
keywords = {software architecture, exceptional behaviour, exception handling, component-based software development},
location = {Atlanta, Georgia},
series = {WEH '08}
}

@inproceedings{10.5555/318773.319262,
author = {Bayer, Joachim and Girard, Jean-Fran\c{c}ois and W\"{u}rthner, Martin and DeBaud, Jean-Marc and Apel, Martin},
title = {Transitioning legacy assets to a product line architecture},
year = {1999},
isbn = {3540665382},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A successful software system evolves over time, but this evolution often occurs in an ad-hoc fashion. One approach to structure system evolution is the concept of software product lines where a core architecture supports a variety of application contexts. However, in practice, the high cost and high risks of redevelopment as well as the substantial investments made to develop the existing systems most often mandate significant leverage of the legacy assets. Yet, there is little guidance in the literature on how to transition legacy assets into a product line set-up.In this paper, we present RE-PLACE, an approach developed to support the transition of existing software assets towards a product line architecture while taking into account anticipated new system variants. We illustrate this approach with its application in an industrial setting.},
booktitle = {Proceedings of the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {446–463},
numpages = {18},
keywords = {software product line, reuse, reengineering, domain-specific software architecture, architecture recovery},
location = {Toulouse, France},
series = {ESEC/FSE-7}
}

@inproceedings{10.1145/581339.581416,
author = {Bratthall, Lars G. and van der Geest, Robert and Hofmann, Holger and Jellum, Edgar and Korendo, Zbigniew and Martinez, Robert and Orkisz, Michal and Zeidler, Christian and Andersson, Johan S},
title = {Integrating hundred's of products through one architecture: the industrial IT architecture},
year = {2002},
isbn = {158113472X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/581339.581416},
doi = {10.1145/581339.581416},
abstract = {During the last few years, software product line engineering has gained significant interest as a way for creating software products faster and cheaper. But what architecture is needed to integrate huge amounts of products, from different product lines? This paper describes such an architecture and its support processes and tools. Through cases, it is illustrated how the architecture is used to integrate new --- and old --- products in such diverse integration projects as vessel motion control, airport baggage handling systems, pulp&amp;paper and oil&amp;gas, in a very large organization. However, in a large organization it is a challenge to make everyone follow an architecture. Steps taken to ensure global architectural consistency are presented. It is concluded that a single architecture can be used to unify development in a huge organization, where the distributed development practices otherwise may prohibit integration of various products.},
booktitle = {Proceedings of the 24th International Conference on Software Engineering},
pages = {604–614},
numpages = {11},
location = {Orlando, Florida},
series = {ICSE '02}
}

@inproceedings{10.1007/11424758_6,
author = {Kim, Soo Dong and Chang, Soo Ho and La, Hyun Jung},
title = {A systematic process to design product line architecture},
year = {2005},
isbn = {3540258604},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11424758_6},
doi = {10.1007/11424758_6},
abstract = {Product Line Engineering is being accepted as a representative software reuse methodology by using core assets and product line architecture is known as a key element of core assets. However, current research on product line engineering has room to provide specific and detailed guidelines of designing product line architectures and reflecting variability in the architecture. In this paper, we present a reference model and a process to design the architecture with detailed instructions. Especially architectural variability is codified by describing decision model representing variation.},
booktitle = {Proceedings of the 2005 International Conference on Computational Science and Its Applications - Volume Part I},
pages = {46–56},
numpages = {11},
location = {Singapore},
series = {ICCSA'05}
}

@article{10.1007/s10586-018-02893-y,
author = {Tarasov, Vasily and Rupprecht, Lukas and Skourtis, Dimitris and Li, Wenji and Rangaswami, Raju and Zhao, Ming},
title = {Evaluating Docker storage performance: from workloads to graph drivers},
year = {2019},
issue_date = {Dec 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {4},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-02893-y},
doi = {10.1007/s10586-018-02893-y},
abstract = {Containers are a widely successful technology today popularized by Docker. They improve system utilization by increasing workload density and enable seamless deployment of workloads across development, test, and production environments. Docker’s unique approach to data management, which involves frequent snapshot creation and removal, presents a new set of exciting challenges for storage systems. At the same time, storage management for Docker containers has remained largely unexplored with a dizzying array of solution choices and configuration options. In this paper we unravel the multi-faceted nature of Docker storage and demonstrate its impact on system and workload performance. As we uncover new properties of the popular Docker storage drivers, this is a sobering reminder that widespread use of new technologies can often precede their careful evaluation.},
journal = {Cluster Computing},
month = dec,
pages = {1159–1172},
numpages = {14},
keywords = {Performance, Storage, Docker, Containers}
}

@inproceedings{10.1145/3180155.3180163,
author = {Guo, Jianmei and Shi, Kai},
title = {To preserve or not to preserve invalid solutions in search-based software engineering: a case study in software product lines},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180163},
doi = {10.1145/3180155.3180163},
abstract = {Multi-objective evolutionary algorithms (MOEAs) have been successfully applied for software product lines (SPLs) to search for optimal or near-optimal solutions that balance multiple objectives. However, MOEAs usually produce invalid solutions that violate the constraints predefined. As invalid solutions are unbuildable in practice, we debate the preservation of invalid solutions during the search. We conduct experiments on seven real-world SPLs, including five largest SPLs hitherto reported and two SPLs with realistic values and constraints of quality attributes. We identify three potential limitations of preserving invalid solutions. Furthermore, based on the state-of-the-art, we design five algorithm variants that adopt different evolutionary operators. By performance evaluation, we provide empirical guidance on how to preserve valid solutions. Our empirical study demonstrates that whether or not to preserve invalid solutions deserves more attention in the community, and in some cases, we have to preserve valid solutions all along the way.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1027–1038},
numpages = {12},
keywords = {constraint solving, multi-objective evolutionary algorithms, search-based software engineering, software product lines, validity},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2910019.2910101,
author = {Cledou, Guillermina and Barbosa, Lu\'{\i}s Soares},
title = {An Ontology for Licensing Public Transport Services},
year = {2016},
isbn = {9781450336406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2910019.2910101},
doi = {10.1145/2910019.2910101},
abstract = {By 2050 it is expected that 66% of the world population will reside in cities, compared to 54% in 2014. One particular challenge associated to urban population growth refers to transportation systems, and as an approach to face it, governments are investing significant efforts enhancing public transport services. An important aspect of public transport is ensuring that licensing of such services fulfill existing government regulations. Due to the differences in government regulations, and to the difficulties in ensuring the fulfillment of their specific features, many local governments develop tailored Information and Communication Technology (ICT) solutions to automate the licensing of public transport services. In this paper we propose an ontology for licensing such services following the REFSENO methodology. In particular, the ontology captures common concepts involved in the application and processing stage of licensing public bus passenger services. The main contribution of the proposed ontology is to define a common vocabulary to share knowledge between domain experts and software engineers, and to support the definition of a software product line for families of public transport licensing services.},
booktitle = {Proceedings of the 9th International Conference on Theory and Practice of Electronic Governance},
pages = {230–239},
numpages = {10},
keywords = {Software Product Lines, Public Transport Licensing Services, Ontologies},
location = {Montevideo, Uruguay},
series = {ICEGOV '15-16}
}

@inproceedings{10.1145/1944892.1944894,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Th\"{u}m, Thomas and Saake, Gunter},
title = {Multi-dimensional variability modeling},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944894},
doi = {10.1145/1944892.1944894},
abstract = {The variability of a software product line (SPL)is often described with a feature model. To avoid highly complex models, stakeholders usually try to separate different variability dimensions, such as domain variability and implementation variability. This results in distinct variability models, which are easier to handle than one large model. On the other hand, it is sometimes required to analyze the variability dimensions of an SPL in combination using a single model only. To combine separate modeling and integrated analysis of variability, we present Velvet, a language for multi-dimensional variability modeling. Velvet allows stakeholders to model each variability dimension of an SPL separately and to compose the separated dimensions on demand. This improves reuse of feature models and supports independent modeling variability dimensions. Furthermore, Velvet integrates feature modeling and configuration in a single language. The combination of both concepts creates further reuse opportunities and allows stakeholders to independently configure variability dimensions.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {11–20},
numpages = {10},
keywords = {variability modeling, separation of concerns, feature models},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@article{10.1504/IJAOSE.2008.016800,
author = {Verstraete, Paul and Germain, Bart Saint and Valckenaers, Paul and Brussel, Hendrik Van and Belle, Jan Van and Hadeli},
title = {Engineering manufacturing control systems using PROSA and delegate MAS},
year = {2008},
issue_date = {January 2008},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {2},
number = {1},
issn = {1746-1375},
url = {https://doi.org/10.1504/IJAOSE.2008.016800},
doi = {10.1504/IJAOSE.2008.016800},
abstract = {This paper presents a systematic description of a reusable software architecture for multiagent systems in the domain of manufacturing control. The architectural description consolidates the authors' expertise in this area. Until now, the research has taken a manufacturing control perspective of multiagent systems. The research team has focused on providing benefits to the manufacturing control domain by designing a novel type of control system. This paper takes a software architectural perspective of multiagent manufacturing control. The systematic description specifies a software product line architecture for manufacturing control. The paper describes the assets of the software product line architecture and how these assets can be combined.},
journal = {Int. J. Agent-Oriented Softw. Eng.},
month = jan,
pages = {62–89},
numpages = {28},
keywords = {software reuse, software architecture, multi-agent systems, manufacturing control, agent-based systems, MASs}
}

@article{10.1007/s11761-014-0161-y,
author = {Huergo, Rosane S. and Pires, Paulo F. and Delicato, Flavia C. and Costa, Bruno and Cavalcante, Everton and Batista, Thais},
title = {A systematic survey of service identification methods},
year = {2014},
issue_date = {September 2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {8},
number = {3},
issn = {1863-2386},
url = {https://doi.org/10.1007/s11761-014-0161-y},
doi = {10.1007/s11761-014-0161-y},
abstract = {One of the major challenges for the adoption of the service-oriented architecture (SOA) is the service identification phase that aims to determine which services are appropriate to be implemented. In the last decade, several service identification methods (SIMs) were proposed. However, the service identification phase still remains a challenge to organizations due to the lack of systematic methods and comprehensive approaches that support the examination of the businesses from multiple perspectives and consider service quality attributes. This work aims to provide an overview of existing SIMs by detailing which service's perspectives, stated as relevant by the industry, are addressed by the SIMs and also by synthesizing the identification techniques used by them. We have performed a systematic survey over publications about SIMs from 2002 to June 2013, and 105 studies were selected. A detailed investigation on the analyzed SIMs revealed that the identification techniques applied by them have a correlation on how they address many of the service's perspectives. In addition, they are supporting the SOA adoption by handling many perspectives of the OASIS' reference architecture for SOA. However, most of them do not explicitly address service quality attributes and few studies support the evaluation of both. Therefore, future research should follow the direction toward hybrid methods with mechanisms to elicit business and service's quality attributes.},
journal = {Serv. Oriented Comput. Appl.},
month = sep,
pages = {199–219},
numpages = {21},
keywords = {Systematic survey, Service-oriented architecture, Service identification method, SOA, SIM}
}

@inproceedings{10.1145/1944892.1944897,
author = {Gilson, Fabian and Englebert, Vincent},
title = {Towards handling architecture design, variability and evolution with model transformations},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944897},
doi = {10.1145/1944892.1944897},
abstract = {Software systems have to face evolving requirements from information system stakeholders, infrastructure modifications, and evolving rationales about the implementation. This increases the rate of migration and redeployment of systems. Recent approaches intend to abstract architectural element specifications from the implementing technology and manage software design through model transformations. Based on an Architecture Description Language integrating infrastructure modelling facilities and a requirement modelling language, the present work manages architecturally significant requirements and infrastructure evolutions by model transformations. Our approach offers support for evolution and variability management tasks as it makes explicit the rationales concerning requirements, infrastructure and implementation alternatives that guide both the software architecture and the infrastructure definition.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {39–48},
numpages = {10},
keywords = {model transformation, infrastructure constraint, architecture variability, architecture description language, architecturally significant requirement},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/3302333.3302350,
author = {Garc\'{\i}a, Sergio and Str\"{u}ber, Daniel and Brugali, Davide and Di Fava, Alessandro and Schillinger, Philipp and Pelliccione, Patrizio and Berger, Thorsten},
title = {Variability Modeling of Service Robots: Experiences and Challenges},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302350},
doi = {10.1145/3302333.3302350},
abstract = {Sensing, planning, controlling, and reasoning, are human-like capabilities that can be artificially replicated in an autonomous robot. Such a robot implements data structures and algorithms devised on a large spectrum of theories, from probability theory, mechanics, and control theory to ethology, economy, and cognitive sciences. Software plays a key role in the development of robotic systems, as it is the medium to embody intelligence in the machine. During the last years, however, software development is increasingly becoming the bottleneck of robotic systems engineering due to three factors: (a) the software development is mostly based on community efforts and it is not coordinated by key stakeholders; (b) robotic technologies are characterized by a high variability that makes reuse of software a challenging practice; and (c) robotics developers are usually not specifically trained in software engineering. In this paper, we illustrate our experiences from EU, academic, and industrial projects in identifying, modeling, and managing variability in the domain of service robots. We hope to raise awareness for the specific variability challenges in robotics software engineering and to inspire other researchers to advance this field.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {6},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@article{10.1007/s10664-014-9345-5,
author = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud and Liaaen, Marius},
title = {A systematic test case selection methodology for product lines: results and insights from an industrial case study},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9345-5},
doi = {10.1007/s10664-014-9345-5},
abstract = {In the context of product lines, test case selection aims at obtaining a set of relevant test cases for a product from the entire set of test cases available for a product line. While working on a research-based innovation project on automated testing of product lines of Video Conferencing Systems (VCSs) developed by Cisco, we felt the need to devise a cost-effective way of selecting relevant test cases for a product. To fulfill such need, we propose a systematic and automated test selection methodology using: 1) Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line; 2) Component Family Model for Testing (CFM_T) to model the structure of test case repository; 3) A tool to automatically build restrictions from CFM_T to FM_T and traces from CFM_T to the actual test cases. Using our methodology, a test engineer is only required to select relevant features through FM_T at a higher level of abstraction for a product and the corresponding test cases will be obtained automatically. We evaluate our methodology by applying it to a VCS product line called Saturn with seven commercial products and the results show that our methodology can significantly reduce cost measured as test selection time and at the same time achieves higher effectiveness (feature coverage, feature pairwise coverage and fault detection) as compared with the current manual process. Moreover, we conduct a questionnaire-based study to solicit the views of test engineers who are involved in developing FM_T and CFM_T. The results show that test engineers are positive about adapting our methodology in their current practice. Finally, we present a set of lessons learnt while applying product line engineering at Cisco for test case selection.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1586–1622},
numpages = {37},
keywords = {Test case selection, Product line, Feature model, Component family model}
}

@inproceedings{10.5555/1566971.1567004,
author = {Ahmed, Zeeshan},
title = {Measurement Analysis and Fault Proneness Indication in Product Line Applications (PLA)},
year = {2007},
isbn = {9781586037949},
publisher = {IOS Press},
address = {NLD},
abstract = {In this paper we propose an approach to handle the additional level complexity and indicate the rate of increase or decrease of fault proneness in software product line applications. The proposed approach is based on measurement analysis and consisting of three main components.i.e., Analysis, Measurement and Visualisation to dynamically analyse the internal preprocessed source code characteristics, calculate metrics and visualise results in two dimensional diagrams.i.e., graphs, bar chart and tree maps. To evaluate the effectiveness of proposed approach we first implemented it in a real time software application and then performed experimentation using some real time data sets. Narrowing the scope of our research, we only focus on analysing software product line applications developed in C++ programming language.},
booktitle = {Proceedings of the 2007 Conference on New Trends in Software Methodologies, Tools and Techniques: Proceedings of the Sixth SoMeT_07},
pages = {391–400},
numpages = {10},
keywords = {Variability, Product Line, Measurement Analysis, Fault Proneness}
}

@article{10.1016/j.infsof.2019.106198,
author = {Assun\c{c}\~{a}o, Wesley K.G. and Vergilio, Silvia R. and Lopez-Herrejon, Roberto E.},
title = {Automatic extraction of product line architecture and feature models from UML class diagram variants},
year = {2020},
issue_date = {Jan 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {117},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106198},
doi = {10.1016/j.infsof.2019.106198},
journal = {Inf. Softw. Technol.},
month = jan,
numpages = {19},
keywords = {Search-based techniques, SPL architecture, Feature model, Model merging}
}

@article{10.1007/s00607-018-0646-1,
author = {Galindo, Jos\'{e} A. and Benavides, David and Trinidad, Pablo and Guti\'{e}rrez-Fern\'{a}ndez, Antonio-Manuel and Ruiz-Cort\'{e}s, Antonio},
title = {Automated analysis of feature models: Quo vadis?},
year = {2019},
issue_date = {May       2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {101},
number = {5},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-018-0646-1},
doi = {10.1007/s00607-018-0646-1},
abstract = {Feature models have been used since the 90s to describe software product lines as a way of reusing common parts in a family of software systems. In 2010, a systematic literature review was published summarizing the advances and settling the basis of the area of automated analysis of feature models (AAFM). From then on, different studies have applied the AAFM in different domains. In this paper, we provide an overview of the evolution of this field since 2010 by performing a systematic mapping study considering 423 primary sources. We found six different variability facets where the AAFM is being applied that define the tendencies: product configuration and derivation; testing and evolution; reverse engineering; multi-model variability-analysis; variability modelling and variability-intensive systems. We also confirmed that there is a lack of industrial evidence in most of the cases. Finally, we present where and when the papers have been published and who are the authors and institutions that are contributing to the field. We observed that the maturity is proven by the increment in the number of journals published along the years as well as the diversity of conferences and workshops where papers are published. We also suggest some synergies with other areas such as cloud or mobile computing among others that can motivate further research in the future.},
journal = {Computing},
month = may,
pages = {387–433},
numpages = {47},
keywords = {Variability-intensive systems, Software product lines, Feature models, Automated analysis, 68T35}
}

@article{10.1007/s10664-019-09705-w,
author = {Kolesnikov, Sergiy and Siegmund, Norbert and K\"{a}stner, Christian and Apel, Sven},
title = {On the relation of control-flow and performance feature interactions: a case study},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09705-w},
doi = {10.1007/s10664-019-09705-w},
abstract = {Detecting feature interactions is imperative for accurately predicting performance of highly-configurable systems. State-of-the-art performance prediction techniques rely on supervised machine learning for detecting feature interactions, which, in turn, relies on time-consuming performance measurements to obtain training data. By providing information about potentially interacting features, we can reduce the number of required performance measurements and make the overall performance prediction process more time efficient. We expect that information about potentially interacting features can be obtained by analyzing the source code of a highly-configurable system, which is computationally cheaper than performing multiple performance measurements. To this end, we conducted an in-depth qualitative case study on two real-world systems (mbedTLS and SQLite), in which we explored the relation between internal (precisely control-flow) feature interactions, detected through static program analysis, and external (precisely performance) feature interactions, detected by performance-prediction techniques using performance measurements. We found that a relation exists that can potentially be exploited to predict performance interactions.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {2410–2437},
numpages = {28},
keywords = {Variability, Performance feature interaction, Highly configurable software system, Feature-interaction prediction, Feature interaction, Feature, Control-flow feature interaction}
}

@inproceedings{10.1109/ICSE.2017.58,
author = {Behringer, Benjamin and Palz, Jochen and Berger, Thorsten},
title = {PEoPL: projectional editing of product lines},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.58},
doi = {10.1109/ICSE.2017.58},
abstract = {The features of a software product line---a portfolio of system variants---can be realized using various implementation techniques (a.k.a., variability mechanisms). Each technique represents the software artifacts of features differently, typically classified into annotative (e.g., C preprocessor) and modular representations (e.g., feature modules), each with distinct advantages and disadvantages. Annotative representations are easy to realize, but annotations clutter source code and hinder program comprehension. Modular representations support comprehension, but are difficult to realize. Most importantly, to engineer feature artifacts, developers need to choose one representation and adhere to it for evolving and maintaining the same artifacts.We present PEoPL, an approach to combine the advantages of annotative and modular representations. When engineering a feature artifact, developers can choose the most-suited representation and even use different representations in parallel. PEoPL relies on separating a product line into an internal and external representation, the latter by providing editable projections used by the developers. We contribute a programming-language-independent internal representation of variability, five editable projections reflecting different variability representations, a supporting IDE, and a tailoring of PEoPL to Java. We evaluate PEoPL's expressiveness, scalability, and flexibility in eight Java-based product lines, finding that all can be realized, that projections are feasible, and that variant computation is fast (&lt;45ms on average for our largest subject Berkeley DB).},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {563–574},
numpages = {12},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.5555/2682923.2682935,
author = {Bittner, B. and Bozzano, M. and Cimatti, A. and Gario, M. and Griggio, A.},
title = {Towards Pareto-Optimal Parameter Synthesis for Monotonic Cost Functions},
year = {2014},
isbn = {9780983567844},
publisher = {FMCAD Inc},
address = {Austin, Texas},
abstract = {Designers are often required to explore alternative solutions, trading off along different dimensions (e.g., power consumption, weight, cost, reliability, response time). Such exploration can be encoded as a problem of parameter synthesis, i.e., finding a parameter valuation (representing a design solution) such that the corresponding system satisfies a desired property. In this paper, we tackle the problem of parameter synthesis with multi-dimensional cost functions by finding solutions that are in the Pareto front: in the space of best trade-offs possible. We propose several algorithms, based on IC3, that interleave in various ways the search for parameter valuations that satisfy the property, and the optimization with respect to costs. The most effective one relies on the reuse of inductive invariants and on the extraction of unsatisfiable cores to accelerate convergence. Our experimental evaluation shows the feasibility of the approach on practical benchmarks from diagnosability synthesis and product-line engineering, and demonstrates the importance of a tight integration between model checking and cost optimization.},
booktitle = {Proceedings of the 14th Conference on Formal Methods in Computer-Aided Design},
pages = {23–30},
numpages = {8},
location = {Lausanne, Switzerland},
series = {FMCAD '14}
}

@inproceedings{10.1145/3251104,
author = {Langdon, William B. and Petke, Justyna and White, David R.},
title = {Session details: Genetic Improvement 2015 Workshop},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251104},
doi = {10.1145/3251104},
abstract = {It is our great pleasure to welcome you to the first international workshop on the Genetic Improvement of Software -- GI-2015, held at GECCO'15. Our goal was to bring together research from across the globe to exchange ideas on using optimisation techniques, particularly evolutionary computation such as genetic programming, to improve existing software. We invited short position papers to encourage the discussion of new ideas and recent work in addition to longer and more concrete submissions. The call for participation invited GI work on automatic bug-fixing; improving functionality; improving non-functional properties such as efficiency, memory and energy consumption; "plastic surgery" by transplanting functionality from other existing code to host software; and automatically specialising generic software for dedicated tasks. As you will see, we have accepted papers in most of these areas as well as papers on improving the nascent genetic improvement tools in use, improving parallel code, GI's relationship with software product lines (SPL), improving security and GI for embedded systems.We had submissions from Asia, Europe and both North and South America. They were exactly evenly split between full-length submissions (8) and two page position papers (8).},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.1007/11880240_1,
author = {Gomaa, Hassan},
title = {A software modeling odyssey: designing evolutionary architecture-centric real-time systems and product lines},
year = {2006},
isbn = {3540457720},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11880240_1},
doi = {10.1007/11880240_1},
abstract = {According to OMG, “modeling is the designing of software applications before coding.” This paper describes a modeling approach to software design. The paper describes the key elements of design methods for component based software product lines, which promote reuse, variability management, and evolution. Approaches for executable models and performance analysis of concurrent and real-time design are discussed. Finally, some outstanding challenges are outlined, in particular the design of evolutionary and dynamically reconfigurable software architectures.},
booktitle = {Proceedings of the 9th International Conference on Model Driven Engineering Languages and Systems},
pages = {1–15},
numpages = {15},
keywords = {software product lines, software modeling, software design, software architecture, real-time systems},
location = {Genova, Italy},
series = {MoDELS'06}
}

@article{10.1007/s11276-014-0838-3,
author = {Yang, Meng and Kim, Donghyun and Li, Deying and Chen, Wenping and Tokuta, Alade O.},
title = {Maximum lifetime suspect monitoring on the street with battery-powered camera sensors},
year = {2015},
issue_date = {May       2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {4},
issn = {1022-0038},
url = {https://doi.org/10.1007/s11276-014-0838-3},
doi = {10.1007/s11276-014-0838-3},
abstract = {A camera sensor network is a sensor network of a group of camera sensors and is being deployed for various surveillance and monitoring applications. In this paper, we propose a new surveillance model for camera sensor network, namely half-view model, which requires a camera sensor network to capture the face image of any object if it moves forward to pass over an area of interest. Based on this new surveillance model, we introduce a new sleep-wakeup scheduling problem in camera sensor network, namely the maximum lifetime half-view barrier-coverage (MaxL-HV-BC) problem, whose goal is to find an on-off schedule of battery-operated camera sensors such that the continuous time duration providing half-view barrier-coverage over an area of interest is maximized. We develop a strategy to check if a region is half-view covered by a given set of camera sensors, and use this strategy to design two new heuristic algorithms for MaxL-HV-BC. We also conduct simulations to compare the average performance of the proposed algorithms with a trivial solution as well as the theoretical upper bound.},
journal = {Wirel. Netw.},
month = may,
pages = {1093–1107},
numpages = {15},
keywords = {Maximum lifetime, Half-view coverage, Energy-efficiency, Camera sensor networks, Barrier coverage, Scheduling}
}

@inproceedings{10.1145/2993236.2993252,
author = {Rothberg, Valentin and Dietrich, Christian and Ziegler, Andreas and Lohmann, Daniel},
title = {Towards scalable configuration testing in variable software},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993252},
doi = {10.1145/2993236.2993252},
abstract = {Testing a software product line such as Linux implies building the source with different configurations. Manual approaches to generate configurations that enable code of interest are doomed to fail due to the high amount of variation points distributed over the feature model, the build system and the source code. Research has proposed various approaches to generate covering configurations, but the algorithms show many drawbacks related to run-time, exhaustiveness and the amount of generated configurations. Hence, analyzing an entire Linux source can yield more than 30 thousand configurations and thereby exceeds the limited budget and resources for build testing.  In this paper, we present an approach to fill the gap between a systematic generation of configurations and the necessity to fully build software in order to test it. By merging previously generated configurations, we reduce the number of necessary builds and enable global variability-aware testing. We reduce the problem of merging configurations to finding maximum cliques in a graph. We evaluate the approach on the Linux kernel, compare the results to common practices in industry, and show that our implementation scales even when facing graphs with millions of edges.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {156–167},
numpages = {12},
keywords = {Configurability, Linux, Sampling, Software Product Lines, Software Testing},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@inproceedings{10.1007/978-3-642-30982-3_7,
author = {Petriu, Dorina C. and Alhaj, Mohammad and Tawhid, Rasha},
title = {Software performance modeling},
year = {2012},
isbn = {9783642309816},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-30982-3_7},
doi = {10.1007/978-3-642-30982-3_7},
abstract = {Ideally, a software development methodology should include both the ability to specify non-functional requirements and to analyze them starting early in the lifecycle; the goal is to verify whether the system under development would be able to meet such requirements. This chapter considers quantitative performance analysis of UML software models annotated with performance attributes according to the standard "UML Profile for Modeling and Analysis of Real-Time and Embedded Systems" (MARTE). The chapter describes a model transformation chain named PUMA (Performance by Unified Model Analysis) that enables the integration of performance analysis in a UML-based software development process, by automating the derivation of performance models from UML+MARTE software models, and by facilitating the interoperability of UML tools and performance tools. PUMA uses an intermediate model called "Core Scenario Model" (CSM) to bridge the gap between different kinds of software models accepted as input and different kinds of performance models generated as output. Transformation principles are described for transforming two kinds of UML behaviour representation (sequence and activity diagrams) into two kinds of performance models (Layered Queueing Networks and stochastic Petri nets). Next, PUMA extensions are described for two classes of software systems: service-oriented architecture (SOA) and software product lines (SPL).},
booktitle = {Proceedings of the 12th International Conference on Formal Methods for the Design of Computer, Communication, and Software Systems: Formal Methods for Model-Driven Engineering},
pages = {219–262},
numpages = {44},
location = {Bertinoro, Italy},
series = {SFM'12}
}

@inproceedings{10.5555/2772879.2773415,
author = {Genter, Katie and Laue, Tim and Stone, Peter},
title = {The RoboCup 2014 SPL Drop-in Player Competition: Encouraging Teamwork without Pre-coordination},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The Standard Platform League is a soccer league at the annual RoboCup world championships in which teams of five humanoid robots play against each other. In 2014, the Drop-in Player Competition was added to the league to serve as a testbed for cooperation without pre-coordination. Instead of homogeneous robot teams that are programmed by each team to implicitly work together, this competition features ad hoc teams, i.e. teams that consist of robots originating from different RoboCup teams and that are each running different software. In this extended abstract, we provide an overview of this competition, including its motivation and rules.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1745–1746},
numpages = {2},
keywords = {ad hoc teamwork, cooperation, robot soccer},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@inproceedings{10.1145/2451617.2451619,
author = {Kowal, Matthias and Schulze, Sandro and Schaefer, Ina},
title = {Towards efficient SPL testing by variant reduction},
year = {2013},
isbn = {9781450318679},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451617.2451619},
doi = {10.1145/2451617.2451619},
abstract = {Testing software systems plays a pivotal role for quality, reliability, and safety of such systems. Several approaches exist that provide efficient algorithms to test one software system. However, in the context of variable software systems, called software product lines (SPLs), testing has to deal with potentially thousands of variants. Unfortunately, current approaches do not scale to this problem and thus testing SPLs efficiently is a challenging task. In this paper, we propose an approach to reduce the test set by explicitly modeling information about shared resources and communication in feature models. As a result, we can figure out features that interact with each other and thus are more likely to cause problems. We show with a small case study that our approach reduces both, the features under test as well as the time for computing all feature combinations to be tested.},
booktitle = {Proceedings of the 4th International Workshop on Variability &amp; Composition},
pages = {1–6},
numpages = {6},
keywords = {feature models, software product lines, testing},
location = {Fukuoka, Japan},
series = {VariComp '13}
}

@inproceedings{10.5555/2666064.2666066,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Baudry, Benoit and Le Noir, J\'{e}r\^{o}me},
title = {Leveraging variability modeling for multi-dimensional model-driven software product lines},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {In order to be adopted in industrial cases, the Software Product Line paradigm must be adapted to the specific organizational context and culture. In this paper, we consider a scenario of a multinational company that would benefit from SPL. This company uses a model-based software and system development process, which allows them to build reliable and consistent systems for the defence, security, aerospace and transportation domain. Initial efforts to adopt SPL in their software production proved successful. However, they still need to leverage variability modeling to the software and system level, integrating it to their existing model-based development. Therefore, this work aims at (i) presenting an industrial scenario and identifying the main challenges to leverage variability modeling for it, (ii) outlining our point of view and perspectives on how these challenges can be addressed, and (iii) discussing the suitability of current variability modeling approaches.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {5–8},
numpages = {4},
keywords = {model-driven engineering, variability modeling},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@article{10.1016/j.infsof.2019.01.004,
author = {Souza, Eric and Moreira, Ana and Goul\~{a}o, Miguel},
title = {Deriving architectural models from requirements specifications: A systematic mapping study},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.004},
doi = {10.1016/j.infsof.2019.01.004},
journal = {Inf. Softw. Technol.},
month = may,
pages = {26–39},
numpages = {14},
keywords = {Software architecture, Mapping study, Literature review}
}

@article{10.1016/j.infsof.2008.04.002,
author = {Deelstra, Sybren and Sinnema, Marco and Bosch, Jan},
title = {Variability assessment in software product families},
year = {2009},
issue_date = {January, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {1},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.002},
doi = {10.1016/j.infsof.2008.04.002},
abstract = {Software variability management is a key factor in the success of software systems and software product families. An important aspect of software variability management is the evolution of variability in response to changing markets, business needs, and advances in technology. To be able to determine whether, when, and how variability should evolve, we have developed the COVAMOF software variability assessment method (COSVAM). The contribution of COSVAM is that it is a novel, and industry-strength assessment process that addresses the issues that are associated to the current variability assessment practice. In this paper, we present the successful validation of COSVAM in an industrial software product family.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {195–218},
numpages = {24},
keywords = {Assessment, Evolution, Software product families, Variability}
}

@article{10.1109/TNET.2021.3056772,
author = {Ruby, Rukhsana and Zhong, Shuxin and ElHalawany, Basem M. and Luo, Hanjiang and Wu, Kaishun},
title = {SDN-Enabled Energy-Aware Routing in Underwater Multi-Modal Communication Networks},
year = {2021},
issue_date = {June 2021},
publisher = {IEEE Press},
volume = {29},
number = {3},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2021.3056772},
doi = {10.1109/TNET.2021.3056772},
abstract = {Despite extensive research efforts, underwater sensor networks (UWSNs) still suffer from serious performance issues due to their inefficient and uncoordinated channel access and resource management. For example, due to the lack of holistic knowledge on the network resources, existing decentralized routing protocols fail to provide globally optimal performance. On the other hand, Software Defined Networking (SDN), as a promising paradigm to provide prominent centralized solutions, can be employed to address the aforementioned issues in UWSNs. Indeed, SDN brings unprecedented opportunities to improve the network performance through the development of advanced algorithms at controllers. In this paper, we study the routing problem in such a network with new features including centralized route decision, global network-state awareness, seamless route discovery while considering the optimization of several long-term global performance metrics. We formulate the entire routing problem of a multi-modal UWSN as an optimization problem while considering the interference phenomenon of ad hoc scenarios and some long-term global performance metrics of an ideal routing protocol. Our formulated problem nicely captures all possible flexibilities of a sensor node no matter it has the full-duplex or half-duplex functionality. Upon the formulation, we recognize the NP-hard nature of the problem for all possible scenarios. We adopt a rounding technique based on the convex programming relaxation concept to solve the formulated routing problem that considers full-duplex scenarios, whereas we solve the problem for half-duplex scenarios using a greedy method upon interpreting it as a submodular function maximization problem. Through extensive simulation via our Python-based in-house simulator, we verify that our proposed globally optimal routing scheme always outperforms three existing decentralized routing protocols (each of these protocols are selected from each of three prominent protocol types, i.e., flooding, cross-layer information and adaptive machine learning based, respectively) in terms of reliability, latency, energy efficiency, lifetime and fairness.},
journal = {IEEE/ACM Trans. Netw.},
month = feb,
pages = {965–978},
numpages = {14}
}

@article{10.1007/s10270-013-0364-2,
author = {Acher, Mathieu and Cleve, Anthony and Collet, Philippe and Merle, Philippe and Duchien, Laurence and Lahire, Philippe},
title = {Extraction and evolution of architectural variability models in plugin-based systems},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0364-2},
doi = {10.1007/s10270-013-0364-2},
abstract = {Variability management is a key issue when building and evolving software-intensive systems, making it possible to extend, configure, customize and adapt such systems to customers' needs and specific deployment contexts. A wide form of variability can be found in extensible software systems, typically built on top of plugin-based architectures that offer a (large) number of configuration options through plugins. In an ideal world, a software architect should be able to generate a system variant on-demand, corresponding to a particular assembly of plugins. To this end, the variation points and constraints between architectural elements should be properly modeled and maintained over time (i.e., for each version of an architecture). A crucial, yet error-prone and time-consuming, task for a software architect is to build an accurate representation of the variability of an architecture, in order to prevent unsafe architectural variants and reach the highest possible level of flexibility. In this article, we propose a reverse engineering process for producing a variability model (i.e., a feature model) of a plugin-based architecture. We develop automated techniques to extract and combine different variability descriptions, including a hierarchical software architecture model, a plugin dependency model and the software architect knowledge. By computing and reasoning about differences between versions of architectural feature models, software architect can control both the variability extraction and evolution processes. The proposed approach has been applied to a representative, large-scale plugin-based system (FraSCAti), considering different versions of its architecture. We report on our experience in this context.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1367–1394},
numpages = {28},
keywords = {Architecture recovery, Configuration management, Product lines, Reverse engineering, Software evolution, Variability}
}

@inproceedings{10.1109/ICSEA.2008.80,
author = {Kim, Kangtae and Kim, Hyungrok and Kim, Sundeok and Chang, Gihun},
title = {A Case Study on SW Product Line Architecture Evaluation: Experience in the Consumer Electronics Domain},
year = {2008},
isbn = {9780769533728},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSEA.2008.80},
doi = {10.1109/ICSEA.2008.80},
abstract = {A well-executed software architecture is one of the most critical factors for achieving the intended effectiveness of a software product line as a holistic picture of a system. Today, many organizations are investing in architecture and its quality attributes for productivity, time to market and etc. In this paper, we show an evaluation framework named which provides criteria for measuring execution(designing and implementing) of an architecture and guideline for improvement based on measurement, analysis and improvement principle. We focused on software architecture design itself because we are mainly concerned with design and implementation issues thus concentrating on the architecture criteria. The contribution of the paper is to identify and demonstrate a architecture analysis and improvement process with practical experimentation results. The framework is based on design attributes of product line architecture and static analysis of architecture implementation.},
booktitle = {Proceedings of the 2008 The Third International Conference on Software Engineering Advances},
pages = {192–197},
numpages = {6},
keywords = {product line, software architecture evaluation},
series = {ICSEA '08}
}

