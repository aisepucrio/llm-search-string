@inproceedings{10.1145/3336294.3336304,
author = {Horcas, Jose-Miguel and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Software Product Line Engineering: A Practical Experience},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336304},
doi = {10.1145/3336294.3336304},
abstract = {The lack of mature tool support is one of the main reasons that make the industry to be reluctant to adopt Software Product Line (SPL) approaches. A number of systematic literature reviews exist that identify the main characteristics offered by existing tools and the SPL phases in which they can be applied. However, these reviews do not really help to understand if those tools are offering what is really needed to apply SPLs to complex projects. These studies are mainly based on information extracted from the tool documentation or published papers. In this paper, we follow a different approach, in which we firstly identify those characteristics that are currently essential for the development of an SPL, and secondly analyze whether the tools provide or not support for those characteristics. We focus on those tools that satisfy certain selection criteria (e.g., they can be downloaded and are ready to be used). The paper presents a state of practice with the availability and usability of the existing tools for SPL, and defines different roadmaps that allow carrying out a complete SPL process with the existing tool support.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {164–176},
numpages = {13},
keywords = {spl in practice, state of practice, tool support, tooling roadmap},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.infsof.2020.106389,
author = {Chac\'{o}n-Luna, Ana Eva and Guti\'{e}rrez, Antonio Manuel and Galindo, Jos\'{e} A. and Benavides, David},
title = {Empirical software product line engineering: A systematic literature review},
year = {2020},
issue_date = {Dec 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {128},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2020.106389},
doi = {10.1016/j.infsof.2020.106389},
journal = {Inf. Softw. Technol.},
month = dec,
numpages = {22},
keywords = {Software product lines, Empirical strategies, Case study, Experiment, Systematic literature review}
}

@article{10.1007/s11227-021-03627-5,
author = {Kiani, Azaz Ahmed and Hafeez, Yaser and Imran, Muhammad and Ali, Sadia},
title = {A dynamic variability management approach working with agile product line engineering practices for reusing features},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {8},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-021-03627-5},
doi = {10.1007/s11227-021-03627-5},
abstract = {Agile software development (ASD) and software product line (SPL) have shown significant benefits for software engineering processes and practices. Although both methodologies promise similar benefits, they are based on different foundations. SPL encourages systematic reuse that exploits the commonalities of various products belonging to a common domain and manages their variations systematically. In contrast, ASD stresses a flexible and rapid development of products using iterative and incremental approaches. ASD encourages active involvement of customers and their frequent feedback. Both ASD and SPL require alternatives to extend agile methods for several reasons such as (1) to manage reusability and variability across the products of any domain, (2) to avoid the risk of developing core assets that will become obsolete and not used in future projects, and (3) to meet the requirements of changing markets. This motivates the researchers for the integration of ASD and SPL approaches. As a result, an innovative approach called agile product line engineering (APLE) by integrating SPL and ASD has been introduced. The principal aim of APLE is to maximize the benefits of ASD and SPL and address the shortcomings of both. However, combining both is a major challenge. Researchers have proposed a few approaches that try to put APLE into practice, but none of the existing approaches cover all APLE features needed. This paper proposes a new dynamic variability approach for APLE that uses APLE practices for reusing features. The proposed approach (PA) is based on the agile method Scrum and the reactive approach of SPL. In this approach, reusable core assets respond reactively to customer requirements. The PA constructs and develops the SPL architecture iteratively and incrementally. It provides the benefits of reusability and maintainability of SPLs while keeping the delivery-focused approach from agile methods. We conducted a quantitative survey of software companies applying the APLE to assess the performance of the PA and hypotheses of empirical study. Findings of empirical evaluation provide evidence on integrating ASD and SPL and the application of APLE into practices.},
journal = {J. Supercomput.},
month = aug,
pages = {8391–8432},
numpages = {42},
keywords = {Software product line, Agile software development, Agile software product line, Agile product line engineering}
}

@article{10.1016/j.jss.2019.04.054,
author = {Acher, Mathieu and Cohen, Myra B.},
title = {Special issue on systems and software product line engineering},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.054},
doi = {10.1016/j.jss.2019.04.054},
journal = {J. Syst. Softw.},
month = aug,
pages = {110–111},
numpages = {2}
}

@inproceedings{10.1145/3233027.3233045,
author = {Becker, Martin and Zhang, Bo},
title = {How do our neighbours do product line engineering? a comparison of hardware and software product line engineering approaches from an industrial perspective},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233045},
doi = {10.1145/3233027.3233045},
abstract = {Product line engineering (PLE) approaches have been followed in industry for hardware and software solutions for more than three decades now. However, the different engineering disciplines (e.g. mechanics, electrics, software) have developed and evolved their approaches within their own realms, which is fine as long as there is no need for integrated approaches. Driven by the increasing complexity of systems, there is a rising need for interdisciplinary systems engineering these days. Companies engineering cyber-physical systems and their components have to integrate product line engineering approaches across the involved engineering disciplines to enable a global optimization of portfolio, solution structures, and assets along their lifecycle. From a bird's-eye view, there is noticeable commonality but also variety in the approaches followed for PLE in the different engineering disciplines, which renders the integration of approaches a non-trivial endeavour. In order to foster the development of integrated PLE approaches, this paper explores, maps, and compares PLE approaches in the field of hardware and software engineering. Furthermore, the paper identifies integration opportunities and challenges. As the paper targets industrial practitioners, it mainly provides references to respective industrial events and material and does not fully cover related work in the respective research communities.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {190–195},
numpages = {6},
keywords = {SPLC, academia, industry, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1016/j.infsof.2018.01.016,
author = {Soares, Larissa Rocha and Schobbens, Pierre-Yves and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Feature interaction in software product line engineering: A systematic mapping study},
year = {2018},
issue_date = {Jun 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {98},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.01.016},
doi = {10.1016/j.infsof.2018.01.016},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {44–58},
numpages = {15},
keywords = {Feature interaction, Software product lines, Systematic mapping}
}

@inproceedings{10.1145/3106195.3106224,
author = {Tizzei, Leonardo P. and Nery, Marcelo and Segura, Vin\'{\i}cius C. V. B. and Cerqueira, Renato F. G.},
title = {Using Microservices and Software Product Line Engineering to Support Reuse of Evolving Multi-tenant SaaS},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106224},
doi = {10.1145/3106195.3106224},
abstract = {In order to achieve economies of scale, a Software as a Service (SaaS) should be configurable, multi-tenant efficient, and scalable. But building SaaS with these characteristics comes at a price of having more complex services. Some works in the literature integrate software product line engineering and service-oriented architecture to tackle the complexity of building multi-tenant SaaS. Most of these works focused on centralized approaches that rely on middleware or platforms, but they do not investigate the use of decentralized architectural style. Microservices architecture is an architectural style that relies on small, decentralized, and autonomous services that work together. Thus, this paper investigates the integrated use of microservices architecture and software produt line techniques to develop multi-tenant SaaS. We conducted an empirical study that analyzes the behavior of software reuse during the evolution of a multi-tenant SaaS. This empirical study showed an average software reuse of 62% of lines of code among tenants. We also provide lessons we learned during the the re-engineering and maintenance of such multi-tenant SaaS.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {205–214},
numpages = {10},
keywords = {Microservices, Multi-tenancy, Service-oriented Architectures, Software Evolution, Software Reuse},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2811681.2811703,
author = {Tan, Lei and Lin, Yuqing},
title = {An Aspect-Oriented Feature Modelling Framework for Software Product Line Engineering},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2811703},
doi = {10.1145/2811681.2811703},
abstract = {Software Product Line Engineering (SPLE) is a software development paradigm that focusing on systematic software assets reuse. SPLE treats software products in the same application domains as a product family and developing various of assets could be reused in the product family. Feature modelling is a critical activity of SPLE, which developing the requirement model for product families and providing guidance for individual product implementation. In this paper, we discuss several drawbacks of current feature modelling and propose a solution which adopting aspect-oriented development ideas and approaches. The proposed framework is intended to better manage complex feature relationships, and enhance quality-aware feature modelling. We include a case study of a real-life experience to demonstrate the proposed approach.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {111–115},
numpages = {5},
keywords = {aspectoriented, feature modelling, software product line engineering},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@inproceedings{10.1109/APSEC.2008.45,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Kuhlemann, Martin and K\"{a}stner, Christian and Saake, Gunter},
title = {Measuring Non-Functional Properties in Software Product Line for Product Derivation},
year = {2008},
isbn = {9780769534466},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2008.45},
doi = {10.1109/APSEC.2008.45},
abstract = {A software product line (SPL) enables stakeholders to derive different software products for a domain while providing a high degree of reuse of their code units. Software products are derived in a configuration process by composing different code units. The configuration process becomes complex if SPLs contain hundreds of features. In many cases, a stakeholder is not only interested in functional but also in non-functional properties of a desired product. Because SPLs can be used in different application scenarios alternative implementations of already existing functionality are developed to meet special non-functional requirements, like restricted binary size and performance guarantees. To enable these complex configurations we discuss and present techniques to measure non-functional properties of software modules and use these values to compute SPL configurations optimized to the users needs.},
booktitle = {Proceedings of the 2008 15th Asia-Pacific Software Engineering Conference},
pages = {187–194},
numpages = {8},
keywords = {Non-functional Properties, Product Derivation, Software Product Lines},
series = {APSEC '08}
}

@inproceedings{10.1007/978-3-319-23781-7_26,
author = {Brisaboa, Nieves R. and Corti\~{n}as, Alejandro and Luaces, Miguel R. and Pol'La, Matias},
title = {A Reusable Software Architecture for Geographic Information Systems Based on Software Product Line Engineering},
year = {2015},
isbn = {9783319237800},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-23781-7_26},
doi = {10.1007/978-3-319-23781-7_26},
abstract = {In the last years there has been a continuous growth in functionality of geographic information systems GIS resulting in many different software artifacts. Even though each GIS is used in different areas with different objectives, they all share many features and requirements and therefore it is possible to apply techniques based on intensive software reuse, such as software product line engineering SPLE. Although there has been much research on software product line engineering in the last years, the definition of a software product line for the domain of geographic information systems has not been undertaken.In this work we identify the requirements and functionalities of a generic product for a web-based geographic information system, grouping them into commonalities that allow us to reuse many software artifacts, and variabilities that allow use to configure different products. Then, we define the functional and technological architecture of a software product line that uses current technologies for web-based application development. Finally, we design a tool to configure and assemble the components to generate the possible products. The resulting platform is flexible enough to adapt each product to the specific needs of each customer.},
booktitle = {Proceedings of the 5th International Conference on Model and Data Engineering - Volume 9344},
pages = {320–331},
numpages = {12},
keywords = {General-purpose software architecture, Geographic information systems, Software product line engineering, Variability management},
location = {Rhodes, Greece},
series = {MEDI 2015}
}

@inproceedings{10.1145/2934466.2934481,
author = {Sion, Laurens and Van Landuyt, Dimitri and Joosen, Wouter and de Jong, Gjalt},
title = {Systematic quality trade-off support in the software product-line configuration process},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934481},
doi = {10.1145/2934466.2934481},
abstract = {Software product line engineering is a compelling methodology that accomplishes systematic reuse in families of systems by relying on two key principles: (i) the decomposition of complex systems into composable and reusable building blocks (often logical units called features), and (ii) on-demand construction of products and product variants by composing these building blocks.However, unless the stakeholder responsible for product configuration has detailed knowledge of the technical ins and outs of the software product line (e.g., the architectural impact of a specific feature, or potential feature interactions), he is in many cases flying in the dark. Although many initial approaches and techniques have been proposed that take into account quality considerations and involve trade-off decisions during product configuration, no systematic support exists.In this paper, we present a reference architecture for product configuration tooling, providing support for (i) up-front generation of variants, and (ii) quality analysis of these variants. This allows pro-actively assessing and predicting architectural quality properties for each product variant and in turn, product configuration tools can take into account architectural considerations. In addition, we provide an in-depth discussion of techniques and tactics for dealing with the problem of variant explosion, and as such to maintain practical feasibility of such approaches.We validated and implemented our reference architecture in the context of a real-world industrial application, a product-line for the firmware of an automotive sensor. Our prototype, based on FeatureIDE, is open for extension and readily available.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {164–173},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3307630.3342418,
author = {Rinc\'{o}n, Luisa and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {Analyzing the Convenience of Adopting a Product Line Engineering Approach: An Industrial Qualitative Evaluation},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342418},
doi = {10.1145/3307630.3342418},
abstract = {Engineering Software Product Lines may be a strategy to reduce costs and efforts for developing software and increasing business productivity. However, it cannot be considered as a "silver bullet" that applies to all types of organizations. Companies must consider pros and cons to determine sound reasons and justify its adoption. In previous work, we proposed the APPLIES evaluation framework to help decision-makers find arguments that may justify (or not) adopting a product line engineering approach. This paper presents our experience using this framework in a mid-sized software development company with more than 25 years of experience but without previous experience in product line engineering. This industrial experience, conducted as a qualitative empirical evaluation, helped us to evaluate to what extent APPLIES is practical to be used in a real environment and to gather ideas from real potential users to improve the framework.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {90–97},
numpages = {8},
keywords = {empirical evaluation, product line adoption, product line engineering, qualitative evaluation},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.5555/2525401.2525415,
author = {Tan, Lei and Lin, Yuqing and Ye, Huilin and Zhang, Guoheng},
title = {Improving product configuration in software product line engineering},
year = {2013},
isbn = {9781921770203},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Software Product Line Engineering (SPLE) is a emerging software reuse paradigm. SPLE focuses on systematic software reuse from requirement engineering to product derivation throughout the software development life-cycle. Feature model is one of the most important reusable assets which represents all design considerations of a software product line. Feature model will be used in the product configuration process to produce a software. The product configuration is a decision-making process, where all kinds of relationships among configurable features will be considered to select the desired features for the product. To improve the efficiency and quality of product configuration, we are proposing a new approach which aims at identifying a small set of key features. The product configuration should always start from this set of features since, based on the feature dependencies, the decisions made on these features will imply decisions on the rest of the features of the product line, thus reduce the features visited in the configuration process. We have also conducted some experiments to demonstrate how the proposed approach works and evaluate the efficiency of the approach.},
booktitle = {Proceedings of the Thirty-Sixth Australasian Computer Science Conference - Volume 135},
pages = {125–133},
numpages = {9},
keywords = {feature model, minimum vertex cover, product configuration, software product line},
location = {Adelaide, Australia},
series = {ACSC '13}
}

@inproceedings{10.1145/2491627.2499880,
author = {Clarke, Dave and Schaefer, Ina and ter Beek, Maurice H. and Apel, Sven and Atlee, Joanne M.},
title = {Formal methods and analysis in software product line engineering: 4th edition of FMSPLE workshop series},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2499880},
doi = {10.1145/2491627.2499880},
abstract = {FMSPLE 2013 is the fourth edition of the FMSPLE workshop series aimed at connecting researchers and practitioners interested in raising the efficiency and the effectiveness of software product line engineering through the application of innovative analysis approaches and formal methods.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {266–267},
numpages = {2},
keywords = {evolution, formal methods, semantics, software product lines, testing, variability, verification},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1007/978-3-319-35122-3_2,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Automated Composition of Service Mashups Through Software Product Line Engineering},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_2},
doi = {10.1007/978-3-319-35122-3_2},
abstract = {The growing number of online resources, including data and services, has motivated both researchers and practitioners to provide methods and tools for non-expert end-users to create desirable applications by putting these resources together leading to the so called mashups. In this paper, we focus on a class of mashups referred to as service mashups. A service mashup is built from existing services such that the developed service mashup offers added-value through new functionalities. We propose an approach which adopts concepts from software product line engineering and automated AI planning to support the automated composition of service mashups. One of the advantages of our work is that it allows non-experts to build and optimize desired mashups with little knowledge of service composition. We report on the results of the experimentation that we have performed which support the practicality and scalability of our proposed work.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {20–38},
numpages = {19},
keywords = {Automated composition, Feature model, Planning, Service mashups, Software product lines, Workflow optimization},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1145/3106195.3106219,
author = {Gregg, Susan P. and Albert, Denise M. and Clements, Paul},
title = {Product Line Engineering on the Right Side of the "V"},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106219},
doi = {10.1145/3106195.3106219},
abstract = {Product line engineering (PLE) is well-known for the savings it brings to organizations. This paper shows how a very large, in-service systems and software product line is achieving PLE-based savings in their verification and validation phase of development. The paper addresses how to achieve the sharing across product variants while the products being tested are evolving over time. Additionally, we will give a pragmatic set of decision criteria to help answer the longstanding issue in PLE-based testing of whether to test on the domain side or the application (product) side of the product derivation process.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {165–174},
numpages = {10},
keywords = {AEGIS Combat System, PLE factory, Product line engineering, bill-of-features, feature modeling, feature profiles, product configurator, product portfolio, second generation product line engineering, software product lines, variation points},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3236405.3237200,
author = {Bilic, Damir and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter and Causevic, Adnan and Amlinger, Christoffer},
title = {Model-based product line engineering in an industrial automotive context: an exploratory case study},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237200},
doi = {10.1145/3236405.3237200},
abstract = {Product Line Engineering is an approach to reuse assets of complex systems by taking advantage of commonalities between product families. Reuse within complex systems usually means reuse of artifacts from different engineering domains such as mechanical, electronics and software engineering. Model-based systems engineering is becoming a standard for systems engineering and collaboration within different domains. This paper presents an exploratory case study on initial efforts of adopting Product Line Engineering practices within the model-based systems engineering process at Volvo Construction Equipment (Volvo CE), Sweden. We have used SysML to create overloaded models of the engine systems at Volvo CE. The variability within the engine systems was captured by using the Orthogonal Variability Modeling language. The case study has shown us that overloaded SysML models tend to become complex even on small scale systems, which in turn makes scalability of the approach a major challenge. For successful reuse and to, possibly, tackle scalability, it is necessary to have a database of reusable assets from which product variants can be derived.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {56–63},
numpages = {8},
keywords = {model-based systems engineering, orthogonal variability modeling, system product lines, variability management},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s10664-020-09913-9,
author = {Lindohf, Robert and Kr\"{u}ger, Jacob and Herzog, Erik and Berger, Thorsten},
title = {Software product-line evaluation in the large},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09913-9},
doi = {10.1007/s10664-020-09913-9},
abstract = {Software product-line engineering is arguably one of the most successful methods for establishing large portfolios of software variants in an application domain. However, despite the benefits, establishing a product line requires substantial upfront investments into a software platform with a proper product-line architecture, into new software-engineering processes (domain engineering and application engineering), into business strategies with commercially successful product-line visions and financial planning, as well as into re-organization of development teams. Moreover, establishing a full-fledged product line is not always possible or desired, and thus organizations often adopt product-line engineering only to an extent that deemed necessary or was possible. However, understanding the current state of adoption, namely, the maturity or performance of product-line engineering in an organization, is challenging, while being crucial to steer investments. To this end, several measurement methods have been proposed in the literature, with the most prominent one being the Family Evaluation Framework (FEF), introduced almost two decades ago. Unfortunately, applying it is not straightforward, and the benefits of using it have not been assessed so far. We present an experience report of applying the FEF to nine medium- to large-scale product lines in the avionics domain. We discuss how we tailored and executed the FEF, together with the relevant adaptations and extensions we needed to perform. Specifically, we elicited the data for the FEF assessment with 27 interviews over a period of 11 months. We discuss experiences and assess the benefits of using the FEF, aiming at helping other organizations assessing their practices for engineering their portfolios of software variants.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {41},
keywords = {software product lines, process maturity, experience report, family evaluation framework}
}

@article{10.1016/j.infsof.2013.05.006,
author = {Mohabbati, Bardia and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and M\"{u}ller, Hausi A.},
title = {Combining service-orientation and software product line engineering: A systematic mapping study},
year = {2013},
issue_date = {November, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.006},
doi = {10.1016/j.infsof.2013.05.006},
abstract = {Context: Service-Orientation (SO) is a rapidly emerging paradigm for the design and development of adaptive and dynamic software systems. Software Product Line Engineering (SPLE) has also gained attention as a promising and successful software reuse development paradigm over the last decade and proven to provide effective solutions to deal with managing the growing complexity of software systems. Objective: This study aims at characterizing and identifying the existing research on employing and leveraging SO and SPLE. Method: We conducted a systematic mapping study to identify and analyze related literature. We identified 81 primary studies, dated from 2000-2011 and classified them with respect to research focus, types of research and contribution. Result: The mapping synthesizes the available evidence about combining the synergy points and integration of SO and SPLE. The analysis shows that the majority of studies focus on service variability modeling and adaptive systems by employing SPLE principles and approaches. In particular, SPLE approaches, especially feature-oriented approaches for variability modeling, have been applied to the design and development of service-oriented systems. While SO is employed in software product line contexts for the realization of product lines to reconcile the flexibility, scalability and dynamism in product derivations thereby creating dynamic software product lines. Conclusion: Our study summarizes and characterizes the SO and SPLE topics researchers have investigated over the past decade and identifies promising research directions as due to the synergy generated by integrating methods and techniques from these two areas.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1845–1859},
numpages = {15},
keywords = {Service-oriented architecture, Software product lines, Systematic mapping}
}

@inproceedings{10.1145/2362536.2362576,
author = {ter Beek, Maurice H. and Becker, Martin and Classen, Andreas and Roos-Frantz, Fabricia and Schaefer, Ina and Wong, Peter Y. H.},
title = {Formal methods and analysis in software product line engineering: 3rd edition of FMSPLE workshop series},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362576},
doi = {10.1145/2362536.2362576},
abstract = {FMSPLE 2012 is the third edition of the FMSPLE workshop series, traditionally affiliated with SPLC, which aims to connect researchers and practitioners interested in raising the efficiency and the effectiveness of SPLE through the application of innovative analysis approaches and formal methods.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {286–287},
numpages = {2},
keywords = {evolution, formal methods, semantics, software product lines, testing, variability, verification},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3385032.3385043,
author = {Bilic, Damir and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter and Causevic, Adnan and Amlinger, Christoffer and Barkah, Dani},
title = {Towards a Model-Driven Product Line Engineering Process: An Industrial Case Study},
year = {2020},
isbn = {9781450375948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385032.3385043},
doi = {10.1145/3385032.3385043},
abstract = {Many organizations developing software-intensive systems face challenges with high product complexity and large numbers of variants. In order to effectively maintain and develop these product variants, Product-Line Engineering methods are often considered, while Model-based Systems Engineering practices are commonly utilized to tackle product complexity. In this paper, we report on an industrial case study concerning the ongoing adoption of Product Line Engineering in the Model-based Systems Engineering environment at Volvo Construction Equipment (Volvo CE) in Sweden. In the study, we identify and define a Product Line Engineering process that is aligned with Model-based Systems Engineering activities at the engines control department of Volvo CE. Furthermore, we discuss the implications of the migration from the current development process to a Model-based Product Line Engineering-oriented process. This process, and its implications, are derived by conducting and analyzing interviews with Volvo CE employees, inspecting artifacts and documents, and by means of participant observation. Based on the results of a first system model iteration, we were able to document how Model-based Systems Engineering and variability modeling will affect development activities, work products and stakeholders of the work products.},
booktitle = {Proceedings of the 13th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {9},
numpages = {11},
keywords = {Engine System Development, Model-Based Systems Engineering, Product Line Engineering},
location = {Jabalpur, India},
series = {ISEC '20}
}

@phdthesis{10.5555/2519127,
author = {Tawhid, Rasha},
title = {Integrating performance analysis in model driven software product line engineering},
year = {2012},
isbn = {9780494893104},
publisher = {Carleton University},
address = {CAN},
abstract = {A  Software Product Line  (SPL) is a set of similar software systems that share a common set of features satisfying a particular domain, and are built from a shared set of software assets using a common means of production. This research proposes to integrate performance analysis in the early phases of the model-driven development process of SPL. We start by adding generic performance annotations to the UML model representing the set of core reusable SPL assets using the MARTE Profile adopted by OMG. A model transformation realized in Atlas Transformation Language (ATL), derives the UML model of a specific product with concrete performance annotations from the SPL model, which is further transformed into a performance model by using a previously developed transformation called PUMA. The automatic derivation of a specific product model based on a given feature configuration is enabled through the mapping between features from the feature model and their realizations in the design model. An efficient mapping technique is proposed that aims to minimize the amount of explicit feature annotations in the UML model of SPL. Implicit feature mapping is inferred during product derivation from the relationships between annotated and non-annotated model elements as defined in the UML metamodel. The mapping technique is used to derive automatically a given product model. Performance is a run-time property of the deployed system and depends on other factors that are external to the design model, characterizing the underlying platforms and run-time environment. Performance completions provide a means to extend the modeling constructs of a system by including the influence of these factors. The variability space of the performance completions is covered and represented through Performance Completion-feature model (PC-feature model). Dealing manually with a large number of performance parameters annotating a UML+MARTE product model is an error-prone process. A model-driven user-friendly technique is proposed to automatically collect all generic performance parameters that need binding from the generated product model and present them to developers in a spreadsheet format, together with context and guiding information where each PC-feature is mapped to certain MARTE annotations corresponding to UML model elements in the product model.},
note = {AAINR89310}
}

@inproceedings{10.1145/3336294.3336303,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and Ramos-Guti\'{e}rrez, Bel\'{e}n and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Process Mining to Unleash Variability Management: Discovering Configuration Workflows Using Logs},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336303},
doi = {10.1145/3336294.3336303},
abstract = {Variability models are used to build configurators. Configurators are programs that guide users through the configuration process to reach a desired configuration that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the elements that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suites stakeholders according to previous configurations. For example, when configuring a Linux distribution, the configuration process start by choosing the network or the graphic card, and then other packages with respect to a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), an automated technique that given a set of logs of previous configurations and a variability model can automatically assist to determine the configuration workflow that better fits the configuration logs generated by user activities. The technique is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Our proposal is validated using existing data from an ERP configuration environment showing its feasibility. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {265–276},
numpages = {12},
keywords = {clustering, configuration workflow, process discovery, process mining, variability},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10664-016-9439-3,
author = {Bagheri, Ebrahim and Benavides, David and Schmid, Klaus and Runeson, Per},
title = {Foreword to the special issue on empirical evidence on software product line engineering},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9439-3},
doi = {10.1007/s10664-016-9439-3},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1579–1585},
numpages = {7}
}

@inproceedings{10.5555/2666064.2666075,
author = {Fant, Julie Street and Gomaa, Hassan and Pettit, Robert G.},
title = {Software product line engineering of space flight software},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {This paper presents a practical solution to a real-life industrial problem in the unmanned space flight software (FSW) domain using software product lines and software architectural design patterns. In the FSW domain, there exists a significant amount of variability in the required capabilities. For example, some FSW have a significant amount of hardware to control and operate in a nearly autonomous fashion. In contrast, other FSW have a small amount of hardware to control and rely heavily of commanding from the ground station to operate the spacecraft. The underlying architecture and component interactions needed for the different FSWs are quite different. This amount of architectural variability makes it difficult to develop a SPL architecture that covers the all possible variability in the FSW domain. Therefore, this paper presents a practical solution to this real world problem that leverages software product line concepts and software architectural design patterns.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {41–44},
numpages = {4},
keywords = {UML, software architectural design patterns, software product lines, unmanned space flight software},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1145/1982185.1982336,
author = {Asadi, Mohsen and Bagheri, Ebrahim and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Mohabbati, Bardia},
title = {Goal-driven software product line engineering},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982336},
doi = {10.1145/1982185.1982336},
abstract = {Feature Models encapsulate functionalities and quality properties of a product family. The employment of feature models for managing variability and commonality of large-scale product families raises an important question: on what basis should the features of a product family be selected for a target software application, which is going to be derived from the product family. Thus, the selection of the most suitable features for a specific application requires the understanding of its stakeholders' intentions and also the relationship between their intentions and the available software features. To address this important issue, we adopt a standard goal-oriented requirements engineering framework, i.e., the i* framework, for identifying stakeholders' intentions and propose an approach for explicitly mapping and bridging between the features of a product family and the goals and objectives of the stakeholders. We propose a novel approach to automatically preconfigure a given feature model based on the objectives of the target product stakeholders. Also, our approach is able to elucidate the rationale behind the selection of the most important features of a family for a target application.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {691–698},
numpages = {8},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@inproceedings{10.1145/2420942.2420948,
author = {Gonz\'{a}lez-Huerta, Javier and Insfran, Emilio and Abrah\~{a}o, Silvia and McGregor, John D.},
title = {Non-functional requirements in model-driven software product line engineering},
year = {2012},
isbn = {9781450318075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420942.2420948},
doi = {10.1145/2420942.2420948},
abstract = {Developing variant-rich software systems through the application of the software product line approach requires the management of a wide set of requirements. However, in most cases, the focus of those requirements is limited to the functional requirements. The non-functional requirements are often informally defined and their management does not provide traceability mechanisms for their validation. In this paper, we present a multimodel approach that allows the explicit representation of non-functional requirements for software product lines both at domain engineering, and application engineering levels. The multimodel allows the representation of different viewpoints of a software product line, including the non-functional requirements and the relationships that these non-functional requirements might have with features and functionalities. The feasibility of this approach is illustrated through a specific example from the automotive domain.},
booktitle = {Proceedings of the Fourth International Workshop on Nonfunctional System Properties in Domain Specific Modeling Languages},
articleno = {6},
numpages = {6},
keywords = {model driven engineering, non-functional requirements, software product lines},
location = {Innsbruck, Austria},
series = {NFPinDSML '12}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {Software product lines, product-line analysis}
}

@inproceedings{10.1145/1321631.1321730,
author = {Dhungana, Deepak and Rabiser, Rick and Gr\"{u}nbacher, Paul and Neumayer, Thomas},
title = {Integrated tool support for software product line engineering},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321730},
doi = {10.1145/1321631.1321730},
abstract = {Product line engineering comprises many heterogeneous activities such as capturing the variability of reusable assets, supporting the derivation of products from the product line, evolving the product line, or tailoring the approach to the specifics of a domain. The inherent complexity of product lines implicates that tool support is inevitable to facilitate smooth performance and to avoid costly errors. Product line engineering tools have to support heterogeneous stakeholders involved in diverse activities. Tool integration therefore is of particular importance to foster their seamless cooperation. However, the integration is difficult to achieve due to the diversity of models and work products. This paper describes the DOPLER tool suite which has been developed to provide such integrated support. The tool suite is flexible and extensible to support domain-specific needs},
booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {533–534},
numpages = {2},
keywords = {model evolution, multi-team modeling, product derivation, product line engineering, product line tools, variability modeling},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{10.1145/1629716.1629724,
author = {Elsner, Christoph and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Product derivation for solution-driven product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629724},
doi = {10.1145/1629716.1629724},
abstract = {Solution-driven product line engineering is a project business where products are created for each customer individually. Although reuse of results from former projects is widely done, configuration and integration of the results currently is often a manual, time-consuming, and error-prone task and needs considerable knowledge about implementation details.In this paper, we elaborate and approach the challenges when giving automated support for product derivation (i.e., product configuration and generation) in a large-scale solution-driven product line context. Our PLiC approach resembles the fact that, in practice, the domain of a large product line is divided into sub-domains. A PLiC (product line component) packages all results (configuration, generation, and implementation assets) of a sub-domain and offers interfaces for configuration and generation. With our approach we tackle the challenges of using multiple and different types of configuration models and text files, give support for automated product generation, and integrate feature modeling to support application engineering as an extensive development task.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {35–41},
numpages = {7},
keywords = {feature modeling, software product line development, solution-driven software development},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.5555/1753235.1753277,
author = {Botterweck, Goetz and Groher, Iris and Polzer, Andreas and Schwanninger, Christa and Thiel, Steffen and V\"{o}lter, Markus},
title = {1st International Workshop on Model-driven Approaches in Software Product Line Engineering: (MAPLE 2009)},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {The MAPLE workshop focuses on the combination of Model-driven Software Engineering and Software Product Lines (SPL). It explores how model-driven approaches can help to achieve the goals of product lines in terms of reducing cost and time to market and increasing quality and productivity. In particular the workshop revolves around three themes: Efficient product derivation, the link between SPL research and industry practice, and SPL models with a meaning.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {297–298},
numpages = {2},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2934466.2934491,
author = {Fogdal, Thomas and Scherrebeck, Helene and Kuusela, Juha and Becker, Martin and Zhang, Bo},
title = {Ten years of product line engineering at Danfoss: lessons learned and way ahead},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934491},
doi = {10.1145/2934466.2934491},
abstract = {Software and systems product line engineering (PLE) has been an established approach for reducing time to market as well as cost and increasing quality in a set of related products for two decades now. Although there is a huge body of knowledge on PLE, adopting a concrete PLE approach is still not a trivial endeavor for interested companies. With the increasing importance of development speed, the advent of agile engineering approaches, and decreasing management interest in improvements that require large organizational transformations and only show benefits after several years, companies are facing challenges in successfully adopting this approach. They often hesitate as there is no clear adoption path, nor any certainty, that the intended improvement steps will also provide added value in the short- and mid-term perspective. In consequence, a considerable amount of PLE potential still remains unexploited.To help such companies with the adoption of PLE, the goal of this paper is to provide inspiration and evidence that PLE is a sound approach and its successful introduction is possible even in settings that differ substantially from those of pioneer product lines.To this end, this paper presents the following main contributions with the PLE adoption case at Danfoss Drives: an overview of the key change drivers and the motivation for adopting a PLE approach, a discussion of incremental PLE introduction in an agile engineering context, a presentation of the current PLE setting with a focus on key concepts, and finally a presentation of motivators and directions for future improvements.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {252–261},
numpages = {10},
keywords = {industrial experiences, product line adoption, product line evaluation},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2791060.2791067,
author = {Yue, Tao and Ali, Shaukat and Selic, Bran},
title = {Cyber-physical system product line engineering: comprehensive domain analysis and experience report},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791067},
doi = {10.1145/2791060.2791067},
abstract = {Cyber-Physical Systems (CPSs) are the future generation of highly connected embedded systems having applications in diverse domains including Oil and Gas. Employing Product Line Engineering (PLE) is believed to bring potential benefits with respect to reduced cost, higher productivity, higher quality, and faster time-to-market. However, relatively few industrial field studies are reported regarding the application of PLE to develop large-scale systems, and more specifically CPSs. In this paper, we report about our experiences and insights gained from investigating the application of model-based PLE at a large international organization developing subsea production systems (typical CPSs) to manage the exploitation of oil and gas production fields. We report in this paper 1) how two systematic domain analyses (on requirements engineering and product configuration/derivation) were conducted to elicit CPS PLE requirements and challenges, 2) key results of the domain analysis (commonly observed in other domains), and 3) our initial experience of developing and applying two Model Based System Engineering (MBSE) PLE solution to address some of the requirements and challenges elicited during the domain analyses.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {338–347},
numpages = {10},
keywords = {cyber physical system (CPS), domain analysis, model based system engineering, product line engineering (PLE), requirements engineering},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1007/978-3-030-64148-1_6,
author = {Hayashi, Kengo and Aoyama, Mikio},
title = {A Portfolio-Driven Development Model and Its Management Method of Agile Product Line Engineering Applied to Automotive Software Development},
year = {2020},
isbn = {978-3-030-64147-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64148-1_6},
doi = {10.1007/978-3-030-64148-1_6},
abstract = {In recent automotive systems development, realizing both variability and agility is the key competitiveness to meet the diverse requirements in global markets and rapidly increasing intelligent functions. This article proposes a portfolio-driven development method and its management method of APLE (Agile Product Line Engineering). The proposed method is intended to manage agile evolution of multiple product lines while increasing variability of products. To establish a portfolio management of development resources, it is necessary for an organization to manage multiple product lines on APLE in an entire development. We propose a portfolio-driven development method of three layers on APLE and its management method based on a concept of portfolio management life cycle. We applied the proposed management model and method to the multiple product lines of automotive software systems, and demonstrated an improvement of manageability with better predictability of both productivity and development size. This article contributes to provide an entire development management method for APLE, and its practical experience in the automotive multiple product lines.},
booktitle = {Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings},
pages = {88–105},
numpages = {18},
keywords = {Software product line, Agile software development, Agile product line engineering, Portfolio management, Automotive software development},
location = {Turin, Italy}
}

@inproceedings{10.1145/3233027.3233028,
author = {Rabiser, Rick and Schmid, Klaus and Becker, Martin and Botterweck, Goetz and Galster, Matthias and Groher, Iris and Weyns, Danny},
title = {A study and comparison of industrial vs. academic software product line research published at SPLC},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233028},
doi = {10.1145/3233027.3233028},
abstract = {The study presented in this paper aims to provide evidence for the hypothesis that software product line research has been changing and that the works in industry and academia have diverged over time. We analysed a subset (140) of all (593) papers published at the Software Product Line Conference (SPLC) until 2017. The subset was randomly selected to cover all years as well as types of papers. We assessed the research type of the papers (academic or industry), the kind of evaluation (application example, empirical, etc.), and the application domain. Also, we assessed which product line life-cycle phases, development practices, and topics the papers address. We present an analysis of the topics covered by academic vs. industry research and discuss the evolution of these topics and their relation over the years. We also discuss implications for researchers and practitioners. We conclude that even though several topics have received more attention than others, academic and industry research on software product lines are actually rather in line with each other.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {14–24},
numpages = {11},
keywords = {SPLC, academia, industry, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1109/ICSE43902.2021.00147,
author = {Mahmood, Wardah and Str\"{u}ber, Daniel and Berger, Thorsten and L\"{a}mmel, Ralf and Mukelabai, Mukelabai},
title = {Seamless Variability Management With the Virtual Platform},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00147},
doi = {10.1109/ICSE43902.2021.00147},
abstract = {Customization is a general trend in software engineering, demanding systems that support variable stakeholder requirements. Two opposing strategies are commonly used to create variants: software clone&amp;own and software configuration with an integrated platform. Organizations often start with the former, which is cheap, agile, and supports quick innovation, but does not scale. The latter scales by establishing an integrated platform that shares software assets between variants, but requires high up-front investments or risky migration processes. So, could we have a method that allows an easy transition or even combine the benefits of both strategies? We propose a method and tool that supports a truly incremental development of variant-rich systems, exploiting a spectrum between both opposing strategies. We design, formalize, and prototype the variability-management framework virtual platform. It bridges clone&amp;own and platform-oriented development. Relying on programming-language-independent conceptual structures representing software assets, it offers operators for engineering and evolving a system, comprising: traditional, asset-oriented operators and novel, feature-oriented operators for incrementally adopting concepts of an integrated platform. The operators record meta-data that is exploited by other operators to support the transition. Among others, they eliminate expensive feature-location effort or the need to trace clones. Our evaluation simulates the evolution of a real-world, clone-based system, measuring its costs and benefits.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1658–1670},
numpages = {13},
keywords = {clone management, framework, re-engineering, software product lines, variability management},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/2491627.2493906,
author = {Bashari, Mahdi and Bagheri, Ebrahim},
title = {Engineering self-adaptive systems and dynamic software product line},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2493906},
doi = {10.1145/2491627.2493906},
abstract = {Self-adaptive systems are a class of software applications, which are able to dynamically transform their internal structure and hence their behavior in response to internal or external stimuli. The transformation may provide the basis for new functionalities or improve or maintain non-functional properties in order to match the application better to its operational requirements and standards. Software Product Line Engineering has rich methods and techniques in variability modeling and management which is one of the main issues in developing self-adaptive systems. Dynamic software product lines (DSPL) have been proposed to exploit the knowledge acquired in SPLE to develop self-adaptive software systems.In this tutorial, we portray the problem of developing self-adaptive systems. Then we investigate how the idea of dynamic software product line could help to deal with the challenges that we face in developing efficient self-adaptive software. We also offer insight into the different approaches that use dynamic software product line engineering for developing self-adaptive systems focusing on practical approaches by showing how the approaches are applied to real case studies and also methods for evaluating these approaches. This tutorial also discuss how DSPL could be used some relevant areas to self-adaptive systems and challenges which still exist in the area.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {285},
numpages = {1},
keywords = {dynamic software product line, self-adaptive systems},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2362536.2362545,
author = {Lee, Jihyun and Kang, Sungwon and Lee, Danhyung},
title = {A survey on software product line testing},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362545},
doi = {10.1145/2362536.2362545},
abstract = {Software product line (SPL) testing consists of two separate but closely related test engineering activities: domain testing and application testing. Various software product line testing approaches have been developed over the last decade, and surveys have been conducted on them. However, thus far none of them deeply addressed the questions of what researches have been conducted in order to overcome the challenges posed by the two separate testing activities and their relationships. Thus, this paper surveys the current software product line testing approaches by defining a reference SPL testing processes and identifying, based on them, key research perspectives that are important in SPL testing. Through this survey, we identify the researches that addressed the challenges and also derive open research opportunities from each perspective.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {31–40},
numpages = {10},
keywords = {software product line engineering, software product line testing, software testing},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1145/1640162.1640164,
author = {Catal, Cagatay},
title = {Barriers to the adoption of software product line engineering},
year = {2009},
issue_date = {November 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1640162.1640164},
doi = {10.1145/1640162.1640164},
abstract = {Software development costs and time to deploy a software-intensive system significantly decrease when Software Product Line Engineering (SPLE) approach is applied. Numerous case stu-dies in industrial and military domains have shown that reliability, quality, productivity and user interface consistency improve drasti-cally in addition to the decrease of cost and time-to-market. Also, this system engineering approach is very effective in three market strategies known as cost leadership, differentiation, and focusing. Despite these measurable benefits, product line engineering adop-tion is slower than the other technological trends such as Service Oriented Architecture (SOA), Model Driven Development (MDD), and Aspect Oriented Software Development (AOSD). In this pa-per, we investigate the barriers to the adoption of SPLE and ex-plore the root causes of them from three points of views: Project sponsor, organization, and SPLE community. We provide sugges-tions for how the industry and SPLE community can solve these multi-dimensional issues in a short term.},
journal = {SIGSOFT Softw. Eng. Notes},
month = dec,
pages = {1–4},
numpages = {4},
keywords = {commonality, core asset development, product families, software product lines, software reuse, variability}
}

@article{10.1016/j.csi.2016.03.003,
author = {Afzal, Uzma and Mahmood, Tariq and Shaikh, Zubair},
title = {Intelligent software product line configurations},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {48},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2016.03.003},
doi = {10.1016/j.csi.2016.03.003},
abstract = {A software product line (SPL) is a set of industrial software-intensive systems for configuring similar software products in which personalized feature sets are configured by different business teams. The integration of these feature sets can generate inconsistencies that are typically resolved through manual deliberation. This is a time-consuming process and leads to a potential loss of business resources. Artificial intelligence (AI) techniques can provide the best solution to address this issue autonomously through more efficient configurations, lesser inconsistencies and optimized resources. This paper presents the first literature review of both research and industrial AI applications to SPL configuration issues. Our results reveal only 19 relevant research works which employ traditional AI techniques on small feature sets with no real-life testing or application in industry. We categorize these works in a typology by identifying 8 perspectives of SPL. We also show that only 2 standard industrial SPL tools employ AI in a limited way to resolve inconsistencies. To inject more interest and application in this domain, we motivate and present future research directions. Particularly, using real-world SPL data, we demonstrate how predictive analytics (a state of the art AI technique) can separately model inconsistent and consistent patterns, and then predict inconsistencies in advance to help SPL designers during the configuration of a product. Literature review of AI applications to SPL configuration issuesDevelop a taxonomy based on eight different problem domainsThis review shows use of logic, constraint satisfaction, reasoning, ontology and optimization.Several important future research directions are proposed.We justify advanced analytics and swarm intelligence as better future applications.},
journal = {Comput. Stand. Interfaces},
month = nov,
pages = {30–48},
numpages = {19},
keywords = {Artificial intelligence, Automated feature selection, Inconsistencies, Industrial SPL tools, Literature review, Predictive analytics, Software product line}
}

@inproceedings{10.1145/2648511.2648548,
author = {Sierszecki, Krzysztof and Steffens, Michaela and Hojrup, Helene H. and Savolainen, Juha and Beuche, Danilo},
title = {Extending variability management to the next level},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648548},
doi = {10.1145/2648511.2648548},
abstract = {Danfoss Power Electronics is a centre with both extensive power electronics know-how and many competencies within frequency converters and solar inverters. Development of embedded controllers built in Danfoss products raises similar challenges found in many other companies: creation of product series with an increasing number of variants, while at the same time decreasing time-to-market and keeping development costs low. Introduction of a Software Product Line approach into product development is a challenge that Danfoss Power Electronics decided to take in order to reduce software development efforts few years ago. The approach has been successful allowing for development of a number of highly engineered products. However, the software product line is in a constant evolution. It grows over time as new functionality is added in the form of extra software artefacts and further products are configured from it. As a result, the overall complexity and maintenance of assets hinders further efficiency of the approach. This paper presents extension of the variability management that goes beyond the scope of software assets reuse previously introduced into the organization. A prototype of the technique linking multi-level variability management is further elaborated using pure::variants.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {320–329},
numpages = {10},
keywords = {industrial experience, product specifications, variability management},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1016/j.jss.2010.02.018,
author = {Dhungana, Deepak and Gr\"{u}nbacher, Paul and Rabiser, Rick and Neumayer, Thomas},
title = {Structuring the modeling space and supporting evolution in software product line engineering},
year = {2010},
issue_date = {July, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {7},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2010.02.018},
doi = {10.1016/j.jss.2010.02.018},
abstract = {The scale and complexity of product lines means that it is practically infeasible to develop a single model of the entire system, regardless of the languages or notations used. The dynamic nature of real-world systems means that product line models need to evolve continuously to meet new customer requirements and to reflect changes of product line artifacts. To address these challenges, product line engineers need to apply different strategies for structuring the modeling space to ease the creation and maintenance of models. This paper presents an approach that aims at reducing the maintenance effort by organizing product lines as a set of interrelated model fragments defining the variability of particular parts of the system. We provide support to semi-automatically merge fragments into complete product line models. We also provide support to automatically detect inconsistencies between product line artifacts and the models representing these artifacts after changes. Furthermore, our approach supports the co-evolution of models and their respective meta-models. We discuss strategies for structuring the modeling space and show the usefulness of our approach using real-world examples from our ongoing industry collaboration.},
journal = {J. Syst. Softw.},
month = jul,
pages = {1108–1122},
numpages = {15},
keywords = {Model evolution, Product line engineering, Variability modeling}
}

@inproceedings{10.1145/2701319.2701326,
author = {Soares, Larissa Rocha and do Carmo Machado, Ivan and de Almeida, Eduardo Santana},
title = {Non-Functional Properties in Software Product Lines: A Reuse Approach},
year = {2015},
isbn = {9781450332736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701319.2701326},
doi = {10.1145/2701319.2701326},
abstract = {Software Product Line Engineering (SPLE) emerges for software organizations interested in customized products at reasonable costs. Based on the selection of features, stakeholders can derive programs satisfying a range of functional properties and non-functional ones. The explicit definition of Non-Functional Properties (NFP) during software configuration has been considered a challenging task. Dealing with them is not well established yet, neither in theory nor in practice. In this sense, we present a framework to specify NFP for SPLE and we also propose a reuse approach that promotes the reuse of NFP values during the product configuration. We discuss the results of a case study aimed to evaluate the applicability of the proposed work.},
booktitle = {Proceedings of the 9th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {67–74},
numpages = {8},
keywords = {Empirical Software Engineering, Quality Attributes, Software Product Line},
location = {Hildesheim, Germany},
series = {VaMoS '15}
}

@article{10.1007/s10664-019-09787-6,
author = {Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp and Ziadi, Tewfik and Robin, Jacques and Martinez, Jabier},
title = {The state of adoption and the challenges of systematic variability management in industry},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09787-6},
doi = {10.1007/s10664-019-09787-6},
abstract = {Handling large-scale software variability is still a challenge for many organizations. After decades of research on variability management concepts, many industrial organizations have introduced techniques known from research, but still lament that pure textbook approaches are not applicable or efficient. For instance, software product line engineering—an approach to systematically develop portfolios of products—is difficult to adopt given the high upfront investments; and even when adopted, organizations are challenged by evolving their complex product lines. Consequently, the research community now mainly focuses on re-engineering and evolution techniques for product lines; yet, understanding the current state of adoption and the industrial challenges for organizations is necessary to conceive effective techniques. In this multiple-case study, we analyze the current adoption of variability management techniques in twelve medium- to large-scale industrial cases in domains such as automotive, aerospace or railway systems. We identify the current state of variability management, emphasizing the techniques and concepts they adopted. We elicit the needs and challenges expressed for these cases, triangulated with results from a literature review. We believe our results help to understand the current state of adoption and shed light on gaps to address in industrial practice.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {1755–1797},
numpages = {43},
keywords = {Variability management, Software product lines, Multiple-case study, Challenges}
}

@article{10.1007/s10664-012-9234-8,
author = {Reinhartz-Berger, Iris and Sturm, Arnon},
title = {Comprehensibility of UML-based software product line specifications},
year = {2014},
issue_date = {June      2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9234-8},
doi = {10.1007/s10664-012-9234-8},
abstract = {Software Product Line Engineering (SPLE) deals with developing artifacts that capture the common and variable aspects of software product families. Domain models are one kind of such artifacts. Being developed in early stages, domain models need to specify commonality and variability and guide the reuse of the artifacts in particular software products. Although different modeling methods have been proposed to manage and support these activities, the assessment of these methods is still in an inceptive stage. In this work, we examined the comprehensibility of domain models specified in ADOM, a UML-based SPLE method. In particular, we conducted a controlled experiment in which 116 undergraduate students were required to answer comprehension questions regarding a domain model that was equipped with explicit reuse guidance and/or variability specification. We found that explicit specification of reuse guidance within the domain model helped understand the model, whereas explicit specification of variability increased comprehensibility only to a limited extent. Explicit specification of both reuse guidance and variability often provided intermediate results, namely, results that were better than specification of variability without reuse guidance, but worse than specification of reuse guidance without variability. All these results were perceived in different UML diagram types, namely, use case, class, and sequence diagrams and for different commonality-, variability-, and reuse-related aspects.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {678–713},
numpages = {36},
keywords = {Domain models, Empirical evaluation, Software product line engineering, UML, Variability management}
}

@article{10.1007/s11219-011-9165-4,
author = {Lochau, Malte and Oster, Sebastian and Goltz, Ursula and Sch\"{u}rr, Andy},
title = {Model-based pairwise testing for feature interaction coverage in software product line engineering},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9165-4},
doi = {10.1007/s11219-011-9165-4},
abstract = {Testing software product lines (SPLs) is very challenging due to a high degree of variability leading to an enormous number of possible products. The vast majority of today's testing approaches for SPLs validate products individually using different kinds of reuse techniques for testing. Because of their reusability and adaptability capabilities, model-based approaches are suitable to describe variability and are therefore frequently used for implementation and testing purposes of SPLs. Due to the enormous number of possible products, individual product testing becomes more and more infeasible. Pairwise testing offers one possibility to test a subset of all possible products. However, according to the best of our knowledge, there is no contribution discussing and rating this approach in the SPL context. In this contribution, we provide a mapping between feature models describing the common and variable parts of an SPL and a reusable test model in the form of statecharts. Thereby, we interrelate feature model-based coverage criteria and test model-based coverage criteria such as control and data flow coverage and are therefore able to discuss the potentials and limitations of pairwise testing. We pay particular attention to test requirements for feature interactions constituting a major challenge in SPL engineering. We give a concise definition of feature dependencies and feature interactions from a testing point of view, and we discuss adequacy criteria for SPL coverage under pairwise feature interaction testing and give a generalization to the T-wise case. The concept and implementation of our approach are evaluated by means of a case study from the automotive domain.},
journal = {Software Quality Journal},
month = sep,
pages = {567–604},
numpages = {38},
keywords = {Combinatorial testing, Feature interaction, Model-based engineering and testing, Software product lines, Test generation and coverage}
}

@inproceedings{10.1145/2491627.2491649,
author = {Lanman, Jeremy and Darbin, Rowland and Rivera, Jorge and Clements, Paul and Krueger, Charles},
title = {The challenges of applying service orientation to the U.S. Army's live training software product line},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491649},
doi = {10.1145/2491627.2491649},
abstract = {Live Training Transformation (LT2) is the product line strategy put in place by the United States Army Program Executive Office for Simulation, Training and Instrumentation (PEO STRI). The purpose of the LT2 product line is to provide a common set of core assets including architectures, software components, standards and processes that form the basis of all Army Live Training systems. As products consuming LT2 core assets evolve to meet the latest requirements of the military live training community, changes to the core product line architecture must also be made. Based on thorough analysis of the LT2 core capabilities and user trends toward web-enabled and mobile computing technologies, a Service Oriented Architecture (SOA) strategy was identified and adopted as the objective architecture for the evolving LT2 product line. Future success of the LT2 product line now depends on the alignment of product line engineering concepts with the business and technical benefits of SOA, and to ensure that systematic reuse continues to provide substantial return-on-investment for the Army. This paper addresses the challenges of adopting SOA into an existing software product line, the unique circumstances of the LT2 SOA environment, and present a set of analysis and design considerations for the product line engineering community.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {244–253},
numpages = {10},
keywords = {bill-of-features, feature modeling, feature profiles, hierarchical product lines, product audit, product baselines, product configurator, product derivation, product line engineering, product portfolio, second generation product line engineering, software product lines, variation points},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3372297.3417234,
author = {Schwartz, Edward J. and Cohen, Cory F. and Gennari, Jeffrey S. and Schwartz, Stephanie M.},
title = {A Generic Technique for Automatically Finding Defense-Aware Code Reuse Attacks},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417234},
doi = {10.1145/3372297.3417234},
abstract = {Code reuse attacks have been the subject of a substantial amount of research during the past decade. This research largely resulted from early work on Return-Oriented Programming (ROP), which showed that the then newly proposed Non-Executable Memory (NX) defense could be bypassed. More recently, the research community has been simultaneously investigating new defenses that are believed to thwart code reuse attacks, such as Control Flow Integrity (CFI), and defense-aware techniques for attacking these defenses, such as Data-Oriented Programming (DOP). Unfortunately, the feasibility of defense-aware attacks are very dependent on the behaviors of the attacked program, which makes it difficult for defenders to understand how much protection a defense such as CFI may provide. To better understand this, researchers have introduced automated defense-aware code reuse attack systems. Unfortunately, the handful of existing systems implement a single fixed, defense-specific strategy that is complex and cannot be used to consider other defenses.In this paper, we propose a generic framework for automatically discovering defense-aware code reuse attacks in executables. Unlike existing work, which utilizes hard-coded strategies for specific defenses, our framework can produce attacks for multiple defenses by analyzing the runtime behavior of the defense. The high-level insight behind our framework is that code reuse attacks can be defined as a state reachability problem, and that defenses prevent some transitions between states. We implement our framework as a tool named Limbo, which employs an existing binary concolic executor to solve the reachability problem. We evaluate Limbo and show that it excels when there is little code available for reuse, making it complementary to existing techniques. We show that, in such scenarios, Limbo outperforms existing systems that automate ROP attacks, as well as systems that automate DOP attacks in the presence of fine-grained CFI, despite having no special knowledge about ROP or DOP attacks.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1789–1801},
numpages = {13},
keywords = {code reuse attacks, software defenses},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/2362536.2362557,
author = {Elsner, Christoph},
title = {Light-weight tool support for staged product derivation},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362557},
doi = {10.1145/2362536.2362557},
abstract = {Tool support that checks for configuration errors and generates product parts from configurations can significantly improve on product derivation in product line engineering. Up to now, however, derivation tools commonly disregard the staged derivation process. They do not restrict configuration consistency checks to process entities such as configuration stages, stakeholders, or build tasks. As a result, constraints that are only valid for certain process entities must either be checked permanently, leading to false positive errors, or one must refrain from defining them at all.This paper contributes a light-weight approach to provide tailored tool support for staged product derivation. Compared to previous approaches, it is not tied to a single configuration mechanism (e.g., feature modeling), and also accounts for the stakeholders involved and the build tasks that generate product parts. First, the product line engineer describes the derivation process in a concise model. Then, based on constraint checks on the configuration (e.g., a feature model configuration) that are linked to the modeled entities, comprehensive tool support can be provided: Configuration actions can be guided and restricted depending on the configuring stakeholder in a fine-grained manner, and constraints attached to a build task will only be checked if it actually shall be executed. Finally, in combination with previous work, the paper provides evidence that the approach is applicable to legacy product lines in a light-weight manner and that it technically scales to thousands of constraint checks.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {146–155},
numpages = {10},
keywords = {product line, staged product derivation, tool support},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/978-3-030-63882-5_12,
author = {Alves, Thayonara and Teixeira, Leopoldo and Alves, Vander and Castro, Thiago},
title = {Porting the Software Product Line Refinement Theory to the Coq Proof&nbsp;Assistant},
year = {2020},
isbn = {978-3-030-63881-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63882-5_12},
doi = {10.1007/978-3-030-63882-5_12},
abstract = {Software product lines are an engineering approach to systematically build similar software products from a common asset base. When evolving such systems, it is important to have assurance that we are not introducing errors or changing the behavior of existing products. The product line refinement theory establishes the necessary conditions for such assurance. This theory has been specified and proved using the PVS proof assistant. However, the Coq proof assistant is increasingly popular among researchers and practitioners, and, given that some programming languages are already formalized into such tool, the refinement theory might benefit from the potential integration. Therefore, in this work we present a case study on porting the PVS specification of the refinement theory to Coq. We compare the proof assistants based on the noted differences between the specifications and proofs of this theory, providing some reflections on the tactics and strategies used to compose the proofs. According to our study, PVS provided more succinct definitions than Coq, in several cases, as well as a greater number of successful automatic commands that resulted in shorter proofs. Despite that, Coq also brought facilities in definitions such as enumerated and recursive types, and features that support developers in their proofs.},
booktitle = {Formal Methods: Foundations and Applications: 23rd Brazilian Symposium, SBMF 2020, Ouro Preto, Brazil, November 25–27, 2020, Proceedings},
pages = {192–209},
numpages = {18},
keywords = {Software product lines, Theorem provers, Coq, PVS},
location = {Ouro Preto, Brazil}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {Clafer, ClaferIG, ClaferMOO, ClaferMOO visualizer, ClaferWiki, clafer configurator},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3168365.3168373,
author = {Pereira, Juliana Alves and Schulze, Sandro and Krieter, Sebastian and Ribeiro, M\'{a}rcio and Saake, Gunter},
title = {A Context-Aware Recommender System for Extended Software Product Line Configurations},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168373},
doi = {10.1145/3168365.3168373},
abstract = {Mass customization of standardized products has become a trend to succeed in today's market environment. Software Product Lines (SPLs) address this trend by describing a family of software products that share a common set of features. However, choosing the appropriate set of features that matches a user's individual interests is hampered due to the overwhelming amount of possible SPL configurations. Recommender systems can address this challenge by filtering the number of configurations and suggesting a suitable set of features for the user's requirements. In this paper, we propose a context-aware recommender system for predicting feature selections in an extended SPL configuration scenario, i.e. taking nonfunctional properties of features into consideration. We present an empirical evaluation based on a large real-world dataset of configurations derived from industrial experience in the Enterprise Resource Planning domain. Our results indicate significant improvements in the predictive accuracy of our context-aware recommendation approach over a state-of-the-art binary-based approach.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {97–104},
numpages = {8},
keywords = {Configuration, Feature Model, Non-Functional Properties, Recommender Systems, Software Product Lines},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/2019136.2019165,
author = {Lettner, Daniela and Thaller, Daniel and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul and Heider, Wolfgang},
title = {Supporting business calculations in a product line engineering tool suite},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019165},
doi = {10.1145/2019136.2019165},
abstract = {Software Product Line Engineering (SPLE) involves defining the commonalities and variability of similar products to leverage extensive reuse and to accelerate the derivation of customized products. However, sales people and customers do not only care about technical properties of product features during product derivation. They also need information concerning the business value of product features. Existing approaches have addressed this issue by combining business information with variability models, e.g., by defining feature attributes or by integrating third party tools. However, a solution that seamlessly integrates variability and business calculations within a SPLE tool is still lacking. We report on our ongoing efforts to integrate business calculations in the DOPLER tool suite. We use examples of product lines from the industrial plant automation domain to motivate and demonstrate our solution.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {26},
numpages = {4},
keywords = {business calculations, tool support, value-based software engineering, variability models},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3382025.3414953,
author = {Abbas, Muhammad and Jongeling, Robbert and Lindskog, Claes and Enoiu, Eduard Paul and Saadatmand, Mehrdad and Sundmark, Daniel},
title = {Product line adoption in industry: an experience report from the railway domain},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414953},
doi = {10.1145/3382025.3414953},
abstract = {The software system controlling a train is typically deployed on various hardware architectures and must process various signals across those deployments. The increase of such customization scenarios and the needed adherence of the software to various safety standards in different application domains has led to the adoption of product line engineering within the railway domain. This paper explores the current state-of-practice of software product line development within a team developing industrial embedded software for a train propulsion control system. Evidence is collected using a focus group session with several engineers and through inspection of archival data. We report several benefits and challenges experienced during product line adoption and deployment. Furthermore, we identify and discuss improvement opportunities, focusing mainly on product line evolution and test automation.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {3},
numpages = {11},
keywords = {challenges and opportunities, overloaded assets, software product-line engineering},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1016/j.knosys.2019.104883,
author = {Ayala, Inmaculada and Amor, Mercedes and Horcas, Jose-Miguel and Fuentes, Lidia},
title = {A goal-driven software product line approach for evolving multi-agent systems in the Internet of Things},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {184},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.104883},
doi = {10.1016/j.knosys.2019.104883},
journal = {Know.-Based Syst.},
month = nov,
numpages = {18},
keywords = {Software product line, Evolution, Internet of Things, MAS-PL, Goal models, GORE}
}

@inproceedings{10.1145/3167132.3167353,
author = {Pereira, Juliana Alves and Martinez, Jabier and Gurudu, Hari Kumar and Krieter, Sebastian and Saake, Gunter},
title = {Visual guidance for product line configuration using recommendations and non-functional properties},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167353},
doi = {10.1145/3167132.3167353},
abstract = {Software Product Lines (SPLs) are a mature approach for the derivation of a family of products using systematic reuse. Different combinations of predefined features enable tailoring the product to fit the needs of each customer. These needs are related to functional properties of the system (optional features) as well as non-functional properties (e.g., performance or cost of the final product). In industrial scenarios, the configuration process of a final product is complex and the tool support is usually limited to check functional properties interdependencies. In addition, the importance of nonfunctional properties as relevant drivers during configuration has been overlooked. Thus, there is a lack of holistic paradigms integrating recommendation systems and visualizations that can help the decision makers. In this paper, we propose and evaluate an interrelated set of visualizations for the configuration process filling these gaps. We integrate them as part of the FeatureIDE tool and we evaluate its effectiveness, scalability, and performance.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {2058–2065},
numpages = {8},
keywords = {configuration, feature model, recommendation systems, software product lines, visualization},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1109/SEAA.2014.48,
author = {Soares, Larissa Rocha and Potena, Pasqualina and Machado, Ivan do Carmo and Crnkovic, Ivica and Almeida, Eduardo Santana de},
title = {Analysis of Non-functional Properties in Software Product Lines: A Systematic Review},
year = {2014},
isbn = {9781479957958},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2014.48},
doi = {10.1109/SEAA.2014.48},
abstract = {Software Product Lines (SPL) approach has been widely developed in academia and successfully applied in industry. Based on the selection of features, stakeholders can efficiently derive tailor-made programs satisfying different requirements. While SPL was very successful at building products based on identified features, achievements and preservation of many nonfunctional properties (NFPs) remain challenging. A knowledge how to deal with NFPs is still not fully obtained. In this paper, we present a systematic literature review of NFPs analysis for SPL products, focusing on runtime NFPs. The goal of the paper is twofold: (i) to present an holistic overview of SPL approaches that have been reported regarding the analysis of runtime NFPs, and (ii) to categorize NFPs treated in the scientific literature regarding development of SPLs. We analyzed 36 research papers, and identified that system performance attributes are typically the most considered. The results also aid future research studies in NFPs analysis by providing an unbiased view of the body of empirical evidence and by guiding future research directions.},
booktitle = {Proceedings of the 2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {328–335},
numpages = {8},
keywords = {Non-functional Properties, Product Derivation, Software Product Lines, Systematic Literature Review},
series = {SEAA '14}
}

@article{10.1007/s10009-012-0242-1,
author = {Heymans, Patrick and Boucher, Quentin and Classen, Andreas and Bourdoux, Arnaud and Demonceau, Laurent},
title = {A code tagging approach to software product line development},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0242-1},
doi = {10.1007/s10009-012-0242-1},
abstract = {Software product line engineering seeks to systematise reuse when developing families of similar software systems so as to minimise development time, cost and defects. To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations. These concerns were the motivation for the industry---university collaboration described in this paper in which we developed a minimally intrusive coding technique based on tags. The approach was complemented with traceability from code to feature diagrams which were exploited for automated configuration. It is supported by a toolchain and is now in use in the partner company for the development of flight-grade satellite communication software libraries.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {553–566},
numpages = {14},
keywords = {Automation, Code tagging, Feature diagrams, Software product line engineering}
}

@inproceedings{10.1145/2364412.2364428,
author = {Zhang, Bo and Becker, Martin},
title = {Code-based variability model extraction for software product line improvement},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364428},
doi = {10.1145/2364412.2364428},
abstract = {Successful Software Product Lines (SPLs) evolve over time. However, one practical problem is that during SPL evolution the core assets, especially the code, tend to become complicated and difficult to understand, use, and maintain. Typically, more and more problems arise over time with implicit or already lost adaptation knowledge about the interdependencies of the different system variants and the supported variability. In this paper, we present a model-based SPL improvement process that analyzes existing large-scale SPL reuse infrastructure to identify improvement potential with respective metrics. Since Conditional Compilation (CC) is one of the most widely used mechanisms to implement variability, we parse variability-related facts from preprocessor code. Then we automatically extract an implementation variability model, including product configuration and variation points that are structured in a hierarchical variability tree. The extraction process is presented with concrete measurement results from an industrial case study.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {91–98},
numpages = {8},
keywords = {conditional compilation, software product line maintenance, variability model},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1016/j.infsof.2009.11.001,
author = {Rabiser, Rick and Gr\"{u}nbacher, Paul and Dhungana, Deepak},
title = {Requirements for product derivation support: Results from a systematic literature review and an expert survey},
year = {2010},
issue_date = {March, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.11.001},
doi = {10.1016/j.infsof.2009.11.001},
abstract = {Context: An increasing number of publications in product line engineering address product derivation, i.e., the process of building products from reusable assets. Despite its importance, there is still no consensus regarding the requirements for product derivation support. Objective: Our aim is to identify and validate requirements for tool-supported product derivation. Method: We identify the requirements through a systematic literature review and validate them with an expert survey. Results: We discuss the resulting requirements and provide implementation examples from existing product derivation approaches. Conclusions: We conclude that key requirements are emerging in the research literature and are also considered relevant by experts in the field.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {324–346},
numpages = {23},
keywords = {Product derivation, Product line engineering, Software product line, Systematic literature review}
}

@article{10.1016/j.infsof.2012.07.020,
author = {Siegmund, Norbert and Rosenm\"{u}Ller, Marko and K\"{a}Stner, Christian and Giarrusso, Paolo G. and Apel, Sven and Kolesnikov, Sergiy S.},
title = {Scalable prediction of non-functional properties in software product lines: Footprint and memory consumption},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.020},
doi = {10.1016/j.infsof.2012.07.020},
abstract = {Context: A software product line is a family of related software products, typically created from a set of common assets. Users select features to derive a product that fulfills their needs. Users often expect a product to have specific non-functional properties, such as a small footprint or a bounded response time. Because a product line may have an exponential number of products with respect to its features, it is usually not feasible to generate and measure non-functional properties for each possible product. Objective: Our overall goal is to derive optimal products with respect to non-functional requirements by showing customers which features must be selected. Method: We propose an approach to predict a product's non-functional properties based on the product's feature selection. We aggregate the influence of each selected feature on a non-functional property to predict a product's properties. We generate and measure a small set of products and, by comparing measurements, we approximate each feature's influence on the non-functional property in question. As a research method, we conducted controlled experiments and evaluated prediction accuracy for the non-functional properties footprint and main-memory consumption. But, in principle, our approach is applicable for all quantifiable non-functional properties. Results: With nine software product lines, we demonstrate that our approach predicts the footprint with an average accuracy of 94%, and an accuracy of over 99% on average if feature interactions are known. In a further series of experiments, we predicted main memory consumption of six customizable programs and achieved an accuracy of 89% on average. Conclusion: Our experiments suggest that, with only few measurements, it is possible to accurately predict non-functional properties of products of a product line. Furthermore, we show how already little domain knowledge can improve predictions and discuss trade-offs between accuracy and required number of measurements. With this technique, we provide a basis for many reasoning and product-derivation approaches.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {491–507},
numpages = {17},
keywords = {Measurement, Non-functional properties, Prediction, SPL Conqueror, Software product lines}
}

@inproceedings{10.1145/2019136.2019184,
author = {Holl, Gerald},
title = {Product line bundles to support product derivation in multi product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019184},
doi = {10.1145/2019136.2019184},
abstract = {A multi product line comprises several heterogeneous product lines that are part of a large-scale system. Typically, multi product lines (MPLs) cannot be managed centrally as the involved product lines are developed and evolved by multiple teams that often work independently. Support for modularity and the management of dependencies are thus essential in MPLs. We aim at developing a tool-supported approach for modularizing MPLs to facilitate product derivation in MPLs. We elicit requirements for MPL tool support based on a literature survey and by involving experts from our industry partners. Our approach is based on product line bundles which allow to organize and deploy product line models and specific tool support. We also support the distributed configuration of a MPL based on different types of dependencies between product lines. We will evaluate our research in the laboratory and industrial case studies. We will also conduct experiments to assess the usefulness of the developed tool features.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {41},
numpages = {6},
keywords = {multi product lines, product derivation, tool support},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2791060.2791065,
author = {Gregg, Susan P. and Scharadin, Rick and Clements, Paul},
title = {The more you do, the more you save: the superlinear cost avoidance effect of systems product line engineering},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791065},
doi = {10.1145/2791060.2791065},
abstract = {Product lines that use automated tools to configure shared assets (e.g., software or requirements or test cases or user documentation) based on product descriptions have long been known to bring about substantial development cost avoidance when compared to clone-and-own or product-specific development techniques. Now, however, it can be shown that the cost avoidance for configuring multiple shared assets is superlinear -- that is, the overall cost avoidance exceeds the sum of the that brought about by working with each of the shared assets in isolation. That is, a product line that configures (for example) requirements and code will avoid more cost than the sum of code-based plus requirements-based cost avoidance. In addition, we also observe a superlinear effect in terms of the number of products in the portfolio as well. This paper explores why these effects occur, and presents analytical and empirical evidence for their existence from one of the largest and most successful product lines in the literature, the AEGIS Weapon System. The result may lead to new insight into the economics of product line engineering in the systems engineering realm.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {303–310},
numpages = {8},
keywords = {AEGIS, feature modeling, product configurator, product derivation, product line economics, product line engineering, product line measurement, second generation product line engineering, systems and software product lines, variation points},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2976767.2976804,
author = {Fang, Miao and Leyh, Georg and Doerr, Joerg and Elsner, Christoph},
title = {Multi-variability modeling and realization for software derivation in industrial automation management},
year = {2016},
isbn = {9781450343213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976767.2976804},
doi = {10.1145/2976767.2976804},
abstract = {The systems of industrial automation management (IAM) are in the domain of information systems. IAM systems have software components that support manufacturing processes. The operational parts of IAM coordinate highly plug-compatible hardware devices. These functions lead to process and topology variability, which result in development and reuse challenges for software engineers in practice. This paper presents an approach aiming at improving the development and derivation of one IAM software family within Siemens. The approach integrates feature modeling with domain-specific modeling languages (DSMLs) for variability representation. Moreover, by combining code generation techniques, the configuration of variability models can be used to automate the software derivation. We report on a case study of applying the approach in practice. The outcome shows the enhancement of variability representation by introducing DSMLs and the improvement on automating software derivation. Finally, we present the lessons learned during the execution of this case study.},
booktitle = {Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems},
pages = {2–12},
numpages = {11},
keywords = {code generation, domain-specific modeling, model-based engineering, software derivation, software product line, variability modeling},
location = {Saint-malo, France},
series = {MODELS '16}
}

@inproceedings{10.1145/2364412.2364447,
author = {Vianna, Alexandre and Pinto, Felipe and Sena, Dem\'{o}stenes and Kulesza, Uir\'{a} and Coelho, Roberta and Santos, Jadson and Lima, Jalerson and Lima, Gleydson},
title = {Squid: an extensible infrastructure for analyzing software product line implementations},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364447},
doi = {10.1145/2364412.2364447},
abstract = {Software product line engineering is about producing a set of related products that share more commonalities than variabilities. This approach promotes benefits such as cost reduction, product quality, productivity and time to market, but it brings new challenges that must be considered during the evolution of the software product line. In this context, recent research has explored and proposed automated approaches based on code analysis and traceability techniques for change impact analysis. This paper presents Squid, an extensible infrastructure for analyzing software product line implementations. The approach uses information from variability modeling, variability mapping to code assets, and dependency relationships between code assets to perform analysis of SPL implementations. A Squid instantiation example is presented to illustrate the usage of the tool in practical scenarios.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {209–216},
numpages = {8},
keywords = {software analysis, software product line, software product line evolution},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753274,
author = {Pech, Daniel and Knodel, Jens and Carbon, Ralf and Schitter, Clemens and Hein, Dirk},
title = {Variability management in small development organizations: experiences and lessons learned from a case study},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Product line practices promise to reduce development and maintenance efforts, to improve the productivity and to reduce the time to market by systematic reuse of commonalities and variabilities. However, in order to reap the fruits of exploiting those, an upfront investment is required. This paper presents a case study, which analyzes the cost-benefit ratio for one product line discipline -- variability management. Wikon GmbH -- a small German development organization evolving a product line of remote monitoring and controlling devices -- switched from manual, file-based conditional compilation to tool-supported decision models. We discuss experiences made and show that the break-even was reached with the 4th product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {285–294},
numpages = {10},
keywords = {decision model, evolution, product line engineering, software architecture, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.5555/1753235.1753250,
author = {Jepsen, Hans Peter and Beuche, Danilo},
title = {Running a software product line: standing still is going backwards},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Danfoss Drives - one of the largest producers of frequency converters in the world - has been doing Software Product Line development for its frequency converter products for about 3 years. This paper describes the approach used and the experiences with it. It discusses processes, ways to convince the unconvinced and arising tool issues when doing product line development.This paper is a follow-up on a previous article which described the product line migration process in detail.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {101–110},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2556624.2556643,
author = {Fenske, Wolfram and Th\"{u}m, Thomas and Saake, Gunter},
title = {A taxonomy of software product line reengineering},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556643},
doi = {10.1145/2556624.2556643},
abstract = {In the context of single software systems, refactoring is commonly accepted to be the process of restructuring an existing body of code in order to improve its internal structure without changing its external behavior. This process is vital to the maintenance and evolution of software systems.Software product line engineering is a paradigm for the construction and customization of large-scale software systems. As systems grow in complexity and size, maintaining a clean structure becomes arguably more important. However, product line literature uses the term "refactoring" for such a wide range of reengineering activities that it has become difficult to see how these activities pertain to maintenance and evolution and how they are related.We improve this situation in the following way: i) We identify the dimensions along which product line reengineering occurs. ii) We derive a taxonomy that distinguishes and relates these reengineering activities. iii) We propose definitions for the three main branches of this taxonomy. iv) We classify a corpus of existing work.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {4},
numpages = {8},
keywords = {reengineering, refactoring, software product lines, taxonomy},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1007/s00766-013-0165-8,
author = {Bagheri, Ebrahim and Ensan, Faezeh},
title = {Dynamic decision models for staged software product line configuration},
year = {2014},
issue_date = {June      2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0165-8},
doi = {10.1007/s00766-013-0165-8},
abstract = {Software product line engineering practices offer desirable characteristics such as rapid product development, reduced time-to-market, and more affordable development costs as a result of systematic representation of the variabilities of a domain of discourse that leads to methodical reuse of software assets. The development lifecycle of a product line consists of two main phases: domain engineering, which deals with the understanding and formally modeling of the target domain, and application engineering that is concerned with the configuration of a product line into one concrete product based on the preferences and requirements of the stakeholders. The work presented in this paper focuses on the application engineering phase and builds both the theoretical and technological tools to assist the stakeholders in (a) understanding the complex interactions of the features of a product line; (b) eliciting the utility of each feature for the stakeholders and hence exposing the stakeholders' otherwise implicit preferences in a way that they can more easily make decisions; and (c) dynamically building a decision model through interaction with the stakeholders and by considering the structural characteristics of software product line feature models, which will guide the stakeholders through the product configuration process. Initial exploratory empirical experiments that we have performed show that our proposed approach for helping stakeholders understand their feature preferences and its associated staged feature model configuration process is able to positively impact the quality of the end results of the application engineering process within the context of the limited number of participants. In addition, it has been observed that the offered tooling support is able to ease the staged feature model configuration process.},
journal = {Requir. Eng.},
month = jun,
pages = {187–212},
numpages = {26},
keywords = {Feature models, Software product lines, Stakeholder preferences, Utility elicitation}
}

@article{10.1016/j.infsof.2012.02.005,
author = {Thurimella, Anil Kumar and Bruegge, Bernd},
title = {Issue-based variability management},
year = {2012},
issue_date = {September, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {9},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.02.005},
doi = {10.1016/j.infsof.2012.02.005},
abstract = {Context: Variability management is a key activity in software product line engineering. This paper focuses on managing rationale information during the decision-making activities that arise during variability management. By decision-making we refer to systematic problem solving by considering and evaluating various alternatives. Rationale management is a branch of science that enables decision-making based on the argumentation of stakeholders while capturing the reasons and justifications behind these decisions. Objective: Decision-making should be supported to identify variability in domain engineering and to resolve variation points in application engineering. We capture the rationale behind variability management decisions. The captured rationale information is useful to evaluate future changes of variability models as well as to handle future instantiations of variation points. We claim that maintaining rationale will enhance the longevity of variability models. Furthermore, decisions should be performed using a formal communication between domain engineering and application engineering. Method: We initiate the novel area of issue-based variability management (IVM) by extending variability management with rationale management. The key contributions of this paper are: (i) an issue-based variability management methodology (IVMM), which combines questions, options and criteria (QOC) and a specific variability approach; (ii) a meta-model for IVMM and a process for variability management and (iii) a tool for the methodology, which was developed by extending an open source rationale management tool. Results: Rationale approaches (e.g. questions, options and criteria) guide distributed stakeholders when selecting choices for instantiating variation points. Similarly, rationale approaches also aid the elicitation of variability and the evaluation of changes. The rationale captured within the decision-making process can be reused to perform future decisions on variability. Conclusion: IVMM was evaluated comparatively based on an experimental survey, which provided evidence that IVMM is more effective than a variability modeling approach that does not use issues.},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {933–950},
numpages = {18},
keywords = {Empirical software engineering, Product line engineering, Rationale management, Requirements engineering}
}

@inproceedings{10.1145/3461002.3473951,
author = {Morais Ferreira, David and Tenev, Vasil L. and Becker, Martin},
title = {Product-line analysis cookbook: a classification system for complex analysis toolchains},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473951},
doi = {10.1145/3461002.3473951},
abstract = {Adopting Product Line Engineering (PLE) approaches in the context of software-intensive systems reduces overall development and maintenance costs, reduces time to market and leads to an overall improvement in product quality. The Software and System Product Line (SPL) community has provided a large number of different analysis approaches and tools, which were developed in different contexts, answer different questions, and can contribute to the fulfillment of different analysis goals. Typically, these analysis tools are initially developed as part of a research study, where they serve a specific purpose, e. g. for investigating the use of a new technology, or to demonstrate the transfer of methods from other fields. Generally, such purpose is aligned with a specific, but not explicitly stated, high-level goal. The pursuit of these goals requires holistic approaches, i. e. integrated toolchains and classification of analyses, which are documented as a centralized collection of wisdom. Therefore, we propose a classification system which describes existing analyses and reveals possible combinations, i. e. integrated toolchains, and provide first examples. This method supports the search for toolchains which address complex industrial needs. With the support of the SPL community, we hope to collaboratively document existing analyses and corresponding goals on an open platform.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {99–104},
numpages = {6},
keywords = {holistic toolchain, product line engineering, product-line aware analyses, reverse engineering},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.5555/1753235.1753247,
author = {Chen, Lianping and Ali Babar, Muhammad and Ali, Nour},
title = {Variability management in software product lines: a systematic review},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Variability Management (VM) in Software Product Line (SPL) is a key activity that usually affects the degree to which a SPL is successful. SPL community has spent huge amount of resources on developing various approaches to dealing with variability related challenges over the last decade. To provide an overview of different aspects of the proposed VM approaches, we carried out a systematic literature review of the papers reporting VM in SPL. This paper presents and discusses the findings from this systematic literature review. The results reveal the chronological backgrounds of various approaches over the history of VM research, and summarize the key issues that drove the evolution of different approaches. This study has also identified several gaps that need to be filled by future efforts in this line of research.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {81–90},
numpages = {10},
keywords = {software product lines, systematic reviews, variability management},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2695664.2695797,
author = {Tizzei, Leonardo P. and Azevedo, Leonardo G. and de Bayser, Maximilien and Cerqueira, Renato F. G.},
title = {Architecting cloud tools using software product line techniques: an exploratory study},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695797},
doi = {10.1145/2695664.2695797},
abstract = {Multitenant cloud computing tools are usually complex and have to manage variabilities to support customization. Software Product Line (SPL) techniques have been successfully applied in the industry to manage variability in complex systems. However, few works in the literature discuss the application of SPL techniques to architect industry cloud computing tools, resulting in a lack of support to cloud architects on how to apply such techniques. This work presents how software product line techniques can be applied for architecting cloud tools, and discusses the benefits, drawbacks, and some challenges of applying such techniques to develop a real industry cloud tool, named as Installation Service.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1441–1448},
numpages = {8},
location = {Salamanca, Spain},
series = {SAC '15}
}

@article{10.1016/j.infsof.2012.09.007,
author = {Guana, Victor and Correal, Dario},
title = {Improving software product line configuration: A quality attribute-driven approach},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.09.007},
doi = {10.1016/j.infsof.2012.09.007},
abstract = {Context: During the definition of software product lines (SPLs) it is necessary to choose the components that appropriately fulfil a product's intended functionalities, including its quality requirements (i.e., security, performance, scalability). The selection of the appropriate set of assets from many possible combinations is usually done manually, turning this process into a complex, time-consuming, and error-prone task. Objective: Our main objective is to determine whether, with the use of modeling tools, we can simplify and automate the definition process of a SPL, improving the selection process of reusable assets. Method: We developed a model-driven strategy based on the identification of critical points (sensitivity points) inside the SPL architecture. This strategy automatically selects the components that appropriately match the product's functional and quality requirements. We validated our approach experimenting with different real configuration and derivation scenarios in a mobile healthcare SPL where we have worked during the last three years. Results: Through our SPL experiment, we established that our approach improved in nearly 98% the selection of reusable assets when compared with the unassisted analysis selection. However, using our approach there is an increment in the time required for the configuration corresponding to the learning curve of the proposed tools. Conclusion: We can conclude that our domain-specific modeling approach significantly improves the software architect's decision making when selecting the most suitable combinations of reusable components in the context of a SPL.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {541–562},
numpages = {22},
keywords = {Domain specific modeling, Model driven - software product lines, Quality evaluation, Sensitivity points, Software architecture, Variability management}
}

@inproceedings{10.5555/3155562.3155615,
author = {Lin, Yun and Meng, Guozhu and Xue, Yinxing and Xing, Zhenchang and Sun, Jun and Peng, Xin and Liu, Yang and Zhao, Wenyun and Dong, Jinsong},
title = {Mining implicit design templates for actionable code reuse},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = {In this paper, we propose an approach to detecting project-specific recurring designs in code base and abstracting them into design templates as reuse opportunities. The mined templates allow programmers to make further customization for generating new code. The generated code involves the code skeleton of recurring design as well as the semi-implemented code bodies annotated with comments to remind programmers of necessary modification. We implemented our approach as an Eclipse plugin called MICoDe. We evaluated our approach with a reuse simulation experiment and a user study involving 16 participants. The results of our simulation experiment on 10 open source Java projects show that, to create a new similar feature with a design template, (1) on average 69% of the elements in the template can be reused and (2) on average 60% code of the new feature can be adopted from the template. Our user study further shows that, compared to the participants adopting the copy-paste-modify strategy, the ones using MICoDe are more effective to understand a big design picture and more efficient to accomplish the code reuse task.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {394–404},
numpages = {11},
keywords = {code generation, design template, duplicated design, mining, recurring design},
location = {Urbana-Champaign, IL, USA},
series = {ASE '17}
}

@inproceedings{10.1145/3267183.3267188,
author = {Barbosa, Jefferson and Andrade, Rossana M. C. and Filho, Jo\~{a}o Bosco F. and Bezerra, Carla I. M. and Barreto, Isaac and Capilla, Rafael},
title = {Cloning in Customization Classes: A Case of a Worldwide Software Product Line},
year = {2018},
isbn = {9781450365543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267183.3267188},
doi = {10.1145/3267183.3267188},
abstract = {Cloning-and-owning, in the long run, can severely affect evolution, as changes in cloned fragments may require modifications in various parts of the system. This problem scales if cloning is used in classes that derive products in a Software Product Line, because these classes can impact in several features and products. However, it is hard to know to which extent cloning in customization classes can impact in a project. We conduct a study, within an SPL that generates mobile software for over 150 countries, to analyze cloning practices and how cloned parts relate to the maintainability of customization classes. We collect and identify clones inside customization classes during a period of 13 months, involving 70 customization classes and 5 branches. In parallel, we collect the respective issues from the issue tracking tool of the SPL project, obtaining over 140 issues related to customization classes. We then confront the time spent to solve each issue with its nature (i.e., if it relates to cloned code or not). As first result, we verify that issues related to cloning take in average 136% more time to be solved. Our study helps to understand how cloning relates to maintainability in the context of mass customization, giving insights about cloned code evolution and its impacts in a software product line project.},
booktitle = {Proceedings of the VII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {43–52},
numpages = {10},
keywords = {Clone, Customization, Software Product Line},
location = {Sao Carlos, Brazil},
series = {SBCARS '18}
}

@inproceedings{10.1145/1985484.1985489,
author = {Michalik, Bartosz and Weyns, Danny and Van Betsbrugge, Wim},
title = {On the problems with evolving Egemin's software product line},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985489},
doi = {10.1145/1985484.1985489},
abstract = {Egemin, an industrial manufacturer of logistic systems is adopting a Software Product Line (SPL) approach to manage the development of their product portfolio. However, due to the intrinsic complexity of the logistic systems and lack of explicitly documented architectural knowledge evolution of the products is error-prone. Faulty updates increase maintenance costs and harm the company's reputation. Therefore, Egemin searches for a systematic solution that can improve their SPL evolution strategy.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {15–19},
numpages = {5},
keywords = {evolution, software product line, spl},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@article{10.1145/2180921.2180941,
author = {Ripon, Shamim H.},
title = {A unified tabular method for modeling variants of software product line},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/2180921.2180941},
doi = {10.1145/2180921.2180941},
abstract = {Reuse of software is a promising approach to improving the efficiency of software development regarding time, cost and quality. Reuse requires a systematic approach. The best results are achieved if we focus on systems in a specific domain, so-called product line. The key difference between the conventional software engineering and software product line engineering is variant management. The main idea of software product line is to identify the common core functionality which can be implemented once and reused afterwards for all members of the product line. To facilitate this reuse opportunity the domain engineering phase makes the domain model comprising the common as well as variant requirements. In principle, common requirements among systems in a family are easy to handle. However, problem arises during handling variants. Different variants have dependencies on each other; a single variant can affect several variants of the domain model. These problems become complex when the volume of information grows in a domain and there are a lot of variants with several interdependencies. Hence, a separate model is required for handling the variants. This paper presents a mechanism, which we call, Unified Tabular Method to facilitate the management of variant dependencies in product lines. The tabular method consists of a variant part to model the variants and their dependencies, and a decision table to depict the customization decision regarding each variant while deriving customized products. Tabular method alleviates the problem of possible explosion of variant combinations and facilitates the tracing of variant information in the domain model},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–7},
numpages = {7},
keywords = {modeling variants, software product line, unified tabular method}
}

@inproceedings{10.1145/3461002.3473068,
author = {Santos, Edilton Lima dos},
title = {STARS: software technology for adaptable and reusable systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473068},
doi = {10.1145/3461002.3473068},
abstract = {Dynamic Software Product Lines (DSPLs) engineering implements self-adaptive systems by dynamically binding or unbinding features at runtime according to a feature model. However, these features may interact in unexpected and undesired ways leading to critical consequences for the DSPL. Moreover, (re)configurations may negatively affect the runtime system's architectural qualities, manifesting architectural bad smells. These issues are challenging to detect due to the combinatorial explosion of the number of interactions amongst features. As some of them may appear at runtime, we need a runtime approach to their analysis and mitigation. This thesis introduces the Behavioral Map (BM) formalism that captures information from different sources (feature model, code) to automatically detect these issues. We provide behavioral map inference algorithms. Using the Smart Home Environment (SHE) as a case study, we describe how a BM is helpful to identify critical feature interactions and architectural smells. Our preliminary results already show promising progress for both feature interactions and architectural bad smells identification at runtime.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {13–17},
numpages = {5},
keywords = {MAPE-K loop, dynamic software product lines engineering, self-adapting system, software architecture, software product line engineering, software testing},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-642-36757-1_11,
author = {Zhang, Xiaorui and M\o{}ller-Pedersen, Birger},
title = {Towards correct product derivation in model-driven product lines},
year = {2012},
isbn = {9783642367564},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-36757-1_11},
doi = {10.1007/978-3-642-36757-1_11},
abstract = {In a product line model, the product line developer often specifies not only high-level domain features but also their low-level realization steps. We see two challenges against deriving and intended products with respect to the specification of feature realizations:1 The developer is not provided with immediate feedback on the realization steps at design time.2 How to ensure that the realization steps are consistent with high-level features.The Common Variability Language (CVL) is a generic language for modeling variability and the CVL tool can be used for product line development. We propose two extensions to the CVL tool to address the aforementioned challenges:1 A simulator that simulates the feature realizations and visualizes the resulting product model at design time.2 A consistency checker that checks if the realizations are consistent with high-level features.We illustrate these two added procedures by applying them to the development of a train control product line. A tool prototype is implemented and used for evaluation.},
booktitle = {Proceedings of the 7th International Conference on System Analysis and Modeling: Theory and Practice},
pages = {179–197},
numpages = {19},
keywords = {common variability language, model-driven software product line, product derivation},
location = {Innsbruck, Austria},
series = {SAM'12}
}

@article{10.4018/ijkss.2014100104,
author = {Ripon, Shamim H and Hossain, Sk. Jahir and Piash, Moshiur Mahamud},
title = {Logic-Based Analysis and Verification of Software Product Line Variant Requirement Model},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100104},
doi = {10.4018/ijkss.2014100104},
abstract = {Software Product Line SPL provides the facility to systematically reuse of software improving the efficiency of software development regarding time, cost and quality. The main idea of SPL is to identify the common core functionality that can be implemented once and reused afterwards. A variant model has also to be developed to manage the variants of the SPL. Usually, a domain model consisting of the common and variant requirements is developed during domain engineering phase to alleviate the reuse opportunity. The authors present a product line model comprising of a variant part for the management of variant and a decision table to depict the customization of decision regarding each variant. Feature diagrams are widely used to model SPL variants. Both feature diagram and our variant model, which is based on tabular method, lacks logically sound formal representation and hence, not amenable to formal verification. Formal representation and verification of SPL has gained much interest in recent years. This chapter presents a logical representation of the variant model by using first order logic. With this representation, the table based variant model as well as the graphical feature diagram can now be verified logically. Besides applying first-order-logic to model the features, the authors also present an approach to model and analyze SPL model by using semantic web approach using OWL-DL. The OWL-DL representation also facilitates the search and maintenance of feature models and support knowledge sharing within a reusable engineering context. Reasoning tools are used to verify the consistency of the feature configuration for both logic-based and semantic web-based approaches.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {52–76},
numpages = {25},
keywords = {Domain Model, Feature Diagrams, OWL-DL, Software Product Line SPL, Web-Based Approaches}
}

@article{10.1016/j.infsof.2012.03.008,
author = {O'Leary, P\'{a}Draig and De Almeida, Eduardo Santana and Richardson, Ita},
title = {The Pro-PD Process Model for Product Derivation within software product lines},
year = {2012},
issue_date = {September, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {9},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.03.008},
doi = {10.1016/j.infsof.2012.03.008},
abstract = {Background: The derivation of products from a software product line is a time consuming and expensive activity. Despite recognition that an effective process could alleviate many of the difficulties associated with product derivation, existing approaches have different scope, emphasise different aspects of the derivation process and are frequently too specialised to serve as a general solution. Objective: To define a systematic process that will provide a structured approach to the derivation of products from a software product line, based on a set of tasks, roles and artefacts. Method: Through a series of research stages using sources in industry and academia, this research has developed a Process Model for Product Derivation (Pro-PD). We document the evidence for the construction of Pro-PD and the design decisions taken. We evaluate Pro-PD through comparison with prominent existing approaches and standards. Results: This research presents a Process Model for Product Derivation (Pro-PD). Pro-PD describes the tasks, roles and work artefacts used to derive products from a software product line. Conclusion: In response to a need for methodological support, we developed Pro-PD (Process Model for Product Derivation). Pro-PD was iteratively developed and evaluated through four research stages. Our research is a first step toward an evidence-based methodology for product derivation and a starting point for the definition of a product derivation approach.},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {1014–1028},
numpages = {15},
keywords = {Process, Product derivation, Software product lines}
}

@article{10.1145/3034827,
author = {Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
title = {CASE Tool Support for Variability Management in Software Product Lines},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3034827},
doi = {10.1145/3034827},
abstract = {Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools’ characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {14},
numpages = {45},
keywords = {Software engineering, computer-aided software engineering, software variability}
}

@inproceedings{10.5555/1753235.1753253,
author = {O'Leary, P\'{a}draig and Rabiser, Rick and Richardson, Ita and Thiel, Steffen},
title = {Important issues and key activities in product derivation: experiences from two independent research projects},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {When compared to the vast amount of research on domain engineering and building product lines, relatively little work has been dedicated to the derivation of individual products from product lines. Existing approaches to product derivation have been developed in isolation with different aims and purposes. The definition of a generic product derivation approach applicable to every domain may not be possible. However, comparing existing approaches allows the identification of both important issues to be addressed and key activities to be supported. In this experience paper we report on how we compared two product derivation approaches developed in two different, independent research projects. Based on the comparison and our experiences, we identify key activities that any approach to product derivation should consider. Additionally, we point out areas of uncertainty and identify remaining challenges within product derivation.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {121–130},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2523599.2523604,
author = {Urli, Simon and Blay-Fornarino, Mireille and Collet, Philippe and Mosser, S\'{e}bastien},
title = {Using composite feature models to support agile software product line evolution},
year = {2012},
isbn = {9781450317986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2523599.2523604},
doi = {10.1145/2523599.2523604},
abstract = {Managing continuous change in a Software Product Line (SPL) is one of the challenges now faced by the SPL engineering community. On the one hand, the SPL paradigm captures the intrinsic variability of a software based on a systemic vision of the software to model. On the other hand, Agile Software Development advocates the incremental development of software based on constant interaction with a customer community. In this paper, we present an approach based on Composite Feature Models (CFM) to support the agile evolution of a SPL. This study is driven by the refactoring of a daily used application (information broadcasting system), in the context of a nationally funded project. Preliminary results show that CFMs support the incremental development of a SPL based on interactions with a community, tackling the challenge of SPL continuous evolution.},
booktitle = {Proceedings of the 6th International Workshop on Models and Evolution},
pages = {21–26},
numpages = {6},
keywords = {agile, evolution, feature model, software product line},
location = {Innsbruck, Austria},
series = {ME '12}
}

@article{10.1016/j.jss.2007.10.025,
author = {Hanssen, Geir K. and F\'{\i}gri, Tor E.},
title = {Process fusion: An industrial case study on agile software product line engineering},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {6},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.10.025},
doi = {10.1016/j.jss.2007.10.025},
abstract = {This paper presents a case study of a software product company that has successfully integrated practices from software product line engineering and agile software development. We show how practices from the two fields support the company's strategic and tactical ambitions, respectively. We also discuss how the company integrates strategic, tactical and operational processes to optimize collaboration and consequently improve its ability to meet market needs, opportunities and challenges. The findings from this study are relevant to software product companies seeking ways to balance agility and product management. The findings also contribute to research on industrializing software engineering.},
journal = {J. Syst. Softw.},
month = jun,
pages = {843–854},
numpages = {12},
keywords = {Agile software development, Software product development, Software product line engineering, Software product management}
}

@article{10.1007/s10270-015-0471-3,
author = {Bonif\'{a}cio, Rodrigo and Borba, Paulo and Ferraz, Cristiano and Accioly, Paola},
title = {Empirical assessment of two approaches for specifying software product line use case scenarios},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0471-3},
doi = {10.1007/s10270-015-0471-3},
abstract = {Modularity benefits, including the independent maintenance and comprehension of individual modules, have been widely advocated. However, empirical assessments to investigate those benefits have mostly focused on source code, and thus, the relevance of modularity to earlier artifacts is still not so clear (such as requirements and design models). In this paper, we use a multimethod technique, including designed experiments, to empirically evaluate the benefits of modularity in the context of two approaches for specifying product line use case scenarios: PLUSS and MSVCM. The first uses an annotative approach for specifying variability, whereas the second relies on aspect-oriented constructs for separating common and variant scenario specifications. After evaluating these approaches through the specifications of several systems, we find out that MSVCM reduces feature scattering and improves scenario cohesion. These results suggest that evolving a product line specification using MSVCM requires only localized changes. On the other hand, the results of six experiments reveal that MSVCM requires more time to derive the product line specifications and, contrasting with the modularity results, reduces the time to evolve a product line specification only when the subjects have been well trained and are used to the task of evolving product line specifications.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {97–123},
numpages = {27},
keywords = {Experimentation in software engineering, Requirements engineering, Software modularity, Software product lines, Usage scenarios}
}

@article{10.1016/j.infsof.2012.07.017,
author = {Ghezzi, Carlo and Molzam Sharifloo, Amir},
title = {Model-based verification of quantitative non-functional properties for software product lines},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.017},
doi = {10.1016/j.infsof.2012.07.017},
abstract = {Evaluating quality attributes of a design model in the early stages of development can significantly reduce the cost and risks of developing a low quality product. To make this possible, software designers should be able to predict quality attributes by reasoning on a model of the system under development. Although there exists a variety of quality-driven analysis techniques for software systems, only a few work address software product lines. This paper describes how probabilistic model checking techniques and tools can be used to verify non-functional properties of different configurations of a software product line. We propose a model-based approach that enables software engineers to assess their design solutions for software product lines in the early stages of development. Furthermore, we discuss how the analysis time can be surprisingly reduced by applying parametric model checking instead of classic model checking. The results show that the parametric approach is able to substantially alleviate the verification time and effort required to analyze non-functional properties of software product lines.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {508–524},
numpages = {17},
keywords = {Non-functional requirements, Parametric verification, Probabilistic model checking, Quality analysis, Software product lines}
}

@inproceedings{10.5555/1753235.1753258,
author = {Ganesan, Dharmalingam and Lindvall, Mikael and Ackermann, Chris and McComas, David and Bartholomew, Maureen},
title = {Verifying architectural design rules of the flight software product line},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {This paper presents experiences of verifying architectural design rules of the NASA Core Flight Software (CFS) product line implementation. The goal is to check whether the implementation is consistent with the CFS' architectural rules derived from the developer's guide. The results indicate that consistency checking helps a) identifying architecturally significant deviations that were eluded during code reviews, b) clarifying the design rules to the team, and c) assessing the overall implementation quality. Furthermore, it helps connecting business goals to architectural principles, and to the implementation. This paper is the first step in the definition of a method for analyzing and evaluating product line implementations from an architecture-centric perspective.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {161–170},
numpages = {10},
keywords = {architectural rules, business goals, flight software, implemented architecture},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3461001.3471148,
author = {Krieter, Sebastian and Arens, Rahel and Nieke, Michael and Sundermann, Chico and He\ss{}, Tobias and Th\"{u}m, Thomas and Seidl, Christoph},
title = {Incremental construction of modal implication graphs for evolving feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471148},
doi = {10.1145/3461001.3471148},
abstract = {A feature model represents a set of variants as configurable features and dependencies between them. During variant configuration, (de)selection of a feature may entail that other features must or cannot be selected. A Modal Implication Graph (MIG) enables efficient decision propagation to perform automatic (de)selection of subsequent features. In addition, it facilitates other configuration-related activities such as t-wise sampling. Evolution of a feature model may change its configuration logic, thereby invalidating an existing MIG and forcing a full recomputation. However, repeated recomputation of a MIG is expensive, and thus hampers the overall usefulness of MIGs for frequently evolving feature models. In this paper, we devise a method to incrementally compute updated MIGs after feature model evolution. We identify expensive steps in the MIG construction algorithm, enable them for incremental computation, and measure performance compared to a full rebuild of a complete MIG within the evolution histories of four real-world feature models. Results show that our incremental method can increase the speed of MIG construction by orders of magnitude, depending on the given scenario and extent of evolutionary changes.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {64–74},
numpages = {11},
keywords = {configurable system, evolution, software product line},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/1814392.1814397,
author = {bin Abid, Saad},
title = {Resolving feature dependency implementations inconsistencies during product derivation},
year = {2010},
isbn = {9781605589930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814392.1814397},
doi = {10.1145/1814392.1814397},
abstract = {Features implementing the functionality in a software product line (SPL) often interact and depend on each other. It is hard to maintain the consistency between feature dependencies on the model level and the actual implementation over time, resulting in inconsistency during product derivation. We describe our initial results when working with feature dependency implementations and the related inconsistencies in actual code. Our aim is to improve consistency checking during product derivation. We have provided tool support for maintaining consistency between feature dependency implementations on both model and code levels in a product line. The tool chain supports the consistency checking on both the domain engineering and the application levels between actual code and models. We report our experience of managing feature dependency consistency in the context of an existing scientific calculator product line.},
booktitle = {Proceedings of the 6th ECMFA Traceability Workshop},
pages = {31–38},
numpages = {8},
keywords = {AspectJ programming, aspect-oriented product line, consistency checking, feature implementation dependencies, product derivation, software product lines, tool support, variability models},
location = {Paris, France},
series = {ECMFA-TW '10}
}

@inproceedings{10.1145/2996890.3007893,
author = {Ruiz, Carlos and Duran-Limon, Hector A. and Parlavantzas, Nikos},
title = {Towards a software product line-based approach to adapt IaaS cloud configurations},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.3007893},
doi = {10.1145/2996890.3007893},
abstract = {Cloud computing is nowadays one of the most promising IT technologies, since it provides seemingly unlimited resources on demand at low costs. Hence, different types of applications have been migrated to IaaS environments, e.g. multi-tier (distributed) applications. However, in order to benefit from such characteristics, cloud configurations (i.e. virtual resource configurations) should be designed accordingly to the necessities of the applications. Furthermore, such configurations have to provide the required resources not only at the application deployment-time, but also during the whole application execution time. Hence, adaptive paradigms are required when designing solutions to cloud applications with dynamic resource requirements. Software Product Lines (SPLs) provide great flexibility and a high level of abstraction to describe complete system configurations. Even though SPLs are not commonly used to describe changes after an initial product (configuration) has been created, their inherent characteristics can enable producing the required virtual resource configuration to adapt applications after their initial deployment, i.e., at runtime. In this paper, we present an approach to create and adapt cloud configurations at the IaaS level by using SPLs. We focus on the architectural design of our solution as well as on the possible implementation challenges we could face.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {398–403},
numpages = {6},
keywords = {cloud computing, self-adaptation, software product lines},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {machine learning, quality assurance, software product line, software testing, software variability},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.infsof.2011.01.001,
author = {Peng, Xin and Yu, Yijun and Zhao, Wenyun},
title = {Analyzing evolution of variability in a software product line: From contexts and requirements to features},
year = {2011},
issue_date = {July, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {7},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.01.001},
doi = {10.1016/j.infsof.2011.01.001},
abstract = {Context: In the long run, features of a software product line (SPL) evolve with respect to changes in stakeholder requirements and system contexts. Neither domain engineering nor requirements engineering handles such co-evolution of requirements and contexts explicitly, making it especially hard to reason about the impact of co-changes in complex scenarios. Objective: In this paper, we propose a problem-oriented and value-based analysis method for variability evolution analysis. The method takes into account both kinds of changes (requirements and contexts) during the life of an evolving software product line. Method: The proposed method extends the core requirements engineering ontology with the notions to represent variability-intensive problem decomposition and evolution. On the basis of problemorientation, the analysis method identifies candidate changes, detects influenced features, and evaluates their contributions to the value of the SPL. Results and Conclusion: The process of applying the analysis method is illustrated using a concrete case study of an evolving enterprise software system, which has confirmed that tracing back to requirements and contextual changes is an effective way to understand the evolution of variability in the software product line.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {707–721},
numpages = {15},
keywords = {Context, Evolution, Feature, Requirements, Software product line, Variability}
}

@article{10.1016/j.jss.2010.09.042,
author = {Rabiser, Rick and O'Leary, P\'{a}draig and Richardson, Ita},
title = {Key activities for product derivation in software product lines},
year = {2011},
issue_date = {February, 2011},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {2},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2010.09.042},
doi = {10.1016/j.jss.2010.09.042},
abstract = {More and more organizations adopt software product lines to leverage extensive reuse and deliver a multitude of benefits such as increased quality and productivity and a decrease in cost and time-to-market of their software development. When compared to the vast amount of research on developing product lines, relatively little work has been dedicated to the actual use of product lines to derive individual products, i.e., the process of product derivation. Existing approaches to product derivation have been developed independently for different aims and purposes. While the definition of a general approach applicable to every domain may not be possible, it would be interesting for researchers and practitioners to know which activities are common in existing approaches, i.e., what are the key activities in product derivation. In this paper we report on how we compared two product derivation approaches developed by the authors in two different, independent research projects. Both approaches independently sought to identify product derivation activities, one through a process reference model and the other through a tool-supported derivation approach. Both approaches have been developed and validated in research industry collaborations with different companies. Through the comparison of the approaches we identify key product derivation activities. We illustrate the activities' importance with examples from industry collaborations. To further validate the activities, we analyze three existing product derivation approaches for their support for these activities. The validation provides evidence that the identified activities are relevant to product derivation and we thus conclude that they should be considered (e.g., as a checklist) when developing or evaluating a product derivation approach.},
journal = {J. Syst. Softw.},
month = feb,
pages = {285–300},
numpages = {16},
keywords = {Process, Product derivation, Software product lines}
}

@inproceedings{10.1145/3307630.3342705,
author = {Krieter, Sebastian},
title = {Enabling Efficient Automated Configuration Generation and Management},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342705},
doi = {10.1145/3307630.3342705},
abstract = {Creating and managing valid configurations is one of the main tasks in software product line engineering. Due to the often complex constraints from a feature model, some kind of automated configuration generation is required to facilitate the configuration process for users and developers. For instance, decision propagation can be applied to support users in configuring a product from a software product line (SPL) with less manual effort and error potential, leading to a semi-automatic configuration process. Furthermore, fully-automatic configuration processes, such as random sampling or t-wise interaction sampling can be employed to test or to optimize an SPL. However, current techniques for automated configuration generation still do not scale well to SPLs with large and complex feature models. Within our thesis, we identify current challenges regarding the efficiency and effectiveness of the semi- and fully-automatic configuration process and aim to address these challenges by introducing novel techniques and improving current ones. Our preliminary results show already show promising progress for both, the semi- and fully-automatic configuration process.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {215–221},
numpages = {7},
keywords = {configurable system, decision propagation, software product lines, t-wise sampling, uniform random sampling},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10009-012-0229-y,
author = {Heider, Wolfgang and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Facilitating the evolution of products in product line engineering by capturing and replaying configuration decisions},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0229-y},
doi = {10.1007/s10009-012-0229-y},
abstract = {Software product lines rely on developing reusable artifacts and defining their variability in models to support and accelerate the derivation of individual products. A major challenge in product lines is the continuous evolution of both the reusable artifacts and derived products. Products that have been derived from a product line have to be updated regularly, e.g., after bugfixes or the development of new features. Changes to reusable artifacts and variability models have to be propagated to derived products. The aim of our research is to provide automated support for the evolution of products derived from product lines by capturing and replaying configuration decisions. Our PUPLE (Product Updates in Product Line Engineering) approach supports updating derived products after changes to the product line they have been derived from. It exploits the structure of variability models and uses change-tracking data to minimize user intervention. The paper first explores how different types of product line changes influence the derived products. It then presents extensions to our decision-oriented product line approach DOPLER to support product line evolution. We evaluate the feasibility of the PUPLE approach with evolution tasks that were performed by engineers of an industry partner on a product line of an Eclipse-based tool suite with six derived products. We conclude with lessons learned and limitations of our approach.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {613–630},
numpages = {18},
keywords = {Product line engineering, Product update tool, Software evolution}
}

@inproceedings{10.1145/3336294.3336318,
author = {Ebert, Rolf and Jolianis, Jahir and Kriebel, Stefan and Markthaler, Matthias and Pruenster, Benjamin and Rumpe, Bernhard and Salman, Karin Samira},
title = {Applying Product Line Testing for the Electric Drive System},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336318},
doi = {10.1145/3336294.3336318},
abstract = {The growth in electrification and digitalization of vehicles leads to increasing variability and complexity of automotive systems. This poses new challenges for verification and validation, identified in a Product Line Engineering case study for the electric drive system. To overcome those challenges we developed a Product Line Testing methodology called TIGRE. In this paper, we present the TIGRE methodology. TIGRE comprises the identification and documentation of relevant data for efficient product line testing and the application of this data in the test management of an agile project environment. Furthermore, we present our experiences from the introduction into a large-scale industrial context. Based on our results from the introduction, we conclude that the TIGRE approach reduces the testing effort for automotive product lines significantly and, furthermore, allows us to transfer the results to untested products.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {14–24},
numpages = {11},
keywords = {automotive industry, product line engineering, product line testing, software product lines},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2362536.2362548,
author = {Soltani, Samaneh and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on functional and non-functional requirements},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362548},
doi = {10.1145/2362536.2362548},
abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {56–65},
numpages = {10},
keywords = {artificial intelligence, configuration, feature model, planning techniques, software product line engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2755567.2755568,
author = {Oliveira, Edson and Allian, Ana P.},
title = {Do Reference Architectures can Contribute to Standardizing Variability Management Tools?},
year = {2015},
isbn = {9781450334457},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2755567.2755568},
doi = {10.1145/2755567.2755568},
abstract = {Variability Management (VM) is one of the core activities for the success of software reuse. Several VM tools developed in academia and industry support mass customization of new software products and decrease time to market. Despite of a significant number of VM tools, in most cases, industry has adopted different techniques for managing variability, including producing their own tools. Such a heterogeneity provides difficulties in establishing VM, product customization and derivation, and standardization. From another perspective, reference architectures (RA) are a special type of software architecture as it encompasses specific domain knowledge, making it easier the development, standardization and evolution of software systems. Concepts from reference architectures can mitigate the lacking of VM tools standardization. Therefore, this position paper presents a vision towards supporting architectural standardization of VM tools, through reference architectures, for achieving a well-recognized understanding of such a domain and promoting reuse of design expertise. In this context, the main contribution of this paper is providing a discussion with regard to reference architectures and variability management tools towards supporting answering the following research question: "Do reference architectures can contribute to standardizing VM tools"?. Such standardization is useful as it fosters interoperability and reuse.},
booktitle = {Proceedings of the 1st International Workshop on Exploring Component-Based Techniques for Constructing Reference Architectures},
pages = {9–12},
numpages = {4},
keywords = {reference architectures, standardization, variability management tools},
location = {Montr\'{e}al, QC, Canada},
series = {CobRA '15}
}

@article{10.1016/j.jss.2011.04.066,
author = {Cirilo, Elder and Nunes, Ingrid and Kulesza, Uir\'{a} and Lucena, Carlos},
title = {Automating the product derivation process of multi-agent systems product lines},
year = {2012},
issue_date = {February, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {85},
number = {2},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.04.066},
doi = {10.1016/j.jss.2011.04.066},
abstract = {Agent-oriented software engineering and software product lines are two promising software engineering techniques. Recent research work has been exploring their integration, namely multi-agent systems product lines (MAS-PLs), to promote reuse and variability management in the context of complex software systems. However, current product derivation approaches do not provide specific mechanisms to deal with MAS-PLs. This is essential because they typically encompass several concerns (e.g., trust, coordination, transaction, state persistence) that are constructed on the basis of heterogeneous technologies (e.g., object-oriented frameworks and platforms). In this paper, we propose the use of multi-level models to support the configuration knowledge specification and automatic product derivation of MAS-PLs. Our approach provides an agent-specific architecture model that uses abstractions and instantiation rules that are relevant to this application domain. In order to evaluate the feasibility and effectiveness of the proposed approach, we have implemented it as an extension of an existing product derivation tool, called GenArch. The approach has also been evaluated through the automatic instantiation of two MAS-PLs, demonstrating its potential and benefits to product derivation and configuration knowledge specification.},
journal = {J. Syst. Softw.},
month = feb,
pages = {258–276},
numpages = {19},
keywords = {Application engineering, Model-driven development, Multi-agent systems, Product derivation tool, Software product lines}
}

@article{10.1007/s11219-011-9152-9,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Kuhlemann, Martin and K\"{a}stner, Christian and Apel, Sven and Saake, Gunter},
title = {SPL Conqueror: Toward optimization of non-functional properties in software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9152-9},
doi = {10.1007/s11219-011-9152-9},
abstract = {A software product line (SPL) is a family of related programs of a domain. The programs of an SPL are distinguished in terms of features, which are end-user visible characteristics of programs. Based on a selection of features, stakeholders can derive tailor-made programs that satisfy functional requirements. Besides functional requirements, different application scenarios raise the need for optimizing non-functional properties of a variant. The diversity of application scenarios leads to heterogeneous optimization goals with respect to non-functional properties (e.g., performance vs. footprint vs. energy optimized variants). Hence, an SPL has to satisfy different and sometimes contradicting requirements regarding non-functional properties. Usually, the actually required non-functional properties are not known before product derivation and can vary for each application scenario and customer. Allowing stakeholders to derive optimized variants requires us to measure non-functional properties after the SPL is developed. Unfortunately, the high variability provided by SPLs complicates measurement and optimization of non-functional properties due to a large variant space. With SPL Conqueror, we provide a holistic approach to optimize non-functional properties in SPL engineering. We show how non-functional properties can be qualitatively specified and quantitatively measured in the context of SPLs. Furthermore, we discuss the variant-derivation process in SPL Conqueror that reduces the effort of computing an optimal variant. We demonstrate the applicability of our approach by means of nine case studies of a broad range of application domains (e.g., database management and operating systems). Moreover, we show that SPL Conqueror is implementation and language independent by using SPLs that are implemented with different mechanisms, such as conditional compilation and feature-oriented programming.},
journal = {Software Quality Journal},
month = sep,
pages = {487–517},
numpages = {31},
keywords = {Feature-oriented software development, Measurement and optimization, Non-functional properties, SPL Conqueror, Software product lines}
}

@inproceedings{10.1145/2430502.2430529,
author = {Zhang, Bo and Becker, Martin},
title = {Mining complex feature correlations from software product line configurations},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430529},
doi = {10.1145/2430502.2430529},
abstract = {As a Software Product Line (SPL) evolves with increasing number of features and feature values, the feature correlations become extremely intricate, and the specifications of these correlations tend to be either incomplete or inconsistent with their realizations, causing misconfigurations in practice. In order to guide product configuration processes, we present a solution framework to recover complex feature correlations from existing product configurations. These correlations are further pruned automatically and validated by domain experts. During implementation, we use association mining techniques to automatically extract strong association rules as potential feature correlations. This approach is evaluated using a large-scale industrial SPL in the embedded system domain, and finally we identify a large number of complex feature correlations.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {7},
keywords = {association mining, feature correlation, product line configuration},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@article{10.1016/j.jss.2013.12.038,
author = {Capilla, Rafael and Bosch, Jan and Trinidad, Pablo and Ruiz-Cort\'{e}s, Antonio and Hinchey, Mike},
title = {An overview of Dynamic Software Product Line architectures and techniques: Observations from research and industry},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.12.038},
doi = {10.1016/j.jss.2013.12.038},
abstract = {Over the last two decades, software product lines have been used successfully in industry for building families of systems of related products, maximizing reuse, and exploiting their variable and configurable options. In a changing world, modern software demands more and more adaptive features, many of them performed dynamically, and the requirements on the software architecture to support adaptation capabilities of systems are increasing in importance. Today, many embedded system families and application domains such as ecosystems, service-based applications, and self-adaptive systems demand runtime capabilities for flexible adaptation, reconfiguration, and post-deployment activities. However, as traditional software product line architectures fail to provide mechanisms for runtime adaptation and behavior of products, there is a shift toward designing more dynamic software architectures and building more adaptable software able to handle autonomous decision-making, according to varying conditions. Recent development approaches such as Dynamic Software Product Lines (DSPLs) attempt to face the challenges of the dynamic conditions of such systems but the state of these solution architectures is still immature. In order to provide a more comprehensive treatment of DSPL models and their solution architectures, in this research work we provide an overview of the state of the art and current techniques that, partially, attempt to face the many challenges of runtime variability mechanisms in the context of Dynamic Software Product Lines. We also provide an integrated view of the challenges and solutions that are necessary to support runtime variability mechanisms in DSPL models and software architectures.},
journal = {J. Syst. Softw.},
month = may,
pages = {3–23},
numpages = {21},
keywords = {Dynamic Software Product Lines, Dynamic variability, Feature models, Software architecture}
}

@inproceedings{10.1145/3461002.3473941,
author = {Fadhlillah, Hafiyyan Sayyid and Feichtinger, Kevin and Sonnleithner, Lisa and Rabiser, Rick and Zoitl, Alois},
title = {Towards heterogeneous multi-dimensional variability modeling in cyber-physical production systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473941},
doi = {10.1145/3461002.3473941},
abstract = {Cyber-Physical Production Systems (CPPSs) are complex systems interacting with their environment by sensors and actuators. Such systems typically have a long lifespan, over which a plethora of variants are developed and maintained. The heterogeneity of hardware and software components used in CPPSs and the multiple disciplines (mechanical, electrical, software engineering) involved in the development and maintenance of CPPSs, however, make it difficult to manage their variability. Specifically, variability needs to be expressed in and across multiple disciplines, which use heterogeneous methods and tools. This also affects configuration as well as co-evolution of models and artifacts. In this short paper, we discuss our first ideas towards a Heterogeneous Multi-Dimensional Variability Modeling approach for CPPSs. Our approach builds on and extends existing work to address the challenges of modeling the variability of CPPSs and supporting their configuration and evolution. We showcase our idea using a case study system and outline a research agenda.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {123–129},
numpages = {7},
keywords = {cyber-physical production system, software configuration, software product line, variability modeling},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.5555/2022115.2022131,
author = {Wu, Yijian and Peng, Xin and Zhao, Wenyun},
title = {Architecture evolution in software product line: an industrial case study},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A software product line (SPL) usually involves a shared set of core assets and a series of application products. To ensure consistency, the evolution of the core assets and all the application products should be coordinated and synchronized under a unified evolution process. Therefore, SPL evolution often involves cross-product propagation and synchronization besides application derivation based on core assets, presenting quite different characteristic from the evolution of individual software products. As software architectures, including the product line architecture (PLA) and application architectures, play a central role in SPL engineering and evolution, architecture-based evolution analysis is a natural way for analyzing and managing SPL evolution. In this paper, we explore common practices of architecture evolution and the rationale behind in industrial SPL development. To this end, we conduct a case study with Wingsoft examination system product line (WES-PL), an industrial product line with an evolution history of eight years and more than 10 application products. In the case study, we reviewed the evolution history of WES-PL architecture and analyzed several typical evolution cases. Based on the historical analysis, we identify some special problems in industrial SPL practice from the aspect of architecture evolution and summarize some useful experiences about SPL evolution decisions to complement classical SPL methodology. On the other hand, we also propose some possible improvements for the evolution management in WES-PL.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {135–150},
numpages = {16},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1145/2491627.2491655,
author = {Dumitrescu, Cosmin and Mazo, Raul and Salinesi, Camille and Dauron, Alain},
title = {Bridging the gap between product lines and systems engineering: an experience in variability management for automotive model based systems engineering},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491655},
doi = {10.1145/2491627.2491655},
abstract = {We present in this paper an experience in modeling a family of parking brake systems, with shared assets and alternative solutions, and relate them to the needs of Renault in terms of variability management. The models are realized using a set of customized tools for model based systems engineering and variability management, based on SysML models. The purpose is to present an industrial context that requires the adoption of a product line approach and of variability modeling techniques, outside of a pure-software domain. At Renault, the interest is in identifying variations and reuse opportunities early in the product development cycle, as well as in preparing vehicle configuration specifications during the systems engineering process. This would lead to lowering the engineering effort and to higher quality and confidence in carry-over and carry across based solutions. We advocate for a tight integration of variability management with the model based systems engineering approach, which needs to address methodological support, modeling techniques and efficient tools for interactive configuration, adapted for engineering activities.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {254–263},
numpages = {10},
keywords = {systems engineering, variability management},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.5555/2399776.2399785,
author = {Bagheri, Ebrahim and Ensan, Faezeh and Gasevic, Dragan},
title = {Grammar-based test generation for software product line feature models},
year = {2012},
publisher = {IBM Corp.},
address = {USA},
abstract = {Product lines are often employed for the facilitation of software re-use, rapid application development and increase in productivity. Despite the numerous advantages of software product lines, the task of testing them is a cumbersome process due to the fact that the number of applications that need to be tested is exponential to the number of features represented in the product line. In this paper, we attempt to reduce the number of required tests for testing a software product line while at the same time preserving an acceptable fault coverage. For this purpose, we introduce eight coverage criteria based on the transformation of software product line feature models into formal context-free grammars. The theoretical foundation for the proposed coverage criteria is based on the development of equivalence partitions on the software product line configuration space and the use of boundary value analysis for test suite generation. We have performed experiments on several SPLOT feature models, the results of which show that the test suite generation strategies based on the proposed coverage criteria are effective in significantly reducing the number of required tests and at the same time maintaining a high fault coverage ratio.},
booktitle = {Proceedings of the 2012 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {87–101},
numpages = {15},
location = {Toronto, Ontario, Canada},
series = {CASCON '12}
}

@inproceedings{10.1145/1944892.1944900,
author = {Istoan, Paul and Biri, Nicolas and Klein, Jacques},
title = {Issues in model-driven behavioural product derivation},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944900},
doi = {10.1145/1944892.1944900},
abstract = {Model Driven Engineering (MDE) was identified as a viable software development paradigm to help improve the product derivation phase of the Software Product Line (SPL) engineering process. Existing model-driven derivation approaches fail to properly address the behavioural derivation part, yielding a frustrating situation. In this paper we first introduce a model-driven derivation approach that combines Feature Diagrams (FD) and model fragments. We then identify and analyse several issues that emerge during the derivation process. We show that the order in which models associated to selected features are composed has a great impact on the end result of the derivation. We also present a particular class of features called disjoint and prove that current composition operators do not offer any viable solution to compose them. Finally, we argue that insufficient information available to composition operators leads to derivation results that do not satisfy user requirements.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {69–78},
numpages = {10},
keywords = {aspect oriented modelling, model composition, model driven engineering, software product lines},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1007/978-3-642-12107-4_8,
author = {Alf\'{e}rez, Mauricio and Santos, Jo\~{a}o and Moreira, Ana and Garcia, Alessandro and Kulesza, Uir\'{a} and Ara\'{u}jo, Jo\~{a}o and Amaral, Vasco},
title = {Multi-view composition language for software product line requirements},
year = {2009},
isbn = {3642121063},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12107-4_8},
doi = {10.1007/978-3-642-12107-4_8},
abstract = {Composition of requirements models in Software Product Line (SPL) development enables stakeholders to derive the requirements of target software products and, very important, to reason about them. Given the growing complexity of SPL development and the various stakeholders involved, their requirements are often specified from heterogeneous, partial views. However, existing requirements composition languages are very limited to generate specific requirements views for SPL products. They do not provide specialized composition rules for referencing and composing elements in recurring requirements models, such as use cases and activity models. This paper presents a multi-view composition language for SPL requirements, the Variability Modeling Language for Requirements (VML4RE). This language describes how requirements elements expressed in different models should be composed to generate a specific SPL product. The use of VML4RE is illustrated with UML-based requirements models defined for a home automation SPL case study. The language is evaluated with additional case studies from different application domains, such as mobile phones and sales management.},
booktitle = {Proceedings of the Second International Conference on Software Language Engineering},
pages = {103–122},
numpages = {20},
keywords = {cmposition languages, requirements engineering, requirements reuse, software product lines, variability management},
location = {Denver, CO},
series = {SLE'09}
}

@inproceedings{10.1145/1868688.1868691,
author = {Torres, M\'{a}rio and Kulesza, Uir\'{a} and Sousa, Matheus and Batista, Thais and Teixeira, Leopoldo and Borba, Paulo and Cirilo, Elder and Lucena, Carlos and Braga, Rosana and Masiero, Paulo},
title = {Assessment of product derivation tools in the evolution of software product lines: an empirical study},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868691},
doi = {10.1145/1868688.1868691},
abstract = {Product derivation approaches automate the customization process of software product lines. Over the last years, many tools have been proposed aiming at synthesize and generate products from a set of reusable assets. These tools adopt different techniques and strategies to implement and automate the product derivation activities. In this paper, we analyzed six modern product derivation tools (Captor, CIDE, GenArch, MSVCM, pure::variants, XVCL) in the context of evolution scenarios of a software product line. Our study has adopted several metrics to analyze the modularity, complexity and stability of product derivation artifacts related to configuration knowledge along different releases of a mobile product line. The preliminary results of our study have shown that approaches with a dedicated model or file to represent the CK specification can bring several benefits to the modularization and stability of a software product line.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {10–17},
numpages = {8},
keywords = {measurement, product derivation tools},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/1655925.1656013,
author = {Alsawalqah, Hamad I. and Abotsi, Komi S. and Lee, Dan Hyung},
title = {An automated mechanism for organizing and retrieving core asset artifacts for product derivation in SPL},
year = {2009},
isbn = {9781605587103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1655925.1656013},
doi = {10.1145/1655925.1656013},
abstract = {Software Product Line, SPL, is a software development strategy in which products are developed from a common set of core assets in a prescribed way with product specific features to satisfy specific market segment [1]. The SPL development process is carried out in two phases: the first phase is about building core assets called domain engineering, which has gained a lot of researchers' attention. The second step is about instantiating the specifics of the products by adding to the common part the specific features that identify the product from the other application engineering. For large and complex domains, it is argued that organizing and retrieving the development of artifacts from the core asset required by the application under development is a way of shortening the application development time, thus reduces the time to market. In this paper, we propose an automation mechanism for organizing the core assets using feature based organization to divide the customized domain feature model based on the application features and their dependencies. When that retrieval step where the artifacts are represented by relations that inherit the dependencies between the features in each division of the feature model, takes place, the final result is a set of development artifacts with their traceability links to be customized based on the application variability model and integrated with the application specific artifacts. To demonstrate our work, we applied this mechanism on a watch, a case study in the digital watch domain.},
booktitle = {Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human},
pages = {480–485},
numpages = {6},
keywords = {digital watch, feature model, ontology, product derivation, software product line},
location = {Seoul, Korea},
series = {ICIS '09}
}

@inproceedings{10.1145/1321211.1321255,
author = {Nestor, Daren and O'Malley, Luke and Healy, Patrick and Quigley, Aaron and Thiel, Steffen},
title = {Visualisation techniques to support derivation tasks in software product line development},
year = {2007},
publisher = {IBM Corp.},
address = {USA},
url = {https://doi.org/10.1145/1321211.1321255},
doi = {10.1145/1321211.1321255},
abstract = {Adopting a software product line approach allows companies to realise significant improvements in time-to-market, cost, productivity, and system quality, A fundamental problem in software product line engineering is the fact that a product line of industrial size can easily incorporate several thousand variation points. The scale and interdependencies can lead to variability management and product derivation tasks that are extremely complex to manage. This paper investigates visualisation techniques to support and improve the effectiveness of these tasks.},
booktitle = {Proceedings of the 2007 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {315–325},
numpages = {11},
location = {Richmond Hill, Ontario, Canada},
series = {CASCON '07}
}

@article{10.1007/s10270-020-00839-w,
author = {Pol’la, Matias and Buccella, Agustina and Cechich, Alejandra},
title = {Analysis of variability models: a systematic literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00839-w},
doi = {10.1007/s10270-020-00839-w},
abstract = {Dealing with variability, during Software Product Line Engineering (SPLE), means trying to allow software engineers to develop a set of similar applications based on a manageable range of variable functionalities according to expert users’ needs. Particularly, variability management (VM) is an activity that allows flexibility and a high level of reuse during software development. In the last years, we have witnessed a proliferation of methods, techniques and supporting tools for VM in general, and for its analysis in particular. More precisely, a specific field has emerged, named (automated) variability analysis, focusing on verifying variability models across the SPLE’s phases. In this paper, we introduce a systematic literature review of existing proposals (as primary studies) focused on analyzing variability models. We define a classification framework, which is composed of 20 sub-characteristics addressing general aspects, such as scope and validation, as well as model-specific aspects, such as variability primitives, reasoner type. The framework allows to look at the analysis of variability models during its whole life cycle—from design to derivation—according to the activities involved during an SPL development. Also, the framework helps us answer three research questions defined for showing the state of the art and drawing challenges for the near future. Among the more interesting challenges, we can highlight the needs of more applications in industry, the existence of more mature tools, and the needs of providing more semantics in the way of variability primitives for identifying inconsistencies in the models.},
journal = {Softw. Syst. Model.},
month = aug,
pages = {1043–1077},
numpages = {35},
keywords = {Variability analysis, Software Product Line, Variability management, Supporting tools}
}

@article{10.1007/s00766-013-0185-4,
author = {Derakhshanmanesh, Mahdi and Fox, Joachim and Ebert, J\"{u}rgen},
title = {Requirements-driven incremental adoption of variability management techniques and tools: an industrial experience report},
year = {2014},
issue_date = {November  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-013-0185-4},
doi = {10.1007/s00766-013-0185-4},
abstract = {In theory, software product line engineering has reached a mature state. In practice though, implementing a variability management approach remains a tough case-by-case challenge for any organization. To tame the complexity of this undertaking, it is inevitable to handle variability from multiple perspectives and to manage variability consistently across artifacts, tools, and workflows. Especially, a solid understanding and management of the requirements to be met by the products is an inevitable prerequisite. In this article, we share experiences from the ongoing incremental adoption of explicit variability management at TRW Automotive's department for automotive slip control systems--located in Koblenz, Germany. On the technical side, the three key drivers of this adoption effort are (a) domain modeling and scoping, (b) handling of variability in requirements and (c) tighter integration of software engineering focus areas (e.g., domain modeling, requirements engineering, architectural modeling) to make use of variability-related data. In addition to implementation challenges with using and integrating concrete third-party tools, social and workflow-related issues are covered as well. The lessons learned are presented, discussed, and thoroughly compared with the state of the art in research.},
journal = {Requir. Eng.},
month = nov,
pages = {333–354},
numpages = {22},
keywords = {Features, Incremental adoption, Requirements, Reuse, Software product lines, Tool integration}
}

@article{10.1007/s11219-011-9156-5,
author = {Roos-Frantz, Fabricia and Benavides, David and Ruiz-Cort\'{e}s, Antonio and Heuer, Andr\'{e} and Lauenroth, Kim},
title = {Quality-aware analysis in product line engineering with the orthogonal variability model},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9156-5},
doi = {10.1007/s11219-011-9156-5},
abstract = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e.g., CPU and memory consumption) and constraints on these attributes (e.g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e.g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i.e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e.g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions.},
journal = {Software Quality Journal},
month = sep,
pages = {519–565},
numpages = {47},
keywords = {Automated analysis, Orthogonal variability model, Quality modelling, Quality-aware analysis, Software product lines}
}

@inproceedings{10.1145/3382025.3414969,
author = {Bilic, Damir and Carlson, Jan and Sundmark, Daniel and Afzal, Wasif and Wallin, Peter},
title = {Detecting inconsistencies in annotated product line models},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414969},
doi = {10.1145/3382025.3414969},
abstract = {Model-based product line engineering applies the reuse practices from product line engineering with graphical modeling for the specification of software intensive systems. Variability is usually described in separate variability models, while the implementation of the variable systems is specified in system models that use modeling languages such as SysML. Most of the SysML modeling tools with variability support, implement the annotation-based modeling approach. Annotated product line models tend to be error-prone since the modeler implicitly describes every possible variant in a single system model. To identifying variability-related inconsistencies, in this paper, we firstly define restrictions on the use of SysML for annotative modeling in order to avoid situations where resulting instances of the annotated model may contain ambiguous model constructs. Secondly, inter-feature constraints are extracted from the annotated model, based on relations between elements that are annotated with features. By analyzing the constraints, we can identify if the combined variability- and system model can result in incorrect or ambiguous instances. The evaluation of our prototype implementation shows the potential of our approach by identifying inconsistencies in the product line model of our industrial partner which went undetected through several iterations of the model.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {20},
numpages = {11},
keywords = {SysML, consistency checking, model-based systems engineering, product line engineering, variability modeling},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.1016/j.infsof.2010.12.006,
author = {Chen, Lianping and Ali Babar, Muhammad},
title = {A systematic review of evaluation of variability management approaches in software product lines},
year = {2011},
issue_date = {April, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {53},
number = {4},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.12.006},
doi = {10.1016/j.infsof.2010.12.006},
abstract = {ContextVariability management (VM) is one of the most important activities of software product-line engineering (SPLE), which intends to develop software-intensive systems using platforms and mass customization. VM encompasses the activities of eliciting and representing variability in software artefacts, establishing and managing dependencies among different variabilities, and supporting the exploitation of the variabilities for building and evolving a family of software systems. Software product line (SPL) community has allocated huge amount of effort to develop various approaches to dealing with variability related challenges during the last two decade. Several dozens of VM approaches have been reported. However, there has been no systematic effort to study how the reported VM approaches have been evaluated. ObjectiveThe objectives of this research are to review the status of evaluation of reported VM approaches and to synthesize the available evidence about the effects of the reported approaches. MethodWe carried out a systematic literature review of the VM approaches in SPLE reported from 1990s until December 2007. ResultsWe selected 97 papers according to our inclusion and exclusion criteria. The selected papers appeared in 56 publication venues. We found that only a small number of the reviewed approaches had been evaluated using rigorous scientific methods. A detailed investigation of the reviewed studies employing empirical research methods revealed significant quality deficiencies in various aspects of the used quality assessment criteria. The synthesis of the available evidence showed that all studies, except one, reported only positive effects. ConclusionThe findings from this systematic review show that a large majority of the reported VM approaches have not been sufficiently evaluated using scientifically rigorous methods. The available evidence is sparse and the quality of the presented evidence is quite low. The findings highlight the areas in need of improvement, i.e., rigorous evaluation of VM approaches. However, the reported evidence is quite consistent across different studies. That means the proposed approaches may be very beneficial when they are applied properly in appropriate situations. Hence, it can be concluded that further investigations need to pay more attention to the contexts under which different approaches can be more beneficial.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {344–362},
numpages = {19},
keywords = {Empirical studies, Software product line, Systematic literature reviews, Variability management}
}

@inproceedings{10.1007/978-3-642-12107-4_7,
author = {Zschaler, Steffen and S\'{a}nchez, Pablo and Santos, Jo\~{a}o and Alf\'{e}rez, Mauricio and Rashid, Awais and Fuentes, Lidia and Moreira, Ana and Ara\'{u}jo, Jo\~{a}o and Kulesza, Uir\'{a}},
title = {VML* – a family of languages for variability management in software product lines},
year = {2009},
isbn = {3642121063},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12107-4_7},
doi = {10.1007/978-3-642-12107-4_7},
abstract = {Managing variability is a challenging issue in software-product-line engineering. A key part of variability management is the ability to express explicitly the relationship between variability models (expressing the variability in the problem space, for example using feature models) and other artefacts of the product line, for example, requirements models and architecture models. Once these relations have been made explicit, they can be used for a number of purposes, most importantly for product derivation, but also for the generation of trace links or for checking the consistency of a product-line architecture. This paper bootstraps techniques from product-line engineering to produce a family of languages for variability management for easing the creation of new members of the family of languages. We show that developing such language families is feasible and demonstrate the flexibility of our language family by applying it to the development of two variability-management languages.},
booktitle = {Proceedings of the Second International Conference on Software Language Engineering},
pages = {82–102},
numpages = {21},
keywords = {domain-specific languages, family of languages, software product lines, variability management},
location = {Denver, CO},
series = {SLE'09}
}

@inproceedings{10.5555/2022115.2022129,
author = {Gamez, Nadia and Fuentes, Lidia},
title = {Software product line evolution with cardinality-based feature models},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature models are widely used for modelling variability present in a Software Product Line family. We propose using cardinality-based feature models and clonable features to model and manage the evolution of the structural variability present in pervasive systems, composed by a large variety of heterogeneous devices. The use of clonable features increases the expressiveness of feature models, but also greatly increases the complexity of the resulting configurations. So, supporting the evolution of product configurations becomes an intractable task to do it manually. In this paper, we propose a model driven development process to propagate changes made in an evolved feature model, into existing configurations. Furthermore, our process allows us to calculate the effort needed to perform the evolution changes in the customized products. To do this, we have defined two operators, one to calculate the differences between two configurations and another to create a new configuration from a previous one. Finally, we validate our approach, showing that by using our tool support we can generate new configurations for a family of products with thousands of cloned features.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {102–118},
numpages = {17},
keywords = {evolution, feature models, software product lines},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1145/3336294.3336316,
author = {Tolvanen, Juha-Pekka and Kelly, Steven},
title = {How Domain-Specific Modeling Languages Address Variability in Product Line Development: Investigation of 23 Cases},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336316},
doi = {10.1145/3336294.3336316},
abstract = {Domain-Specific Modeling raises the level of abstraction beyond programming by specifying the solution directly with domain concepts. Within product lines domain-specific approaches are applied to specify variability and then generate final products together with commonality. Such automated product derivation is possible because both the modeling language and generator are made for a particular product line --- often inside a single company. In this paper we examine which kinds of reuse and product line approaches are applied in industry with domain-specific modeling. Our work is based on empirical analysis of 23 cases and the languages and models created there. The analysis reveals a wide variety and some commonalities in the size of languages and in the ways they apply reuse and product line approaches.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {155–163},
numpages = {9},
keywords = {code generation, domain-specific language, domain-specific modeling, product derivation, product line variability},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.5555/2022115.2022130,
author = {Wu, Yijian and Yang, Yiming and Peng, Xin and Qiu, Cheng and Zhao, Wenyun},
title = {Recovering object-oriented framework for software product line reengineering},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A large number of software product lines (SPL) in practice are not constructed from scratch, but reengineered from legacy variant products. In order to transfer legacy products to SPL core assets, reverse variability analysis should be involved to find commonality and differences among variant artifacts. In this paper we concentrate on the recovery of SPL framework which can be represented by an object-oriented design model with variation points. We propose a semi-automatic SPL framework recovery approach with the assumption that involved legacy products have similar designs and implementations. In this approach, we adopt a bottom-up process based on clone detection and context analysis to identify corresponding mappings among design elements in different products. Then we use a top-down process from class level to method level with some heuristic rules to determine the commonality/variability classification and the variability type for each design element. In order to evaluate the effectiveness of our approach, we conduct a case study on an industrial product line and present comprehensive analysis and discussions on the results.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {119–134},
numpages = {16},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1007/978-3-642-31095-9_40,
author = {Ensan, Faezeh and Bagheri, Ebrahim and Ga\v{s}evi\'{c}, Dragan},
title = {Evolutionary search-based test generation for software product line feature models},
year = {2012},
isbn = {9783642310942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31095-9_40},
doi = {10.1007/978-3-642-31095-9_40},
abstract = {Product line-based software engineering is a paradigm that models the commonalities and variabilities of different applications of a given domain of interest within a unique framework and enhances rapid and low cost development of new applications based on reuse engineering principles. Despite the numerous advantages of software product lines, it is quite challenging to comprehensively test them. This is due to the fact that a product line can potentially represent many different applications; therefore, testing a single product line requires the test of its various applications. Theoretically, a product line with n software features can be a source for the development of 2n application. This requires the test of 2n applications if a brute-force comprehensive testing strategy is adopted. In this paper, we propose an evolutionary testing approach based on Genetic Algorithms to explore the configuration space of a software product line feature model in order to automatically generate test suites. We will show through the use of several publicly-available product line feature models that the proposed approach is able to generate test suites of O(n) size complexity as opposed to O(2n) while at the same time form a suitable tradeoff balance between error coverage and feature coverage in its generated test suites.},
booktitle = {Proceedings of the 24th International Conference on Advanced Information Systems Engineering},
pages = {613–628},
numpages = {16},
keywords = {evolutionary testing, feature models, software product lines},
location = {Gda\'{n}sk, Poland},
series = {CAiSE'12}
}

@inproceedings{10.1145/3461001.3473059,
author = {Azanza, Maider and Montalvillo, Leticia and D\'{\i}az, Oscar},
title = {20 years of industrial experience at SPLC: a systematic mapping study},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3473059},
doi = {10.1145/3461001.3473059},
abstract = {Software Product Lines (SPLs) have been around since the late 1970s and have established themselves as a way to deal with product variability. Tens of companies around the globe can pay testament to their advantages. Practitioners, however, have lamented the lack of data on other practitioners' experiences that would help them in the SPL journey. This work intends to analyze the application of SPLs in industry in the last 20 years. We departed from 194 industrial studies that were published at the Software Product Line Conference, the premier venue for SPL research. After the filtering process we selected 66 primary studies, from 43 different companies and 15 countries. The studies were classified to answer three research questions: (i) which contexts have SPLs been applied in?, (ii) what phenomena have been reported? and, (iii) what evidences have been collected in terms of obtained benefits, encountered issues and lessons learned? Regarding the context, SPLs have mainly been reported in USA and Germany (50%) and are used to develop embedded systems (76%). The most cited reason to adopt SPLs is the need to increase product variants (42.42%). As for the phenomena, the most reported problem area is adoption (39.39%). Last, as for evidences the most cited benefit is a cost reduction (53.03%), the issue is evolution (13.13%) and the learned lesson is that architecture is essential (24.24%). We believe the findings will be of interest to the community as a whole in quest to bridge the gap between industry and academia while balancing rigor, authenticity and relevance.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {172–183},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/2491627.2491629,
author = {Clements, Paul and Krueger, Charles and Shepherd, James and Winkler, Andrew},
title = {A PLE-based auditing method for protecting restricted content in derived products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491629},
doi = {10.1145/2491627.2491629},
abstract = {Many organizations that produce a portfolio of products for different customers need to ensure that sensitive or restricted content that may appear in some products must not appear in others. Examples of this need include complying with statutes in different countries of sale, protection of intellectual property developed specifically for one customer, and more. For organizations operating under these requirements and producing their products under a product line engineering paradigm that relies on automation in product derivation, there is a need for a method to ensure that the content restrictions have been met in the derived products. This paper describes an auditing method that meets this need. It was created for use in the Second Generation Product Line Engineering approach that is being applied by Lockheed Martin in their AEGIS ship combat system product line.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {218–226},
numpages = {9},
keywords = {bill-of-features, feature modeling, feature profiles, hierarchical product lines, product audit, product baselines, product configurator, product derivation, product line engineering, product portfolio, second generation product line engineering, software product lines, variation points},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3106195.3106212,
author = {Marimuthu, C. and Chandrasekaran, K.},
title = {Systematic Studies in Software Product Lines: A Tertiary Study},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106212},
doi = {10.1145/3106195.3106212},
abstract = {Software product lines are widely used in the software industries to increase the re-usability and to decrease maintenance cost. On the other hand, systematic reviews are widely used in the software engineering research community to provide the overview of the research field and practitioners guidelines. Researchers have conducted many systematic studies on the different aspects of SPLs. To the best of our knowledge, till now there is no tertiary study conducted on systematic studies of SPL related research topics. In this paper, we aim at conducting a systematic mapping study of existing systematic studies to report the overview of the findings for researchers and practitioners. We performed snowballing and automated search to find out the relevant systematic studies. As a result, we analyzed 60 relevant studies to answer 5 research questions. The main focus of this tertiary study is to highlight the research topics, type of published reviews, active researchers and publication forums. Additionally, we highlight some of the limitations of the systematic studies. The important finding of this study is that the research field is well matured as the systematic studies covered a wide range of research topics. Another important finding is that many studies provided information for practitioners as well as researchers which is a notable improvement in the systematic reviews. However, many studies failed to assess the quality of the primary studies which is the major limitation of the existing systematic studies.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {143–152},
numpages = {10},
keywords = {software product line, systematic review, tertiary study},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/1842752.1842809,
author = {Helleboogh, Alexander and Avgeriou, Paris and Bouck\'{e}, Nelis and Heymans, Patrick},
title = {Workshop on Variability in Software Product Line Architectures (VARI-ARCH 2010)},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842809},
doi = {10.1145/1842752.1842809},
abstract = {The objective of this workshop is to bring together researchers from the software product line community and software architecture community to identify critical challenges and progress the state-of-the-art on variability in software product line architectures.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {309–311},
numpages = {3},
keywords = {assets, concern, model, product line architecture, product lines, software architecture, variability, view, viewpoint},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@article{10.1007/s11334-011-0174-z,
author = {Polzer, Andreas and Merschen, Daniel and Botterweck, Goetz and Pleuss, Andreas and Thomas, Jacques and Hedenetz, Bernd and Kowalewski, Stefan},
title = {Managing complexity and variability of a model-based embedded software product line},
year = {2012},
issue_date = {March     2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {8},
number = {1},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-011-0174-z},
doi = {10.1007/s11334-011-0174-z},
abstract = {This paper presents a framework for model-based product lines of embedded systems. We show how to integrate model-based product line techniques into a consistent framework that can deal with large product lines as they are common in industry. The framework demonstrates the strengths of model-based techniques like abstraction, support for customised representations, and a high degree of automation. In particular, we provide the following contributions: (1) to shift existing product lines towards a model-based approach, we support the (semi-) automated extraction of models from existing requirement, test, and implementation artefacts; (2) to cope with the complexity of artefacts and their interrelations in industrial product lines, we support the generation of context-specific views. These views support developers, e.g., in analysing complex dependencies between different artefacts; (3) finally, we support automated product derivation based on an integrated hardware abstraction layer. Most of the presented concepts have been inspired by challenges arising in the industrial application of product line techniques in the model-based engineering of embedded systems. We report on experiences gathered during the application of the techniques to a prototypical product line (on a rapid prototyping platform in the university lab) and to industrial sample cases (at the industry partner).},
journal = {Innov. Syst. Softw. Eng.},
month = mar,
pages = {35–49},
numpages = {15},
keywords = {Complexity, Model transformation, Software product lines, Traceability, Variability modelling}
}

@inproceedings{10.5555/2022115.2022134,
author = {Lorenz, David H. and Rosenan, Boaz},
title = {Code reuse with language oriented programming},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {There is a gap between our ability to reuse high-level concepts in software design and our ability to reuse the code implementing them. Language Oriented Programming (LOP) is a software development paradigm that aims to close this gap, through extensive use of Domain Specific Languages (DSLs). With LOP, the high-level reusable concepts become reusable DSL constructs, and their translation into code level concepts is done in the DSL implementation. Particular products are implemented using DSL code, thus reusing only high-level concepts. In this paper we provide a comparison between two implementation approaches for LOP: (a) using external DSLs with a projectional language workbench (MPS); and (b) using internal DSLs with an LOP language (Cedalion). To demonstrate how reuse is achieved in each approach, we present a small case study, where LOP is used to build a Software Product Line (SPL) of calculator software.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {167–182},
numpages = {16},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@inproceedings{10.1145/2934466.2962731,
author = {Kr\"{u}ger, Jacob and Fenske, Wolfram and Meinicke, Jens and Leich, Thomas and Saake, Gunter},
title = {Extracting software product lines: a cost estimation perspective},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2962731},
doi = {10.1145/2934466.2962731},
abstract = {Companies are often forced to customize their software products. Thus, a common practice is to clone and adapt existing systems to new customer requirements. With the extractive approach, those derived variants can be migrated into a software product line. However, changing to a new development process is risky and may result in unnecessary costs. Therefore, companies apply cost estimations to predict whether another development approach is beneficial. Existing cost models for software-product-line engineering focus on development from scratch. Contrarily, the extractive approach is more common in practice but specialized models are missing. Thus, in this work we focus on product-line extraction from a set of legacy systems. We i) describe according cost factors, ii) put them in context with the development process and cost curves, and iii) identify open challenges in product-line economics. This way, our work supports cost estimations for the extractive approach and provides a basis for further research.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {354–361},
numpages = {8},
keywords = {cost estimation, extractive approach, investment analysis, risk assessment, software product line},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3236405.3236410,
author = {Kr\"{o}her, Christian and El-Sharkawy, Sascha and Schmid, Klaus},
title = {KernelHaven: an open infrastructure for product line analysis},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236410},
doi = {10.1145/3236405.3236410},
abstract = {KernelHaven is an open infrastructure for Software Product Line (SPL) analysis. It is intended both as a production-quality analysis tool set as well as a research support tool, e.g., to support researchers in systematically exploring research hypothesis. For flexibility and ease of experimentation KernelHaven components are plug-ins for extracting certain information from SPL artifacts and processing this information, e.g., to check the correctness and consistency of variability information or to apply metrics. A configuration-based setup along with automatic documentation functionality allows different experiments and supports their easy reproduction.Here, we describe KernelHaven as a product line analysis research tool and highlight its basic approach as well as its fundamental capabilities. In particular, we describe available information extraction and processing plug-ins and how to combine them. On this basis, researchers and interested professional users can rapidly conduct a first set of experiments. Further, we describe the concepts for extending KernelHaven by new plug-ins, which reduces development effort when realizing new experiments.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {5–10},
numpages = {6},
keywords = {empirical software engineering, software product line analysis, static analysis, variability extraction},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1109/MEMCOD.2007.371243,
author = {Oh, Youngseok and Lee, Dan Hyung and Kang, Sungwon and Lee, Ji Hyun},
title = {Extended Architecture Analysis Description Language for Software Product Line Approach in Embedded Systems},
year = {2007},
isbn = {1424410509},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MEMCOD.2007.371243},
doi = {10.1109/MEMCOD.2007.371243},
abstract = {Describing architecture variabilities explicitly and precisely is important in the software product line approach for software development since it helps product derivation as well as modeling and managing the variabilities. The SAE AADL is an industry standard architecture analysis and design language for the automotive community, which originally was not intended to be used for software product line. In this paper, we propose EAADL a software product line architecture description language for the automotive domain that extends the SAE AADL. By incorporating orthogonal variability model into it, EAADL offers traceability with requirement engineering as well as the implementation process that is essential in software product line engineering.},
booktitle = {Proceedings of the 5th IEEE/ACM International Conference on Formal Methods and Models for Codesign},
pages = {87–88},
numpages = {2},
series = {MEMOCODE '07}
}

@inproceedings{10.1145/1383559.1383571,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Towards automatic derivation of a product performance model from a UML software product line model},
year = {2008},
isbn = {9781595938732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1383559.1383571},
doi = {10.1145/1383559.1383571},
abstract = {Software Product Line (SPL) engineering is a software development approach that takes advantage of the commonality and variability between products from a family, and supports the generation of specific products by reusing a set of core family assets. This paper proposes a UML model transformation approach for software product lines to derive a performance model for a specific product. The input to the proposed technique, the "source model", is a UML model of a SPL with performance annotations, which uses two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The source model is generic and therefore its performance annotations must be parameterized. The proposed derivation of a performance model for a concrete product requires two steps: a) the transformation of a SPL model to a UML model with performance annotations for a given product, and b) the transformation of the outcome of the first step into a performance model. This paper focuses on the first step, whereas the second step will use the PUMA transformation approach of annotated UML models to performance models, developed in previous work. The output of the first step, named "target model", is a UML model with MARTE annotations, where the variability expressed in the SPL model has been analyzed and bound to a specific product, and the generic performance annotations have been bound to concrete values for the product. The proposed technique is illustrated with an e-commerce case study.},
booktitle = {Proceedings of the 7th International Workshop on Software and Performance},
pages = {91–102},
numpages = {12},
keywords = {marte, model transformation, software performance engineering, software product line, uml},
location = {Princeton, NJ, USA},
series = {WOSP '08}
}

@inproceedings{10.5555/1308171.1308196,
author = {Rabiser, Rick and Grunbacher, Paul and Dhungana, Deepak},
title = {Supporting Product Derivation by Adapting and Augmenting Variability Models},
year = {2007},
isbn = {0769528880},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Product derivation is the process of constructing products from the core assets in a product line. Guidance and support are needed to increase efficiency and to deal with the complexity of product derivation. Research has, however, devoted comparatively little attention to this process. In this paper we describe an approach for supporting product derivation. We show that variability models need to be prepared for concrete projects before they can be effectively utilized in the derivation process. Project-specific information and sales knowledge should be added and irrelevant variability should be pruned. We also present tool support and illustrate the approach using examples from ongoing research collaboration.},
booktitle = {Proceedings of the 11th International Software Product Line Conference},
pages = {141–150},
numpages = {10},
series = {SPLC '07}
}

@inproceedings{10.1145/2648511.2648531,
author = {Yu, Wenjing and Zhang, Wei and Zhao, Haiyan and Jin, Zhi},
title = {TDL: a transformation description language from feature model to use case for automated use case derivation},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648531},
doi = {10.1145/2648511.2648531},
abstract = {Software product line engineering (SPLE) is a widely adopted approach to systematic software reuse. One basic research issue in SPLE is the product derivation problem, which focuses on how to derive software products from reusable software assets efficiently. In this paper, we focus on a sub-problem of product derivation: the problem of automated use case derivation, i.e. deriving the use cases of a software product in an automated way. We take a feature-oriented approach to this problem, an approach involving two components: a feature model, and the transformation information from the feature model to a set of use cases. In particular, we propose a transformation description language (TDL) to specify the transformation information from a feature model to a set of related use cases, and to support automated derivation of use cases corresponding to a valid feature model configuration. In addition, we also propose a set of criteria to check the validity of a TDL program. Three case studies have been conducted to demonstrate the usability of TDL and the feasibility of the automated use case derivation process based on TDL programs.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {187–196},
numpages = {10},
keywords = {feature model, software product line, transformation, use case},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2648511.2648541,
author = {Gregg, Susan P. and Scharadin, Rick and LeGore, Eric and Clements, Paul},
title = {Lessons from AEGIS: organizational and governance aspects of a major product line in a multi-program environment},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648541},
doi = {10.1145/2648511.2648541},
abstract = {This paper tells the story of the AEGIS Weapon System product line and how it evolved from a series of standalone software programs with no sharing into a true systems and software product line. The paper focuses on the strong internal and external governance of the product line. The need for strong governance is brought about by the strong role that the AEGIS customer community plays in oversight of design, development, and procurement. The paper recounts the product line's beginnings, and describes how the product line is operated today. Organizational issues, measurement issues, and governance issues are covered, along with a summary of important lessons learned about operating a product line in an environment of strong competing interests.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {264–273},
numpages = {10},
keywords = {AEGIS, Navy, bill-of-features, combat systems, command and control, feature modeling, feature profiles, hierarchical product lines, product audit, product baselines, product configurator, product derivation, product line engineering, product line governance, product portfolio, second generation product line engineering, software product lines, variation points},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3382026.3425769,
author = {Nieke, Michael and Sampaio, Gabriela and Th\"{u}m, Thomas and Seidl, Christoph and Teixeira, Leopoldo and Schaefer, Ina},
title = {GuyDance: Guiding Configuration Updates for Product-Line Evolution},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3425769},
doi = {10.1145/3382026.3425769},
abstract = {A product line is an approach for systematically managing configuration options of customizable systems, usually by means of features. Products are generated by utilizing configurations consisting of selected features. Product-line evolution can lead to unintended changes to product behavior. We illustrate that updating configurations after product-line evolution requires decisions of both, domain engineers responsible for product-line evolution as well as application engineers responsible for configurations. The challenge is that domain and application engineers might not be able to talk to each other. We propose a formal foundation and a methodology that enables domain engineers to guide application engineers through configuration evolution by sharing knowledge on product-line evolution and by defining configuration update operations. As an effect, we enable knowledge transfer between those engineers without the need to talk to each other. We evaluate our method by providing formal proofs that show product behavior of configurations can be preserved for typical evolution scenarios.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {56–64},
numpages = {9},
keywords = {configuration, evolution, software product line},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3461001.3471155,
author = {Martin, Hugo and Acher, Mathieu and Pereira, Juliana Alves and J\'{e}z\'{e}quel, Jean-Marc},
title = {A comparison of performance specialization learning for configurable systems},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471155},
doi = {10.1145/3461001.3471155},
abstract = {The specialization of the configuration space of a software system has been considered for targeting specific configuration profiles, usages, deployment scenarios, or hardware settings. The challenge is to find constraints among options' values that only retain configurations meeting a performance objective. Since the exponential nature of configurable systems makes a manual specialization unpractical, several approaches have considered its automation using machine learning, i.e., measuring a sample of configurations and then learning what options' values should be constrained. Even focusing on learning techniques based on decision trees for their built-in explainability, there is still a wide range of possible approaches that need to be evaluated, i.e., how accurate is the specialization with regards to sampling size, performance thresholds, and kinds of configurable systems. In this paper, we compare six learning techniques: three variants of decision trees (including a novel algorithm) with and without the use of model-based feature selection. We first perform a study on 8 configurable systems considered in previous related works and show that the accuracy reaches more than 90% and that feature selection can improve the results in the majority of cases. We then perform a study on the Linux kernel and show that these techniques performs as well as on the other systems. Overall, our results show that there is no one-size-fits-all learning variant (though high accuracy can be achieved): we present guidelines and discuss tradeoffs.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {46–57},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3236405.3237199,
author = {Fadhlillah, Hafiyyan Sayyid and Adianto, Daya and Azurat, Ade and Sakinah, Siti Ina},
title = {Generating adaptable user interface in SPLE: using delta-oriented programming and interaction flow modeling language},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3237199},
doi = {10.1145/3236405.3237199},
abstract = {We explore the possibility of including Delta-Oriented Programming (DOP) and Abstract User Interface (AUI) model during product generation in Software Product Line Engineering (SPLE). Previous work showed that DOP is applicable in a SPLE for Web applications albeit User Interface (UI) elements in derived product are still manually created without UI modeling. AUI model is proven to be successful for modeling UI elements for products in SPLE as it can model generic UI elements while still encouraging customization. Therefore, we pick an existing AUI modeling language called Interaction Flow Modeling Language (IFML) to create model of UI elements in a SPLE. We also suggest a new SPLE design that follows DOP and the proposed UI modeling language to generate adaptable UI given product configuration. The process of designing UI for each feature in the product line is based on reference implementation process used in previous work. We hope that the suggested process can solve the current DOP practices limitation in generating UI elements for products in SPLE.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {52–55},
numpages = {4},
keywords = {delta-oriented programming, software product lines, user interface engineering},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3382025.3414961,
author = {Favalli, Luca and K\"{u}hn, Thomas and Cazzola, Walter},
title = {Neverlang and FeatureIDE just married: integrated language product line development environment},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414961},
doi = {10.1145/3382025.3414961},
abstract = {Language development is inherently complex. With the support of a suitable language development environment most computer scientists could develop their own domain-specific language (DSL) with relative ease. Yet, when the DSL is the result of a configuration over a language product line (LPL)---a special software product line (SPL) of compilers/interpreters and corresponding IDE services---they fail to provide adequate support. An environment for LPL engineering should facilitate the underlying process involving three distinct roles: a language engineer developing the LPL, a language deployer configuring a language product, and a language user using the language product. Neither IDEs nor SPLE environments can cater all three roles and fully support the LPL engineering process with distributed, incremental development, configuration, and deployment of language variants. In this paper, we present an LPL engineering process for the distributed, incremental development of LPLs and an integrated language product line development environment supporting this process, catering the three roles, and ensuring the consistency among all artifacts of the LPL: language components implementing a language feature, the feature model, language configurations and the resulting language products. To create such an environment, we married the Neverlang language workbench and AiDE its LPL engineering environment with the FeatureIDE SPL engineering environment. While Neverlang supports the development of LPLs and deployment of language products, AiDE generates the feature model for the LPL under development, whereas FeatureIDE handles the feature configuration. We illustrate the applicability of the LPL engineering process and the suitability of our development environment for the three roles by showcasing its application for teaching programming with a growable language. In there, an LPL for Javascript was developed/refactored, 15 increasingly complex language products were configured/updated and finally deployed.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {33},
numpages = {11},
keywords = {domain specific languages, language product lines, neverlang},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2364412.2364430,
author = {Creff, Stephen and Champeau, Jo\"{e}l and J\'{e}z\'{e}quel, Jean-Marc and Mon\'{e}gier, Arnaud},
title = {Model-based product line evolution: an incremental growing by extension},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364430},
doi = {10.1145/2364412.2364430},
abstract = {Model-Based Engineering (MBE) and Product Line Engineering (PLE) have been combined, to handle new system development constraints like: increasing complexity, higher product quality, faster time-to-market and cost reduction. As observed by some authors, the derivation of a product from product line shared core assets has been insufficiently addressed and can remain tedious in practice. We cope with this issue focusing on having a flexible and reactive model-based derivation, and propose an incremental evolution by extension of the product line coupled with this derivation activity. Process and tools bridge the gap between Application and Domain Engineering introducing a semi-automatic feedback to benefits from the developments made in the Application Engineering. The approach is applied to a model-based product line dedicated to Class diagrams, and is tooled within the Eclipse environment.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {107–114},
numpages = {8},
keywords = {design tools, evolution by extension, methodology, model based engineering, product derivation, product line engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/998675.999486,
author = {Bosch, Jan},
title = {Software Variability Management},
year = {2004},
isbn = {0769521630},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {During recent years, the amount of variability that hasto be supported by a software artefact is growingconsiderably and its management is evolving into amajor challenge during development, usage, andevolution of software artefacts. Successful managementof variability in software leads to better customizablesoftware products that are in turn likely to result inhigher market success.The aim of this tutorial is to present softwarevariability management both from a \'{y}problems\'{y} andfrom a \'{y}solutions\'{y} perspective by discussingexperiences from industrial practice and from appliedresearch in academia. Issues that are addressedinclude, but are not limited to, technological, process,and organizational aspects as well as notation,assessment, design, and evolution aspects.},
booktitle = {Proceedings of the 26th International Conference on Software Engineering},
pages = {720–721},
numpages = {2},
keywords = {adaptation and configuration, software customization, software product families, software variability, variability management},
series = {ICSE '04}
}

@inproceedings{10.1145/3106195.3106221,
author = {Hayashi, Kengo and Aoyama, Mikio and Kobata, Keiji},
title = {Agile Tames Product Line Variability: An Agile Development Method for Multiple Product Lines of Automotive Software Systems},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106221},
doi = {10.1145/3106195.3106221},
abstract = {This article proposes an agile development method and its management method for multiple product lines of automotive software systems. In product line development, the problem area is divided into the domain engineering and application engineering for delivering diverse products. Now, the development of automotive software requires agility and extreme diversity. Conventional simple product line model could not accommodate the requirements. Therefore, we developed an agile development method for automotive multiple product lines. First, we propose an agile development method for multiple product lines by iteratively reusing process assets in application engineering. To manage the diversity of the products derived from the multiple product lines, we propose a management method which integrates the portfolio management and product development management into the agile development method. We applied the proposed method to the development of multiple product lines for our automotive software systems, and demonstrated a reduction of the cost and complexity of the multiple product lines, and improvement of on-time delivery.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {180–189},
numpages = {10},
keywords = {agile development, automotive software, multiple product lines, portfolio management, process asset, software product line},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3461002.3473948,
author = {Xu, Hao and Baarir, Souheib and Ziadi, Tewfik and Hillah, Lom Messan and Essodaigui, Siham and Bossu, Yves},
title = {Optimisation for the product configuration system of Renault: towards an integration of symmetries},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473948},
doi = {10.1145/3461002.3473948},
abstract = {The problem of configuring model variability is widespread in many different domains. Renault, a leading french automobile manufacturer, has developed its technology internally to model vehicle diversity. This technology relies on the approach known as knowledge compilation. Since its inception, continuous progress has been made in the tool while monitoring the latest developments from the software field and academia. However, the growing number of vehicle models brings potential risks and higher requirements for the tool. This paper presents a short reminder of Renault's technology principles and the improvements we intend to achieve by analyzing and leveraging notable data features of Renault problem instances. In particular, the aim is to exploit symmetry properties.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {86–90},
numpages = {5},
keywords = {SAT, knowledge compilation, product line, symmetries},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.scico.2012.04.009,
author = {Marinho, Fabiana G. and Andrade, Rossana M. C. and Werner, Cl\'{a}udia and Viana, Windson and Maia, Marcio E. F. and Rocha, Lincoln S. and Teixeira, Eld\'{\i}nae and Filho, Jo\~{a}o B. Ferreira and Dantas, Val\'{e}ria L. L. and Lima, Fabr\'{\i}cio and Aguiar, Saulo},
title = {MobiLine: A Nested Software Product Line for the domain of mobile and context-aware applications},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.04.009},
doi = {10.1016/j.scico.2012.04.009},
abstract = {Mobile devices are multipurpose and multi-sensor equipments supporting applications able to adapt their behavior according to changes in the user's context (device, location, time, etc.). Meanwhile, the development of mobile and context-aware software is not a simple task, mostly due to the peculiar characteristics of these devices. Although several solutions have been proposed to facilitate their development, reuse is not systematically used throughout the software development life-cycle. In this paper, we discuss an approach for the development of mobile and context-aware software using the Software Product Line (SPL) paradigm. Furthermore, a Nested SPL for the domain of mobile and context-aware applications is presented, lessons learned in the SPL development are discussed and a product for a context-aware visit guide is shown.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2381–2398},
numpages = {18},
keywords = {Context-awareness, Mobility, Software product line}
}

@article{10.1145/2853073.2853082,
author = {Soujanya, K. L.S. and AnandaRao, A.},
title = {A Generic Framework for Configuration Management of SPL and Controlling Evolution of Complex Software Products},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853082},
doi = {10.1145/2853073.2853082},
abstract = {Efficient configuration management system is crucial for the success of any software product line (SPL). Due to ever changing needs of customers, SPL undergoes constant changes that are to be tracked in real time. In the context of customer-driven development, anticipation and change management are to be given paramount importance. It demands implementation of software variability that drives home changed, extended and customized configurations besides economy at scale. Moreover, the emergence of distributed technologies, the unprecedented growth of component based, serviceoriented systems throw ever increasing challenges to software product line configuration management. Derivation of a new product is a dynamic process in software product line that should consider functionality and quality attributes. Very few approaches are found on configuration management (CM) of SPL though CM is enough matured for traditional products. They are tailor made and inadequate to provide a general solution. Stated differently, a comprehensive approach for SPL configuration management and product derivation is still to be desired. In this paper, we proposed a framework that guides in doing so besides helping in SPL definitions in generic way. Our framework facilitates SPL configuration management and product derivation based on critical path analysis, weight computation and feedback. We proposed two algorithms namely Quality Driven Product Derivation (QDPD) and Composition Analysis algorithm for generating satisfied compositions and to find best possible composition respectively. The usage of weights and critical path analysis improves quality of product derivation. The framework is extensible and flexible thus it can be leveraged with variability-aware design patterns and ontology. We built a prototype that demonstrates the proof of concept. We tested our approach with Dr. School product line. The results reveal that the framework supports configuration management of SPL and derivation of high quality product in the product line. We evaluated results with ground truth to establish significance of our implementation},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–10},
numpages = {10},
keywords = {Software product line, configuration management, critical path analysis, product derivation, weighted approach}
}

@inproceedings{10.5555/1885639.1885642,
author = {Bagheri, Ebrahim and Di Noia, Tommaso and Ragone, Azzurra and Gasevic, Dragan},
title = {Configuring software product line feature models based on Stakeholders' soft and hard requirements},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling is a technique for capturing commonality and variability. Feature models symbolize a representation of the possible application configuration space, and can be customized based on specific domain requirements and stakeholder goals. Most feature model configuration processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called P(N). Furthermore, we formalize the representation of soft constraints in fuzzy P(N) and explain how semi-automated feature model configuration is performed. The model configuration derivation process that we propose respects the soundness and completeness properties.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {16–31},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/2364412.2364419,
author = {Asadi, Mohsen and Bagheri, Ebrahim and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {Requirements engineering in feature oriented software product lines: an initial analytical study},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364419},
doi = {10.1145/2364412.2364419},
abstract = {Requirements engineering is recognized as a critical stage in software development lifecycle. Given the nature of Software Product Lines (SPL), the importance of requirements engineering is more pronounced as SPLs pose more complex challenges than development of a 'single' product. Several methods have been proposed in the literature, which encompass activities for capturing requirements, their variability and commonality. To investigate the maturity and effectiveness of the current requirements engineering approaches in software product lines, we develop an evaluation framework containing a set of evaluation criteria and assess feature oriented requirements engineering methods based on the proposed criteria. As a result of this initial study, we find out the majority of approaches lacks proper techniques for supporting the validation of family requirements models as well as dealing with delta requirements. Additionally, capturing stakeholders' preferences and applying them during the course of software feature configuration have not been taken into account and addressed in the proposed approaches.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {36–44},
numpages = {9},
keywords = {evaluation criteria, requirements engineering, software engineering, software product line engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/11767718_28,
author = {Chang, Soo Ho and Kim, Soo Dong and Rhew, Sung Yul},
title = {A variability-centric approach to instantiating core assets in product line engineering},
year = {2006},
isbn = {3540346821},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11767718_28},
doi = {10.1007/11767718_28},
abstract = {As a key activity in product line engineering (PLE), instantiation is a task to generate target applications by resolving variability embedded in core assets. However, instantiation is often conducted in manual and ad-hoc fashion, largely replying on domain knowledge and experience. Hence, it can easily lead to technical problems in precisely specifying decision model consisting of product-specific variation points and variants, and in handling inter-variant conflicts/dependency. To overcome this difficulty, it is desirable to develop a systematic process which includes a set of systematic activities, detailed instructions, and concrete specification of artifacts. In this paper, we first propose a meta-model of a core asset to specify its key elements. Then, we represent a comprehensive process that defines key instantiation activities, representations of artifacts, and work instructions. With the proposed process, one can instantiate core assets more effectively and systematically.},
booktitle = {Proceedings of the 7th International Conference on Product-Focused Software Process Improvement},
pages = {334–347},
numpages = {14},
location = {Amsterdam, The Netherlands},
series = {PROFES'06}
}

@inproceedings{10.1145/3461001.3471142,
author = {Gu\'{e}gain, \'{E}douard and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {On reducing the energy consumption of software product lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471142},
doi = {10.1145/3461001.3471142},
abstract = {Along the last decade, several studies considered green software design as a key development concern to improve the energy efficiency of software. Yet, few techniques address this concern for Software Product Lines (SPL). In this paper, we therefore introduce two approaches to measure and reduce the energy consumption of a SPL by analyzing a limited set of products sampled from this SPL. While the first approach relies on the analysis of individual feature consumptions, the second one takes feature interactions into account to better mitigate energy consumption of resulting products.Our experimental results on a real-world SPL indicate that both approaches succeed to produce significant energy improvements on a large number of products, while consumption data was modeled from a small set of sampled products. Furthermore, we show that taking feature interactions into account leads to more products improved with higher energy savings per product.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {89–99},
numpages = {11},
keywords = {consumption, energy, measurement, mitigation, software product lines},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3109729.3109737,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar and Azanza, Maider},
title = {Visualizing product customization efforts for spotting SPL reuse opportunities},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109737},
doi = {10.1145/3109729.3109737},
abstract = {Migrating a set of product variants to a managed SPL is rarely a one-shot effort. Experiences from industry revealed that a complete migration to an SPL might take years, during which customers' requirements still need to be fulfilled by the company (customization effort). Analyzing the assets that have been customized by products (customization analysis) becomes a main stepping stone in ascertaining reuse opportunities. This requires to remain vigilant to arising reuse opportunities not just at the SPL onset, but throughout the whole process. Traditionally, a common mechanism to identify reuse opportunities is the diff utility whereby differences between two files are calculated and displayed. But this mechanism might not scale up. Given the sheer number of both core-assets and SPL products, visualizations that abstract from conventional line-level diffs to higher level visualization are required to spot reuse opportunities a ta glance. To this end, we introduce visualizations that help to estimate the extent of the customization effort broken down by product and core-asset. The aim: a prompt insight into questions such as, how much effort are product developers spending on customization?; or, which core-assets needed a larger tuning to meet product requirements? This vision is realized in CUSTOMS, a visualization utility on top of FeatureHouse that resorts to alluvial diagrams and tree maps to display customization effort. CUSTOMS might serve as a first stepping stone for spotting reuse opportunities.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {73–80},
numpages = {8},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2019136.2019172,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Using knowledge-based systems to manage quality attributes in software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019172},
doi = {10.1145/2019136.2019172},
abstract = {Product configuration in a feature model in software product line engineering is a process, in which the desired features are selected based on the customers' functional requirements and non-functional requirements. The functional requirements of the target product can be satisfied by including the proper functional features. However, there is no such a straightforward way to realize the non-functional requirements and quality attributes of the target product. In our early work, we have developed a quantitative based method to assess the quality attributes for a configured product. However, this approach cannot adequately represent the inter-relationships among quality attributes which play an important role in product configuration process. We supplement our previous work by introducing a quality attribute knowledge base (QA_KB) to represent the inter-relationships among different quality attributes in a SPL. Furthermore, we develop algorithms for configuring a product based on customers' quality requirements. We also use a case study to illustrate our approach.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {32},
numpages = {7},
keywords = {feature model, non-functional requirements, product configuration, quality attributes, software product line},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3233027.3233049,
author = {Horcas, Jose-Miguel and Corti\~{n}as, Alejandro and Fuentes, Lidia and Luaces, Miguel R.},
title = {Integrating the common variability language with multilanguage annotations for web engineering},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233049},
doi = {10.1145/3233027.3233049},
abstract = {Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {196–207},
numpages = {12},
keywords = {CVL, SPL, annotations, automation, composition, variability, web engineering},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3336294.3336313,
author = {Fernandez-Amoros, David and Heradio, Ruben and Mayr-Dorn, Christoph and Egyed, Alexander},
title = {A Kconfig Translation to Logic with One-Way Validation System},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336313},
doi = {10.1145/3336294.3336313},
abstract = {Automated analysis of variability models is crucial for managing software system variants, customized for different market segments or contexts of use. As most approaches for automated analysis are built upon logic engines, they require having a Boolean logic translation of the variability models. However, the translation of some significant languages to Boolean logic is remarkably non-trivial. The contribution of this paper is twofold: first, a translation of the Kconfig language is presented; second, an approach to test the translation for any given model is provided. The proposed translation has been empirically tested with the introduced validation procedure on five open-source projects.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {303–308},
numpages = {6},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3461001.3471146,
author = {Horcas, Jose-Miguel and Galindo, Jos\'{e} A. and Heradio, Ruben and Fernandez-Amoros, David and Benavides, David},
title = {Monte Carlo tree search for feature model analyses: a general framework for decision-making},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471146},
doi = {10.1145/3461001.3471146},
abstract = {The colossal solution spaces of most configurable systems make intractable their exhaustive exploration. Accordingly, relevant analyses remain open research problems. There exist analyses alternatives such as SAT solving or constraint programming. However, none of them have explored simulation-based methods. Monte Carlo-based decision making is a simulation-based method for dealing with colossal solution spaces using randomness. This paper proposes a conceptual framework that tackles various of those analyses using Monte Carlo methods, which have proven to succeed in vast search spaces (e.g., game theory). Our general framework is described formally, and its flexibility to cope with a diversity of analysis problems is discussed (e.g., finding defective configurations, feature model reverse engineering or getting optimal performance configurations). Additionally, we present a Python implementation of the framework that shows the feasibility of our proposal. With this contribution, we envision that different problems can be addressed using Monte Carlo simulations and that our framework can be used to advance the state of the art a step forward.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {190–201},
numpages = {12},
keywords = {configurable systems, feature models, monte carlo tree search, software product lines, variability modeling},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3233027.3233039,
author = {Pereira, Juliana Alves and Schulze, Sandro and Figueiredo, Eduardo and Saake, Gunter},
title = {N-dimensional tensor factorization for self-configuration of software product lines at runtime},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233039},
doi = {10.1145/3233027.3233039},
abstract = {Dynamic software product lines demand self-adaptation of their behavior to deal with runtime contextual changes in their environment and offer a personalized product to the user. However, taking user preferences and context into account impedes the manual configuration process, and thus, an efficient and automated procedure is required. To automate the configuration process, context-aware recommendation techniques have been acknowledged as an effective mean to provide suggestions to a user based on their recognized context. In this work, we propose a collaborative filtering method based on tensor factorization that allows an integration of contextual data by modeling an N-dimensional tensor User-Feature-Context instead of the traditional two-dimensional User-Feature matrix. In the proposed approach, different types of non-functional properties are considered as additional contextual dimensions. Moreover, we show how to self-configure software product lines by applying our N-dimensional tensor factorization recommendation approach. We evaluate our approach by means of an empirical study using two datasets of configurations derived for medium-sized product lines. Our results reveal significant improvements in the predictive accuracy of the configuration over a state-of-the-art non-contextual matrix factorization approach. Moreover, it can scale up to a 7-dimensional tensor containing hundred of configurations in a couple of milliseconds.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {87–97},
numpages = {11},
keywords = {recommender systems, runtime decision-making, self-configuration, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2648511.2648523,
author = {Urli, Simon and Blay-Fornarino, Mireille and Collet, Philippe},
title = {Handling complex configurations in software product lines: a tooled approach},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648523},
doi = {10.1145/2648511.2648523},
abstract = {As Software Product Lines (SPLs) are now more widely applied in new application fields such as IT or Web systems, complex and large-scale configurations have to be handled. In these fields, the strong domain orientation leads to the need to manage interrelated SPLs and multiple instances of configured sub-products, resulting in complex configurations that cannot be easily represented by simple sets of features. In this paper we propose a tooled approach to manage such SPLs through a domain model that interrelates several feature models in a consistent way. The approach thus shifts part of the domain knowledge to the problem space and supports the derivation of complex configurations with multiple instantiations and associations of sub-products. We also report on the application of our approach to an industrial-strength software development in the field of digital signage.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {112–121},
numpages = {10},
keywords = {configuration, software product line},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2791060.2791099,
author = {Filho, Jo\~{a}o Bosco Ferreira and Allier, Simon and Barais, Olivier and Acher, Mathieu and Baudry, Benoit},
title = {Assessing product line derivation operators applied to Java source code: an empirical study},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791099},
doi = {10.1145/2791060.2791099},
abstract = {Product Derivation is a key activity in Software Product Line Engineering. During this process, derivation operators modify or create core assets (e.g., model elements, source code instructions, components) by adding, removing or substituting them according to a given configuration. The result is a derived product that generally needs to conform to a programming or modeling language. Some operators lead to invalid products when applied to certain assets, some others do not; knowing this in advance can help to better use them, however this is challenging, specially if we consider assets expressed in extensive and complex languages such as Java. In this paper, we empirically answer the following question: which product line operators, applied to which program elements, can synthesize variants of programs that are incorrect, correct or perhaps even conforming to test suites? We implement source code transformations, based on the derivation operators of the Common Variability Language. We automatically synthesize more than 370,000 program variants from a set of 8 real large Java projects (up to 85,000 lines of code), obtaining an extensive panorama of the sanity of the operations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {36–45},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2499777.2500719,
author = {Schr\"{o}ter, Reimar and Siegmund, Norbert and Th\"{u}m, Thomas},
title = {Towards modular analysis of multi product lines},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500719},
doi = {10.1145/2499777.2500719},
abstract = {Software product-line engineering enables efficient development of tailor-made software by means of reusable artifacts. As practitioners increasingly develop software systems as product lines, there is a growing potential to reuse product lines in other product lines, which we refer to as multi product line. We identify challenges when developing multi product lines and propose interfaces for different levels of abstraction ranging from variability modeling to functional and non-functional properties. We argue that these interfaces ease the reuse of product lines and identify research questions that need to be solved toward modular analysis of multi product lines.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {96–99},
numpages = {4},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2019136.2019149,
author = {Murugesupillai, Esan and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {A preliminary mapping study of approaches bridging software product lines and service-oriented architectures},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019149},
doi = {10.1145/2019136.2019149},
abstract = {Service Oriented Architectures (SOA) and Software Product Lines (SPL) have individually proven to be software engineering concepts that create added value to the development of software systems. Recently, the research community has recognized and investigated potentials for combining these two concepts. However, there have been no mapping study and literature surveys that systematically review the present research results in combining the two. This paper presents results of a preliminary work on a systematic mapping study of research papers that report on combining SOA and SPL. The main goal of a systematic mapping study is to provide a breath overview, classification of approaches and the quantity and type of research as well as available research results, which is complimentary step toward further systematic literature review. This paper, based on selected papers published from 2002 to mid-2010, reports on various aspects of the analyzed literature, including the motivations for combining the two concepts; contributions to specific stages of software engineering lifecycles; types of synergies and characteristics that are accomplished through combinations of the two concepts; and the methods used for and the rigor of the evaluations of the research conducted on the studied topic.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {11},
numpages = {8},
keywords = {service-oriented architecture, service-oriented product line, software product line, software variability, variability management},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2362536.2362561,
author = {de Oliveira, Thiago Henrique Burgos and Becker, Martin and Nakagawa, Elisa Yumi},
title = {Supporting the analysis of bug prevalence in software product lines with product genealogy},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362561},
doi = {10.1145/2362536.2362561},
abstract = {The term bug prevalence is derived from the medical world vocabulary and applied to Software Product Line (SPL), meaning all products that are affected by one particular bug. In single systems development, this concept is not relevant since a bug is either present or not. However, when it comes to SPL, analyzing the bug prevalence of a certain bug is still a challenge and a highly relevant topic, since the same bug may be present in several products. To support this analysis, the main contribution of this paper is the Product Genealogy approach. A core concept in our approach is the Product Genealogy Tree, in which the hierarchy of products in the SPL is represented, reflecting how each product evolved or was derived from another or from the core assets. In this context, the benefit of such a tree is the rapid visualization of the product's structure in the SPL, providing input on which products are to be examined initially. Besides that, in this paper we introduce a novel analogy between the medical genetics world and SPL in order to better explain the principles of our approach.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {181–185},
numpages = {5},
keywords = {bug prevalence, change impact, product genealogy, software product line},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2647908.2655964,
author = {Mannion, Mike and Kaindl, Hermann},
title = {Using similarity metrics for mining variability from software repositories},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655964},
doi = {10.1145/2647908.2655964},
abstract = {Much activity within software product line engineering has been concerned with explicitly representing and exploiting commonality and variability at the feature level for the purpose of a particular engineering task e.g. requirements specification, design, coding, verification, product derivation process, but not for comparing how similar products in the product line are with each other. In contrast, a case-based approach to software development is concerned with descriptions and models as a set of software cases stored in a repository for the purpose of searching at a product level, typically as a foundation for new product development. New products are derived by finding the most similar product descriptions in the repository using similarity metrics.The new idea is to use such similarity metrics for mining variability from software repositories. In this sense, software product line engineering could be informed by the case-based approach. This approach requires defining and implementing such similarity metrics based on the representations used for the software cases in such a repository. It provides complementary benefits to the ones given through feature-based representations of variability and may help mining such variability.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {32–35},
numpages = {4},
keywords = {case-based reasoning, commonality and variability, feature-based representation, product lines, similarity metrics},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2377816.2377821,
author = {Garcia-Alonso, Jose and Olmeda, Javier Berrocal and Murillo, Juan Manuel},
title = {Architectural variability management in multi-layer web applications through feature models},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377821},
doi = {10.1145/2377816.2377821},
abstract = {The development of large web applications has focused on the use of increasingly complex architectures based on the layer architectural pattern and different development frame-works. Many techniques have been proposed to deal with this increasing complexity, mostly in the field of model-based development which abstracts the architects and designers from the architectural and technological complexities. However, these techniques do not take into account the great variability of these architectures, and therefore limit the architectural options available for their users. We here describe a feature model that captures the architectural and technological variability of multilayer applications. Using this feature model as the core of a model-driven development process, we are able to incorporate architectural and technological variability into the model-based development of multilayer applications. This approach keeps complexity under control whilst flexibility on choosing technologies is not penalized},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {29–36},
numpages = {8},
keywords = {design patterns, development frameworks, feature model, model-driven development, multilayer architectures},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1145/2791060.2791108,
author = {Berger, Thorsten and Lettner, Daniela and Rubin, Julia and Gr\"{u}nbacher, Paul and Silva, Adeline and Becker, Martin and Chechik, Marsha and Czarnecki, Krzysztof},
title = {What is a feature? a qualitative study of features in industrial software product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791108},
doi = {10.1145/2791060.2791108},
abstract = {The notion of features is commonly used to describe the functional and non-functional characteristics of a system. In software product line engineering, features often become the prime entities of software reuse and are used to distinguish the individual products of a product line. Properly decomposing a product line into features, and correctly using features in all engineering phases, is core to the immediate and long-term success of such a system. Yet, although more than ten different definitions of the term feature exist, it is still a very abstract concept. Definitions lack concrete guidelines on how to use the notion of features in practice.To address this gap, we present a qualitative empirical study on actual feature usage in industry. Our study covers three large companies and an in-depth, contextualized analysis of 23 features, perceived by the interviewees as typical, atypical (outlier), good, or bad representatives of features. Using structured interviews, we investigate the rationales that lead to a feature's perception, and identify and analyze core characteristics (facets) of these features. Among others, we find that good features precisely describe customer-relevant functionality, while bad features primarily arise from rashly executed processes. Outlier features, serving unusual purposes, are necessary, but do not require the full engineering process of typical features.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {16–25},
numpages = {10},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3336294.3336306,
author = {Ghamizi, Salah and Cordy, Maxime and Papadakis, Mike and Traon, Yves Le},
title = {Automated Search for Configurations of Convolutional Neural Network Architectures},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336306},
doi = {10.1145/3336294.3336306},
abstract = {Convolutional Neural Networks (CNNs) are intensively used to solve a wide variety of complex problems. Although powerful, such systems require manual configuration and tuning. To this end, we view CNNs as configurable systems and propose an end-to-end framework that allows the configuration, evaluation and automated search for CNN architectures. Therefore, our contribution is threefold. First, we model the variability of CNN architectures with a Feature Model (FM) that generalizes over existing architectures. Each valid configuration of the FM corresponds to a valid CNN model that can be built and trained. Second, we implement, on top of Tensorflow, an automated procedure to deploy, train and evaluate the performance of a configured model. Third, we propose a method to search for configurations and demonstrate that it leads to good CNN models. We evaluate our method by applying it on image classification tasks (MNIST, CIFAR-10) and show that, with limited amount of computation and training, our method can identify high-performing architectures (with high accuracy). We also demonstrate that we outperform existing state-of-the-art architectures handcrafted by ML researchers. Our FM and framework have been released to support replication and future research.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {119–130},
numpages = {12},
keywords = {AutoML, NAS, configuration search, feature model, neural architecture search},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2364412.2364429,
author = {Parra, Carlos and Giral, Leonardo and Infante, Alvaro and Cort\'{e}s, Camilo},
title = {Extractive SPL adoption using multi-level variability modeling},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364429},
doi = {10.1145/2364412.2364429},
abstract = {Software Product Line engineering aims at reusing and automating software development to reduce costs, have shorter development cycles, and maintain quality. However, for organizations with settled development processes and a large code base, adopting an SPL approach may prove to be a daunting task. In this paper we present an industrial experimentation and a proposal for an SPL adoption in Heinsohn Business Technology (HBT), a software development company specialized in financial, transportation, mortgage-backed securities, and pension-fund solutions. We start by identifying and modeling multiple levels of variability inherent to the kind of developments undertaken by HBT. Next, we define restrictions inside every level as well as between the levels to fully characterize an HBT software product. To limit the impact on the organization development process, we use an extractive approach. This allows us to design core assets starting from current software artifacts. The overall approach is based on real-world software artifacts developed over the years by HBT, whose combinations result in approximately 4.88e11 possible product configurations.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {99–106},
numpages = {8},
keywords = {model-driven engineering, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3307630.3342401,
author = {Villota, Angela and Mazo, Ra\'{u}l and Salinesi, Camille},
title = {The High-Level Variability Language: An Ontological Approach},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342401},
doi = {10.1145/3307630.3342401},
abstract = {Given its relevance, there is an extensive body of research for modeling variability in diverse domains. Regretfully, the community still faces issues and challenges to port or share variability models among tools and methodological approaches. There are researchers, for instance, implementing the same algorithms and analyses again because they use a specific modeling language and cannot use some existing tool. This paper introduces the High-Level Variability Language (HLVL), an expressive and extensible textual language that can be used as a modeling and an intermediate language for variability. HLVL was designed following an ontological approach, i.e., by defining their elements considering the meaning of the concepts existing on different variability languages. Our proposal not only provides a unified language based on a comprehensive analysis of the existing ones but also sets foundations to build tools that support different notations and their combination.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {162–169},
numpages = {8},
keywords = {domain specific language, variability language, variability specification},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.procs.2019.12.173,
author = {Chemingui, Houssem and Gam, Ines and Mazo, Ra\'{u}l and Salinesi, Camille and Ghezala, Henda Ben},
title = {Product Line Configuration Meets Process Mining},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {164},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.12.173},
doi = {10.1016/j.procs.2019.12.173},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {199–210},
numpages = {12},
keywords = {Product line engineering, configuration process, process mining, enhancing, configuration difficulties}
}

@inproceedings{10.1145/2364412.2364426,
author = {Villela, Karina and Arif, Taslim and Zanardini, Damiano},
title = {Towards product configuration taking into account quality concerns},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364426},
doi = {10.1145/2364412.2364426},
abstract = {The configuration of concrete products from a product line infrastructure is the process of resolving the variability captured in the product line according to a company's market strategy or specific customer's requirements. Several aspects influence the selection of features for a concrete product, such as dependencies and constraints between features, the different stakeholders involved in the process, the desired degree of quality, and cost constraints. This paper presents the vision of a configurator that will focus on providing indicators of security and performance for features and empowering its users to interactively observe the effect of the selected set of features on these two quality characteristics. We propose the use of reusable expert knowledge and static analysis for obtaining the indicators of security and performance, respectively. The two main issues to be investigated are: (1) to which degree the configuration process should be automated; and (2) how exactly to obtain indicators of security and performance for features that can be used to predict the security and performance of whole configurations.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {82–90},
numpages = {9},
keywords = {feature models, product configuration, product line engineering, quality concerns, static analysis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2499777.2500711,
author = {Ciolfi Felice, Marianela and Filho, Joao Bosco Ferreira and Acher, Mathieu and Blouin, Arnaud and Barais, Olivier},
title = {Interactive visualisation of products in online configurators: a case study for variability modelling technologies},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500711},
doi = {10.1145/2499777.2500711},
abstract = {Numerous companies develop interactive environments to assist users in customising sales products through the selection of configuration options. A visual representation of these products is an important factor in terms of user experience. However, an analysis of 100+ existing configurators highlights that not all provide visual representations of configured products. One of the current challenges is the trade-off developers face between either the memory consuming use of pregenerated images of all the combinations of options, or rendering products on the fly, which is non trivial to implement efficiently. We believe that a new approach to associate product configurations to visual representations is needed to compose and render them dynamically. In this paper we present a formal statement of the problem and a model-driven perspective for addressing it as well as our ongoing work and further challenges.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {82–85},
numpages = {4},
keywords = {configurator, software product line, user interface, variability modelling},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2934466.2934474,
author = {Myll\"{a}rniemi, Varvana and Raatikainen, Mikko and Savolainen, Juha and M\"{a}nnist\"{o}, Tomi},
title = {Purposeful performance variability in software product lines: a comparison of two case studies},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934474},
doi = {10.1145/2934466.2934474},
abstract = {Within software product lines, customers may have different quality needs. To produce products with purposefully different quality attributes, several challenges must be addressed. First, one must be able to distinguish product quality attributes to the customers in a meaningful way. Second, one must create the desired quality attribute differences during product-line architecture design and derivation. To study how performance is varied purposefully in software product lines, we conducted a comparison and re-analysis of two industrial case studies in the telecommunication and mobile game domains. The results show that performance variants must be communicated to the customer in a way that links to customer value and her role. When performance or its adaptation are crucial for the customer, performance differences must be explicitly "designed in" with software or hardware means. Due to the emergent nature of performance, it is important to test performance and manage how other variability affects performance.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {144–153},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2019136.2019161,
author = {Pleuss, Andreas and Rabiser, Rick and Botterweck, Goetz},
title = {Visualization techniques for application in interactive product configuration},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019161},
doi = {10.1145/2019136.2019161},
abstract = {In product line engineering (PLE) a major challenge is the complexity of artifacts that have to be handled. In real-world product lines, variability models can become large and complex comprising thousands of elements with hundreds of non-trivial dependencies. Visual and interactive techniques aim to reduce the (cognitive) complexity and support the user during challenging PLE tasks like product configuration. There are many visualization techniques described in the literature -- e.g., in Software Visualization -- and some isolated techniques have been applied in PLE tools. Nevertheless, the full potential of visualization in the context of PLE has not been exploited so far. This paper provides an overview of (1) available visualization techniques and criteria to judge their benefits and drawbacks for product configuration, (2) which have been applied in product configuration in PLE, and (3) which could be beneficial to support product configuration. We propose a research agenda for future work in visual and interactive PLE techniques.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {22},
numpages = {8},
keywords = {product configuration, product line engineering, software visualization},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/1842752.1842814,
author = {Geertsema, Bas and Jansen, Slinger},
title = {Increasing software product reusability and variability using active components: a software product line infrastructure},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842814},
doi = {10.1145/1842752.1842814},
abstract = {Software Product Lines are typically used to support development of a software product family and not a software product population, which denotes a broader and more diverse range of software products. We present a Software Product Line Infrastructure (SPLI) that has been designed to increase the reuse of software efforts in product populations. The SPLI takes a bottom-up approach by structuring product features in highly reusable software components called Active Components which contain different types of artefacts. Variability is expressed using domain-specific models and formal variability models. Variability is bound during product derivation by executing model-to-artefact transformations. Components are active because they are invoked during the derivation process, thereby empowering the component. The SPLI enables step-wise refinements of applications by allowing specialization and composition of models before variability is bound. A prototype of the SPLI has been created that was used to develop and evaluate an experimental software product line. It is concluded that within the context of our experimental software product line the SPLI improves software reuse in software product populations.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {336–343},
numpages = {8},
keywords = {active components, components, model-driven development, software product lines, variability},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@inproceedings{10.1145/2362536.2362558,
author = {Rubin, Julia and Kirshin, Andrei and Botterweck, Goetz and Chechik, Marsha},
title = {Managing forked product variants},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362558},
doi = {10.1145/2362536.2362558},
abstract = {We consider the problem of supporting effective code reuse as part of Software Product Line Engineering. Our approach is based on code forking -- a practice commonly used in industry where new products are created by cloning the existing ones. We propose to maintain meta-information allowing organization to reason about the developed product line in terms of features rather than incremental code changes made in different forks and to detect inconsistencies in implementations of these features. In addition, we propose to detect and maintain semantic, implementation-level require relationships between features, supporting the developers when they copy features from different branches or delete features in their own branch, thus facilitating reuse of features between products. Our approach aims at mitigating the disadvantages of the forking mechanism while leveraging its advantages. We illustrate the approach on an example, and discuss its possible implementation and integration with Software Configuration Management systems.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {156–160},
numpages = {5},
keywords = {SCM, software configuration management, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791066,
author = {Dhungana, Deepak and Falkner, Andreas and Haselb\"{o}ck, Alois and Schreiner, Herwig},
title = {Smart factory product lines: a configuration perspective on smart production ecosystems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791066},
doi = {10.1145/2791060.2791066},
abstract = {Smart production aims to increase the flexibility of the production processes and be more efficient in the use of resources. Two important pillars of this initiative are "smart products" and "smart factories". From the perspective of product line engineering, these can be seen as two product lines (product line of factories and product line of goods) that need to be integrated for a common systems engineering approach. In this paper, we look at this problem from the perspective of configuration technologies, outline the research challenges in this area and illustrate our vision using an industrial example. The factory product line goes hand-in-hand with the product line of the products to be manufactured. Future research in product line engineering needs to consider an ecosystem of a multitude of stakeholders - e.g., factory component vendors, product designers, factory owners/operators and end-consumers.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {201–210},
numpages = {10},
keywords = {product and production configuration, product line of factories, smart factory, smart product, smart production},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s10664-014-9353-5,
author = {Asadi, Mohsen and Soltani, Samaneh and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek},
title = {The effects of visualization and interaction techniques on feature model configuration},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9353-5},
doi = {10.1007/s10664-014-9353-5},
abstract = {A Software Product Line is a set of software systems of a domain, which share some common features but also have significant variability. A feature model is a variability modeling artifact which represents differences among software products with respect to variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by selecting features in the feature model (referred to as the configuration process) and by instantiating the reference model. However, feature model configuration can be a cumbersome task because: 1) feature models may consist of a large number of features, which are hard to comprehend and maintain; and 2) many factors including technical limitations, implementation costs, stakeholders' requirements and expectations must be considered in the configuration process. Recognizing these issues, a significant amount of research efforts has been dedicated to different aspects of feature model configuration such as automating the configuration process. Several approaches have been proposed to alleviate the feature model configuration challenges through applying visualization and interaction techniques. However, there have been limited empirical insights available into the impact of visualization and interaction techniques on the feature model configuration process. In this paper, we present a set of visualization and interaction interventions for representing and configuring feature models, which are then empirically validated to measure the impact of the proposed interventions. An empirical study was conducted by following the principles of control experiments in software engineering and by applying the well-known software quality standard ISO 9126 to operationalize the variables investigated in the experiment. The results of the empirical study revealed that the employed visualization and interaction interventions significantly improved completion time of comprehension and changing of the feature model configuration. Additionally, according to results, the proposed interventions are easy-to-use and easy-to-learn for the participants.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1706–1743},
numpages = {38},
keywords = {Controlled experiment, Software product line engineering, Tools}
}

@inproceedings{10.1145/3233027.3233034,
author = {K\"{u}hn, Thomas and Kassin, Kevin Ivo and Cazzola, Walter and A\ss{}mann, Uwe},
title = {Modular feature-oriented graphical editor product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233034},
doi = {10.1145/3233027.3233034},
abstract = {Software Product Lines (SPLs) have a long tradition and aim at reducing development costs by increasing reuse. They have been successfully applied to develop families of languages, ultimately establishing the field of Language Product Lines (LPLs). Currently, LPLs facilitate a family of textual languages by defining an SPL of compilers/interpreters. In contrast, this work aims at supporting families of graphical languages by defining an SPL of graphical editors, whereas each language variant is supported by a corresponding product of a Graphical Editor Product Line (GEPL). Thus far, there exists no modular approach for the development of GEPLs for families of visual languages. To remedy this, this paper introduces a feature-oriented development approach for GEPLs that ensures modularity, maintainability, and extensibility of the resulting product line. To showcase the suitability and applicability of our approach, we developed a modular GEPL for the family of role-based modeling languages, a feature rich family of conceptual modeling languages. Finally, we illustrate its extensibility by adding a complex language feature.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {76–86},
numpages = {11},
keywords = {graphical editors product lines, language product lines, modeling languages, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3106195.3106210,
author = {Markiegi, Urtzi and Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire},
title = {Search-based product line fault detection allocating test cases iteratively},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106210},
doi = {10.1145/3106195.3106210},
abstract = {The large number of possible configurations makes it unfeasible to test every single system variant in a product line. Consequently, a small subset of the product line products must be selected, typically following combinatorial interaction testing approaches. Recently, many product line engineering approaches have considered the selection and prioritization of relevant products within the product line. In a further step, these products are thoroughly tested individually. However, the test cases that must be executed in each of the products are not always insignificant, and in systems such as Cyber-Physical System Product Lines (CPSPLs), their test execution time can vary from tens to thousands of seconds. This issue leads to spending a lot of time testing each individual product. To solve this problem we propose a search-based approach to perform the testing of product lines by allocating small number of test cases in each of the products. This approach increases the probability of detecting faults faster. Specifically, our search-based approach obtains a set of products, which are derived from using any state-of-the-art approach as inputs, and a set of attributed test cases. As an output a list of allocated test cases for each product is obtained. We also define a novel fitness function to guide the search and we propose corresponding crossover and mutation operators. The search and test process is iteratively repeated until the time budget is consumed. We performed an evaluation with a CPSPL as a case study. Results suggest that our approach can reduce the fault detection time by 61% and 65% on average when compared with the traditional test process and the Random Search algorithm respectively.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {123–132},
numpages = {10},
keywords = {Fault Detection, Product Line Testing, Search-based Software Engineering},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2647648.2647649,
author = {Raschke, Wolfgang and Zilli, Massimiliano and Loinig, Johannes and Weiss, Reinhold and Steger, Christian and Kreiner, Christian},
title = {Embedding research in the industrial field: a case of a transition to a software product line},
year = {2014},
isbn = {9781450330459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647648.2647649},
doi = {10.1145/2647648.2647649},
abstract = {Java Cards [4, 5] are small resource-constrained embedded systems that have to fulfill rigorous security requirements. Multiple application scenarios demand diverse product performance profiles which are targeted towards markets such as banking applications and mobile applications. In order to tailor the products to the customer's needs we implemented a Software Product Line (SPL). This paper reports on the industrial case of an adoption to a SPL during the development of a highly-secure software system. In order to provide a scientific method which allows the description of research in the field, we apply Action Research (AR). The rationale of AR is to foster the transition of knowledge from a mature research field to practical problems encountered in the daily routine. Thus, AR is capable of providing insights which might be overlooked in a traditional research approach. In this paper we follow the iterative AR process, and report on the successful transfer of knowledge from a research project to a real industrial application.},
booktitle = {Proceedings of the 2014 International Workshop on Long-Term Industrial Collaboration on Software Engineering},
pages = {3–8},
numpages = {6},
keywords = {action research, knowledge transfer, software reuse},
location = {Vasteras, Sweden},
series = {WISE '14}
}

@inproceedings{10.1145/2791060.2791110,
author = {McVoy, Larry},
title = {Preliminary product line support in BitKeeper},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791110},
doi = {10.1145/2791060.2791110},
abstract = {One of the challenges of implementing a product line process is finding the appropriate tools for automation. One of our larger customers was implementing a product line process by-hand in a labor intensive and fragile way. We collaborated with them to evolve our distributed version control system, BitKeeper, into a tool that could handle their performance and product line requirements. The resulting product line generated several complex CPUs (around a billion transistors each).In this paper, we describe their by-hand process for producing different variations of a computer processor; we'll provide some background on the distributed version control system they were using; we'll describe the architectural changes implemented in BitKeeper for supporting product line work flows; we'll describe some of the changes we did to increase performance and provide some benchmark results comparing BitKeeper to Git, and we'll describe the work flow resulting from using the new architecture to replace their by-hand process.In the final section we'll discuss the current limitations of the existing tool, and describe how we plan on evolving it to overcome those limitations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {245–252},
numpages = {8},
keywords = {code reuse, configuration management, software product lines, version control},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2934466.2934492,
author = {Groher, Iris and Weinreich, Rainer and Buchgeher, Georg and Schossleitner, Robert},
title = {Reusable architecture variants for customer-specific automation solutions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934492},
doi = {10.1145/2934466.2934492},
abstract = {Manufacturing execution systems (MES) are key elements of industrial automation systems. MES can be deployed at different levels of scale from a single site or plant to a company with globally distributed production sites all over the world. Establishing or extending an MES is a complex process, which requires taking the already existing software and system architecture into account in addition to the desired MES features. We developed an approach and an associated tool to support the process of creating offers for customer-specific MES solutions based on a vendor-specific automation platform. We define architecture variants for selecting a specific MES feature set and for supporting different MES expansion stages. Additionally, we provide an architecture modeling approach to explore the integration with existing software and system infrastructures. The approach has been applied at the STIWA Group, a vendor of MES for industrial production lines.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {242–251},
numpages = {10},
keywords = {architecture variants, automation platform, customer-specific offer, feature set, manufacturing execution system (MES)},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2362536.2362567,
author = {Savolainen, Juha and Mannion, Mike and Kuusela, Juha},
title = {Developing platforms for multiple software product lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362567},
doi = {10.1145/2362536.2362567},
abstract = {Many approaches to software product line engineering have been founded on the development of a single product line platform. However as customer requirements change and new products are added to the product line, software producers recognize that the platform cannot be "stretched" indefinitely and a significant problem is striking a balance between development efficiency by increasing platform commonality and customer dissatisfaction from products with additional undesirable features and properties.One alternative is to develop multiple product lines (MPLs). However the challenge remains about what to include in a multiple product line platform. Drawing upon industrial experience of working with 4 companies, this paper explores the characteristics of the contexts in which MPLs are a viable alternative development strategy and then proposes a framework of approaches to platform development.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {220–228},
numpages = {9},
keywords = {industrial experience, multiple product lines, software reuse},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3233027.3233036,
author = {Hamza, Mostafa and Walker, Robert J. and Elaasar, Maged},
title = {CIAhelper: towards change impact analysis in delta-oriented software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233036},
doi = {10.1145/3233027.3233036},
abstract = {Change is inevitable for software systems to deal with the evolving environment surrounding them, and applying changes requires careful design and implementation not to break existing functionalities. Evolution in software product lines (SPLs) is more complex compared to evolution for individual products: a change applied to a single feature might affect all the products in the whole product family. In this paper we present an approach for change impact analysis in delta-oriented programming (DOP), an existing language aimed at supporting SPLs. We propose the CIAHelper tool to identify dependencies within a DOP program, by analyzing the semantics of both the code artifacts and variability models to construct a directed dependency graph. We also consider how the source code history could be used to enhance the recall of detecting the affected artifacts given a change proposal. We evaluate our approach by means of five case studies on two different DOP SPLs.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {31–42},
numpages = {12},
keywords = {change impact analysis, code assets, delta-oriented programming, feature model, variability model},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2791060.2791083,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar},
title = {Tuning GitHub for SPL development: branching models &amp; repository operations for product engineers},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791083},
doi = {10.1145/2791060.2791083},
abstract = {SPLs distinguish between domain engineering (DE) and application engineering (AE). Though each realm has its own lifecycle, they might need to be regularly synchronized to avoid SPL erosion during evolution. This introduces two sync paths: update propagation (from DE to AE) and feedback propagation (from AE to DE). This work looks at how to support sync paths in Version Control Systems (VCSs) using traditional VCS constructs (i.e. merge, branch, fork and pull). In this way, synchronization mismatches can be resolved \`{a} la VCS, i.e. highlighting difference between distinct versions of the same artifact. However, this results in a conceptual gap between how propagations are conceived (i.e. update, feedback) and how propagation are realized (i.e. merge, branch, etc). To close this gap, we propose to enhance existing VCSs with SPL sync paths as first-class operations. As a proof-of-concept, we use Web Augmentation techniques to extend GitHub's Web pages with this extra functionality. Through a single click, product engineers can now (1) generate product repositories, (2) update propagating newer feature versions, or (3), feedback propagating product customizations amenable to be upgraded as core assets.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {111–120},
numpages = {10},
keywords = {SPL evolution, VCS, branching model, change propagation},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2362536.2362543,
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
title = {A comparison of strategies for tolerating inconsistencies during decision-making},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362543},
doi = {10.1145/2362536.2362543},
abstract = {Tolerating inconsistencies is well accepted in design modeling because it is often neither obvious how to fix an inconsistency nor important to do so right away. However, there are technical reasons why inconsistencies are not tolerated in many areas of software engineering. The most obvious being that common reasoning engines are rendered (partially) useless in the presence of inconsistencies. This paper investigates automated strategies for tolerating inconsistencies during decision-making in product line engineering, based on isolating parts from reasoning that cause inconsistencies. We compare trade offs concerning incorrect and incomplete reasoning and demonstrate that it is even possible to fully eliminate incorrect reasoning in the presence of inconsistencies at the expense of marginally less complete reasoning. Our evaluation is based on seven medium-to-large size software product line case studies. It is important to note that our mechanism for tolerating inconsistencies can be applied to arbitrary SAT problems and thus the basic principles of this approach are applicable to other domains also.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {11–20},
numpages = {10},
keywords = {formal reasoning, inconsistencies, user guidance},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2499777.2500713,
author = {Lettner, Daniela and Petruzelka, Michael and Rabiser, Rick and Angerer, Florian and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {Custom-developed vs. model-based configuration tools: experiences from an industrial automation ecosystem},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500713},
doi = {10.1145/2499777.2500713},
abstract = {High demands regarding the variability of automation software motivate organizations to automate the configuration process. In practice, this often leads to the development of custom configuration tools designed specifically for configuring the automation software they were developed for. This approach works well as long as both, the development of the software and the configurator are under the full control of the organization. However, software platforms are increasingly open, i.e., key customers add capabilities and thereby change the platform's variability. Often, these customers create a new platform themselves, which they offer to their customers. Moving from a closed platform to a software ecosystem means that development and variability management happen at multiple layers involving multiple teams with different backgrounds. This poses new requirements regarding the flexibility of configuration tools. In this paper, we report experiences and issues with a custom-developed configurator currently in use in an industrial automation software ecosystem. We describe how a model-based tool can be applied to address these issues and provide a scenario-based comparison of the custom-developed solution and the model-based configurator.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {52–58},
numpages = {7},
keywords = {configuration, model-based product lines, software ecosystem},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using machine learning to infer constraints for product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {constraints and variability mining, machine learning, software product lines, software testing, variability modeling},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1109/MODELS-C.2019.00045,
author = {Bilic, Damir and Brosse, Etienne and Sadovykh, Andrey and Truscan, Dragos and Bruneliere, Hugo and Ryssel, Uwe},
title = {An integrated model-based tool chain for managing variability in complex system design},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00045},
doi = {10.1109/MODELS-C.2019.00045},
abstract = {Software-intensive systems in the automotive domain are often built in different variants, notably in order to support different market segments and legislation regions. Model-based concepts are frequently applied to manage complexity in such variable systems. However, the considered approaches are often focused on single-product development. In order to support variable products in a model-based systems engineering environment, we describe a tool-supported approach that allows us to annotate SysML models with variability data. Such variability information is exchanged between the system modeling tool and variability management tools through the Variability Exchange Language. The contribution of the paper includes the introduction of the model-based product line engineering tool chain and its application on a practical case study at Volvo Construction Equipment. Initial results suggest an improved efficiency in developing such a variable system.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems Companion},
pages = {288–293},
numpages = {6},
keywords = {integrated tool chain, model-based systems engineering, product line engineering},
location = {Munich, Germany},
series = {MODELS '19 Companion}
}

@article{10.1007/s10270-020-00803-8,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming},
title = {A framework for automated multi-stage and multi-step product configuration of cyber-physical systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00803-8},
doi = {10.1007/s10270-020-00803-8},
abstract = {Product line engineering (PLE) has been employed to large-scale cyber-physical systems (CPSs) to provide customization based on users’ needs. A PLE methodology can be characterized by its support for capturing and managing the abstractions as commonalities and variabilities and the automation of the configuration process for effective selection and customization of reusable artifacts. The automation of a configuration process heavily relies on the captured abstractions and formally specified constraints using a well-defined modeling methodology. Based on the results of our previous work and a thorough literature review, in this paper, we propose a conceptual framework to support multi-stage and multi-step automated product configuration of CPSs, including a comprehensive classification of constraints and a list of automated functionalities of a CPS configuration solution. Such a framework can serve as a guide for researchers and practitioners to evaluate an existing CPS PLE solution or devise a novel CPS PLE solution. To validate the framework, we conducted three real-world case studies. Results show that the framework fulfills all the requirements of the case studies in terms of capturing and managing variabilities and constraints. Results of the literature review indicate that the framework covers all the functionalities concerned by the literature, suggesting that the framework is complete for enabling the maximum automation of configuration in CPS PLE.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {211–265},
numpages = {55},
keywords = {Cyber-physical systems, Product line engineering, Automated configuration, Multi-stage and multi-step configuration process, Constraint classification, Variability modeling, Real-world case studies}
}

@inproceedings{10.1145/3106195.3106208,
author = {El-Sharkawy, Sascha and Krafczyk, Adam and Schmid, Klaus},
title = {An Empirical Study of Configuration Mismatches in Linux},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106208},
doi = {10.1145/3106195.3106208},
abstract = {Ideally the variability of a product line is represented completely and correctly by its variability model. However, in practice additional variability is often represented on the level of the build system or in the code. Such a situation may lead to inconsistencies, where the actually realized variability does not fully correspond to the one described by the variability model. In this paper we focus on configuration mismatches, i.e., cases where the effective variability differs from the variability as it is represented by the variability model. While previous research has already shown that these situations still exist even today in well-analyzed product lines like Linux, so far it was unclear under what circumstances such issues occur in reality. In particular, it is open what types of configuration mismatches occur and how severe they are. Here, our contribution is to close this gap by presenting a detailed manual analysis of 80 configuration mismatches in the Linux 4.4.1 kernel and assess their criticality. We identify various categories of configuration issues and show that about two-thirds of the configuration mismatches may actually lead to kernel misconfigurations.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {19–28},
numpages = {10},
keywords = {Kconfig, Linux, Software product lines, configuration mismatches, empirical software engineering, static analysis, variability modeling},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/2934466.2934485,
author = {Lape\~{n}a, Ra\'{u}l and Ballarin, Manuel and Cetina, Carlos},
title = {Towards clone-and-own support: locating relevant methods in legacy products},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934485},
doi = {10.1145/2934466.2934485},
abstract = {Clone-and-Own (CAO) is a common practice in families of software products consisting of reusing code from methods in legacy products in new developments. In industrial scenarios, CAO consumes high amounts of time and effort without guaranteeing good results. We propose a novel approach, Computer Assisted CAO (CACAO), that given the natural language requirements of a new product, and the legacy products from that family, ranks the legacy methods in the family for each of the new product requirements according to their relevancy to the new development. We evaluated our approach in the industrial domain of train control software. Without CACAO, software engineers tasked with the development of a new product had to manually review a total of 2200 methods in the family. Results show that CACAO can reduce the number of methods to be reviewed, and guide software engineers towards the identification of relevant legacy methods to be reused in the new product.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {194–203},
numpages = {10},
keywords = {clone and own, families of software products, software reuse},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1145/2579281.2579294,
author = {Castelluccia, Daniela and Boffoli, Nicola},
title = {Service-oriented product lines: a systematic mapping study},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2579281.2579294},
doi = {10.1145/2579281.2579294},
abstract = {Software product line engineering and service-oriented architectures both enable organizations to capitalize on reuse of existing software assets and capabilities and improve competitive advantage in terms of development savings, product flexibility, time-to-market. Both approaches accommodate variation of assets, including services, by changing the software being reused or composing services according a new orchestration. Therefore, variability management in Service-oriented Product Lines (SoPL) is one of the main challenges today. In order to highlight the emerging evidence-based results from the research community, we apply the well-defined method of systematic mapping in order to populate a classification scheme for the SoPL field of interest. The analysis of results throws light on the current open issues. Moreover, different facets of the scheme can be combined to answer more specific research questions. The report reveals the need for more empirical research able to provide new metrics measuring efficiency and efficacy of the proposed models, new methods and tools supporting variability management in SoPL, especially during maintenance and verification and validation. The mapping study about SoPL opens further investigations by means of a complete systematic review to select and validate the most efficient solutions to variability management in SoPL.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {1–6},
numpages = {6},
keywords = {empirical study, mapping study, product line development, service-oriented architecture, service-oriented computing, software product line, variability management}
}

@inproceedings{10.5555/1753235.1753257,
author = {Carbon, Ralf and Adam, Sebastian and Uchida, Takayuki},
title = {Towards a product line approach for office devices: facilitating customization of office devices at Ricoh Co. Ltd.},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Like in many other domains, customization is one of the major challenges for providers of office devices like Ricoh Co. Ltd. The specific challenge is the integration of office devices with the workflows and existing office infrastructures of customers. Hence, an approach to support customization of office devices has been developed by Ricoh and Fraunhofer IESE. The approach builds upon product line engineering and focuses on improving application engineering to support customization based on the workflows and office infrastructures of specific customers. The key ideas of the approach are flexibility concepts on architecture level that support recurring types of customizations and a requirements engineering process that is driven by the workflows of individual customers. In this paper, the approach developed in cooperation with Ricoh is presented. A case study illustrates the applicability of the concepts and the overall approach.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {151–160},
numpages = {10},
keywords = {application engineering, flexibility, product line architecture, product line engineering, service orientation},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2019136.2019158,
author = {Guana, Victor and Correal, Dario},
title = {Variability quality evaluation on component-based software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019158},
doi = {10.1145/2019136.2019158},
abstract = {Quality assurance and evaluation in Model Driven Software Product Lines (MD-SPLs) are pivotal points for the growing and solidification of the generative software factories. They are framed as one of the future fact methodologies for the construction of software systems. Although several approximations address the problem of generative environments, software product line scope expression, and core asset definition, not many of them try to solve, as a fundamental step, the automation of the quality attribute evaluation in the MD-SPL development cycle. This paper presents a model-driven engineering method and a tool for the quality evaluation of product line configurations through a cross architectural view analysis.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {19},
numpages = {8},
keywords = {domain specific modeling, model composition, model-driven software product line, quality attribute, sensitivity point},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2791060.2791075,
author = {Fang, Miao and Leyh, Georg and Doerr, Joerg and Elsner, Christoph and Zhao, Jingjing},
title = {Towards model-based derivation of systems in the industrial automation domain},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791075},
doi = {10.1145/2791060.2791075},
abstract = {Many systems in the industrial automation domain include information systems. They manage manufacturing processes and control numerous distributed hardware and software components. In current practice, the development and reuse of such systems is costly and time-consuming, due to the variability of systems' topology and processes. Up to now, product line approaches for systematic modeling and management of variability have not been well established for such complex domains.In this paper, we present a model-based approach to support the derivation of systems in the target domain. The proposed architecture of the derivation infrastructure enables feature-, topology- and process configuration to be integrated into the multi-staged derivation process. We have developed a prototype to prove feasibility and improvement of derivation efficiency. We report the evaluation results that we collected through semi-structured interviews from domain stakeholders. The results show high potential to improve derivation efficiency by adopting the approach in practice. Finally, we report the lessons learned that raise the opportunities and challenges for future research.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {283–292},
numpages = {10},
keywords = {derivation, model-based engineering, product line, variability modeling},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2019136.2019146,
author = {Gerlach, Simon},
title = {Improving efficiency when deriving numerous products from software product lines simultaneously},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019146},
doi = {10.1145/2019136.2019146},
abstract = {In-car infotainment systems must allow for product differentiation and the adaption to the needs of different markets. Product line approaches are applied because large numbers of different product variants need to be developed simultaneously. During development, updated versions of each projected product variant need to be derived from the product line assets repeatedly. Current build tools create each of the numerous product variants one after another. Accordingly, the creation process can take much time. This paper presents an approach to abbreviate this creation process based on the fact that multiple product variants created at once can have parts in common. To benefit from this optimization potential the workflow that creates an individual product variant is subdivided into multiple fragments. Whenever a set of such product variants needs to be created, an optimization algorithm then calculates an individual execution order of the fragments for this set. This order minimizes the total execution time by a systematic reuse of workflow fragment's results for the creation of multiple different product variants.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {9},
numpages = {4},
keywords = {application engineering, automotive, product configuration, product derivation, software product lines},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2491627.2491639,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Acher, Mathieu and Baudry, Benoit and Le Noir, J\'{e}r\^{o}me},
title = {Generating counterexamples of model-based software product lines: an exploratory study},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491639},
doi = {10.1145/2491627.2491639},
abstract = {Model-based Software Product Line (MSPL) engineering aims at deriving customized models corresponding to individual products of a family. MSPL approaches usually promote the joint use of a variability model, a base model expressed in a specific formalism, and a realization layer that maps variation points to model elements. The design space of an MSPL is extremely complex to manage for the engineer, since the number of variants may be exponential and the derived product models have to be conformant to numerous well-formedness and business rules. In this paper, the objective is to provide a way to generate MSPLs, called counterexamples, that can produce invalid product models despite a valid configuration in the variability model. We provide a systematic and automated process, based on the Common Variability Language (CVL), to randomly search the space of MSPLs for a specific formalism. We validate the effectiveness of this process for three formalisms at different scales (up to 247 metaclasses and 684 rules). We also explore and discuss how counterexamples could guide practitioners when customizing derivation engines, when implementing checking rules that prevent early incorrect CVL models, or simply when specifying an MSPL.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {72–81},
numpages = {10},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2648511.2648549,
author = {Berger, Thorsten and St\u{a}nciulescu, \c{S}tefan and \O{}g\r{a}rd, Ommund and Haugen, \O{}ystein and Larsen, Bo and W\k{a}sowski, Andrzej},
title = {To connect or not to connect: experiences from modeling topological variability},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648549},
doi = {10.1145/2648511.2648549},
abstract = {Variability management aims at taming variability in large and complex software product lines. To efficiently manage variability, it has to be modeled using formal representations, such as feature or decision models. Such models are efficient in many domains, where variability is about switching on and off features, or using parameters to customize products of the product line. However, variability can be represented in the form of a topology in domains where variability is about connecting components in a certain order, in specific interconnected hierarchies, or in different quantities.In this experience report, we explore topological variability within a case study of large-scale fire alarm systems. We identify core characteristics of the variability, derive modeling requirements, model the variability using UML2 class diagrams, and discuss the applicability of further variability modeling languages. We show that, although challenging, class diagrams can suffice to represent topological variability in order to generate a configurator tool. In contrast, modeling parallel and recursive structures, cycles, informal constraints, and orthogonal hierarchies were among the main experienced challenges that require further research.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {330–339},
numpages = {10},
keywords = {class diagrams, configuration, experience report, software product lines, topology, variability modeling},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2364412.2364446,
author = {Leitner, Andrea and Wei\ss{}, Reinhold and Kreiner, Christian and Ebner, Wolfgang},
title = {Improving domain representation with multi-paradigm modeling},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364446},
doi = {10.1145/2364412.2364446},
abstract = {Domain modeling is a key task in Software Product Line (SPL) development. We identified two popular modeling paradigms: Feature-Oriented Domain Modeling (FODM) and Domain-Specific Modeling (DSM). The representation of the domain model is crucial in SPL engineering, since domain models have a long lifecycle and represent the externalized organizational domain knowledge. For complex and heterogeneous domains, such as embedded systems, different representation techniques can be useful to describe different aspects of the system.This paper describes a multi-paradigm modeling approach which enables the combined representation of Feature models and Domain-Specific Languages (DSL). The main idea is to reduce the complexity of the model and, thus, to improve its usability and maintainability. The technical realization of the multi-paradigm modeling approach uses 3 types of constraints to connect different modeling paradigms. The constraint checking mechanism reuses existing technology in order to not re-invent the wheel.A case study describes the applicability of the approach in a real-life automotive project for hybrid electric vehicle control software (HybConS) and shows the improvement of this approach compared to single-paradigm modeling.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {201–208},
numpages = {8},
keywords = {domain-specific modeling, feature-oriented domain modeling, multi-paradigm modeling, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2851613.2851959,
author = {Noorian, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Quality-centric feature model configuration using goal models},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851959},
doi = {10.1145/2851613.2851959},
abstract = {In software product line engineering, a feature model represents the possible configuration space and can be customized based on the stakeholders' needs. Considering the complexity of feature models in addition to the diversity of the stake-holders' expectations, the configuration process is viewed as a complex optimization problem. In this paper, we propose a holistic approach for the configuration process that seeks to satisfy the stakeholders' requirements as well as the feature models' structural and integrity constraints. Here, we model stakeholders' functional and non-functional needs and their preferences using requirement engineering goal models. We formalize the structure of the feature model, the stake-holders' objectives, and their preferences in the form of an integer linear program to automatically perform feature selection.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1296–1299},
numpages = {4},
keywords = {configuration process, feature model, goal model},
location = {Pisa, Italy},
series = {SAC '16}
}

@article{10.4018/ijkss.2014100103,
author = {Bashari, Mahdi and Noorian, Mahdi and Bagheri, Ebrahim},
title = {Product Line Stakeholder Preference Elicitation via Decision Processes},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {5},
number = {4},
issn = {1947-8208},
url = {https://doi.org/10.4018/ijkss.2014100103},
doi = {10.4018/ijkss.2014100103},
abstract = {In the software product line configuration process, certain features are selected based on the stakeholders' needs and preferences regarding the available functional and quality properties. This book chapter presents how a product configuration can be modeled as a decision process and how an optimal strategy representing the stakeholders' desirable configuration can be found. In the decision process model of product configuration, the product is configured by making decisions at a number of decision points. The decisions at each of these decision points contribute to functional and quality attributes of the final product. In order to find an optimal strategy for the decision process, a utility-based approach can be adopted, through which, the strategy with the highest utility is selected as the optimal strategy. In order to define utility for each strategy, a multi-attribute utility function is defined over functional and quality properties of a configured product and a utility elicitation process is then introduced for finding this utility function. The utility elicitation process works based on asking gamble queries over functional and quality requirement from the stakeholder. Using this utility function, the optimal strategy and therefore optimal product configuration is determined.},
journal = {Int. J. Knowl. Syst. Sci.},
month = oct,
pages = {35–51},
numpages = {17},
keywords = {Configuration Process, Decision Process, Economic Value, Software Product Line, Utility Elicitation}
}

@inproceedings{10.1145/2648511.2648525,
author = {Stein, Jacob and Nunes, Ingrid and Cirilo, Elder},
title = {Preference-based feature model configuration with multiple stakeholders},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648525},
doi = {10.1145/2648511.2648525},
abstract = {Feature model configuration is known to be a hard, error-prone and time-consuming activity. This activity gets even more complicated when it involves multiple stakeholders in the configuration process. Research work has proposed approaches to aid multi-stakeholder feature model configuration, but they rely on systematic processes that constraint decisions of some of the stakeholders. In this paper, we propose a novel approach to improve the multi-stakeholder configuration process, considering stakeholders' preferences expressed through both hard and soft constraints. Based on such preferences, we recommend different product configurations using different strategies from the social choice theory. We conducted an empirical study to evaluate the effectiveness of our strategies with respect to individual stakeholder satisfaction and fairness among all stakeholders. Results indicate that particular strategies perform best with respect to these aspects.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {132–141},
numpages = {10},
keywords = {feature model configuration, preferences, social choice},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2364412.2364449,
author = {Helvensteijn, Michiel},
title = {Abstract delta modeling: my research plan},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364449},
doi = {10.1145/2364412.2364449},
abstract = {Software product lines are sets of software programs with well defined commonalities and variabilities that are distinguished by which features they support. There is need of a way to organize the underlying code to clearly link features on the feature modeling level to code artifacts on the implementation level, without code duplication or overspecification, so we can support automated product derivation. Existing approaches are still lacking in one way or another. My answer to this problem is delta modeling. My thesis will approach delta modeling from an abstract algebraic perspective called Abstract Delta Modeling. It will give a thorough formal treatment of the subject and extend it in several directions. A workflow for building a product line from scratch, a way to model dynamic product lines as well as plenty of practical examples and case studies.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {217–224},
numpages = {8},
keywords = {PhD thesis, delta modeling, development workflow, dynamic product lines, modal logic, product lines, type systems},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3297280.3297510,
author = {Heisig, Philipp and Stegh\"{o}fer, Jan-Philipp and Brink, Christopher and Sachweh, Sabine},
title = {A generic traceability metamodel for enabling unified end-to-end traceability in software product lines},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297510},
doi = {10.1145/3297280.3297510},
abstract = {Mature development methodologies like software product line engineering or model-driven engineering are more and more adopted in software development. Accordingly, the resulting development processes combine artifacts from different disciplines and on different abstraction levels. It is crucial that the relationship between these artifacts is explicitly maintained to be able to track the development process and the reasons for design decisions. This problem becomes exacerbated if variability is considered since it is a cross-cutting concern that impacts all disciplines and artifacts. Traceability links support the linking of artifacts across model boundaries in an end-to-end manner. However, existing traceability solutions are either limited to specific development processes, tools, and artifact types, lack in uniformity, or do not consider variability. Thus, this paper introduces a MOF-based generic traceability metamodel for establishing uniform traceability-enabled workflows in a variability-aware and model-based environment. Necessary steps for instantiating the metamodel to specific artifact types of certain development processes are described. We evaluate the proposed solution with an exemplar of a car headlight and demonstrate the benefits of a consistent traceability concept.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2344–2353},
numpages = {10},
keywords = {component model, feature model, model-driven engineering, requirement, software product line, traceability, workflow},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2648511.2648533,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Generation, composition, and verification of families of human-intensive systems},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648533},
doi = {10.1145/2648511.2648533},
abstract = {Software products are rarely developed without providing different sets of features to better meet varying user needs, whether through tiered products as part of a product line or different subscription levels for software as a service (SaaS). Software product line approaches for generating and maintaining a family of different variants of software products address such needs for variation quite well. Real-world human-intensive systems (HISs) display similar needs for families of variants. A key contribution of this paper is to show how many of these needs can be rigorously and systematically addressed by adapting established techniques from system and software product line engineering (SPLE).In this paper, we present an approach for creating such families by explicitly modeling variation in HISs. We focus on two kinds of variation we have previously described in other work---functional detail variation and service variation. We describe a prototype system that is able to meet the need for these kinds of variation within an existing modeling framework and present a case study of the application of our prototype system to generate a family in an HIS from the domain of elections. Our approach also demonstrates how to perform model-checking of this family to discover whether any variants in the family may violate specified system requirements.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {207–216},
numpages = {10},
keywords = {process families, software product lines, system variation},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1007/s10270-012-0305-5,
author = {Buchmann, Thomas and Westfechtel, Bernhard},
title = {Mapping feature models onto domain models: ensuring consistency of configured domain models},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-012-0305-5},
doi = {10.1007/s10270-012-0305-5},
abstract = {We present an approach to model-driven software product line engineering which is based on feature models and domain models. A feature model describes both common and varying properties of the instances of a software product line. The domain model is composed of a structural model (package and class diagrams) and a behavioral model (story diagrams). Features are mapped onto the domain model by annotating elements of the domain model with features. An element of a domain model is specific to the features included in its feature annotation. An instance of the product line is defined by a set of selected features (a feature configuration). A configuration of the domain model is built by excluding all elements whose feature set is not included in the feature configuration. To ensure consistency of the configured domain model, we define constraints on the annotations of inter-dependent domain model elements. These constraints guarantee that a model element may be selected only when the model elements are also included on which it depends. Violations of dependency constraints may be removed automatically with the help of an error repair tool which propagates features to dependent model elements.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1495–1527},
numpages = {33},
keywords = {Dependency constraints, Domain models, Feature mappings, Feature models, Model-driven software product line engineering}
}

@inproceedings{10.1145/2362536.2362563,
author = {Heider, Wolfgang and Rabiser, Rick and Gr\"{u}nbacher, Paul and Lettner, Daniela},
title = {Using regression testing to analyze the impact of changes to variability models on products},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362563},
doi = {10.1145/2362536.2362563},
abstract = {Industrial product lines are typically maintained for a long time and evolve continuously to address changing requirements and new technologies. Already derived products often have to be re-derived after such changes to benefit from new and updated features. Product line engineers thus frequently need to analyze the impact of changes to variability models to prevent unexpected changes of re-derived products. In this paper we present a tool-supported approach that informs engineers about the impacts of variability model changes on existing products. Regression tests are used to determine whether existing product configurations and generated product outputs can be re-derived without unexpected effects. We evaluate the feasibility of the approach based on changes observed in a real-world software product line. More specifically, we show how our approach helps engineers performing specific evolution tasks to analyze the change impacts on existing products. We also evaluate the performance and scalability of our approach. Our results show that variability change impact analyses can be automated using model regression testing and can help reducing the gap between domain engineering and application engineering.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {196–205},
numpages = {10},
keywords = {product line evolution, regression testing, variability models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2491627.2492152,
author = {Taylor, Richard N.},
title = {The role of architectural styles in successful software ecosystems},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2492152},
doi = {10.1145/2491627.2492152},
abstract = {Software ecosystems are complex systems composed of multiple independent elements interacting with the system as a whole and with each other. "Success" for an ecosystem may be judged primarily in economic terms, but may alternatively be assessed with regard to other qualities, such as reduced time-to-market, widespread use, or adaptability. Example successful ecosystems include iOS apps, Photoshop Lightroom plug-ins, RESTful web services, and numerous e-commerce systems. This talk will examine the critical role that architectural styles play in making and sustaining successful ecosystems. Architectural styles are sets of design decisions applicable to a particular context, constraining development within that context, and yielding beneficial qualities. Styles carry lessons learned through experience, aid communication, provide vocabulary, and speed design. Most importantly, they can be key elements in maintaining conceptual integrity. After examining the role of styles in several ecosystems, the talk will focus on the particular problems of ecosystems in which some participants may be malicious, or where high degrees of customization or adaptability are required.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {2–4},
numpages = {3},
keywords = {COAST, REST, architectural styles, software ecosystems},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/2648511.2648517,
author = {Angerer, Florian and Pr\"{a}hofer, Herbert and Lettner, Daniela and Grimmer, Andreas and Gr\"{u}nbacher, Paul},
title = {Identifying inactive code in product lines with configuration-aware system dependence graphs},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648517},
doi = {10.1145/2648511.2648517},
abstract = {Application engineers frequently create customer-specific products in two stages: the required software components are first selected to create an initial product which is then evolved by refining the selected features and adapting the code to meet the customers' requirements. For instance, developers frequently set configuration options in the code to adjust the product. However, given that such changes are often necessary in the entire code base it is hard to know which part of the code is still relevant for the chosen configuration options. This means that engineers need to understand and maintain a lot of code that is potentially inactive in a particular product variant. Existing approaches provide only partial solutions: for instance, feature-to-code mappings do not adequately consider complex code dependencies of the implemented features. Static analysis techniques provide better results but usually do not consider variability aspects. We present an approach to automatically identify inactive code in product variants using a configuration-aware code analysis technique. We demonstrate the flexibility of our approach by customizing it to a product line of an industry partner in the domain of industrial automation. We further evaluate the approach to demonstrate its effectiveness, accuracy, and performance.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {52–61},
numpages = {10},
keywords = {application engineering, clone-and-own product lines, configuration, maintenance, static analysis},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1007/978-3-030-64694-3_11,
author = {Abbas, Muhammad and Saadatmand, Mehrdad and Enoiu, Eduard and Sundamark, Daniel and Lindskog, Claes},
title = {Automated Reuse Recommendation of Product Line Assets Based on Natural Language Requirements},
year = {2020},
isbn = {978-3-030-64693-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64694-3_11},
doi = {10.1007/978-3-030-64694-3_11},
abstract = {Software product lines (SPLs) are based on reuse rationale to aid quick and quality delivery of complex products at scale. Deriving a new product from a product line requires reuse analysis to avoid redundancy and support a high degree of assets reuse. In this paper, we propose and evaluate automated support for recommending SPL assets that can be reused to realize new customer requirements. Using the existing customer requirements as input, the approach applies natural language processing and clustering to generate reuse recommendations for unseen customer requirements in new projects. The approach is evaluated both quantitatively and qualitatively in the railway industry. Results show that our approach can recommend reuse with 74% accuracy and 57.4% exact match. The evaluation further indicates that the recommendations are relevant to engineers and can support the product derivation and feasibility analysis phase of the projects. The results encourage further study on automated reuse analysis on other levels of abstractions.},
booktitle = {Reuse in Emerging Software Engineering Practices: 19th International Conference on Software and Systems Reuse, ICSR 2020, Hammamet, Tunisia, December 2–4, 2020, Proceedings},
pages = {173–189},
numpages = {17},
keywords = {Software product line, Reuse recommender, Natural language processing, Word embedding},
location = {Hammamet, Tunisia}
}

@inproceedings{10.1145/2499777.2500712,
author = {Kolokolov, Viktor and Baumann, Paul and Santini, Silvia and Ruehl, Stefan T. and Verclas, Stephan A. W.},
title = {Flexible development of variable software features for mobile business applications},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500712},
doi = {10.1145/2499777.2500712},
abstract = {With recent advances in development and deployment of mobile business applications (MBAs) based on the hybrid Web approach (hybrid MBAs) enterprises around the world well recognize new potentials to mobilize their business processes (BPs). Variability has a natural appearance in complex environments of different enterprises, where even similar BPs can have varying facets on the cross-enterprise scale. Yet, despite this fact current development tools for hybrid MBAs are lacking systematic variability management. Further, the literature on this particular technological landscape is scarce. We highlight in this paper emerging importance of this research field and describe its context and a research methodology. We propose an SPL-based approach to tackle considerable variabilities of hybrid MBAs.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {67–73},
numpages = {7},
keywords = {hybrid web, mobile business applications, software product lines, variability modeling},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2648511.2648528,
author = {Barreiros, Jorge and Moreira, Ana},
title = {A cover-based approach for configuration repair},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648528},
doi = {10.1145/2648511.2648528},
abstract = {Feature models are often used to describe variability and commonality in Software Product Lines, specifying admissible configurations of valid products. However, invalid configurations may arise in some scenarios. These include feature model evolution that invalidates pre-existing products or collaborative configuration by multiple stakeholders with conflicting goals, among others. This problem has been acknowledged in the literature and some techniques for configuration repair have already been proposed. However, common optimization criteria such as proximity between original and repaired configurations can result in a significant number of alternative repair possibilities, easily attaining thousands of alternatives for models of practical dimension. Consequently, rather than just efficiently providing an exhaustive list of possibilities, an approach that specifically addresses this issue should be able to offer the user a manageable and comprehensible view of the configuration problems and potential repair options. We offer a novel approach for configuration repair, based on partitioning and cover analysis, with high performance and generating high quality solutions, which allows efficient identification and presentation of multiple competing repairs.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {157–166},
numpages = {10},
keywords = {configuration, configuration diagnosis, configuration repair, feature modeling, software product lines},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2556624.2556634,
author = {Lytra, Ioanna and Eichelberger, Holger and Tran, Huy and Leyh, Georg and Schmid, Klaus and Zdun, Uwe},
title = {On the interdependence and integration of variability and architectural decisions},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556634},
doi = {10.1145/2556624.2556634},
abstract = {In software product line engineering, the design of assets for reuse and the derivation of software products entails low-level and high-level decision making. In this process, two major types of decisions must be addressed: variability decisions, i.e., decisions made as part of variability management, and architectural decisions, i.e., fundamental decisions to be made during the design of the architecture of the product line or the products. In practice, variability decisions often overlap with or influence architectural decisions. For instance, resolving a variability may enable or prevent some architectural options. This inherent interdependence has not been explicitly and systematically targeted in the literature, and therefore, is mainly resolved in an ad hoc and informal manner today. In this paper, we discuss possible ways how variability and architectural decisions interact, as well as their management and integration in a systematic manner. We demonstrate the integration between the two types of decisions in a motivating case and leverage existing tools for implementing our proposal.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {8},
keywords = {architectural decisions, product derivation, software product lines, variability decisions},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.1145/2019136.2019140,
author = {Pichler, Christian and Huemer, Christian},
title = {Feature modeling for business document models},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019140},
doi = {10.1145/2019136.2019140},
abstract = {The United Nations Centre for Trace Facilitation and eBusiness (UN/CEFACT) provides a conceptual approach named Core Components for defining business document types based on generic, reusable building blocks. For facilitating interoperability in Electronic Data Interchange, these reusable building blocks are defined in an all-embracing manner. Accordingly, business partners customize the standard business document types for fitting their needs and requirements, resulting in different business document type variants. However, the approach is missing sufficient mechanisms for managing business document model variants. First, customizing standardized business document types is purely based on a textual specification. Second, the variability present within the Core Component approach lacks an explicit representation. In this paper, we aim at making variability explicit as well as adding a formal aspect to the business document type customization process by employing variability concepts from Product Line Engineering. Furthermore, based on having explicit variability models, business partners are provided with an approach for customizing business document types through configuring variability models.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {3},
numpages = {8},
keywords = {business document models, feature modeling, service-oriented architecture, variability modeling},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2362536.2362560,
author = {Lettner, Daniela and Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Supporting end users with business calculations in product configuration},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362560},
doi = {10.1145/2362536.2362560},
abstract = {Business calculations like break-even, return on investment, or cost are essential in many domains to support decision making while configuring products. For instance, customers and sales people need to estimate and compare the business value of different product variants. Some product line approaches provide initial support, e.g., by defining quality attributes in relation to features. However, an approach that allows domain engineers to easily define business calculations together with variability models is still lacking. In product configuration, calculation results need to be instantly presented to end users after making configuration choices. Further, due to the often high number of calculations, the presentation of calculation results to end users can be challenging. These challenges cannot be addressed by integrating off-the-shelf applications performing the calculations with product line tools. We thus present an approach based on dedicated calculation models that are related to variability models. Our approach seamlessly integrates business calculations with product configuration and provides support for formatting calculations and calculation results. We use the DOPLER tool suite to deploy calculations together with variability models to end users in product configuration. We evaluate the expressiveness and practical relevance of the approach by investigating the development of business calculations for 15 product lines from the domain of industrial automation.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {171–180},
numpages = {10},
keywords = {business calculations, product configuration, variability models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2364412.2364414,
author = {Derakhshanmanesh, Mahdi and Fox, Joachim and Ebert, J\"{u}rgen},
title = {Adopting feature-centric reuse of requirements assets: an industrial experience report},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364414},
doi = {10.1145/2364412.2364414},
abstract = {In this paper, we share practical experiences from an ongoing effort towards adopting a feature-centric method that enhances reuse of requirements at TRW Automotive's slip control system department (based in Koblenz, Germany). After introducing identified challenges in detail, key solution factors and a technical reuse concept for managing and deriving product-specific requirements are presented. Then, we demonstrate one way of implementing this solution approach based on industry-standard tools. In addition, identified pitfalls and lessons learned are discussed.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {2–9},
numpages = {8},
keywords = {features, requirements, reuse, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2647908.2655973,
author = {Cordy, Maxime and Willemart, Marco and Dawagne, Bruno and Heymans, Patrick and Schobbens, Pierre-Yves},
title = {An extensible platform for product-line behavioural analysis},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655973},
doi = {10.1145/2647908.2655973},
abstract = {Software Product-Line (SPL) model checking has reached an adequate level of efficiency and expressiveness to be applied on real-world cases. Yet a major challenge remains: model checkers should consist of black-box tools that do not require in-depth expertise to be used. In particular, it is essential to provide engineers with easy-to-learn languages to model both the behaviour of their SPL and the properties to check. In this paper, we propose a framework to build customized product-line verifiers modularly. Our extensible architecture allows one to plug new modelling languages or verifications algorithms without modifying other parts of it. It also provides means of representing and reasoning on variability that can facilitate the development of other SPL quality assurance techniques. We illustrate the benefits of our approach by detailing how we created a new domain-specific SPL modelling language and linked it to our tool.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {102–109},
numpages = {8},
keywords = {features, model checking, software product lines, tool},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2362536.2362554,
author = {Martini, Antonio and Pareto, Lars and Bosch, Jan},
title = {Enablers and inhibitors for speed with reuse},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362554},
doi = {10.1145/2362536.2362554},
abstract = {An open issue in industry is software reuse in the context of large scale Agile product development. The speed offered by agile practices is needed to hit the market, while reuse is needed for long-term productivity, efficiency, and profit. The paper presents an empirical investigation of factors influencing speed and reuse in three large product developing organizations seeking to implement Agile practices. The paper identifies, through a multiple case study with 3 organizations, 114 business-, process-, organizational-, architecture-, knowledge- and communication factors with positive or negative influences on reuse, speed or both. Contributions are a categorized inventory of influencing factors, a display for organizing factors for the purpose of process improvement work, and a list of key improvement areas to address when implementing reuse in organizations striving to become more Agile. Categories identified include good factors with positive influences on reuse or speed, harmful factors with negative influences, and complex factors involving inverse or ambiguous relationships. Key improvement areas in the studied organizations are intra-organizational communication practices, reuse awareness and practices, architectural integration and variability management. Results are intended to support process improvement work in the direction of Agile product development. Feedback on results from the studied organizations has been that the inventory captures current situations, and is useful for software process improvement work.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {116–125},
numpages = {10},
keywords = {agile software development, embedded systems, enablers, inhibitors, software process improvement (SPI), software reuse, speed},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2499777.2500709,
author = {Romero, Daniel and Urli, Simon and Quinton, Cl\'{e}ment and Blay-Fornarino, Mireille and Collet, Philippe and Duchien, Laurence and Mosser, S\'{e}bastien},
title = {SPLEMMA: a generic framework for controlled-evolution of software product lines},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500709},
doi = {10.1145/2499777.2500709},
abstract = {Managing in a generic way the evolution process of feature-oriented Software Product Lines (spls) is complex due to the number of elements that are impacted and the heterogeneity of the spls regarding artifacts used to define them. Existing work presents specific approaches to manage the evolution of spls in terms of such artifacts, i.e., assets, feature models and relation definitions. Moreover stakeholders do not necessarily master all the knowledge of the spl making its evolution difficult and error-prone without a proper tool support. In order to deal with these issues, we introduce SPLEmma, a generic framework that follows a Model Driven Engineering approach to capture the evolution of a spl independently of the kind of assets, technologies or feature models used for the product derivation. Authorized changes are described by the spl maintainer and captured in a model used to generate tools that guide the evolution process and preserve the consistency of the whole spl. We report on the application of our approach on two spls: YourCast for digital signage systems, and SALOON, which enables generation of configurations for cloud providers.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {59–66},
numpages = {8},
keywords = {automation, code generation, evolution, model-driven engineering},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2934466.2934470,
author = {K\"{u}hn, Thomas and Cazzola, Walter},
title = {Apples and oranges: comparing top-down and bottom-up language product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934470},
doi = {10.1145/2934466.2934470},
abstract = {Over the past decade language development tools have been significantly improved. This permitted both practitioners and researchers to design a wide variety of domain-specific languages (DSL) and extensions to programming languages. Moreover, multiple researchers have combined different language variants to form families of DSLs as well as programming languages. Unfortunately, current language development tools cannot directly support the development of these families. To overcome this limitation, researchers have recently applied ideas from software product lines (SPL) to create product lines of compilers/interpreters for language families, denoted language product lines (LPL). Similar to SPLs, however, these product lines can be created either using a top-down or a bottom-up approach. Yet, there exist no case study comparing the suitability of both approaches to the development of LPLs, making it unclear how language development tools should evolve. Accordingly, this paper compares both feature modeling approaches by applying them to the development of an LPL for the family of role-based programming languages and discussing their applicability, feasibility and overall suitability for the development of LPLs. Although one might argue that this compares apples and oranges, we believe that this case still provides crucial insights into the requirements, assumptions, and challenges of each approach.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {50–59},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1007/978-3-319-23781-7_27,
author = {Bouarar, Selma and Jean, St\'{e}phane and Siegmund, Norbert},
title = {SPL Driven Approach for Variability in Database Design},
year = {2015},
isbn = {9783319237800},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-23781-7_27},
doi = {10.1007/978-3-319-23781-7_27},
abstract = {The evolution of computer technology has strongly impacted the database design. No phase was spared: several conceptual formalisms e.g. ER, UML, ontological, various logical models e.g. relational, object, key-value, a wide panoply of physical optimization structures and deployment platforms have been proposed. As a result, the database design process has become more complex involving more tasks and even more actors as database architect or analyst. Getting inspired from software engineering in dealing with variable similar systems, we propose a methodological framework for a variability-aware design of databases, whereby this latter is henceforth devised as a Software Product Line. Doing so guarantees a high reuse, automation, and customizability in generating ready-to-be implemented databases. We also propose a solution to help users make a suitable choice among the wide panoply. Finally, a case study is presented.},
booktitle = {Proceedings of the 5th International Conference on Model and Data Engineering - Volume 9344},
pages = {332–342},
numpages = {11},
keywords = {Database design, Software Product Line, Variability},
location = {Rhodes, Greece},
series = {MEDI 2015}
}

@inproceedings{10.1145/2362536.2362544,
author = {Dietrich, Christian and Tartler, Reinhard and Schr\"{o}der-Preikschat, Wolfgang and Lohmann, Daniel},
title = {A robust approach for variability extraction from the Linux build system},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362544},
doi = {10.1145/2362536.2362544},
abstract = {With more than 11,000 optional and alternative features, the Linux kernel is a highly configurable piece of software. Linux is generally perceived as a textbook example for preprocessor-based product derivation, but more than 65 percent of all features are actually handled by the build system. Hence, variability-aware static analysis tools have to take the build system into account.However, extracting variability information from the build system is difficult due to the declarative and turing-complete make language. Existing approaches based on text processing do not cover this challenges and tend to be tailored to a specific Linux version and architecture. This renders them practically unusable as a basis for variability-aware tool support -- Linux is a moving target!We describe a robust approach for extracting implementation variability from the Linux build system. Instead of extracting the variability information by a text-based analysis of all build scripts, our approach exploits the build system itself to produce this information. As our results show, our approach is robust and works for all versions and architectures from the (git-)history of Linux.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {21–30},
numpages = {10},
keywords = {Linux, VAMOS, build systems, configurability, kbuild, maintenance, static analysis},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2791060.2791082,
author = {Hotz, Lothar and Wang, Yibo and Riebisch, Matthias and G\"{o}tz, Olaf and Lackhove, Josef},
title = {Evaluation across multiple views for variable automation systems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791082},
doi = {10.1145/2791060.2791082},
abstract = {Automation systems in industry are often software-intensive systems consisting of software and hardware components. During their development several engineers of different disciplines are involved, such as mechanical, electrical and software engineering. Each engineer focuses on specific system aspects to be developed. To enable an efficient development, product lines especially with feature models for variability modeling are promising technologies. In order to reduce the complexity of both feature models and development process, views on feature models can be applied. The use of views for filtering purposes constitutes an established method. However, views also enable further options missing in current approaches, such as evaluations regarding requirements, including non-functional ones. This paper presents an approach for evaluation across multiple views to enable collaborative development for developers who focus on different system aspects. We validate our approach by applying it in an industrial project for the planning of flying saws.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {311–315},
numpages = {5},
keywords = {automation systems, configuration, consistency check, feature model, multi-criteria evaluation, product lines},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/2647908.2655969,
author = {ter Beek, Maurice H. and Mazzanti, Franco},
title = {VMC: recent advances and challenges ahead},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655969},
doi = {10.1145/2647908.2655969},
abstract = {The variability model checker VMC accepts a product family specified as a Modal Transition System (MTS) with additional variability constraints. Consequently, it offers behavioral variability analyses over both the family and its valid product behavior. This ranges from product derivation and simulation to efficient on-the-fly model checking of logical properties expressed in a variability-aware version of action-based CTL. In this paper, we first explain the reasons and assumptions underlying the choice for a modeling and analysis framework based on MTSs. Subsequently, we present recent advances on proving inheritance of behavioral analysis properties from a product family to its valid products. Finally, we illustrate challenges remaining for the future.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {70–77},
numpages = {8},
keywords = {behavioral variability, model checking, product families},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1016/j.infsof.2012.07.010,
author = {Buchmann, Thomas and Dotor, Alexander and Westfechtel, Bernhard},
title = {MOD2-SCM: A model-driven product line for software configuration management systems},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.010},
doi = {10.1016/j.infsof.2012.07.010},
abstract = {Context: Software Configuration Management (SCM) is the discipline of controlling the evolution of large and complex software systems. Over the years many different SCM systems sharing similar concepts have been implemented from scratch. Since these concepts usually are hard-wired into the respective program code, reuse is hardly possible. Objective: Our objective is to create a model-driven product line for SCM systems. By explicitly describing the different concepts using models, reuse can be performed on the modeling level. Since models are executable, the need for manual programming is eliminated. Furthermore, by providing a library of loosely coupled modules, we intend to support flexible composition of SCM systems. Method: We developed a method and a tool set for model-driven software product line engineering which we applied to the SCM domain. For domain analysis, we applied the FORM method, resulting in a layered feature model for SCM systems. Furthermore, we developed an executable object-oriented domain model which was annotated with features from the feature model. A specific SCM system is configured by selecting features from the feature model and elements of the domain model realizing these features. Results: Due to the orthogonality of both feature model and domain model, a very large number of SCM systems may be configured. We tested our approach by creating instances of the product line which mimic wide-spread systems such as CVS, GIT, Mercurial, and Subversion. Conclusion: The experiences gained from this project demonstrate the feasibility of our approach to model-driven software product line engineering. Furthermore, our work advances the state of the art in the domain of SCM systems since it support the modular composition of SCM systems at the model rather than the code level.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {630–650},
numpages = {21},
keywords = {Code generation, Executable models, Feature models, Model transformation, Model-driven software engineering, Software configuration management, Software product line engineering}
}

@inproceedings{10.1145/1509239.1509258,
author = {Bonif\'{a}cio, Rodrigo and Borba, Paulo},
title = {Modeling scenario variability as crosscutting mechanisms},
year = {2009},
isbn = {9781605584423},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1509239.1509258},
doi = {10.1145/1509239.1509258},
abstract = {Variability management is a common challenge for Software Product Line (SPL) adoption, since developers need suitable mechanisms for specifying and implementing variability that occurs at different SPL artifacts (requirements, design, implementation, and test). In this paper, we present a novel approach for use case scenario variability management, enabling a better separation of concerns between languages used to manage variabilities and languages used to specify use case scenarios. The result is that both representations can be understood and evolved in a separate way. We achieve such a goal by modeling variability management as a crosscutting phenomenon, for the reason that artifacts such as feature models, product configurations, and configuration knowledge crosscut each other with respect to each specific SPL member. After applying our approach to different case studies, we achieved a better feature modularity and scenario cohesion.},
booktitle = {Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development},
pages = {125–136},
numpages = {12},
keywords = {requirements models, software product line, variability management},
location = {Charlottesville, Virginia, USA},
series = {AOSD '09}
}

@article{10.1007/s10270-011-0220-1,
author = {Hubaux, Arnaud and Heymans, Patrick and Schobbens, Pierre-Yves and Deridder, Dirk and Abbasi, Ebrahim Khalil},
title = {Supporting multiple perspectives in feature-based configuration},
year = {2013},
issue_date = {July      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-011-0220-1},
doi = {10.1007/s10270-011-0220-1},
abstract = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {641–663},
numpages = {23},
keywords = {Feature diagram, Feature-based configuration, Multi-view, Separation of concerns, Software product line engineering}
}

@inproceedings{10.1007/978-3-030-64694-3_17,
author = {Benmerzoug, Amine and Yessad, Lamia and Ziadi, Tewfik},
title = {Analyzing the Impact of Refactoring Variants on Feature Location},
year = {2020},
isbn = {978-3-030-64693-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64694-3_17},
doi = {10.1007/978-3-030-64694-3_17},
abstract = {Due to the increasing importance of feature location process, several studies evaluate the performance of different techniques based on IR strategies and a set of software variants as input artifacts. The proposed techniques attempt to improve the results obtained but it is often a difficult task. None of the existing feature location techniques considers the changing nature of the input artifacts, which may undergo series of refactoring changes. In this paper, we investigate the impact of refactoring variants on the feature location techniques. We first evaluate the performance of two techniques through the ArgoUML SPL benchmark when the variants are refactored. We then discuss the degraded results and the possibility of restoring them. Finally, we outline a process of variant alignment that aims to preserve the performance of the feature location.},
booktitle = {Reuse in Emerging Software Engineering Practices: 19th International Conference on Software and Systems Reuse, ICSR 2020, Hammamet, Tunisia, December 2–4, 2020, Proceedings},
pages = {279–291},
numpages = {13},
keywords = {Software Product Line, Feature location, Refactoring},
location = {Hammamet, Tunisia}
}

@inproceedings{10.1145/2362536.2362542,
author = {Pleuss, Andreas and Hauptmann, Benedikt and Keunecke, Markus and Botterweck, Goetz},
title = {A case study on variability in user interfaces},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362542},
doi = {10.1145/2362536.2362542},
abstract = {Software Product Lines (SPL) enable efficient derivation of products. SPL concepts have been applied successfully in many domains including interactive applications. However, the user interface (UI) part of applications has barely been addressed yet. While standard SPL concepts allow derivation of functionally correct UIs, there are additional non-functional requirements, like usability, which have to be considered. This paper presents a case study investigating UI variability found in variants of the commercial web-based information system HIS-GX/QIS. We analyze which aspects of a UI vary and to which degree. The results show that just tweaking the final UI (e.g., using stylesheets) is not sufficient but there is a need for more customization which must be supported by, e.g., UI-specific models.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {6–10},
numpages = {5},
keywords = {software product lines, user interface engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Software product line, Configurable system, Software variability, Software testing, Machine learning, Quality assurance}
}

@article{10.1145/3389397,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Pattern-based Interactive Configuration Derivation for Cyber-physical System Product Lines},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {2378-962X},
url = {https://doi.org/10.1145/3389397},
doi = {10.1145/3389397},
abstract = {Deriving a Cyber-Physical System (CPS) product from a product line requires configuring hundreds to thousands of configurable parameters of components and devices from multiple domains, e.g., computing, control, and communication. A fully automated configuration process for a CPS product line is seldom possible in practice, and a dynamic and interactive process is expected. Therefore, some configurable parameters are to be configured manually, and the rest can be configured either automatically or manually, depending on pre-defined constraints, the order of configuration steps, and previous configuration data in such a dynamic and interactive configuration process. In this article, we propose a pattern-based, interactive configuration derivation methodology (named as Pi-CD) to maximize opportunities of automatically deriving correct configurations of CPSs by benefiting from pre-defined constraints and configuration data of previous configuration steps. Pi-CD requires architectures of CPS product lines modeled with Unified Modeling Language extended with four types of variabilities, along with constraints specified in Object Constraint Language (OCL). Pi-CD is equipped with 324 configuration derivation patterns that we defined by systematically analyzing the OCL constructs and semantics. We evaluated Pi-CD by configuring 20 CPS products of varying complexity from two real-world CPS product lines. Results show that Pi-CD can achieve up to 72% automation degree with a negligible time cost. Moreover, its time performance remains stable with the increase in the number of configuration parameters as well as constraints.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jun,
articleno = {44},
numpages = {24},
keywords = {Product line engineering, configuration derivation, object constraint language, product configuration}
}

@inproceedings{10.1145/2648511.2648519,
author = {Moens, Hendrik and De Turck, Filip},
title = {Feature-based application development and management of multi-tenant applications in clouds},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648519},
doi = {10.1145/2648511.2648519},
abstract = {In recent years, there has been a rising interest in cloud computing, which is often used to offer Software as a Service (SaaS) over the Internet. SaaS applications can be offered to clients at a lower cost as they are usually multi-tenant: many end users make use of a single application instance, even when they are from different organisations. It is difficult to offer highly customizable SaaS applications that are still multi-tenant, which is why these SaaS applications are often offered in a one size fits all approach.In some application domains applications must be highly customizable, making it more difficult to migrate them to a cloud environment, and losing the benefits of multi-tenancy. In this paper we compare multiple approaches for the development and management of highly customizable multitenant SaaS applications, and present a methodology for developing and managing these applications. We compare two approaches, an application-based approach focusing on deploying multiple multi-tenant applications variants, and a feature-based approach where applications are composed out of multi-tenant services using a service oriented architecture. In addition, we also discuss a hybrid approach combining properties of both. We conclude that the feature-based approach results in the fewest application instances at runtime resulting in more multi-tenancy.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {72–81},
numpages = {10},
keywords = {cloud computing, feature modeling, multi-tenancy},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2364412.2364444,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Baudry, Benoit and Viana, Windson and Andrade, Rossana M. C.},
title = {An approach for semantic enrichment of software product lines},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364444},
doi = {10.1145/2364412.2364444},
abstract = {Software Product Lines (SPLs) have evolved and gained attention as one of the most promising approaches for software reuse. Feature models are the main technique to represent domain variability in SPLs. However, there are other domain aspects, besides variability, which cannot be expressed in a feature model. Also, these diagrams were not designed to facilitate information retrieval, interoperability and inference. In contrast, ontologies seem to be the best solution to meet these requirements. Therefore, this work presents an approach for semantic enrichment of SPLs using ontologies. Our proposal provides methods to add domain information besides variability description, and a top-ontology that specifies generic concepts and relations in an SPL, working as a guide model for information addition. The proposed approach reuses the existing SPL feature model, adding semantic descriptions in a less intrusive way than modifying the feature model notation.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {188–195},
numpages = {8},
keywords = {knowledge, ontology, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753238,
author = {White, Jules and Dougherty, Brian and Schmidt, Doulas C. and Benavides, David},
title = {Automated reasoning for multi-step feature model configuration problems},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of increasing software reusability. One software reuse approach is to develop a Software Product-line (SPL), which is a reconfigurable software architecture that can be reused across projects. Creating configurations of the SPL that meets arbitrary requirements is hard.Existing research has focused on techniques that produce a configuration of the SPL in a single step. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these CSP configuration problem CSPs can be derived automatically with a constraint solver. Third, we present empirical results demonstrating that our CSP-based technique can solve multi-step configuration problems involving hundreds of features in seconds.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {11–20},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2019136.2019139,
author = {Passos, Leonardo and Novakovic, Marko and Xiong, Yingfei and Berger, Thorsten and Czarnecki, Krzysztof and W\k{a}sowski, Andrzej},
title = {A study of non-Boolean constraints in variability models of an embedded operating system},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019139},
doi = {10.1145/2019136.2019139},
abstract = {Many variability modeling tasks can be supported by automated analyses of models. Unfortunately, most analyses for Boolean variability models are NP-hard, while analyses for non-Boolean models easily become undecidable. It is thus crucial to exploit the properties of realistic models to construct viable analysis algorithms. Unfortunately, little work exists about non-Boolean models, and no benchmarks are available for such.We present the non-Boolean aspects of 116 variability models available in the codebase of eCos---a real time embedded operating system. We characterize the types of non-Boolean features in the models, kinds and quantities of non-Boolean constraints in use, and the impact of these characteristics on the hardness of this model from analysis perspective. This way we provide researchers and practitioners with a basis for discussion of relevance of non-Boolean models and their analyses, along with the first ever benchmark for effectiveness of such analyses.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {2},
numpages = {8},
keywords = {automated model analysis, decision models, feature models, variability modeling},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/2364412.2364435,
author = {Saller, Karsten and Oster, Sebastian and Sch\"{u}rr, Andy and Schroeter, Julia and Lochau, Malte},
title = {Reducing feature models to improve runtime adaptivity on resource limited devices},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364435},
doi = {10.1145/2364412.2364435},
abstract = {Mobile devices like smartphones are getting increasingly important in our daily lifes. They are used in various environments and have to dynamically adapt themselves accordingly in order to provide an optimal runtime behavior. Naturally, adapting to continuously changing environmental conditions is a challenging task because mobile devices are always limited in their resources and have to adapt in real-time. In this paper, we introduce an approach that enables resource limited devices to adapt to changing conditions using dynamic software product lines techniques. Therefore, feature models are reduced to a specific hardware context before installing the adaptive mobile application on the device. This reduces the amount of possible configurations that are compatible with the device and, thereby, minimizes the costs and the duration of an adaptation during runtime.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {135–142},
numpages = {8},
keywords = {adaptive systems, context-awareness, dynamic software product lines, feature models},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2499777.2500716,
author = {Saller, Karsten and Lochau, Malte and Reimund, Ingo},
title = {Context-aware DSPLs: model-based runtime adaptation for resource-constrained systems},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500716},
doi = {10.1145/2499777.2500716},
abstract = {Dynamic Software Product Lines (DSPLs) provide a promising approach for planning and applying runtime reconfiguration scenarios to adaptive software systems. However, applying DSPLs in the vital domain of highly context-aware systems, e.g., mobile devices, is obstructed by the inherently limited resources being insufficient to handle large, constrained (re-)configurations spaces. To tackle these drawbacks, we propose a novel model-based approach for designing DSPLs in a way that allows for a trade-off between precomputation of reconfiguration scenarios at development time and on-demand evolution at runtime. Therefore, we (1) enrich feature models with context information to reason about potential context changes, and (2) specify context-aware reconfiguration processes on the basis of a scalable transition system incorporating state space abstractions and incremental refinement at runtime. We illustrate our concepts by means of a smartphone case study and present an implementation and evaluation considering different trade-off metrics.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {106–113},
numpages = {8},
keywords = {DSPL, adaptive systems, contexts, feature models, state space reduction},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/2364412.2364441,
author = {Schroeter, Julia and Mucha, Peter and Muth, Marcel and Jugel, Kay and Lochau, Malte},
title = {Dynamic configuration management of cloud-based applications},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364441},
doi = {10.1145/2364412.2364441},
abstract = {Cloud-based applications are multi-tenant aware, whereas customers (i.e., tenants) share hardware and software resources. Offering highly configurable applications to thousands of tenants in a shared cloud environment demands for scalable configuration management. Based on an example scenario taken from the Indenica project, we identify requirements for applying methods from software product line (SPL) engineering to configure cloud-based multi-tenant aware applications. Using an extended feature model (EFM) to express variability of functionality and service qualities, we propose a concept for dynamic configuration management to address the identified requirements. Our proposed configuration management includes an adaptive staged configuration process that is capable of adding and removing stakeholders dynamically and that allows for reconfiguration of variants as stakeholders' objectives change.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {171–178},
numpages = {8},
keywords = {cloud computing, extended feature model, multi-tenancy, software, software configuration management, software engineering, staged configuration},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.5555/1753235.1753267,
author = {Mendonca, Marcilio and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof},
title = {SAT-based analysis of feature models is easy},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Feature models are a popular variability modeling notation used in product line engineering. Automated analyses of feature models, such as consistency checking and interactive or offline product selection, often rely on translating models to propositional logic and using satisfiability (SAT) solvers.Efficiency of individual satisfiability-based analyses has been reported previously. We generalize and quantify these studies with a series of independent experiments. We show that previously reported efficiency is not incidental. Unlike with the general SAT instances, which fall into easy and hard classes, the instances induced by feature modeling are easy throughout the spectrum of realistic models. In particular, the phenomenon of phase transition is not observed for realistic feature models.Our main practical conclusion is a general encouragement for researchers to continued development of SAT-based methods to further exploit this efficiency in future.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {231–240},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3180155.3180159,
author = {Krieter, Sebastian and Th\"{u}m, Thomas and Schulze, Sandro and Schr\"{o}ter, Reimar and Saake, Gunter},
title = {Propagating configuration decisions with modal implication graphs},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180159},
doi = {10.1145/3180155.3180159},
abstract = {Highly-configurable systems encompass thousands of interdependent configuration options, which require a non-trivial configuration process. Decision propagation enables a backtracking-free configuration process by computing values implied by user decisions. However, employing decision propagation for large-scale systems is a time-consuming task and, thus, can be a bottleneck in interactive configuration processes and analyses alike. We propose modal implication graphs to improve the performance of decision propagation by precomputing intermediate values used in the process. Our evaluation results show a significant improvement over state-of-the-art algorithms for 120 real-world systems.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {898–909},
numpages = {12},
keywords = {configuration, decision propagation, software product line},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.jss.2018.07.054,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Juliana, Alves Pereira and Castro, Harold and Saake, Gunter},
title = {A systematic literature review on the semi-automatic configuration of extended product lines},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.07.054},
doi = {10.1016/j.jss.2018.07.054},
journal = {J. Syst. Softw.},
month = oct,
pages = {511–532},
numpages = {22},
keywords = {Extended product line, Product configuration, Systematic literature review}
}

@inproceedings{10.5555/1885639.1885643,
author = {Lee, Kwanwoo and Kang, Kyo C.},
title = {Usage context as key driver for feature selection},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product derivation in software product line engineering starts with selection of variable features manifested in a feature model. Selection of variable features for a particular product, however, is not made arbitrarily. There are various factors affecting feature selection. We experienced that the usage context of a product is often the primary driver for feature selection. In this paper, we propose a model showing how product usage contexts are related to product features, and present a method for developing such a model during the domain engineering process and utilizing it to derive an optimal product configuration during the application engineering process. An elevator control software example is used to illustrate and validate the concept and the method.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {32–46},
numpages = {15},
keywords = {commonality and variability, feature modeling, product derivation, product usage contexts},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.1007/s10664-020-09853-4,
author = {Hajri, Ines and Goknil, Arda and Pastore, Fabrizio and Briand, Lionel C.},
title = {Automating system test case classification and prioritization for use case-driven testing in product lines},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09853-4},
doi = {10.1007/s10664-020-09853-4},
abstract = {Product Line Engineering (PLE) is a crucial practice in many software development environments where software systems are complex and developed for multiple customers with varying needs. At the same time, many development processes are use case-driven and this strongly influences their requirements engineering and system testing practices. In this paper, we propose, apply, and assess an automated system test case classification and prioritization approach specifically targeting system testing in the context of use case-driven development of product families. Our approach provides: (i) automated support to classify, for a new product in a product family, relevant and valid system test cases associated with previous products, and (ii) automated prioritization of system test cases using multiple risk factors such as fault-proneness of requirements and requirements volatility in a product family. Our evaluation was performed in the context of an industrial product family in the automotive domain. Results provide empirical evidence that we propose a practical and beneficial way to classify and prioritize system test cases for industrial product lines.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3711–3769},
numpages = {59},
keywords = {Product Line Engineering, Use case driven development, Regression testing, Test case selection and prioritization, Automotive, Requirements engineering}
}

@article{10.1016/j.jss.2019.110422,
author = {Edded, Sabrine and Sassi, Sihem Ben and Mazo, Ra\'{u}l and Salinesi, Camille and Ghezala, Henda Ben},
title = {Collaborative configuration approaches in software product lines engineering: A systematic mapping study},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110422},
doi = {10.1016/j.jss.2019.110422},
journal = {J. Syst. Softw.},
month = dec,
numpages = {17},
keywords = {Product lines, Collaborative configuration, Systematic mapping study, Framework}
}

@article{10.1007/s10664-014-9359-z,
author = {Myll\"{a}rniemi, Varvana and Savolainen, Juha and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi},
title = {Performance variability in software product lines: proposing theories from a case study},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9359-z},
doi = {10.1007/s10664-014-9359-z},
abstract = {In the software product line research, product variants typically differ by their functionality and quality attributes are not purposefully varied. The goal is to study purposeful performance variability in software product lines, in particular, the motivation to vary performance, and the strategy for realizing performance variability in the product line architecture. The research method was a theory-building case study that was augmented with a systematic literature review. The case was a mobile network base station product line with capacity variability. The data collection, analysis and theorizing were conducted in several stages: the initial case study results were augmented with accounts from the literature. We constructed three theoretical models to explain and characterize performance variability in software product lines: the models aim to be generalizable beyond the single case. The results describe capacity variability in a base station product line. Thereafter, theoretical models of performance variability in software product lines in general are proposed. Performance variability is motivated by customer needs and characteristics, by trade-offs and by varying operating environment constraints. Performance variability can be realized by hardware or software means; moreover, the software can either realize performance differences in an emergent way through impacts from other variability or by utilizing purposeful varying design tactics. The results point out two differences compared with the prevailing literature. Firstly, when the customer needs and characteristics enable price differentiation, performance may be varied even with no trade-offs or production cost differences involved. Secondly, due to the dominance of feature modeling, the literature focuses on the impact management realization. However, performance variability can be realized through purposeful design tactics to downgrade the available software resources and by having more efficient hardware.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1623–1669},
numpages = {47},
keywords = {Case study, Software architecture, Software product line, Variability}
}

@inproceedings{10.1007/978-3-642-25535-9_29,
author = {Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Asadi, Mohsen and Bagheri, Ebrahim and Bo\v{s}kovi\'{c}, Marko},
title = {A quality aggregation model for service-oriented software product lines based on variability and composition patterns},
year = {2011},
isbn = {9783642255342},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25535-9_29},
doi = {10.1007/978-3-642-25535-9_29},
abstract = {Quality evaluation is a challenging task in monolithic software systems. It is even more complex when it comes to Service-Oriented Software Product Lines (SOSPL), as it needs to analyze the attributes of a family of SOA systems. In SOSPL, variability can be planned and managed at the architectural level to develop a software product with the same set of functionalities but different degrees of non-functional quality attribute satisfaction. Therefore, architectural quality evaluation becomes crucial due to the fact that it allows for the examination of whether or not the final product satisfies and guarantees all the ranges of quality requirements within the envisioned scope. This paper addresses the open research problem of aggregating QoS attribute ranges with respect to architectural variability. Previous solutions for quality aggregation do not consider architectural variability for composite services. Our approach introduces variability patterns that can possibly occur at the architectural level of an SOSPL. We propose an aggregation model for QoS computation which takes both variability and composition patterns into account.},
booktitle = {Proceedings of the 9th International Conference on Service-Oriented Computing},
pages = {436–451},
numpages = {16},
keywords = {QoS aggregation, feature modeling, non-functional properties, process family, service variability, service-oriented architecture (SOA), software product line (SPL), variability management},
location = {Paphos, Cyprus},
series = {ICSOC'11}
}

@article{10.1145/3088440,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {Teaching Software Product Lines: A Snapshot of Current Practices and Challenges},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
url = {https://doi.org/10.1145/3088440},
doi = {10.1145/3088440},
abstract = {Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving, as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, and what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. In this article, we report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, that is, an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {31},
keywords = {Software product lines, software engineering teaching, software product line teaching, variability modeling}
}

@article{10.1007/s10270-016-0539-8,
author = {Hajri, Ines and Goknil, Arda and Briand, Lionel C. and Stephany, Thierry},
title = {Configuring use case models in product families},
year = {2018},
issue_date = {July      2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-016-0539-8},
doi = {10.1007/s10270-016-0539-8},
abstract = {In many domains such as automotive and avionics, the size and complexity of software systems is quickly increasing. At the same time, many stakeholders tend to be involved in the development of such systems, which typically must also be configured for multiple customers with varying needs. Product Line Engineering (PLE) is therefore an inevitable practice for such systems. Furthermore, because in many areas requirements must be explicit and traceability to them is required by standards, use cases and domain models are common practice for requirements elicitation and analysis. In this paper, based on the above observations, we aim at supporting PLE in the context of use case-centric development. Therefore, we propose, apply, and assess a use case-driven configuration approach which interactively receives configuration decisions from the analysts to generate product-specific (PS) use case and domain models. Our approach provides the following: (1) a use case-centric product line modeling method (PUM), (2) automated, interactive configuration support based on PUM, and (3) an automatic generation of PS use case and domain models from Product Line (PL) models and configuration decisions. The approach is supported by a tool relying on Natural Language Processing (NLP) and integrated with an industrial requirements management tool, i.e., IBM DOORS. We successfully applied and evaluated our approach to an industrial case study in the automotive domain, thus showing evidence that the approach is practical and beneficial to capture variability at the appropriate level of granularity and to configure PS use case and domain models in industrial settings.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {939–971},
numpages = {33},
keywords = {Configuration, Consistency checking, Natural language processing, Product line engineering, Use case-driven development}
}

@inproceedings{10.1145/2425415.2425420,
author = {Eyal-Salman, Hamzeh and Seriai, Abdelhak-Djamel and Dony, Christophe and Al-msie'deen, Ra'fat},
title = {Recovering traceability links between feature models and source code of product variants},
year = {2012},
isbn = {9781450318099},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2425415.2425420},
doi = {10.1145/2425415.2425420},
abstract = {Usually software product variants, developed by clone-and-own approach, form often a starting point for building Software Product Line (SPL). To migrate software products that deemed similar into a product line, it is essential to trace variability among software artifacts because the distinguishing factor between traditional software engineering and software product line engineering is the variability. Variability tracing is used to support conversion from traditional software development into software product line development and automate products derivation process such that core assets can be automatically configured for a product according to the features selection from the feature model. Tracing and maintaining interrelationships between artifacts within a software system also are needed to facilitate program comprehension, make the process of maintaining the system less dependent on individual experts. This paper presents a method based on information retrieval approach namely, latent semantic indexing, to establish traceability links between object-oriented source code of product variants and their feature model as representative of variability model.},
booktitle = {Proceedings of the VARiability for You Workshop: Variability Modeling Made Useful for Everyone},
pages = {21–25},
numpages = {5},
keywords = {feature models, latent semantic indexing, software product line, source code, traceability links, variability},
location = {Innsbruck, Austria},
series = {VARY '12}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00123,
author = {Le, Viet-Man},
title = {Group recommendation techniques for feature modeling and configuration},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00123},
doi = {10.1109/ICSE-Companion52605.2021.00123},
abstract = {In large-scale feature models, feature modeling and configuration processes are highly expected to be done by a group of stakeholders. In this context, recommendation techniques can increase the efficiency of feature-model design and find optimal configurations for groups of stakeholders. Existing studies show plenty of issues concerning feature model navigation support, group members' satisfaction, and conflict resolution. This study proposes group recommendation techniques for feature modeling and configuration on the basis of addressing the mentioned issues.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {266–268},
numpages = {3},
keywords = {configuration, feature models, group decision making, group-based recommendation, software product line},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1007/s10664-020-09911-x,
author = {Ramos-Guti\'{e}rrez, Bel\'{e}n and Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Discovering configuration workflows from existing logs using process mining},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09911-x},
doi = {10.1007/s10664-020-09911-x},
abstract = {Variability models are used to build configurators, for guiding users through the configuration process to reach the desired setting that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the design options that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suits stakeholders according to previous configurations. For example, when configuring a Linux distribution the configuration process starts by choosing the network or the graphic card and then, other packages concerning a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), a framework that can automatically assist determining the configuration workflow that better fits the configuration logs generated by user activities given a set of logs of previous configurations and a variability model. COLOSSI is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Derived from the possible complexity of both logs and the discovered processes, often, it is necessary to divide the traces into small ones. This provides an easier configuration workflow to be understood and followed by the user during the configuration process. In this paper, we apply and compare four different techniques for the traces clustering: greedy, backtracking, genetic and hierarchical algorithms. Our proposal is validated in three different scenarios, to show its feasibility, an ERP configuration, a Smart Farming, and a Computer Configuration. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering along with the necessity to apply clustering techniques for the trace preparation in the context of configuration workflows.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {41},
keywords = {Variability, Configuration workflow, Process mining, Process discovery, Clustering}
}

@inproceedings{10.5555/1753235.1753245,
author = {Cetina, Carlos and Haugen, \O{}ystein and Zhang, Xiaorui and Fleurey, Franck and Pelechano, Vicente},
title = {Strategies for variability transformation at run-time},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {More and more approaches propose to use Software Product Lines (SPLs) modelling techniques to implement dynamic adaptive systems. The resulting Dynamic Software Product Lines (DSPLs) present new challenges since the variability transformations used to derive alternative configurations have to be intensively used at runtime. This paper proposes to use the Common Variability Language (CVL) for modelling runtime variability and evaluates a set of alternative strategies for implementing the associated variability transformations. All the proposed strategies have been implemented and evaluated on the case-study of a smart-home system. Results show that the proposed strategies provide the same reconfiguration service with significant differences in quality-of-service.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {61–70},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1109/SPLINE.2007.31,
author = {Loesch, Felix and Ploedereder, Erhard},
title = {Optimization of Variability in Software Product Lines},
year = {2007},
isbn = {0769528880},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLINE.2007.31},
doi = {10.1109/SPLINE.2007.31},
abstract = {The widespread use of the product line approach allows companies to realize significant improvements in time-tomarket, cost, productivity, and quality. However, a fundamental problem in software product line engineering is that a product line of industrial size can easily incorporate several thousand variable features. The complexity caused by this amount of variability makes variability management and product derivation tasks extremely difficult. To address this problem, we present a new method to optimize the variability provided in a software product line. Our method constructs a visualization that provides a classification of the usage of variable features in real products derived from the product line. We show how this classification can be used to derive restructuring strategies for simplifying the variability. The effectiveness of our work is demonstrated by presenting a case study of optimizing the variability in a large industrial software product line.},
booktitle = {Proceedings of the 11th International Software Product Line Conference},
pages = {151–162},
numpages = {12},
series = {SPLC '07}
}

@article{10.1007/s10009-012-0252-z,
author = {Pleuss, Andreas and Botterweck, Goetz},
title = {Visualization of variability and configuration options},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0252-z},
doi = {10.1007/s10009-012-0252-z},
abstract = {When designing, constructing, and maintaining diverse and variable software systems, a key challenge is the complexity of systems. A potential approach to tackle this challenge are techniques from variability management and product line engineering to handle the diversity and variability. A key asset in variability management is a variability model, which explicitly specifies the commonalities and variability of a system and the constraints between variants. However, handling variability and configurations remains a challenge due to the complexity on a cognitive level as human engineers reach their limits in identifying, understanding, and using all relevant details. In this paper we address this issue by providing concepts for interactive visual tool support for the configuration of systems with the help of feature models. We discuss relevant principles from the area of information visualization and their application to the domain of feature model configuration. We discuss techniques for interactive configuration support based on a reasoning engine, which, e.g., ensures the validity of configurations. We illustrate our findings by a concrete tool solution called S2T2 Configurator.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {497–510},
numpages = {14},
keywords = {Feature model, Interactive tool, Product configuration, Software product line, Variability, Visualization}
}

@article{10.1016/j.cl.2016.09.004,
author = {M\'{e}ndez-Acu\~{n}a, David and Galindo, Jos\'{e} A. and Degueule, Thomas and Combemale, Beno\^{\i}t and Baudry, Beno\^{\i}t},
title = {Leveraging Software Product Lines Engineering in the development of external DSLs},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2016.09.004},
doi = {10.1016/j.cl.2016.09.004},
abstract = {The use of domain-specific languages (DSLs) has become a successful technique in the development of complex systems. Consequently, nowadays we can find a large variety of DSLs for diverse purposes. However, not all these DSLs are completely different; many of them share certain commonalities coming from similar modeling patterns - such as state machines or petri nets - used for several purposes. In this scenario, the challenge for language designers is to take advantage of the commonalities existing among similar DSLs by reusing, as much as possible, formerly defined language constructs. The objective is to leverage previous engineering efforts to minimize implementation from scratch. To this end, recent research in software language engineering proposes the use of product line engineering, thus introducing the notion of language product lines. Nowadays, there are several approaches that result useful in the construction of language product lines. In this article, we report on an effort for organizing the literature on language product line engineering. More precisely, we propose a definition for the life-cycle of language product lines, and we use it to analyze the capabilities of current approaches. In addition, we provide a mapping between each approach and the technological space it supports. HighlightsSurvey on the applicability of software product lines in the construction of DSLs.General life-cycle for language product lines.Mapping current approaches on language product lines and technological spaces.Research map in language product lines engineering.},
journal = {Comput. Lang. Syst. Struct.},
month = nov,
pages = {206–235},
numpages = {30},
keywords = {Domain-specific languages, Software Product Lines Engineering, Software language engineering, Variability management}
}

@article{10.1145/2501654.2501665,
author = {Hubaux, Arnaud and Tun, Thein Than and Heymans, Patrick},
title = {Separation of concerns in feature diagram languages: A systematic survey},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501665},
doi = {10.1145/2501654.2501665},
abstract = {The need for flexible customization of large feature-rich software systems, according to requirements of various stakeholders, has become an important problem in software development. Among the many software engineering approaches dealing with variability management, the notion of Software Product Line (SPL) has emerged as a major unifying concept. Drawing from established disciplines of manufacturing, SPL approaches aim to design repertoires of software artifacts, from which customized software systems for specific stakeholder requirements can be developed. A major difficulty SPL approaches attempt to address is the modularization of software artifacts, which reconciles the user's needs for certain features and the development and technical constraints. Towards this end, many SPL approaches use feature diagrams to describe possible configurations of a feature set. There have been several proposals for feature diagram languages with varying degrees of expressiveness, intuitiveness, and precision. However, these feature diagram languages have limited scalability when applied to realistic software systems. This article provides a systematic survey of various concerns of feature diagrams and ways in which concerns have been separated. The survey shows how the uncertainty in the purpose of feature diagram languages creates both conceptual and practical limitations to scalability of those languages.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {51},
numpages = {23},
keywords = {Software product line, feature diagram, separation of concerns, variability}
}

@article{10.1016/j.infsof.2012.02.002,
author = {Holl, Gerald and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {A systematic review and an expert survey on capabilities supporting multi product lines},
year = {2012},
issue_date = {August, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.02.002},
doi = {10.1016/j.infsof.2012.02.002},
abstract = {Context: Complex software-intensive systems comprise many subsystems that are often based on heterogeneous technological platforms and managed by different organizational units. Multi product lines (MPLs) are an emerging area of research addressing variability management for such large-scale or ultra-large-scale systems. Despite the increasing number of publications addressing MPLs the research area is still quite fragmented. Objective: The aims of this paper are thus to identify, describe, and classify existing approaches supporting MPLs and to increase the understanding of the underlying research issues. Furthermore, the paper aims at defining success-critical capabilities of infrastructures supporting MPLs. Method: Using a systematic literature review we identify and analyze existing approaches and research issues regarding MPLs. Approaches described in the literature support capabilities needed to define and operate MPLs. We derive capabilities supporting MPLs from the results of the systematic literature review. We validate and refine these capabilities based on a survey among experts from academia and industry. Results: The paper discusses key research issues in MPLs and presents basic and advanced capabilities supporting MPLs. We also show examples from research approaches that demonstrate how these capabilities can be realized. Conclusions: We conclude that approaches supporting MPLs need to consider both technical aspects like structuring large models and defining dependencies between product lines as well as organizational aspects such as distributed modeling and product derivation by multiple stakeholders. The identified capabilities can help to build, enhance, and evaluate MPL approaches.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {828–852},
numpages = {25},
keywords = {Large-scale systems, Multi product lines, Product line engineering, Systematic literature review}
}

@article{10.1016/j.infsof.2015.12.004,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat and Zhang, Li},
title = {Model-based incremental conformance checking to enable interactive product configuration},
year = {2016},
issue_date = {April 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {72},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.12.004},
doi = {10.1016/j.infsof.2015.12.004},
abstract = {ContextModel-based product line engineering (PLE) is a paradigm that can enable automated product configuration of large-scale software systems, in which models are used as an abstract specification of commonalities and variabilities of products of a product line. ObjectiveIn the context of PLE, providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. MethodIn an existing work, a UML-based variability modeling methodology named as SimPL and an interactive configuration process was proposed. Based on the existing work, we propose an automated, incremental and efficient conformance checking approach to ensure that the manual configuration of a variation point conforms to a set of pre-defined conformance rules specified in the Object Constraint Language (OCL). The proposed approach, named as Zen-CC, has been implemented as an integrated part of our product configuration and derivation tool: Zen-Configurator. ResultsThe performance and scalability of Zen-CC have been evaluated with a real-world case study. Results show that Zen-CC significantly outperformed two baseline engines in terms of performance. Besides, the performance of Zen-CC remains stable during the configuration of all the 10 products of the product line and its efficiency also remains un-impacted even with the growing product complexity, which is not the case for both of the baseline engines. ConclusionThe results suggest that Zen-CC performs practically well and is much more scalable than the two baseline engines and is scalable for configuring products with a larger number of variation points.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {68–89},
numpages = {22},
keywords = {Incremental conformance checking, Interactive product configuration, Model based engineering, Product line engineering, Variation point}
}

@inproceedings{10.1145/2364412.2364442,
author = {Cavalcante, Everton and Almeida, Andr\'{e} and Batista, Thais and Cacho, N\'{e}lio and Lopes, Frederico and Delicato, Flavia C. and Sena, Thiago and Pires, Paulo F.},
title = {Exploiting software product lines to develop cloud computing applications},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364442},
doi = {10.1145/2364412.2364442},
abstract = {With the advance of the Cloud Computing paradigm, new challenges in terms of models, tools, and techniques to support developers to design, build and deploy complex software systems that make full use of the cloud technology arise. In the heterogeneous scenario of this new paradigm, the development of applications using cloud services becomes hard, and the software product lines (SPL) approach is potentially promising for this context since specificities of the cloud platforms, such as services heterogeneity, pricing model, and other aspects can be catered as variabilities to core features. In this perspective, this paper (i) proposes a seamless adaptation of the SPL-based development to include important features of cloud-based applications, and (ii) reports the experience of developing HW-CSPL, a SPL for the Health Watcher (HW) System, which allows citizens to register complaints and consult information regarding the public health system of a city. Several functionalities of this system were implemented using different Cloud Computing platforms, and run time specificities of this application deployed on the cloud were analyzed, as well as other information such as change impact and pricing.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {179–187},
numpages = {9},
keywords = {cloud computing, cloud platforms, health watcher system, services, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2677758.2677773,
author = {Tan, Lei and Bille, Ross and Lin, Yuqing and Chalup, Stephan and Tucker, Chris},
title = {Software Development in the City Evolutions Project},
year = {2014},
isbn = {9781450327909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677758.2677773},
doi = {10.1145/2677758.2677773},
abstract = {The goal of the City Evolutions Project is to establish interactive systems and games to entertain users. Because of the existing variabilities in the system and potential reuse for similar systems in this domain, the software system is designed and developed in a reuse-based way, i.e. Software Product Line Engineering (SPLE). SPLE is a reuse-based software approach with reusable software assets in order to maximise software reuse. In SPLE, it is very important to maintain the requirement traceability from software family establishment to individual product derivation. In this paper, we describe our experience of applying SPLE approach in the City Evolutions project and propose an approach to enhance the requirements traceability in SPLE.},
booktitle = {Proceedings of the 2014 Conference on Interactive Entertainment},
pages = {1–7},
numpages = {7},
location = {Newcastle, NSW, Australia},
series = {IE2014}
}

@article{10.1016/j.jksuci.2016.01.005,
author = {Ma\^{a}zoun, Jihen and Bouassida, Nadia and Ben-Abdallah, Han\^{e}ne},
title = {Change impact analysis for software product lines},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {28},
number = {4},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2016.01.005},
doi = {10.1016/j.jksuci.2016.01.005},
abstract = {A software product line (SPL) represents a family of products in a given application domain. Each SPL is constructed to provide for the derivation of new products by covering a wide range of features in its domain. Nevertheless, over time, some domain features may become obsolete with the apparition of new features while others may become refined. Accordingly, the SPL must be maintained to account for the domain evolution. Such evolution requires a means for managing the impact of changes on the SPL models, including the feature model and design. This paper presents an automated method that analyzes feature model evolution, traces their impact on the SPL design, and offers a set of recommendations to ensure the consistency of both models. The proposed method defines a set of new metrics adapted to SPL evolution to identify the effort needed to maintain the SPL models consistently and with a quality as good as the original models. The method and its tool are illustrated through an example of an SPL in the Text Editing domain. In addition, they are experimentally evaluated in terms of both the quality of the maintained SPL models and the precision of the impact change management.},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = oct,
pages = {364–380},
numpages = {17},
keywords = {Change impact management, Feature model, Model evolution, Software product line}
}

@inproceedings{10.1109/ISSRE.2014.13,
author = {Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming and Zhang, Li},
title = {Zen-CC: An Automated and Incremental Conformance Checking Solution to Support Interactive Product Configuration},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.13},
doi = {10.1109/ISSRE.2014.13},
abstract = {In the context of product line engineering (PLE), providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. Model-based PLE has brought opportunities to enable automated product configuration and derivation for large-scale systems/software, in which models are used as the abstract specification of commonalities and variabilities of products of a product line. In our previous work, we have proposed a UML-based variability modeling methodology and an interactive configuration process. Based on these work, in this paper, we propose an automated and incremental conformance checking approach to ensure that the manual configuration to each variation point conforms to a set of pre-defined conformance rules specified in OCL. The proposed approach, called Zen-CC is implemented as a component of our product configuration and derivation tool, named as Zen-Configurator. The proposed approach is evaluated with two real-world case studies and results showed that the performance of Zen-CC is significantly better than a baseline algorithm checking all the conformance rules at each configuration step. Moreover, the performance of Zen-CC rarely varies during the configuration process, suggesting that our approach is scalable for configuring products with a large number of configuration points.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {13–22},
numpages = {10},
keywords = {Conformance Checking, Product Configuration, Product Line Engineering, Variation Point},
series = {ISSRE '14}
}

@article{10.1016/j.jss.2018.02.021,
author = {Hajri, Ines and Goknil, Arda and Briand, Lionel C. and Stephany, Thierry},
title = {Change impact analysis for evolving configuration decisions in product line use case models},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {139},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.02.021},
doi = {10.1016/j.jss.2018.02.021},
journal = {J. Syst. Softw.},
month = may,
pages = {211–237},
numpages = {27},
keywords = {Change impact analysis, Product line engineering, Use case driven development, Use case configurator, Evolving decisions, Incremental reconfiguration}
}

@inproceedings{10.5555/1753235.1753237,
author = {Arboleda, Hugo and Casallas, Rubby and Royer, Jean-Claude},
title = {Dealing with fine-grained configurations in model-driven SPLs},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {In Model-Driven SPL approaches, the derivation of a product starts from a domain application model. This model is transformed using model transformations, which are selected according to variants included in configurations, until a product is obtained. There are at least two drawbacks to these approaches. First, the selection of variants affects the whole domain application model, impeding fine-grained configurations, i.e. configurations at the level of each element in the model, and second, model transformations are coupled with variants which make their maintenance and adaptation difficult. We present an approach that uses meta-modeling and feature modeling. A novelty in our approach is the possibility of configuring a product from a domain application model in which elements can be bound separately to features. These fine-grained configurations are an input to the derivation process which uses decision models and Aspect-Oriented Programming, facilitating the reuse, adaptation and composition of model transformations.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {1–10},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/2771783.2771808,
author = {Tan, Tian Huat and Xue, Yinxing and Chen, Manman and Sun, Jun and Liu, Yang and Dong, Jin Song},
title = {Optimizing selection of competing features via feedback-directed evolutionary algorithms},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771808},
doi = {10.1145/2771783.2771808},
abstract = {Software that support various groups of customers usually require complicated configurations to attain different functionalities. To model the configuration options, feature model is proposed to capture the commonalities and competing variabilities of the product variants in software family or Software Product Line (SPL). A key challenge for deriving a new product is to find a set of features that do not have inconsistencies or conflicts, yet optimize multiple objectives (e.g., minimizing cost and maximizing number of features), which are often competing with each other. Existing works have attempted to make use of evolutionary algorithms (EAs) to address this problem. In this work, we incorporated a novel feedback-directed mechanism into existing EAs. Our empirical results have shown that our method has improved noticeably over all unguided version of EAs on the optimal feature selection. In particular, for case studies in SPLOT and LVAT repositories, the feedback-directed Indicator-Based EA (IBEA) has increased the number of correct solutions found by 72.33% and 75%, compared to unguided IBEA. In addition, by leveraging a pre-computed solution, we have found 34 sound solutions for Linux X86, which contains 6888 features, in less than 40 seconds.},
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {246–256},
numpages = {11},
keywords = {SAT solvers, Software product line, evolutionary algorithms},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@inproceedings{10.1145/2110147.2110157,
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
title = {Managing SAT inconsistencies with HUMUS},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110157},
doi = {10.1145/2110147.2110157},
abstract = {In Product Line Engineering, as in any other modeling domain, designers and end users are prone to making inconsistent assumptions (errors) because of complexity and lack of system knowledge. We previously envisioned a way of allowing inconsistencies during product configuration and in this paper we present a solution on how to realize this vision. We introduce HUMUS (High-level Union of Minimal Unsatisfiable Sets), which enables correct reasoning in product line engineering (encoded in SAT) despite the presence of errors. We focus mainly on tolerating inconsistencies during product configuration, to make it possible to resolve inconsistencies later without misguiding the human user along the way. We also provide a discussion of other applications in product line engineering and beyond. The main advantage of using HUMUS is, that it is possible to isolate erroneous parts of a product line model such that existing automations continue to be useful. The applications of HUMUS are thus likely beyond product line engineering.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {83–91},
numpages = {9},
keywords = {formal reasoning, product line engineering, user guidance},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@inproceedings{10.1145/2499777.2500722,
author = {ter Beek, Maurice H. and Lafuente, Alberto Lluch and Petrocchi, Marinella},
title = {Combining declarative and procedural views in the specification and analysis of product families},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2500722},
doi = {10.1145/2499777.2500722},
abstract = {We introduce the feature-oriented language FLan as a proof of concept for specifying both declarative aspects of product families, namely constraints on their features, and procedural aspects, namely feature configuration and run-time behaviour. FLan is inspired by the concurrent constraint programming paradigm. A store of constraints allows one to specify in a declarative way all common constraints on features, including inter-feature constraints. A standard yet rich set of process-algebraic operators allows one to specify in a procedural way the configuration and behaviour of products. There is a close interaction between both views: (i) the execution of a process is constrained by its store to forbid undesired configurations; (ii) a process can query a store to resolve design and behavioural choices; (iii) a process can update the store by adding new features. An implementation in the Maude framework allows for a variety of formal automated analyses of product families specified in FLan, ranging from consistency checking to model checking.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {10–17},
numpages = {8},
keywords = {Maude, behavioural analyses, concurrent constraint programming, process algebra, product families, variability},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@article{10.1007/s11219-013-9197-z,
author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
title = {Quality attribute modeling and quality aware product configuration in software product lines},
year = {2014},
issue_date = {September 2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-013-9197-z},
doi = {10.1007/s11219-013-9197-z},
abstract = {In software product line engineering, the customers mostly concentrate on the functionalities of the target product during product configuration. The quality attributes of a target product, such as security and performance, are often assessed until the final product is generated. However, it might be very costly to fix the problem if it is found that the generated product cannot satisfy the customers' quality requirements. Although the quality of a generated product will be affected by all the life cycles of product development, feature-based product configuration is the first stage where the estimation or prediction of the quality attributes should be considered. As we know, the key issue of predicting the quality attributes for a product configured from feature models is to measure the interdependencies between functional features and quality attributes. The current existing approaches have several limitations on this issue, such as requiring real products for the measurement or involving domain experts' efforts. To overcome these limitations, we propose a systematic approach of modeling quality attributes in feature models based on domain experts' judgments using the analytic hierarchical process (AHP) and conducting quality aware product configuration based on the captured quality knowledge. Domain experts' judgments are adapted to avoid generating the real products for quality evaluation, and AHP is used to reduce domain experts' efforts involved in the judgments. A prototype tool is developed to implement the concepts of the proposed approach, and a formal evaluation is carried out based on a large-scale case study.},
journal = {Software Quality Journal},
month = sep,
pages = {365–401},
numpages = {37},
keywords = {Analytic hierarchical process (AHP), Feature model, Non-functional requirement (NFR) framework, Product configuration, Quality attributes assessment, Software product line}
}

@inproceedings{10.1145/2814251.2814263,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Th\"{u}m, Thomas},
title = {Using decision rules for solving conflicts in extended feature models},
year = {2015},
isbn = {9781450336864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814251.2814263},
doi = {10.1145/2814251.2814263},
abstract = {Software Product Line Engineering has introduced feature modeling as a domain analysis technique used to represent the variability of software products and decision-making scenarios. We present a model-based transformation approach to solve conflicts among configurations performed by different stakeholders on feature models. We propose the usage of a domain-specific language named CoCo to specify attributes as non-functional properties of features, and to describe business-related decision rules in terms of costs, time, and human resources. These specifications along with the stakeholders' configurations and the feature model are transformed into a constraint programming problem, on which decision rules are executed to find a non-conflicting set of solution configurations that are aligned to business objectives. We evaluate CoCo's compositionality and model complexity simplification while using a set of motivating decision scenarios.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {149–160},
numpages = {12},
keywords = {Domain engineering, conflicting configurations, constraint satisfaction problem, domain-specific language, extended feature model, model transformation chain},
location = {Pittsburgh, PA, USA},
series = {SLE 2015}
}

@article{10.4018/jismd.2012100101,
author = {Asadi, Mohsen and Mohabbati, Bardia and Ga\v{s}evic, Dragan and Bagheri, Ebrahim and Hatala, Marek},
title = {Developing Semantically-Enabled Families of Method-Oriented Architectures},
year = {2012},
issue_date = {October 2012},
publisher = {IGI Global},
address = {USA},
volume = {3},
number = {4},
issn = {1947-8186},
url = {https://doi.org/10.4018/jismd.2012100101},
doi = {10.4018/jismd.2012100101},
abstract = {Method Engineering ME aims to improve software development methods by creating and proposing adaptation frameworks whereby methods are created to provide suitable matches with the requirements of the organization and address project concerns and fit specific situations. Therefore, methods are defined and modularized into components stored in method repositories. The assembly of appropriate methods depends on the particularities of each project, and rapid method construction is inevitable in the reuse and management of existing methods. The ME discipline aims at providing engineering capability for optimizing, reusing, and ensuring flexibility and adaptability of methods; there are three key research challenges which can be observed in the literature: 1 the lack of standards and tooling support for defining, publishing, discovering, and retrieving methods which are only locally used by their providers without been largely adapted by other organizations; 2 dynamic adaptation and assembly of methods with respect to imposed continuous changes or evolutions of the project lifecycle; and 3 variability management in software methods in order to enable rapid and effective construction, assembly and adaptation of existing methods with respect to particular situations. The authors propose semantically-enabled families of method-oriented architecture by applying service-oriented product line engineering principles and employing Semantic Web technologies.},
journal = {Int. J. Inf. Syst. Model. Des.},
month = oct,
pages = {1–26},
numpages = {26},
keywords = {Method Engineering, Method Oriented Architecture MOA, Semantic Web, Software Development, Software Product Line}
}

@inproceedings{10.1145/2648511.2648514,
author = {Seidl, Christoph and Schaefer, Ina and A\ss{}mann, Uwe},
title = {Integrated management of variability in space and time in software families},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648514},
doi = {10.1145/2648511.2648514},
abstract = {Software product lines (SPLs) and software ecosystems (SECOs) encompass a family of closely related software systems in terms of common and variable assets that are configured to concrete products (variability in space). Over the course of time, variable assets of SPLs and especially SECOs are subject to change in order to meet new requirements as part of software evolution (variability in time). Even though both dimensions of variability have to be handled simultaneously, e.g., as not all customers upgrade their respective products immediately or completely, there currently is no approach that can create variants with a selection of variable assets in various versions. In this paper, we introduce an integrated approach to manage variability in space and time in software families using Hyper Feature Models (HFMs) with feature versions and combine them with an extension of the transformational variability realization mechanism delta modeling. This allows derivation of concrete software systems from an SPL or SECO configuring both functionality (features) as well as versions.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {22–31},
numpages = {10},
keywords = {delta modeling, evolution, hyper feature models (HFMs), software ecosystems, software product lines, variability},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/1409720.1409748,
author = {Nestor, Daren and Thiel, Steffen and Botterweck, Goetz and Cawley, Ciar\'{a}n and Healy, Patrick},
title = {Applying visualisation techniques in software product lines},
year = {2008},
isbn = {9781605581125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1409720.1409748},
doi = {10.1145/1409720.1409748},
abstract = {Software product lines of industrial size can easily incorporate thousands of variation points. This scale of variability can become extremely complex to manage resulting in a product development process that bears significant costs. One technique that can be applied beneficially in this context is visualisation. Visualisation is widely used in software engineering and has proven useful to amplify human cognition in data intensive applications. Adopting this technique in software product line engineering can help stakeholders in supporting essential work tasks and in enhancing their understanding of large and complex product lines.The research presented in this paper describes an integrated meta-model and research tool that employs visualisation techniques to address significant software product line tasks such as variability management and product derivation. Examples of the tasks are described and the ways in which these tasks can be further supported by utilising visualisation techniques are explained.},
booktitle = {Proceedings of the 4th ACM Symposium on Software Visualization},
pages = {175–184},
numpages = {10},
keywords = {feature configuration, interaction, software product lines, visualisation},
location = {Ammersee, Germany},
series = {SoftVis '08}
}

@inproceedings{10.5555/2022115.2022123,
author = {Shen, Liwei and Peng, Xin and Liu, Jindu and Zhao, Wenyun},
title = {Towards feature-oriented variability reconfiguration in dynamic software product lines},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Dynamic Software Product Line (DSPL) provides a new paradigm for developing self-adaptive systems with the principles of software product line engineering. DSPL emphasizes variability analysis and design at development time and variability binding and reconfiguration at runtime, thus requires some kinds of variability mechanisms to map high-level variations (usually represented by features) to low-level implementation and support runtime reconfiguration. Existing work on DSPL usually assumes that variation features can be directly mapped to coarse-grained elements like services, components or plug-ins, making the methods hard to be applied for traditional software systems. In this paper, we propose a feature-oriented method to support runtime variability reconfiguration in DSPLs. The method introduces the concept of role model, an intermediate level between feature variations and implementations to improve their traceability. On the other hand, the method involves a reference implementation framework based on dynamic aspect mechanisms to implement the runtime reconfiguration. We illustrate the process of applying the proposed method with a concrete case study, which helps to validate the effectiveness of our method.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {52–68},
numpages = {17},
keywords = {dynamic AOP, dynamic software product line, reconfiguration, self-adaptation, variability binding},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@article{10.1016/j.jss.2019.04.026,
author = {Gacit\'{u}a, Ricardo and Sep\'{u}lveda, Samuel and Mazo, Ra\'{u}l},
title = {FM-CF: A framework for classifying feature model building approaches},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.04.026},
doi = {10.1016/j.jss.2019.04.026},
journal = {J. Syst. Softw.},
month = aug,
pages = {1–21},
numpages = {21},
keywords = {Feature model, Software product lines, Framework, Classification, Models}
}

@article{10.1007/s00766-015-0237-z,
author = {Oliinyk, Olesia and Petersen, Kai and Schoelzke, Manfred and Becker, Martin and Schneickert, Soeren},
title = {Structuring automotive product lines and feature models: an exploratory study at Opel},
year = {2017},
issue_date = {March     2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {1},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-015-0237-z},
doi = {10.1007/s00766-015-0237-z},
abstract = {Automotive systems are highly complex and customized systems containing a vast amount of variability. 
Feature modeling plays a key role in customization. Empirical evidence through industry application, and in particular methodological guidance of how to structure automotive product lines and their feature models is needed. The overall aim of this work is to provide guidance to practitioners how to structure automotive product lines and their feature models, understanding strengths and weaknesses of alternative structures. The research was conducted in three phases. In the first phase, the context situation was understood using interviews and workshops. In the second phase, possible structures of product lines and feature models were evaluated based on industry feedback collected in workshops. In the third phase, the structures were implemented in the tool GEARS and practitioner feedback was collected. One key challenge was the unavailability of structuring guidelines, which was the focus of this research. The structures considered most suitable for the automotive product line were multiple product lines with modular decomposition. The structures most suitable for the feature model were functional decomposition, using context variability, models corresponding to assets, and feature categories. Other structures have been discarded, and the rationales have been presented. It was possible to support the most suitable structures with the commercial tool GEARS. The implementation in GEARS and the feedback from the practitioners provide early indications for the potential usefulness of the structures and the tool implementation.},
journal = {Requir. Eng.},
month = mar,
pages = {105–135},
numpages = {31},
keywords = {Automotive, Case study, Empirical, Feature modeling, Product line engineering, Variability modeling}
}

@article{10.1016/j.infsof.2017.01.012,
author = {Reinhartz-Berger, Iris and Figl, Kathrin and Haugen, ystein},
title = {Investigating styles in variability modeling},
year = {2017},
issue_date = {July 2017},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {87},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.01.012},
doi = {10.1016/j.infsof.2017.01.012},
abstract = {ContextA common way to represent product lines is with variability modeling. Yet, there are different ways to extract and organize relevant characteristics of variability. Comprehensibility of these models and the ease of creating models are important for the efficiency of any variability management approach. ObjectiveThe goal of this paper is to investigate the comprehensibility of two common styles to organize variability into models hierarchical and constrained where the dependencies between choices are specified either through the hierarchy of the model or as cross-cutting constraints, respectively. MethodWe conducted a controlled experiment with a sample of 90 participants who were students with prior training in modeling. Each participant was provided with two variability models specified in Common Variability Language (CVL) and was asked to answer questions requiring interpretation of provided models. The models included 920 nodes and 819 edges and used the main variability elements. After answering the questions, the participants were asked to create a model based on a textual description. ResultsThe results indicate that the hierarchical modeling style was easier to comprehend from a subjective point of view, but there was also a significant interaction effect with the degree of dependency in the models, that influenced objective comprehension. With respect to model creation, we found that the use of a constrained modeling style resulted in higher correctness of variability models. ConclusionsPrior exposure to modeling style and the degree of dependency among elements in the model determine what modeling style a participant chose when creating the model from natural language descriptions. Participants tended to choose a hierarchical style for modeling situations with high dependency and a constrained style for situations with low dependency. Furthermore, the degree of dependency also influences the comprehension of the variability model.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {81–102},
numpages = {22},
keywords = {Cognitive aspects, Comprehensibility, Empirical research, Feature modeling, Hierarchical modeling, Product line engineering, Textual constraints, Variability modeling}
}

@article{10.1016/j.cageo.2014.09.004,
author = {Buccella, Agustina and Cechich, Alejandra and Pol'la, Matias and Arias, Maximiliano and del Socorro Doldan, Maria and Morsan, Enrique},
title = {Marine ecology service reuse through taxonomy-oriented SPL development},
year = {2014},
issue_date = {December 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {73},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2014.09.004},
doi = {10.1016/j.cageo.2014.09.004},
abstract = {Nowadays, reusing software applications encourages researchers and industrials to collaborate in order to increase software quality and to reduce software development costs. However, effective reuse is not easy and only a limited portion of reusable models actually offers effective evidence regarding their appropriateness, usability and/or effectiveness. Focusing reuse on a particular domain, such as marine ecology, allows us to narrow the scope; and along with a systematic approach such as software product line development, helps us to potentially improving reuse. From our experiences developing a subdomain-oriented software product line (SPL for the marine ecology subdomain), in this paper we describe semantic resources created for assisting this development and thus promoting systematic software reuse. The main contributions of our work are focused on the definition of a standard conceptual model for marine ecology applications together with a set of services and guides which assist the process of product derivation. The services are structured in a service taxonomy (as a specialization of the ISO 19119 std) in which we create a new set of categories and services built over a conceptual model for marine ecology applications. We also define and exemplify a set of guides for composing the services of the taxonomy in order to fulfill different functionalities of particular systems in the subdomain. HighlightsSolutions for software reuse for GIS domains by using standard information.Domain-specific taxonomy for supporting the generation of software artifacts.Guides for using geographic services in order to fulfill different GIS functionalities of systems in the domain.Evaluation of the effectiveness of the taxonomy and guides when building an SPL and two derived products.Improvements on time and costs of new GIS products being developed.},
journal = {Comput. Geosci.},
month = dec,
pages = {108–121},
numpages = {14},
keywords = {Domain engineering, Domain-specific taxonomies, Geographic information systems, ISO 19100 standards, Software reuse}
}

@article{10.1016/j.jss.2013.10.010,
author = {White, Jules and Galindo, Jos\'{e} A. and Saxena, Tripti and Dougherty, Brian and Benavides, David and Schmidt, Douglas C.},
title = {Evolving feature model configurations in software product lines},
year = {2014},
issue_date = {January, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {87},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.10.010},
doi = {10.1016/j.jss.2013.10.010},
abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of reusing software components across development projects. One approach to increasing software reusability is to develop a software product-line (SPL), which is a software architecture that can be reconfigured and reused across projects. Rather than developing software from scratch for a new project, a new configuration of the SPL is produced. It is hard, however, to find a configuration of an SPL that meets an arbitrary requirement set and does not violate any configuration constraints in the SPL. Existing research has focused on techniques that produce a configuration of an SPL in a single step. Budgetary constraints or other restrictions, however, may require multi-step configuration processes. For example, an aircraft manufacturer may want to produce a series of configurations of a plane over a span of years without exceeding a yearly budget to add features. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these SPL configuration problems can be automatically derived with a constraint solver by mapping them to CSPs. Moreover, we show how feature model changes can be mapped to our approach in a multi-step scenario by using feature model drift. Third, we present empirical results demonstrating that our CSP-based reasoning technique can scale to SPL models with hundreds of features and multiple configuration steps.},
journal = {J. Syst. Softw.},
month = jan,
pages = {119–136},
numpages = {18},
keywords = {Feature model, Multi-step configuration, Software product line}
}

@inproceedings{10.1109/ASE.2011.6100118,
author = {Soltani, Samaneh and Asadi, Mohsen and Hatala, Marek and Gasevic, Dragan and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on stakeholders' business concerns},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100118},
doi = {10.1109/ASE.2011.6100118},
abstract = {In Software Product Line Engineering, concrete products of a family can be generated through a configuration process over a feature model. The configuration process selects features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from all the available features in the feature model is a cumbersome task because 1) the stakeholders may have diverse business concerns and limited resources that they can spend on a product and 2) features may have negative and positive contributions on different business concern. Many configurations techniques have been proposed to facilitate software developers' tasks through automated product derivation. However, most of the current proposals for automatic configuration are not devised to cope with business oriented requirements and stakeholders' resource limitations. We propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy the stakeholders' business concerns and resource limitations. We also provide tooling support to facilitate the use of our framework.},
booktitle = {Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {536–539},
numpages = {4},
series = {ASE '11}
}

@article{10.1016/j.jss.2007.10.028,
author = {Noor, Muhammad A. and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {Agile product line planning: A collaborative approach and a case study},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {6},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.10.028},
doi = {10.1016/j.jss.2007.10.028},
abstract = {Agile methods and product line engineering (PLE) have both proven successful in increasing customer satisfaction and decreasing time to market under certain conditions. Key characteristics of agile methods are lean and highly iterative development with a strong emphasis on stakeholder involvement. PLE leverages reuse through systematic approaches such as variability modeling or product derivation. Integrating agile approaches with product line engineering is an interesting proposition which - not surprisingly - entails several challenges: Product lines (PL) rely on complex plans and models to ensure their long-term evolution while agile methods emphasize simplicity and short-term value-creation for customers. When incorporating agility in product line engineering, it is thus essential to define carefully how agile principles can support particular PLE processes. For instance, the processes of defining and setting up a product line (domain engineering) and deriving products (application engineering) differ significantly in practices and focus with implications on the suitability of agile principles. This paper presents practical experiences of adopting agile principles in product line planning (a domain engineering activity). ThinkLets, i.e., collaborative practices from the area of collaboration engineering, are the building blocks of the presented approach as they codify agile principles such as stakeholder involvement, rapid feedback, or value-based prioritization. We discuss how our approach balances agility and the intrinsic needs of product line planning. A case study carried out with an industrial partner indicates that the approach is practicable, usable, and useful.},
journal = {J. Syst. Softw.},
month = jun,
pages = {868–882},
numpages = {15},
keywords = {Agile methods, Collaboration engineering, Product line engineering, Product line planning}
}

@inproceedings{10.1145/2377816.2377822,
author = {Buchmann, Thomas and Schw\"{a}gerl, Felix},
title = {Ensuring well-formedness of configured domain models in model-driven product lines based on negative variability},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377822},
doi = {10.1145/2377816.2377822},
abstract = {Model-driven development is a well-known practice in modern software engineering. Many tools exist which allow developers to build software in a model-based or even model-driven way, but they do not provide dedicated support for software product line development. Only recently some approaches combined model-driven engineering and software product line engineering. In this paper we present an approach that allows for combining feature models and Ecore-based domain models and provides extensive support to keep the mapping between the involved models consistent. Our key contribution is a declarative textual language which allows to phrase domain-specific consistency constraints which are preserved during the configuration process in order to ensure context-sensitive syntactical correctness of derived domain models.},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {37–44},
numpages = {8},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1145/3168365.3168375,
author = {Bezerra, Carla I. M. and Andrade, Rossana M. C. and Monteiro, Jos\'{e} M. S. and Cedraz, Davi},
title = {Aggregating Measures using Fuzzy Logic for Evaluating Feature Models},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168375},
doi = {10.1145/3168365.3168375},
abstract = {In the context of Software Product Lines (SPLs), evaluating the quality of a feature model is essential to ensure that errors in the early stages do not spread throughout the SPL. One way to evaluate a feature model is to use measures. However, measures alone are not enough to characterize the feature model quality, because most of them cover specific aspects, such as the number of features. So, there is a need for methods to aggregate measures at the level of quality sub-characteristic or characteristic. In this paper, we aim to investigate how to aggregate measures that have been proposed to evaluate the quality of feature models in SPL. We have used the fuzzy logic theory in order to aggregate these measures. The new aggregated measures can be applied to evaluate different and complex aspects of a feature model, such as: size, stability, flexibility and dynamicity. Moreover, to evaluate the use of the new aggregate measures, we applied them in different feature models. Our findings suggest that aggregate measures can assist the domain engineer in evaluating the maintainability of feature models.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {35–42},
numpages = {8},
keywords = {Feature Models, Fuzzy Logic, Measures, Software Product Line},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@article{10.1007/s10270-012-0289-1,
author = {Leitner, Andrea and Preschern, Christopher and Kreiner, Christian},
title = {Effective development of automation systems through domain-specific modeling in a small enterprise context},
year = {2014},
issue_date = {February  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-012-0289-1},
doi = {10.1007/s10270-012-0289-1},
abstract = {High development and maintenance costs and a high error rate are the major problems in the development of automation systems, which are mainly caused by bad communication and inefficient reuse methods. To overcome these problems, we propose a more systematic reuse approach. Though systematic reuse approaches such as software product lines are appealing, they tend to involve rather burdensome development and management processes. This paper focuses on small enterprises. Since such companies are often unable to perform a "big bang" adoption of the software product line, we suggest an incremental, more lightweight process to transition from single-system development to software product line development. Besides the components of the transition process, this paper discusses tool selection, DSL technology, stakeholder communication support, and business considerations. Although based on problems from the automation system domain, we believe the approach may be general enough to be applicable in other domains as well. The approach has proven successful in two case studies. First, we applied it to a research project for the automation of a logistics lab model, and in the second case (a real-life industry case), we investigated the approaches suitability for fish farm automation systems. Several metrics were collected throughout the evolution of each case, and this paper presents the data for single system development, clone&amp;own and software product line development. The results and observable effects are compared, discussed, and finally summarized in a list of lessons learned.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {35–54},
numpages = {20},
keywords = {Automation system, Domain-specific modeling, Small enterprise cost model, Software product line, System development process}
}

@article{10.1007/s10586-019-03012-1,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e} and Ther\'{o}n, Roberto and Amo Filv\`{a}, Daniel and Fonseca Escudero, David},
title = {Connecting domain-specific features to source code: towards the automatization of dashboard generation},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-03012-1},
doi = {10.1007/s10586-019-03012-1},
abstract = {Dashboards are useful tools for generating knowledge and support decision-making processes, but the extended use of technologies and the increasingly available data asks for user-friendly tools that allow any user profile to exploit their data. Building tailored dashboards for any potential user profile would involve several resources and long development times, taking into account that dashboards can be framed in very different contexts that should be studied during the design processes to provide practical tools. This situation leads to the necessity of searching for methodologies that could accelerate these processes. The software product line paradigm is one recurrent method that can decrease the time-to-market of products by reusing generic core assets that can be tuned or configured to meet specific requirements. However, although this paradigm can solve issues regarding development times, the configuration of the dashboard is still a complex challenge; users’ goals, datasets, and context must be thoroughly studied to obtain a dashboard that fulfills the users’ necessities and that fosters insight delivery. This paper outlines the benefits and a potential approach to automatically configuring information dashboards by leveraging domain commonalities and code templates. The main goal is to test the functionality of a workflow that can connect external algorithms, such as artificial intelligence algorithms, to infer dashboard features and feed a generator based on the software product line paradigm.},
journal = {Cluster Computing},
month = sep,
pages = {1803–1816},
numpages = {14},
keywords = {SPL, Domain engineering, Meta-model, Information dashboards, Feature model, Artificial intelligence, Automatic configuration}
}

@article{10.1016/j.scico.2012.04.004,
author = {Hartmann, Herman and Keren, Mila and Matsinger, Aart and Rubin, Julia and Trew, Tim and Yatzkar-Haham, Tali},
title = {Using MDA for integration of heterogeneous components in software supply chains},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.04.004},
doi = {10.1016/j.scico.2012.04.004},
abstract = {Software product lines are increasingly built using components from specialized suppliers. A company that is in the middle of a supply chain has to integrate components from its suppliers and offer (partially configured) products to its customers. To satisfy both the variability required by each customer and the variability required to satisfy different customers' needs, it may be necessary for such a company to use components from different suppliers, partly offering the same feature set. This leads to a product line with alternative components, possibly using different mechanisms for interfacing, binding and variability, which commonly occurs in embedded software development. In this paper, we describe the limitations of the current practice of combining heterogeneous components in a product line and describe the challenges that arise from software supply chains. We introduce a model-driven approach for automating the integration between components that can generate a partially or fully configured variant, including glue between mismatched components. We analyze the consequences of using this approach in an industrial context, using a case study derived from an existing supply chain and describe the process and roles associated with this approach.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {2313–2330},
numpages = {18},
keywords = {Component technology, Model driven engineering, Resource constrained products, Software integration, Software product line engineering, Software supply chains}
}

@inproceedings{10.1145/1774088.1774530,
author = {Bettini, Lorenzo and Damiani, Ferruccio and Schaefer, Ina},
title = {Implementing software product lines using traits},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774530},
doi = {10.1145/1774088.1774530},
abstract = {A software product line (SPL) is a set of software systems with well-defined commonalities and variabilities that are developed by managed reuse of common artifacts. In this paper, we present a novel approach to implement SPL by fine-grained reuse mechanisms which are orthogonal to class-based inheritance. We introduce the Featherweight Record-Trait Java (FRTJ) calculus where units of product functionality are modeled by traits, a construct that was already shown useful with respect to code reuse, and by records, a construct that complements traits to model the variability of the state part of products explicitly. Records and traits are assembled in classes that are used to build products. This composition of product functionalities is realized by explicit operators of the calculus, allowing code manipulations for modeling product variability. The FRTJ type system ensures that the products in the SPL are type-safe by type-checking only once the records, traits and classes shared by different products. Moreover, type-safety of an extension of a (type-safe) SPL can be guaranteed by checking only the newly added parts.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2096–2102},
numpages = {7},
keywords = {featherweight java, feature model, software product line, trait, type system},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@article{10.1016/j.jss.2008.08.026,
author = {Lago, Patricia and Muccini, Henry and van Vliet, Hans},
title = {A scoped approach to traceability management},
year = {2009},
issue_date = {January, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2008.08.026},
doi = {10.1016/j.jss.2008.08.026},
abstract = {Traceability is the ability to describe and follow the life of a software artifact and a means for modeling the relations between software artifacts in an explicit way. Traceability has been successfully applied in many software engineering communities and has recently been adopted to document the transition among requirements, architecture and implementation. We present an approach to customize traceability to the situation at hand. Instead of automating tracing, or representing all possible traces, we scope the traces to be maintained to the activities stakeholders must carry out. We define core traceability paths, consisting of essential traceability links required to support the activities. We illustrate the approach through two examples: product derivation in software product lines, and release planning in software process management. By using a running software product line example, we explain why the core traceability paths identified are needed when navigating from feature to structural models and from family to product level and backward between models used in software product derivation. A feasibility study in release planning carried out in an industrial setting further illustrates the use of core traceability paths during production and measures the increase in performance of the development processes supported by our approach. These examples show that our approach can be successfully used to support both product and process traceability in a pragmatic yet efficient way.},
journal = {J. Syst. Softw.},
month = jan,
pages = {168–182},
numpages = {15},
keywords = {Software process management, Software product line, Traceability issues, Traceability paths}
}

@inproceedings{10.1145/1808937.1808940,
author = {Strobl, Stefan and Bernhart, Mario and Grechenig, Thomas},
title = {An experience report on the incremental adoption and evolution of an SPL in eHealth},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808940},
doi = {10.1145/1808937.1808940},
abstract = {This work presents an experience report on the evolutionary development of a software product line (SPL) in the eHealth domain. The effort was triggered by the concurrent development of two similar products and the ambition to reduce redundant development and quality assurance. The result is a scalable base for a complex, highly adaptable information system. This system is required to be applicable in multiple business domains and diverging environments ranging from large scale hospitals to single practitioner clinics.During this effort we were able to extract the common denominator in the form of core assets from existing applications specific to a medical field. For customisations well defined variation points were developed. Our solution allows for easy implementation of medical documentation requirements compared to tedious development of new applications from scratch. It significantly reduced the necessary development effort and time to market. The resulting core documentation platform can be used for an arbitrary medical field completely eliminating the dependence on the specific customer domain.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {16–23},
numpages = {8},
keywords = {eHealth, evolutionary software product line, experience report, incremental software product line approach, new generation methodology, software product lines},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@article{10.1016/j.jss.2011.06.026,
author = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
title = {A genetic algorithm for optimized feature selection with resource constraints in software product lines},
year = {2011},
issue_date = {December, 2011},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {12},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.06.026},
doi = {10.1016/j.jss.2011.06.026},
abstract = {Abstract: Software product line (SPL) engineering is a software engineering approach to building configurable software systems. SPLs commonly use a feature model to capture and document the commonalities and variabilities of the underlying software system. A key challenge when using a feature model to derive a new SPL configuration is determining how to find an optimized feature selection that minimizes or maximizes an objective function, such as total cost, subject to resource constraints. To help address the challenges of optimizing feature selection in the face of resource constraints, this paper presents an approach that uses G enetic A lgorithms for optimized FE ature S election (GAFES) in SPLs. Our empirical results show that GAFES can produce solutions with 86-97% of the optimality of other automated feature selection algorithms and in 45-99% less time than existing exact and heuristic feature selection techniques.},
journal = {J. Syst. Softw.},
month = dec,
pages = {2208–2221},
numpages = {14},
keywords = {Configuration, Feature models, Genetic algorithm, Optimization, Product derivation, Software product lines}
}

@article{10.1007/s10270-017-0610-0,
author = {Guo, Jianmei and Liang, Jia Hui and Shi, Kai and Yang, Dingyu and Zhang, Jingsong and Czarnecki, Krzysztof and Ganesh, Vijay and Yu, Huiqun},
title = {SMTIBEA: a hybrid multi-objective optimization algorithm for configuring large constrained software product lines},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {2},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0610-0},
doi = {10.1007/s10270-017-0610-0},
abstract = {A key challenge to software product line engineering is to explore a huge space of various products and to find optimal or near-optimal solutions that satisfy all predefined constraints and balance multiple often competing objectives. To address this challenge, we propose a hybrid multi-objective optimization algorithm called SMTIBEA that combines the indicator-based evolutionary algorithm (IBEA) with the satisfiability modulo theories (SMT) solving. We evaluated the proposed algorithm on five large, constrained, real-world SPLs. Compared to the state-of-the-art, our approach significantly extends the expressiveness of constraints and simultaneously achieves a comparable performance. Furthermore, we investigate the performance influence of the SMT solving on two evolutionary operators of the IBEA.},
journal = {Softw. Syst. Model.},
month = apr,
pages = {1447–1466},
numpages = {20},
keywords = {Constraint solving, Feature models, Multi-objective evolutionary algorithms, Search-based software engineering, Software product lines}
}

@inproceedings{10.1145/3302333.3302344,
author = {Ferreira, Fischer and Diniz, Jo\~{a}o P. and Silva, Cleiton and Figueiredo, Eduardo},
title = {Testing Tools for Configurable Software Systems: A Review-based Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302344},
doi = {10.1145/3302333.3302344},
abstract = {Configurable software systems are software systems that can be adapted or configured according to a set of features with the goal of increasing reuse and productivity. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. The lack of studies to explore the tools that apply those techniques motivated us to investigate the literature to find testing tools for configurable software systems and to understand how they work. In this paper, we conducted a systematic mapping and identified 34 testing tools for configurable software systems. We first summarized and discussed their main characteristics. We then designed and performed a comparative empirical study of the main sound testing tools found: VarexJ and SPLat. They are considered sound testing techniques because they explore all reachable configurations from a given test. Overall, we observed that VarexJ and SPLat presented distinct results for efficiency while testing the target systems and that, although VarexJ found more errors than SPLat for the majority of the target systems, such result deserves a more in-depth investigation because we expected a higher intersection of errors encountered by them.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {10},
keywords = {Software Product Line, Systematic Mapping Study, Testing Configurable Software Systems},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1007/978-3-642-33666-9_46,
author = {Ali, Shaukat and Yue, Tao and Briand, Lionel and Walawege, Suneth},
title = {A product line modeling and configuration methodology to support model-based testing: an industrial case study},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_46},
doi = {10.1007/978-3-642-33666-9_46},
abstract = {Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behavioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {726–742},
numpages = {17},
keywords = {UML state machine, aspect-oriented modeling, behavioral variability, model-based testing, product line engineering},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/3168365.3168377,
author = {Ananieva, Sofia and Klare, Heiko and Burger, Erik and Reussner, Ralf},
title = {Variants and Versions Management for Models with Integrated Consistency Preservation},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168377},
doi = {10.1145/3168365.3168377},
abstract = {Modern software systems are often developed and maintained by describing them in several modeling and programming languages. To reduce complexity and improve understandability of such systems, models represent specific views on the system. These views have semantic interrelations (e.g., by sharing common or dependent information) that need to be kept consistent during evolution of the system. Apart from that, modern systems need to run in many different contexts and be highly configurable to satisfy the demand for fully customizable products. Such variable systems often comprise various dependencies from which inconsistencies may arise. Combining solutions for consistency management with variants and versions management, however, comes with many challenges.In this research-in-progress paper, we introduce the VaVe approach which makes variants and versions management aware of automated consistency preservation in the context of multi-view modeling. We explain core features of the approach and reason about its benefits and limitations.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {3–10},
numpages = {8},
keywords = {Delta-Based Consistency Preservation, Software Product Lines, Variability Management},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/3278122.3278123,
author = {Nieke, Michael and Mauro, Jacopo and Seidl, Christoph and Th\"{u}m, Thomas and Yu, Ingrid Chieh and Franzke, Felix},
title = {Anomaly analyses for feature-model evolution},
year = {2018},
isbn = {9781450360456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278122.3278123},
doi = {10.1145/3278122.3278123},
abstract = {Software Product Lines (SPLs) are a common technique to capture families of software products in terms of commonalities and variabilities. On a conceptual level, functionality of an SPL is modeled in terms of features in Feature Models (FMs). As other software systems, SPLs and their FMs are subject to evolution that may lead to the introduction of anomalies (e.g., non-selectable features). To fix such anomalies, developers need to understand the cause for them. However, for large evolution histories and large SPLs, explanations may become very long and, as a consequence, hard to understand. In this paper, we present a method for anomaly detection and explanation that, by encoding the entire evolution history, identifies the evolution step of anomaly introduction and explains which of the performed evolution operations lead to it. In our evaluation, we show that our method significantly reduces the complexity of generated explanations.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {188–201},
numpages = {14},
keywords = {Anomalies, Evolution, Evolution Operation, Explanation, Feature Model, Software Product Line},
location = {Boston, MA, USA},
series = {GPCE 2018}
}

@article{10.1007/s10515-010-0076-6,
author = {Dhungana, Deepak and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {The DOPLER meta-tool for decision-oriented variability modeling: a multiple case study},
year = {2011},
issue_date = {March     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-010-0076-6},
doi = {10.1007/s10515-010-0076-6},
abstract = {The variability of a product line is typically defined in models. However, many existing variability modeling approaches are rigid and don't allow sufficient domain-specific adaptations. We have thus been developing a flexible and extensible approach for defining product line variability models. Its main purposes are to guide stakeholders through product derivation and to automatically generate product configurations. Our approach is supported by the DOPLER (  D ecision-  O riented  P roduct  L ine  E ngineering for effective  R euse) meta-tool that allows modelers to specify the types of reusable assets, their attributes, and dependencies for their specific system and context. The aim of this paper is to investigate the suitability of our approach for different domains. More specifically, we explored two research questions regarding the implementation of variability and the utility of DOPLER for variability modeling in different domains. We conducted a multiple case study consisting of four cases in the domains of industrial automation systems and business software. In each of these case studies we analyzed variability implementation techniques. Experts from our industry partners then developed domain-specific meta-models, tool extensions, and variability models for their product lines using DOPLER. The four cases demonstrate the flexibility of the DOPLER approach and the extensibility and adaptability of the supporting meta tool.},
journal = {Automated Software Engg.},
month = mar,
pages = {77–114},
numpages = {38},
keywords = {Decision models, Meta-tools, Product line engineering}
}

@inproceedings{10.1007/978-3-642-41533-3_23,
author = {Nie, Kunming and Yue, Tao and Ali, Shaukat and Zhang, Li and Fan, Zhiqiang},
title = {Constraints: The Core of Supporting Automated Product Configuration of Cyber-Physical Systems},
year = {2013},
isbn = {9783642415326},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-41533-3_23},
doi = {10.1007/978-3-642-41533-3_23},
abstract = {In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration solution, based on our experience of studying three industrial product lines.},
booktitle = {Proceedings of the 16th International Conference on Model-Driven Engineering Languages and Systems - Volume 8107},
pages = {370–387},
numpages = {18},
keywords = {Classification, Configuration, Constraints, Cyber-Physical Systems, Industrial Case Studies, Product Line Engineering}
}

@inproceedings{10.5555/2662593.2662594,
author = {Albassam, Emad and Gomaa, Hassan},
title = {Applying software product lines to multiplatform video games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {In this paper, we explore the application of Software Product Line (SPL) technology in the video games domain by exploiting differences in various video game platforms to design a variable component-based software product line architecture for a multiplatform video game. Our approach consists of constructing a feature dependency model for describing variability in multiplatform video games. We explored variability in the user interface, input devices, output devices, CPU, as well as other variability in various video game platforms. Then, we designed a variable component-based SPL that is tailored to every video game in the product line. We validated our approach by implementing a SPL of a combat flight-simulator game and by deriving two versions of the game: a Windows desktop version and a Windows Phone version. The derivation process of each version is done by selecting features from the feature dependency model and the corresponding software components and SPL parameters that relate to those features.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {1–7},
numpages = {7},
keywords = {feature modeling, multiplatform variability, software product line design, video games},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.1145/1944892.1944895,
author = {Holl, Gerald and Vierhauser, Michael and Heider, Wolfgang and Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {Product line bundles for tool support in multi product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944895},
doi = {10.1145/1944892.1944895},
abstract = {Many organizations adopt a product line approach to increase the degree of reuse in software development and to deal with the variability of their systems. Large-scale systems are often composed of multiple heterogeneous subsystems that are based on diverse technological platforms. Providing product line engineering tools for such multi product line environments is challenging as tool requirements of stakeholders can differ significantly. In this paper we present product line bundles (PLiBs), an approach that supports developers in tailoring and extending product line tools in a multi product line context. Based on an industrial example, we examine the specific requirements and challenges of using PLiBs to manage tool extensions in multi product lines and to simplify the integration and deployment of system-specific tool features.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {21–27},
numpages = {7},
keywords = {multi product lines, product line bundles, product line engineering, tool support},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/3194760.3194761,
author = {Kessel, Marcus and Atkinson, Colin},
title = {Integrating reuse into the rapid, continuous software engineering cycle through test-driven search},
year = {2018},
isbn = {9781450357456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194760.3194761},
doi = {10.1145/3194760.3194761},
abstract = {Today's advanced agile practices such as Continuous Integration and Test-Driven Development support a wide range of software development activities to facilitate the rapid delivery of high-quality software. However, the reuse of pre-existing, third-party software components is not one of them. Software reuse is still primarily perceived as a time-consuming, unsystematic and ultimately, "discontinuous" activity even though it aims to deliver the same basic benefits as continuous software engineering - namely, a reduction in the time and effort taken to deliver quality software. However, the increasingly central role of testing in continuous software engineering offers a way of addressing this problem by exploiting the new generation of test-driven search engines that can harvest components based on tests. This search technology not only exploits artifacts that have already been created as part of the continuous testing process to harvest components, it returns results that have a high likelihood of being fit for purpose and thus of being worth reusing. In this paper, we propose to augment continuous software engineering with the rapid, continuous reuse of software code units by integrating the test-driven mining of software artifact repositories into the continuous integration process. More specifically, we propose to use tests written as part of the Test-First Development approach to perform test-driven searches for matching functionality while developers are working on their normal development activities. We discuss the idea of rapid, continuous code reuse based on recent advances in our test-driven search platform and elaborate on scenarios for its application in the future.},
booktitle = {Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering},
pages = {8–11},
numpages = {4},
keywords = {rapid continuous code reuse, rapid continuous integration, test-driven development, test-driven reuse, test-driven search},
location = {Gothenburg, Sweden},
series = {RCoSE '18}
}

@article{10.1016/j.infsof.2015.11.004,
author = {Heradio, Ruben and Perez-Morago, Hector and Fernandez-Amoros, David and Javier Cabrerizo, Francisco and Herrera-Viedma, Enrique},
title = {A bibliometric analysis of 20 years of research on software product lines},
year = {2016},
issue_date = {April 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {72},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.11.004},
doi = {10.1016/j.infsof.2015.11.004},
abstract = {Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality.Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way.Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis.Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations.Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {1–15},
numpages = {15},
keywords = {Bibliometrics, Performance analysis, Science mapping, Software product lines}
}

@inproceedings{10.1145/2851613.2851764,
author = {Gharibi, Gharib and Zheng, Yongjie},
title = {ArchFeature: integrating features into product line architecture},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851764},
doi = {10.1145/2851613.2851764},
abstract = {Product line architecture (PLA) captures the architectural commonality and variability among products of a product family. Existing PLA modeling approaches are limited in the sense that (1) it is often difficult to relate a product line feature to its implementation in the PLA, and (2) variation points in the PLA have to be manually developed and maintained. In this paper, we present a novel PLA modeling approach and a toolset called ArchFeature that addresses these two challenges. ArchFeature integrates PLA and feature specification in a single monolithic architecture model. It includes a graphical modeling environment that can (1) automatically capture, maintain, and visualize the feature-PLA relationship, (2) encapsulate variability modeling from the user, and (3) support automatic derivation of architecture instances from the PLA. ArchFeature is an Eclipse plugin integrated in ArchStudio, an Eclipse-based architecture development platform. We assessed its usability and effectiveness in a case study by using it to develop a full-featured architecture model for an open-source software system, Apache Solr.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1302–1308},
numpages = {7},
keywords = {architecture modeling, product line architecture, software product line},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.5555/2820656.2820661,
author = {Segura, Vin\'{\i}cius C. V. B. and Tizzei, Leonardo P. and de F. Ramirez, Jo\~{a}o Paulo and dos Santos, Marcelo N. and Azevedo, Leonardo G. and de G. Cerqueira, Renato F.},
title = {WISE-SPL: bringing multi-tenancy to the weather InSights environment system},
year = {2015},
publisher = {IEEE Press},
abstract = {Weather conditions affect many cities and companies. The WISE (Weather InSights Environment) system serves as a central place to gather and present weather related information for decision makers. It was initially developed to fit a single tenant. Due to a multi-tenant opportunity, WISE is evolving to be deployed on a Cloud environment to support on-demand computing resources and multiple clients. Software product line techniques were applied to model common and variable features of tenants. WISE-SPL enables the derivation of products for each client and also the deployment on Cloud infrastructure. The contribution of this work is a demonstration and discussion of benefits and limitations in applying SPL techniques, following a extractive approach, to build a multi-tenant Cloud application.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {7–10},
numpages = {4},
location = {Florence, Italy},
series = {PLEASE '15}
}

@article{10.1016/j.infsof.2015.01.008,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
title = {A systematic mapping study of search-based software engineering for software product lines},
year = {2015},
issue_date = {May 2015},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {61},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.01.008},
doi = {10.1016/j.infsof.2015.01.008},
abstract = {ContextSearch-Based Software Engineering (SBSE) is an emerging discipline that focuses on the application of search-based optimization techniques to software engineering problems. Software Product Lines (SPLs) are families of related software systems whose members are distinguished by the set of features each one provides. SPL development practices have proven benefits such as improved software reuse, better customization, and faster time to market. A typical SPL usually involves a large number of systems and features, a fact that makes them attractive for the application of SBSE techniques which are able to tackle problems that involve large search spaces. ObjectiveThe main objective of our work is to identify the quantity and the type of research on the application of SBSE techniques to SPL problems. More concretely, the SBSE techniques that have been used and at what stage of the SPL life cycle, the type of case studies employed and their empirical analysis, and the fora where the research has been published. MethodA systematic mapping study was conducted with five research questions and assessed 77 publications from 2001, when the term SBSE was coined, until 2014. ResultsThe most common application of SBSE techniques found was testing followed by product configuration, with genetic algorithms and multi-objective evolutionary algorithms being the two most commonly used techniques. Our study identified the need to improve the robustness of the empirical evaluation of existing research, a lack of extensive and robust tool support, and multiple avenues worthy of further investigation. ConclusionsOur study attested the great synergy existing between both fields, corroborated the increasing and ongoing interest in research on the subject, and revealed challenging open research questions.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {33–51},
numpages = {19},
keywords = {Evolutionary algorithm, Metaheuristics, Search based software engineering, Software product line, Systematic mapping study}
}

@inproceedings{10.1109/ASE.2008.46,
author = {Gr\"{u}nbacher, P. and Rabiser, R. and Dhungana, D.},
title = {Product Line Tools are Product Lines Too: Lessons Learned from Developing a Tool Suite},
year = {2008},
isbn = {9781424421879},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2008.46},
doi = {10.1109/ASE.2008.46},
abstract = {Tool developers are facing high expectations regarding the capabilities and usability of software engineering tools. Users expect tools which are tailored to their specific needs and integrated in their environment. This increases the complexity of tools and makes their customization more difficult, although numerous mechanisms supporting adaptability and extensibility are available. In this experience paper we report on the lessons we have learned when developing a tool suite for product line engineering. Our experiences suggest that software engineering tools should be designed as product lines.},
booktitle = {Proceedings of the 23rd IEEE/ACM International Conference on Automated Software Engineering},
pages = {351–354},
numpages = {4},
keywords = {product line engineering, product line tools, software engineering tools, tool suite},
series = {ASE '08}
}

@article{10.1007/s10664-013-9253-0,
author = {Ihme, Tuomas and Pikkarainen, Minna and Teppola, Susanna and K\"{a}\"{a}ri\"{a}inen, Jukka and Biot, Olivier},
title = {Challenges and industry practices for managing software variability in small and medium sized enterprises},
year = {2014},
issue_date = {August    2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-013-9253-0},
doi = {10.1007/s10664-013-9253-0},
abstract = {Software variability is an ability to change (configure, customize, extend) software artefacts (e.g. code, product, domain requirements, models, design, documentation, test cases) for a specific context. Optimized variability management can lead a software company to 1) shorter development lead time, 2) improved customer and improved user satisfaction, 3) reduced complexity of product management (more variability, same $) and 4) reduced costs (same variability, less $). However, it is not easy for software companies, especially small and medium size of enterprises to deal with variability. In this paper we present variability challenges and used practices collected from five SMEs. Our study indicates that increased product complexity can lead growing SMEs to the time-consuming decision-making. Many of the analyzed medium size of companies also expect improved tool support to help them to boost their productivity when managing increasingly complex products and increasing amount of variants In fact, in many of the analysed SMEs, a high level of automation in design, release management and testing are or become a key factor for market success By introducing the challenges and used practices related to variability the paper deepens understanding of this highly relevant but relatively under-researched phenomenon and contributes to the literature on software product line engineering.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1144–1168},
numpages = {25},
keywords = {Software variability challenges, Variability practices}
}

@inproceedings{10.1145/3136040.3136054,
author = {Linsbauer, Lukas and Berger, Thorsten and Gr\"{u}nbacher, Paul},
title = {A classification of variation control systems},
year = {2017},
isbn = {9781450355247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136040.3136054},
doi = {10.1145/3136040.3136054},
abstract = {Version control systems are an integral part of today's software and systems development processes. They facilitate the management of revisions (sequential versions) and variants (concurrent versions) of a system under development and enable collaboration between developers. Revisions are commonly maintained either per file or for the whole system. Variants are supported via branching or forking mechanisms that conceptually clone the whole system under development. It is known that such cloning practices come with disadvantages. In fact, while short-lived branches for isolated development of new functionality (a.k.a. feature branches) are well supported, dealing with long-term and fine-grained system variants currently requires employing additional mechanisms, such as preprocessors, build systems or custom configuration tools. Interestingly, the literature describes a number of variation control systems, which provide a richer set of capabilities for handling fine-grained system variants compared to the version control systems widely used today. In this paper we present a classification and comparison of selected variation control systems to get an understanding of their capabilities and the advantages they can offer. We discuss problems of variation control systems, which may explain their comparably low popularity. We also propose research activities we regard as important to change this situation.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {49–62},
numpages = {14},
keywords = {Variability management, configuration management, software product lines, software repositories},
location = {Vancouver, BC, Canada},
series = {GPCE 2017}
}

@article{10.1016/j.scico.2017.10.013,
author = {Castro, Thiago and Lanna, Andr and Alves, Vander and Teixeira, Leopoldo and Apel, Sven and Schobbens, Pierre-Yves},
title = {All roads lead to Rome},
year = {2018},
issue_date = {January 2018},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2017.10.013},
doi = {10.1016/j.scico.2017.10.013},
abstract = {The formalization of seven strategies for product-line reliability analysis.The first feature-family-product-based strategy for product-line model checking.A general principle for lifting analyses to product lines using ADDs.Proofs that the formalized strategies commute.All strategies proven sound with respect to single-product reliability analysis. Software product line engineering is a means to systematically manage variability and commonality in software systems, enabling the automated synthesis of related programs (products) from a set of reusable assets. However, the number of products in a software product line may grow exponentially with the number of features, so it is practically infeasible to quality-check each of these products in isolation. There is a number of variability-aware approaches to product-line analysis that adapt single-product analysis techniques to cope with variability in an efficient way. Such approaches can be classified along three analysis dimensions (product-based, family-based, and feature-based), but, particularly in the context of reliability analysis, there is no theory comprising both (a) a formal specification of the three dimensions and resulting analysis strategies and (b) proof that such analyses are equivalent to one another. The lack of such a theory hinders formal reasoning on the relationship between the analysis dimensions and derived analysis techniques. We formalize seven approaches to reliability analysis of product lines, including the first instance of a feature-family-product-based analysis in the literature. We prove the formalized analysis strategies to be sound with respect to the probabilistic approach to reliability analysis of a single product. Furthermore, we present a commuting diagram of intermediate analysis steps, which relates different strategies and enables the reuse of soundness proofs between them.},
journal = {Sci. Comput. Program.},
month = jan,
pages = {116–160},
numpages = {45},
keywords = {Model checking, Product-line analysis, Reliability analysis, Software product lines, Verification}
}

@inproceedings{10.1145/1321631.1321711,
author = {Botterweck, Goetz and O'Brien, Liam and Thiel, Steffen},
title = {Model-driven derivation of product architectures},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321711},
doi = {10.1145/1321631.1321711},
abstract = {Product Derivation is one of the central activities in Software Product Lines (SPL). One of the main challenges of the process of product derivation is dealing with complexity, which is caused by the large number of artifacts and dependencies between them. Another major challenge is maximizing development efficiency and reducing time-to-market, while at the same time producing high quality products. One approach to overcome these challenges is to automate the derivation process. To this end, this paper focuses on one particular activity of the derivation process; the derivation of the product-specific architecture and describes how this activity can be automated using a model-driven approach. The approach derives the product-specific architecture by selectively copying elements from the product-line architecture. The decision, which elements are included in the derived architecture, is based on a product-specific feature configuration. We present a prototype that implements the derivation as a model transformation described in the Atlas Transformation Language (ATL). We conclude with a short overview of related work and directions for future research},
booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {469–472},
numpages = {4},
keywords = {ATL, model transformation, model-driven approaches, product derivation, software architectures, software product lines},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{10.1145/3023956.3023968,
author = {Mjeda, Anila and Wasala, Asanka and Botterweck, Goetz},
title = {Decision spaces in product lines, decision analysis, and design exploration: an interdisciplinary exploratory study},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023968},
doi = {10.1145/3023956.3023968},
abstract = {Context. From recent works on product properties resulting from configurations and the optimisation of these properties, one comes quickly to more complex challenges such as multi-objective optimisation, conflicting objectives, multiple stakeholders, and conflict resolution. The intuition is that Software Product Line Engineering (SPLE) can draw from other disciplines that deal with decision spaces and complex decision scenarios.Objectives. We aim to (1) explore links to such disciplines, (2) systematise and compare concepts, and (3) identify opportunities, where SPLE approaches can be enriched.Method. We undertake an exploratory study: Starting from common SPLE activities and artefacts, we identify aspects where we expect to find corresponding counterparts in other disciplines. We focus on Multiple Criteria Decision Analysis (MCDA), Multi-Objective Optimisation (MOO), and Design Space Exploration (DSE), and perform a comparison of the key concepts.Results. The resulting comparison relates SPLE activities and artefacts to concepts from MCDA, MOO, and DSE and identifies areas where SPLE approaches can be enriched. We also provide examples of existing work at the intersections of SPLE with the other fields. These findings are aimed to foster the conversation on research opportunities where SPLE can draw techniques from other disciplines dealing with complex decision scenarios.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {68–75},
numpages = {8},
keywords = {decision modelling, design-space exploration, multi-criteria decision analysis, multi-objective optimisation},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1145/1982185.1982522,
author = {Mohabbati, Bardia and Hatala, Marek and Ga\v{s}evi\'{c}, Dragan and Asadi, Mohsen and Bo\v{s}kovi\'{c}, Marko},
title = {Development and configuration of service-oriented systems families},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982522},
doi = {10.1145/1982185.1982522},
abstract = {Software Product Lines (SPLs) are families of software systems which share a common sets of feature and are developed through common set of core assets in order to promotes software reusability, mass customization, reducing cost, time-to-market and improving the quality of the product. SPLs are sets (i.e., families) of software applications developed as a whole for a specific business domain. Particular applications are derived from software families by selecting the desired features through configuration process. Traditionally, SPLs are implemented with systematically developed components, shared by members of the SPLs and reused every time a new application is derived. In this paper, we propose an approach to the development and configuration of Service-Oriented SPLs in which services are used as reusable assets and building blocks of implementation. Our proposed approach also suggests prioritization of family features according to stakeholder's non-functional requirements (NFRs) and preferences. Priorities of NFRs are used to filter the most important features of the family, which is performed by Stratified Analytic Hierarchical Process (S-AHP). The priorities also are used further for the selection of appropriate services implementation for business processes realizing features. We apply Mixed Integer Linear Programming to find the optimal service selection within the constraints boundaries specified by stakeholders.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {1606–1613},
numpages = {8},
keywords = {feature-oriented development, optimization, service selection, service-oriented architecture, software product line},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@inproceedings{10.5555/1885639.1885681,
author = {Lin, Yuqing and Ye, Huilin and Tang, Jianmin},
title = {An approach to efficient product configuration in software product lines},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling has been widely used in software product line engineering to represent commonality and variabilities among products in a product family. When developing a new software product belonging to a product line, a feature model representing the product line will be used to configure products. The product configuration process is a decision making process, various kinds of constraints and complex relationships among configurable features make the decision making a time consuming and error prone task. In this paper, we present an approach which will improve the efficiency and quality of product configuration.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {435–439},
numpages = {5},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/1960314.1960338,
author = {Cirilo, Elder and Kulesza, Uir\'{a} and Garcia, Alessandro and Lucena, Carlos},
title = {GenArch+: an extensible infrastructure for building framework-based software product lines},
year = {2011},
isbn = {9781450306065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1960314.1960338},
doi = {10.1145/1960314.1960338},
abstract = {Software product line (SPL) engineering has been focused on tailor single products without programming new completion code. Systematic reuse as configuration potentially lead to significant gains but requires the configuration knowledge to be well conducted. However, due to the use of frameworks to relive the development of software systems, it might become difficult to have precise and comprehensible configuration knowledge specifications. First, because the completion code of a specific framework-provided concept might be scattered across and tangled with code implementing other concepts or features. Second, creating an instance of a framework-provided abstraction involves making implementation choices, some of which are stipulated by hidden programming interface and crosscut heterogeneous languages. In this demonstration we present a tool based on Domain Knowledge Modeling Languages. They are used to express models specifying the configuration knowledge of a specific implementation domain and, ensure the consistency and ease the comprehension of framework-based SPL.},
booktitle = {Proceedings of the Tenth International Conference on Aspect-Oriented Software Development Companion},
pages = {69–70},
numpages = {2},
keywords = {configuration knowledge, product derivation tool, software product lines},
location = {Porto de Galinhas, Brazil},
series = {AOSD '11}
}

@inproceedings{10.1145/1808937.1808939,
author = {Hartmann, Herman and Keren, Mila and Matsinger, Aart and Rubin, Julia and Trew, Tim and Yatzkar-Haham, Tali},
title = {Integrating heterogeneous components in software supply chains},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808939},
doi = {10.1145/1808937.1808939},
abstract = {Numerous software product lines today are built from components supplied by different vendors. Companies situated in the middle of a software supply chain must configure and integrate components from their suppliers and offer (partially configured) variants for their customers, who can then complete the configuration and use these components in product lines or products that they develop. Covering the entire product line often involves using components from multiple suppliers, many of which providing overlapping functionality. This leads to a product line with different possible alternatives for components. These components may use mismatched interfaces and therefore require glue for integration.In this paper we analyze the consequences of combining heterogeneous components -- components that are not designed using a common architecture -- in a product line. We describe the limitations of the current practice and the challenges that arise from combining such components and delivering partially configured products. We introduce a new variability pattern that allows us to deal with heterogeneous components implementing overlapping functionality. This pattern consists of a reference architectural model, as well as transformations that generate a partially configured application including artifacts for gluing mismatched components.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {8–15},
numpages = {8},
keywords = {component technology, model driven engineering, resource constraint products, software integration, software product line engineering, software supply chains, variability},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@article{10.1016/j.jss.2019.02.027,
author = {Carbonnel, Jessie and Huchard, Marianne and Nebut, Cl\'{e}mentine},
title = {Modelling equivalence classes of feature models with concept lattices to assist their extraction from product descriptions},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.02.027},
doi = {10.1016/j.jss.2019.02.027},
journal = {J. Syst. Softw.},
month = jun,
pages = {1–23},
numpages = {23},
keywords = {Software product lines, Reverse engineering, Formal concept analysis, Variability modelling, Feature models}
}

@inproceedings{10.1007/978-3-662-45234-9_20,
author = {Collet, Philippe},
title = {Domain Specific Languages for Managing Feature Models: Advances and Challenges},
year = {2014},
isbn = {9783662452332},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-45234-9_20},
doi = {10.1007/978-3-662-45234-9_20},
abstract = {Managing multiple and complex feature models is a tedious and error-prone activity in software product line engineering. Despite many advances in formal methods and analysis techniques, the supporting tools and APIs are not easily usable together, nor unified. In this paper, we report on the development and evolution of the Familiar Domain-Specific Language DSL. Its toolset is dedicated to the large scale management of feature models through a good support for separating concerns, composing feature models and scripting manipulations. We overview various applications of Familiar and discuss both advantages and identified drawbacks. We then devise salient challenges to improve such DSL support in the near future.},
booktitle = {Part I of the Proceedings of the 6th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change - Volume 8802},
pages = {273–288},
numpages = {16}
}

@article{10.1145/1183236.1183260,
author = {Sugumaran, Vijayan and Park, Sooyong and Kang, Kyo C.},
title = {Introduction},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/1183236.1183260},
doi = {10.1145/1183236.1183260},
journal = {Commun. ACM},
month = dec,
pages = {28–32},
numpages = {5}
}

@article{10.1016/j.jss.2007.06.002,
author = {Sinnema, Marco and Deelstra, Sybren},
title = {Industrial validation of COVAMOF},
year = {2008},
issue_date = {April, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {4},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.06.002},
doi = {10.1016/j.jss.2007.06.002},
abstract = {COVAMOF is a variability management framework for product families that was developed to reduce the number of iterations required during product derivation and to reduce the dependency on experts. In this paper, we present the results of an experiment with COVAMOF in industry. The results show that with COVAMOF, engineers that are not involved in the product family were now capable of deriving the products in 100% of the cases, compared to 29% of the cases without COVAMOF. For experts, the use of COVAMOF reduced the number of iterations by 42%, and the total derivation time by 38%.},
journal = {J. Syst. Softw.},
month = apr,
pages = {584–600},
numpages = {17},
keywords = {Industrial validation, Product family engineering, Software Variability Management}
}

@inproceedings{10.1145/1509239.1509259,
author = {Niu, Nan and Easterbrook, Steve},
title = {Concept analysis for product line requirements},
year = {2009},
isbn = {9781605584423},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1509239.1509259},
doi = {10.1145/1509239.1509259},
abstract = {Traditional methods characterize a software product line's requirements using either functional or quality criteria. This appears to be inadequate to assess modularity, detect interferences, and analyze trade-offs. We take advantage of both symmetric and asymmetric views of aspects, and perform formal concept analysis to examine the functional and quality requirements of an evolving product line. The resulting concept lattice provides a rich notion which allows remarkable insights into the modularity and interactions of requirements. We formulate a number of problems that aspect-oriented product line requirements engineering should address, and present our solutions according to the concept lattice. We describe a case study applying our approach to analyze a mobile game product line's requirements, and review lessons learned.},
booktitle = {Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development},
pages = {137–148},
numpages = {12},
keywords = {formal concept analysis, functional requirements profiles, product line engineering, quality attribute scenarios},
location = {Charlottesville, Virginia, USA},
series = {AOSD '09}
}

@article{10.1109/TSE.2015.2449854,
author = {Duran-Limon, Hector A. and Garcia-Rios, Carlos A. and Castillo-Barrera, Francisco E. and Capilla, Rafael},
title = {An Ontology-Based Product Architecture Derivation Approach},
year = {2015},
issue_date = {Dec. 2015},
publisher = {IEEE Press},
volume = {41},
number = {12},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2015.2449854},
doi = {10.1109/TSE.2015.2449854},
abstract = {Software product line (SPL) engineering has proven to improve software quality and shorten development cycles, cost and time. In product line engineering, product derivation is concerned with the realization of the variability at the implementation level. However, the majority of research works focuses on instantiating the variants selected in the final product, while the derivation at the architecture level has been poorly explored. As product line engineers often customize the product architecture by hand during the application engineering phase, the derivation and customization processes of the product line architecture (PLA) might be in some cases error-prone. Consequently, in this research we present an Ontology-based product Architecture Derivation (OntoAD) framework which automates the derivation of product-specific architectures from an SPL architecture. Our solution uses a language-independent model to specify the product line architecture and a model-driven engineering approach for architecture derivation activities. We use an ontology formalism to reason about the automatic generation of model-to-model transformation rules based on the selection of features and we illustrate our approach using a voice over IP motivating example. Finally, we report results about scalability and performance regarding the size of the variability model.},
journal = {IEEE Trans. Softw. Eng.},
month = dec,
pages = {1153–1168},
numpages = {16}
}

@inproceedings{10.1007/978-3-642-34026-0_16,
author = {Devroey, Xavier and Cordy, Maxime and Perrouin, Gilles and Kang, Eun-Young and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel and Baudry, Benoit},
title = {A vision for behavioural model-driven validation of software product lines},
year = {2012},
isbn = {9783642340253},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-34026-0_16},
doi = {10.1007/978-3-642-34026-0_16},
abstract = {The Software Product Lines (SPLs) paradigm promises faster development cycles and increased quality by systematically reusing software assets. This paradigm considers a family of systems, each of which can be obtained by a selection of features in a variability model. Though essential, providing Quality Assurance (QA) techniques for SPLs has long been perceived as a very difficult challenge due to the combinatorics induced by variability and for which very few techniques were available. Recently, important progress has been made by the model-checking and testing communities to address this QA challenge, in a very disparate way though. We present our vision for a unified framework combining model-checking and testing approaches applied to behavioural models of SPLs. Our vision relies on Featured Transition Systems (FTSs), an extension of transition systems supporting variability. This vision is also based on model-driven technologies to support practical SPL modelling and orchestrate various QA scenarios. We illustrate one of such scenarios on a vending machine SPL.},
booktitle = {Proceedings of the 5th International Conference on Leveraging Applications of Formal Methods, Verification and Validation: Technologies for Mastering Change - Volume Part I},
pages = {208–222},
numpages = {15},
keywords = {model-based testing, model-checking, software product line},
location = {Heraklion, Crete, Greece},
series = {ISoLA'12}
}

@inproceedings{10.5555/1885639.1885659,
author = {Ghanam, Yaser and Maurer, Frank},
title = {Linking feature models to code artifacts using executable acceptance tests},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A feature model is a representation of the requirements in a given system abstracted at the feature level. Linking conceptual requirements in feature models to actual implementation artifacts provides for many advantages such as increased program comprehension, implementation completeness assessment, impact analysis, and reuse opportunities. However, in practice, as systems evolve, traceability links between the model and the code artifacts may become broken or outdated. In this paper, we contribute an approach to provide traceability links in a way that ensures consistency between the feature model and the code artifacts, enables the evolution of variability in the feature model, and supports the product derivation process. We do that by using executable acceptance tests as a direct traceability link between feature models and code artifacts. We evaluate our approach and present a brief overview of the tool support we provide.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {211–225},
numpages = {15},
keywords = {agile product line engineering, executable acceptance tests, feature models, traceability, variability evolution},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/1385486.1385488,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Schirmeier, Horst and Sincero, Julio and Apel, Sven and Leich, Thomas and Spinczyk, Olaf and Saake, Gunter},
title = {FAME-DBMS: tailor-made data management solutions for embedded systems},
year = {2008},
isbn = {9781595939647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1385486.1385488},
doi = {10.1145/1385486.1385488},
abstract = {Data management functionality is not only needed in large-scale server systems, but also in embedded systems. Resource restrictions and heterogeneity of hardware, however, complicate the development of data management solutions for those systems. In current practice, this typically leads to the redevelopment of data management because existing solutions cannot be reused and adapted appropriately. In this paper, we present our ongoing work on FAME-DBMS, a research project that explores techniques to implement highly customizable data management solutions, and illustrate how such systems can be created with a software product line approach. With this approach a concrete instance of a DBMS is derived by composing features of the DBMS product line that are needed for a specific application scenario. This product derivation process is getting complex if a large number of features is available. Furthermore, in embedded systems also non-functional properties, e.g., memory consumption, have to be considered when creating a DBMS instance. To simplify the derivation process we present approaches for its automation.},
booktitle = {Proceedings of the 2008 EDBT Workshop on Software Engineering for Tailor-Made Data Management},
pages = {1–6},
numpages = {6},
location = {Nantes, France},
series = {SETMDM '08}
}

@article{10.1016/j.csi.2019.04.011,
author = {Barros-Justo, Jos\'{e} L. and Benitti, Fabiane B.V. and Matalonga, Santiago},
title = {Trends in software reuse research: A tertiary study},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {66},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2019.04.011},
doi = {10.1016/j.csi.2019.04.011},
journal = {Comput. Stand. Interfaces},
month = oct,
numpages = {18},
keywords = {Software reuse, Trends in software reuse, Systematic literature review, Tertiary study}
}

@inproceedings{10.5555/2093889.2093921,
author = {Bagheri, Ebrahim and Asadi, Mohsen and Ensan, Faezeh and Ga\v{s}evi\'{c}, Dragan and Mohabbati, Bardia},
title = {Bringing semantics to feature models with SAFMDL},
year = {2011},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software product line engineering is a paradigm that advocates the reusability of software engineering assets and the rapid development of new applications for a target domain. These objectives are achieved by capturing the commonalities and variabilities between the applications of a target domain and through the development of comprehensive and variability-covering domain models. The domain models developed within the software product line development process need to cover all of the possible features and aspects of the target domain. In other words, the domain models often described using feature models should be elaborate representations of the feature space of that domain. In order to operationalize feature-based representations of a software application, appropriate implementation mechanisms need to be employed. In this paper, we propose a Semantic Web-oriented language, called Semantic Annotations for Feature Modeling Description Language (SAFMDL) that provides the means to semantically describe feature models. We will show that using SAFMDL along with Semantic Web Query techniques, we are able to bridge the gap between software product lines and SOA technology. Our proposed work allows software practitioners to use Semantic Web technology to quickly and rapidly develop new software products based on SOA technology from software product lines.},
booktitle = {Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {287–300},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {CASCON '11}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Systematic literature review, Software product lines, Machine learning, Configurable systems}
}

@inproceedings{10.5555/1885639.1885661,
author = {Stricker, Vanessa and Metzger, Andreas and Pohl, Klaus},
title = {Avoiding redundant testing in application engineering},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Many software product line testing techniques have been presented in the literature. The majority of those techniques address how to define reusable test assets (such as test models or test scenarios) in domain engineering and how to exploit those assets during application engineering. In addition to test case reuse however, the execution of test cases constitutes one important activity during application testing. Without a systematic support for the test execution in application engineering, while considering the specifics of product lines, product line artifacts might be tested redundantly. Redundant testing in application engineering, however, can lead to an increased testing effort without increasing the chance of uncovering failures. In this paper, we propose the model-based ScenTED-DF technique to avoid redundant testing in application engineering. Our technique builds on data flow-based testing techniques for single systems and adapts and extends those techniques to consider product line variability. The paper sketches the prototypical implementation of our technique to show its general feasibility and automation potential, and it describes the results of experiments using an academic product line to demonstrate that ScenTED-DF is capable of avoiding redundant tests in application engineering.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {226–240},
numpages = {15},
keywords = {application engineering, data flow, regression testing, software product line testing},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.1007/s00766-014-0216-9,
author = {Karata\c{s}, Ahmet Serkan and O\u{g}uzt\"{u}z\"{u}n, Halit},
title = {Attribute-based variability in feature models},
year = {2016},
issue_date = {June      2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-014-0216-9},
doi = {10.1007/s00766-014-0216-9},
abstract = {Extended feature models enable the expression of complex cross-tree constraints involving feature attributes. The inclusion of attributes in cross-tree relations not only enriches the constraints, but also engenders an extended type of variability that involves attributes. In this article, we elaborate on the effects of this new variability type on feature models. We start by analyzing the nature of the variability involving attributes and extend the definitions of the configuration and the product to suit the emerging requirements. Next, we propose classifications for the features, configurations, and products to identify and formalize the ramifications that arise due to the new type of variability. Then, we provide a semantic foundation grounded on constraint satisfaction for our proposal. We introduce an ordering relation between configurations and show that the set of all the configurations represented by a feature model forms a semilattice. This is followed by a demonstration of how the feature model analyses will be affected using illustrative examples selected from existing and novel analysis operations. Finally, we summarize our experiences, gained from a commercial research and development project that employs an extended feature model.},
journal = {Requir. Eng.},
month = jun,
pages = {185–208},
numpages = {24},
keywords = {Extended feature models, Software product lines, Variability involving attributes, Variability management}
}

@inproceedings{10.1145/3183440.3183499,
author = {Mukelabai, Mukelabai and Behringer, Benjamin and Fey, Moritz and Palz, Jochen and Kr\"{u}ger, Jacob and Berger, Thorsten},
title = {Multi-view editing of software product lines with PEoPL},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183499},
doi = {10.1145/3183440.3183499},
abstract = {A software product line is a portfolio of software variants in an application domain. It relies on a platform integrating common and variable features of the variants using variability mechanisms---typically classified into annotative and compositional mechanisms. Annotative mechanisms (e.g., using the C preprocessor) are easy to apply, but annotations clutter source code and feature code is often scattered across the platform, which hinders program comprehension and increases maintenance effort. Compositional mechanisms (e.g., using feature modules) support program comprehension and maintainability by modularizing feature code, but are difficult to adopt. Most importantly, engineers need to choose one mechanism and then stick to it for the whole life cycle of the platform. The PEoPL (Projectional Editing of Product Lines) approach combines the advantages of both kinds of mechanisms. In this paper, we demonstrate the PEoPL IDE, which supports the approach by providing various kinds of editable views, each of which represents the same software product line using annotative or compositional variability mechanisms, or subsets of concrete variants. Software engineers can seamlessly switch these views, or use multiple views side-by-side, based on the current engineering task. A demo video of PEoPL is available at Youtube: https://youtu.be/wByUxSPLoSY},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {81–84},
numpages = {4},
keywords = {annotative, modular, product lines, projectional editing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.infsof.2006.08.001,
author = {Sinnema, Marco and Deelstra, Sybren},
title = {Classifying variability modeling techniques},
year = {2007},
issue_date = {July, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {7},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.08.001},
doi = {10.1016/j.infsof.2006.08.001},
abstract = {Variability modeling is important for managing variability in software product families, especially during product derivation. In the past few years, several variability modeling techniques have been developed, each using its own concepts to model the variability provided by a product family. The publications regarding these techniques were written from different viewpoints, use different examples, and rely on a different technical background. This paper sheds light on the similarities and differences between six variability modeling techniques, by exemplifying the techniques with one running example, and classifying them using a framework of key characteristics for variability modeling. It furthermore discusses the relation between differences among those techniques, and the scope, size, and application domain of product families.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {717–739},
numpages = {23},
keywords = {Classification, Software product family, Variability management, Variability modeling}
}

@inproceedings{10.1145/1987875.1987886,
author = {Belategi, Lorea and Sagardui, Goiuria and Etxeberria, Leire},
title = {Model based analysis process for embedded software product lines},
year = {2011},
isbn = {9781450307307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987875.1987886},
doi = {10.1145/1987875.1987886},
abstract = {Nowadays, embedded system development is increasing its complexity dealing with quality, cost and time-to-market among others. Quality attributes are an important issue to consider in embedded software development where time issues may be critical. Development paradigms such as Model Driven Development and Software Product Lines can be an adequate alternative to traditional software development and validation methods due to the characteristics of embedded systems. But for a proper validation and verification based on MARTE model analysis, all variability issues and critical quality attributes that take part in analysis must be properly modelled and managed. Therefore, a model analysis process for Model Driven Embedded Software Product Lines has been defined as some process lacks have been found.},
booktitle = {Proceedings of the 2011 International Conference on Software and Systems Process},
pages = {53–62},
numpages = {10},
keywords = {model based analysis process, model driven development, performance, quality attributes, schedulability, software product line},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSSP '11}
}

@article{10.1007/s10009-012-0250-1,
author = {Wong, Peter Y. and Albert, Elvira and Muschevici, Radu and Proen\c{c}a, Jos\'{e} and Sch\"{a}fer, Jan and Schlatte, Rudolf},
title = {The ABS tool suite: modelling, executing and analysing distributed adaptable object-oriented systems},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0250-1},
doi = {10.1007/s10009-012-0250-1},
abstract = {Modern software systems must support a high degree of variability to accommodate a wide range of requirements and operating conditions. This paper introduces the Abstract Behavioural Specification (ABS) language and tool suite, a comprehensive platform for developing and analysing highly adaptable distributed concurrent software systems. The ABS language has a hybrid functional and object- oriented core, and comes with extensions that support the development of systems that are adaptable to diversified requirements, yet capable to maintain a high level of trustworthiness. Using ABS, system variability is consistently traceable from the level of requirements engineering down to object behaviour. This facilitates temporal evolution, as changes to the required set of features of a system are automatically reflected by functional adaptation of the system's behaviour. The analysis capabilities of ABS stretch from debugging, observing and simulating to resource analysis of ABS models and help ensure that a system will remain dependable throughout its evolutionary lifetime. We report on the experience of using the ABS language and the ABS tool suite in an industrial case study.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {567–588},
numpages = {22},
keywords = {Concurrency, Feature modelling, Formal modelling and analysis, Software product line, Tool support, Variability}
}

@inproceedings{10.1007/978-3-642-39031-9_10,
author = {Silva, Eduardo and Medeiros, Ana Luisa and Cavalcante, Everton and Batista, Thais},
title = {A lightweight language for software product lines architecture description},
year = {2013},
isbn = {9783642390302},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39031-9_10},
doi = {10.1007/978-3-642-39031-9_10},
abstract = {The architecture description of a software product line (SPL) is essential to make it clear how the architecture realizes the feature model and to represent both the domain and application engineering architectural artefacts. However, most architecture description languages (ADLs) for SPL have limited support regarding variability management and they do not express the relationship between features and the architecture, besides the lack of tools for graphical and textual modelling and a non-clear separation between the domain and application engineering activities. In order to overcome these deficiencies, this paper presents LightPL-ACME, an ADL whose main goal is to be a simple, lightweight language for the SPL architecture description, and enable the association between the architectural specification and the artefacts involved in the SPL development process, including the relationship with the feature model and the representation of both domain and application engineering elements.},
booktitle = {Proceedings of the 7th European Conference on Software Architecture},
pages = {114–121},
numpages = {8},
keywords = {ACME, LightPL-ACME, architecture description languages, software product lines architectures},
location = {Montpellier, France},
series = {ECSA'13}
}

@inproceedings{10.1145/1456659.1456662,
author = {Chapman, Mark and van der Merwe, Alta},
title = {Contemplating systematic software reuse in a project-centric company},
year = {2008},
isbn = {9781605582863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1456659.1456662},
doi = {10.1145/1456659.1456662},
abstract = {Systematic software reuse is still the most promising strategy for increasing productivity and improving quality in the software industry. Although it is simple in concept, successful software reuse implementation is difficult in practice. A reason put forward for this is the dependence of software reuse on the context in which it is implemented. This paper describes an interpretive case study aimed at investigating the potential for the implementation of systematic software reuse in a project-centric company. The study confirmed the need for systematic software reuse and identified the reuse issues that could present challenges. The study also revealed a number of problems relating to the project-centric structure for which systematic reuse provides potential solutions.},
booktitle = {Proceedings of the 2008 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries: Riding the Wave of Technology},
pages = {16–26},
numpages = {11},
keywords = {action research, ethnography, interpretive case study, project-centric, software product line engineering, software product lines, software reuse, systematic software reuse},
location = {Wilderness, South Africa},
series = {SAICSIT '08}
}

@article{10.1016/j.jss.2009.06.048,
author = {Khurum, Mahvish and Gorschek, Tony},
title = {A systematic review of domain analysis solutions for product lines},
year = {2009},
issue_date = {December, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {12},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.048},
doi = {10.1016/j.jss.2009.06.048},
abstract = {Domain analysis is crucial and central to software product line engineering (SPLE) as it is one of the main instruments to decide what to include in a product and how it should fit in to the overall software product line. For this reason many domain analysis solutions have been proposed both by researchers and industry practitioners. Domain analysis comprises various modeling and scoping activities. This paper presents a systematic review of all the domain analysis solutions presented until 2007. The goal of the review is to analyze the level of industrial application and/or empirical validation of the proposed solutions with the purpose of mapping maturity in terms of industrial application, as well as to what extent proposed solutions might have been evaluated in terms of usability and usefulness. The finding of this review indicates that, although many new domain analysis solutions for software product lines have been proposed over the years, the absence of qualitative and quantitative results from empirical application and/or validation makes it hard to evaluate the potential of proposed solutions with respect to their usability and/or usefulness for industry adoption. The detailed results of the systematic review can be used by individual researchers to see large gaps in research that give opportunities for future work, and from a general research perspective lessons can be learned from the absence of validation as well as from good examples presented. From an industry practitioner view, the results can be used to gauge as to what extent solutions have been applied and/or validated and in what manner, both valuable as input prior to industry adoption of a domain analysis solution.},
journal = {J. Syst. Softw.},
month = dec,
pages = {1982–2003},
numpages = {22},
keywords = {Domain analysis, Domain modeling, Domain scoping, Empirical evidence, Systematic review, Usability, Usefulness}
}

@inproceedings{10.1145/2188286.2188304,
author = {Tawhid, Rasha and Petriu, Dorina},
title = {User-friendly approach for handling performance parameters during predictive software performance engineering},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188304},
doi = {10.1145/2188286.2188304},
abstract = {A Software Product Line (SPL) is a set of similar software systems that share a common set of features. Instead of building each product from scratch, SPL development takes advantage of the reusability of the core assets shared among the SPL members. In this work, we integrate performance analysis in the early phases of SPL development process, applying the same reusability concept to the performance annotations. Instead of annotating from scratch the UML model of every derived product, we propose to annotate the SPL model once with generic performance annotations. After deriving the model of a product from the family model by an automatic transformation, the generic performance annotations need to be bound to concrete product-specific values provided by the developer. Dealing manually with a large number of performance annotations, by asking the developer to inspect every diagram in the generated model and to extract these annotations is an error-prone process. In this paper we propose to automate the collection of all generic parameters from the product model and to present them to the developer in a user-friendly format (e.g., a spreadsheet per diagram, indicating each generic parameter together with guiding information that helps the user in providing concrete binding values). There are two kinds of generic parametric annotations handled by our approach: product-specific (corresponding to the set of features selected for the product) and platform-specific (such as device choices, network connections, middleware, and runtime environment). The following model transformations for (a) generating a product model with generic annotations from the SPL model, (b) building the spreadsheet with generic parameters and guiding information, and (c) performing the actual binding are all realized in the Atlas Transformation Language (ATL).},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {109–120},
numpages = {12},
keywords = {atl, marte, model-driven development, performance completion, performance model, spl, uml},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@inproceedings{10.1109/ASE.2009.11,
author = {Gr\"{u}nbacher, Paul and Rabiser, Rick and Dhungana, Deepak and Lehofer, Martin},
title = {Model-Based Customization and Deployment of Eclipse-Based Tools: Industrial Experiences},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.11},
doi = {10.1109/ASE.2009.11},
abstract = {Developers of software engineering tools are facing high expectations regarding capabilities and usability. Users expect tools tailored to their specific needs and integrated in their working environment. This increases tools' complexity and complicates their customization and deployment despite available mechanisms for adaptability and extensibility. A main challenge lies in understanding and managing the dependencies between different technical mechanisms for realizing tool variability. We report on industrial experiences of applying a model-based and tool-supported product line approach for the customization and deployment of two Eclipse-based tools. We illustrate challenges of customizing these tools to different development contexts: In the first case study we developed variability models of a product line tool suite used by an industry partner and utilized these models for tool customization and deployment. In the second case study we applied the same approach to a maintenance and setup tool of our industry partner. Our experiences suggest to design software tools as product lines; to formally describe the tools' variability in models; and to provide end-user capabilities for customizing and deploying the tools.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {247–256},
numpages = {10},
keywords = {Elicpse-based tools, deployment, end-user customization, industrial experience, product line engineering},
series = {ASE '09}
}

@inproceedings{10.5555/1885639.1885667,
author = {Bagheri, Ebrahim and Asadi, Mohsen and Gasevic, Dragan and Soltani, Samaneh},
title = {Stratified analytic hierarchy process: prioritization and selection of software features},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product line engineering allows for the rapid development of variants of a domain specific application by using a common set of reusable assets often known as core assets. Variability modeling is a critical issue in product line engineering, where the use of feature modeling is one of most commonly used formalisms. To support an effective and automated derivation of concrete products for a product family, staged configuration has been proposed in the research literature. In this paper, we propose the integration of well-known requirements engineering principles into stage configuration. Being inspired by the well-established Preview requirements engineering framework, we initially propose an extension of feature models with capabilities for capturing business oriented requirements. This representation enables a more effective capturing of stakeholders' preferences over the business requirements and objectives (e.g.,. implementation costs or security) in the form of fuzzy linguistic variables (e.g., high, medium, and low). On top of this extension, we propose a novel method, the Stratified Analytic Hierarchy process, which first helps to rank and select the most relevant high level business objectives for the target stakeholders (e.g., security over implementation costs), and then helps to rank and select the most relevant features from the feature model to be used as the starting point in the staged configuration process. Besides a complete formalization of the process, we define the place of our proposal in existing software product line lifecycles as well as demonstrate the use of our proposal on the widely-used e-Shop case study. Finally, we report on the results of our user study, which indicates a high appreciation of the proposed method by the participating industrial software developers. The tool support for S-AHP is also introduced.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {300–315},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using multi-objective search and machine learning to infer rules constraining product configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.},
journal = {Automated Software Engg.},
month = jun,
pages = {1–62},
numpages = {62},
keywords = {Product line, Configuration, Rule mining, Multi-objective search, Machine learning, Interacting products}
}

@article{10.1016/j.infsof.2012.09.006,
author = {Behjati, Razieh and Yue, Tao and Briand, Lionel and Selic, Bran},
title = {SimPL: A product-line modeling methodology for families of integrated control systems},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.09.006},
doi = {10.1016/j.infsof.2012.09.006},
abstract = {Context: Integrated control systems (ICSs) are heterogeneous systems where software and hardware components are integrated to control and monitor physical devices and processes. A family of ICSs share the same software code base, which is configured differently for each product to form a unique installation. Due to the complexity of ICSs and inadequate automation support, product configuration in this context is typically error-prone and costly. Objective: As a first step to overcome these challenges, we propose a UML-based product-line modeling methodology that provides a foundation for semi-automated product configuration in the specific context of ICSs. Method: We performed a comprehensive domain analysis to identify characteristics of ICS families, and their configuration challenges. Based on this, we formulated the characteristics of an adequate configuration solution, and derived from them a set of modeling requirements for a model-based solution to configuration. The SimPL methodology is proposed to fulfill these requirements. Results: To evaluate the ability of SimPL to fulfill the modeling requirements, we applied it to a large-scale industrial case study. Our experience with the case study shows that SimPL is adequate to provide a model of the product family that meets the modeling requirements. Further evaluation is still required to assess the applicability and scalability of SimPL in practice. Doing this requires conducting field studies with human subjects and is left for future work. Conclusion: We conclude that configuration in ICSs requires better automation support, and UML-based approaches to product family modeling can be tailored to provide the required foundation.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {607–629},
numpages = {23},
keywords = {Integrated control systems, MARTE, Product-line engineering, UML, Variability modeling}
}

@inproceedings{10.1145/3377812.3381399,
author = {Abbas, Muhammad},
title = {Variability aware requirements reuse analysis},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3381399},
doi = {10.1145/3377812.3381399},
abstract = {Problem: The goal of a software product line is to aid quick and quality delivery of software products, sharing common features. Effectively achieving the above-mentioned goals requires reuse analysis of the product line features. Existing requirements reuse analysis approaches are not focused on recommending product line features, that can be reused to realize new customer requirements. Hypothesis: Given that the customer requirements are linked to product line features' description satisfying them: then the customer requirements can be clustered based on patterns and similarities, preserving the historic reuse information. New customer requirements can be evaluated against existing customer requirements and reuse of product line features can be recommended. Contributions: We treated the problem of feature reuse analysis as a text classification problem at the requirements-level. We use Natural Language Processing and clustering to recommend reuse of features based on similarities and historic reuse information. The recommendations can be used to realize new customer requirements.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {190–193},
numpages = {4},
keywords = {product line, requirements, similarities, software reuse, variability},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1007/s11219-011-9153-8,
author = {Mussbacher, Gunter and Ara\'{u}jo, Jo\~{a}o and Moreira, Ana and Amyot, Daniel},
title = {AoURN-based modeling and analysis of software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9153-8},
doi = {10.1007/s11219-011-9153-8},
abstract = {Software Product Line Engineering concerns itself with domain engineering and application engineering. During domain engineering, the whole product family is modeled with a preferred flavor of feature models and additional models as required (e.g., domain models or scenario-based models). During application engineering, the focus shifts toward a single family member and the configuration of the member's features. Recently, aspectual concepts have been employed to better encapsulate individual features of a Software Product Line (SPL), but the existing body of SPL work does not include a unified reasoning framework that integrates aspect-oriented feature description artifacts with the capability to reason about stakeholders' goals while taking feature interactions into consideration. Goal-oriented SPL approaches have been proposed, but do not provide analysis capabilities that help modelers meet the needs of the numerous stakeholders involved in an SPL while at the same time considering feature interactions. We present an aspect-oriented SPL approach for the requirements phase that allows modelers (a) to capture features, goals, and scenarios in a unified framework and (b) to reason about stakeholders' needs and perform trade-off analyses while considering undesirable interactions that are not obvious from the feature model. The approach is based on the Aspect-oriented User Requirements Notation (AoURN) and helps identify, prioritize, and choose products based on analysis results provided by AoURN editor and analysis tools. We apply the AoURN-based SPL framework to the Via Verde SPL to demonstrate the feasibility of this approach through the selection of a Via Verde product configuration that satisfies stakeholders' needs and results in a high-level, scenario-based specification that is free from undesirable feature interactions.},
journal = {Software Quality Journal},
month = sep,
pages = {645–687},
numpages = {43},
keywords = {Aspect-oriented modeling, Feature interactions, Goal-based requirements engineering, Scenario-based requirements engineering, Software product lines, User Requirements Notation}
}

@article{10.5555/3044222.3051232,
author = {Montalvillo, Leticia and D\'{\i}az, Oscar},
title = {Requirement-driven evolution in software product lines},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
abstract = {We conducted a systematic mapping study on SPL evolution.We identified 107 relevant contributions on the topic up to mid 2015.We elaborated on the traditional change mini-cycle to classify the contributions.We identified well-established topics, trends and open research issues. CONTEXT. Software Product Lines (SPLs) aim to support the development of a whole family of software products through systematic reuse of shared assets. As SPLs exhibit a long life-span, evolution is an even greater concern than for single-systems. For the purpose of this work, evolution refers to the adaptation of the SPL as a result of changing requirements. Hence, evolution is triggered by requirement changes, and not by bug fixing or refactoring.OBJECTIVE. Research on SPL evolution has not been previously mapped. This work provides a mapping study along Petersen's and Kichenham's guidelines, to identify strong areas of knowledge, trends and gaps.RESULTS. We identified 107 relevant contributions. They were classified according to four facets: evolution activity (e.g., identify, analyze and plan, implement), product-derivation approach (e.g., annotation-based, composition-based), research type (e.g., solution, experience, evaluation), and asset type (i.e., variability model, SPL architecture, code assets and products).CONCLUSION. Analyses of the results indicate that "Solution proposals" are the most common type of contribution (31%). Regarding the evolution activity, "Implement change" (43%) and "Analyze and plan change" (37%) are the most covered ones. A finer-grained analysis uncovered some tasks as being underexposed. A detailed description of the 107 papers is also included.},
journal = {J. Syst. Softw.},
month = dec,
pages = {110–143},
numpages = {34},
keywords = {Evolution, Software product lines, Systematic mapping study}
}

@inproceedings{10.1007/978-3-642-33666-9_19,
author = {Kulkarni, Vinay and Barat, Souvik and Roychoudhury, Suman},
title = {Towards business application product lines},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_19},
doi = {10.1007/978-3-642-33666-9_19},
abstract = {With continued increase in business dynamics, it is becoming increasingly harder to deliver purpose-specific business systems in the ever-shrinking window of opportunity. Code-centric software product line engineering (SPLE) techniques show unacceptable responsiveness as business applications are subjected to changes along multiple dimensions that continue to evolve simultaneously. Through clear separation of functional concerns from technology, model-driven approaches enable easy delivery of the same functionality into multiple technology platforms. However, business systems for same functional intent tend to have similar but non-identical functionality. This makes a strong case for bringing in SPLE ideas i.e., what can change where and when, to models. We propose an abstraction that aims to address composition, variability and resolution in a unified manner; describe its model-based realization; and outline the key enablers necessary for raising business application product lines. Early experience of our approach and issues that remain to be addressed for industry acceptance are highlighted.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {285–301},
numpages = {17},
keywords = {model driven engineering, software product lines},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1109/ISORCW.2011.18,
author = {Tawhid, Rasha and Petriu, Dorina C.},
title = {Product Model Derivation by Model Transformation in Software Product Lines},
year = {2011},
isbn = {9780769543772},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISORCW.2011.18},
doi = {10.1109/ISORCW.2011.18},
abstract = {Product derivation is an essential part of the Software Product Line (SPL) development process. The paperproposes a model transformation for deriving automatically a UML model of a specific product from the UML model of a product line. This work is a part of a larger project aiming to integrate performance analysis in the SPL model-driven development. The SPL source model is expressed in UML extended with two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The automatic derivation of a concrete product model based on a given feature configuration is enabled through the mapping between features from the feature model and their realizations in the design model. The paper proposes an efficient mapping technique that aims to minimize the amount of explicit feature annotations in the UML design model of SPL. Implicit feature mapping is inferred during product derivation from the relationships between annotated and non-annotated model elements as defined in the UML metamodel and well formedness rules. The transformation is realized in the Atlas Transformation Language (ATL) and illustrated with an ecommerce case study that models structural and behavioural SPL views.},
booktitle = {Proceedings of the 2011 14th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
pages = {72–79},
numpages = {8},
keywords = {ATL, Feature Mapping, MARTE, SPL, UML},
series = {ISORCW '11}
}

@inproceedings{10.1145/3023956.3023959,
author = {Ochoa, Lina and Pereira, Juliana Alves and Gonz\'{a}lez-Rojas, Oscar and Castro, Harold and Saake, Gunter},
title = {A survey on scalability and performance concerns in extended product lines configuration},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023959},
doi = {10.1145/3023956.3023959},
abstract = {Product lines have been employed as a mass customisation method that reduces production costs and time-to-market. Multiple product variants are represented in a product line, however the selection of a particular configuration depends on stakeholders' functional and non-functional requirements. Methods like constraint programming and evolutionary algorithms have been used to support the configuration process. They consider a set of product requirements like resource constraints, stakeholders' preferences, and optimization objectives. Nevertheless, scalability and performance concerns start to be an issue when facing large-scale product lines and runtime environments. Thus, this paper presents a survey that analyses strengths and drawbacks of 21 approaches that support product line configuration. This survey aims to: i) evidence which product requirements are currently supported by studied methods; ii) how scalability and performance is considered in existing approaches; and iii) point out some challenges to be addressed in future research.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {5–12},
numpages = {8},
keywords = {configuration, literature review, performance, product line, product requirements, scalability, survey},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.5555/2667025.2667027,
author = {Siegmund, Norbert and Mory, Maik and Feigenspan, Janet and Saake, Gunter and Nykolaychuk, Mykhaylo and Schumann, Marco},
title = {Interoperability of non-functional requirements in complex systems},
year = {2012},
isbn = {9781467318532},
publisher = {IEEE Press},
abstract = {Heterogeneity of embedded systems leads to the development of variable software, such as software product lines. From such a family of programs, stakeholders select the specific variant that satisfies their functional requirements. However, different functionality exposes different non-functional properties of these variants. Especially in the embedded-system domain, non-functional requirements are vital, because resources are scarce. Hence, when selecting an appropriate variant, we have to fulfill also non-functional requirements. Since more systems are interconnected, the challenge is to find a variant that additionally satisfies global nonfunctional (or quality) requirements. In this paper, we advert the problem of achieving interoperability of non-functional requirements among multiple interacting systems using a real-world scenario. Furthermore, we show an approach to find optimal variants for multiple systems that reduces computation effort by means of a stepwise configuration process.},
booktitle = {Proceedings of the Second International Workshop on Software Engineering for Embedded Systems},
pages = {2–8},
numpages = {7},
location = {Zurich, Switzerland},
series = {SEES '12}
}

@article{10.1016/j.eswa.2014.05.049,
author = {Mizouni, Rabeb and Matar, Mohammad Abu and Mahmoud, Zaid Al and Alzahmi, Salwa and Salah, Aziz},
title = {A framework for context-aware self-adaptive mobile applications SPL},
year = {2014},
issue_date = {November, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {16},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.05.049},
doi = {10.1016/j.eswa.2014.05.049},
abstract = {Mobile Applications are rapidly emerging as a convenient medium for using a variety of services. Over time and with the high penetration of smartphones in society, self-adaptation has become an essential capability required by mobile application users. In an ideal scenario, an application is required to adjust its behavior according to the current context of its use. This raises the challenge in mobile computing towards the design and development of applications that sense and react to contextual changes to provide a value-added user experience. In its general sense, context information can relate to the environment, the user, or the device status. In this paper, we propose a novel framework for building context aware and adaptive mobile applications. Based on feature modeling and Software Product Lines (SPL) concepts, this framework guides the modeling of adaptability at design time and supports context awareness and adaptability at runtime. In the core of the approach, is a feature meta-model that incorporates, in addition to SPL concepts, application feature priorities to drive the adaptability. A tool, based on that feature model, is presented to model the mobile application features and to derive the SPL members. A mobile framework, built on top of OSGI framework to dynamically adapt the application at runtime is also described.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {7549–7564},
numpages = {16},
keywords = {Feature priority, Mobile devices, Multi-view variability model, Runtime adaptability, SPL}
}

@article{10.1016/j.jss.2013.06.034,
author = {Alf\'{e}rez, G. H. and Pelechano, V. and Mazo, R. and Salinesi, C. and Diaz, D.},
title = {Dynamic adaptation of service compositions with variability models},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.06.034},
doi = {10.1016/j.jss.2013.06.034},
abstract = {Web services run in complex contexts where arising events may compromise the quality of the whole system. Thus, it is desirable to count on autonomic mechanisms to guide the self-adaptation of service compositions according to changes in the computing infrastructure. One way to achieve this goal is by implementing variability constructs at the language level. However, this approach may become tedious, difficult to manage, and error-prone. In this paper, we propose a solution based on a semantically rich variability model to support the dynamic adaptation of service compositions. When a problematic event arises in the context, this model is leveraged for decision-making. The activation and deactivation of features in the variability model result in changes in a composition model that abstracts the underlying service composition. These changes are reflected into the service composition by adding or removing fragments of Business Process Execution Language (WS-BPEL) code, which can be deployed at runtime. In order to reach optimum adaptations, the variability model and its possible configurations are verified at design time using Constraint Programming. An evaluation demonstrates several benefits of our approach, both at design time and at runtime.},
journal = {J. Syst. Softw.},
month = may,
pages = {24–47},
numpages = {24},
keywords = {Autonomic computing, Constraint programming, Dynamic adaptation, Dynamic software product line, Models at runtime, Variability, Verification, Web service composition}
}

@inproceedings{10.1007/978-3-319-35122-3_27,
author = {Pereira, Juliana Alves and Krieter, Sebastian and Meinicke, Jens and Schr\"{o}ter, Reimar and Saake, Gunter and Leich, Thomas},
title = {FeatureIDE: Scalable Product Configuration of Variable Systems},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_27},
doi = {10.1007/978-3-319-35122-3_27},
abstract = {In the last decades, variability management for similar products is one of the main challenges in software systems. In this context, feature models are used to describe the dependencies between reusable common and variable artifacts, called features. However, for large feature models it is a complex task to find a valid feature combination as product configuration. Our Eclipse plug-in FeatureIDE provides several mechanisms, such as information hiding and decision propagation, which support the configuration process to combine the reusable artifacts in various manners. We illustrate the applications of these mechanisms from a user's point of view.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {397–401},
numpages = {5},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@article{10.1007/s10270-010-0186-4,
author = {Perrouin, Gilles and Vanwormhoudt, Gilles and Morin, Brice and Lahire, Philippe and Barais, Olivier and J\'{e}z\'{e}quel, Jean-Marc},
title = {Weaving variability into domain metamodels},
year = {2012},
issue_date = {July      2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-010-0186-4},
doi = {10.1007/s10270-010-0186-4},
abstract = {Domain-specific modeling languages (DSMLs) are the essence of MDE. A DSML describes the concepts of a particular domain in a metamodel, as well as their relationships. Using a DSML, it is possible to describe a wide range of different models that often share a common base and vary on some parts. On the one hand, some current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a significant overhead in product line engineering. On the other hand, approaches integrating variability in DSMLs lack generality and tool support. We argue that aspect-oriented modeling techniques enabling flexible metamodel composition and results obtained by the software product line community to manage and resolve variability form the pillars for a solution for integrating variability into DSMLs. In this article, we consider variability as an independent and generic aspect to be woven into the DSML. In particular, we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variability into two different metamodels: Ecore--widely used for DSML definition--and SmartAdapters, our aspect model weaver. These results emphasize how new abilities of the language can be provided by this means.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {361–383},
numpages = {23},
keywords = {Domain specific languages, Model weaving, Variability and software product lines}
}

@inproceedings{10.1145/2424563.2424575,
author = {Zaid, Lamia Abo and De Troyer, Olga},
title = {Modelling and managing variability with feature assembly: an experience report},
year = {2012},
isbn = {9781450318112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2424563.2424575},
doi = {10.1145/2424563.2424575},
abstract = {Feature models have been commonly used to model the variability and commonality in software product lines. We have defined the Feature Assembly Modelling, a feature modelling technique that allows to model variability in software adopting a multi perspective approach. Furthermore, the approach allows modelling software by combining both variability and reusability, i.e. we have developed an approach to take reusability into account while defining new software. To support the approach, we have also developed an information retrieval framework that provides an interactive visualization of the feature models. The visualization allows users to explore and query the existing models. In this paper, we report on our experience in introducing this variability modelling approach into a small-scale software company. This experience was very useful for both parties. The company was able to uncover the structure of their software and the modelling exercise provided them better insight in their products. For us, it has helped to better understand the needs of companies, to evaluate the usability of our Feature Assembly approach and the associated learning curve, as well as revealing its current limitations. Moreover, as we are aware of the fact that classical feature modelling is not yet a practice adopted by companies, it was interesting to see that our approach was well accepted and appreciated by the company.},
booktitle = {Proceedings of the Second Edition of the International Workshop on Experiences and Empirical Studies in Software Modelling},
articleno = {9},
numpages = {7},
keywords = {Feature Assembly, experience report, feature models, software product lines, variability, variability management},
location = {Innsbruck, Austria},
series = {EESSMod '12}
}

@article{10.1016/j.is.2010.01.001,
author = {Benavides, David and Segura, Sergio and Ruiz-Cort\'{e}s, Antonio},
title = {Automated analysis of feature models 20 years later: A literature review},
year = {2010},
issue_date = {September, 2010},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {35},
number = {6},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2010.01.001},
doi = {10.1016/j.is.2010.01.001},
abstract = {Software product line engineering is about producing a set of related products that share more commonalities than variabilities. Feature models are widely used for variability and commonality management in software product lines. Feature models are information models where a set of products are represented as a set of features in a single model. The automated analysis of feature models deals with the computer-aided extraction of information from feature models. The literature on this topic has contributed with a set of operations, techniques, tools and empirical results which have not been surveyed until now. This paper provides a comprehensive literature review on the automated analysis of feature models 20 years after of their invention. This paper contributes by bringing together previously disparate streams of work to help shed light on this thriving area. We also present a conceptual framework to understand the different proposals as well as categorise future contributions. We finally discuss the different studies and propose some challenges to be faced in the future.},
journal = {Inf. Syst.},
month = sep,
pages = {615–636},
numpages = {22},
keywords = {Automated analyses, Feature models, Literature review, Software product lines}
}

@inproceedings{10.1145/2451436.2451449,
author = {Barbosa, Fernando S\'{e}rgio and Aguiar, Ademar},
title = {Using roles to model crosscutting concerns},
year = {2013},
isbn = {9781450317665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451436.2451449},
doi = {10.1145/2451436.2451449},
abstract = {In object oriented languages the problem of crosscutting concerns, due to limitations in the composition mechanisms, is recurrent. In order to reduce this problem we propose to use roles as a way of composing classes that extends the Object Oriented approach and can be used to model crosscutting concerns. To support our approach we developed a role language that extends Java, while being compatible with existing virtual machines. As validation we conducted a case study using three open source systems. We identified crosscutting concerns in the systems and then modeled them using our role approach. Results show that roles are a viable option for modeling crosscutting concerns.},
booktitle = {Proceedings of the 12th Annual International Conference on Aspect-Oriented Software Development},
pages = {97–108},
numpages = {12},
keywords = {code reuse, composition, crosscutting concerns, modularity, roles},
location = {Fukuoka, Japan},
series = {AOSD '13}
}

@article{10.1016/j.is.2012.11.010,
author = {Gr\"{o}Ner, Gerd and Bo\v{s}Kovi\'{c}, Marko and Silva Parreiras, Fernando and Ga\v{s}Evi\'{c}, Dragan},
title = {Modeling and validation of business process families},
year = {2013},
issue_date = {July, 2013},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {38},
number = {5},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2012.11.010},
doi = {10.1016/j.is.2012.11.010},
abstract = {Process modeling is an expensive task that needs to encompass requirements of different stakeholders, assure compliance with different standards, and enable the flexible adaptivity to newly emerging requirements in today's dynamic global market. Identifying reusability of process models is a promising direction towards reducing the costs of process modeling. Recent research has offered several solutions. Such solutions promote effective and formally sound methods for variability modeling and configuration management. However, ensuring behavioral validity of reused process models with respect to the original process models (often referred to as reference process models) is still an open research challenge. To address this challenge, in this paper, we propose the notion of business process families by building upon the well-known software engineering discipline-software product line engineering. Business process families comprise (i) a variability modeling perspective, (ii) a process model template (or reference model), and (iii) mappings between (i) and (ii). For business process families, we propose a correct validation algorithm ensuring that each member of a business process family adheres to the core intended behavior that is specified in the process model template. The proposed validation approach is based on the use of Description Logics, variability is represented by using the well-known Feature Models and behavior of process models is considered in terms of control flow patterns. The paper also reports on the experience gained in two external trial cases and results obtained by measuring the tractability of the implementation of the proposed validation approach.},
journal = {Inf. Syst.},
month = jul,
pages = {709–726},
numpages = {18},
keywords = {Business process families, Control flow relations, Process model configuration, Process model variability, Validation}
}

@article{10.1016/j.infsof.2010.03.014,
author = {Alves, Vander and Niu, Nan and Alves, Carina and Valen\c{c}a, George},
title = {Requirements engineering for software product lines: A systematic literature review},
year = {2010},
issue_date = {August, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.03.014},
doi = {10.1016/j.infsof.2010.03.014},
abstract = {Context: Software product line engineering (SPLE) is a growing area showing promising results in research and practice. In order to foster its further development and acceptance in industry, it is necessary to assess the quality of the research so that proper evidence for adoption and validity are ensured. This holds in particular for requirements engineering (RE) within SPLE, where a growing number of approaches have been proposed. Objective: This paper focuses on RE within SPLE and has the following goals: assess research quality, synthesize evidence to suggest important implications for practice, and identify research trends, open problems, and areas for improvement. Method: A systematic literature review was conducted with three research questions and assessed 49 studies, dated from 1990 to 2009. Results: The evidence for adoption of the methods is not mature, given the primary focus on toy examples. The proposed approaches still have serious limitations in terms of rigor, credibility, and validity of their findings. Additionally, most approaches still lack tool support addressing the heterogeneity and mostly textual nature of requirements formats as well as address only the proactive SPLE adoption strategy. Conclusions: Further empirical studies should be performed with sufficient rigor to enhance the body of evidence in RE within SPLE. In this context, there is a clear need for conducting studies comparing alternative methods. In order to address scalability and popularization of the approaches, future research should be invested in tool support and in addressing combined SPLE adoption strategies.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {806–820},
numpages = {15},
keywords = {Requirements engineering, Software product lines, Systematic literature review}
}

@inproceedings{10.1007/978-3-030-73128-1_1,
author = {Abbas, Muhammad and Ferrari, Alessio and Shatnawi, Anas and Enoiu, Eduard Paul and Saadatmand, Mehrdad},
title = {Is Requirements Similarity a Good Proxy for Software Similarity? An Empirical Investigation in Industry},
year = {2021},
isbn = {978-3-030-73127-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-73128-1_1},
doi = {10.1007/978-3-030-73128-1_1},
abstract = {[Context and Motivation] Content-based recommender systems for requirements are typically built on the assumption that similar requirements can be used as proxies to retrieve similar software. When a new requirement is proposed by a stakeholder, natural language processing (NLP)-based similarity metrics can be exploited to retrieve existing requirements, and in turn identify previously developed code. [Question/problem] Several NLP approaches for similarity computation are available, and there is little empirical evidence on the adoption of an effective technique in recommender systems specifically oriented to requirements-based code reuse. [Principal ideas/results] This study compares different state-of-the-art NLP approaches and correlates the similarity among requirements with the similarity of their source code. The evaluation is conducted on real-world requirements from two industrial projects in the railway domain. Results show that requirements similarity computed with the traditional tf-idf approach has the highest correlation with the actual software similarity in the considered context. Furthermore, results indicate a moderate positive correlation with Spearman’s rank correlation coefficient of more than 0.5. [Contribution] Our work is among the first ones to explore the relationship between requirements similarity and software similarity. In addition, we also identify a suitable approach for computing requirements similarity that reflects software similarity well in an industrial context. This can be useful not only in recommender systems but also in other requirements engineering tasks in which similarity computation is relevant, such as tracing and categorization.},
booktitle = {Requirements Engineering:  Foundation  for Software Quality: 27th International Working Conference, REFSQ 2021, Essen, Germany, April 12–15, 2021, Proceedings},
pages = {3–18},
numpages = {16},
keywords = {Requirements similarity, Software similarity, Correlation}
}

@article{10.1145/2581376,
author = {Behjati, Razieh and Nejati, Shiva and Briand, Lionel C.},
title = {Architecture-Level Configuration of Large-Scale Embedded Software Systems},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2581376},
doi = {10.1145/2581376},
abstract = {Configuration in the domain of Integrated Control Systems (ICS) is largely manual, laborious, and error prone. In this article, we propose a model-based configuration approach that provides automation support for reducing configuration effort and the likelihood of configuration errors in the ICS domain. We ground our approach on component-based specifications of ICS families. We then develop a configuration algorithm using constraint satisfaction techniques over finite domains to generate products that are consistent with respect to their ICS family specifications. We reason about the termination and consistency of our configuration algorithm analytically. We evaluate the effectiveness of our configuration approach by applying it to a real subsea oil production system. Specifically, we have rebuilt a number of existing verified product configurations of our industry partner. Our experience shows that our approach can automatically infer up to 50% of the configuration decisions, and reduces the complexity of making configuration decisions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {25},
numpages = {43},
keywords = {Model-based product-line engineering, UML/OCL, consistent configuration, constraint satisfaction techniques, formal specification, product configuration}
}

@inproceedings{10.1109/ICSE-C.2017.154,
author = {Pereira, Juliana Alves},
title = {Runtime collaborative-based configuration of software product lines},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.154},
doi = {10.1109/ICSE-C.2017.154},
abstract = {Software Product Line (SPL) configuration practices have been employed by industries as a mass customization process. However, the inherent variability of large SPLs leads to configuration spaces of exponential sizes. Thus, scalability and performance concerns start to be an issue when facing runtime environments, since it is usually infeasible to explore the entire configuration space exhaustively. In this context, the aim of my research is therefore to propose an efficient collaborative-based runtime approach that relies on recommender techniques to provide accurate and scalable configurations to users. To demonstrate the efficiency of the proposed approach, I conduct series of experiments on real-world SPLs. In addition, I plan empirically verify through a user case study the usability of the proposed approach. My expected contribution is to support the adoption of SPL configuration practices in industrial scenarios.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {94–96},
numpages = {3},
keywords = {collaborative-based recommendations, configuration, recommender systems, software product lines},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@article{10.1016/j.jss.2017.11.004,
author = {Carvalho, Michelle Larissa Luciano and da Silva, Matheus Lessa Gonalves and Gomes, Gecynalda Soares da Silva and Santos, Alcemir Rodrigues and Machado, Ivan do Carmo and Souza, Magno Lu de Jesus and de Almeida, Eduardo Santana},
title = {On the implementation of dynamic software product lines},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {136},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.11.004},
doi = {10.1016/j.jss.2017.11.004},
abstract = {A set of criteria to characterize mechanisms suitable to implement dynamic variability.A characterization of thirteen DSPL-ready variability mechanisms.Empirical evaluation of OOP and AOP from the perspective of DSPL evolution.Evidence showing that AOP is a feasible strategy to implement DSPL projects. Dynamic Software Product Line (DSPL) engineering is a paradigm aimed at handling adaptations at runtime. An inherent challenge in DSPL engineering is to reduce the design complexity of adaptable software, particularly in terms of evolution. Existing research only recently started to investigate evolution in this field, but does not assess the impact of different implementations under software quality in evolutionary scenarios. This work presents a characterization of thirteen dynamic variability mechanisms. Based on such characterization, we implemented a DSPL using Object-oriented Programming (OOP) mechanisms. From this implementation, we evidenced that DSPL requires changes and extensions to design, in terms of functionality and adaptation capabilities. Since Aspect-oriented Programming (AOP) was well ranked according to characterization and some studies have demonstrated the likely synergies between AOP and DSPL, we decided to compare it with OOP. We empirically evaluated how OOP and AOP could affect source code quality from the viewpoint of an evolving DSPL. As a result, AOP yields better results in terms of size, SoC, cohesion, and coupling measures. Conversely, AOP provides lower change propagation impact. Although the packages in AOP were more susceptible to changes than in OOP, we could indicate that AOP may be a feasible strategy for DSPL implementation.},
journal = {J. Syst. Softw.},
month = feb,
pages = {74–100},
numpages = {27},
keywords = {Dynamic software product lines, Evidence-based software engineering, Software evolution, Variability mechanisms}
}

@inproceedings{10.1145/3377024.3377036,
author = {Sprey, Joshua and Sundermann, Chico and Krieter, Sebastian and Nieke, Michael and Mauro, Jacopo and Th\"{u}m, Thomas and Schaefer, Ina},
title = {SMT-based variability analyses in FeatureIDE},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3377036},
doi = {10.1145/3377024.3377036},
abstract = {Handling configurable systems with thousands of configuration options is a challenging problem in research and industry. One of the most common approaches to manage the configuration options of large systems is variability modelling. The verification and configuration process of large variability models is manually infeasible. Hence, they are usually assisted by automated analyses based on solving satisfiability problems (SAT). Recent advances in satisfiability modulo theories (SMT) could prove SMT solvers as a viable alternative to SAT solvers. However, SMT solvers are typically not utilized for variability analyses. A comparison for SAT and SMT could help to estimate SMT solvers potential for the automated analysis. We integrated two SMT solvers into FeatureIDE and compared them against a SAT solver on analyses for feature models, configurations, and realization artifacts. We give an overview of all variability analyses in FeatureIDE and present the results of our empirical evaluation for over 122 systems. We observed that SMT solvers are generally faster in generating explanations of unsatisfiable requests. However, the evaluated SAT solver outperformed SMT solvers for other analyses.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {9},
keywords = {SAT, SAT analysis, SAT vs SMT, SMT, SMT analysis, attribute optimization, configuration analysis, feature attributes, feature model analysis, feature models, preprocessor analysis, variability analysis},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.5555/1332044.1332081,
author = {Noda, Atsushi and Nakanishi, Tsuneo and Kitasuka, Teruaki and Fukuda, Akira},
title = {Introducing fault tree analysis into product line software engineering for exception handling feature exploitation},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {In product line software development, developers recognize functional and non-functional features of the product members of a product line, analyze commonality and variability of the product members in terms of their equipping features, and construct or acquire core assets with consideration of reusability. The method proposed in this paper is for reusability of exception handling that are considerable parts of products. The proposing method exploits exception handling features with using fault tree analysis (or FTA), reflects the exploited features in the feature diagram, and enables management of core assets with keeping traceability from feature diagram. The proposing method reduces omission of exception handling, moreover, manages the constructed fault tree as a core asset and enables derivation of fault trees of product members of the product line to use them for improving safety and reliability.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {229–234},
numpages = {6},
keywords = {exception handling, fault tree analysis, feature diagram, software product family, software product line},
location = {Innsbruck, Austria},
series = {SE'07}
}

@article{10.1145/3428225,
author = {Shahin, Ramy and Chechik, Marsha},
title = {Automatic and efficient variability-aware lifting of functional programs},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428225},
doi = {10.1145/3428225},
abstract = {A software analysis is a computer program that takes some representation of a software product as input and produces some useful information about that product as output. A software product line encompasses many software product variants, and thus existing analyses can be applied to each of the product variations individually, but not to the entire product line as a whole. Enumerating all product variants and analyzing them one by one is usually intractable due to the combinatorial explosion of the number of product variants with respect to product line features. Several software analyses (e.g., type checkers, model checkers, data flow analyses) have been redesigned/re-implemented to support variability. This usually requires a lot of time and effort, and the variability-aware version of the analysis might have new errors/bugs that do not exist in the original one. Given an analysis program written in a functional language based on PCF, in this paper we present two approaches to transforming (lifting) it into a semantically equivalent variability-aware analysis. A light-weight approach (referred to as shallow lifting) wraps the analysis program into a variability-aware version, exploring all combinations of its input arguments. Deep lifting, on the other hand, is a program rewriting mechanism where the syntactic constructs of the input program are rewritten into their variability-aware counterparts. Compositionally this results in an efficient program semantically equivalent to the input program, modulo variability. We present the correctness criteria for functional program lifting, together with correctness proof sketches of shallow lifting. We evaluate our approach on a set of program analyses applied to the BusyBox C-language product line.},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {157},
numpages = {27},
keywords = {Lifting, PCF, Program Rewriting, Software Product Lines, Variability-aware Programming}
}

@inproceedings{10.1145/2305484.2305491,
author = {Pleuss, Andreas and Hauptmann, Benedikt and Dhungana, Deepak and Botterweck, Goetz},
title = {User interface engineering for software product lines: the dilemma between automation and usability},
year = {2012},
isbn = {9781450311687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2305484.2305491},
doi = {10.1145/2305484.2305491},
abstract = {Software Product Lines (SPL) are systematic approach to develop families of similar software products by explicating their commonalities and variability, e.g., in a feature model. Using techniques from model-driven development, it is then possible to automatically derive a concrete product from a given configuration (i.e., selection of features). However, this is problematic for interactive applications with complex user interfaces (UIs) as automatically derived UIs often provide limited usability. Thus, in practice, the UI is mostly created manually for each product, which results in major drawbacks concerning efficiency and maintenance, e.g., when applying changes that affect the whole product family. This paper investigates these problems based on real-world examples and analyses the development of product families from a UI perspective. To address the underlying challenges, we propose the use of abstract UI models, as used in HCI, to bridge the gap between automated, traceable product derivation and customized, high quality user interfaces. We demonstrate the feasibility of the approach by a concrete example implementation for the suggested model-driven development process.},
booktitle = {Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {25–34},
numpages = {10},
keywords = {model-driven development, software product lines, usability engineering, user interface engineering},
location = {Copenhagen, Denmark},
series = {EICS '12}
}

@inproceedings{10.1145/3243734.3243739,
author = {Ispoglou, Kyriakos K. and AlBassam, Bader and Jaeger, Trent and Payer, Mathias},
title = {Block Oriented Programming: Automating Data-Only Attacks},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243739},
doi = {10.1145/3243734.3243739},
abstract = {With the widespread deployment of Control-Flow Integrity (CFI), control-flow hijacking attacks, and consequently code reuse attacks, are significantly more difficult. CFI limits control flow to well-known locations, severely restricting arbitrary code execution. Assessing the remaining attack surface of an application under advanced control-flow hijack defenses such as CFI and shadow stacks remains an open problem. We introduce BOPC, a mechanism to automatically assess whether an attacker can execute arbitrary code on a binary hardened with CFI/shadow stack defenses. BOPC computes exploits for a target program from payload specifications written in a Turing-complete, high-level language called SPL that abstracts away architecture and program-specific details. SPL payloads are compiled into a program trace that executes the desired behavior on top of the target binary. The input for BOPC is an SPL payload, a starting point (e.g., from a fuzzer crash) and an arbitrary memory write primitive that allows application state corruption. To map SPL payloads to a program trace, BOPC introduces Block Oriented Programming (BOP), a new code reuse technique that utilizes entire basic blocks as gadgets along valid execution paths in the program, i.e., without violating CFI or shadow stack policies. We find that the problem of mapping payloads to program traces is NP-hard, so BOPC first reduces the search space by pruning infeasible paths and then uses heuristics to guide the search to probable paths. BOPC encodes the BOP payload as a set of memory writes. We execute 13 SPL payloads applied to 10 popular applications. BOPC successfully finds payloads and complex execution traces -- which would likely not have been found through manual analysis -- while following the target's Control-Flow Graph under an ideal CFI policy in 81% of the cases.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1868–1882},
numpages = {15},
keywords = {binary analysis, block oriented programming, data only attacks, exploitation, program synthesis},
location = {Toronto, Canada},
series = {CCS '18}
}

@inproceedings{10.1145/3434780.3436640,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a Pe\~{n}alvo, Francisco Jos\'{e} and Theron, Roberto},
title = {Advances in the use of domain engineering to support feature identification and generation of information visualizations},
year = {2021},
isbn = {9781450388504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434780.3436640},
doi = {10.1145/3434780.3436640},
abstract = {Information visualization tools are widely used to better understand large and complex datasets. However, to make the most out of them, it is necessary to rely on proper designs that consider not only the data to be displayed, but also the audience and the context. There are tools that already allow users to configure their displays without requiring programming skills, but this research project aims at exploring the automatic generation of information visualizations and dashboards in order to avoid the configuration process, and select the most suitable features of these tools taking into account their contexts. To address this problem, a domain engineering, and machine learning approach is proposed.},
booktitle = {Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {1053–1056},
numpages = {4},
keywords = {Automatic generation, Domain engineering, High-level requirements, Information Dashboards, Machine Learning, Meta-modeling},
location = {Salamanca, Spain},
series = {TEEM'20}
}

@inproceedings{10.1007/978-3-662-54494-5_25,
author = {Damiani, Ferruccio and H\"{a}hnle, Reiner and Kamburjan, Eduard and Lienhardt, Michael},
title = {A Unified and Formal Programming Model for Deltas and Traits},
year = {2017},
isbn = {9783662544938},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-54494-5_25},
doi = {10.1007/978-3-662-54494-5_25},
abstract = {This paper presents a unified model for two complementary approaches of code reuse: Traits and Delta-Oriented Programming DOP. Traits are used to modularly construct classes, while DOP is a modular approach to construct Software Product Lines. In this paper, we identify the common structure of these two approaches, present a core calculus that combine Traits and DOP in a unified framework, provide an implementation for the ABS modelling language, and illustrate its application in an industrial modeling scenario.},
booktitle = {Proceedings of the 20th International Conference on Fundamental Approaches to Software Engineering - Volume 10202},
pages = {424–441},
numpages = {18}
}

@article{10.1504/IJKESDP.2013.052716,
author = {Elfaki, Abdelrahman Osman and Fong, Sim Liew and Aik, Kevin Loo Teow and Johar, Md Gapar Md},
title = {Towards detecting redundancy in domain engineering process using first order logic rules},
year = {2013},
issue_date = {March 2013},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {4},
number = {1},
issn = {1755-3210},
url = {https://doi.org/10.1504/IJKESDP.2013.052716},
doi = {10.1504/IJKESDP.2013.052716},
abstract = {Software product line SPL is an emerging methodology for developing software products. SPL consists of two processes: domain-engineering and application-engineering. Successful software product is highly dependent on the validity of a domain engineering process. Therefore, validation is a significant process within the domain-engineering. Anomalies such as dead feature, redundancy, and wrong-cardinality are well-known problems in SPL. In the literature, redundancy did not take the signs of attentions as a dead feature and wrong-cardinality. The maturity of the SPL can be enhanced by detecting and removing the redundancy from the domain engineering. This paper proposes first order logic FOL rules for detecting the redundancy in domain-engineering process. Detecting redundancy in the domain engineering direct is our contribution. Our methodology comprised of three steps: 1 variability is modelled in the form of predicates as a prerequisite; 2 for each type of the redundancy, a general form is formulated to swathe all possible cases; 3 FOL rules are illustrated to implement each possibility based on deducing the results from predefined cases. As a result, all forms of redundancies in the domain-engineering process are amorphous. Finally, experiments are conducted to attest the scalability of our method.},
journal = {Int. J. Knowl. Eng. Soft Data Paradigm.},
month = mar,
pages = {1–20},
numpages = {20}
}

@inproceedings{10.1145/3276604.3276609,
author = {Guerra, Esther and de Lara, Juan and Chechik, Marsha and Salay, Rick},
title = {Analysing meta-model product lines},
year = {2018},
isbn = {9781450360296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276604.3276609},
doi = {10.1145/3276604.3276609},
abstract = {Model-driven engineering advocates the use of models to describe and automate many software development tasks. The syntax of modelling languages is defined by meta-models, making them essential artefacts. A combination of product line engineering methods and meta-models has been proposed to enable specification of modelling language variants, e.g., to describe a range of systems. However, there is a lack of techniques for ensuring syntactic correctness of all meta-models within a family (including their OCL constraints), and semantic correctness related to properties of individual instances of the different variants. The absence of verification methods at the product-line level can cause synthesis of ill-formed meta-models and problematic feature combinations whose effect at the instance level may go unnoticed.  To attack this problem, we propose an approach to lifting both the meta-model syntax checking and the satisfiability checking of properties of individual meta-model instances, to the product-line level. We validate the approach via a prototype tool called Merlin, and report on several experiments that show the advantages of our method w.r.t. an enumerative analysis approach.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {160–173},
numpages = {14},
keywords = {Meta-Modelling, Model Finding, Model-Driven Engineering, OCL, Product Lines},
location = {Boston, MA, USA},
series = {SLE 2018}
}

@inproceedings{10.1145/2568225.2568267,
author = {Salay, Rick and Famelis, Michalis and Rubin, Julia and Di Sandro, Alessio and Chechik, Marsha},
title = {Lifting model transformations to product lines},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568267},
doi = {10.1145/2568225.2568267},
abstract = {Software product lines and model transformations are two techniques used in industry for managing the development of highly complex software. Product line approaches simplify the handling of software variants while model transformations automate software manipulations such as refactoring, optimization, code generation, etc. While these techniques are well understood independently, combining them to get the benefit of both poses a challenge because most model transformations apply to individual models while model-level product lines represent sets of models. In this paper, we address this challenge by providing an approach for automatically ``lifting'' model transformations so that they can be applied to product lines. We illustrate our approach using a case study and evaluate it through a set of experiments.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {117–128},
numpages = {12},
keywords = {Model Driven Engineering, Model Transformations, Software Product Lines},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/1404946.1404950,
author = {Hubaux, A. and Heymans, P. and Unphon, H.},
title = {Separating variability concerns in a product line re-engineering project},
year = {2008},
isbn = {9781605581439},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1404946.1404950},
doi = {10.1145/1404946.1404950},
abstract = {Feature diagrams have now become common variability models in software product lines engineering literature. Whereas ongoing research keeps improving their expressiveness, formalisation, and automation, open studies of their usage in real projects are still missing. This paper intends to (1) present the process we followed to elicit the variability of PloneMeeting, an Open Source project, and (2) report on the initial results obtained when applying variability modelling techniques promoting separation of concerns between software variability and product line variability.},
booktitle = {Proceedings of the 2008 AOSD Workshop on Early Aspects},
articleno = {4},
numpages = {8},
keywords = {feature diagram, open source, separation of concerns, software product lines, variability management, variability model},
location = {Brussels, Belgium},
series = {EA '08}
}

@article{10.1145/3229096,
author = {Logre, Ivan and D\'{e}ry-Pinna, Anne-Marie},
title = {MDE in Support of Visualization Systems Design: a Multi-Staged Approach Tailored for Multiple Roles},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {EICS},
url = {https://doi.org/10.1145/3229096},
doi = {10.1145/3229096},
abstract = {Visualization systems such as dashboards are commonly used to analyze data and support users in their decision making, in communities as different as medical care, transport and software engineering. The increasing amount of data produced and continuous development of new visualizations exacerbate the difficulty of designing such dashboards, while the visualization need is broaden to specialist and non-specialist final users. In this context, we offer a multi-user approach, based on Model Driven Engineering (MDE). The idea is for the designer to express the visualization need by characterization, according to a given taxonomy. We provide a Domain Specific Language (DSL) to design the system and a Software Product Line (SPL) to capture the technological variability of visualization widgets. We performed a user study, using a software project management use case, to validate if dashboard users and designers are able to use a taxonomy to express their visualization need.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {14},
numpages = {17},
keywords = {domain specific language, meta-model, visualization}
}

@inproceedings{10.1145/375212.375269,
author = {Gacek, Critina and Anastasopoules, Michalis},
title = {Implementing product line variabilities},
year = {2001},
isbn = {1581133588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/375212.375269},
doi = {10.1145/375212.375269},
abstract = {Software product lines have numerous members. Thus, a product line infrastructure must cover various systems. This is the significant difference to usual software systems and the reason for additional requirements on the various assets present during software product line engineering. It is imperative that they support the description of the product line as a whole, as well as its instantiation for the derivation of individual products.Literature has already addressed how to create and instantiate generic product line assets, such as domain models and architectures to generate instance specific ones [1, 2, 3], yet little attention has been given on how to actually deal with this genericity at the code level.This paper addresses the issue of handling product line variability at the code level. To this end various implementation approaches are examined with respect to their use in a product line context.},
booktitle = {Proceedings of the 2001 Symposium on Software Reusability: Putting Software Reuse in Context},
pages = {109–117},
numpages = {9},
keywords = {implementation approaches, implementing variabilities, product line variability, software product lines, traceability},
location = {Toronto, Ontario, Canada},
series = {SSR '01}
}

@inproceedings{10.5555/1885639.1885676,
author = {Mannion, Mike and Savolainen, Juha},
title = {Aligning business and technical strategies for software product lines},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A successful software product line strategy has business goals, a business strategy, a target market and a technical strategy that is aligned with the business goals and the target market. A common challenge in a number of organizations is for business and engineering units to understand what business and technical strategy alignment actually means in practice and to maintain that alignment as business goals and target markets evolve. If they are misaligned, then at best significant development inefficiencies occur, and at worst there is loss of market share. This paper explains different business and technical strategies, describes commonly used engineering techniques to manage commonality and variability and their deployment under different strategies.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {406–419},
numpages = {14},
keywords = {business alignment, business strategy, feature modeling, product lines, software architecture},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.1007/s11219-011-9170-7,
author = {Acher, Mathieu and Collet, Philippe and Gaignard, Alban and Lahire, Philippe and Montagnat, Johan and France, Robert B.},
title = {Composing multiple variability artifacts to assemble coherent workflows},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9170-7},
doi = {10.1007/s11219-011-9170-7},
abstract = {The development of scientific workflows is evolving toward the systematic use of service-oriented architectures, enabling the composition of dedicated and highly parameterized software services into processing pipelines. Building consistent workflows then becomes a cumbersome and error-prone activity as users cannot manage such large-scale variability. This paper presents a rigorous and tooled approach in which techniques from Software Product Line (SPL) engineering are reused and extended to manage variability in service and workflow descriptions. Composition can be facilitated while ensuring consistency. Services are organized in a rich catalog which is organized as a SPL and structured according to the common and variable concerns captured for all services. By relying on sound merging techniques on the feature models that make up the catalog, reasoning about the compatibility between connected services is made possible. Moreover, an entire workflow is then seen as a multiple SPL (i.e., a composition of several SPLs). When services are configured within, the propagation of variability choices is then automated with appropriate techniques and the user is assisted in obtaining a consistent workflow. The approach proposed is completely supported by a combination of dedicated tools and languages. Illustrations and experimental validations are provided using medical imaging pipelines, which are representative of current scientific workflows in many domains.},
journal = {Software Quality Journal},
month = sep,
pages = {689–734},
numpages = {46},
keywords = {Composition, Feature models, Scientific workflows, Software product lines}
}

@article{10.1145/1968587.1968597,
author = {Fricker, Samuel and Seyff, Norbert},
title = {1st international requirements engineering efficiency workshop: REEW 2011},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/1968587.1968597},
doi = {10.1145/1968587.1968597},
abstract = {Requirements engineering research has for a long time focused on specification quality, leading to recommendations of how to engineer "perfect" requirements specifications. Practitioners, however, do not have the time, resources, and interests for overdoing requirements engineering. Rather, many situations call for shortcuts that allow investing effort in those concerns that are critical for success, while reducing effort in other areas where risk is comparably smaller. The social context, smart collaboration processes, and novel ways of looking at the interface between stakeholders and the supplier can be a basis to increase the yield of requirements engineering, while reducing required effort.The International Requirements Engineering Efficiency Workshop (REEW 2011) aimed at initiating, facilitating, and nurturing the discussion on efficient approaches to engineer just goodenough requirements. Requirements engineering was seen as a means that can be simplified, automated, or combined with other practices to achieve successful systems in an economically efficient manner. REEW 2011 provided a platform for the community of practitioners and research experts that are interested in productivity-enhancing approaches to requirements engineering. This report describes the workshop results including tactics, practice, and trade-offs for achieving requirements engineering efficiency.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {26–28},
numpages = {3},
keywords = {efficiency, pragmatism, productivity, requirements engineering, software engineering}
}

@inproceedings{10.1145/2110147.2110154,
author = {Steffens, Michaela and Oster, Sebastian and Lochau, Malte and Fogdal, Thomas},
title = {Industrial evaluation of pairwise SPL testing with MoSo-PoLiTe},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110154},
doi = {10.1145/2110147.2110154},
abstract = {Testing Software Product Lines is a very challenging task due to variability. Frequently, approaches such as combinatorial testing are used to generate representative sets of products for testing purposes instead of testing each individual product of the SPL under test. In this contribution we present the results of applying the MoSo-PoLiTe framework at Danfoss Power Electronics A/S to calculate a representative set of product configurations for black box testing purposes. Within this evaluation we use MoSo-PoLiTe's pairwise configuration selection component on the basis of a feature model. This component implements a heuristics finding a minimal subset of configurations covering 100% T-wise feature interaction. According to the best of our knowledge, this is the first publication providing industrial results about pairwise SPL testing.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {55–62},
numpages = {8},
keywords = {combinatorial testing, evaluation, feature model-based testing, pairwise testing, product lines},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@inproceedings{10.1007/978-3-642-33666-9_34,
author = {Vierhauser, Michael and Gr\"{u}nbacher, Paul and Heider, Wolfgang and Holl, Gerald and Lettner, Daniela},
title = {Applying a consistency checking framework for heterogeneous models and artifacts in industrial product lines},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_34},
doi = {10.1007/978-3-642-33666-9_34},
abstract = {Product line engineering relies on heterogeneous models and artifacts to define and implement the product line's reusable assets. The complexity and heterogeneity of product line artifacts as well as their interdependencies make it hard to maintain consistency during development and evolution, regardless of the modeling approaches used. Engineers thus need support for detecting and resolving inconsistencies within and between the various artifacts. In this paper we present a framework for checking and maintaining consistency of arbitrary product line artifacts. Our approach is flexible and extensible regarding the supported artifact types and the definition of constraints. We discuss tool support developed for the DOPLER product line tool suite. We report the results of applying the approach to sales support applications of industrial product lines.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {531–545},
numpages = {15},
keywords = {consistency checking, model-based product lines, sales support},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/2480362.2480596,
author = {Ara\'{u}jo, Jo\~{a}o and Goul\~{a}o, Miguel and Moreira, Ana and Sim\~{a}o, In\^{e}s and Amaral, Vasco and Baniassad, Elisa},
title = {Advanced modularity for building SPL feature models: a model-driven approach},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480596},
doi = {10.1145/2480362.2480596},
abstract = {Feature Models are commonly used to specify commonalities and variabilities in Software Product Lines (SPL). Our goal is to enhance feature modeling with traceability and improved support for crosscutting concerns. While traceability will show the features' requirement-origins, providing means to reason about their existence, crosscutting concerns will be handled through advanced modularity mechanisms (e.g. aspects), making the impact of changes to SPL models less difficult to understand and analyze. The result is Theme/SPL, a novel SPL requirements technique based on a concern-driven approach (Theme/Doc). Theme/SPL includes the proposal of a domain-specific language for specifying Theme/Doc models and uses model-driven development to generate automatically feature models from them. We show the applicability of the technique through a case study using a within-group design to evaluate the final results and tools developed.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1246–1253},
numpages = {8},
keywords = {advanced modularity, model-driven development, software product lines},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/1944892.1944894,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Th\"{u}m, Thomas and Saake, Gunter},
title = {Multi-dimensional variability modeling},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944894},
doi = {10.1145/1944892.1944894},
abstract = {The variability of a software product line (SPL)is often described with a feature model. To avoid highly complex models, stakeholders usually try to separate different variability dimensions, such as domain variability and implementation variability. This results in distinct variability models, which are easier to handle than one large model. On the other hand, it is sometimes required to analyze the variability dimensions of an SPL in combination using a single model only. To combine separate modeling and integrated analysis of variability, we present Velvet, a language for multi-dimensional variability modeling. Velvet allows stakeholders to model each variability dimension of an SPL separately and to compose the separated dimensions on demand. This improves reuse of feature models and supports independent modeling variability dimensions. Furthermore, Velvet integrates feature modeling and configuration in a single language. The combination of both concepts creates further reuse opportunities and allows stakeholders to independently configure variability dimensions.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {11–20},
numpages = {10},
keywords = {feature models, separation of concerns, variability modeling},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@article{10.1016/j.jss.2019.01.044,
author = {Th\"{u}m, Thomas and Kn\"{u}ppel, Alexander and Kr\"{u}ger, Stefan and Bolle, Stefanie and Schaefer, Ina},
title = {Feature-oriented contract composition},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.01.044},
doi = {10.1016/j.jss.2019.01.044},
journal = {J. Syst. Softw.},
month = jun,
pages = {83–107},
numpages = {25},
keywords = {Feature-oriented programming, Software product lines, Design by contract, Deductive verification, Formal methods}
}

@article{10.1145/3089649.3089657,
author = {Sahu, Madhusmita and Mohapatra, Durga Prasad},
title = {Computing Dynamic Slices of Feature--Oriented Programs Using Execution Trace File},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/3089649.3089657},
doi = {10.1145/3089649.3089657},
abstract = {Feature-Oriented Programming (FOP) is a general paradigm for synthesizing programs in software product lines. A family of software systems constitutes a software product line (SPL). The unique characteristics of feature-oriented programs such as mixin layers, refinements of classes, refinements of constructors, constants, refinements, etc. pose special difficulties in the slicing of these programs. This paper proposes a dynamic slicing algorithm for feature-oriented programs. The algorithm is named Execution Trace File Based Feature-Oriented Dynamic Slicing (ETBFODS) algorithm. The ETBFODS algorithm uses a dependence based representation called Dynamic Feature Composition Dependence Graph (DFCDG) and an execution trace file to store execution history of the program for a given input. The dynamic slice is computed by traversing the DFCDG in breadth--first or depth-first wise and then mapping the resultant traversed vertices to the program statements.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jun,
pages = {1–16},
numpages = {16},
keywords = {Dynamic Slicing, Execution Trace File, Feature-Oriented Programming, Jak language, Mixin layer}
}

@inproceedings{10.5555/2666719.2666730,
author = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
title = {Software feature model recommendations using data mining},
year = {2012},
isbn = {9781467317597},
publisher = {IEEE Press},
abstract = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation.},
booktitle = {Proceedings of the Third International Workshop on Recommendation Systems for Software Engineering},
pages = {47–51},
numpages = {5},
keywords = {design decisions, feature models, range ranking},
location = {Zurich, Switzerland},
series = {RSSE '12}
}

@inproceedings{10.5555/1025115.1025267,
author = {Rauschmayer, Axel and Knapp, Alexander and Wirsing, Martin},
title = {Consistency Checking in an Infrastructure for Large-Scale Generative Programming},
year = {2004},
isbn = {0769521312},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Ubiquitous computing increases the pressure on the software industry to produce ever more and error-free code. Two recipes from automated programming are available to meet this challenge: On the one hand, generative programming raises the level of abstraction in software development by describing problems in high-level domain-specific languages and making them executable. On the other hand, in situations where one needs to produce a family of similar programs, product line engineering supports code reuse by composing programs from a set of common assets (or features). AHEAD (Algebraic Hierarchical Equations for Application Design) is a framework for generative programming and product line engineering that achieves additional productivity gains by scaling feature composition up. Our contribution is GRAFT, a calculus that gives a formal foundation to AHEAD and provides several mechanisms for making sure that feature combinations are legal and that features in themselves are consistent.},
booktitle = {Proceedings of the 19th IEEE International Conference on Automated Software Engineering},
pages = {238–247},
numpages = {10},
series = {ASE '04}
}

@article{10.1007/s10009-014-0341-2,
author = {Filho, Jo\~{a}o Bosco and Barais, Olivier and Acher, Mathieu and Le Noir, J\'{e}r\^{o}me and Legay, Axel and Baudry, Benoit},
title = {Generating counterexamples of model-based software product lines},
year = {2015},
issue_date = {October   2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-014-0341-2},
doi = {10.1007/s10009-014-0341-2},
abstract = {In a model-based software product line (MSPL), the variability of the domain is characterized in a variability model and the core artifacts are base models conforming to a modeling language (also called metamodel). A realization model connects the features of the variability model to the base model elements, triggering operations over these elements based on a configuration. The design space of an MSPL is extremely complex to manage for the engineer, since the number of variants may be exponential and the derived product models have to be conforming to numerous well-formedness and business rules. In this paper, the objective is to provide a way to generate MSPLs, called counterexamples (also called antipatterns), that can produce invalid product models despite a valid configuration in the variability model. We describe the foundations and motivate the usefulness of counterexamples (e.g., inference of guidelines or domain-specific rules to avoid earlier the specification of incorrect mappings; testing oracles for increasing the robustness of derivation engines given a modeling language). We provide a generic process, based on the common variability language (CVL) to randomly search the space of MSPLs for a specific modeling language. We develop LineGen a tool on top of CVL and modeling technologies to support the methodology and the process. LineGen targets different scenarios and is flexible to work either with just a domain metamodel as input or also with pre-defined variability models and base models. We validate the effectiveness of this process for three formalisms at different scales (up to 247 metaclasses and 684 rules). We also apply the approach in the context of a real industrial scenario involving a large-scale metamodel.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {585–600},
numpages = {16},
keywords = {Counterexamples, Model-based engineering, Software product lines}
}

@article{10.1016/j.cl.2018.01.003,
author = {Pereira, Juliana Alves and Matuszyk, Pawel and Krieter, Sebastian and Spiliopoulou, Myra and Saake, Gunter},
title = {Personalized recommender systems for product-line configuration processes},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {54},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2018.01.003},
doi = {10.1016/j.cl.2018.01.003},
journal = {Comput. Lang. Syst. Struct.},
month = dec,
pages = {451–471},
numpages = {21},
keywords = {Product lines, Feature model, Product-line configuration, Recommender systems, Personalized recommendations}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {configuration, machine learning, multi-objective search, product line, rule mining},
location = {Berlin, Germany},
series = {GECCO '17}
}

@article{10.1504/IJWET.2015.069359,
author = {Berkane, Mohamed Lamine and Seinturier, Lionel and Boufaida, Mahmoud},
title = {Using variability modelling and design patterns for self-adaptive system engineering: application to smart-home},
year = {2015},
issue_date = {May 2015},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {1},
issn = {1476-1289},
url = {https://doi.org/10.1504/IJWET.2015.069359},
doi = {10.1504/IJWET.2015.069359},
abstract = {Adaptability is an increasingly important requirement for many systems, in particular for those that are deployed in dynamically changing environments. The purpose is to let the systems react and adapt autonomously to changing executing conditions without human intervention. Due to the large number of variability decisions e.g., user needs, environment characteristics and the current lack of reusable adaptation expertise, it becomes increasingly difficult to build a system that satisfies all the requirements and constraints that might arise during its lifetime. In this paper, we propose an approach for developing policies for self-adaptive systems at multiple levels of abstraction. This approach is the first that allows the combination of variability with feature model and reusability with design pattern into a single solution for product derivation that gives strong support to develop self-adaptive systems in a modular way. We demonstrate the feasibility of the proposed approach with a use case based on a smart home scenario.},
journal = {Int. J. Web Eng. Technol.},
month = may,
pages = {65–93},
numpages = {29}
}

@article{10.1016/j.jss.2005.02.028,
author = {Feng, Qian and Lutz, Robyn R.},
title = {Bi-directional safety analysis of product lines},
year = {2005},
issue_date = {November 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {78},
number = {2},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2005.02.028},
doi = {10.1016/j.jss.2005.02.028},
abstract = {As product-line engineering becomes more widespread, more safety-critical software product lines are being built. This paper describes a structured method for performing safety analysis on a software product line, building on standard product-line assets: product-line requirements, architecture, and scenarios. The safety-analysis method is bi-directional in that it combines a forward analysis (from failure modes to effects) with a backward analysis (from hazards to contributing causes). Safety-analysis results are converted to XML files to allow automated consistency checking between the forward and backward analysis results and to support reuse of the safety-analysis results throughout the product line. The paper demonstrates and evaluates the method on a safety-critical product-line subsystem, the Door Control System. Results show that the bi-directional safety-analysis method found both missing and incorrect software safety requirements. Some of the new safety requirements affected all the systems in the product line while others affected only some of the systems in the product line. The results demonstrate that the proposed method can handle the challenges to safety analysis posed by variations within a product line.},
journal = {J. Syst. Softw.},
month = nov,
pages = {111–127},
numpages = {17},
keywords = {Product lines, Reuse, Software architecture, Software safety, XML}
}

@inproceedings{10.1145/3131151.3131162,
author = {Guedes, Gabriela and Silva, Carla and Soares, Monique},
title = {Comparing Configuration Approaches for Dynamic Software Product Lines},
year = {2017},
isbn = {9781450353267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131151.3131162},
doi = {10.1145/3131151.3131162},
abstract = {Dynamic Software Product Lines (DSPLs) are Software Product Lines (SPLs) in which the configuration may occur at runtime. DSPL approaches provide means for modeling variability as well as configuring the product according to its runtime context and/or non-functional requirements (NFRs) satisfaction. In this paper, we present a Requirements Engineering (RE) approach for DSPL, ConG4DaS (Contextual Goal models For Dynamic Software product lines), which provides: (i) models for capturing variability with goals, NFRs, contexts and the relationship between them; and (ii) a configuration process that takes contexts, NFRs and their priority and interactions into account. We have used simulation based assessment to compare ConG4DaS with another approach, REFAS (Requirements Engineering For self-Adaptive Software systems), with respect to the satisfaction level of the highest priority softgoal. For the comparison, we modeled two DSPL examples and simulated different scenarios where reconfiguration is necessary. Next, we compared the configurations selected by the approaches with respect to overall NFRs' satisfaction. The results showed that ConG4DaS, which uses utility function in the configuration process, selects configurations that better satisfy NFRs compared to REFAS, which uses constraint programming.},
booktitle = {Proceedings of the XXXI Brazilian Symposium on Software Engineering},
pages = {134–143},
numpages = {10},
keywords = {Dynamic Software Product Lines, Dynamic Variability, Goal Models, Self-Adaptive Systems},
location = {Fortaleza, CE, Brazil},
series = {SBES '17}
}

@article{10.1007/s10270-017-0641-6,
author = {Li, Yan and Yue, Tao and Ali, Shaukat and Zhang, Li},
title = {Enabling automated requirements reuse and configuration},
year = {2019},
issue_date = {June      2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0641-6},
doi = {10.1007/s10270-017-0641-6},
abstract = {A system product line (PL) often has a large number of reusable and configurable requirements, which in practice are organized hierarchically based on the architecture of the PL. However, the current literature lacks approaches that can help practitioners to systematically and automatically develop structured and configuration-ready PL requirements repositories. In the context of product line engineering and model-based engineering, automatic requirements structuring can benefit from models. Such a structured PL requirements repository can greatly facilitate the development of product-specific requirements repository, the product configuration at the requirements level, and the smooth transition to downstream product configuration phases (e.g., at the architecture design phase). In this paper, we propose a methodology with tool support, named as Zen-ReqConfig, to tackle the above challenge. Zen-ReqConfig is built on existing model-based technologies, natural language processing, and similarity measure techniques. It automatically devises a hierarchical structure for a PL requirements repository, automatically identifies variabilities in textual requirements, and facilitates the configuration of products at the requirements level, based on two types of variability modeling techniques [i.e., cardinality-based feature modeling (CBFM) and a UML-based variability modeling methodology (named as SimPL)]. We evaluated Zen-ReqConfig with five case studies. Results show that Zen-ReqConfig can achieve a better performance based on the character-based similarity measure Jaro than the term-based similarity measure Jaccard. With Jaro, Zen-ReqConfig can allocate textual requirements with high precision and recall, both over 95% on average and identify variabilities in textual requirements with high precision (over 97% on average) and recall (over 94% on average). Zen-ReqConfig achieved very good time performance: with less than a second for generating a hierarchical structure and less than 2 s on average for allocating a requirement. When comparing SimPL and CBFM, no practically significant difference was observed, and they both performed well when integrated with Zen-ReqConfig.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {2177–2211},
numpages = {35},
keywords = {Configuration, Feature model, Product line, Requirements, Reuse}
}

@inproceedings{10.1145/2161996.2161998,
author = {Takeyama, Fuminobu and Chiba, Shigeru},
title = {Feature-oriented programming with family polymorphism},
year = {2012},
isbn = {9781450311014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2161996.2161998},
doi = {10.1145/2161996.2161998},
abstract = {In feature-oriented programming (FOP), code clones are also important issue. Although an approach called a software product line (SPL) enables to implement products efficiently by reusing most of their code, SPLs implemented by FOP contain a lot of code clones. Code clones are often caused by alternative features and we also found clones in derivatives among alternative features. To resolve this problem, we propose a new FOP language named FeatureGluonJ, which supports family polymorphism with revisers. The code clones among alternative features are separated into another feature and can be shared among the alternative features by extending that feature. Furthermore, clones in derivatives can be removed as well.},
booktitle = {Proceedings of the 3rd International Workshop on Variability &amp; Composition},
pages = {1–6},
numpages = {6},
keywords = {family polymorphism, feature-oriented programming, java, software product lines},
location = {Potsdam, Germany},
series = {VariComp '12}
}

@article{10.1007/s00607-018-0646-1,
author = {Galindo, Jos\'{e} A. and Benavides, David and Trinidad, Pablo and Guti\'{e}rrez-Fern\'{a}ndez, Antonio-Manuel and Ruiz-Cort\'{e}s, Antonio},
title = {Automated analysis of feature models: Quo vadis?},
year = {2019},
issue_date = {May       2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {101},
number = {5},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-018-0646-1},
doi = {10.1007/s00607-018-0646-1},
abstract = {Feature models have been used since the 90s to describe software product lines as a way of reusing common parts in a family of software systems. In 2010, a systematic literature review was published summarizing the advances and settling the basis of the area of automated analysis of feature models (AAFM). From then on, different studies have applied the AAFM in different domains. In this paper, we provide an overview of the evolution of this field since 2010 by performing a systematic mapping study considering 423 primary sources. We found six different variability facets where the AAFM is being applied that define the tendencies: product configuration and derivation; testing and evolution; reverse engineering; multi-model variability-analysis; variability modelling and variability-intensive systems. We also confirmed that there is a lack of industrial evidence in most of the cases. Finally, we present where and when the papers have been published and who are the authors and institutions that are contributing to the field. We observed that the maturity is proven by the increment in the number of journals published along the years as well as the diversity of conferences and workshops where papers are published. We also suggest some synergies with other areas such as cloud or mobile computing among others that can motivate further research in the future.},
journal = {Computing},
month = may,
pages = {387–433},
numpages = {47},
keywords = {68T35, Automated analysis, Feature models, Software product lines, Variability-intensive systems}
}

@inproceedings{10.5555/2050167.2050171,
author = {Nunes, Ingrid and Cowan, Donald and Cirilo, Elder and De Lucena, Carlos J. P.},
title = {A case for new directions in agent-oriented software engineering},
year = {2010},
isbn = {9783642226359},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The state-of-the-art of Agent-oriented Software Engineering (AOSE) is insufficiently reflected in the state-of-practice in developing complex distributed systems. This paper discusses software engineering (SE) areas that have not been widely addressed in the context of AOSE, leading to a lack of mechanisms that support the development of Multiagent Systems (MASs) based on traditional SE principles, such as modularity, reusability and maintainability. This discussion is based on an exploratory study of the development of a family of buyer agents following the belief-desire-intention model and using a Software Product Line architecture. Based on the discussion presented in this paper, we hope to encourage the AOSE community to address particular SE issues on the development of MAS that have not yet been (widely) considered.},
booktitle = {Proceedings of the 11th International Conference on Agent-Oriented Software Engineering},
pages = {37–61},
numpages = {25},
keywords = {agent-oriented software engineering, multi-agent systems, software architectures, software product lines, software reuse},
location = {Toronto, Canada},
series = {AOSE'10}
}

@inproceedings{10.5555/2666064.2666066,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Baudry, Benoit and Le Noir, J\'{e}r\^{o}me},
title = {Leveraging variability modeling for multi-dimensional model-driven software product lines},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {In order to be adopted in industrial cases, the Software Product Line paradigm must be adapted to the specific organizational context and culture. In this paper, we consider a scenario of a multinational company that would benefit from SPL. This company uses a model-based software and system development process, which allows them to build reliable and consistent systems for the defence, security, aerospace and transportation domain. Initial efforts to adopt SPL in their software production proved successful. However, they still need to leverage variability modeling to the software and system level, integrating it to their existing model-based development. Therefore, this work aims at (i) presenting an industrial scenario and identifying the main challenges to leverage variability modeling for it, (ii) outlining our point of view and perspectives on how these challenges can be addressed, and (iii) discussing the suitability of current variability modeling approaches.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {5–8},
numpages = {4},
keywords = {model-driven engineering, variability modeling},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1145/3362789.3362923,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco J. and Ther\'{o}n, Roberto},
title = {Automatic generation of software interfaces for supporting decision-making processes. An application of domain engineering and machine learning},
year = {2019},
isbn = {9781450371919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3362789.3362923},
doi = {10.1145/3362789.3362923},
abstract = {Information dashboards are sophisticated tools. Although they enable users to reach useful insights and support their decision-making challenges, a good design process is essential to obtain powerful tools. Users need to be part of these design processes, as they will be the consumers of the information displayed. But users are very diverse and can have different goals, beliefs, preferences, etc., and creating a new dashboard for each potential user is not viable. There exist several tools that allow users to configure their displays without requiring programming skills. However, users might not exactly know what they want to visualize or explore, also becoming the configuration process a tedious task. This research project aims to explore the automatic generation of user interfaces for supporting these decision-making processes. To tackle these challenges, a domain engineering, and machine learning approach is taken. The main goal is to automatize the design process of dashboards by learning from the context, including the end-users and the target data to be displayed.},
booktitle = {Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {1007–1011},
numpages = {5},
keywords = {Automatic generation, Domain engineering, High-level requirements, Information Dashboards, Meta-modeling},
location = {Le\'{o}n, Spain},
series = {TEEM'19}
}

@inproceedings{10.1145/1944892.1944910,
author = {Merschen, Daniel and Polzer, Andreas and Botterweck, Goetz and Kowalewski, Stefan},
title = {Experiences of applying model-based analysis to support the development of automotive software product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944910},
doi = {10.1145/1944892.1944910},
abstract = {In embedded systems in general and in automotive systems in particular the systematic reuse of existing assets is crucial. Moreover, companies in these domains often offer whole families of similar products. Hence, the application of product line engineering seems to be an obvious option.However, current products have reached a complexity level where management of products within a product line cannot be handled with current techniques and tools (e.g. Matlab/Simulink) alone. To sustain an efficient engineering process and to reach the required quality levels of the products, additional techniques are required.In this paper we report on a prototypical framework for the analysis of embedded systems product lines. The techniques and tools offered by the framework were developed to support engineers in typical tasks, which occur during design, implementation, and maintenance of embedded software product lines. The techniques allow to analyse product line artefacts by transforming them into models, which are then used in an analysis process based on model transformation languages.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {141–150},
numpages = {10},
keywords = {Matlab, Simulink, eclipse modeling framework, embedded systems},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.5555/1887899.1887919,
author = {Parra, Carlos and Cleve, Anthony and Blanc, Xavier and Duchien, Laurence},
title = {Feature-based composition of software architectures},
year = {2010},
isbn = {3642151132},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In Software Product Lines variability refers to the definition and utilization of differences between several products. Feature Diagrams (FD) are a well-known approach to express variability, and can be used to automate the derivation process. Nevertheless, this may be highly complex due to possible interactions between selected features and the artifacts realizing them. Deriving concrete products typically involves the composition of such inter-dependent software artifacts. This paper presents a feature-based composition approach to automatically derive a product architecture from a given feature configuration. The proposed approach relies on the combination of Model-Driven Engineering (MDE) and Aspect-Oriented Modeling (AOM) techniques. We introduce a metamodel to reify each feature as a high-level aspect model. Product derivation is achieved by weaving the set of aspect models corresponding to a particular feature configuration. The weaving strategy is derived from an in-depth cross-analysis of both the feature interactions and the aspect model dependencies.},
booktitle = {Proceedings of the 4th European Conference on Software Architecture},
pages = {230–245},
numpages = {16},
location = {Copenhagen, Denmark},
series = {ECSA'10}
}

@inproceedings{10.1145/1944892.1944905,
author = {John, Isabel and Silva, Adeline},
title = {Evaluating variability instantiation strategies for product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944905},
doi = {10.1145/1944892.1944905},
abstract = {Explicit variability management is essential for large product lines and requires explicit strategies for instantiating the managed variabilities during application engineering. An instantiation strategy proposes a certain order for the resolution of variabilities during application engineering or for testing. If an alphabetical strategy is used, for instance, the variabilities are resolved in alphabetical order, from A to Z. In this paper, we motivate the necessity of strategies for large variability models, which help to identify starting points and guide the resolution of variability models.We sketch the application of the strategies in a tool and give the results of an experiment performed to compare the strategies in different situations. The experiment showed that the efficiency of instantiation differs by more than 35% between different strategies. Additionally, the meaningfulness of the instantiation was perceived differently for the various strategies and the strategies were all perceived as being easy to resolve. With the experiment, we managed to demonstrate that the effectiveness of instantiation strategies differs, which motivates the need for different variability instantiation strategies in different situations.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {105–113},
numpages = {9},
keywords = {decisions, instantiation, variability},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@article{10.1016/j.infsof.2012.06.012,
author = {Gamez, Nadia and Fuentes, Lidia},
title = {Architectural evolution of FamiWare using cardinality-based feature models},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.06.012},
doi = {10.1016/j.infsof.2012.06.012},
abstract = {Context: Ambient Intelligence systems domain is an outstanding example of modern systems that are in permanent evolution, as new devices, technologies or facilities are continuously appearing. This means it would be desirable to have a mechanism that helps with the propagation of evolution changes in deployed systems. Objective: We present a software product line engineering process to manage the evolution of FamiWare, a family of middleware for ambient intelligence environments. This process drives the evolution of FamiWare middleware configurations using cardinality-based feature models, which are especially well suited to express the structural variability of ambient intelligence systems. Method: FamiWare uses cardinality-based feature models and clonable features to model the structural variability present in ambient intelligence systems, composed of a large variety of heterogeneous devices. Since the management evolution of configurations with clonable features is manually untreatable due to the high number of features, our process automates it and propagates changes made at feature level to the architectural components of the FamiWare middleware. This is a model driven development process as the evolution management, the propagation of evolution changes and the code generation are performed using some kind of model mappings and transformations. Concretely we present a variability modelling language to map the selection of features to the corresponding FamiWare middleware architectural components. Results: Our process is able to manage the evolution of cardinality-based feature models with thousands of features, something which is not possible to tackle manually. Thanks to the use of the variability language and the automatic code generation it is possible to propagate and maintain a correspondence between the FamiWare architectural model and the code. The process is then able to calculate the architectural differences between the evolved configuration and the previous one. Checking these differences, our process helps to calculate the effort needed to perform the evolution changes in the customized products. To perform those tasks we have defined two operators, one to calculate the differences between two feature model configurations and another to create a new configuration from a previous one. Conclusion: Our process automatically propagates the evolution changes of the middleware family into the existing configurations where the middleware is already deployed and also helps us to calculate the effort in performing the changes in every configuration. Finally, we validated our approach, demonstrating the functioning of the defined operators and showing that by using our tool we can generate evolved configurations for FamiWare with thousands of cloned features, for several case studies.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {563–580},
numpages = {18},
keywords = {Evolution, Feature Models, Middleware family, Software Product Lines}
}

@inproceedings{10.1109/SEAMS.2007.13,
author = {Gomaa, Hassan and Hussein, Mohamed},
title = {Model-Based Software Design and Adaptation},
year = {2007},
isbn = {0769529739},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAMS.2007.13},
doi = {10.1109/SEAMS.2007.13},
abstract = {This paper describes a modeling approach to software design and adaptation, in particular the design of evolutionary and dynamically reconfigurable software architectures. The different versions of an evolutionary system are considered a software product line, with each version of the system a product line member. After implementation, the model co-exists with the system and evolves with it. The software architecture is built out of architectural patterns. For each software architectural pattern, there is a corresponding software reconfiguration pattern, which describes how the software architecture can be dynamically adapted.},
booktitle = {Proceedings of the 2007 International Workshop on Software Engineering for Adaptive and Self-Managing Systems},
pages = {7},
series = {SEAMS '07}
}

@inproceedings{10.1007/11880240_1,
author = {Gomaa, Hassan},
title = {A software modeling odyssey: designing evolutionary architecture-centric real-time systems and product lines},
year = {2006},
isbn = {3540457720},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11880240_1},
doi = {10.1007/11880240_1},
abstract = {According to OMG, “modeling is the designing of software applications before coding.” This paper describes a modeling approach to software design. The paper describes the key elements of design methods for component based software product lines, which promote reuse, variability management, and evolution. Approaches for executable models and performance analysis of concurrent and real-time design are discussed. Finally, some outstanding challenges are outlined, in particular the design of evolutionary and dynamically reconfigurable software architectures.},
booktitle = {Proceedings of the 9th International Conference on Model Driven Engineering Languages and Systems},
pages = {1–15},
numpages = {15},
keywords = {real-time systems, software architecture, software design, software modeling, software product lines},
location = {Genova, Italy},
series = {MoDELS'06}
}

@article{10.1016/j.scico.2010.12.005,
author = {Parra, Carlos and Blanc, Xavier and Cleve, Anthony and Duchien, Laurence},
title = {Unifying design and runtime software adaptation using aspect models},
year = {2011},
issue_date = {December, 2011},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {76},
number = {12},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2010.12.005},
doi = {10.1016/j.scico.2010.12.005},
abstract = {Software systems are seen more and more as evolutive systems. At the design phase, software is constantly in adaptation by the building process itself, and at runtime, it can be adapted in response to changing conditions in the executing environment such as location or resources. Adaptation is generally difficult to specify because of its cross-cutting impact on software. This article introduces an approach to unify adaptation at design and at runtime based on Aspect Oriented Modeling. Our approach proposes a unified aspect metamodel and a platform that realizes two different weaving processes to achieve design and runtime adaptations. This approach is used in a Dynamic Software Product Line which derives products that can be configured at design time and adapted at runtime in order to dynamically fit new requirements or resource changes. Such products are implemented using the Service Component Architecture and Java. Finally, we illustrate the use of our approach based on an adaptive e-shopping scenario. The main advantages of this unification are: a clear separation of concerns, the self-contained aspect model that can be weaved during the design and execution, and the platform independence guaranteed by two different types of weaving.},
journal = {Sci. Comput. Program.},
month = dec,
pages = {1247–1260},
numpages = {14},
keywords = {Aspect oriented modeling, Software product lines}
}

@inproceedings{10.1007/11741060_6,
author = {Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang and Spinczyk, Olaf},
title = {The design of application-tailorable operating system product lines},
year = {2005},
isbn = {3540336893},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11741060_6},
doi = {10.1007/11741060_6},
abstract = {System software for deeply embedded devices has to cope with a broad variety of requirements and platforms, but especially with strict resource constraints. To compete against proprietary systems (and thereby to facilitate reuse), an operating system product line for deeply embedded systems has to be highly configurable and tailorable. It is therefore crucial that all selectable and configurable features can be encapsulated into fine-grained, exchangeable and reusable implementation components. However, the encapsulation of non-functional properties is often limited, due to their cross-cutting character. Fundamental system policies, like synchronization or activation points for the scheduler, have typically to be reflected in many points of the operating system component code. The presented approach is based on feature modeling, C++ class composition and overcomes the above mentioned problems by means of aspect-oriented programming (AOP). It facilitates a fine-grained encapsulation and configuration of even non-functional properties in system software.},
booktitle = {Proceedings of the Second International Conference on Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
pages = {99–117},
numpages = {19},
location = {Nice, France},
series = {CASSIS'05}
}

@article{10.1007/s10515-011-0080-5,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Apel, Sven and Saake, Gunter},
title = {Flexible feature binding in software product lines},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0080-5},
doi = {10.1007/s10515-011-0080-5},
abstract = {A software product line (SPL) is a family of programs that share assets from a common code base. The programs of an SPL can be distinguished in terms of features, which represent units of program functionality that satisfy stakeholders' requirements. The features of an SPL can be bound either statically at program compile time or dynamically at run time. Both binding times are used in SPL development and have different advantages. For example, dynamic binding provides high flexibility whereas static binding supports fine-grained customizability without any impact on performance (e.g., for use on embedded systems). However, contemporary techniques for implementing SPLs force a programmer to choose the binding time already when designing an SPL and to mix different implementation techniques when multiple binding times are needed. We present an approach that integrates static and dynamic feature binding seamlessly. It allows a programmer to implement an SPL once and to decide per feature at deployment time whether it should be bound statically or dynamically. Dynamic binding usually introduces an overhead regarding resource consumption and performance. We reduce this overhead by statically merging features that are used together into dynamic binding units. A program can be configured at run time by composing binding units on demand. We use feature models to ensure that only valid feature combinations can be selected at compile and at run time. We provide a compiler and evaluate our approach on the basis of two non-trivial SPLs.},
journal = {Automated Software Engg.},
month = jun,
pages = {163–197},
numpages = {35},
keywords = {Dynamic binding, Feature binding time, Feature composition, Feature-oriented programming, Software product lines, Static binding}
}

@inproceedings{10.1007/978-3-662-45234-9_25,
author = {Beek, Maurice H. and Fantechi, Alessandro and Gnesi, Stefania},
title = {Challenges in Modelling and Analyzing Quantitative Aspects of Bike-Sharing Systems},
year = {2014},
isbn = {9783662452332},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-45234-9_25},
doi = {10.1007/978-3-662-45234-9_25},
abstract = {Bike-sharing systems are becoming popular not only as a sustainable means of transportation in the urban environment, but also as a challenging case study that presents interesting run-time optimization problems. As a side-study within a research project aimed at quantitative analysis that used such a case study, we have observed how the deployed systems enjoy a wide variety of different features. We have therefore applied variability analysis to define a family of bike-sharing systems, and we have sought support in available tools. We have so established a tool chain that includes academic tools that provide different functionalities regarding the analysis of software product lines, from feature modelling to product derivation and from quantitative evaluation of the attributes of products to model checking value-passing modal specifications. The tool chain is currently experimented inside the mentioned project as a complement to more sophisticated product-based analysis techniques.},
booktitle = {Part I of the Proceedings of the 6th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change - Volume 8802},
pages = {351–367},
numpages = {17}
}

@inproceedings{10.1145/2668930.2688051,
author = {Hork\'{y}, Vojt\v{e}ch and Libi\v{c}, Peter and Marek, Luk\'{a}\v{s} and Steinhauser, Antonin and T\r{u}ma, Petr},
title = {Utilizing Performance Unit Tests To Increase Performance Awareness},
year = {2015},
isbn = {9781450332484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668930.2688051},
doi = {10.1145/2668930.2688051},
abstract = {Many decisions taken during software development impact the resulting application performance. The key decisions whose potential impact is large are usually carefully weighed. In contrast, the same care is not used for many decisions whose individual impact is likely to be small -- simply because the costs would outweigh the benefits. Developer opinion is the common deciding factor for these cases, and our goal is to provide the developer with information that would help form such opinion, thus preventing performance loss due to the accumulated effect of many poor decisions.Our method turns performance unit tests into recipes for generating performance documentation. When the developer selects an interface and workload of interest, relevant performance documentation is generated interactively. This increases performance awareness -- with performance information available alongside standard interface documentation, developers should find it easier to take informed decisions even in situations where expensive performance evaluation is not practical. We demonstrate the method on multiple examples, which show how equipping code with performance unit tests works.},
booktitle = {Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering},
pages = {289–300},
numpages = {12},
keywords = {java, javadoc, performance awareness, performance documentation, performance testing},
location = {Austin, Texas, USA},
series = {ICPE '15}
}

@article{10.1016/j.jvlc.2013.08.001,
author = {Anjorin, Anthony and Saller, Karsten and Reimund, Ingo and Oster, Sebastian and Zorcic, Ivan and Sch\"{u}rr, Andy},
title = {Model-driven rapid prototyping with programmed graph transformations},
year = {2013},
issue_date = {December, 2013},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {24},
number = {6},
issn = {1045-926X},
url = {https://doi.org/10.1016/j.jvlc.2013.08.001},
doi = {10.1016/j.jvlc.2013.08.001},
abstract = {Modern software systems are constantly increasing in complexity and supporting the rapid prototyping of such systems has become crucial to check the feasibility of extensions and optimizations, thereby reducing risks and, consequently, the cost of development. As modern software systems are also expected to be reused, extended, and adapted over a much longer lifetime than ever before, ensuring the maintainability of such systems is equally gaining relevance. In this paper, we present the development, optimization and maintenance of MoSo-PoLiTe, a framework for Software Product Line (SPL) testing, as a novel case study for rapid prototyping via metamodelling and programmed graph transformations. The first part of the case study evaluates the use of programmed graph transformations for optimizing an existing, hand-written system (MoSo-PoLiTe) via rapid prototyping of various strategies. In the second part, we present a complete re-engineering of the hand-written system with programmed graph transformations and provide a critical comparison of both implementations. Our results and conclusions indicate that metamodelling and programmed graph transformation are not only suitable techniques for rapid prototyping, but also lead to more maintainable systems.},
journal = {J. Vis. Lang. Comput.},
month = dec,
pages = {441–462},
numpages = {22},
keywords = {Metamodelling, Model-driven testing, Programmed graph transformations, Rapid prototyping, Software product lines}
}

@article{10.1007/s00779-020-01413-3,
author = {Iglesias-Urkia, Markel and G\'{o}mez, Abel and Casado-Mansilla, Diego and Urbieta, Aitor},
title = {Automatic generation of Web of Things servients using Thing Descriptions},
year = {2020},
issue_date = {Feb 2024},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {1},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-020-01413-3},
doi = {10.1007/s00779-020-01413-3},
abstract = {Similarly to the standardization effort initiated for the World Wide Web in the 1990s, the World Wide Web Consortium is currently working on the Web of Things (WoT) specification. This initiative aims to tackle current fragmentation in the so-called Internet of Things by using existing Web standards. The ultimate goal is to cope with the increasing number of devices that are being connected to the Internet and to enable interoperability among them. On the other hand, Model-Driven Engineering (MDE) approaches make use of models to raise the abstraction level with the objective of accelerating the software development process, enabling design and code reuse, and increasing software quality.This work proposes to apply MDE techniques to enable the efficient development of WoT servients. Based on the WoT Thing Description specification, this work proposes both a textual-based concrete syntax and a model-based abstract syntax—both fully compliant with the WoT specification—that enable the generation of WoT servients in C++ with CoAP communication capabilities. This proposal is implemented by a tool that covers the whole development process, which is publicly available under an open source license.},
journal = {Personal Ubiquitous Comput.},
month = jul,
pages = {325–341},
numpages = {17},
keywords = {Web of Things (WoT), Internet of Things (IoT), Model-driven engineering (MDE), Domain-specific languages (DSL)}
}

@article{10.1016/j.infsof.2016.12.004,
author = {Vale, Tassio and de Almeida, Eduardo Santana and Alves, Vander and Kulesza, Uir and Niu, Nan and de Lima, Ricardo},
title = {Software product lines traceability},
year = {2017},
issue_date = {April 2017},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {84},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2016.12.004},
doi = {10.1016/j.infsof.2016.12.004},
abstract = {This paper analyzes 62 SPL traceability studies dating from 2001 to 2015.We discuss goals, strategies, domains, research intensity and challenges of the area.This work identifies gaps in research which should be addressed.It identifies common practices and areas for further improvements as well. Context: Traceability in Software Product Lines (SPL) is the ability to interrelate software engineering artifacts through required links to answer specific questions related to the families of products and underlying development processes. Despite the existence of studies to map out available evidence on traceability for single systems development, there is a lack of understanding on common strategies, activities, artifacts, and research gaps for SPL traceability.Objective: This paper analyzes 62 studies dating from 2001 to 2015 and discusses seven aspects of SPL traceability: main goals, strategies, application domains, research intensity, research challenges, rigor, and industrial relevance. In addition to the analysis, this paper also synthesizes the available evidence, identifies open issues and points out areas calling for further research.Method: To gather evidence, we defined a mapping study process adapted from existing guidelines. Driven by a set of research questions, this process comprises three major phases: planning, conducting, and documenting the review.Results: This work provides a structured understanding of SPL traceability, indicating areas for further research. The lack of evidence regarding the application of research methods indicates the need for more rigorous SPL traceability studies with better description of context, study design, and limitations. For practitioners, although most identified studies have low industrial relevance, a few of them have high relevance and thus could provide some decision making support for application of SPL traceability in practice.Conclusions: This work concludes that SPL traceability is maturing and pinpoints areas where further investigation should be performed. As future work, we intend to improve the comparison between traceability proposals for SPL and single-system development.},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {1–18},
numpages = {18},
keywords = {Software and systems traceability, Software product lines, Software reuse, Systematic mapping study}
}

@article{10.1016/j.jss.2017.01.031,
author = {Lucas, Edson M. and Oliveira, Toacy C. and Farias, Kleinner and Alencar, Paulo S.C.},
title = {CollabRDL},
year = {2017},
issue_date = {September 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {131},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.01.031},
doi = {10.1016/j.jss.2017.01.031},
abstract = {Extends the Reuse Description Language (RDL) to address collaborative reuse processesIncludes three new commands in RDL, including ROLE, PARALLEL and DOPARALLELCollabRDL can represent parallelism, synchronization, multiple-choice and roleCollabRDL is capable of representing critical workflow patterns Coordinating software reuse activities is a complex problem when considering collaborative software development. This is mainly motivated due to the difficulty in specifying how the artifacts and the knowledge produced in previous projects can be applied in future ones. In addition, modern software systems are developed in group working in separate geographical locations. Therefore, techniques to enrich collaboration on software development are important to improve quality and reduce costs. Unfortunately, the current literature fails to address this problem by overlooking existing reuse techniques. There are many reuse approaches proposed in academia and industry, including Framework Instantiation, Software Product Line, Transformation Chains, and Staged Configuration. But, the current approaches do not support the representation and implementation of collaborative instantiations that involve individual and group roles, the simultaneous performance of multiple activities, restrictions related to concurrency and synchronization of activities, and allocation of activities to reuse actors as a coordination mechanism. These limitations are the main reasons why the Reuse Description Language (RDL) is unable to promote collaborative reuse, i.e., those related to reuse activities in collaborative software development. To overcome these shortcomings, this work, therefore, proposes CollabRDL, a language to coordinate collaborative reuse by providing essential concepts and constructs for allowing group-based reuse activities. For this purpose, we extend RDL by introducing three new commands, including role, parallel, and doparallel. To evaluate CollabRDL we have conducted a case study in which developer groups performed reuse activities collaboratively to instantiate a mainstream Java framework. The results indicated that CollabRDL was able to represent critical workflow patterns, including parallel split pattern, synchronization pattern, multiple-choice pattern, role-based distribution pattern, and multiple instances with decision at runtime. Overall, we believe that the provision of a new language that supports group-based activities in framework instantiation can help enable software organizations to document their coordinated efforts and achieve the benefits of software mass customization with significantly less development time and effort.},
journal = {J. Syst. Softw.},
month = sep,
pages = {505–527},
numpages = {23},
keywords = {Collaboration, Framework, Language, Reuse process, Software reuse}
}

@inproceedings{10.1145/2168697.2168699,
author = {Quinton, Cl\'{e}ment and Rouvoy, Romain and Duchien, Laurence},
title = {Leveraging feature models to configure virtual appliances},
year = {2012},
isbn = {9781450311618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168697.2168699},
doi = {10.1145/2168697.2168699},
abstract = {Cloud computing is a major trend in distributed computing environments. Software virtualization technologies allow cloud Infrastructure-as-a-Service (IaaS) providers to instantiate and run a large number of virtual appliances. However, one of the major challenges is to reduce the disk space footprint of such virtual appliances to improve their storage and transfer across cloud servers. In this paper, we propose to use a Software Product Line (SPL) approach and describe the virtual appliance as a set of common and variable elements modeled by means of Feature Model (FM). We describe a solution to reverse engineer a FM from a virtual appliance and we show how we take advantage of the SPL configuration mechanisms to significantly reduce the size of a virtual appliance.},
booktitle = {Proceedings of the 2nd International Workshop on Cloud Computing Platforms},
articleno = {2},
numpages = {6},
location = {Bern, Switzerland},
series = {CloudCP '12}
}

@article{10.1007/s10664-017-9573-6,
author = {Guo, Jianmei and Yang, Dingyu and Siegmund, Norbert and Apel, Sven and Sarkar, Atrisha and Valov, Pavel and Czarnecki, Krzysztof and Wasowski, Andrzej and Yu, Huiqun},
title = {Data-efficient performance learning for configurable systems},
year = {2018},
issue_date = {Jun 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9573-6},
doi = {10.1007/s10664-017-9573-6},
abstract = {Many software systems today are configurable, offering customization of functionality by feature selection. Understanding how performance varies in terms of feature selection is key for selecting appropriate configurations that meet a set of given requirements. Due to a huge configuration space and the possibly high cost of performance measurement, it is usually not feasible to explore the entire configuration space of a configurable system exhaustively. It is thus a major challenge to accurately predict performance based on a small sample of measured system variants. To address this challenge, we propose a data-efficient learning approach, called DECART, that combines several techniques of machine learning and statistics for performance prediction of configurable systems. DECART builds, validates, and determines a prediction model based on an available sample of measured system variants. Empirical results on 10 real-world configurable systems demonstrate the effectiveness and practicality of DECART. In particular, DECART achieves a prediction accuracy of 90% or higher based on a small sample, whose size is linear in the number of features. In addition, we propose a sample quality metric and introduce a quantitative analysis of the quality of a sample for performance prediction.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1826–1867},
numpages = {42},
keywords = {Performance prediction, Configurable systems, Regression, Model selection, Parameter tuning}
}

@article{10.1007/s11219-011-9146-7,
author = {Montagud, Sonia and Abrah\~{a}o, Silvia and Insfran, Emilio},
title = {A systematic review of quality attributes and measures for software product lines},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9146-7},
doi = {10.1007/s11219-011-9146-7},
abstract = {It is widely accepted that software measures provide an appropriate mechanism for understanding, monitoring, controlling, and predicting the quality of software development projects. In software product lines (SPL), quality is even more important than in a single software product since, owing to systematic reuse, a fault or an inadequate design decision could be propagated to several products in the family. Over the last few years, a great number of quality attributes and measures for assessing the quality of SPL have been reported in literature. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the objective of identifying and interpreting all the available studies from 1996 to 2010 that present quality attributes and/or measures for SPL. These attributes and measures have been classified using a set of criteria that includes the life cycle phase in which the measures are applied; the corresponding quality characteristics; their support for specific SPL characteristics (e.g., variability, compositionality); the procedure used to validate the measures, etc. We found 165 measures related to 97 different quality attributes. The results of the review indicated that 92% of the measures evaluate attributes that are related to maintainability. In addition, 67% of the measures are used during the design phase of Domain Engineering, and 56% are applied to evaluate the product line architecture. However, only 25% of them have been empirically validated. In conclusion, the results provide a global vision of the state of the research within this area in order to help researchers in detecting weaknesses, directing research efforts, and identifying new research lines. In particular, there is a need for new measures with which to evaluate both the quality of the artifacts produced during the entire SPL life cycle and other quality characteristics. There is also a need for more validation (both theoretical and empirical) of existing measures. In addition, our results may be useful as a reference guide for practitioners to assist them in the selection or the adaptation of existing measures for evaluating their software product lines.},
journal = {Software Quality Journal},
month = sep,
pages = {425–486},
numpages = {62},
keywords = {Measures, Quality, Quality attributes, Software product lines, Systematic literature review}
}

@inproceedings{10.1145/2814228.2814229,
author = {Arzt, Steven and Nadi, Sarah and Ali, Karim and Bodden, Eric and Erdweg, Sebastian and Mezini, Mira},
title = {Towards secure integration of cryptographic software},
year = {2015},
isbn = {9781450336888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814228.2814229},
doi = {10.1145/2814228.2814229},
abstract = {While cryptography is now readily available to everyone and can, provably, protect private information from attackers, we still frequently hear about major data leakages, many of which are due to improper use of cryptographic mechanisms. The problem is that many application developers are not cryptographic experts. Even though high-quality cryptographic APIs are widely available, programmers often select the wrong algorithms or misuse APIs due to a lack of understanding. Such issues arise with both simple operations such as encryption as well as with complex secure communication protocols such as SSL. In this paper, we provide a long-term solution that helps application developers integrate cryptographic components correctly and securely by bridging the gap between cryptographers and application developers. Our solution consists of a software product line (with an underlying feature model) that automatically identifies the correct cryptographic algorithms to use, based on the developer's answers to high-level questions in non-expert terminology. Each feature (i.e., cryptographic algorithm) maps into corresponding Java code and a usage protocol describing API restrictions. By composing the user's selected features, we automatically synthesize a secure code blueprint and a usage protocol that corresponds to the selected usage scenario. Since the developer may change the application code over time, we use the usage protocols to statically analyze the program and ensure that the correct use of the API is not violated over time.},
booktitle = {2015 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward!)},
pages = {1–13},
numpages = {13},
keywords = {API protocols, Software product lines, cryptography, typestate analysis},
location = {Pittsburgh, PA, USA},
series = {Onward! 2015}
}

@article{10.1007/s10270-013-0364-2,
author = {Acher, Mathieu and Cleve, Anthony and Collet, Philippe and Merle, Philippe and Duchien, Laurence and Lahire, Philippe},
title = {Extraction and evolution of architectural variability models in plugin-based systems},
year = {2014},
issue_date = {October   2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-013-0364-2},
doi = {10.1007/s10270-013-0364-2},
abstract = {Variability management is a key issue when building and evolving software-intensive systems, making it possible to extend, configure, customize and adapt such systems to customers' needs and specific deployment contexts. A wide form of variability can be found in extensible software systems, typically built on top of plugin-based architectures that offer a (large) number of configuration options through plugins. In an ideal world, a software architect should be able to generate a system variant on-demand, corresponding to a particular assembly of plugins. To this end, the variation points and constraints between architectural elements should be properly modeled and maintained over time (i.e., for each version of an architecture). A crucial, yet error-prone and time-consuming, task for a software architect is to build an accurate representation of the variability of an architecture, in order to prevent unsafe architectural variants and reach the highest possible level of flexibility. In this article, we propose a reverse engineering process for producing a variability model (i.e., a feature model) of a plugin-based architecture. We develop automated techniques to extract and combine different variability descriptions, including a hierarchical software architecture model, a plugin dependency model and the software architect knowledge. By computing and reasoning about differences between versions of architectural feature models, software architect can control both the variability extraction and evolution processes. The proposed approach has been applied to a representative, large-scale plugin-based system (FraSCAti), considering different versions of its architecture. We report on our experience in this context.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1367–1394},
numpages = {28},
keywords = {Architecture recovery, Configuration management, Product lines, Reverse engineering, Software evolution, Variability}
}

@article{10.1016/j.infsof.2008.04.002,
author = {Deelstra, Sybren and Sinnema, Marco and Bosch, Jan},
title = {Variability assessment in software product families},
year = {2009},
issue_date = {January, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {1},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.002},
doi = {10.1016/j.infsof.2008.04.002},
abstract = {Software variability management is a key factor in the success of software systems and software product families. An important aspect of software variability management is the evolution of variability in response to changing markets, business needs, and advances in technology. To be able to determine whether, when, and how variability should evolve, we have developed the COVAMOF software variability assessment method (COSVAM). The contribution of COSVAM is that it is a novel, and industry-strength assessment process that addresses the issues that are associated to the current variability assessment practice. In this paper, we present the successful validation of COSVAM in an industrial software product family.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {195–218},
numpages = {24},
keywords = {Assessment, Evolution, Software product families, Variability}
}

@inproceedings{10.1145/3382494.3410677,
author = {Shu, Yangyang and Sui, Yulei and Zhang, Hongyu and Xu, Guandong},
title = {Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410677},
doi = {10.1145/3382494.3410677},
abstract = {Context: Many software systems are highly configurable. Different configuration options could lead to varying performances of the system. It is difficult to measure system performance in the presence of an exponential number of possible combinations of these options.Goal: Predicting software performance by using a small configuration sample.Method: This paper proposes Perf-AL to address this problem via adversarial learning. Specifically, we use a generative network combined with several different regularization techniques (L1 regularization, L2 regularization and a dropout technique) to output predicted values as close to the ground truth labels as possible. With the use of adversarial learning, our network identifies and distinguishes the predicted values of the generator network from the ground truth value distribution. The generator and the discriminator compete with each other by refining the prediction model iteratively until its predicted values converge towards the ground truth distribution.Results: We argue that (i) the proposed method can achieve the same level of prediction accuracy, but with a smaller number of training samples. (ii) Our proposed model using seven real-world datasets show that our approach outperforms the state-of-the-art methods. This help to further promote software configurable performance.Conclusion: Experimental results on seven public real-world datasets demonstrate that PERF-AL outperforms state-of-the-art software performance prediction methods.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {16},
numpages = {11},
keywords = {Software performance prediction, adversarial learning, configurable systems, regularization},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.5555/645882.672252,
author = {Bosch, Jan},
title = {Maturity and Evolution in Software Product Lines: Approaches, Artefacts and Organization},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines have received considerable adoption in the software industry and prove to be a very successful approach to intra-organizational software reuse. Existing literature, however, often presents only a single approach towards adopting and evolving a software product line. In this paper, we present an overview of different approaches to the architecture-centric, intra-organizational reuse of software artefacts. We relate these to maturity levels for product line artefacts and organizational models.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {257–271},
numpages = {15},
series = {SPLC 2}
}

@article{10.1007/s10515-015-0188-0,
author = {Bulej, Lubom\'{\i}r and Bure\v{s}, Tom\'{a}\v{s} and Hork\'{y}, Vojtundefinedch and Kotr\u{a}\'{z}, Jaroslav and Marek, Luk\'{a}\v{s} and Troj\'{a}nek, Tom\'{a}\v{s} and T\'{z}Ma, Petr},
title = {Unit testing performance with Stochastic Performance Logic},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0188-0},
doi = {10.1007/s10515-015-0188-0},
abstract = {Unit testing is an attractive quality management tool in the software development process, however, practical obstacles make it difficult to use unit tests for performance testing. We present Stochastic Performance Logic, a formalism for expressing performance requirements, together with interpretations that facilitate performance evaluation in the unit test context. The formalism and the interpretations are implemented in a performance testing framework and evaluated in multiple experiments, demonstrating the ability to identify performance differences in realistic unit test scenarios.},
journal = {Automated Software Engg.},
month = mar,
pages = {139–187},
numpages = {49},
keywords = {Java, Performance evaluation, Unit testing}
}

@inproceedings{10.1007/978-3-642-30982-3_7,
author = {Petriu, Dorina C. and Alhaj, Mohammad and Tawhid, Rasha},
title = {Software performance modeling},
year = {2012},
isbn = {9783642309816},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-30982-3_7},
doi = {10.1007/978-3-642-30982-3_7},
abstract = {Ideally, a software development methodology should include both the ability to specify non-functional requirements and to analyze them starting early in the lifecycle; the goal is to verify whether the system under development would be able to meet such requirements. This chapter considers quantitative performance analysis of UML software models annotated with performance attributes according to the standard "UML Profile for Modeling and Analysis of Real-Time and Embedded Systems" (MARTE). The chapter describes a model transformation chain named PUMA (Performance by Unified Model Analysis) that enables the integration of performance analysis in a UML-based software development process, by automating the derivation of performance models from UML+MARTE software models, and by facilitating the interoperability of UML tools and performance tools. PUMA uses an intermediate model called "Core Scenario Model" (CSM) to bridge the gap between different kinds of software models accepted as input and different kinds of performance models generated as output. Transformation principles are described for transforming two kinds of UML behaviour representation (sequence and activity diagrams) into two kinds of performance models (Layered Queueing Networks and stochastic Petri nets). Next, PUMA extensions are described for two classes of software systems: service-oriented architecture (SOA) and software product lines (SPL).},
booktitle = {Proceedings of the 12th International Conference on Formal Methods for the Design of Computer, Communication, and Software Systems: Formal Methods for Model-Driven Engineering},
pages = {219–262},
numpages = {44},
location = {Bertinoro, Italy},
series = {SFM'12}
}

@inproceedings{10.5555/1860875.1860879,
author = {Elsner, Christoph and Schwanninger, Christa and Schr\"{o}der-Preikschat, Wolgang and Lohmann, Daniel},
title = {Multi-Level Product Line Customization},
year = {2010},
isbn = {9781607506287},
publisher = {IOS Press},
address = {NLD},
abstract = {Managing and developing a set of software products jointly using a software product line approach has achieved significant productivity and quality gain in the last decade. More and more, product lines now are becoming themselves entities that are sold and bought in the software supply chain. Customers build more specialized product lines on top of them or derive themselves the concrete products. As customers have different requirements, whole product lines now may vary depending on customer needs---they need to be customized. Current approaches going beyond the scope of one product line do not provide appropriate means for customization. They either are tailored to specific implementation techniques, only regard customization on few levels (e.g., only source code level), or imply a lot of manual effort for performing the customization.The PLiC Approach tackles this challenge by providing a generic, reusable reference architecture and methodology for implementing such customizable product lines. In the reference architecture, a product line consists of so-called product line components (PLiCs), which are flexibly recombinable slices of a formerly monolithic product line, thereby maintaining strict separation of concerns. The approach furthermore comprises a tool-supported methodology for recombination of PLiCs based on customer needs and thus minimizes manual intervention when customizing. We implemented the PLiC Approach for a complex model-driven product line, where it facilitates comprehensive customization on various levels in the models, the model transformation chain, and in the source code with reasonable effort. This gives evidence that our approach can be applied in various other contexts where the same or fewer customization levels need to be considered.},
booktitle = {Proceedings of the 2010 Conference on New Trends in Software Methodologies, Tools and Techniques: Proceedings of the 9th SoMeT_10},
pages = {37–58},
numpages = {22}
}

@inproceedings{10.1007/978-3-031-15116-3_8,
author = {Lima dos Santos, Edilton and Fortz, Sophie and Schobbens, Pierre-Yves and Perrouin, Gilles},
title = {Behavioral Maps: Identifying Architectural Smells in&nbsp;Self-adaptive Systems at&nbsp;Runtime},
year = {2021},
isbn = {978-3-031-15115-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-15116-3_8},
doi = {10.1007/978-3-031-15116-3_8},
abstract = {Self-adaptive systems (SAS) change their behavior and structure at runtime, depending on environmental changes and reconfiguration plans and goals. Such systems combine architectural fragments or solutions in their (re)configuration process. However, this process may negatively impact the system’s architectural qualities, exhibiting architectural bad smells (ABS). Also, some smells may appear in only particular runtime conditions. This issue is challenging to detect due to the combinatorial explosion of interactions amongst features. We initially proposed the notion of Behavioral Map to explore architectural issues at runtime. This extended study applies the Behavioral Map to analyze the ABS in self-adaptive systems at runtime. In particular, we look for Cyclic Dependency, Extraneous Connector, Hub-Like Dependency, and Oppressed Monitor ABS in various runtime adaptations in the Smart Home Environment (SHE) framework, Adasim, and mRUBiS systems developed in Java. The results indicate that runtime ABS identification is required to fully capture SAS architectural qualities because the ABS are feature-dependent, and their number is highly variable for each adaptation. We have observed that some ABS appears in all runtime adaptations, some in only a few. However, some ABS only appear in the publish-subscribe architecture, such as Extraneous Connector and Oppressed Monitor smell. We discuss the reasons behind these architectural smells for each system and motivate the need for targeted ABS analyses in SAS.},
booktitle = {Software Architecture: 15th European Conference, ECSA 2021 Tracks and Workshops; V\"{a}xj\"{o}, Sweden, September 13–17, 2021, Revised Selected Papers},
pages = {159–180},
numpages = {22},
keywords = {Architectural smells, Dynamic software product lines, Runtime validation, Self-adaptive systems, Behavioral maps},
location = {V\"{a}xj\"{o}, Sweden}
}

@inproceedings{10.1145/2517208.2517214,
author = {Kramer, Dean and Oussena, Samia and Komisarczuk, Peter and Clark, Tony},
title = {Using document-oriented GUIs in dynamic software product lines},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517214},
doi = {10.1145/2517208.2517214},
abstract = {Dynamic Software Product Line (DSPL) Engineering has gained interest through its promise of being able to unify software adaptation whereby software adaptation can be realised at compile time and runtime. While previous work has enabled program logic adaptation by the use of language extensions and platform support, little attention has been placed on Graphical User Interface (GUI) variability. Different design patterns including the Model View Controller are commonly used in GUI implementation, with GUI documents being used for declaring the GUI. To handle dynamic GUI variability currently, the developer needs to implement GUI refinements using multiple techniques. This paper proposes a solution for dealing with GUI document variability, statically and dynamically, in a unified way. In our approach, we currently use a compile time method for producing GUI variants, and code transformations to handle these variants within the application at runtime. To avoid GUI duplicates, only GUI variants that are unique, and related to a valid product configuration, are produced. To validate our approach, we implemented tool support to enable this for Android based applications.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {85–94},
numpages = {10},
keywords = {dynamic software product lines, graphical user interfaces},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@article{10.4018/jismd.2012040102,
author = {Mazo, Ra\'{u}l and Salinesi, Camille and Diaz, Daniel and Djebbi, Olfa and Lora-Michiels, Alberto},
title = {Constraints: The Heart of Domain and Application Engineering in the Product Lines Engineering Strategy},
year = {2012},
issue_date = {April 2012},
publisher = {IGI Global},
address = {USA},
volume = {3},
number = {2},
issn = {1947-8186},
url = {https://doi.org/10.4018/jismd.2012040102},
doi = {10.4018/jismd.2012040102},
abstract = {Drawing from an analogy between features based Product Line PL models and Constraint Programming CP, this paper explores the use of CP in the Domain Engineering and Application Engineering activities that are put in motion in a Product Line Engineering strategy. Specifying a PL as a constraint program instead of a feature model carries out two important qualities of CP: expressiveness and direct automation. On the one hand, variables in CP can take values over boolean, integer, real or even complex domains and not only boolean values as in most PL languages such as the Feature-Oriented Domain Analysis FODA. Specifying boolean, arithmetic, symbolic and reified constraint, provides a power of expression that spans beyond that provided by the boolean dependencies in FODA models. On the other hand, PL models expressed as constraint programs can directly be executed and analyzed by off-the-shelf solvers. This paper explores the issues of a how to specify a PL model using CP, including in the presence of multi-model representation, b how to verify PL specifications, c how to specify configuration requirements, and d how to support the product configuration activity. Tests performed on a benchmark of 50 PL models show that the approach is efficient and scales up easily to very large and complex PL specifications.},
journal = {Int. J. Inf. Syst. Model. Des.},
month = apr,
pages = {33–68},
numpages = {36},
keywords = {Computer Science, Constraint-Based Product Lines, Information Systems, Product Line Analysis, Product Line Configuration, Product Line Integration, Product Line Reasoning, Product Line Specification, Product Line Verification}
}

@inproceedings{10.1145/3368089.3409675,
author = {Siegmund, Norbert and Ruckel, Nicolai and Siegmund, Janet},
title = {Dimensions of software configuration: on the configuration context in modern software development},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409675},
doi = {10.1145/3368089.3409675},
abstract = {With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure. This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined. However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings, translate them to practice, and to generalize the results. Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {338–349},
numpages = {12},
keywords = {Dimensions of software configuration, configuration management and life cycle, developer study, variability},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1007/s10664-014-9357-1,
author = {B\'{e}can, Guillaume and Acher, Mathieu and Baudry, Benoit and Nasr, Sana Ben},
title = {Breathing ontological knowledge into feature model synthesis: an empirical study},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9357-1},
doi = {10.1007/s10664-014-9357-1},
abstract = {Feature Models (FMs) are a popular formalism for modeling and reasoning about the configurations of a software product line. As the manual construction of an FM is time-consuming and error-prone, management operations have been developed for reverse engineering, merging, slicing, or refactoring FMs from a set of configurations/dependencies. Yet the synthesis of meaningless ontological relations in the FM --- as defined by its feature hierarchy and feature groups --- may arise and cause severe difficulties when reading, maintaining or exploiting it. Numerous synthesis techniques and tools have been proposed, but only a few consider both configuration and ontological semantics of an FM. There are also few empirical studies investigating ontological aspects when synthesizing FMs. In this article, we define a generic, ontologic-aware synthesis procedure that computes the likely siblings or parent candidates for a given feature. We develop six heuristics for clustering and weighting the logical, syntactical and semantical relationships between feature names. We then perform an empirical evaluation on hundreds of FMs, coming from the SPLOT repository and Wikipedia. We provide evidence that a fully automated synthesis (i.e., without any user intervention) is likely to produce FMs far from the ground truths. As the role of the user is crucial, we empirically analyze the strengths and weaknesses of heuristics for computing ranking lists and different kinds of clusters. We show that a hybrid approach mixing logical and ontological techniques outperforms state-of-the-art solutions. We believe our approach, environment, and empirical results support researchers and practitioners working on reverse engineering and management of FMs.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1794–1841},
numpages = {48},
keywords = {Feature model, Model management, Refactoring, Reverse engineering, Software product lines, Variability}
}

@article{10.1016/j.procs.2021.01.128,
author = {Rabiser, Rick and Zoitl, Alois},
title = {Towards Mastering Variability in Software-Intensive Cyber-Physical Production Systems},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {180},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.01.128},
doi = {10.1016/j.procs.2021.01.128},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {50–59},
numpages = {10},
keywords = {variability, cyber-physical production systems, variability modeling, variability mining, evolution}
}

@article{10.1016/j.infsof.2012.11.001,
author = {Schmid, Klaus and De Almeida, Eduardo Santana and Kishi, Tomoji},
title = {Editorial: Guest Editors' Introduction: Special Issue on Software Reuse and Product Lines},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.11.001},
doi = {10.1016/j.infsof.2012.11.001},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {489–490},
numpages = {2}
}

@inproceedings{10.1145/3338906.3338974,
author = {Ne\v{s}i\'{c}, Damir and Kr\"{u}ger, Jacob and St\u{a}nciulescu, undefinedtefan and Berger, Thorsten},
title = {Principles of feature modeling},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338974},
doi = {10.1145/3338906.3338974},
abstract = {Feature models are arguably one of the most intuitive and successful notations for modeling the features of a variant-rich software system. Feature models help developers to keep an overall understanding of the system, and also support scoping, planning, development, variant derivation, configuration, and maintenance activities that sustain the system's long-term success. Unfortunately, feature models are difficult to build and evolve. Features need to be identified, grouped, organized in a hierarchy, and mapped to software assets. Also, dependencies between features need to be declared. While feature models have been the subject of three decades of research, resulting in many feature-modeling notations together with automated analysis and configuration techniques, a generic set of principles for engineering feature models is still missing. It is not even clear whether feature models could be engineered using recurrent principles. Our work shows that such principles in fact exist. We analyzed feature-modeling practices elicited from ten interviews conducted with industrial practitioners and from 31 relevant papers. We synthesized a set of 34 principles covering eight different phases of feature modeling, from planning over model construction, to model maintenance and evolution. Grounded in empirical evidence, these principles provide practical, context-specific advice on how to perform feature modeling, describe what information sources to consider, and highlight common characteristics of feature models. We believe that our principles can support researchers and practitioners enhancing feature-modeling tooling, synthesis, and analyses techniques, as well as scope future research.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {62–73},
numpages = {12},
keywords = {Feature models, modeling principles, software product lines},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/2110147.2110160,
author = {Schroeter, Julia and Cech, Sebastian and G\"{o}tz, Sebastian and Wilke, Claas and A\ss{}mann, Uwe},
title = {Towards modeling a variable architecture for multi-tenant SaaS-applications},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110160},
doi = {10.1145/2110147.2110160},
abstract = {A widespread business model in cloud computing is to offer software as a service (SaaS) over the Internet. Such applications are often multi-tenant aware, which means that multiple tenants share hardware and software resources of the same application instance. However, SaaS stakeholders have different or even contradictious requirements and interests: For a user, the application's quality and non-functional properties have to be maximized (e.g., choosing the fastest available algorithm for a computation at runtime). In contrast, a resource or application provider is interested in minimizing the operating costs while maximizing his profit. Finally, tenants are interested in offering a customized functionality to their users. To identify an optimal compromise for all these objectives, multiple levels of variability have to be supported by reference architectures for multi-tenant SaaS applications. In this paper, we identify requirements for such a runtime architecture addressing the individual interests of all involved stakeholders. Furthermore, we show how our existing architecture for dynamically adaptive applications can be extended for the development and operation of multi-tenant applications.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {111–120},
numpages = {10},
keywords = {auto-tuning, multi-tenancy, self-optimization, software-as-a-service, variability modeling},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@inproceedings{10.1007/978-3-030-64266-2_5,
author = {Gottschalk, Sebastian and Yigitbas, Enes and Schmidt, Eugen and Engels, Gregor},
title = {Model-Based Product Configuration in Augmented Reality Applications},
year = {2020},
isbn = {978-3-030-64265-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64266-2_5},
doi = {10.1007/978-3-030-64266-2_5},
abstract = {Augmented Reality (AR) has recently found high attention in mobile shopping apps such as in domains like furniture or decoration. Here, the developers of the apps focus on the positioning of atomic 3D objects in the physical environment. With this focus, they neglect the configuration of multi-faceted 3D object composition according to the user needs and environmental constraints. To tackle these challenges, we present a model-based approach to support AR-assisted product configuration based on the concept of Dynamic Software Product Lines. Our approach splits products (e.g. table) into parts (e.g. tabletop, table legs, funnier) with their 3D objects and additional information (e.g. name, price). The possible products, which can be configured out of these parts, are stored in a feature model. At runtime, this feature model can be used to configure 3D object compositions out of the product parts and adapt to user needs and environmental constraints. The benefits of this approach are demonstrated by a case study of configuring modular kitchens with the help of a prototypical mobile-based implementation.},
booktitle = {Human-Centered Software Engineering: 8th IFIP WG 13.2 International Working Conference, HCSE 2020, Eindhoven, The Netherlands, November 30 – December 2, 2020, Proceedings},
pages = {84–104},
numpages = {21},
keywords = {Product configuration, Augmented Ueality, Runtime adaptation, Dynamic Software Product Lines},
location = {Eindhoven, The Netherlands}
}

@article{10.1016/j.cl.2015.02.001,
title = {Neverlang},
year = {2015},
issue_date = {October 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2015.02.001},
doi = {10.1016/j.cl.2015.02.001},
abstract = {Reuse in programming language development is an open research problem. Many authors have proposed frameworks for modular language development. These frameworks focus on maximizing code reuse, providing primitives for componentizing language implementations. There is also an open debate on combining feature-orientation with modular language development. Feature-oriented programming is a vision of computer programming in which features can be implemented separately, and then combined to build a variety of software products. However, even though feature-orientation and modular programming are strongly connected, modular language development frameworks are not usually meant primarily for feature-oriented language definition. In this paper we present a model of language development that puts feature implementation at the center, and describe its implementation in the Neverlang framework. The model has been evaluated through several languages implementations: in this paper, a state machine language is used as a means of comparison with other frameworks, and a JavaScript interpreter implementation is used to further illustrate the benefits that our model provides. HighlightsThis paper presents Neverlang: a framework for modular development of programming languages.Neverlang fosters language composition and restriction.Neverlang supports separate compilation and dynamic extension of the programming languages.Neverlang has been compared with other frameworks with similar aims.Neverlang has been evaluated against significant case studies as an implementation of javascript.},
journal = {Comput. Lang. Syst. Struct.},
month = oct,
pages = {1–40},
numpages = {40}
}

@article{10.1016/j.eswa.2011.10.014,
author = {Guo, Jianmei and Wang, Yinglin and Trinidad, Pablo and Benavides, David},
title = {Consistency maintenance for evolving feature models},
year = {2012},
issue_date = {April, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {39},
number = {5},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.10.014},
doi = {10.1016/j.eswa.2011.10.014},
abstract = {Software product line (SPL) techniques handle the construction of customized systems. One of the most common representations of the decisions a customer can make in SPLs is feature models (FMs). An FM represents the relationships among common and variable features in an SPL. Features are a representation of the characteristics in a system that are relevant to customers. FMs are subject to change since the set of features and their relationships can change along an SPL lifecycle. Due to this evolution, the consistency of FMs may be compromised. There exist some approaches to detect and explain inconsistencies in FMs, however this process can take a long time for large FMs. In this paper we present a complementary approach to dealing with inconsistencies in FM evolution scenarios that improves the performance for existing approaches reducing the impact of change to the smallest part of an FM that changes. To achieve our goal, we formalize FMs from an ontological perspective and define constraints that must be satisfied in FMs to be consistent. We define a set of primitive operations that modify FMs and which are responsible for the FM evolution, analyzing their impact on the FM consistency. We propose a set of predefined strategies to keep the consistency for error-prone operations. As a proof-of-concept we present the results of our experiments, where we check for the effectiveness and efficiency of our approach in FMs with thousands of features. Although our approach is limited by the kinds of consistency constraints and the primitive operations we define, the experiments present a significant improvement in performance results in those cases where they are applicable.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {4987–4998},
numpages = {12},
keywords = {Consistency maintenance, Evolution, Feature models, Ontology, Semantics, Software product lines}
}

@inproceedings{10.5555/1759394.1759396,
author = {Bosch, Jan},
title = {Software product families: towards compositionality},
year = {2007},
isbn = {9783540712886},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product families have become the most successful approach to intra-organizational reuse. Especially in the embedded systems industry, but also elsewhere, companies are building rich and diverse product portfolios based on software platforms that capture the commonality between products while allowing for their differences. Software product families, however, easily become victims of their own success in that, once successful, there is a tendency to increase the scope of the product family by incorporating a broader and more diverse product portfolio. This requires organizations to change their approach to product families from relying on a pre-integrated platform for product derivation to a compositional approach where platform components are composed in a product-specific configuration.},
booktitle = {Proceedings of the 10th International Conference on Fundamental Approaches to Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {compositionality, software product families},
location = {Braga, Portugal},
series = {FASE'07}
}

@article{10.1016/j.datak.2009.07.013,
author = {Rosenm\"{u}ller, Marko and Apel, Sven and Leich, Thomas and Saake, Gunter},
title = {Tailor-made data management for embedded systems: A case study on Berkeley DB},
year = {2009},
issue_date = {December, 2009},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {68},
number = {12},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2009.07.013},
doi = {10.1016/j.datak.2009.07.013},
abstract = {Applications in the domain of embedded systems are diverse and store an increasing amount of data. In order to satisfy the varying requirements of these applications, data management functionality is needed that can be tailored to the applications' needs. Furthermore, the resource restrictions of embedded systems imply a need for data management that is customized to the hardware platform. In this paper, we present an approach for decomposing data management software for embedded systems using feature-oriented programming. The result of such a decomposition is a software product line that allows us to generate tailor-made data management systems. While existing approaches for tailoring software have significant drawbacks regarding customizability and performance, a feature-oriented approach overcomes these limitations, as we will demonstrate. In a non-trivial case study on Berkeley DB, we evaluate our approach and compare it to other approaches for tailoring DBMS.},
journal = {Data Knowl. Eng.},
month = dec,
pages = {1493–1512},
numpages = {20},
keywords = {Embedded systems, Feature-oriented programming, FeatureC++, Software product lines, Tailor-made data management}
}

@article{10.1147/JRD.2013.2243535,
author = {Hirzel, M. and Andrade, H. and Gedik, B. and Jacques-Silva, G. and Khandekar, R. and Kumar, V. and Mendell, M. and Nasgaard, H. and Schneider, S. and Soul\'{e}, R. and Wu, K.-L.},
title = {IBM streams processing language: analyzing big data in motion},
year = {2013},
issue_date = {May/July 2013},
publisher = {IBM Corp.},
address = {USA},
volume = {57},
number = {3–4},
issn = {0018-8646},
url = {https://doi.org/10.1147/JRD.2013.2243535},
doi = {10.1147/JRD.2013.2243535},
abstract = {The IBM Streams Processing Language (SPL) is the programming language for IBM InfoSphere® Streams, a platform for analyzing Big Data in motion. By "Big Data in motion," we mean continuous data streams at high data-transfer rates. InfoSphere Streams processes such data with both high throughput and short response times. To meet these performance demands, it deploys each application on a cluster of commodity servers. SPL abstracts away the complexity of the distributed system, instead exposing a simple graph-of-operators view to the user. SPL has several innovations relative to prior streaming languages. For performance and code reuse, SPL provides a code-generation interface to C++ and Java®. To facilitate writing well-structured and concise applications, SPL provides higher-order composite operators that modularize stream sub-graphs. Finally, to enable static checking while exposing optimization opportunities, SPL provides a strong type system and user-defined operator models. This paper provides a language overview, describes the implementation including optimizations such as fusion, and explains the rationale behind the language design.},
journal = {IBM J. Res. Dev.},
month = may,
articleno = {1},
numpages = {1}
}

@inproceedings{10.1145/3302333.3302347,
author = {Njima, Mercy and Demeyer, Serge},
title = {An Exploratory Study on Migrating Single-Products towards Product Lines in Startup Contexts},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302347},
doi = {10.1145/3302333.3302347},
abstract = {A majority of technology startups fail; inadequate software engineering practices are known to be a contributing factor. The smooth transitioning towards software product lines in particular is a major stumbling block for startups that must broaden their product portfolio to deal with divergent demands imposed by the market. We conducted a preliminary study within two software engineering startups, which revealed the motivating factors and benefits that would lead to the migration from a single product into a product line. Despite the benefits, tackling the challenges foreseen and the identification of features and their relations in the current product is the crucial first step towards implementing an appropriate highly-configurable product portfolio.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {10},
numpages = {6},
keywords = {Exploratory Study, Feature Identification, Software Product Lines, Startups, Transition},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@article{10.1007/s00779-010-0354-0,
author = {G\'{a}mez, Nadia and Fuentes, Lidia},
title = {FamiWare: a family of event-based middleware for ambient intelligence},
year = {2011},
issue_date = {April     2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {4},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-010-0354-0},
doi = {10.1007/s00779-010-0354-0},
abstract = {Most of the middlewares currently available focus on one type of device (e.g., TinyOS sensors) and/or are designed with one requirement in mind (e.g., data management). This is an important limitation since most of the AmI applications work with several devices (such as sensors, smartphones or PDAs) and use a high diversity of low-level services. Ideally, the middleware should provide a single interface for accessing all those services able to work in heterogeneous devices. To address this issue, we propose a family of configurable middleware (FamiWare) with a really flexible architecture, instead of building a single version of a middleware with a rigid structure. In this work, we present the architecture of our middleware that can be configured, following a Software Product Line approach, in order to be instantiated in a particular device fulfilling specific application requirements. Furthermore, we evaluate that the decisions taken at architecture and implementation are the adequate ones for this kind of constrained devices.},
journal = {Personal Ubiquitous Comput.},
month = apr,
pages = {329–339},
numpages = {11},
keywords = {AmI, Events, Middleware, Publish/Subscribe, SPLs}
}

@inproceedings{10.1007/978-3-642-12107-4_6,
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert},
title = {Composing feature models},
year = {2009},
isbn = {3642121063},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12107-4_6},
doi = {10.1007/978-3-642-12107-4_6},
abstract = {Feature modeling is a widely used technique in Software Product Line development. Feature models allow stakeholders to describe domain concepts in terms of commonalities and differences within a family of software systems. Developing a complex monolithic feature model can require significant effort and restrict the reusability of a set of features already modeled. We advocate using modeling techniques that support separating and composing concerns to better manage the complexity of developing large feature models. In this paper, we propose a set of composition operators dedicated to feature models. These composition operators enable the development of large feature models by composing smaller feature models which address well-defined concerns. The operators are notably distinguished by their documented capabilities to preserve some significant properties.},
booktitle = {Proceedings of the Second International Conference on Software Language Engineering},
pages = {62–81},
numpages = {20},
location = {Denver, CO},
series = {SLE'09}
}

@inproceedings{10.5555/1332044.1332080,
author = {Friess, Wolfgang and Sincero, Julio and Schroeder-Preikschat, Wolfgang},
title = {Modelling compositions of modular embedded software product lines},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {Coping with lots of variants is a challenging task in the field of embedded software development. Due to the restricted hardware resources in this domain, it is essential for the embedded system software to be highly adaptable to the specific needs of the application and no unused functionality is implemented. Configurable system software can realise this adaption, but it brings the problem of variant management in this domain. Currently, software product line methods are in the focus of research to cope with high amounts of software variants. But current methods lack of support for systems composed of several subsystems, configured independently. However, such modular systems are very common in the domain of embedded software. This paper introduces a concept for modelling compositions of several software product lines, like the composition of an application software product line and an operating system product line, for example. With this concept, it is possible to model not only single software product lines but also compositions of several ones. This supports the development of modular software systems with high variability. After that, an implementation of a tool for verifying compositions based on this concept is presented.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {224–228},
numpages = {5},
keywords = {embedded systems, reusability, software product lines, software tools},
location = {Innsbruck, Austria},
series = {SE'07}
}

@inproceedings{10.1145/3319008.3319356,
author = {Neto, Amadeu Anderlin and Kalinowski, Marcos and Garcia, Alessandro and Winkler, Dietmar and Biffl, Stefan},
title = {A Preliminary Comparison of Using Variability Modeling Approaches to Represent Experiment Families},
year = {2019},
isbn = {9781450371452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319008.3319356},
doi = {10.1145/3319008.3319356},
abstract = {Background: Replication is essential to build knowledge in empirical science. Experiment replications reported in the software engineering context present variabilities on their design elements, e.g., variables, materials. The understanding of these variabilities is required to plan experimental replications within a research program. However, the lack of an explicit representation of experiments' variabilities and commonalities is likely to hamper their understanding and replication planning. Aims: The goal of this paper is to explore the use of Variability Modeling Approaches (VMAs) to represent experiment families (i.e., an original study and its replications) and to investigate the feasibility of using VMAs to support experiment replication planning. Method: We selected two experiment families, analyzed their commonalities and variabilities, and represented them using a set of well-known VMAs: Feature Model, Decision Model, and Orthogonal Variability Model. Based on the resulting models, we conducted a preliminary comparison of using such alternative VMAs to support replication planning. Results: Subjects were able to plan consistent experiment replications with the VMAs as support. Additionally, through a qualitative analysis, we identified and discuss advantages and limitations of using the VMAs. Conclusions: It is feasible to represent experiment families and to plan replications using VMAs. Based on our emerging results, we conclude that the Feature Model VMA provides the most suitable representation. Furthermore, we identified benefits in a potential merge between the Feature Model and Decision Model VMAs to provide more details to support replication planning.},
booktitle = {Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering},
pages = {333–338},
numpages = {6},
keywords = {Experiment planning, experiment lines, experiment replication},
location = {Copenhagen, Denmark},
series = {EASE '19}
}

@inproceedings{10.1007/11554844_20,
author = {Etxeberria, Leire and Sagardui, Goiuria},
title = {Product-line architecture: new issues for evaluation},
year = {2005},
isbn = {3540289364},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11554844_20},
doi = {10.1007/11554844_20},
abstract = {In the product-line context, where a lack or mismatch in a quality attribute is potentially replicated among all products, product-line evaluation could detect problems before concrete products are developed. The life span of a software product-line architecture is much longer than the one of an ordinary software product and it serves as a basis for a set of related systems. Therefore, the product-line architecture should be adaptable to evolution as well as support a number of different products. All these characteristics set new requirements to the product-line architecture evaluation. This paper highlights the new issues that can arise when evaluating a product-line architecture versus evaluating a single-system architecture, including classifications of relevant attributes in product-line architecture evaluation, new evaluation moments and techniques. These issues are used as components of a framework to survey product-line architecture evaluation methods and metrics.},
booktitle = {Proceedings of the 9th International Conference on Software Product Lines},
pages = {174–185},
numpages = {12},
location = {Rennes, France},
series = {SPLC'05}
}

@inproceedings{10.1007/978-3-642-40615-7_1,
author = {H\"{a}hnle, Reiner},
title = {The Abstract Behavioral Specification Language: A Tutorial Introduction},
year = {2012},
isbn = {9783642406140},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-40615-7_1},
doi = {10.1007/978-3-642-40615-7_1},
abstract = {ABS for abstract behavioral specification is a novel language for modeling feature-rich, distributed, object-oriented systems at an abstract, yet precise level. ABS has a clear and simple concurrency model that permits synchronous as well as actor-style asynchronous communication. ABS abstracts away from specific datatype or I/O implementations, but is a fully executable language and has code generators for Java, Scala, and Maude. ABS goes beyond conventional programming languages in two important aspects: first, it embeds architectural concepts such as components or feature hierarchies and allows to connect features with their implementation in terms of product families. In contrast to standard OO languages, code reuse in ABS is feature-based instead of inheritance-based. Second, ABS has a formal semantics and has been designed with formal analyzability in mind. This paper gives a tutorial introduction to ABS. We discuss all important design features, explain why they are present and how they are intended to be used.},
booktitle = {Revised Lectures of the 11th International Symposium on Formal Methods for Components and Objects - Volume 7866},
pages = {1–37},
numpages = {37},
location = {Bertinoro, Italy},
series = {FMCO 2012}
}

@article{10.1007/s00607-020-00833-6,
author = {M\"{a}kitalo, Niko and Taivalsaari, Antero and Kiviluoto, Arto and Mikkonen, Tommi and Capilla, Rafael},
title = {On opportunistic software reuse},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {102},
number = {11},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-020-00833-6},
doi = {10.1007/s00607-020-00833-6},
abstract = {The availability of open source assets for almost all imaginable domains has led the software industry to opportunistic design—an approach in which people develop new software systems in an ad hoc fashion by reusing and combining components that were not designed to be used together. In this paper we investigate this emerging approach. We demonstrate the approach with an industrial example in which Node.js modules and various subsystems are used in an opportunistic way. Furthermore, to study opportunistic reuse as a phenomenon, we present the results of three contextual interviews and a survey with reuse practitioners to understand to what extent opportunistic reuse offers improvements over traditional systematic reuse approaches.},
journal = {Computing},
month = nov,
pages = {2385–2408},
numpages = {24},
keywords = {Software reuse, Software engineering, Opportunistic design, Opportunistic reuse, Software architecture, Code snippet, 68-04}
}

@inproceedings{10.1109/MSR.2017.19,
author = {Ishio, Takashi and Sakaguchi, Yusuke and Ito, Kaoru and Inoue, Katsuro},
title = {Source file set search for clone-and-own reuse analysis},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.19},
doi = {10.1109/MSR.2017.19},
abstract = {Clone-and-own approach is a natural way of source code reuse for software developers. To assess how known bugs and security vulnerabilities of a cloned component affect an application, developers and security analysts need to identify an original version of the component and understand how the cloned component is different from the original one. Although developers may record the original version information in a version control system and/or directory names, such information is often either unavailable or incomplete. In this research, we propose a code search method that takes as input a set of source files and extracts all the components including similar files from a software ecosystem (i.e., a collection of existing versions of software packages). Our method employs an efficient file similarity computation using b-bit minwise hashing technique. We use an aggregated file similarity for ranking components To evaluate the effectiveness of this tool, we analyzed 75 cloned components in Firefox and Android source code! The tool took about two hours to report the original components from 10 million files in Debian GNU/Linux packages. Recall of the top-five components in the extracted lists is 0.907, while recall of a baseline using SHA-1 file hash is 0.773, according to the ground truth recorded in the source code repositories.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {257–268},
numpages = {12},
keywords = {file clone detection, origin analysis, software reuse, source code search},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.5555/1885639.1885657,
author = {Elsner, Christoph and Ulbrich, Peter and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Consistent product line configuration across file type and product line boundaries},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Creating a valid software configuration of a product line can require laborious customizations involving multiple configuration file types, such as feature models, domain-specific languages, or preprocessor defines in C header files. Using configurable off-the-shelf components causes additional complexity. Without checking of constraints across file types boundaries already at configuration time, intricate inconsistencies are likely to be introduced--resulting in product defects, which are costly to discover and resolve later on.Up to now, at best ad-hoc solutions have been applied. To tackle this problem in a general way, we have developed an approach and a corresponding plug-in infrastructure. It allows for convenient definition and checking of constraints across configuration file types and product line boundaries. Internally, all configuration files are converted to models, facilitating the use of model-based constraint languages (e.g., OCL). Converter plug-ins for arbitrary configuration file types may be integrated and hide a large amount of complexity usually associated with modeling. We have validated our approach using a quadrotor helicopter product line comprising three sub-product-lines and four different configuration file formats. The results give evidence that our approach is practically applicable, reduces time and effort for product derivation (by avoiding repeated compiling, testing, and reconfiguration cycles), and prevents faulty software deployment.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {181–195},
numpages = {15},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@article{10.1016/j.infsof.2015.02.002,
author = {Galindo, Jos\'{e} A. and Dhungana, Deepak and Rabiser, Rick and Benavides, David and Botterweck, Goetz and Gr\"{u}nbacher, Paul},
title = {Supporting distributed product configuration by integrating heterogeneous variability modeling approaches},
year = {2015},
issue_date = {June 2015},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {62},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.02.002},
doi = {10.1016/j.infsof.2015.02.002},
abstract = {ContextIn industrial settings products are developed by more than one organization. Software vendors and suppliers commonly typically maintain their own product lines, which contribute to a larger (multi) product line or software ecosystem. It is unrealistic to assume that the participating organizations will agree on using a specific variability modeling technique-they will rather use different approaches and tools to manage the variability of their systems. ObjectiveWe aim to support product configuration in software ecosystems based on several variability models with different semantics that have been created using different notations. MethodWe present an integrative approach that provides a unified perspective to users configuring products in multi product line environments, regardless of the different modeling methods and tools used internally. We also present a technical infrastructure and a prototype implementation based on web services. ResultsWe show the feasibility of the approach and its implementation by using it with the three most widespread types of variability modeling approaches in the product line community, i.e., feature-based, OVM-style, and decision-oriented modeling. To demonstrate the feasibility and flexibility of our approach, we present an example derived from industrial experience in enterprise resource planning. We further applied the approach to support the configuration of privacy settings in the Android ecosystem based on multiple variability models. We also evaluated the performance of different model enactment strategies used in our approach. ConclusionsTools and techniques allowing stakeholders to handle variability in a uniform manner can considerably foster the initiation and growth of software ecosystems from the perspective of software reuse and configuration.},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {78–100},
numpages = {23},
keywords = {Automated analysis, Product configuration, Software product lines}
}

@article{10.1007/s10664-020-09912-w,
author = {Damasceno, Carlos Diego Nascimento and Mousavi, Mohammad Reza and Simao, Adenilso da Silva},
title = {Learning by sampling: learning behavioral family models from software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09912-w},
doi = {10.1007/s10664-020-09912-w},
abstract = {Family-based behavioral analysis operates on a single specification artifact, referred to as family model, annotated with feature constraints to express behavioral variability in terms of conditional states and transitions. Family-based behavioral modeling paves the way for efficient model-based analysis of software product lines. Family-based behavioral model learning incorporates feature model analysis and model learning principles to efficiently unify product models into a family model and integrate the behavior of various products into a behavioral family model. Albeit reasonably effective, the exhaustive analysis of product lines is often infeasible due to the potentially exponential number of valid configurations. In this paper, we first present a family-based behavioral model learning techniques, called FFSMDiff. Subsequently, we report on our experience on learning family models by employing product sampling. Using 105 products of six product lines expressed in terms of Mealy machines, we evaluate the precision of family models learned from products selected from different settings of the T-wise product sampling criterion. We show that product sampling can lead to models as precise as those learned by exhaustive analysis and hence, reduce the costs for family model learning.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {46},
keywords = {Software product lines, Model learning, Family model, T-wise sampling}
}

@inproceedings{10.1145/1842752.1842769,
author = {Weyns, Danny and Capilla, Rafael},
title = {Current and emerging topics in software architecture (ECSA 2010 Workshops Summary)},
year = {2010},
isbn = {9781450301794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842752.1842769},
doi = {10.1145/1842752.1842769},
abstract = {Since 2004 in St. Andrews (Scotland, U.K.), ECSA the European Conference on Software Architecture (formerly EWSA, the European Workshop on Software Architecture) has been considered as an important meeting point for researchers and practitioners on the topic of software architecture. ECSA has matured from a workshop format to a full software engineering conference in the subfield of software architecture.This year, ECSA has become more ambitious and expanded its scope and schedule up to four full days. The program includes a series of tutorials, a doctoral mentoring program, and four full-day workshops. New and existing software challenges have led to a variety of trends in software architecture research, which makes the conference and workshops more attractive and promotes the discussion on current and emerging topics.Based on the scientific and technical interest of the topics, the innovativeness of workshop topics, and the capacity of the conference workshop program, the workshop co-chairs selected four workshops from the nine submitted proposals. We summarize the aims and goals of each workshop and the contributions accepted for the four workshops:• 2nd International Workshop on Software Ecosystems (EcoSys). Piers Campbell, Faheem Ahmed, Jan Bosch, Sliger Jansen.• 1st International Workshop on Measurability of Security in Software Architectures (MeSSa). Reijo Savola, Teemu Kranst\'{e}n, Antti Evesti.• 8th Nordic Workshop on Model Driven Software Engineering (NW-MODE). Andrzej Wasowski, Dragos Truscan, Ludwik Kuzniarz.• 1st International Workshop on Variability in Software Product Line Architectures (VARI-ARCH). Alexander Helleboogh, Paris Avgeriou, Nelis Boucke, Patryck Heymans.The ECSA 2010 Workshop co-chairs would like to thanks all workshop organizers for their effort and enthusiasm to attract submission in different software architecture research topics and make the ECSA 2010 workshops a success.},
booktitle = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
pages = {59–62},
numpages = {4},
location = {Copenhagen, Denmark},
series = {ECSA '10}
}

@article{10.1016/j.scico.2011.06.007,
author = {Bettini, Lorenzo and Damiani, Ferruccio and Schaefer, Ina and Strocco, Fabio},
title = {TraitRecordJ: A programming language with traits and records},
year = {2013},
issue_date = {May, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {5},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2011.06.007},
doi = {10.1016/j.scico.2011.06.007},
abstract = {Traits have been designed as units for fine-grained reuse of behavior in the object-oriented paradigm. Records have been devised to complement traits for fine-grained reuse of state. In this paper, we present the language TraitRecordJ, a Java dialect with records and traits. Records and traits can be composed by explicit linguistic operations, allowing code manipulations to achieve fine-grained code reuse. Classes are assembled from (composite) records and traits and instantiated to generate objects. We introduce the language through examples and illustrate the prototypical implementation of TraitRecordJ using Xtext, an Eclipse framework for the development of programming languages as well as other domain-specific languages. Our implementation comprises an Eclipse-based editor for TraitRecordJ with typical IDE functionalities, and a stand-alone compiler, which translates TraitRecordJ programs into standard Java programs. As a case study, we present the TraitRecordJ implementation of a part of the software used in a web-based information system previously implemented in Java.},
journal = {Sci. Comput. Program.},
month = may,
pages = {521–541},
numpages = {21},
keywords = {Eclipse, Implementation, Java, Trait, Type system}
}

@article{10.1007/s11219-010-9115-6,
author = {Tiarks, Rebecca and Koschke, Rainer and Falke, Raimar},
title = {An extended assessment of type-3 clones as detected by state-of-the-art tools},
year = {2011},
issue_date = {June      2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9115-6},
doi = {10.1007/s11219-010-9115-6},
abstract = {Code reuse through copying and pasting leads to so-called software clones. These clones can be roughly categorized into identical fragments (type-1 clones), fragments with parameter substitution (type-2 clones), and similar fragments that differ through modified, deleted, or added statements (type-3 clones). Although there has been extensive research on detecting clones, detection of type-3 clones is still an open research issue due to the inherent vagueness in their definition. In this paper, we analyze type-3 clones detected by state-of-the-art tools and investigate type-3 clones in terms of their syntactic differences. Then, we derive their underlying semantic abstractions from their syntactic differences. Finally, we investigate whether there are code characteristics that indicate that a tool-suggested clone candidate is a real type-3 clone from a human's perspective. Our findings can help developers of clone detectors and clone refactoring tools to improve their tools.},
journal = {Software Quality Journal},
month = jun,
pages = {295–331},
numpages = {37},
keywords = {Clone categorization, Software clones, Type-3 clones}
}

@article{10.1007/s11219-021-09571-0,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {Dynamic test prioritization of product lines: An application on configurable simulation models},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-021-09571-0},
doi = {10.1007/s11219-021-09571-0},
abstract = {Product line testing is challenging due to the potentially huge number of configurations. Several approaches have tackled this challenge; most of them focused on reducing the number of tested products by selecting a representative subset. However, little attention has been paid to product line test optimization using test results, while tests are executed. This paper aims at optimizing the testing process of product lines by increasing the fault detection rate. To this end we propose a dynamic test prioritization approach. In contrast to traditional static test prioritization, our dynamic test prioritization leverages information of tests being executed in specific products. Processing this information, the initially prioritized tests are rearranged in order to find non-discovered faults. The proposed approach is valid for any kind of product lines, but we have adapted it to the context of configurable simulation models, an area where testing is especially time-consuming and optimization methods are paramount. The approach was empirically evaluated by employing two case studies. The results of this evaluation reveal that the proposed test prioritization approach improves both the static prioritization algorithm and the selected baseline technique. The results provide a basis for suggesting that the proposed dynamic test prioritization approach is appropriate to optimize the testing process of product lines.},
journal = {Software Quality Journal},
month = dec,
pages = {943–988},
numpages = {46},
keywords = {Test prioritization, Software product lines, Simulation-based testing, Cyber-Physical systems}
}

@inproceedings{10.1145/3023956.3023963,
author = {Halin, Axel and Nuttinck, Alexandre and Acher, Mathieu and Devroey, Xavier and Perrouin, Gilles and Heymans, Patrick},
title = {Yo variability! JHipster: a playground for web-apps analyses},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023963},
doi = {10.1145/3023956.3023963},
abstract = {Though variability is everywhere, there has always been a shortage of publicly available cases for assessing variability-aware tools and techniques as well as supports for teaching variability-related concepts. Historical software product lines contains industrial secrets their owners do not want to disclose to a wide audience. The open source community contributed to large-scale cases such as Eclipse, Linux kernels, or web-based plugin systems (Drupal, WordPress). To assess accuracy of sampling and prediction approaches (bugs, performance), a case where all products can be enumerated is desirable. As configuration issues do not lie within only one place but are scattered across technologies and assets, a case exposing such diversity is an additional asset. To this end, we present in this paper our efforts in building an explicit product line on top of JHipster, an industrial open-source Web-app configurator that is both manageable in terms of configurations (≈ 163,000) and diverse in terms of technologies used. We present our efforts in building a variability-aware chain on top of JHipster's configurator and lessons learned using it as a teaching case at the University of Rennes. We also sketch the diversity of analyses that can be performed with our infrastructure as well as early issues found using it. Our long term goal is both to support students and researchers studying variability analysis and JHipster developers in the maintenance and evolution of their tools.},
booktitle = {Proceedings of the 11th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {44–51},
numpages = {8},
keywords = {case study, variability-related analyses, web-apps},
location = {Eindhoven, Netherlands},
series = {VaMoS '17}
}

@inproceedings{10.1145/2420942.2420944,
author = {Olaechea, Rafael and Stewart, Steven and Czarnecki, Krzysztof and Rayside, Derek},
title = {Modelling and multi-objective optimization of quality attributes in variability-rich software},
year = {2012},
isbn = {9781450318075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420942.2420944},
doi = {10.1145/2420942.2420944},
abstract = {Variability-rich software, such as software product lines, offers optional and alternative features to accommodate varying needs of users. Designers of variability-rich software face the challenge of reasoning about the impact of selecting such features on the quality attributes of the resulting software variant. Attributed feature models have been proposed to model such features and their impact on quality attributes, but existing variability modelling languages and tools have limited or no support for such models and the complex multi-objective optimization problem that arises. This paper presents ClaferMoo, a language and tool that addresses these shortcomings. ClaferMoo uses type inheritance to modularize the attribution of features in feature models and allows specifying multiple optimization goals. We evaluate an implementation of the language on a set of attributed feature models from the literature, showing that the optimization infrastructure can handle small-scale feature models with about a dozen features within seconds.},
booktitle = {Proceedings of the Fourth International Workshop on Nonfunctional System Properties in Domain Specific Modeling Languages},
articleno = {2},
numpages = {6},
keywords = {multi-objective optimization, software product lines},
location = {Innsbruck, Austria},
series = {NFPinDSML '12}
}

@inproceedings{10.1145/2494603.2480298,
author = {Pleuss, Andreas and Wollny, Stefan and Botterweck, Goetz},
title = {Model-driven development and evolution of customized user interfaces},
year = {2013},
isbn = {9781450321389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2494603.2480298},
doi = {10.1145/2494603.2480298},
abstract = {One of the main benefits of model-driven development of User Interfaces (UIs) is the increase in efficiency and consistency when developing multiple variants of a UI. For instance, multiple UIs for different target users, platforms, devices, or for whole product families can be generated from the same abstract models. However, purely generated UIs are not always sufficient as there is often need for customizing the individual UI variants, e.g., due to usability issues or specific customer requirements.In this paper we present a model-driven approach for the development of UI families with systematic support for customizations. The approach supports customizing all aspects of a UI (UI elements, screens, navigation, etc.) and storing the customizations in specific models. As a result, a UI family can be evolved more efficiently because individual UI variants can be re-generated (after some changes have been applied to the family) without losing any previously made customizations. We demonstrate this by thirty highly customized real-world products from a commercial family of web information systems called HIS-GX/QIS.},
booktitle = {Proceedings of the 5th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {13–22},
numpages = {10},
keywords = {model-driven development, software product lines, usability engineering, user interface engineering},
location = {London, United Kingdom},
series = {EICS '13}
}

@inproceedings{10.1145/1868688.1868699,
author = {Kulkarni, Vinay},
title = {Raising family is a good practice},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868699},
doi = {10.1145/1868688.1868699},
abstract = {The need for adaptiveness of business applications is on the rise with continued increase in business dynamics. Code-centric techniques show unacceptable responsiveness in this dynamic context as business applications are subjected to changes along multiple dimensions that continue to evolve simultaneously. Recent literature suggests the use of product line architectures to increase adaptiveness by capturing commonality and variability to suitably configure the application. Use of model driven techniques for developing business applications is argued as a preferable option because platform independent specification can be retargeted to technology platform of choice through a code generation process. Business applications can be visualized to vary along five dimensions, namely, Functionality (F), Business process (P), Design decisions (D), Architecture (A) and Technology platform (T). Use of models is largely limited to F and P dimensions in commonly used model-driven development techniques thus limiting the benefits of product line concept to these two dimensions. We argue this is not sufficient to achieve the desired adaptiveness, and it is critical to extend the product line concept to D, A and T dimensions also. To address adaptation needs of business applications, this paper presents a model-driven generative approach that further builds on the ideas of separation of concerns, variability management and feature modeling. Early experience and lessons learnt are discussed, and future work outlined.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {72–79},
numpages = {8},
keywords = {adaptiveness, business applications, commonality, model-driven development, product families, product lines, variability},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/3425898.3426959,
author = {Bordis, Tabea and Runge, Tobias and Schaefer, Ina},
title = {Correctness-by-construction for feature-oriented software product lines},
year = {2020},
isbn = {9781450381741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425898.3426959},
doi = {10.1145/3425898.3426959},
abstract = {Software product lines are increasingly used to handle the growing demand of custom-tailored software variants. They provide systematic reuse of software paired with variability mechanisms in the code to implement whole product families rather than single software products. A common domain of application for product lines are safety-critical systems, which require behavioral correctness to avoid dangerous situations in-field. While most approaches concentrate on post-hoc verification for product lines, we argue that a stepwise approach to create correct programs may be beneficial for developers to manage the growing variability. Correctness-by-construction is such a stepwise approach to create programs using a set of small, tractable refinement rules that guarantee the correctness of the program with regard to its specification. In this paper, we propose the first approach to develop correct-by-construction software product lines using feature-oriented programming. First, we extend correctness-by-construction by two refinement rules for variation points in the code. Second, we give a proof for the soundness of the proposed rules. Third, we implement our technique in a tool called VarCorC and show the applicability of the tool by conducting two case studies.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {22–34},
numpages = {13},
keywords = {correctness-by-construction, feature-oriented programming, formal verification, software product lines},
location = {Virtual, USA},
series = {GPCE 2020}
}

@inproceedings{10.1145/2430502.2430520,
author = {Erwig, Martin and Ostermann, Klaus and Rendel, Tillmann and Walkingshaw, Eric},
title = {Adding configuration to the choice calculus},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430520},
doi = {10.1145/2430502.2430520},
abstract = {The choice calculus, a formal language for representing variation in software artifacts, features syntactic forms to map dimensions of variability to local choices between source code variants. However, the process of selecting alternatives from dimensions was relegated to an external operation. The lack of a syntactic form for selection precludes many interesting variation and reuse patterns, such as nested product lines, and theoretical results, such as a syntactic description of the configuration process.In this paper we add a selection operation to the choice calculus and illustrate how that increases the expressiveness of the calculus. We investigate some alternative semantics of this operation and study their impact and utility. Specifically, we will examine selection in the context of static and dynamically scoped dimension declarations, as a well as a linear and comprehensive form of dimension elimination. We also present a design for a type system to ensure configuration safety and modularity of nested product lines.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {13},
numpages = {8},
keywords = {choice calculus, modularity, semantics},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1145/1852761.1852780,
author = {Bettini, Lorenzo and Damiani, Ferruccio and Schaefer, Ina and Strocco, Fabio},
title = {A prototypical Java-like language with records and traits},
year = {2010},
isbn = {9781450302692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852761.1852780},
doi = {10.1145/1852761.1852780},
abstract = {Traits have been designed as units of fine-grained behavior reuse in the object-oriented paradigm. In this paper, we present the language Sugared Welterweight Record-Trait Java (SWRTJ), a Java dialect with records and traits. Records have been devised to complement traits for fine-grained state reuse. Records and traits can be composed by explicit linguistic operations, allowing code manipulations to achieve fine-grained code reuse. Classes are assembled from (composite) records and traits and instantiated to generate objects. We present the prototypical implementation of SWRTJ using Xtext, an Eclipse framework for the development of programming languages as well as other domain-specific languages. Our implementation comprises an Eclipse-based editor for SWRTJ with typical IDE functionalities, and a stand-alone compiler, which translates SWRTJ programs into standard Java programs.},
booktitle = {Proceedings of the 8th International Conference on the Principles and Practice of Programming in Java},
pages = {129–138},
numpages = {10},
keywords = {Eclipse, Java, implementation, trait, type system},
location = {Vienna, Austria},
series = {PPPJ '10}
}

@inproceedings{10.1145/3357765.3359525,
author = {Feichtinger, Kevin and Hinterreiter, Daniel and Linsbauer, Lukas and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {Supporting feature model evolution by suggesting constraints from code-level dependency analyses},
year = {2019},
isbn = {9781450369800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357765.3359525},
doi = {10.1145/3357765.3359525},
abstract = {Feature models are a de facto standard for representing the commonalities and variability of product lines and configurable software systems. Requirements-level features are commonly implemented in multiple source code artifacts, which results in complex dependencies at the code level. As developers change and evolve features frequently, it is challenging to keep feature models consistent with their implementation. We thus present an approach combining feature-to-code mappings and code dependency analyses to inform engineers about possible inconsistencies. Our focus is on code-level changes requiring updates in feature dependencies and constraints. Our approach uses static code analysis and a variation control system to lift complex code-level dependencies to feature models. We present the suggested dependencies to the engineer in two ways: directly as links between features in a feature model and as a heatmap visualizing the dependency changes of all features in a model. We present results of an evaluation on the Pick-and-Place Unit system, which demonstrates the utility and performance of our approach and the quality of the suggestions.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {129–142},
numpages = {14},
keywords = {dependency analysis, product lines, static code analysis, variation control system},
location = {Athens, Greece},
series = {GPCE 2019}
}

@article{10.1016/j.entcs.2016.02.005,
title = {A Model to Guide Dynamic Adaptation Planning in Self-Adaptive Systems},
year = {2016},
issue_date = {March 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {321},
number = {C},
issn = {1571-0661},
url = {https://doi.org/10.1016/j.entcs.2016.02.005},
doi = {10.1016/j.entcs.2016.02.005},
abstract = {Self-adaptive enterprise applications have the ability to continuously reconfigure themselves according to changes in their execution contexts or user requirements. The infrastructure managing such systems is based on IBM's MAPE-K reference model: a Monitor and an Analyzer to sense and interpret context data, a Planner and an Executor to create and apply structural adaptation plans, and a Knowledge manager to share relevant information. In this paper we present a formal model, built on the principles of constraint satisfaction, to address dynamic adaptation planning for self-adaptive enterprise applications. We formalize, modify and extend the approach presented in H. Arboleda, J. F. D\'{\i}az, V. Vargas, and J.-C. Royer, "Automated reasoning for derivation of modeldriven spls," in SPLC'10 MAPLE'10, 2010, pp. 181-188 for working with self-adaptation infrastructures in order to provide automated reasoning on the dynamic creation of structural adaptation plans. We use a running example to demonstrate the applicability of such model, even in situations where complex interactions arise between context elements and the target self-adaptive enterprise application.},
journal = {Electron. Notes Theor. Comput. Sci.},
month = mar,
pages = {67–88},
numpages = {22}
}

@inproceedings{10.1145/3350768.3350774,
author = {Souza, Iuri Santos and Machado, Ivan and Seaman, Carolyn and Gomes, Gecynalda and Chavez, Christina and de Almeida, Eduardo Santana and Masiero, Paulo},
title = {Investigating Variability-aware Smells in SPLs: An Exploratory Study},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350774},
doi = {10.1145/3350768.3350774},
abstract = {Variability-aware smell is a concept referring to artifact shortcomings in the context of highly-configurable systems that can degrade aspects such as program comprehension, maintainability, and evolvability. To the best of our knowledge, there is very little evidence that variability-aware smells exist in Software Product Lines (SPLs). This work presents an exploratory study that investigated (I) evidence that variability-aware smells exist in SPLs and (II) new types of variability-aware smell not yet documented in the literature based on a quantitative study with open source SPL projects. We collected quantitative data to generate reliable research evidence, by performing feature model and source code inspections on eleven open-source SPL projects. Our findings revealed that (1) instances of variability-aware smells exist in open-source SPL projects and (2) feature information presented significant associations with variability-aware smells. Furthermore, (3) the study presented six new types of variability-aware smells.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {367–376},
numpages = {10},
keywords = {Empirical Study, Exploratory Study, Software Product Lines, Variability-Aware Smells},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1109/ICSE43902.2021.00076,
author = {Hata, Hideaki and Kula, Raula Gaikovina and Ishio, Takashi and Treude, Christoph},
title = {Same File, Different Changes: The Potential of Meta-Maintenance on GitHub},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00076},
doi = {10.1109/ICSE43902.2021.00076},
abstract = {Online collaboration platforms such as GitHub have provided software developers with the ability to easily reuse and share code between repositories. With clone-and-own and forking becoming prevalent, maintaining these shared files is important, especially for keeping the most up-to-date version of reused code. Different to related work, we propose the concept of meta-maintenance---i.e., tracking how the same files evolve in different repositories with the aim to provide useful maintenance opportunities to those files. We conduct an exploratory study by analyzing repositories from seven different programming languages to explore the potential of meta-maintenance. Our results indicate that a majority of active repositories on GitHub contains at least one file which is also present in another repository, and that a significant minority of these files are maintained differently in the different repositories which contain them. We manually analyzed a representative sample of shared files and their variants to understand which changes might be useful for meta-maintenance. Our findings support the potential of meta-maintenance and open up avenues for future work to capitalize on this potential.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {773–784},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3442391.3442398,
author = {Bressan, Lucas and de Oliveira, Andr\'{e} Luiz and Campos, Fernanda and Capilla, Rafael},
title = {A variability modeling and transformation approach for safety-critical systems},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442398},
doi = {10.1145/3442391.3442398},
abstract = {Safety-critical autonomous systems are becoming highly variant-intensive with thousands of variations points within a single product. Modeling these systems requires the specification of safety properties, but the diversity of these properties makes hard to configure these systems manually to prevent emerging hazards and fault behaviors. Because existing software variability techniques provide rudimentary mechanisms for mapping variability constructs to functional safety models, we describe in this paper an experience report showing how a novel annotative modeling approach and tool can be used to derive system models enriched with functional safety information. We validate our approach using a case study from the automotive domain and we estimate the effort reduction in the tasks comparing our approach with two similar tools.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {7},
keywords = {Functional safety, Reuse, Safety critical systems, Variability modeling},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.1109/ICSE.2019.00090,
author = {Lillack, Max and St\u{a}nciulescu, \c{S}tefan and Hedman, Wilhelm and Berger, Thorsten and W\k{a}sowski, Andrzej},
title = {Intention-based integration of software variants},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00090},
doi = {10.1109/ICSE.2019.00090},
abstract = {Cloning is a simple way to create new variants of a system. While cheap at first, it increases maintenance cost in the long term. Eventually, the cloned variants need to be integrated into a configurable platform. Such an integration is challenging: it involves merging the usual code improvements between the variants, and also integrating the variable code (features) into the platform. Thus, variant integration differs from traditional software merging, which does not produce or organize configurable code, but creates a single system that cannot be configured into variants. In practice, variant integration requires fine-grained code edits, performed in an exploratory manner, in multiple iterations. Unfortunately, little tool support exists for integrating cloned variants.In this work, we show that fine-grained code edits needed for integration can be alleviated by a small set of integration intentions---domain-specific actions declared over code snippets controlling the integration. Developers can interactively explore the integration space by declaring (or revoking) intentions on code elements. We contribute the intentions (e.g., 'keep functionality' or 'keep as a configurable feature') and the IDE tool INCLINE, which implements the intentions and five editable views that visualize the integration process and allow declaring intentions producing a configurable integrated platform. In a series of experiments, we evaluated the completeness of the proposed intentions, the correctness and performance of INCLINE, and the benefits of using intentions for variant integration. The experiments show that INCLINE can handle complex integration tasks, that views help to navigate the code, and that it consistently reduces mistakes made by developers during variant integration.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {831–842},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3439961.3439975,
author = {Pald\^{e}s, Roberto Avila and Canedo, Edna Dias and Guimar\~{a}es, Fernando de Albuquerque and Calazans, Ang\'{e}lica Toffano Seidel},
title = {Functional Requirements Elicitation in IoT Systems: a follow-up study},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439975},
doi = {10.1145/3439961.3439975},
abstract = {As the Internet of Things (IoT) advances, specific views have been proposed for the entire software development cycle and also for Requirements Engineering (RE). The analysis of the use of RE techniques, tools, and models can contribute to obtain better results in this field. This paper presents a Systematic Mapping Study (SMS) to investigate techniques for Functional Requirements (FR) elicitation in IoT software systems, as well as gaps and limitations of current solutions. During the SMS, seventeen articles focused on FR in the IoT were found. The analysis was complemented with an input from the experience of practitioners who have dedicated to this topic, obtained through structured and semi-structured interviews. The results show that FR elicitation has started from the use of traditional techniques, but that these do not fully meet the specificities of the IoT. The majority of the models found are based on UML (Unified Modeling Language) and the most important techniques are based on scenarios. The tools that support these proposals are maturing or under development. In the conclusion, the study shows the advancements already achieved, as well as the challenges and opportunities that are still present.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {14},
numpages = {10},
keywords = {Functional Requirements Elicitation, Internet of Things, Software System, Systematic Mapping Study.},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@inproceedings{10.5555/2025896.2025909,
author = {Przyby\l{}ek, Adam},
title = {Systems evolution and software reuse in object-oriented programming and aspect-oriented programming},
year = {2011},
isbn = {9783642219511},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Every new programming technique makes claims that software engineers want to hear. Such is the case with aspect-oriented programming (AOP). This paper describes a quasi-controlled experiment which compares the evolution of two functionally equivalent programs, developed in two different paradigms. The aim of the study is to explore the claims that software developed with aspect-oriented languages is easier to maintain and reuse than this developed with object-oriented languages. We have found no evidence to support these claims.},
booktitle = {Proceedings of the 49th International Conference on Objects, Models, Components, Patterns},
pages = {163–178},
numpages = {16},
keywords = {AOP, maintainability, reusability, separation of concerns},
location = {Zurich, Switzerland},
series = {TOOLS'11}
}

@inproceedings{10.1007/978-3-319-26844-6_32,
author = {Brink, Christopher and Heisig, Philipp and Sachweh, Sabine},
title = {Using Cross-Dependencies During Configuration of System Families},
year = {2015},
isbn = {9783319268439},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-26844-6_32},
doi = {10.1007/978-3-319-26844-6_32},
abstract = {Nowadays, the automotive industry uses software product lines to support the management and maintenance of software variants. However, the development of mechatronic systems includes not merely software, but also other system parts like operating system, hardware or even mechanical parts. We call a combination of these system parts a system family SF. This combination raises the question how different variable system parts can be modeled and used for a combined configuration in a flexible way. We argue that a modeling process should combine all of these system parts, while the product configuration has to consider dependencies between them. Based on our previous work, we address this question and discuss dependencies between different system parts.},
booktitle = {Proceedings of the 16th International Conference on Product-Focused Software Process Improvement - Volume 9459},
pages = {439–452},
numpages = {14},
keywords = {Dependencies, Feature models, Hardware/software, Product lines, System families, Systems},
location = {Bolzano, Italy},
series = {PROFES 2015}
}

@article{10.1007/s10270-015-0470-4,
author = {Lochau, Malte and B\"{u}rdek, Johannes and H\"{o}lzle, Stefan and Sch\"{u}rr, Andy},
title = {Specification and automated validation of staged reconfiguration processes for dynamic software product lines},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0470-4},
doi = {10.1007/s10270-015-0470-4},
abstract = {Dynamic software product lines (DSPLs) propose elaborated design and implementation principles for engineering highly configurable runtime-adaptive systems in a sustainable and feature-oriented way. For this, DSPLs add to classical software product lines (SPL) the notions of (1) staged (pre-)configurations with dedicated binding times for each individual feature, and (2) continuous runtime reconfigurations of dynamic features throughout the entire product life cycle. Especially in the context of safety- and mission-critical systems, the design of reliable DSPLs requires capabilities for accurately specifying and validating arbitrary complex constraints among configuration parameters and/or respective reconfiguration options. Compared to classical SPL domain analysis which is usually based on Boolean constraint solving, DSPL validation, therefore, further requires capabilities for checking temporal properties of reconfiguration processes. In this article, we present a comprehensive approach for modeling and automatically verifying essential validity properties of staged reconfiguration processes with complex binding time constraints during DSPL domain engineering. The novel modeling concepts introduced are motivated by (re-)configuration constraints apparent in a real-world industrial case study from the automation engineering domain, which are not properly expressible and analyzable using state-of-the-art SPL domain modeling approaches. We present a prototypical tool implementation based on the model checker SPIN and present evaluation results obtained from our industrial case study, demonstrating the applicability of the approach.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {125–152},
numpages = {28},
keywords = {Dynamic software product lines, Model checking, Model-based domain engineering and validation, Staged configuration}
}

@article{10.1016/j.jss.2015.05.006,
author = {Bakar, Noor Hasrina and Kasirun, Zarinah M. and Salleh, Norsaremah},
title = {Feature extraction approaches from natural language requirements for reuse in software product lines},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2015.05.006},
doi = {10.1016/j.jss.2015.05.006},
abstract = {Hybrid NLP approaches were more common for extracting textual requirements.There is a mixture of automated and semi-automated approaches from IR and data mining.Support tools were not made available to the public.Not all studies use software metrics in conjunction with experiments and case studies.Reconfirm practitioners guidelines' absence from selected studies (Alves et al., 2010). Requirements for implemented system can be extracted and reused for a production of a new similar system. Extraction of common and variable features from requirements leverages the benefits of the software product lines engineering (SPLE). Although various approaches have been proposed in feature extractions from natural language (NL) requirements, no related literature review has been published to date for this topic. This paper provides a systematic literature review (SLR) of the state-of-the-art approaches in feature extractions from NL requirements for reuse in SPLE. We have included 13 studies in our synthesis of evidence and the results showed that hybrid natural language processing approaches were found to be in common for overall feature extraction process. A mixture of automated and semi-automated feature clustering approaches from data mining and information retrieval were also used to group common features, with only some approaches coming with support tools. However, most of the support tools proposed in the selected studies were not made available publicly and thus making it hard for practitioners' adoption. As for the evaluation, this SLR reveals that not all studies employed software metrics as ways to validate experiments and case studies. Finally, the quality assessment conducted confirms that practitioners' guidelines were absent in the selected studies.},
journal = {J. Syst. Softw.},
month = aug,
pages = {132–149},
numpages = {18},
keywords = {Feature extractions, Natural language requirements, Requirements reuse, Software product lines, Systematic literature review}
}

@inproceedings{10.1145/3442391.3442401,
author = {Setyautami, Maya Retno Ayu and H\"{a}hnle, Reiner},
title = {An Architectural Pattern to Realize Multi Software Product Lines in Java},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442401},
doi = {10.1145/3442391.3442401},
abstract = {We present a realization of multi software product lines in the Java programming language that permits full interoperability and hierarchical dependencies among multiple product variants. This concept, called variability modules (VM), is implemented in terms of an architectural pattern in Java and does not require any pre-processing or language extension. It can be used with any Java development environment. The VM architectural pattern comes with a dedicated UML profile, which makes it possible to present variability to non-technical stakeholders. We evaluate our approach with the help of a real-world case study.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {9},
numpages = {9},
keywords = {Software product lines, delta-oriented programming, variability modeling},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.5555/648114.748916,
author = {Salicki, Serge and Farcet, Nicolas},
title = {Expression and Usage of the Variability in the Software Product Lines},
year = {2001},
isbn = {3540436596},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines are used by companies to provide a set of reusable software assets sharing common features that satisfy a market. Though a product line is based on the expression and the capitalization of a family of similar systems, the differences between products must be identified and expressed in order to be able to build the applications by taking the good decisions. Today, even if the flexibility aspects are well covered, there isn't as many studies on variability description and usage. This paper presents a process, methods and techniques investigated in THALES (Research Center and Business Units) to express the variability between products and its usage to derive new products from the Software product line.},
booktitle = {Revised Papers from the 4th International Workshop on Software Product-Family Engineering},
pages = {304–318},
numpages = {15},
keywords = {decision model, derivation, method, process, product line, variability, variation points},
series = {PFE '01}
}

@inproceedings{10.1145/1858996.1859009,
author = {Vierhauser, Michael and Gr\"{u}nbacher, Paul and Egyed, Alexander and Rabiser, Rick and Heider, Wolfgang},
title = {Flexible and scalable consistency checking on product line variability models},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859009},
doi = {10.1145/1858996.1859009},
abstract = {The complexity of product line variability models makes it hard to maintain their consistency over time regardless of the modeling approach used. Engineers thus need support for detecting and resolving inconsistencies. We describe experiences of applying a tool-supported approach for incremental consistency checking on variability models. Our approach significantly improves the overall performance and scalability compared to batch-oriented techniques and allows providing immediate feedback to modelers. It is extensible as new consistency constraints can easily be added. Furthermore, the approach is flexible as it is not limited to variability models and it also checks the consistency of the models with the underlying code base of the product line. We report the results of a thorough evaluation based on real-world product line models and discuss lessons learned.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {incremental consistency checking, lessons learned, memory consumption, model consistency, performance, software product lines, variability models},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.5555/645882.672250,
author = {Ferber, Stefan and Haag, J\"{u}rgen and Savolainen, Juha},
title = {Feature Interaction and Dependencies: Modeling Features for Reengineering a Legacy Product Line},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Reengineering a legacy product line has been addressed very little by current product line research activities. This paper introduces a method to investigate feature dependencies and interactions, which restricts the variants that can be derived from the legacy product line assets. Reorganizing the product line assets with respect to new requirements requires more knowledge than what is easily provided by the classical feature-modeling approaches. Hence, adding all the feature dependencies and interactions into the feature tree results in unreadable and unmanageable feature models that fail to achieve their original goals.We therefore propose two complementary views to represent the feature model. One view shows the hierarchical refinement of features similar to common feature-modeling approaches in a feature tree. The second view describes what kind of dependencies and interactions there are between various features.We show two examples of feature dependencies and interactions in the context of an engine-control software product line, and we demonstrate how our approach helps to define correct product configurations from product line variants.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {235–256},
numpages = {22},
series = {SPLC 2}
}

@article{10.1145/2020976.2020978,
author = {Galster, Matthias and Avgeriou, Paris and Weyns, Danny and M\"{a}nnist\"{o}, Tomi},
title = {Variability in software architecture: current practice and challenges},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2020976.2020978},
doi = {10.1145/2020976.2020978},
abstract = {Variability in software-intensive systems is usually understood as the ability of a software artifact to be changed in order to fit different contexts, environments, or purposes. Software architecture on the other hand determines the structure of a software system, and is described in an architecture description. This description includes the major stakeholders of a software system and their concerns. Variability is reflected in and facilitated through the software architecture. The First International Workshop on Variability in Software Architecture (VARSA) was held jointly with WICSA 2011 in Boulder, Colorado. The goal of the workshop was to explore and advance the state-of-the art in variability in software architecture. It featured four research paper presentations, two invited talks, and three working groups that discussed specific topics. This report summarizes the themes of the workshop, presents the results of the working group discussions, and suggests topics for further research.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {30–32},
numpages = {3}
}

@article{10.1016/j.datak.2021.101893,
author = {G\'{o}mez, Paola and Roncancio, Claudia and Casallas, Rubby},
title = {Analysis and evaluation of document-oriented structures},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {134},
number = {C},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2021.101893},
doi = {10.1016/j.datak.2021.101893},
journal = {Data Knowl. Eng.},
month = jul,
numpages = {21},
keywords = {NoSQL, Structural metrics, Document-oriented systems, MongoDB}
}

@article{10.1007/s10664-015-9360-1,
author = {Hunsen, Claus and Zhang, Bo and Siegmund, Janet and K\"{a}stner, Christian and Leβenich, Olaf and Becker, Martin and Apel, Sven},
title = {Preprocessor-based variability in open-source and industrial software systems: An empirical study},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9360-1},
doi = {10.1007/s10664-015-9360-1},
abstract = {Almost every sufficiently complex software system today is configurable. Conditional compilation is a simple variability-implementation mechanism that is widely used in open-source projects and industry. Especially, the C preprocessor (CPP) is very popular in practice, but it is also gaining (again) interest in academia. Although there have been several attempts to understand and improve CPP, there is a lack of understanding of how it is used in open-source and industrial systems and whether different usage patterns have emerged. The background is that much research on configurable systems and product lines concentrates on open-source systems, simply because they are available for study in the first place. This leads to the potentially problematic situation that it is unclear whether the results obtained from these studies are transferable to industrial systems. We aim at lowering this gap by comparing the use of CPP in open-source projects and industry--especially from the embedded-systems domain--based on a substantial set of subject systems and well-known variability metrics, including size, scattering, and tangling metrics. A key result of our empirical study is that, regarding almost all aspects we studied, the analyzed open-source systems and the considered embedded systems from industry are similar regarding most metrics, including systems that have been developed in industry and made open source at some point. So, our study indicates that, regarding CPP as variability-implementation mechanism, insights, methods, and tools developed based on studies of open-source systems are transferable to industrial systems--at least, with respect to the metrics we considered.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {449–482},
numpages = {34},
keywords = {C preprocessor, Configurable systems, Industrial systems, Open-source systems, Software product lines, Variability, cppstats}
}

@inproceedings{10.5555/645882.672395,
author = {Kang, Kyo Chul and Donohoe, Patrick and Koh, Eunman and Lee, Jaejoon and Lee, Kwanwoo},
title = {Using a Marketing and Product Plan as a Key Driver for Product Line Asset Development},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The product line engineering paradigm has emerged recently to address the need to minimize the development cost and the time to market in this highly competitive global market. Product line development consists of product line asset development and product development using the assets. Product line requirements are essential inputs to product line asset development. These inputs, although critical, are not sufficient to develop product line assets. A marketing and product plan, which includes plans on what features are to be packaged in products, how these features will be delivered to customers (e.g., feature binding time), and how the products will evolve in the future, also drives product line asset development; thus this paper explores design issues from the marketing perspective and presents key design drivers that are tightly coupled with the marketing strategy. An elevator control software example is used to illustrate how product line asset development is related to marketing and product plans.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {366–382},
numpages = {17},
series = {SPLC 2}
}

@inproceedings{10.5555/645882.672259,
author = {Deursen, Arie van and Jonge, Merijn de and Kuipers, Tobias},
title = {Feature-Based Product Line Instantiation Using Source-Level Packages},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we discuss the construction of software products from customer-specific feature selections. We address variability management with the Feature Description Language (FDL) to capture variation points of product line architectures. We describe feature packaging, which covers selecting and packaging implementation components according to feature selections using the autobundle tool. Finally, we discuss a generic approach, based on the abstract factory design pattern, to make instantiated (customer-specific) variability accessible in applications.The solutions and techniques presented in this paper are based on our experience with the product line architecture of the commercial documentation generator DocGen.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {217–234},
numpages = {18},
series = {SPLC 2}
}

@article{10.1016/j.jss.2014.01.021,
author = {Walraven, Stefan and Van Landuyt, Dimitri and Truyen, Eddy and Handekyn, Koen and Joosen, Wouter},
title = {Efficient customization of multi-tenant Software-as-a-Service applications with service lines},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.01.021},
doi = {10.1016/j.jss.2014.01.021},
abstract = {Application-level multi-tenancy is an architectural approach for Software-as-a-Service (SaaS) applications which enables high operational cost efficiency by sharing one application instance among multiple customer organizations (the so-called tenants). However, the focus on increased resource sharing typically results in a one-size-fits-all approach. In principle, the shared application instance satisfies only the requirements common to all tenants, without supporting potentially different and varying requirements of these tenants. As a consequence, multi-tenant SaaS applications are inherently limited in terms of flexibility and variability. This paper presents an integrated service engineering method, called service line engineering, that supports co-existing tenant-specific configurations and that facilitates the development and management of customizable, multi-tenant SaaS applications, without compromising scalability. Specifically, the method spans the design, implementation, configuration, composition, operations and maintenance of a SaaS application that bundles all variations that are based on a common core. We validate this work by illustrating the benefits of our method in the development of a real-world SaaS offering for document processing. We explicitly show that the effort to configure and compose an application variant for each individual tenant is significantly reduced, though at the expense of a higher initial development effort.},
journal = {J. Syst. Softw.},
month = may,
pages = {48–62},
numpages = {15},
keywords = {Multi-tenancy, SaaS, Variability}
}

@article{10.1007/s11219-016-9341-7,
author = {Arrieta, Aitor and Sagardui, Goiuria and Etxeberria, Leire and Zander, Justyna},
title = {Automatic generation of test system instances for configurable cyber-physical systems},
year = {2017},
issue_date = {September 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9341-7},
doi = {10.1007/s11219-016-9341-7},
abstract = {Cyber-physical systems (CPSs) are ubiquitous systems that integrate digital technologies with physical processes. These systems are becoming configurable to respond to the different needs that users demand. As a consequence, their variability is increasing, and they can be configured in many system variants. To ensure a systematic test execution of CPSs, a test system must be elaborated encapsulating several sources such as test cases or test oracles. Manually building a test system for each configuration is a non-systematic, time-consuming, and error-prone process. To overcome these problems, we designed a test system for testing CPSs and we analyzed the variability that it needed to test different configurations. Based on this analysis, we propose a methodology supported by a tool named ASTERYSCO that automatically generates simulation-based test system instances to test individual configurations of CPSs. To evaluate the proposed methodology, we selected different configurations of a configurable Unmanned Aerial Vehicle, and measured the time required to generate their test systems. On average, around 119 s were needed by our tool to generate the test system for 38 configurations. In addition, we compared the process of generating test system instances between the method we propose and a manual approach. Based on this comparison, we believe that the proposed tool allows a systematic method of generating test system instances. We believe that our approach permits an important step toward the full automation of testing in the field of configurable CPSs.},
journal = {Software Quality Journal},
month = sep,
pages = {1041–1083},
numpages = {43},
keywords = {Configurable cyber-physical systems, Test automation, Test system generation}
}

@inproceedings{10.1145/3023147.3023152,
author = {Schuts, Mathijs and Hooman, Jozef},
title = {Improving maintenance by creating a DSL for configuring a fieldbus},
year = {2016},
isbn = {9781450348942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023147.3023152},
doi = {10.1145/3023147.3023152},
abstract = {The high-tech industry produces complex devices in which software plays an important role. Since these devices have been developed for many decades, an increasing part of the software can be classified as legacy which is difficult to maintain and to extend. To improve the maintainability of legacy components, domain specific languages (DSLs) provide promising perspectives. We present a DSL for creating configuration files that describe the topology of a fieldbus. This DSL improves the maintainability and extensibility of a legacy component. Compared to the current way-of-working, the configuration files generated by the DSL are of higher quality due to the concise representation of DSL instances and additional validation checks. To raise the level of abstraction even more, we have created a second DSL which allows a concise description of system configurations and the generation of topologies.},
booktitle = {Proceedings of the International Workshop on Domain-Specific Modeling},
pages = {28–34},
numpages = {7},
keywords = {Domain Specific Languages, Industrial Application, Legacy Software, Software Maintenance},
location = {Amsterdam, Netherlands},
series = {DSM 2016}
}

@article{10.1016/j.infsof.2015.08.007,
author = {Sep\'{u}lveda, Samuel and Cravero, Ania and Cachero, Cristina},
title = {Requirements modeling languages for software product lines},
year = {2016},
issue_date = {January 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {69},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2015.08.007},
doi = {10.1016/j.infsof.2015.08.007},
abstract = {There is a concern for generating proposals with higher levels of expressiveness.There is not a strong relationship between the proposals and SPL development process.There is a need for better ways to validate the modeling proposals.The proposals have a low level of empirical validation and adoption in industry.The level of maturity, expressive power and tool support of the proposals is low. Display Omitted Context: Software product lines (SPLs) have reached a considerable level of adoption in the software industry, having demonstrated their cost-effectiveness for developing higher quality products with lower costs. For this reason, in the last years the requirements engineering community has devoted much effort to the development of a myriad of requirements modelling languages for SPLs.Objective: In this paper, we review and synthesize the current state of research of requirements modelling languages used in SPLs with respect to their degree of empirical validation, origin and context of use, level of expressiveness, maturity, and industry adoption.Method: We have conducted a systematic literature review with six research questions that cover the main objective. It includes 54 studies, published from 2000 to 2013.Results: The mean level of maturity of the modelling languages is 2.59 over 5, with 46% of them falling within level 2 or below -no implemented abstract syntax reported-. They show a level of expressiveness of 0.7 over 1.0. Some constructs (feature, mandatory, optional, alternative, exclude and require) are present in all the languages, while others (cardinality, attribute, constraint and label) are less common. Only 6% of the languages have been empirically validated, 41% report some kind of industry adoption and 71% of the languages are independent from any development process. Last but not least, 57% of the languages have been proposed by the academia, while 43% have been the result of a joint effort between academia and industry.Conclusions: Research on requirements modeling languages for SPLs has generated a myriad of languages that differ in the set of constructs provided to express SPL requirements. Their general lack of empirical validation and adoption in industry, together with their differences in maturity, draws the picture of a discipline that still needs to evolve.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {16–36},
numpages = {21},
keywords = {Modeling languages, Requirements engineering, Software product lines, Systematic literature review}
}

@article{10.1145/3041957,
author = {Rosa, Marcello La and Aalst, Wil M. P. Van Der and Dumas, Marlon and Milani, Fredrik P.},
title = {Business Process Variability Modeling: A Survey},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3041957},
doi = {10.1145/3041957},
abstract = {It is common for organizations to maintain multiple variants of a given business process, such as multiple sales processes for different products or multiple bookkeeping processes for different countries. Conventional business process modeling languages do not explicitly support the representation of such families of process variants. This gap triggered significant research efforts over the past decade, leading to an array of approaches to business process variability modeling. In general, each of these approaches extends a conventional process modeling language with constructs to capture customizable process models. A customizable process model represents a family of process variants in a way that a model of each variant can be derived by adding or deleting fragments according to customization options or according to a domain model. This survey draws up a systematic inventory of approaches to customizable process modeling and provides a comparative evaluation with the aim of identifying common and differentiating modeling features, providing criteria for selecting among multiple approaches, and identifying gaps in the state of the art. The survey puts into evidence an abundance of customizable process-modeling languages, which contrasts with a relative scarcity of available tool support and empirical comparative evaluations.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {2},
numpages = {45},
keywords = {Variability modeling, customizable process model, process model}
}

@inproceedings{10.1145/2430502.2430523,
author = {Pillat, Raquel M. and Basso, Fabio P. and Oliveira, Toacy C. and Werner, Cl\'{a}udia M. L.},
title = {Ensuring consistency of feature-based decisions with a business rule system},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430523},
doi = {10.1145/2430502.2430523},
abstract = {Feature Models are widely used in some domains to represent variabilities and support decisions that configure a specific combination of domain elements. A feature configuration is created by selecting a features set that satisfies constraints imposed by the model. However, especially regarding complex or large models, end users are prone to making inconsistent decisions. In these cases, an automated support to assist users while resolving decision conflicts and restoring the configuration's validity is highly desirable. Thus, this paper proposes a flexible approach to ensure the consistency of feature configurations which is based on a Business Rules Management System (BRMS). Such systems are essential components in the world of business decision support applications due to facilities provided for constraints specification and execution management. The proposed approach shows how existing BRMS can be effectively used in a feature configuration process to resolve decision conflicts and restore the configuration correctness after user's illegal decisions while helping him/her to reason about possibilities that the model offers and to understand the impact of each decision-making. The main advantage of using a BRMS to specify and manage feature model constraints is the facility with which such complex activities can be supported. This paper reports preliminary research results achieved with the proposed approach.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {8},
keywords = {business rule system, consistency management, feature-based decisions},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1145/3377811.3380372,
author = {Lienhardt, Michael and Damiani, Ferruccio and Johnsen, Einar Broch and Mauro, Jacopo},
title = {Lazy product discovery in huge configuration spaces},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380372},
doi = {10.1145/3377811.3380372},
abstract = {Highly-configurable software systems can have thousands of interdependent configuration options across different subsystems. In the resulting configuration space, discovering a valid product configuration for some selected options can be complex and error prone. The configuration space can be organized using a feature model, fragmented into smaller interdependent feature models reflecting the configuration options of each subsystem.We propose a method for lazy product discovery in large fragmented feature models with interdependent features. We formalize the method and prove its soundness and completeness. The evaluation explores an industrial-size configuration space. The results show that lazy product discovery has significant performance benefits compared to standard product discovery, which in contrast to our method requires all fragments to be composed to analyze the feature model. Furthermore, the method succeeds when more efficient, heuristics-based engines fail to find a valid configuration.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1509–1521},
numpages = {13},
keywords = {Linux distribution, composition, configurable software, feature models, software product lines, variability modeling},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1016/j.jss.2011.08.008,
author = {Pleuss, Andreas and Botterweck, Goetz and Dhungana, Deepak and Polzer, Andreas and Kowalewski, Stefan},
title = {Model-driven support for product line evolution on feature level},
year = {2012},
issue_date = {October, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {85},
number = {10},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2011.08.008},
doi = {10.1016/j.jss.2011.08.008},
abstract = {Highlights We model the evolution of a product line on feature model level. Our approach supports both modeling of historic evolution and proactively planning of future evolution. The initial evolution model can be derived automatically from a given sequence of feature model versions. After planning future evolution using the evolution model, the resulting feature models can be generated automatically. The evolution model provides a foundation for automated analyses and interactive tools. Software Product Lines (SPL) are an engineering technique to efficiently derive a set of similar products from a set of shared assets. In particular in conjunction with model-driven engineering, SPL engineering promises high productivity benefits. There is however, a lack of support for systematic management of SPL evolution, which is an important success factor as a product line often represents a long term investment. In this article, we present a model-driven approach for managing SPL evolution on feature level. To reduce complexity we use model fragments to cluster related elements. The relationships between these fragments are specified using feature model concepts itself leading to a specific kind of feature model called EvoFM. A configuration of EvoFM represents an evolution step and can be transformed to a concrete instance of the product line (i.e., a feature model for the corresponding point in time). Similarly, automatic transformations allow the derivation of an EvoFM from a given set of feature models. This enables retrospective analysis of historic evolution and serves as a starting point for introduction of EvoFM, e.g., to plan future evolution steps.},
journal = {J. Syst. Softw.},
month = oct,
pages = {2261–2274},
numpages = {14},
keywords = {Evolving systems, Feature modeling, Model-driven engineering, Software Product Lines}
}

@inproceedings{10.1145/2783258.2783270,
author = {Yan, Feng and Ruwase, Olatunji and He, Yuxiong and Chilimbi, Trishul},
title = {Performance Modeling and Scalability Optimization of Distributed Deep Learning Systems},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783270},
doi = {10.1145/2783258.2783270},
abstract = {Big deep neural network (DNN) models trained on large amounts of data have recently achieved the best accuracy on hard tasks, such as image and speech recognition. Training these DNNs using a cluster of commodity machines is a promising approach since training is time consuming and compute-intensive. To enable training of extremely large DNNs, models are partitioned across machines. To expedite training on very large data sets, multiple model replicas are trained in parallel on different subsets of the training examples with a global parameter server maintaining shared weights across these replicas. The correct choice for model and data partitioning and overall system provisioning is highly dependent on the DNN and distributed system hardware characteristics. These decisions currently require significant domain expertise and time consuming empirical state space exploration.This paper develops performance models that quantify the impact of these partitioning and provisioning decisions on overall distributed system performance and scalability. Also, we use these performance models to build a scalability optimizer that efficiently determines the optimal system configuration that minimizes DNN training time. We evaluate our performance models and scalability optimizer using a state-of-the-art distributed DNN training framework on two benchmark applications. The results show our performance models estimate DNN training time with high estimation accuracy and our scalability optimizer correctly chooses the best configurations, minimizing the training time of distributed DNNs.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1355–1364},
numpages = {10},
keywords = {deep learning, distributed system, optimization, performance modeling, scalability},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2578128.2578237,
author = {de Andrade, Hugo Sica and Almeida, Eduardo and Crnkovic, Ivica},
title = {Architectural bad smells in software product lines: an exploratory study},
year = {2014},
isbn = {9781450325233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2578128.2578237},
doi = {10.1145/2578128.2578237},
abstract = {The Software Product Lines (SPL) paradigm has arisen for taking advantage of existing common aspects between different products, while also considering product-specific features. The architecture of a SPL comprises a model that will result in product architectures, and may include solutions leading to bad (architectural) design. One way to assess such design decisions is through the identification of architectural bad smells, which are properties that prejudice the overall software quality, but are not necessarily faulty or errant. In this paper, we conduct an exploratory study that aims at characterizing bad smells in the context of product line architectures. We analyzed an open source SPL project and extracted its architecture to investigate the occurrence or absence of four smells initially studied in single systems. In addition, we propose a smell specific to the SPL context and discuss possible causes and implications of having those smells in the architecture of a product line. The results indicate that the granularity of the SPL features may influence on the occurrence of smells.},
booktitle = {Proceedings of the WICSA 2014 Companion Volume},
articleno = {12},
numpages = {6},
keywords = {architectural bad smells, architecture, evaluation, exploratory study, software product lines},
location = {Sydney, Australia},
series = {WICSA '14 Companion}
}

@article{10.5555/2594638.2594643,
author = {Hotz, Lothar and Wolter, Katharina},
title = {Beyond physical product configuration --Configuration in unusual domains},
year = {2013},
issue_date = {January 2013},
publisher = {IOS Press},
address = {NLD},
volume = {26},
number = {1},
issn = {0921-7126},
abstract = {Configuration technologies are typically applied in domains with physical products. In this article, we determine characteristics of configuration technologies that are used to compose non-pure physical products. Starting from two case studies software-intensive systems and scene interpretation where we successfully applied configuration, we determine some characteristics of knowledge representation languages and configuration systems that enable to solve configuration tasks in domains beyond pure physical products. As such, the article provides thinking outside the box of physical product configuration.},
journal = {AI Commun.},
month = jan,
pages = {39–66},
numpages = {28},
keywords = {Knowledge Representation, Knowledge-Based Configuration, Scene Interpretation, Software-Intensive Systems}
}

@inproceedings{10.1145/2346536.2346547,
author = {Shang, Richard D. and Mohan, Kannan and Lang, Karl R. and Vragov, Roumen},
title = {A market mechanism for software component reuse: opportunities and barriers},
year = {2012},
isbn = {9781450311977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2346536.2346547},
doi = {10.1145/2346536.2346547},
abstract = {We propose a market based design for trading component-based software products bundled with reuse licenses that allows clients to customize software solutions onsite by reusing and reintegrating components across software systems using their own software development platforms. Using economic experiments in the laboratory with IT professionals we find that introducing reuse licenses has social welfare benefits in terms of both higher seller and higher buyer surplus as well as generating higher product variety in the market. We argue that as software development is increasingly using modularized and component-based approaches software vendor strategies based on flexible licenses permitting the reuse of software offer a viable and sustainable alternative to the traditional software business model build on monolithic user licenses.},
booktitle = {Proceedings of the 14th Annual International Conference on Electronic Commerce},
pages = {62–69},
numpages = {8},
location = {Singapore, Singapore},
series = {ICEC '12}
}

@article{10.1007/s11219-011-9160-9,
author = {Perrouin, Gilles and Oster, Sebastian and Sen, Sagar and Klein, Jacques and Baudry, Benoit and Traon, Yves},
title = {Pairwise testing for software product lines: comparison of two approaches},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9160-9},
doi = {10.1007/s11219-011-9160-9},
abstract = {Software Product Lines (SPL) are difficult to validate due to combinatorics induced by variability, which in turn leads to combinatorial explosion of the number of derivable products. Exhaustive testing in such a large products space is hardly feasible. Hence, one possible option is to test SPLs by generating test configurations that cover all possible t feature interactions (t-wise). It dramatically reduces the number of test products while ensuring reasonable SPL coverage. In this paper, we report our experience on applying t-wise techniques for SPL with two independent toolsets developed by the authors. One focuses on generality and splits the generation problem according to strategies. The other emphasizes providing efficient generation. To evaluate the respective merits of the approaches, measures such as the number of generated test configurations and the similarity between them are provided. By applying these measures, we were able to derive useful insights for pairwise and t-wise testing of product lines.},
journal = {Software Quality Journal},
month = sep,
pages = {605–643},
numpages = {39},
keywords = {Alloy, Model-based engineering and testing, Software product lines, Test generation, t-wise and pairwise}
}

@article{10.1016/j.infsof.2009.05.001,
author = {Lisboa, Liana Barachisio and Garcia, Vinicius Cardoso and Lucr\'{e}dio, Daniel and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero and de Mattos Fortes, Renata Pontin},
title = {A systematic review of domain analysis tools},
year = {2010},
issue_date = {January, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {1},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.05.001},
doi = {10.1016/j.infsof.2009.05.001},
abstract = {The domain analysis process is used to identify and document common and variable characteristics of systems in a specific domain. In order to achieve an effective result, it is necessary to collect, organize and analyze several sources of information about different applications in this domain. Consequently, this process involves distinct phases and activities and also needs to identify which artifacts, arising from these activities, have to be traceable and consistent. In this context, performing a domain analysis process without tool support increases the risks of failure, but the used tool should support the complete process and not just a part of it. This article presents a systematic review of domain analysis tools that aims at finding out how the available tools offer support to the process. As a result, the review identified that these tools are usually focused on supporting only one process and there are still gaps in the complete process support. Furthermore, the results can provide insights for new research in the domain engineering area for investigating and defining new tools, and the study also aids in the identification of companies' needs for a domain analysis tool.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {Domain analysis, Systematic review, Tools}
}

@inproceedings{10.1145/3168365.3168372,
author = {Acher, Mathieu and Temple, Paul and J\'{e}z\'{e}quel, Jean-Marc and Galindo, Jos\'{e} A. and Martinez, Jabier and Ziadi, Tewfik},
title = {VaryLATEX: Learning Paper Variants That Meet Constraints},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168372},
doi = {10.1145/3168365.3168372},
abstract = {How to submit a research paper, a technical report, a grant proposal, or a curriculum vitae that respect imposed constraints such as formatting instructions and page limits? It is a challenging task, especially when coping with time pressure. In this work, we present VaryLATEX, a solution based on variability, constraint programming, and machine learning techniques for documents written in LATEX to meet constraints and deliver on time. Users simply have to annotate LATEX source files with variability information, e.g., (de)activating portions of text, tuning figures' sizes, or tweaking line spacing. Then, a fully automated procedure learns constraints among Boolean and numerical values for avoiding non-acceptable paper variants, and finally, users can further configure their papers (e.g., aesthetic considerations) or pick a (random) paper variant that meets constraints, e.g., page limits. We describe our implementation and report the results of two experiences with VaryLATEX.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {83–88},
numpages = {6},
keywords = {LATEX, constraint programming, generators, machine learning, technical writing, variability modelling},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@article{10.1145/511152.511159,
author = {Knauber, Peter and Succi, Giancarlo},
title = {Perspectives on Software Product Lines: report on Second International Workshop on Software Product Lines: Economics, Architectures, and Implications workshop at 23rd International Conference on Software Engineering (ICSE)},
year = {2002},
issue_date = {March 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/511152.511159},
doi = {10.1145/511152.511159},
abstract = {Product line engineering is a recent concept and one of the hottest topics in software engineering aiming at synergy effects in software development. Diverse benefits like cost reduction, decreased time-to-market, and quality improvement can be expected from reuse of domain-specific software assets, several successful product line projects have been performed and documented [3]. Also non-technical benefits as result of network externalities, product branding, and sharing organizational costs have been observed.Following the remarkable success of the "First International Workshop on Software Product Lines: Economics, Architectures, and Implications" held at ICSE 2000 in Limerick [1], this second workshop stresses more the non-technical, that is, business and organizational aspects of product line adoption and institutionalization. Another major topic of interest are product line tools, as tool support seems to become more and more critical for the success of product line approaches. Different tool concepts have been proposed and discussed during the workshop. Requirements for tools and respective solutions seem to become more concrete, maybe resulting from the fact that the technical concepts and solutions of product line approaches are better understood and can therefore be better supported with tools.The strong emphasis on establishing contacts and giving experts and practitioners from academia and industry a platform for discussion has been continued during this second workshop.Section 2 of this workshop summary describes the formal structure of the workshop. In Section 3, a short summary of the invited talk on issues and opportunities in product line research is given. Section 4 summarizes key points of the presentations of the workshop participants that were given based on their submitted papers that are fully available at [2]. In Section 5, the plenary discussion is described and its major lessons learned are summarized. Section 6 concludes this paper.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {40–45},
numpages = {6}
}

@article{10.1007/s10515-018-0247-4,
author = {Gonzalez-Fernandez, Yasser and Hamidi, Saeideh and Chen, Stephen and Liaskos, Sotirios},
title = {Efficient elicitation of software configurations using crowd preferences and domain knowledge},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-018-0247-4},
doi = {10.1007/s10515-018-0247-4},
abstract = {As software systems grow in size and complexity, the process of configuring them to meet individual needs becomes more and more challenging. Users, especially those that are new to a system, are faced with an ever increasing number of configuration possibilities, making the task of choosing the right one more and more daunting. However, users are rarely alone in using a software system. Crowds of other users or the designers themselves can provide with examples and rules as to what constitutes a meaningful configuration. We introduce a technique for designing optimal interactive configuration elicitation dialogs, aimed at utilizing crowd and expert information to reduce the amount of manual configuration effort. A repository of existing user configurations supplies us with information about popular ways to complete an existing partial configuration. Designers augment this information with their own constraints. A Markov decision process (MDP) model is then created to encode configuration elicitation dialogs that maximize the automatic configuration decisions based on the crowd and the designers' information. A genetic algorithm is employed to solve the MDP when problem sizes prevent use of common exact techniques. In our evaluation with various configuration models we show that the technique is feasible, saves configuration effort and scales for real problem sizes of a few hundreds of features.},
journal = {Automated Software Engg.},
month = mar,
pages = {87–123},
numpages = {37},
keywords = {Genetic algorithms, Markov decision processes, Software configuration, Software customization}
}

@article{10.1016/j.infsof.2012.03.005,
author = {Ghanam, Yaser and Maurer, Frank and Abrahamsson, Pekka},
title = {Making the leap to a software platform strategy: Issues and challenges},
year = {2012},
issue_date = {September, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {9},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.03.005},
doi = {10.1016/j.infsof.2012.03.005},
abstract = {Context: While there are many success stories of achieving high reuse and improved quality using software platforms, there is a need to investigate the issues and challenges organizations face when transitioning to a software platform strategy. Objective: This case study provides a comprehensive taxonomy of the challenges faced when a medium-scale organization decided to adopt software platforms. The study also reveals how new trends in software engineering (i.e. agile methods, distributed development, and flat management structures) interplayed with the chosen platform strategy. Method: We used an ethnographic approach to collect data by spending time at a medium-scale company in Scandinavia. We conducted 16in-depth interviews with representatives of eight different teams, three of which were working on three separate platforms. The collected data was analyzed using Grounded Theory. Results: The findings identify four classes of challenges, namely: business challenges, organizational challenges, technical challenges, and people challenges. The article explains how these findings can be used to help researchers and practitioners identify practical solutions and required tool support. Conclusion: The organization's decision to adopt a software platform strategy introduced a number of challenges. These challenges need to be understood and addressed in order to reap the benefits of reuse. Researchers need to further investigate issues such as supportive organizational structures for platform development, the role of agile methods in software platforms, tool support for testing and continuous integration in the platform context, and reuse recommendation systems.},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {968–984},
numpages = {17},
keywords = {Ethnographic study, Grounded Theory, Platform challenges, Software platform, Software reuse}
}

@inproceedings{10.1145/2889160.2889175,
author = {Meinicke, Jens and Th\"{u}m, Thomas and Schr\"{o}ter, Reimar and Krieter, Sebastian and Benduhn, Fabian and Saake, Gunter and Leich, Thomas},
title = {FeatureIDE: taming the preprocessor wilderness},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889175},
doi = {10.1145/2889160.2889175},
abstract = {Preprocessors are a common way to implement variability in software. They are used in numerous software systems, such as operating systems and databases. Due to the ability of preprocessors to enable and disable code fragments, not all parts of the program are active at the same time. Thus, programmers and tools need to handle the interactions resulting from annotations in the program. With our Eclipse-based tool FeatureIDE, we provide tool support to tackle multiple challenges with preprocessors, such as code comprehension, feature traceability, separation of concerns, and program analysis. With FeatureIDE, instead of focusing on one particular preprocessor, we provide tool support, which can easily be adopted for further preprocessors. Currently, we support development with CPP, Antenna, and Munge. https://youtu.be/jVe7f32mLCQ},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {629–632},
numpages = {4},
keywords = {code analysis, feature traceability, preprocessor},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1007/978-3-319-26172-0_4,
author = {Bryant, Barrett and J\'{e}z\'{e}quel, Jean-Marc and L\"{a}mmel, Ralf and Mernik, Marjan and Schindler, Martin and Steinmann, Friedrich and Tolvanen, Juha-Pekka and Vallecillo, Antonio and V\"{o}lter, Markus},
title = {Globalized Domain Specific Language Engineering},
year = {2014},
isbn = {9783319261713},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-26172-0_4},
doi = {10.1007/978-3-319-26172-0_4},
abstract = {This chapter is dedicated to discussing the engineering aspects involved in the integration of modeling languages, as an essential part of the globalization process. It covers the foundations of language integration, the definition of the relationships between the languages to be integrated, and the various dimensions of language and tool integration. Language variants, evolution, refactoring and retirement are also discussed, as key issues involved in the globalization of modeling languages.},
booktitle = {Revised Papers of the International Dagstuhl Seminar on Globalizing Domain-Specific Languages - Volume 9400},
pages = {43–69},
numpages = {27},
keywords = {Globalized DSLs, Language Engineering}
}

@inproceedings{10.1145/3474624.3476010,
author = {Ferreira, Thiago do Nascimento and Vergilio, Silvia Regina and Kessentini, Marouane},
title = {Implementing Search-Based Software Engineering Approaches with Nautilus},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3476010},
doi = {10.1145/3474624.3476010},
abstract = {Search-Based Software Engineering (SBSE) approaches adopt search-based techniques to solve Software Engineering (SE) optimization problems. Among these techniques, evolutionary algorithms are the most popular and successfully used, such as multi-objective evolutionary algorithms. However, some challenges still need to be addressed. Firstly, SE problems are complex and commonly impacted by many conflicting factors. In this context, the use of many-objective algorithms is necessary. Secondly, the users very often do not recognise the found solutions as feasible because these solutions are usually not generated considering the users’ needs and preferences. Thus, to deal properly with this situation, preference-based algorithms should be applied. Moreover, there are some practical issues regarding the choice of operators, evaluation of algorithms and visualization of solutions. Existing frameworks do not provide support to address these challenges. To overcome these limitations, we present Nautilus, an open-source Java web-platform tool that works with plugins to ease the addition of new problem instances, implementation of search operators and different multi and many-objective optimization algorithms, guided (or not) by human participation. This paper describes Nautilus-NRP, an extension implemented to address the Next Release Problem (NRP). NRP refers to the selection of requirements to be implemented in the next release of a software and is used to illustrate Nautilus’ main functionalities and how it can be extended to solve a SE problem. Link for the video: https://youtu.be/2dbwslTrvhg.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {303–308},
numpages = {6},
keywords = {many-objective optimization, next release problem, preference-based algorithms},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.5555/3370272.3370286,
author = {Harthi, Omar A. Al and Alalfi, Manar H. and Dean, Thomas},
title = {Detection of feature interaction in dynamic scripting languages},
year = {2019},
publisher = {IBM Corp.},
address = {USA},
abstract = {In Plugin-based systems, merging plugins in one page is usually safe, but sometimes it may fail due to feature interaction. While these plugins work correctly when tested alone, they may fail or show unexpected behavior when one or more are used together. To identify and locate the causes of interference, one must inspect the plugin code and possibly examine assignment traces using proper analysis methods. However, manually testing thousands of plugins is not feasible, especially if many of the plugins lack appropriate documentation. Our goal is to introduce an automated detection framework based on static and dynamic analysis to detect potential feature interaction. In this paper, we will focus primarily on static analysis and plan to cover the dynamic analysis at a later stage.First, we present the results of an initial study we conducted on an example plugin system, JQuery, and that to classify the types of conflicts found and to presents a list of patterns of objects assignment, then we present our automated static analysis approach designed to capture the patterns of conflicts. Finally, we present an experiment which applies our approach to a dataset of 2081 JQuery plugins and identified around 357K expression patterns. Our approach flagged 255 expressions as cases of duplicate objects names, and 180 as cases of duplicate global names.},
booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
pages = {130–137},
numpages = {8},
keywords = {features interactions, plugin systems, static analysis},
location = {Toronto, Ontario, Canada},
series = {CASCON '19}
}

@inproceedings{10.1007/978-3-030-59003-1_10,
author = {G\'{o}mez, Paola and Casallas, Rubby and Roncancio, Claudia},
title = {Automatic Schema Generation for Document-Oriented Systems},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_10},
doi = {10.1007/978-3-030-59003-1_10},
abstract = {Popular document-oriented systems store JSON-like data (e.g. MongoDB). Such data formats combine the flexibility of semi-structured models and traditional data structures like records and arrays. This allows numerous structuring possibilities even for simple data. The data structure choice is important as it impacts many aspects such as memory footprint, data access performances and programming complexity. Our work aims at helping users in selecting data structuring from a set of automatically generated alternatives. These alternatives can be analyzed considering complexity metrics, query requirements and best practices using such “schemaless” databases. Our approach for “schema” generation has been inspired from Software Product Lines strategies based on feature models. From a UML class diagram that represents user’s data, we generate automatically a feature model that implicitly contains the structure alternatives with their variations and common points. This feature model satisfies document-oriented constraints so as user constraints reflecting good practices or particular needs. It leads to a set of data structuring alternatives to be considered by the user for his operational choices.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {152–163},
numpages = {12},
keywords = {NoSQL, Document-oriented systems, Variability, Feature models},
location = {Bratislava, Slovakia}
}

@article{10.1145/3462699,
author = {Cheng, Long and Ahmed, Salman and Liljestrand, Hans and Nyman, Thomas and Cai, Haipeng and Jaeger, Trent and Asokan, N. and Yao, Danfeng (Daphne)},
title = {Exploitation Techniques for Data-oriented Attacks with Existing and Potential Defense Approaches},
year = {2021},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {2471-2566},
url = {https://doi.org/10.1145/3462699},
doi = {10.1145/3462699},
abstract = {Data-oriented attacks manipulate non-control data to alter a program’s benign behavior without violating its control-flow integrity. It has been shown that such attacks can cause significant damage even in the presence of control-flow defense mechanisms. However, these threats have not been adequately addressed. In this survey article, we first map data-oriented exploits, including Data-Oriented Programming (DOP) and Block-Oriented Programming (BOP) attacks, to their assumptions/requirements and attack capabilities. Then, we compare known defenses against these attacks, in terms of approach, detection capabilities, overhead, and compatibility. It is generally believed that control flows may not be useful for data-oriented security. However, data-oriented attacks (especially DOP attacks) may generate side effects on control-flow behaviors in multiple dimensions (i.e., incompatible branch behaviors and frequency anomalies). We also characterize control-flow anomalies caused by data-oriented attacks. In the end, we discuss challenges for building deployable data-oriented defenses and open research questions.},
journal = {ACM Trans. Priv. Secur.},
month = sep,
articleno = {26},
numpages = {36},
keywords = {BOP, DOP, Data-oriented attacks, branch correlation, frequency anomaly}
}

@inproceedings{10.5555/2662528.2662537,
author = {Gr\"{u}nbacher, Paul and Rabiser, Rick},
title = {Success factors for empirical studies in industry-academia collaboration: a reflection},
year = {2013},
isbn = {9781467362863},
publisher = {IEEE Press},
abstract = {We conducted several empirical studies over the last couple of years as part of a collaboration with industrial partners in the area of software product lines. Our studies differed regarding their motivation and goals, their scope, the research methods applied, and the involved subjects. In this experience paper we briefly summarize the studies and their key characteristics. We reflect on our experiences based on the success factors for industry-academia collaborations by Wohlin et al. We discuss the role of empirical studies in long-term industry-academia collaborations and present lessons learned.},
booktitle = {Proceedings of the 1st International Workshop on Conducting Empirical Studies in Industry},
pages = {27–32},
numpages = {6},
keywords = {empirical studies, industry-academia, success factors},
location = {San Francisco, California},
series = {CESI '14}
}

@proceedings{10.1145/2993236,
title = {GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.5555/1939345.1939353,
author = {Schaefer, Ina},
title = {Modeling and analyzing diversity: description of EternalS task force 1},
year = {2010},
isbn = {3642165605},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We describe the objectives and vision of the ETERNALS Task Force 1 "Diversity Awareness and Management". We present its organization and workplan. The goal of the task force is to provide a platform for collaboration towards a unifying framework for modeling and analyzing diversity of system data and behavior in all development phases.},
booktitle = {Proceedings of the 4th International Conference on Leveraging Applications of Formal Methods, Verification, and Validation - Volume Part II},
pages = {23–25},
numpages = {3},
location = {Heraklion, Crete, Greece},
series = {ISoLA'10}
}

@inproceedings{10.1145/1370175.1370249,
author = {Avgeriou, Paris and Lago, Patricia and Kruchten, Philippe},
title = {Third international workshop on sharing and reusing architectural knowledge (SHARK 2008)},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370175.1370249},
doi = {10.1145/1370175.1370249},
abstract = {The shift of the software architecture community towards architectural knowledge has brought along some promising research directions. In this workshop we discuss the issues that lead to the application of architectural knowledge in research and industrial practice; ongoing research and new ideas to advance the field. In its previous editions we examined the state of the art and practice, future challenges and trends. This third edition will discuss, among others, architectural knowledge as perceived by different research communities, including requirements engineering, service-oriented computing and international standardization.},
booktitle = {Companion of the 30th International Conference on Software Engineering},
pages = {1065–1066},
numpages = {2},
keywords = {architectural knowledge},
location = {Leipzig, Germany},
series = {ICSE Companion '08}
}

@inproceedings{10.1145/1985793.1985918,
author = {Simidchieva, Borislava I. and Osterweil, Leon J.},
title = {Characterizing process variation (NIER track)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985918},
doi = {10.1145/1985793.1985918},
abstract = {A process model, namely a formal definition of the coordination of agents performing activities using resources and artifacts, can aid understanding of the real-world process it models. Moreover, analysis of the model can suggest improvements to the real-world process. Complex real-world processes, however, exhibit considerable amounts of variation that can be difficult or impossible to represent with a single process model. Such processes can often be modeled better, within the restrictions of a given modeling notation, by a family of models. This paper presents an approach to the formal characterization of some of these process families. A variety of needs for process variation are identified, and suggestions are made about how to meet some of these needs using different approaches. Some mappings of different needs for variability to approaches for meeting them are presented as case studies.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {836–839},
numpages = {4},
keywords = {process families, software product lines, system variation},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2591028.2600810,
author = {Santos, Jadson and Lima, Gleydson and Kulesza, Uir\'{a} and Sena, Demostenes and Pinto, Felipe and Lima, Jalerson and Vianna, Alexandre and Pereira, David and Fernandes, Victor},
title = {Conditional execution: a pattern for the implementation of fine-grained variabilities in software product lines},
year = {2012},
isbn = {9781450327879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591028.2600810},
doi = {10.1145/2591028.2600810},
abstract = {This paper presents the Conditional Execution design pattern that aims to help the implementation of fine-grained variabilities in the context of software product lines of information systems. The pattern has been used successfully in three product lines of web information systems developed by Informatics Superintendence (SINFO) at Federal University of Rio Grande do Norte.},
booktitle = {Proceedings of the 9th Latin-American Conference on Pattern Languages of Programming},
articleno = {1},
numpages = {17},
keywords = {design pattern, fine-grained variabilities, software product lines},
location = {Natal, Rio Grande do Norte, Brazil},
series = {SugarLoafPLoP '12}
}

@inproceedings{10.1145/2993236.2993249,
author = {Pereira, Juliana Alves and Matuszyk, Pawel and Krieter, Sebastian and Spiliopoulou, Myra and Saake, Gunter},
title = {A feature-based personalized recommender system for product-line configuration},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993249},
doi = {10.1145/2993236.2993249},
abstract = {Today’s competitive marketplace requires the industry to understand unique and particular needs of their customers. Product line practices enable companies to create individual products for every customer by providing an interdependent set of features. Users configure personalized products by consecutively selecting desired features based on their individual needs. However, as most features are interdependent, users must understand the impact of their gradual selections in order to make valid decisions. Thus, especially when dealing with large feature models, specialized assistance is needed to guide the users in configuring their product. Recently, recommender systems have proved to be an appropriate mean to assist users in finding information and making decisions. In this paper, we propose an advanced feature recommender system that provides personalized recommendations to users. In detail, we offer four main contributions: (i) We provide a recommender system that suggests relevant features to ease the decision-making process. (ii) Based on this system, we provide visual support to users that guides them through the decision-making process and allows them to focus on valid and relevant parts of the configuration space. (iii) We provide an interactive open-source configurator tool encompassing all those features. (iv) In order to demonstrate the performance of our approach, we compare three different recommender algorithms in two real case studies derived from business experience.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {120–131},
numpages = {12},
keywords = {Personalized Recommendations, Product-Line Configuration, Recommenders, Software Product Lines},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@article{10.1007/s10009-012-0253-y,
author = {Schaefer, Ina and Rabiser, Rick and Clarke, Dave and Bettini, Lorenzo and Benavides, David and Botterweck, Goetz and Pathak, Animesh and Trujillo, Salvador and Villela, Karina},
title = {Software diversity: state of the art and perspectives},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0253-y},
doi = {10.1007/s10009-012-0253-y},
abstract = {Diversity is prevalent in modern software systems to facilitate adapting the software to customer requirements or the execution environment. Diversity has an impact on all phases of the software development process. Appropriate means and organizational structures are required to deal with the additional complexity introduced by software variability. This introductory article to the special section "Software Diversity--Modeling, Analysis and Evolution" provides an overview of the current state of the art in diverse systems development and discusses challenges and potential solutions. The article covers requirements analysis, design, implementation, verification and validation, maintenance and evolution as well as organizational aspects. It also provides an overview of the articles which are part of this special section and addresses particular issues of diverse systems development.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {477–495},
numpages = {19},
keywords = {Software diversity, Software product lines, Variability}
}

@article{10.1145/3229048,
author = {Zheng, Yongjie and Cu, Cuong and Taylor, Richard N.},
title = {Maintaining Architecture-Implementation Conformance to Support Architecture Centrality: From Single System to Product Line Development},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3229048},
doi = {10.1145/3229048},
abstract = {Architecture-centric development addresses the increasing complexity and variability of software systems by focusing on architectural models, which are generally easier to understand and manipulate than source code. It requires a mechanism that can maintain architecture-implementation conformance during architectural development and evolution. The challenge is twofold. There is an abstraction gap between software architecture and implementation, and both may evolve. Existing approaches are deficient in support for both change mapping and product line architecture. This article presents a novel approach named 1.x-way mapping and its extension, 1.x-line mapping to support architecture-implementation mapping in single system development and in product line development, respectively. They specifically address mapping architecture changes to code, maintaining variability conformance between product line architecture and code, and tracing architectural implementation. We built software tools named xMapper and xLineMapper to realize the two approaches, and conducted case studies with two existing open-source systems to evaluate the approaches. The result shows that our approaches are applicable to the implementation of a real software system and are capable of maintaining architecture-implementation conformance during system evolution.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {8},
numpages = {52},
keywords = {Architecture-implementation mapping, architectural evolution, architecture-centric development, architecture-centric feature traceability, variability conformance}
}

@article{10.1145/2807593,
author = {Baudry, Benoit and Monperrus, Martin},
title = {The Multiple Facets of Software Diversity: Recent Developments in Year 2000 and Beyond},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2807593},
doi = {10.1145/2807593},
abstract = {Early experiments with software diversity in the mid 1970s investigated N-version programming and recovery blocks to increase the reliability of embedded systems. Four decades later, the literature about software diversity has expanded in multiple directions: goals (fault tolerance, security, software engineering), means (managed or automated diversity), and analytical studies (quantification of diversity and its impact). Our article contributes to the field of software diversity as the first work that adopts an inclusive vision of the area, with an emphasis on the most recent advances in the field. This survey includes classical work about design and data diversity for fault tolerance, as well as the cybersecurity literature that investigates randomization at different system levels. It broadens this standard scope of diversity to include the study and exploitation of natural diversity and the management of diverse software products. Our survey includes the most recent works, with an emphasis from 2000 to the present. The targeted audience is researchers and practitioners in one of the surveyed fields who miss the big picture of software diversity. Assembling the multiple facets of this fascinating topic sheds a new light on the field.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {16},
numpages = {26},
keywords = {Software diversity, design principles, program transformation}
}

@article{10.1007/s10270-014-0402-8,
author = {Asadi, Mohsen and Gr\"{o}ner, Gerd and Mohabbati, Bardia and Ga\v{s}evi\'{c}, Dragan},
title = {Goal-oriented modeling and verification of feature-oriented product lines},
year = {2016},
issue_date = {February  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-014-0402-8},
doi = {10.1007/s10270-014-0402-8},
abstract = {Goal models represent requirements and intentions of a software system. They play an important role in the development life cycle of software product lines (SPLs). In the domain engineering phase, goal models guide the development of variability in SPLs by providing the rationale for the variability, while they are used for the configuration of SPLs in the application engineering phase. However, variability in SPLs, which is represented by feature models, usually has design and implementation-induced constraints. When those constraints are not aligned with variability in goal models, the configuration with goal models becomes error prone. To remedy this problem, we propose a description logic (DL)-based approach to represent both models and their relations in a common DL knowledge base. Moreover, we apply reasoning to detect inconsistencies in the variability of goal and feature models. A formal proof is provided to demonstrate the correctness of the reasoning approach. An empirical evaluation shows computational tractability of the inconsistency detection.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {257–279},
numpages = {23},
keywords = {Description Logic, Feature Models, Feature oriented software families, Goal-oriented requirements engineering, Software engineering, Verification}
}

@article{10.1016/j.infsof.2019.03.015,
author = {Borg, Markus and Chatzipetrou, Panagiota and Wnuk, Krzysztof and Al\'{e}groth, Emil and Gorschek, Tony and Papatheocharous, Efi and Shah, Syed Muhammad Ali and Axelsson, Jakob},
title = {Selecting component sourcing options: A survey of software engineering’s broader make-or-buy decisions},
year = {2019},
issue_date = {Aug 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {112},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.03.015},
doi = {10.1016/j.infsof.2019.03.015},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {18–34},
numpages = {17},
keywords = {Component-based software engineering, Sourcing, Software architecture, Decision making, Survey}
}

@article{10.1016/j.scico.2009.12.004,
author = {Mendonca, Marcilio and Cowan, Donald},
title = {Decision-making coordination and efficient reasoning techniques for feature-based configuration},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {75},
number = {5},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2009.12.004},
doi = {10.1016/j.scico.2009.12.004},
abstract = {Software Product Lines is a contemporary approach to software development that exploits the similarities and differences within a family of systems in a particular domain of interest in order to provide a common infrastructure for deriving members of this family in a timely fashion, with high-quality standards, and at lower costs. In Software Product Lines, feature-based product configuration is the process of selecting the desired features for a given software product from a repository of features called a feature model. This process is usually carried out collaboratively by people with distinct skills and interests called stakeholders. Collaboration benefits stakeholders by allowing them to directly intervene in the configuration process. However, collaboration also raises an important side effect, i.e., the need of stakeholders to cope with decision conflicts. Conflicts arise when decisions that are locally consistent cannot be applied globally because they violate one or more constraints in the feature model. Unfortunately, current product configuration systems are typically single-user-based in the sense that they do not provide means to coordinate concurrent decision-making on the feature model. As a consequence, configuration is carried out by a single person that is in charge of representing the interests of all stakeholders and managing decision conflicts on their own. This results in an error-prone and time-consuming process that requires past decisions to be revisited continuously either to correct misinterpreted stakeholder requirements or to handle decision conflicts. Yet another challenging issue related to configuration problems is the typically high computational cost of configuration algorithms. In fact, these algorithms frequently fall into the category of NP-hard and thus can become intractable in practice. In this paper, our goal is two-fold. First, we revisit our work on Collaborative Product Configuration (CPC) in which we proposed an approach to describe and validate collaborative configuration scenarios. We discuss how collaborative configuration can be described in terms of a workflow-like plan that safely guides stakeholders during the configuration process. Second, we propose a preliminary set of reasoning algorithms tailored to the feature modelling domain that can be used to provide automated support for product configuration. In addition, we compare empirically the performance of the proposed algorithms to that of a general-purpose solution. We hope that the insights provided in this paper will encourage other researchers to develop new algorithms in the near future.},
journal = {Sci. Comput. Program.},
month = may,
pages = {311–332},
numpages = {22},
keywords = {Automated reasoning, Constraint-based reasoning, Decision-making coordination, Feature modelling, Feature models, Product configuration, Software Product Lines}
}

@inproceedings{10.1145/2993412.3003392,
author = {Boss, Birgit and Tischer, Christian and Krishnan, Sreejith and Nutakki, Arun and Gopinath, Vinod},
title = {Setting up architectural SW health builds in a new product line generation},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3003392},
doi = {10.1145/2993412.3003392},
abstract = {Setting up a new product line generation in a mature domain, typically does not start from scratch but takes into consideration the architecture and assets of the former product line generation. Being able to accommodate legacy and 3rd party code is one of the major product line qualities to be met. On the other side, product line qualities like reusability, maintainability and alterability, i.e. being able to cope up with a large amount of variability, with configurability and fast integratability are major drivers.While setting up a new product line generation and thus a new corresponding architecture, we this time focused on architectural software (SW) health and tracking of architectural metrics from the very beginning. Taking the definition of "architecture being a set of design decisions" [18] literally, we attempt to implement an architectural check for every design decision taken. Architectural design decisions in our understanding do not only - and even not mainly - deal with the definition of components and their interaction but with patterns and rules or anti-patterns. The rules and anti-patterns, "what not to do" or more often also "what not to do &lt;u&gt;any more&lt;/u&gt;", is even more important in setting up a new product line generation because developers are not only used to the old style of developing and the old architecture, but also still have to develop assets for both generations.In this article we describe selected architectural checks that we have implemented, the layered architecture check and the check for usage of obsolete services. Additionally we discuss selected architectural metrics: the coupling coefficient metrics and the instability metrics. In the summary and outlook we describe our experiences and still open topics in setting up architectural SW health checks for a large-scale product line.The real-world examples are taken from the domain of Engine Control Unit development at Robert Bosch GmbH.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {16},
numpages = {7},
keywords = {architectural checks, architectural technical debt, embedded software, product line development, software architecture, software erosion, technical debt},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@article{10.1016/j.jss.2017.05.051,
author = {Vogel-Heuser, Birgit and Fischer, Juliane and Feldmann, Stefan and Ulewicz, Sebastian and Rsch, Susanne},
title = {Modularity and architecture of PLC-based software for automated production Systems},
year = {2017},
issue_date = {September 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {131},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.05.051},
doi = {10.1016/j.jss.2017.05.051},
abstract = {Overview of the state of the art in industrial software engineering of aPS using PLCs.Benchmark process to evaluate the maturity of aPS application software.SWMAT4aPS consists of a self-assessment questionnaire and an expert analysis.3 Maturity measures: modularity, test/quality assurance and start-up/operation/maintenance.Weaknesses of aPS software related to mechanics and automation hardware in comparison to pure software identified. Adaptive and flexible production systems require modular and reusable software especially considering their long-term life cycle of up to 50 years. SWMAT4aPS, an approach to measure Software Maturity for automated Production Systems is introduced. The approach identifies weaknesses and strengths of various companies solutions for modularity of software in the design of automated Production Systems (aPS). At first, a self-assessed questionnaire is used to evaluate a large number of companies concerning their software maturity. Secondly, we analyze PLC code, architectural levels, workflows and abilities to configure code automatically out of engineering information in four selected companies. In this paper, the questionnaire results from 16 German world-leading companies in machine and plant manufacturing and four case studies validating the results from the detailed analyses are introduced to prove the applicability of the approach and give a survey of the state of the art in industry.},
journal = {J. Syst. Softw.},
month = sep,
pages = {35–62},
numpages = {28},
keywords = {Automated production systems, Control software, Factory automation, Maturity, Modularity, Programmable logic controller}
}

@inproceedings{10.1145/2031759.2031771,
author = {Dobrica, Liliana and Ovaska, Eila},
title = {Analysis of a cross-domain reference architecture using change scenarios},
year = {2011},
isbn = {9781450306188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2031759.2031771},
doi = {10.1145/2031759.2031771},
abstract = {The content of this paper addresses the issue of how to perform analysis of a cross domain reference architecture. The cross domain reference architecture is designed based on the domains requirements and features modeling. The definition of a cross domain reference architecture is based on well known concepts from software architecture description, service orientation and product line. We apply a method based on change scenarios to analyze variability at the architectural level. In order to handle complexity in analysis we propose categories of change scenarios to be derived from each problem domain and we provide informal guidelines for each step of the analysis method.},
booktitle = {Proceedings of the 5th European Conference on Software Architecture: Companion Volume},
articleno = {10},
numpages = {9},
keywords = {analysis methods, cross domain reference architecture, quality, scenarios, service, variability},
location = {Essen, Germany},
series = {ECSA '11}
}

@inproceedings{10.1109/CHASE.2009.5071420,
author = {Unphon, Hataichanok and Dittrich, Yvonne and Hubaux, Arnaud},
title = {Taking care of cooperation when evolving socially embedded systems: The PloneMeeting case},
year = {2009},
isbn = {9781424437122},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CHASE.2009.5071420},
doi = {10.1109/CHASE.2009.5071420},
abstract = {This paper proposes a framework to (i) analyse the contexts of socially embedded systems and (ii) support the understanding of change during their evolutions. Our finding is based on a co-operative project with a government agency developing a partially-automated variability configurator for an open source software product family. By employing our framework, we realised that the way variations and their management are implemented have to accommodate work practices from the use context as well as development practice, and here especially the cooperation within the development team and between users and developers. The empirical evidence has confirmed our understanding of what is relevant when estimating the evolvability of socially embedded systems. We propose to use our framework in architecture-level design and evaluation in order to take these cooperative relationships into account early in the evolution cycle.},
booktitle = {Proceedings of the 2009 ICSE Workshop on Cooperative and Human Aspects on Software Engineering},
pages = {96–103},
numpages = {8},
series = {CHASE '09}
}

@inproceedings{10.4108/eai.24-8-2015.2261108,
author = {Meacham, Sofia and Gioulekas, Fotios and Phalp, Keith},
title = {SysML based design for variability enabling the reusability of legacy systems towards the support of diverse standard compliant implementations or standard updates: the case of IEEE-802.15.6 standard for e-Health applications},
year = {2015},
isbn = {9781631900792},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/eai.24-8-2015.2261108},
doi = {10.4108/eai.24-8-2015.2261108},
abstract = {The aim of this paper is to provide a consistent development path enabling the re-usability of in house legacy systems or architectures towards their re-design, in order to ensure compliance withevolving standards, byusing the new features of SysML for modelling variants. Modern standards evolve quickly, include advanced functionalities and operations and support diverse implementations. System industries need to cope with such standards changes by modifying their current technologies. This paper shows howa novel engineering process (SysML modelling)could be employed to define consistently the specification and the migration procedure of legacy systems to their variants. Within this work SysML characteristics such as package and block diagrams, are employed, with an emphasis on variability modelling, as a basis for standard compliant architecture implementation, thus providing design flexibility and reusability at several abstraction levels. As an illustration of our proposed method we present models oftwo variant Physical Layer structures for IEEE-802.15.6 Standard for e-Health Applications. The advanced SysML features are used to target the re-usability of a legacy Narrow-Band (NB) physical layer subsystem for the Wireless Body Area Network standard and to implement the alternative Ultra-Wide Band (UWB). Therefore, we contend that such methods bring potential benefits to those needing to ensure compliance when producing product variants.},
booktitle = {Proceedings of the 8th International Conference on Simulation Tools and Techniques},
pages = {284–289},
numpages = {6},
keywords = {SysML, eHealth, eclipsepapyrus, standard compliance, standard evolution, variability},
location = {Athens, Greece},
series = {SIMUTools '15}
}

@inproceedings{10.1145/3229345.3229419,
author = {Oliveira, Joyce Aline and Vargas, Matheus and Rodrigues, Roni},
title = {SOA Reuse: Systematic Literature Review Updating and Research Directions},
year = {2018},
isbn = {9781450365598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229345.3229419},
doi = {10.1145/3229345.3229419},
abstract = {Service Oriented Architecture (SOA) reuse has been used strategically in organizations to reduce development costs and increase the quality of applications. This article analyzes a systematic literature review in order to identify concepts, goals, strategies, and metrics of SOA reuse. The results show that the main goal of SOA reuse is to decrease development costs. The factor that most negatively influences SOA reuse is the existence of legacy systems. The strategy used most to potentialize SOA reuse is business process management. Metrics proposed by studies to measure SOA reuse are related to modularity and adaptability indicators. The study is relevant because it increases the body of knowledge of the area. Additionally, a set of gaps to be addressed by researchers and reuse practitioners was identified.},
booktitle = {Proceedings of the XIV Brazilian Symposium on Information Systems},
articleno = {71},
numpages = {8},
keywords = {SOA reuse, Service Oriented Architecture, systematic literature review},
location = {Caxias do Sul, Brazil},
series = {SBSI '18}
}

@article{10.1016/j.infsof.2014.05.003,
author = {Sturm, Arnon and Kramer, Oded},
title = {Evaluating the productivity of a reference-based programming approach: A controlled experiment},
year = {2014},
issue_date = {October, 2014},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {56},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2014.05.003},
doi = {10.1016/j.infsof.2014.05.003},
abstract = {Context: Domain engineering aims at facilitating software development in an efficient and economical way. One way to measure that is through productivity indicators, which refer to the ability of creating a quality software product in a limited period and with limited resources. Many approaches have been devised to increase productivity; however, these approaches seem to suffer from a tension between expressiveness on the one hand, and applicability (or the lack of it) in providing guidance for developers. Objective: This paper evaluates the applicability and efficiency of adopting a domain engineering approach, called Application-based DOmain Modeling (ADOM), in the context of the programming task with Java, and thus termed ADOM-Java, for improving productivity in terms of code quality and development time. Method: To achieve that objective we have qualitatively evaluate the approach using questionnaires and following a text analysis procedure. We also set a controlled experiment in which 50 undergraduate students performed a Java-based programming task using either ADOM-Java or Java alone. Results: The qualitative evaluation reveal that the approach is easy to uses and provides valuable guidance. Nevertheless, it requires training. The outcomes of the experiment indicate that the approach is applicable and that the students that used ADOM-Java achieved better code quality, as well as better functionality and within less time than the students who used only Java. Conclusion: The results of the experiments imply that by providing a code base equipped with reuse guidelines for programmers can increase programming productivity in terms of quality and development time. These guidelines may also enforce coding standards and architectural design.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1390–1402},
numpages = {13},
keywords = {Domain engineering, Productivity, Programming, Software quality, Software reusability}
}

@inproceedings{10.1145/2866614.2866619,
author = {Schnabel, Thomas and Weckesser, Markus and Kluge, Roland and Lochau, Malte and Sch\"{u}rr, Andy},
title = {CardyGAn: Tool Support for Cardinality-based Feature Models},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866619},
doi = {10.1145/2866614.2866619},
abstract = {Cardinality-based feature models (CFM) constitute a crucial and non-trivial extension to FODA feature models in terms of UML-like feature multiplicities and corresponding cardinality constraints. CFM allow for specifying configuration choices of software systems incorporating multiple instances (copies) of features, e.g., for tailoring customer-specific and even potentially unrestricted application resources. Nevertheless, the improved expressiveness of CFM compared to FODA feature models complicates configuration semantics, including sub-tree cloning and potentially unbounded configuration spaces. As a consequence, entirely novel anomalies might arise such as dead cardinality intervals, false unboundedness, and cardinality gaps, which are not properly treated by recent feature-modeling tools. In this paper, we present comprehensive tool support for assisting specification, validation, and configuration of CFM. Our tool CARDYGAN, therefore, incorporates capabilities for CFM editing, automated CFM validation including anomaly detection based on a combination of ILP and SMT solvers, as well as a CFM configuration engine based on ALLOY.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {33–40},
numpages = {8},
keywords = {Automated Validation, Extended Feature Models},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@inproceedings{10.1145/2556624.2556627,
author = {B\"{u}rdek, Johannes and Lity, Sascha and Lochau, Malte and Berens, Markus and Goltz, Ursula and Sch\"{u}rr, Andy},
title = {Staged configuration of dynamic software product lines with complex binding time constraints},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556627},
doi = {10.1145/2556624.2556627},
abstract = {Dynamic software product lines (DSPL) constitute a promising approach for developing highly-configurable, runtime-adaptive systems in a feature-oriented way. A DSPL integrates both variability in time and space in a unified conceptual framework. For this, domain features are equipped with additional binding time information to distinguish between static configuration parameters and dynamically (re-) configurable features. Until now, little support exists to specify and validate staged (re-)configuration semantics for DSPLs in a concise way. In this paper, we propose conservative extensions to domain feature models comprising variable feature binding times together with different kinds of binding time constraints. Those extensions are motivated by a real-world industrial case study from the automation engineering domain. Our implementation performs a model transformation into plain feature models treatable by corresponding state-of-the-art analysis tools. We conducted an evaluation of our approach concerning the case study.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {16},
numpages = {8},
keywords = {dynamic software product lines, extended feature models, industrial case study, staged configuration},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@inproceedings{10.5555/1885639.1885673,
author = {Hartmann, Herman and Keren, Mila and Matsinger, Aart and Rubin, Julia and Trew, Tim and Yatzkar-Haham, Tali},
title = {Using MDA for integration of heterogeneous components in software supply chains},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines are increasingly built using components from specialized suppliers. A company that is in the middle of a supply chain has to integrate components from its suppliers and offer (partly configured) products to its customers. To cover the whole product line, it may be necessary for integrators to use components from different suppliers, partly offering the same feature set. This leads to a product line with alternative components, possibly using different mechanisms for interfacing, binding and variability, which commonly occurs in embedded software development.In this paper, we describe a model-driven approach for automating the integration between various components that can generate a partially or fully configured variant, including glue between mismatched components. We analyze the consequences of using this approach in an industrial context, using a case study derived from an existing supply chain and describe the process and roles associated with this approach.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {361–376},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@inproceedings{10.1145/2110147.2110152,
author = {Boucher, Quentin and Perrouin, Gilles and Heymans, Patrick},
title = {Deriving configuration interfaces from feature models: a vision paper},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110152},
doi = {10.1145/2110147.2110152},
abstract = {In software product lines, feature models are the de-facto standard for representing variability as well as for configuring products. Yet, configuration relying on feature models faces two issues: i) it assumes knowledge of the underlying formalism, which may not be true for end users and ii) it does not take advantage of advanced user-interface controls, leading to usability and integration problems with other parts of the user interface. To address these issues, our research focuses on the generation of configuration interfaces based on variability models, both from the visual and behavioral perspectives. We tackle visual issues by generating abstract user-interfaces from feature models. Regarding configuration behavior, in particular the configuration sequence, we plan to use feature configuration workflows, variability-aware models that exhibit similar characteristics as of task, user, discourse and business models found in the in the human-computer interaction community. This paper discusses the main challenges and possible solutions to realize our vision.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {37–44},
numpages = {8},
keywords = {configuration interfaces, feature configuration workflows, software product lines},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@article{10.5555/590631.590636,
author = {Lam, W.},
title = {A case-study of requirements reuse through product  families},
year = {1998},
issue_date = {1998},
publisher = {J. C. Baltzer AG, Science Publishers},
address = {USA},
volume = {5},
number = {1},
issn = {1022-7091},
abstract = {Increasingly, software organisations are looking towards large\'{y}scale reuse as a way of improving productivity, raising quality and reducing delivery timescales. Many in the reuse community have suggested notions of product\'{y}line development and domain engineering life\'{y}cycles. Achieving these in practice, however, requires a systematic process for “early” reuse (requirements reuse) as well as late reuse (code reuse). This paper discusses pratical experience of early reuse. We describe FORE (Family Of REquirements), an approach that we have developed in our work in the domain of aircraft engine control systems. The FORE approach concentrates on the definition of a generic product concept and the formalisation of its requirements. We describe the FORE approach in general terms, and then show how it has been applied in an industrial case\'{y}study. We make an initial evaluation of the FORE approach (and early reuse in general) in terms of how it has changed an existing requirements engineering process. We compare the FORE approach to related work in early reuse, and draw some conclusions about how the approach may scale to other problems.},
journal = {Ann. Softw. Eng.},
month = jan,
pages = {253–277},
numpages = {25}
}

@book{10.5555/2671146,
author = {Mistrik, Ivan and Bahsoon, Rami and Kazman, Rick and Zhang, Yuanyuan},
title = {Economics-Driven Software Architecture},
year = {2014},
isbn = {0124104649},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Economics-driven Software Architecture presents a guide for engineers and architects who need to understand the economic impact of architecture design decisions: the long term and strategic viability, cost-effectiveness, and sustainability of applications and systems. Economics-driven software development can increase quality, productivity, and profitability, but comprehensive knowledge is needed to understand the architectural challenges involved in dealing with the development of large, architecturally challenging systems in an economic way. This book covers how to apply economic considerations during the software architecting activities of a project. Architecture-centric approaches to development and systematic evolution, where managing complexity, cost reduction, risk mitigation, evolvability, strategic planning and long-term value creation are among the major drivers for adopting such approaches. It assists the objective assessment of the lifetime costs and benefits of evolving systems, and the identification of legacy situations, where architecture or a component is indispensable but can no longer be evolved to meet changing needs at economic cost. Such consideration will form the scientific foundation for reasoning about the economics of nonfunctional requirements in the context of architectures and architecting. Familiarizes readers with essential considerations in economic-informed and value-driven software design and analysis Introduces techniques for making value-based software architecting decisions Provides readers a better understanding of the methods of economics-driven architecting}
}

@inproceedings{10.1145/2745802.2745815,
author = {Zhou, You and Zhang, He and Huang, Xin and Yang, Song and Babar, Muhammad Ali and Tang, Hao},
title = {Quality assessment of systematic reviews in software engineering: a tertiary study},
year = {2015},
isbn = {9781450333504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745802.2745815},
doi = {10.1145/2745802.2745815},
abstract = {Context: The quality of an Systematic Literature Review (SLR) is as good as the quality of the reviewed papers. Hence, it is vital to rigorously assess the papers included in an SLR. There has been no tertiary study aimed at reporting the state of the practice of quality assessment used in SLRs in Software Engineering (SE).Objective: We aimed to study the practices of quality assessment of the papers included in SLRs in SE.Method: We conducted a tertiary study of the SLRs that have performed quality assessment of the reviewed papers.Results: We identified and analyzed different aspects of the quality assessment of the papers included in 127 SLRs.Conclusion: Researchers use a variety of strategies for quality assessment of the papers reviewed, but report little about the justification for the used criteria. The focus is creditability but not relevance aspect of the papers. Appropriate guidelines are required for devising quality assessment strategies.},
booktitle = {Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {14},
numpages = {14},
keywords = {quality assessment, software engineering, systematic (literature) review},
location = {Nanjing, China},
series = {EASE '15}
}

@inproceedings{10.1007/11554844_21,
author = {Niemel\"{a}, Eila},
title = {Strategies of product family architecture development},
year = {2005},
isbn = {3540289364},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11554844_21},
doi = {10.1007/11554844_21},
abstract = {Product family engineering (PFE) is successfully applied in different kinds of software intensive systems. As there are several ways to apply PFE, selecting an appropriate approach is a complex task. This paper introduces six ways to set the goal of PFE and eight strategies to achieve the goal. It also introduces steps how to evaluate which strategy provides the best fit for a company. The criteria for selecting a strategy have been derived from seventeen case studies, including nineteen product families, in the various contexts provided by small, medium size and large companies.},
booktitle = {Proceedings of the 9th International Conference on Software Product Lines},
pages = {186–197},
numpages = {12},
location = {Rennes, France},
series = {SPLC'05}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00014,
author = {Idowu, Samuel and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Asset management in machine learning: a survey},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00014},
doi = {10.1109/ICSE-SEIP52600.2021.00014},
abstract = {Machine Learning (ML) techniques are becoming essential components of many software systems today, causing an increasing need to adapt traditional software engineering practices and tools to the development of ML-based software systems. This need is especially pronounced due to the challenges associated with the large-scale development and deployment of ML systems. Among the most commonly reported challenges during the development, production, and operation of ML-based systems are experiment management, dependency management, monitoring, and logging of ML assets. In recent years, we have seen several efforts to address these challenges as witnessed by an increasing number of tools for tracking and managing ML experiments and their assets. To facilitate research and practice on engineering intelligent systems, it is essential to understand the nature of the current tool support for managing ML assets. What kind of support is provided? What asset types are tracked? What operations are offered to users for managing those assets? We discuss and position ML asset management as an important discipline that provides methods and tools for ML assets as structures and the ML development activities as their operations. We present a feature-based survey of 17 tools with ML asset management support identified in a systematic search. We overview these tools' features for managing the different types of assets used for engineering ML-based systems and performing experiments. We found that most of the asset management support depends on traditional version control systems, while only a few tools support an asset granularity level that differentiates between important ML assets, such as datasets and models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {51–60},
numpages = {10},
keywords = {SE4AI, asset management, machine learning},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.5555/2350776.2350779,
author = {Preuveneers, Davy and Novais, Paulo},
title = {A survey of software engineering best practices for the development of smart applications in Ambient Intelligence},
year = {2012},
issue_date = {August 2012},
publisher = {IOS Press},
address = {NLD},
volume = {4},
number = {3},
issn = {1876-1364},
abstract = {Over the past decade, the world of Ambient Intelligence and smart environments has brought us a wide variety of novel applications with potential for exhibiting sophisticated intelligent behavior. These applications are called smart because they can sense, anticipate and adapt themselves to the context, desires and intentions of their users. However, the unpredictability of human behavior, the unanticipated circumstances of execution and a growing heterogeneity of future operational environments impose significant development challenges if these innovative applications are to gain wide acceptance in our daily life. Therefore, applying well-established software engineering methodologies is a fundamental prerequisite for delivering high quality and robust smart software applications.This survey provides a illustrative presentation of software engineering best practices in the area of smart environments and Ambient Intelligence. The aim of this survey is not to explore and compare every possible related work in detail, but to offer insights into the latest developments in this domain and to further the research into the successful design, development and evaluation of Ambient Intelligence frameworks and applications.(This research is partially funded by the Interuniversity Attraction Poles Programme Belgian State, Belgian Science Policy, and by the Research Fund KU Leuven.)},
journal = {J. Ambient Intell. Smart Environ.},
month = aug,
pages = {149–162},
numpages = {14},
keywords = {Ambient Intelligence, Software engineering, smart applications, survey}
}

@article{10.1007/s10270-012-0284-6,
author = {Aβmann, Uwe and Bartho, Andreas and B\"{u}rger, Christoff and Cech, Sebastian and Demuth, Birgit and Heidenreich, Florian and Johannes, Jendrik and Karol, Sven and Polowinski, Jan and Reimann, Jan and Schroeter, Julia and Seifert, Mirko and Thiele, Michael and Wende, Christian and Wilke, Claas},
title = {DropsBox: the Dresden Open Software Toolbox},
year = {2014},
issue_date = {February  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-012-0284-6},
doi = {10.1007/s10270-012-0284-6},
abstract = {The Dresden Open Software Toolbox (DropsBox) is a software modelling toolbox consisting of a set of open source tools developed by the Software Technology Group at TU Dresden. The DropsBox is built on top of the Eclipse Platform and the Eclipse Modeling Framework. The DropsBox contributes to the development and application of domain-specific language changes (DSLs) in model-driven software development. It can be customised by tool and language developers to support various activities of a DSL's life cycle ranging from language design to language application and evolution. In this paper, we provide an overview of the DSL life cycle, the DropsBox tools, and their interaction on a common example. Furthermore, we discuss our experiences in developing and integrating tools for DropsBox in an academic environment.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {133–169},
numpages = {37},
keywords = {Domain-specific language, Domain-specific modelling environment, EMF, Language life cycle, MDSD, Modelling tool}
}

@inproceedings{10.1145/3151848.3151859,
author = {Fonteles, Andr\'{e} Sales and Bouveret, Sylvain and Gensel, J\'{e}r\^{o}me},
title = {A programming framework for Spatial Crowdsourcing},
year = {2017},
isbn = {9781450353007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3151848.3151859},
doi = {10.1145/3151848.3151859},
abstract = {Spatial crowdsourcing platforms (SCP) are systems that allow someone to publish spatial tasks in order to find a suitable workforce to achieve it. These tasks require people, often using mobile devices, to be at a given location in order to accomplish them. SCPs have been source of much interest for academy and industry. For this reason, Doan et al. [4] argued in 2011 that the race was now on "toward building general crowdsourcing platforms that can be used to develop such systems quickly". Since then, little has been done in this matter. Besides, what has been proposed does not take into account real commercial SCPs and its requirements. We propose GENIUS-C, a framework to support the development of SCPs. It is based on a generic architecture proposed by Fonteles et al. [7] designed to reduce the gap between academy and industry. GENIUS-C is meant to decrease development cost and effort and increase overall quality of SCPs. A case study SCP has been created using GENIUS-C to demonstrate its benefits and how it can be used in the developments of SCPs.},
booktitle = {Proceedings of the 15th International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {131–140},
numpages = {10},
keywords = {crowdsourcing, framework, spatial crowdsourcing},
location = {Salzburg, Austria},
series = {MoMM2017}
}

@inproceedings{10.1145/2110147.2110164,
author = {Hubaux, Arnaud and Xiong, Yingfei and Czarnecki, Krzysztof},
title = {A user survey of configuration challenges in Linux and eCos},
year = {2012},
isbn = {9781450310581},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2110147.2110164},
doi = {10.1145/2110147.2110164},
abstract = {Operating systems expose sophisticated configurability to handle variability in hardware platforms like mobile devices, desktops, and servers. The variability model of an operating system kernel like Linux contains thousands of options guarded by hundreds of complex constraints. To guide users throughout the configuration and ensure the validity of their decisions, specialized tools known as configurators have been developed. Despite these tools, configuration still remains a difficult and challenging process. To better understand the challenges faced by users during configuration, we conducted two surveys, one among Linux users and another among eCos users. This paper presents the results of the surveys along three dimensions: configuration practice; user guidance; and language expressiveness. We hope that these results will help researchers and tool builders focus their efforts to improve tool support for software configuration.},
booktitle = {Proceedings of the 6th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {149–155},
numpages = {7},
location = {Leipzig, Germany},
series = {VaMoS '12}
}

@article{10.1145/2993231.2993234,
author = {Vilela, Jessyka and Goncalves, Enyo and Holanda, Ana Carla and Castro, Jaelson and Figueiredo, Bruno},
title = {A retrospective analysis of SAC requirements: engineering track},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1559-6915},
url = {https://doi.org/10.1145/2993231.2993234},
doi = {10.1145/2993231.2993234},
abstract = {Context: The activities related to Requirements engineering (RE) are some of the most important steps in software development, since the requirements describe what will be provided in a software system in order to fulfill the stakeholders' needs. In this context, the ACM Symposium on Applied Computing (SAC) has been a primary gathering forum for many RE activities. When studying a research area, it is important to identify the most active groups, topics, the research trends and so forth. Objective: In a previous paper, we investigated how the SAC RE-Track is evolving, by analyzing the papers published in its 8 previous editions. In this paper, we extended the analysis including the papers of the last edition (2016) and a brief resume of all papers published in the nine editions of SAC-RE track. Method: We adopted a research strategy that combines scoping study and systematic review good practices. Results: We investigated the most active countries, institutions and authors, the main topics discussed, the types of the contributions, the conferences and journals that have most referenced SAC RE-Track papers, the phases of the RE process supported by the contributions, the publications with the greatest impact, and the trends in RE. Conclusions: We found 86 papers over the 9 previous SAC RETrack editions, which were analyzed and discussed.},
journal = {SIGAPP Appl. Comput. Rev.},
month = aug,
pages = {26–41},
numpages = {16},
keywords = {SAC, relevance, requirements engineering, retrospective, scoping study, symposium on applied computing, systematic mapping study, trends}
}

@article{10.1504/IJAOSE.2011.043643,
author = {Nunes, Ingrid and Lucena, Carlos J. P. De and Cowan, Donald and Kulesza, Uir\'{a} and Alencar, Paulo and Nunes, Camila},
title = {Developing multi-agent system product lines: from requirements to code},
year = {2011},
issue_date = {November 2011},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {4},
number = {4},
issn = {1746-1375},
url = {https://doi.org/10.1504/IJAOSE.2011.043643},
doi = {10.1504/IJAOSE.2011.043643},
abstract = {Many modern software systems have autonomous, open, context-aware and highly-interactive properties. The agent abstraction with its autonomous and pro-active characteristics and the related discipline of agent-oriented software engineering (AOSE) are promising paradigms to address these types of systems. Even though agents are frequently being adopted, little effort has been directed in AOSE methodologies toward extensive software reuse techniques, which can provide both reduced time-to-market and lower development costs. Multi-agent system product lines (MAS-PLs) are the result of the integration of AOSE with software product lines (SPLs). SPLs bring many reuse benefits to the agent domain through the exploitation of common characteristics among family members. In this context, this paper presents a domain engineering process for developing MAS-PLs. It defines activities and work products, whose purposes include supporting agent variability and providing agent feature traceability, both not addressed by current SPL and AOSE approaches.},
journal = {Int. J. Agent-Oriented Softw. Eng.},
month = nov,
pages = {353–389},
numpages = {37}
}

@article{10.5555/3220914.3221197,
author = {Lisboa, Liana Barachisio and Garcia, Vinicius Cardoso and Almeida, Eduardo Santana and Meira, Silvio Romero},
title = {ToolDAy: a tool for domain analysis},
year = {2011},
issue_date = {August    2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1433-2779},
abstract = {Domain analysis is the process of identifying and documenting common and variable characteristics of systems in a specific domain. This process is a large and complex one, involving many interrelated activities, making it essential to have a tool support for aiding the process. We present a domain analysis tool called ToolDAy that has the purpose of making the process semi-automatic. The requirements definition presented were based on the results of a systematic review that analyzed several existing tools. Furthermore, this article describes the tool architecture, implementation and its evaluations (two as a controlled experiment and one as an industrial case study) with three different domains. The results of these evaluations indicate that the tool can aid the domain analyst to achieve systematic reuse in an effective way.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = aug,
pages = {337–353},
numpages = {17},
keywords = {Domain analysis, Software reuse, Tool, ToolDay}
}

@article{10.1016/j.jss.2016.06.043,
author = {Nurdiani, Indira and B\"{o}rstler, J\"{u}rgen and Fricker, Samuel A.},
title = {The impacts of agile and lean practices on project constraints},
year = {2016},
issue_date = {September 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {119},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.06.043},
doi = {10.1016/j.jss.2016.06.043},
abstract = {We performed a tertiary study in Agile and Lean methods.TDD is the most studies Agile practice.Each Agile and Lean practice has trade-offs. The growing interest in Agile and Lean software development is reflected in the increasing number of secondary studies on the benefits and limitations of Agile and Lean processes and practices. The aim of this tertiary study is to consolidate empirical evidence regarding Agile and Lean practices and their respective impacts on project constraints as defined in the Project Management Body of Knowledge (PMBOK): scope, quality, schedule, budget, resources, communication, and risk. In this tertiary study, 13 secondary studies were included for detailed analysis. Given the heterogeneity of the data, we were unable to perform a rigorous synthesis. Instead, we mapped the identified Agile and Lean practices, and their impacts on the project constraints described in PMBOK. From 13 secondary studies, we identified 13 Agile and Lean practices. Test-Driven Development (TDD) is studied in ten secondary studies, meanwhile other practices are studied in only one or two secondary studies. This tertiary study provides a consolidated view of the impacts of Agile and Lean practices. The result of this tertiary study indicates that TDD has a positive impact on external quality. However, due to insufficient data or contradictory results, we were unable to make inferences on other Agile and Lean practices. Implications for research and practice are further discussed in the paper.},
journal = {J. Syst. Softw.},
month = sep,
pages = {162–183},
numpages = {22},
keywords = {Agile software development, Lean software development, Project constraints, Tertiary study}
}

@article{10.1007/s10270-014-0405-5,
author = {Iqbal, Muhammad Zohaib and Ali, Shaukat and Yue, Tao and Briand, Lionel},
title = {Applying UML/MARTE on industrial projects: challenges, experiences, and guidelines},
year = {2015},
issue_date = {October   2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-014-0405-5},
doi = {10.1007/s10270-014-0405-5},
abstract = {Modeling and Analysis of Real-Time and Embedded Systems (MARTE) is a Unified Modeling Language (UML) profile, which has been developed to model concepts specific to Real-Time and Embedded Systems (RTES). In the last 5 years, we have applied UML/MARTE to three distinct industrial problems in three industry sectors: architecture modeling and configuration of large-scale and highly configurable integrated control systems, model-based robustness testing of communication-intensive systems, and model-based environment simulator generation of large-scale RTES for testing. In this paper, we report on our experience of solving these problems by applying UML/MARTE on four industrial case studies. We highlight the challenges we faced with respect to the industrial adoption of MARTE. Based on our combined experience, we derive a framework to guide practitioners for future applications of UML/MARTE in an industrial context. The framework provides a set of detailed guidelines that help reduce the gap between the modeling notations and real-world industrial application needs.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1367–1385},
numpages = {19},
keywords = {Architecture Modeling, Industrial Case Studies, MARTE, Model-based Testing, Real-Time Embedded Systems, UML}
}

@article{10.1007/s11219-018-9405-y,
author = {Vale, Gustavo and Fernandes, Eduardo and Figueiredo, Eduardo},
title = {On the proposal and evaluation of a benchmark-based threshold derivation method},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9405-y},
doi = {10.1007/s11219-018-9405-y},
abstract = {Software-intensive systems have been growing in both size and complexity. Consequently, developers need better support for measuring and controlling the software quality. In this context, software metrics aim at quantifying different software quality aspects. However, the effectiveness of measurement depends on the definition of reliable metric thresholds, i.e., numbers that characterize a metric value as critical given a quality aspect. In fact, without proper metric thresholds, it might be difficult for developers to indicate problematic software components for correction, for instance. Based on a literature review, we have found several existing methods for deriving metric thresholds and observed their evolution. Such evolution motivated us to propose a new method that incorporates the best of the existing methods. In this paper, we propose a novel benchmark-based method for deriving metric thresholds. We assess our method, called Vale's method, using a set of metric thresholds derived with the support of our method, aimed at composing detection strategies for two well-known code smells, namely god class and lazy class. For this purpose, we analyze three benchmarks composed of multiple software product lines. In addition, we demonstrate our method in practice by applying it to a benchmark composed of 103 Java open-source software systems. In the evaluation, we compare Vale's method to two state-of-the-practice threshold derivation methods selected as a baseline, which are Lanza's method and Alves' method. Our results suggest that the proposed method provides more realistic and reliable thresholds, with better recall and precision in the code smell detection, when compared to both baseline methods.},
journal = {Software Quality Journal},
month = mar,
pages = {275–306},
numpages = {32},
keywords = {Benchmark, Code smell, Software metric, Software product lines, Threshold}
}

@inproceedings{10.1007/978-3-642-31762-0_5,
author = {Wong, Peter Y. H. and Diakov, Nikolay and Schaefer, Ina},
title = {Modelling adaptable distributed object oriented systems using the HATS approach: a fredhopper case study},
year = {2011},
isbn = {9783642317613},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31762-0_5},
doi = {10.1007/978-3-642-31762-0_5},
abstract = {The HATS project aims at developing a model-centric engineering methodology for the design, implementation and verification of distributed, concurrent and highly configurable systems. Such systems also have high demands on their dependability and trustworthiness. The HATS approach is centered around the Abstract Behavioural Specification modelling language (ABS) and its accompanying tools suite. The HATS approach allows the precise specification and analysis of the abstract behaviour of distributed software systems and their variability. The HATS project measures its success by applying its framework not only to toy examples, but to real industrial scenarios. In this paper, we evaluate the HATS approach for modelling an industrial scale case study provided by the eCommerce company Fredhopper. In this case study we consider Fredhopper Access Server (FAS). We model the commonality and variability of FAS's replication system using the ABS language and provide an evaluation based on our experience.},
booktitle = {Proceedings of the 2011 International Conference on Formal Verification of Object-Oriented Software},
pages = {49–66},
numpages = {18},
keywords = {evaluation, formal modelling and specification, industrial case study, software product lines, variability modelling},
location = {Turin, Italy},
series = {FoVeOOS'11}
}

@article{10.1007/s10922-010-9169-6,
author = {Garc\'{\i}a Clemente, F\'{e}lix J. and Alcaraz Calero, Jose M. and Bernal Bernab\'{e}, Jorge and Mar\'{\i}n P\'{e}rez, Juan Manuel and Mart\'{\i}nez P\'{e}rez, Gregorio and G\'{o}mez Skarmeta, Antonio F.},
title = {Semantic Web-Based Management of Routing Configurations},
year = {2011},
issue_date = {June      2011},
publisher = {Plenum Press},
address = {USA},
volume = {19},
number = {2},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-010-9169-6},
doi = {10.1007/s10922-010-9169-6},
abstract = {Today, network operators typically reason about network behaviour by observing the effects of a particular configuration in operation. This configuration process typically involves logging configuration changes and rolling back to a previous version when a problem arises. Advanced network operators (more each day) use policy-based routing languages to define the routing configuration and tools based on systematic verification techniques to ensure that operational behaviour is consistent with the intended behaviour. These tools help operators to reason about properties of routing protocols. However, these languages and tools work in low-level, i.e. they focus on properties, parameters, and elements of routing protocols. However, network operators receive high-level policies that must be refined to low level parameters before they can be applied. These high-level policies should consider other properties (e.g. extensibility or reasoning capabilities), parameters (e.g. time period, localization or QoS parameters), and elements (e.g. AAA individuals or resources), when the network configuration is defined. We believe that there is a need of broader approaches in languages and tools for defining routing configurations that are more powerful and integrated to other network elements. This article provides the main ideas behind the specification of routing policies using formal languages which enable the description of semantics. These semantics make easier the policy refinement process and allows describing an automated process for doing conflict detection on these policies.},
journal = {J. Netw. Syst. Manage.},
month = jun,
pages = {209–229},
numpages = {21},
keywords = {BGP, Conflict detection, Network management, Policy languages, Routing policy, Semantic web}
}

@inproceedings{10.1145/1960502.1960508,
author = {Machado, Idarlan and Bonif\'{a}cio, Rodrigo and Alves, Vander and Turnes, Lucin\'{e}ia and Machado, Giselle},
title = {Managing variability in business processes: an aspect-oriented approach},
year = {2011},
isbn = {9781450306454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1960502.1960508},
doi = {10.1145/1960502.1960508},
abstract = {Business processes specify key activities in an organization, some of which can be automated. It is often the case that replication of activities across such processes occur and failure in identifying such replication results in organizational costs. To minimize this risk and optimize organizational resources, in this paper we characterize variability in business process and propose an approach to manage such a variability. The characterization of variability relies on the study of industrial-strength applications in the Human Resources domain. The management of variability is based on a compositional and parametric approach with Aspect-Orientation. It leverages and extends an existing tool to address variability in such domain},
booktitle = {Proceedings of the 2011 International Workshop on Early Aspects},
pages = {25–30},
numpages = {6},
keywords = {aspects, business processes, composition, software product lines},
location = {Porto de Galinhas, Brazil},
series = {EA '11}
}

@inproceedings{10.1145/1944892.1944904,
author = {Mazo, Raul and Gr\"{u}nbacher, Paul and Heider, Wolfgang and Rabiser, Rick and Salinesi, Camille and Diaz, Daniel},
title = {Using constraint programming to verify DOPLER variability models},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944904},
doi = {10.1145/1944892.1944904},
abstract = {Software product lines are typically developed using model-based approaches. Models are used to guide and automate key activities such as the derivation of products. The verification of product line models is thus essential to ensure the consistency of the derived products. While many authors have proposed approaches for verifying feature models there is so far no such approach for decision models. We discuss challenges of analyzing and verifying decision-oriented DOPLER variability models. The manual verification of these models is an error-prone, tedious, and sometimes infeasible task. We present a preliminary approach that converts DOPLER variability models into constraint programs to support their verification. We assess the feasibility of our approach by identifying defects in two existing variability models.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {97–103},
numpages = {7},
keywords = {constraint programming, decision-oriented variability models, software product lines, verification},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@inproceedings{10.1145/2351676.2351693,
author = {Rabiser, Rick and Gr\"{u}nbacher, Paul and Lehofer, Martin},
title = {A qualitative study on user guidance capabilities in product configuration tools},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351693},
doi = {10.1145/2351676.2351693},
abstract = {Software systems are nowadays often configured by sales people, domain experts, or even customers instead of engineers. Configuration tools communicate the systems' variability to these end users and provide guidance for selecting and customizing the available features. However, even if a configuration tool creates technically correct systems, addressing the specific needs of business-oriented users remains challenging. We analyze existing configuration tools to identify key capabilities for guiding end users and discuss these capabilities using the cognitive dimensions of notations framework. We present an implementation of the capabilities in our configuration tool DOPLER CW. We performed a qualitative investigation on the usefulness of the tool's capabilities for user guidance in product configuration by involving nine business-oriented experts of two industry partners from the domain of industrial automation. We present key results and derive general implications for tool developers.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {110–119},
numpages = {10},
keywords = {Configuration tools, cognitive dimensions of notations, end user guidance, qualitative study},
location = {Essen, Germany},
series = {ASE '12}
}

@article{10.1016/j.jnca.2015.07.007,
author = {Yongsiriwit, Karn and Assy, Nour and Gaaloul, Walid},
title = {A semantic framework for configurable business process as a service in the cloud},
year = {2016},
issue_date = {January 2016},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {59},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2015.07.007},
doi = {10.1016/j.jnca.2015.07.007},
abstract = {With the advent of Cloud Computing, new opportunities for Business Process Outsourcing services have emerged. Business Process as a Service (BPaaS), a new cloud service model, has recently gained a great importance for outsourcing cloud-based business processes constructed for multi-tenancy. In such a multi-tenant environment, using configurable business process models enables the sharing of a reference process among different tenants that can be customized according to specific needs. With a large choice of configurable process modeling languages, different providers may deliver configurable processes with common functionalities but different representations which makes the process discovery and configuration a manual tedious task. This in turn creates cloud silos and vendors lock-in with non-reusable configurable BPaaS models. Therefore, with the aim of enabling the interoperability between multiple BPaaS providers, we propose in this paper a semantic framework for BPaaS configurable models. Taking advantage of Semantic Web technologies and data mining techniques, our framework allows for (1) an ontology-based high level abstract representation of BPaaS configurable models enriched with configuration guidelines and (2) an automated approach for extracting the configuration guidelines from existing process repositories. To show the feasibility and effectiveness of our approach, we extend Signavio with our semantic framework and conduct experiments on a dataset from SAP reference model.},
journal = {J. Netw. Comput. Appl.},
month = jan,
pages = {168–184},
numpages = {17},
keywords = {BPaaS, Business Process as a Service, Cloud Computing, Configurable process model, Green IT, Semantic technology}
}

@article{10.1007/s10515-012-0117-4,
author = {N\"{o}hrer, Alexander and Egyed, Alexander},
title = {C2O configurator: a tool for guided decision-making},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-012-0117-4},
doi = {10.1007/s10515-012-0117-4},
abstract = {Decision models are widely used in software engineering to describe and restrict decision-making (e.g., deriving a product from a product-line). Since decisions are typically interdependent, it is often neither obvious which decisions have the most significant impact nor which decisions might ultimately conflict. Unfortunately, the current state-of-the-art provides little support for dealing with such situations. On the one hand, some conflicts can be avoided by providing more freedom in which order decisions are made (i.e., most important decisions first). On the other hand, conflicts are unavoidable at times, and living with conflicts may be preferable over forcing the user to fix them right away--particularly because fixing conflicts becomes easier as more is known about a user's intentions. This paper introduces the C2O (Configurator 2.0) tool for guided decision-making. The tool allows the user to answer questions in an arbitrary order--with and without the presence of inconsistencies. While giving users those freedoms, it still supports and guides them by (i) rearranging the order of questions according to their potential to minimize user input, (ii) providing guidance to avoid follow-on conflicts, and (iii) supporting users in fixing conflicts at a later time.},
journal = {Automated Software Engg.},
month = jun,
pages = {265–296},
numpages = {32}
}

@inproceedings{10.1145/2695664.2695875,
author = {Almeida, Andr\'{e} and Bencomo, Nelly and Batista, Thais and Cavalcante, Everton and Dantas, Francisco},
title = {Dynamic decision-making based on NFR for managing software variability and configuration selection},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695875},
doi = {10.1145/2695664.2695875},
abstract = {Due to dynamic variability, identifying the specific conditions under which non-functional requirements (NFRs) are satisfied may be only possible at runtime. Therefore, it is necessary to consider the dynamic treatment of relevant information during the requirements specifications. The associated data can be gathered by monitoring the execution of the application and its underlying environment to support reasoning about how the current application configuration is fulfilling the established requirements. This paper presents a dynamic decision-making infrastructure to support both NFRs representation and monitoring, and to reason about the degree of satisfaction of NFRs during runtime. The infrastructure is composed of: (i) an extended feature model aligned with a domain-specific language for representing NFRs to be monitored at runtime; (ii) a monitoring infrastructure to continuously assess NFRs at runtime; and (iii) a flexible decision-making process to select the best available configuration based on the satisfaction degree of the NRFs. The evaluation of the approach has shown that it is able to choose application configurations that well fit user NFRs based on runtime information. The evaluation also revealed that the proposed infrastructure provided consistent indicators regarding the best application configurations that fit user NFRs. Finally, a benefit of our approach is that it allows us to quantify the level of satisfaction with respect to NFRs specification.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1376–1382},
numpages = {7},
keywords = {SPLs, monitoring, non-functional requirements, variability},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1007/978-3-642-33666-9_36,
author = {Aranega, Vincent and Etien, Anne and Mosser, Sebastien},
title = {Using feature model to build model transformation chains},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_36},
doi = {10.1007/978-3-642-33666-9_36},
abstract = {Model transformations are intrinsically related to model-driven engineering. According to the increasing size of standardised meta-model, large transformations need to be developed to cover them. Several approaches promote separation of concerns in this context, that is, the definition of small transformations in order to master the overall complexity. Unfortunately, the decomposition of transformations into smaller ones raises new issues: organising the increasing number of transformations and ensuring their composition (i.e. the chaining). In this paper, we propose to use feature models to classify model transformations dedicated to a given business domain. Based on this feature models, automated techniques are used to support the designer, according to two axis: (i)the definition of a valid set of model transformations and (ii) the generation of an executable chain of model transformation that accurately implement designer's intention. This approach is validated on Gaspard2, a tool dedicated to the design of embedded system.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {562–578},
numpages = {17},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.5555/1813962.1813999,
author = {Gadelha, Bruno and Nunes, Ingrid and Fuks, Hugo and De Lucena, Carlos J. P.},
title = {An approach for developing groupware product lines based on the 3C collaboration model},
year = {2009},
isbn = {3642042155},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software Product Lines (SPLs) are a new software engineering technology that aims at promoting reduced time and costs in the development of system families by the exploitation of applications commonalities. Given that different Groupware applications typically share a lot of functionalities, Groupware Product Lines (GPLs) have emerged to incorporate SPL benefits to the Groupware development. In this paper, we propose an approach for developing GPLs, which incorporates SPL techniques to allow the derivation of customized groupware according to specific contexts and the systematic reuse of software assets. Our approach is based on the 3C Collaboration Model that allows identifying collaboration needs and guiding the user to select appropriate features according to their collaboration purpose. A GPL of Learning Object repositories, named FLOCOS GPL, is used to illustrate the proposed approach.},
booktitle = {Proceedings of the 15th International Conference on Groupware: Design, Implementation, and Use},
pages = {328–343},
numpages = {16},
keywords = {groupware development, learning objects, software product lines},
location = {Peso da R\'{e}gua, Douro, Portugal},
series = {CRIWG'09}
}

@article{10.1016/j.scico.2012.12.004,
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
title = {FAMILIAR: A domain-specific language for large scale management of feature models},
year = {2013},
issue_date = {June, 2013},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {78},
number = {6},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2012.12.004},
doi = {10.1016/j.scico.2012.12.004},
abstract = {The feature model formalism has become the de facto standard for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. This activity is generally tedious and error-prone. In this article, we present FAMILIAR a Domain-Specific Language (DSL) that is dedicated to the large scale management of feature models and that complements existing tool support. The language provides a powerful support for separating concerns in feature modeling, through the provision of composition and decomposition operators, reasoning facilities and scripting capabilities with modularization mechanisms. We illustrate how an SPL consisting of medical imaging services can be practically managed using reusable FAMILIAR scripts that implement reasoning mechanisms. We also report on various usages and applications of FAMILIAR and its operators, to demonstrate their applicability to different domains and use for different purposes.},
journal = {Sci. Comput. Program.},
month = jun,
pages = {657–681},
numpages = {25},
keywords = {Domain-specific language, Feature model, Model management, Software product lines, Variability}
}

@inproceedings{10.1145/3167132.3167352,
author = {Cordy, Maxime and Heymans, Patrick},
title = {Engineering configurators for the retail industry: experience report and challenges ahead},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167352},
doi = {10.1145/3167132.3167352},
abstract = {Mass customization is a widely embraced paradigm through which engineers, sales people and customers can tailor products to specific needs. One typically achieves this task by using a configurator, i.e. a software application wherein a user can define the product she wants by selecting options and setting parameters. Given their importance, configurators must be dependable and evolvable. Yet, building configurators often constitutes a complex software engineering challenge. In this paper, we report on two configurators developed by a spin-off company of the University of Namur for the retail industry. We highlight the difficulties inherent to such developments and present solutions that can help overcoming them. Finally, we expose open challenges and discuss how future research can address them.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {2050–2057},
numpages = {8},
keywords = {configuration, industrial application, retail},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1145/1629716.1629730,
author = {Heidenreich, Florian},
title = {Towards systematic ensuring well-formedness of software product lines},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629730},
doi = {10.1145/1629716.1629730},
abstract = {Variability modelling with feature models is one key technique for specifying the problem space of software product lines (SPLs). To allow for the automatic derivation of a concrete product based on a given variant configuration, a mapping between features in the problem space and their realisations in the solution space is required. Ensuring the correctness of all participating models of an SPL (i.e., feature models, mapping models, and solution-space models) is a crucial task to create correct products of an SPL. In this paper we discuss different possibilities for checking well-formedness of SPLs and relate them to their implementation in the FeatureMapper SPL tool.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {69–74},
numpages = {6},
keywords = {FeatureMapper, separation of concerns, software product lines, variability modelling, well-formedness rules},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@inproceedings{10.1109/ICSE.2019.00091,
author = {Heradio, Ruben and Fernandez-Amoros, David and Mayr-Dorn, Christoph and Egyed, Alexander},
title = {Supporting the statistical analysis of variability models},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00091},
doi = {10.1109/ICSE.2019.00091},
abstract = {Variability models are broadly used to specify the configurable features of highly customizable software. In practice, they can be large, defining thousands of features with their dependencies and conflicts. In such cases, visualization techniques and automated analysis support are crucial for understanding the models. This paper contributes to this line of research by presenting a novel, probabilistic foundation for statistical reasoning about variability models. Our approach not only provides a new way to visualize, describe and interpret variability models, but it also supports the improvement of additional state-of-the-art methods for software product lines; for instance, providing exact computations where only approximations were available before, and increasing the sensitivity of existing analysis operations for variability models. We demonstrate the benefits of our approach using real case studies with up to 17,365 features, and written in two different languages (KConfig and feature models).},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {843–853},
numpages = {11},
keywords = {binary decision diagrams, feature modeling, software product lines, software visualization, variability modeling},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1007/s10009-014-0301-x,
author = {Wong, Peter Y. and Bubel, Richard and Boer, Frank S. and G\'{o}mez-Zamalloa, Miguel and Gouw, Stijn and H\"{a}hnle, Reiner and Meinke, Karl and Sindhu, Muddassar Azam},
title = {Testing abstract behavioral specifications},
year = {2015},
issue_date = {February  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {1},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-014-0301-x},
doi = {10.1007/s10009-014-0301-x},
abstract = {We present a range of testing techniques for the Abstract Behavioral Specification (ABS) language and apply them to an industrial case study. ABS is a formal modeling language for highly variable, concurrent, component-based systems. The nature of these systems makes them susceptible to the introduction of subtle bugs that are hard to detect in the presence of steady adaptation. While static analysis techniques are available for an abstract language such as ABS, testing is still indispensable and complements analytic methods. We focus on fully automated testing techniques including black-box and glass-box test generation as well as runtime assertion checking, which are shown to be effective in an industrial setting.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = feb,
pages = {107–119},
numpages = {13},
keywords = {Automated testing, Black-box testing, Glass-box testing, Industrial case study, Runtime assertion checking}
}

@book{10.5555/2692450,
author = {Mistrik, Ivan and Bahsoon, Rami and Eeles, Peter and Roshandel, Roshanak and Stal, Michael},
title = {Relating System Quality and Software Architecture},
year = {2014},
isbn = {0124170099},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {System Quality and Software Architecture collects state-of-the-art knowledge on how to intertwine software quality requirements with software architecture and how quality attributes are exhibited by the architecture of the system. Contributions from leading researchers and industry evangelists detail the techniques required to achieve quality management in software architecting, and the best way to apply these techniques effectively in various application domains (especially in cloud, mobile and ultra-large-scale/internet-scale architecture) Taken together, these approaches show how to assess the value of total quality management in a software development process, with an emphasis on architecture. The book explains how to improve system quality with focus on attributes such as usability, maintainability, flexibility, reliability, reusability, agility, interoperability, performance, and more. It discusses the importance of clear requirements, describes patterns and tradeoffs that can influence quality, and metrics for quality assessment and overall system analysis. The last section of the book leverages practical experience and evidence to look ahead at the challenges faced by organizations in capturing and realizing quality requirements, and explores the basis of future work in this area.Explains how design decisions and method selection influence overall system quality, and lessons learned from theories and frameworks on architectural qualityShows how to align enterprise, system, and software architecture for total qualityIncludes case studies, experiments, empirical validation, and systematic comparisons with other approaches already in practice.}
}

@inproceedings{10.1007/978-3-030-45989-5_12,
author = {Sun, Chang-ai and Wang, Jing and Guo, Jing and Wang, Zhen and Duan, Li},
title = {A Reconfigurable Microservice-Based Migration Technique for IoT Systems},
year = {2019},
isbn = {978-3-030-45988-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-45989-5_12},
doi = {10.1007/978-3-030-45989-5_12},
abstract = {An Internet of Things (IoT) system is often an integration of a large number of hardware and software modules, which are expected to be easily replaced or reconfigured in order to cater for quickly-changing environments and requirements. With the popularity of microservices, people have attempted to introduce the microservice architecture to IoT systems, while paid little attention to the connectivity between the decomposed microservices, resulting in poor reconfigurability of the resulting system. In this paper, we propose a reconfigurable microservice-based migration technique for IoT systems, which first decomposes an IoT system as a set of microservices and then introduces variation contexts to make the decomposed microservices reconfigurable. We have conducted a case study on an open-source real-life unmanned aerial vehicle (UAV) system. The results demonstrate that the migrated UAV system can be dynamically reconfigured to handle various run-time changes.},
booktitle = {Service-Oriented Computing – ICSOC 2019 Workshops: WESOACS, ASOCA, ISYCC, TBCE, and STRAPS, Toulouse, France, October 28–31, 2019, Revised Selected Papers},
pages = {142–155},
numpages = {14},
keywords = {Internet of Things (IoT), Microservices, Migration techniques, Service compositions, Reconfigurable systems},
location = {Toulouse, France}
}

@inproceedings{10.5555/3297765.3297769,
author = {Trapp, Matthias and Pasewaldt, Sebastian and D\"{u}rschmid, Tobias and Semmo, Amir and D\"{o}llner, J\"{u}rgen},
title = {Teaching image-processing programming for mobile devices: a software development perspective},
year = {2018},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {In this paper we present a concept of a research course that teaches students in image processing as a building block of mobile applications. Our goal with this course is to teach theoretical foundations, practical skills in software development as well as scientific working principles to qualify graduates to start as fully-valued software developers or researchers. The course includes teaching and learning focused on the nature of small team research and development as encountered in the creative industries dealing with computer graphics, computer animation and game development. We discuss our curriculum design and issues in conducting undergraduate and graduate research that we have identified through four iterations of the course. Joint scientific demonstrations and publications of the students and their supervisors as well as quantitative and qualitative evaluation by students underline the success of the proposed concept. In particular, we observed that developing using a common software framework helps the students to jump start their course projects, while industry software processes such as branching coupled with a three-tier breakdown of project features helps them to structure and assess their progress.},
booktitle = {Proceedings of the 39th Annual European Association for Computer Graphics Conference: Education Papers},
pages = {17–24},
numpages = {8},
location = {Delft, The Netherlands},
series = {EG-EDU '18}
}

@inproceedings{10.1145/3196398.3196442,
author = {Nair, Vivek and Agrawal, Amritanshu and Chen, Jianfeng and Fu, Wei and Mathew, George and Menzies, Tim and Minku, Leandro and Wagner, Markus and Yu, Zhe},
title = {Data-driven search-based software engineering},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196442},
doi = {10.1145/3196398.3196442},
abstract = {This paper introduces Data-Driven Search-based Software Engineering (DSE), which combines insights from Mining Software Repositories (MSR) and Search-based Software Engineering (SBSE). While MSR formulates software engineering problems as data mining problems, SBSE reformulate Software Engineering (SE) problems as optimization problems and use meta-heuristic algorithms to solve them. Both MSR and SBSE share the common goal of providing insights to improve software engineering. The algorithms used in these two areas also have intrinsic relationships. We, therefore, argue that combining these two fields is useful for situations (a) which require learning from a large data source or (b) when optimizers need to know the lay of the land to find better solutions, faster.This paper aims to answer the following three questions: (1) What are the various topics addressed by DSE?, (2) What types of data are used by the researchers in this area?, and (3) What research approaches do researchers use? The paper briefly sets out to act as a practical guide to develop new DSE techniques and also to serve as a teaching resource.This paper also presents a resource (tiny.cc/data-se) for exploring DSE. The resource contains 89 artifacts which are related to DSE, divided into 13 groups such as requirements engineering, software product lines, software processes. All the materials in this repository have been used in recent software engineering papers; i.e., for all this material, there exist baseline results against which researchers can comparatively assess their new ideas.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {341–352},
numpages = {12},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@article{10.1016/j.eswa.2012.08.026,
author = {Ognjanovi\'{c}, Ivana and Ga\v{s}Evi\'{c}, Dragan and Bagheri, Ebrahim},
title = {A stratified framework for handling conditional preferences: An extension of the analytic hierarchy process},
year = {2013},
issue_date = {March, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2012.08.026},
doi = {10.1016/j.eswa.2012.08.026},
abstract = {Representing and reasoning over different forms of preferences is of crucial importance to many different fields, especially where numerical comparisons need to be made between critical options. Focusing on the well-known Analytical Hierarchical Process (AHP) method, we propose a two-layered framework for addressing different kinds of conditional preferences which include partial information over preferences and preferences of a lexicographic kind. The proposed formal two-layered framework, called CS-AHP, provides the means for representing and reasoning over conditional preferences. The framework can also effectively order decision outcomes based on conditional preferences in a way that is consistent with well-formed preferences. Finally, the framework provides an estimation of the potential number of violations and inconsistencies within the preferences. We provide and report extensive performance analysis for the proposed framework from three different perspectives, namely time-complexity, simulated decision making scenarios, and handling cyclic and partially defined preferences.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1094–1115},
numpages = {22},
keywords = {AHP method, Comparative preferences, Conditional preferences, Lexicographic order, S-AHP method, Well-formed preferences}
}

@inproceedings{10.1145/1868688.1868690,
author = {Siegmund, Norbert and Rosenm\"{u}ller, Marko and Apel, Sven},
title = {Automating energy optimization with features},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868690},
doi = {10.1145/1868688.1868690},
abstract = {Mobile devices such as cell phones and notebooks rely on battery power supply. For these systems, optimizing the power consumption is important to increase the system's lifetime. However, this is hard to achieve because energy-saving functions often depend on the hardware, and operating systems. The diversity of hardware components and operating systems makes the implementation time consuming and difficult. We propose an approach to automate energy optimization of programs by implementing energy-saving functionality as modular, separate implementation units (e.g., feature modules or aspects). These units are bundled as energy features into an energy-optimization feature library. Based on aspect-oriented and feature-oriented programming, we discuss different techniques to compose the source code of a client program and the implementation units of the energy features.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {2–9},
numpages = {8},
keywords = {energy consumption, feature-oriented programming, software product lines},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/2896935.2896939,
author = {Zheng, Yongjie and Cu, Cuong},
title = {Towards implementing product line architecture},
year = {2016},
isbn = {9781450341530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896935.2896939},
doi = {10.1145/2896935.2896939},
abstract = {A primary challenge involved in implementing product line architecture is realization of the included variation points (e.g. alternative components, optional interfaces) in source code. Existing architecture implementation techniques are focused on single system development. Software variability implementation techniques such as inheritance and overloading mainly support fine-grained variations at the programming language level. In this paper, we present a novel approach to implementing product line architecture. It combines a code generation and separation pattern with an architecture-based code annotation technique. It can support product line variability in platforms, functions, and implementation mechanisms that are at different degrees of granularity. The goal is to maintain architecture-implementation conformance and increase code reusability.},
booktitle = {Proceedings of the 1st International Workshop on Bringing Architectural Design Thinking into Developers' Daily Activities},
pages = {5–10},
numpages = {6},
keywords = {architecture implementation, architecture-implementation conformance, software variability implementation},
location = {Austin, Texas},
series = {BRIDGE '16}
}

@inproceedings{10.1007/978-3-319-35122-3_17,
author = {Jin, Xiaoyu and Khatwani, Charu and Niu, Nan and Wagner, Michael and Savolainen, Juha},
title = {Pragmatic Software Reuse in Bioinformatics: How Can Social Network Information Help?},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_17},
doi = {10.1007/978-3-319-35122-3_17},
abstract = {Little is known about the specific kinds of questions that bioinformatics programmers ask during pragmatic software reuse tasks and how well development online social networks help answer those questions. To fill the gap, we report an empirical study involving 20 biomedical software developers performing reuse tasks. A key contribution of our study is the discovery of 31 questions needed to be addressed, which we further classify into 5 categories along a software-architecture-centric and problem-domain-centric spectrum. Our study further provides evidence for the positive effect of social network information on pragmatic reuse tasks. Our work can lead to enhanced tool support so as to improve biomedical software reuse in practice.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {247–264},
numpages = {18},
keywords = {Architecture-centric reuse, Biomedical software, Information needs, Pragmatic software reuse, Social network information},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1145/2866614.2866620,
author = {Mauro, Jacopo and Nieke, Michael and Seidl, Christoph and Yu, Ingrid Chieh},
title = {Context Aware Reconfiguration in Software Product Lines},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866620},
doi = {10.1145/2866614.2866620},
abstract = {Software Product Lines (SPLs) are a mechanism for large-scale reuse where families of related software systems are represented in terms of commonalities and variabilities, e.g., using Feature Models (FMs). While FMs define all possible configurations of the SPL, when considering dynamic SPLs not every possible configuration may be valid in all possible contexts. Unfortunately, common FMs can not capture this context dependence. In this paper, we remedy this problem by extending attributed FMs with Validity Formulas (VFs) that constrain the selection of a particular feature to a specific context and that are located directly within the FM. We provide a reconfiguration engine that checks if the active configuration is valid in the current context and, if not, computes how to reconfigure it. Furthermore, we present our implementation and demonstrate its feasibility within a case study derived from scenarios of our industry partner in the automotive domain.},
booktitle = {Proceedings of the 10th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {41–48},
numpages = {8},
keywords = {Context, Feature Models, Software Product Lines, Variability},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@article{10.1007/s10270-020-00831-4,
author = {Klikovits, Stefan and Buchs, Didier},
title = {Pragmatic reuse for DSML development: Composing a DSL for hybrid CPS modeling},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00831-4},
doi = {10.1007/s10270-020-00831-4},
abstract = {By bridging the semantic gap, domain-specific language (DSLs) serve an important role in the conquest to allow domain experts to model their systems themselves. In this publication we present a case study of the development of the Continuous REactive SysTems language (CREST), a DSL for hybrid systems modeling. The language focuses on the representation of continuous resource flows such as water, electricity, light or heat. Our methodology follows a very pragmatic approach, combining the syntactic and semantic principles of well-known modeling means such as hybrid automata, data-flow languages and architecture description languages into a coherent language. The borrowed aspects have been carefully combined and formalised in a well-defined operational semantics. The DSL provides two concrete syntaxes: CREST diagrams, a graphical language that is easily understandable and serves as a model basis, and crestdsl, an internal DSL implementation that supports rapid prototyping—both are geared towards usability and clarity. We present the DSL’s semantics, which thoroughly connect the various language concerns into an executable formalism that enables sound simulation and formal verification in crestdsl, and discuss the lessons learned throughout the project.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {837–866},
numpages = {30},
keywords = {Cyber-physical systems, Domain-specific language, Modeling, Simulation, Verification}
}

@inproceedings{10.1145/1868688.1868697,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Kuhlemann, Martin},
title = {Improving reuse of component families by generating component hierarchies},
year = {2010},
isbn = {9781450302081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868688.1868697},
doi = {10.1145/1868688.1868697},
abstract = {Feature-oriented software development (FOSD) enables developers to generate families of similar components. However, current FOSD approaches degrade component reuse because they do not allow a developer to combine multiple components of the same family in a larger program. This is because individual family members cannot be distinguished from each other. We present an approach to model and generate component hierarchies that allow a programmer to combine multiple component variants. A component hierarchy structures the components of a family according to their functionality. Due to subtyping between the components of a hierarchy, client developers can write generic code that works with different component variants.},
booktitle = {Proceedings of the 2nd International Workshop on Feature-Oriented Software Development},
pages = {57–64},
numpages = {8},
location = {Eindhoven, The Netherlands},
series = {FOSD '10}
}

@inproceedings{10.1145/2245276.2245370,
author = {Parra, Carlos and Romero, Daniel and Mosser, S\'{e}bastien and Rouvoy, Romain and Duchien, Laurence and Seinturier, Lionel},
title = {Using constraint-based optimization and variability to support continuous self-adaptation},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2245370},
doi = {10.1145/2245276.2245370},
abstract = {Self-adaptation is one of the upcoming paradigms that accurately tackles nowadays systems complexity. In this context, Dynamic Software Product Lines model the intrinsic variability of a family of systems, and dynamically support their reconfiguration according to updated context. However, when several configurations are available for the same context, making a decision about the right one is a hard challenge: further dimensions such as QoS are needed to enrich the decision making process. In this paper, we propose to combine variability with Constraint-Satisfaction Problem techniques to face this challenge. The approach is illustrated and validated with a context-driven system used to support the control of a home through mobile devices.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {486–491},
numpages = {6},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1016/j.jss.2017.03.044,
author = {Nuez-Varela, Alberto S. and Prez-Gonzalez, Hctor G. and Martnez-Perez, Francisco E. and Soubervielle-Montalvo, Carlos},
title = {Source code metrics},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {128},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.03.044},
doi = {10.1016/j.jss.2017.03.044},
abstract = {Three major programming paradigms measured by source code metrics were identified.The CK metrics and the object oriented paradigm are the most studied subjects.Java benchmark systems are the most commonly measured systems in research.Technology on metrics extraction mechanisms are not up to research advances.Empirical studies have a major impact on the code metrics community. ContextSource code metrics are essential components in the software measurement process. They are extracted from the source code of the software, and their values allow us to reach conclusions about the quality attributes measured by the metrics. ObjectivesThis paper aims to collect source code metrics related studies, review them, and perform an analysis, while providing an overview on the current state of source code metrics and their current trends. MethodA systematic mapping study was conducted. A total of 226 studies, published between the years 2010 and 2015, were selected and analyzed. ResultsAlmost 300 source code metrics were found. Object oriented programming is the most commonly studied paradigm with the Chidamber and Kemerer metrics, lines of code, McCabe's cyclomatic complexity, and number of methods and attributes being the most used metrics. Research on aspect and feature oriented programming is growing, especially for the current interest in programming concerns and software product lines. ConclusionsObject oriented metrics have gained much attention, but there is a current need for more studies on aspect and feature oriented metrics. Software fault prediction, complexity and quality assessment are recurrent topics, while concerns, big scale software and software product lines represent current trends.},
journal = {J. Syst. Softw.},
month = jun,
pages = {164–197},
numpages = {34},
keywords = {Aspect-oriented metrics, Feature-oriented metrics, Object-oriented metrics, Software metrics, Source code metrics, Systematic mapping study}
}

@inproceedings{10.1145/2642937.2653472,
author = {Angerer, Florian},
title = {Variability-aware change impact analysis of multi-language product lines},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2653472},
doi = {10.1145/2642937.2653472},
abstract = {Change impact analysis (CIA) techniques have been applied successfully to determine the effects of modifications when evolving software systems. However, many software systems today use multiple programming languages and they are organized as software product lines (SPLs) to ease their customization to different customer and market needs. Due to the limitations of current CIA approaches regarding variability and cross-language support assessing the impact of changes becomes difficult and arduous. This work aims at developing a CIA approach for multi language SPLs. The approach is based on a multiple conditional system dependency graphs. We will evaluate the approach based on the software product lines of an industry partner in the domain of industrial automation.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {903–906},
numpages = {4},
keywords = {change impact analysis, clone-and-own, cross-language analysis, variability-aware program analysis},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@inproceedings{10.1145/1289971.1289988,
author = {Laguna, Miguel A. and Gonz\'{a}lez-Baixauli, Bruno and Marqu\'{e}s, Jos\'{e} M.},
title = {Seamless development of software product lines},
year = {2007},
isbn = {9781595938558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1289971.1289988},
doi = {10.1145/1289971.1289988},
abstract = {One of the key problems in the development of software product lines is the representation and management of variability and commonality. The customary way to define both aspects is by means of feature models that also allow the configuration of each specific application within the product line to be selected. However the control of traceability between the features and the architectural models (generally based on UML) is not simple. The fundamental reasons are the complexity of the traceability relationships, and the fact that the same modeling mechanisms (e.g., the specialization in a class diagram) serve to express the variation points in the models that represent the product line and in each specific application. The aim of this work is to use the package merge mechanism of the UML 2 infrastructure meta-model as the representation (and support for the configuration) of the variability in the product line while reserving the classical mechanisms (the specialization in the structural models, the &lt;&lt;extends&gt;&gt; relationship in the use case models, etc.) to express the variants in execution time of each specific application. The structure of the feature models is directly reflected in the relationships between packages in the architectural models, so the traceability of the configuration decisions is straightforward. The direct implementation of the package merge mechanism using the facility of partial classes of languages such as C# is an additional advantage that leads to the ideal of "seamless development".},
booktitle = {Proceedings of the 6th International Conference on Generative Programming and Component Engineering},
pages = {85–94},
numpages = {10},
keywords = {software product lines, seamless development, package merge, feature model},
location = {Salzburg, Austria},
series = {GPCE '07}
}

@inproceedings{10.1007/978-3-642-12107-4_23,
author = {Zschaler, Steffen and Kolovos, Dimitrios S. and Drivalos, Nikolaos and Paige, Richard F. and Rashid, Awais},
title = {Domain-specific metamodelling languages for software language engineering},
year = {2009},
isbn = {3642121063},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12107-4_23},
doi = {10.1007/978-3-642-12107-4_23},
abstract = {Domain-specific languages are constructed to provide modelling capabilities tailored to a specific domain. Sometimes, languages are developed many times, typically to support application in a new context. In doing so, recurring patterns and commonalities as well as variations across the evolving set of languages can be identified. This paper introduces the concept of a domain-specific metamodelling language, which codifies such commonalities and provides concepts and logic for expressing the variations. The challenges and difficulties of using domain-specific metamodelling languages are identified. We illustrate the concept with examples from different domains.},
booktitle = {Proceedings of the Second International Conference on Software Language Engineering},
pages = {334–353},
numpages = {20},
location = {Denver, CO},
series = {SLE'09}
}

@inproceedings{10.1145/1944892.1944898,
author = {Cavalcanti, Yguarat\~{a} Cerqueira and do Carmo Machado, Ivan and da Mota, Paulo Anselmo and Neto, Silveira and Lobato, Luanna Lopes and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero},
title = {Towards metamodel support for variability and traceability in software product lines},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944898},
doi = {10.1145/1944892.1944898},
abstract = {In Software Product Lines (SPL), where a greater variety of products are derived from a common platform and constantly changed and evolved, it is important to manage the SPL variability and the traceability among its artifacts. This paper presents a metamodel which aims to coordinate SPL activities, by managing different SPL phases and their responsibles, and to maintain the traceability and variability among different artifacts. The metamodel was built for a SPL project in a private company working in the medical information management domain, which includes four products encompassing 102 different modules and 840 features. The metamodel is divided into five sub-models: project and risk management, scoping, requirements and testing. It is represented in the UML notation. Organizations using this metamodel as basis for their approaches, can easily understand the relationships between the SPL assets, communicate to the stakeholders, and facilitate the evolution and maintenance of the SPL. The metamodel can also be adapted to the single system development context.},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {49–57},
numpages = {9},
keywords = {variability, software product lines, software engineering, metamodel, design},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@proceedings{10.1145/3001867,
title = {FOSD 2016: Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.1145/3136014.3136016,
author = {Zhang, Haoyuan and Li, Huang and Oliveira, Bruno C. d. S.},
title = {Type-safe modular parsing},
year = {2017},
isbn = {9781450355254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136014.3136016},
doi = {10.1145/3136014.3136016},
abstract = {Over the years a lot of effort has been put on solving extensibility problems, while retaining important software engineering properties such as modular type-safety and separate compilation. Most previous work focused on operations that traverse and process extensible Abstract Syntax Tree (AST) structures. However, there is almost no work on operations that build such extensible ASTs, including parsing. This paper investigates solutions for the problem of modular parsing. We focus on semantic modularity and not just syntactic modularity. That is, the solutions should not only allow complete parsers to be built out of modular parsing components, but also enable the parsing components to be modularly type-checked and separately compiled. We present a technique based on parser combinators that enables modular parsing. Interestingly, the modularity requirements for modular parsing rule out several existing parser combinator approaches, which rely on some non-modular techniques. We show that Packrat parsing techniques, provide solutions for such modularity problems, and enable reasonable performance in a modular setting. Extensibility is achieved using multiple inheritance and Object Algebras. To evaluate the approach we conduct a case study based on the 'Types and Programming Languages' interpreters. The case study shows the effectiveness at reusing parsing code from existing interpreters, and the total parsing code is 69% shorter than an existing code base using a non-modular parsing approach.},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {2–13},
numpages = {12},
keywords = {semantic modularity, modular parsing, Object Algebras},
location = {Vancouver, BC, Canada},
series = {SLE 2017}
}

@inproceedings{10.1145/2162049.2162052,
author = {Brabrand, Claus and Ribeiro, M\'{a}rcio and Tol\^{e}do, T\'{a}rsis and Borba, Paulo},
title = {Intraprocedural dataflow analysis for software product lines},
year = {2012},
isbn = {9781450310925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2162049.2162052},
doi = {10.1145/2162049.2162052},
abstract = {Software product lines (SPLs) are commonly developed using annotative approaches such as conditional compilation that come with an inherent risk of constructing erroneous products. For this reason, it is essential to be able to analyze SPLs. However, as dataflow analysis techniques are not able to deal with SPLs, developers must generate and analyze all valid methods individually, which is expensive for non-trivial SPLs. In this paper, we demonstrate how to take any standard intraprocedural dataflow analysis and automatically turn it into a feature-sensitive dataflow analysis in three different ways. All are capable of analyzing all valid methods of an SPL without having to generate all of them explicitly. We have implemented all analyses as extensions of SOOT's intraprocedural dataflow analysis framework and experimentally evaluated their performance and memory characteristics on four qualitatively different SPLs. The results indicate that the feature-sensitive analyses are on average 5.6 times faster than the brute force approach on our SPLs, and that they have different time and space tradeoffs.},
booktitle = {Proceedings of the 11th Annual International Conference on Aspect-Oriented Software Development},
pages = {13–24},
numpages = {12},
keywords = {software product lines, dataflow analysis},
location = {Potsdam, Germany},
series = {AOSD '12}
}

@inproceedings{10.5555/2486788.2486975,
author = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Le Traon, Yves},
title = {Towards automated testing and fixing of re-engineered feature models},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Mass customization of software products requires their efficient tailoring performed through combination of features. Such features and the constraints linking them can be represented by Feature Models (FMs), allowing formal analysis, derivation of specific variants and interactive configuration. Since they are seldom present in existing systems, techniques to re-engineer FMs have been proposed. There are nevertheless error-prone and require human intervention. This paper introduces an automated search-based process to test and fix FMs so that they adequately represent actual products. Preliminary evaluation on the Linux kernel FM exhibit erroneous FM constraints and significant reduction of the inconsistencies.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1245–1248},
numpages = {4},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/2593882.2593886,
author = {Garlan, David},
title = {Software architecture: a travelogue},
year = {2014},
isbn = {9781450328654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593882.2593886},
doi = {10.1145/2593882.2593886},
abstract = {Over the past two and a half decades software architecture has emerged as an important subfield of software engineering. During that time there has been considerable progress in developing the technological and methodological base for treating architectural design as an engineering discipline. However, much still remains to be done to achieve that. Moreover, the changing face of technology raises a number of challenges for software architecture. This travelogue recounts the history of the field, its current state of practice and research, and speculates on some of the important emerging trends, challenges, and aspirations.},
booktitle = {Future of Software Engineering Proceedings},
pages = {29–39},
numpages = {11},
keywords = {software product lines, software frame-works, architecture trends, architecture styles, architecture description languages, architecture and agility, Software architecture},
location = {Hyderabad, India},
series = {FOSE 2014}
}

@inproceedings{10.1007/978-3-642-13556-9_9,
author = {Habli, Ibrahim and Kelly, Tim},
title = {A safety case approach to assuring configurable architectures of safety-critical product lines},
year = {2010},
isbn = {3642135552},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13556-9_9},
doi = {10.1007/978-3-642-13556-9_9},
abstract = {Companies are increasingly adopting a product-line approach to the development of safety-critical systems. A product line offers large-scale reuse by exploiting common features and assets shared by systems within a specific domain. In this paper, we discuss the challenges of justifying the safety of architectural configurations and variation when developing product-line safety cases. We then address these challenges by defining an approach to developing product-line safety cases using the patterns and modular extensions of the Goal Structuring Notation (GSN). In this approach, we use the GSN patterns extension for explicitly capturing safety case variations and tracing these variations to their extrinsic source in the architectural model. Further, we use the GSN modular extension to organise the safety case into core and variable argument modules which are loosely coupled by means of argument contracts. We demonstrate this approach in a case study based on a product line of aero-engine control systems.},
booktitle = {Proceedings of the First International Conference on Architecting Critical Systems},
pages = {142–160},
numpages = {19},
keywords = {variation management, safety cases, product lines, architectures},
location = {Prague, Czech Republic},
series = {ISARCS'10}
}

@article{10.1007/s10270-020-00840-3,
author = {Akiki, Pierre A. and Maalouf, Hoda W.},
title = {CHECKSUM: tracking changes and measuring contributions in cooperative systems modeling},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00840-3},
doi = {10.1007/s10270-020-00840-3},
abstract = {Models are often used to represent various types of systems. This is especially true for software systems, where cooperating teams create models using a modeling language (e.g., UML). In cooperative modeling scenarios, it is useful to identify contributions and changes performed by individuals and teams. This paper presents a technique called CHECKSUM, which monitors the cooperative work done on models and maintains an immutable changelog. CHECKSUM uses its changelog to measure contributions based on points, time, and quality, and to enable the auditing of a model’s change-history. This paper also presents GEneric Meta-Model (GEMM). The latter unifies the underlying representation of different types of models that follow varying visualization patterns including box and line, container, and interleaving. GEMM enables CHECKSUM to support an extensible variety of model types. We developed a prototype tool that realizes CHECKSUM’s concepts and integrates it into two existing modeling tools. We conducted two studies to evaluate CHECKSUM from two perspectives: technical and user. The studies yielded positive results concerning various qualities including integrability into existing tools, effectiveness, efficiency, usability, and usefulness.},
journal = {Softw. Syst. Model.},
month = aug,
pages = {1079–1122},
numpages = {44},
keywords = {Design tools and techniques, Cooperative work, Contributions, Changes, Diagrams, Models}
}

@inproceedings{10.1145/3297280.3297512,
author = {Markiegi, Urtzi and Arrieta, Aitor and Etxeberria, Leire and Sagardui, Goiuria},
title = {Test case selection using structural coverage in software product lines for time-budget constrained scenarios},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297512},
doi = {10.1145/3297280.3297512},
abstract = {Testing product lines is a challenging activity due to the large number of products to be tested. Many approaches focus on reducing the time for testing a product line by reducing the number of products to be tested, by employing, for instance, combinatorial approaches. However, even if the number of derived products by a combinatorial approach is limited, testing can still be time consuming. In this paper, we propose three different test case selection methods that consider a given time budget to test product lines in an efficient manner using structural coverage information. We analyze the three methods with three white-box coverage criteria (i.e., Decision Coverage, Condition Coverage and Modified Condition/Decision Coverage). We evaluate the different approaches with a case study from the automotive domain and mutation testing. The results suggest that considering coverage information at the domain engineering level helps on detecting more faults, particularly when time budgets are low.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2362–2371},
numpages = {10},
keywords = {product line testing, structural coverage, test case selection},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@article{10.5555/1181901.1181950,
author = {Hunt, John M. and McGregor, John D.},
title = {Software product lines: a pedagogical application},
year = {2006},
issue_date = {December 2006},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {22},
number = {2},
issn = {1937-4771},
abstract = {This paper provides an overview of Software Product Lines and discusses issues involved in using Software Product Lines in courses. An SPL designs and produces common assets for a group of related products as a family; rather then building the products one at a time. SPL has been successful in delivering 80% to 100% reuse. SPL is moving out of an early adaptor phase and into mainstream reuse, which should increase industry demand for developers familiar with SPL. Understanding SPL is best done with a complete example. We discuss a complete set of publicly available SPL related assets that we developed, and discuss their use in the classroom.},
journal = {J. Comput. Sci. Coll.},
month = dec,
pages = {295–302},
numpages = {8}
}

@inbook{10.5555/2554488.2554491,
author = {Brabrand, Claus and Ribeiro, M\'{a}rcio and Tol\^{e}do, T\'{a}rsis and Winther, Johnni and Borba, Paulo},
title = {Intraprocedural dataflow analysis for software product lines},
year = {2013},
isbn = {9783642369636},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines (SPLs) developed using annotative approaches such as conditional compilation come with an inherent risk of constructing erroneous products. For this reason, it is essential to be able to analyze such SPLs. However, as dataflow analysis techniques are not able to deal with SPLs, developers must generate and analyze all valid products individually, which is expensive for non-trivial SPLs.In this paper, we demonstrate how to take any standard intraprocedural dataflow analysis and automatically turn it into a feature-sensitive dataflow analysis in five different ways where the last is a combination of the other four. All analyses are capable of analyzing all valid products of an SPL without having to generate all of them explicitly.We have implemented all analyses using &lt;Literal&gt;SOOT&lt;/Literal&gt;'s intraprocedural dataflow analysis framework and experimentally evaluated four of them according to their performance and memory characteristics on five qualitatively different SPLs. On our benchmarks, the combined analysis strategy is up to almost eight times faster than the brute-force approach.},
booktitle = {Transactions on Aspect-Oriented Software Development X},
pages = {73–108},
numpages = {36}
}

@inproceedings{10.1145/2047862.2047866,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Pukall, Mario and Apel, Sven},
title = {Tailoring dynamic software product lines},
year = {2011},
isbn = {9781450306898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2047862.2047866},
doi = {10.1145/2047862.2047866},
abstract = {Software product lines (SPLs) and adaptive systems aim at variability to cope with changing requirements. Variability can be described in terms of features, which are central for development and configuration of SPLs. In traditional SPLs, features are bound statically before runtime. By contrast, adaptive systems support feature binding at runtime and are sometimes called dynamic SPLs (DSPLs). DSPLs are usually built from coarse-grained components, which reduces the number of possible application scenarios. To overcome this limitation, we closely integrate static binding of traditional SPLs and runtime adaptation of DSPLs. We achieve this integration by statically generating a tailor-made DSPL from a highly customizable SPL. The generated DSPL provides only the runtime variability required by a particular application scenario and the execution environment. The DSPL supports self-configuration based on coarse-grained modules. We provide a feature-based adaptation mechanism that reduces the effort of computing an optimal configuration at runtime. In a case study, we demonstrate the practicability of our approach and show that a seamless integration of static binding and runtime adaptation reduces the complexity of the adaptation process.},
booktitle = {Proceedings of the 10th ACM International Conference on Generative Programming and Component Engineering},
pages = {3–12},
numpages = {10},
keywords = {software product lines, feature-oriented programming, dynamic binding},
location = {Portland, Oregon, USA},
series = {GPCE '11}
}

@article{10.1016/j.future.2015.03.006,
author = {Garc\'{\i}a-Gal\'{a}n, Jes\'{u}s and Trinidad, Pablo and Rana, Omer F. and Ruiz-Cort\'{e}s, Antonio},
title = {Automated configuration support for infrastructure migration to the cloud},
year = {2016},
issue_date = {February 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {55},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2015.03.006},
doi = {10.1016/j.future.2015.03.006},
abstract = {With an increasing number of cloud computing offerings in the market, migrating an existing computational infrastructure to the cloud requires comparison of different offers in order to find the most suitable configuration. Cloud providers offer many configuration options, such as location, purchasing mode, redundancy, and extra storage. Often, the information about such options is not well organised. This leads to large and unstructured configuration spaces, and turns the comparison into a tedious, error-prone search problem for the customers. In this work we focus on supporting customer decision making for selecting the most suitable cloud configuration-in terms of infrastructural requirements and cost. We achieve this by means of variability modelling and analysis techniques. Firstly, we structure the configuration space of an IaaS using feature models, usually employed for the modelling of variability-intensive systems, and present the case study of the Amazon EC2. Secondly, we assist the configuration search process. Feature models enable the use of different analysis operations that, among others, automate the search of optimal configurations. Results of our analysis show how our approach, with a negligible analysis time, outperforms commercial approaches in terms of expressiveness and accuracy. We support the decision making in migration planning to the cloud.We use Feature Models to describe the configuration space of an IaaS.We automate the search of the most suitable IaaS configuration.Our approach improves the results of commercial applications on Amazon EC2.},
journal = {Future Gener. Comput. Syst.},
month = feb,
pages = {200–212},
numpages = {13},
keywords = {IaaS, Feature model, EC2, Cloud migration, Automated analysis}
}

@article{10.1016/j.jss.2010.02.017,
author = {White, J. and Benavides, D. and Schmidt, D. C. and Trinidad, P. and Dougherty, B. and Ruiz-Cortes, A.},
title = {Automated diagnosis of feature model configurations},
year = {2010},
issue_date = {July, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {7},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2010.02.017},
doi = {10.1016/j.jss.2010.02.017},
abstract = {Software product-lines (SPLs) are software platforms that can be readily reconfigured for different project requirements. A key part of an SPL is a model that captures the rules for reconfiguring the software. SPLs commonly use feature models to capture SPL configuration rules. Each SPL configuration is represented as a selection of features from the feature model. Invalid SPL configurations can be created due to feature conflicts introduced via staged or parallel configuration or changes to the constraints in a feature model. When invalid configurations are created, a method is needed to automate the diagnosis of the errors and repair the feature selections. This paper provides two contributions to research on automated configuration of SPLs. First, it shows how configurations and feature models can be transformed into constraint satisfaction problems to automatically diagnose errors and repair invalid feature selections. Second, it presents empirical results from diagnosing configuration errors in feature models ranging in size from 100 to 5,000 features. The results of our experiments show that our CSP-based diagnostic technique can scale up to models with thousands of features.},
journal = {J. Syst. Softw.},
month = jul,
pages = {1094–1107},
numpages = {14},
keywords = {Software product-lines, Optimization, Diagnosis, Constraint satisfaction, Configuration}
}

@inproceedings{10.1145/2602928.2603080,
author = {Lytra, Ioanna and Sobernig, Stefan and Tran, Huy and Zdun, Uwe},
title = {A pattern language for service-based platform integration and adaptation},
year = {2012},
isbn = {9781450329439},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2602928.2603080},
doi = {10.1145/2602928.2603080},
abstract = {Often software systems accommodate one or more software platforms on top of which various applications are developed and executed. Different application areas, such as enterprise resource planning, mobile devices, telecommunications, and so on, require different and specialized platforms. Many of them offer their services using standardized interface technologies to support integration with the applications built on top of them and with other platforms. The diversity of platform technologies and interfaces, however, renders the integration of multiple platforms challenging. In this paper, we discuss design alternatives for tailoring heterogeneous service platforms by studying high-level and low-level architectural design decisions for integrating and for adapting platforms. We survey and organize existing patterns and design decisions in the literature as a pattern language. With this pattern language, we address the various decision categories and interconnections for the service-based integration and the adaptation of applications developed based on software platforms. We apply this pattern language in an industry case study.},
booktitle = {Proceedings of the 17th European Conference on Pattern Languages of Programs},
articleno = {4},
numpages = {27},
keywords = {service-based platform integration, pattern language, design patterns},
location = {Irsee, Germany},
series = {EuroPLoP '12}
}

@inproceedings{10.1145/2491411.2494576,
author = {De Gooijer, Thijmen and Koziolek, Heiko},
title = {Agreements for software reuse in corporations},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2494576},
doi = {10.1145/2491411.2494576},
abstract = {Agreements for sharing of software between entities in a corporation have to be tailored to fit the situation. Such agreements are not legal documents and must address different issues than traditional software licenses. We found that these agreements should cover what is granted, payment, support, ownership and liability. In a case study we learned that an agreement should list its assumptions on the structure and processes of the software organization. The presented work enables others to create guidelines for software sharing agreements tailored to their organization and shares lessons about the differences between software product lines and corporate software sharing and reuse.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {679–682},
numpages = {4},
keywords = {software licensing, corporate agreements, Software reuse},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/2483760.2492396,
author = {Th\"{u}m, Thomas},
title = {Product-line verification with feature-oriented contracts},
year = {2013},
isbn = {9781450321594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2483760.2492396},
doi = {10.1145/2483760.2492396},
abstract = {Software product lines allow programmers to reuse code across similar software products. Software products are decomposed into separate modules representing user-visible features. Based on a selection of desired features, a customized software product can be generated automatically. However, these reuse mechanisms challenge existing techniques for specification and verification of software. Specifying and verifying each product involves redundant steps, and is often infeasible. We discuss how method contracts (i.e., preconditions and postconditions) can be used to efficiently specify and verify product lines.},
booktitle = {Proceedings of the 2013 International Symposium on Software Testing and Analysis},
pages = {374–377},
numpages = {4},
keywords = {verification, feature-oriented programming, design by contract, Software product lines, Java Modeling Language},
location = {Lugano, Switzerland},
series = {ISSTA 2013}
}

@article{10.1016/j.scico.2015.04.005,
author = {Midtgaard, Jan and Dimovski, Aleksandar S. and Brabrand, Claus and W\k{a}sowski, Andrzej},
title = {Systematic derivation of correct variability-aware program analyses},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {105},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2015.04.005},
doi = {10.1016/j.scico.2015.04.005},
abstract = {A recent line of work lifts particular verification and analysis methods to Software Product Lines (SPL). In an effort to generalize such case-by-case approaches, we develop a systematic methodology for lifting single-program analyses to SPLs using abstract interpretation. Abstract interpretation is a classical framework for deriving static analyses in a compositional, step-by-step manner. We show how to take an analysis expressed as an abstract interpretation and lift each of the abstract interpretation steps to a family of programs (SPL). This includes schemes for lifting domain types, and combinators for lifting analyses and Galois connections. We prove that for analyses developed using our method, the soundness of lifting follows by construction. The resulting variational abstract interpretation is a conceptual framework for understanding, deriving, and validating static analyses for SPLs. Then we show how to derive the corresponding variational dataflow equations for an example static analysis, a constant propagation analysis. We also describe how to approximate variability by applying variability-aware abstractions to SPL analysis. Finally, we discuss how to efficiently implement our method and present some evaluation results.},
journal = {Sci. Comput. Program.},
month = jul,
pages = {145–170},
numpages = {26},
keywords = {Verification, Static analysis, Software variability, Software Product Lines, Abstract interpretation}
}

@inproceedings{10.5555/645882.672257,
author = {Thiel, Steffen and Hein, Andreas},
title = {Systematic Integration of Variability into Product Line Architecture Design},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product lines consider related products, their commonalities and their differences. The differences between the single products are also referred to as variability. Consequently, variability is inherent in every product line and makes a key difference as compared to single systems. While, on the requirements level, the methods for analyzing product line variability are understood today, their transition to architecture remains vague. Bringing variability to architecture as an "add-on" is just a provisional solution and forebodes the risk of violating other intentions. This paper presents a systematic approach to integrate variability with product line architecture design. In particular, it promotes variability as an architectural driver, embeds variability requirements in the architecture design framework "Quality-Driven Software Architecting" (QUASAR), and gives guidelines and examples for documenting variability in architectural views.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {130–153},
numpages = {24},
series = {SPLC 2}
}

@article{10.1145/3287070,
author = {Volanschi, Nic and Serpette, Bernard and Carteron, Adrien and Consel, Charles},
title = {A Language for Online State Processing of Binary Sensors, Applied to Ambient Assisted Living},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
url = {https://doi.org/10.1145/3287070},
doi = {10.1145/3287070},
abstract = {There is a large variety of binary sensors in use today, and useful context-aware services can be defined using such binary sensors. However, the currently available approaches for programming context-aware services do not conveniently support binary sensors. Indeed, no existing approach simultaneously supports a notion of state, central to binary sensors, offers a complete set of operators to compose states, allows to define reusable abstractions by means of such compositions, and implements efficient online processing of these operators.This paper proposes a new language for event processing specifically targeted to binary sensors. The central contributions of this language are a native notion of state and semi-causal operators for temporal state composition including: Allen's interval relations generalized for handling multiple intervals, and temporal filters for handling delays. Compared to other approaches such as CEP (complex event processing), our language provides less discontinued information, allows less restricted compositions, and supports reusable abstractions. We implemented an interpreter for our language and applied it to successfully rewrite a full set of real Ambient Assisted Living services. The performance of our prototype interpreter is shown to compete well with a commercial CEP engine when expressing the same services.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = dec,
articleno = {192},
numpages = {26},
keywords = {Smart homes, Binary sensors, Ambient assisted living, Allen interval algebra}
}

@inproceedings{10.1007/978-3-642-33666-9_32,
author = {Behjati, Razieh and Yue, Tao and Briand, Lionel},
title = {A modeling approach to support the similarity-based reuse of configuration data},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_32},
doi = {10.1007/978-3-642-33666-9_32},
abstract = {Product configuration in families of Integrated Control Systems (ICSs) involves resolving thousands of configurable parameters and is, therefore, time-consuming and error-prone. Typically, these systems consist of highly similar components that need to be configured similarly. For large-scale systems, a considerable portion of the configuration data can be reused, based on such similarities, during the configuration of each individual product. In this paper, we propose a model-based approach to automate the reuse of configuration data based on the similarities within an ICS product. Our approach enables configuration engineers to manipulate the reuse of configuration data, and ensures the consistency of the reused data. Evaluation of the approach, using a number of configured products from an industry partner, shows that more than 60% of configuration data can be automatically reused using our similarity-based approach, thereby reducing configuration effort.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {497–513},
numpages = {17},
keywords = {product configuration, model-based software engineering, internal similarities, feature modeling, UML/OCL},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1109/ASE.2013.6693104,
author = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
title = {Scalable product line configuration: a straw to break the camel's back},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693104},
doi = {10.1109/ASE.2013.6693104},
abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a "seed" in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {465–474},
numpages = {10},
keywords = {variability models, multiobjective optimization, evolutionary algorithms, automated configuration, SMT solvers},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1145/2642937.2642960,
author = {Hamidi, Saeideh and Andritsos, Periklis and Liaskos, Sotirios},
title = {Constructing adaptive configuration dialogs using crowd data},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2642960},
doi = {10.1145/2642937.2642960},
abstract = {As modern software systems grow in size and complexity so do their configuration possibilities. Users are easy to be confused and overwhelmed by the amount of choices they need to make in order to fit their systems to their exact needs. We propose a method to construct adaptive configuration elicitation dialogs through utilizing crowd wisdom. A set of configuration preferences in the form of association rules is first mined from a crowd configuration data set. Possible configuration elicitation dialogs are then modeled through a Markov Decision Process (MDP). Association rules are used to inform the model about configuration decisions that can be automatically inferred from knowledge already elicited earlier in the dialog. This way, an MDP solver can search for elicitation strategies which maximize the expected amount of automated decisions, reducing thereby elicitation effort and increasing user confidence of the result. The method is applied to the privacy configuration of Facebook.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {485–490},
numpages = {6},
keywords = {software customization, markov decision processes, facebook, crowdsourcing, association rules mining},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@article{10.1145/1163514.1178645,
author = {Sinnema, Marco and van der Ven, Jan Salvador and Deelstra, Sybren},
title = {Using variability modeling principles to capture architectural knowledge},
year = {2006},
issue_date = {September 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1163514.1178645},
doi = {10.1145/1163514.1178645},
abstract = {In the field of software architectures, there is an emerging awareness of the importance of architectural decisions. In this view, the architecting process is explained as a decision process, while the design and eventually the software system are seen as the result of this decision process. However, the effects of different alternatives on the quality of the system often remain implicit. In the field of software product families, the same issues arise when configuring products. We propose to use the proven expertise from COVAMOF, a framework for managing variability, to solve the issues that arise when relating quality attributes to architectural decisions.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {5–es},
numpages = {6},
keywords = {quality attributes, architectural knowledge, architectural decisions}
}

@article{10.1145/3015777,
author = {Tigori, Kabland Toussaint Gautier and B\'{e}chennec, Jean-Luc and Faucou, S\'{e}bastien and Roux, Olivier Henri},
title = {Formal Model-Based Synthesis of Application-Specific Static RTOS},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1539-9087},
url = {https://doi.org/10.1145/3015777},
doi = {10.1145/3015777},
abstract = {In an embedded system, the specialization of the code of the real-time operating system (RTOS) according to the requirements of the application allows one to remove unused services and other sources of dead code from the binary program. The typical specialization process is based on a mix of precompiler macros and build scripts, both of which are known for being sources of errors.In this article, we present a new model-based approach to the design of application-specific RTOS. Starting with finite state models describing the RTOS and the application requirements, the set of blocks in the RTOS code actually used by the application is automatically computed. This set is used to build an application-specific RTOS model. This model is fed into a code generator to produce the source code of an application-specific RTOS. It is also used to carry on model-based validations and verifications, including the formal verification that the specialization process did not introduce unwanted behaviors or suppress expected ones.To demonstrate the feasibility of this approach, it is applied to specialize Trampoline, an open-source implementation of the AUTOSAR OS standard, to an industrial case study from the automotive domain.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = may,
articleno = {97},
numpages = {25},
keywords = {model-based verification and verification, formal synthesis, application-specific RTOS, OSEK/VDX and AUTOSAR RTOS, Formal methods}
}

@article{10.1016/j.jss.2012.09.016,
author = {Lucena, Carlos and Nunes, Ingrid},
title = {Contributions to the emergence and consolidation of Agent-oriented Software Engineering},
year = {2013},
issue_date = {April, 2013},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {86},
number = {4},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2012.09.016},
doi = {10.1016/j.jss.2012.09.016},
abstract = {Many of the issues addressed with multi-agent approaches, such as distributed coordination and self-organization, are now becoming part of industrial and business systems. However, Multiagent Systems (MASs) are still not widely adopted in industry owing to the lack of a connection between MAS and software engineering. Since 2000, there is an effort to bridge this gap and to produce software engineering techniques for agent-based systems that guide the processes of design, development and maintenance. In Brazil, Agent-oriented Software Engineering (AOSE) was first investigated by the research group in the Software Engineering Laboratory (LES) at PUC-Rio, which after one decade of study in this area has built an AOSE community. This paper presents the history of AOSE at LES by discussing the sub-areas of MAS Software Engineering research and development that have been focus of the LES research group. We give examples of relevant results and present a subset of the extensive literature the group has produced during the last decade. We also report how we faced the challenges that emerged from our research by organizing and developing a research community at the intersection of software engineering, programming and MASs with a concern for scalability of solutions.},
journal = {J. Syst. Softw.},
month = apr,
pages = {890–904},
numpages = {15},
keywords = {SBES 25 years, PUC-Rio, Multiagent systems, LES, Agent-oriented Software Engineering}
}

@inproceedings{10.1007/978-3-642-12261-3_8,
author = {Botterweck, Goetz and Polzer, Andreas and Kowalewski, Stefan},
title = {Using higher-order transformations to derive variability mechanism for embedded systems},
year = {2009},
isbn = {3642122604},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12261-3_8},
doi = {10.1007/978-3-642-12261-3_8},
abstract = {The complexity of embedded systems can partly be handled by models and domain-specific languages (DSLs) like Matlab/Simulink. If we want to apply such techniques to families of similar systems, we have to describe their variability, i.e., commonalities and differences between the similar systems. Here, approaches from Software Product Lines (SPL) and variability modeling can be helpful. In this paper, we discuss three challenges which arise in this context: (1) We have to integrate mechanisms for describing variability into the DSL. (2) To efficiently derive products, we require techniques and tool-support that allow us to configure a particular product and resolve variability in the DSL. (3) When resolving variability, we have to take into account dependencies between elements, e.g., when removing Simulink blocks we have to remove the signals between these blocks as well. The approach presented here uses higher-order transformations (HOT), which derive the variability mechanisms (as a generated model transformation) from the meta-model of a DSL.},
booktitle = {Proceedings of the 2009 International Conference on Models in Software Engineering},
pages = {68–82},
numpages = {15},
location = {Denver, CO},
series = {MODELS'09}
}

@inproceedings{10.1145/2600821.2600826,
author = {Lettner, Daniela and Angerer, Florian and Pr\"{a}hofer, Herbert and Gr\"{u}nbacher, Paul},
title = {A case study on software ecosystem characteristics in industrial automation software},
year = {2014},
isbn = {9781450327541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600821.2600826},
doi = {10.1145/2600821.2600826},
abstract = {In software ecosystems (SECOs) both internal and external developers build software solutions for specific market segments based on common technological platforms. Despite a significant body of research on SECOs there is still a need to empirically investigate the characteristics of SECOs in specific industrial environments to understand and improve development processes. In particular, when defining software processes understanding the roles of the participants in the SECO is crucial. This paper thus reports results of an exploratory case study in the industrial automation domain. We explore two research questions on SECO characteristics and discuss research issues we derived from our analyses. While our study confirms key SECO characteristics reported in the literature we also identify additional properties relevant for development processes in the domain of industrial automation.},
booktitle = {Proceedings of the 2014 International Conference on Software and System Process},
pages = {40–49},
numpages = {10},
keywords = {Software ecosystems, case study, development processes, industrial automation},
location = {Nanjing, China},
series = {ICSSP '14}
}

@inproceedings{10.1145/2377816.2377825,
author = {Passos, Leonardo and Czarnecki, Krzysztof and W\k{a}sowski, Andrzej},
title = {Towards a catalog of variability evolution patterns: the Linux kernel case},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377825},
doi = {10.1145/2377816.2377825},
abstract = {A complete understanding of evolution of variability requires analysis over all project spaces that contain it: source code, build system and the variability model. Aiming at better understanding of how complex variant-rich software evolve, we set to study one, the Linux kernel, in detail. We qualitatively analyze a number of evolution steps in the kernel history and present our findings as a preliminary sample of a catalog of evolution patterns. Our patterns focus on how the variability evolves when features are removed from the variability model, but are kept as part of the software. The identified patterns relate changes to the variability model, the build system, and implementation code. Despite preliminary, they already indicate evolution steps that have not been captured by prior studies, both empirical and theoretical.},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {62–69},
numpages = {8},
keywords = {variability, software product lines, patterns, evolution, Linux},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1145/3148173.3148189,
author = {Bercea, Gheorghe-Teodor and Bertolli, Carlo and Jacob, Arpith C. and Eichenberger, Alexandre and Bataev, Alexey and Rokos, Georgios and Sung, Hyojin and Chen, Tong and O'Brien, Kevin},
title = {Implementing implicit OpenMP data sharing on GPUs},
year = {2017},
isbn = {9781450355650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148173.3148189},
doi = {10.1145/3148173.3148189},
abstract = {OpenMP is a shared memory programming model which supports the offloading of target regions to accelerators such as NVIDIA GPUs. The implementation in Clang/LLVM aims to deliver a generic GPU compilation toolchain that supports both the native CUDA C/C++ and the OpenMP device offloading models. There are situations where the semantics of OpenMP and those of CUDA diverge. One such example is the policy for implicitly handling local variables. In CUDA, local variables are implicitly mapped to thread local memory and thus become private to a CUDA thread. In OpenMP, due to semantics that allow the nesting of regions executed by different numbers of threads, variables need to be implicitly shared among the threads of a contention group.In this paper we introduce a re-design of the OpenMP device data sharing infrastructure that is responsible for the implicit sharing of local variables in the Clang/LLVM toolchain. We introduce a new data sharing infrastructure that lowers implicitly shared variables to the shared memory of the GPU.We measure the amount of shared memory used by our scheme in cases that involve scalar variables and statically allocated arrays. The evaluation is carried out by offloading to K40 and P100 NVIDIA GPUs. For scalar variables the pressure on shared memory is relatively low, under 26% of shared memory utilization for the K40, and does not negatively impact occupancy. The limiting occupancy factor in that case is register pressure. The data sharing scheme offers the users a simple memory model for controlling the implicit allocation of device shared memory.},
booktitle = {Proceedings of the Fourth Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {5},
numpages = {12},
keywords = {shared memory, data sharing, OpenMP, Clang},
location = {Denver, CO, USA},
series = {LLVM-HPC'17}
}

@article{10.1016/j.infsof.2009.04.001,
author = {Nicol\'{a}s, Joaqu\'{\i}n and Toval, Ambrosio},
title = {On the generation of requirements specifications from software engineering models: A systematic literature review},
year = {2009},
issue_date = {September, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {9},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.04.001},
doi = {10.1016/j.infsof.2009.04.001},
abstract = {System and software requirements documents play a crucial role in software engineering in that they must both communicate requirements to clients in an understandable manner and define requirements in precise detail for system developers. The benefits of both lists of textual requirements (usually written in natural language) and software engineering models (usually specified in graphical form) can be brought together by combining the two approaches in the specification of system and software requirements documents. If, moreover, textual requirements are generated from models in an automatic or closely monitored form, the effort of specifying those requirements is reduced and the completeness of the specification and the management of the requirements traceability are improved. This paper presents a systematic review of the literature related to the generation of textual requirements specifications from software engineering models.},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {1291–1307},
numpages = {17},
keywords = {Textual requirements generation from software engineering model, Systematic literature review, Specification generation from software engineering model, Requirements document generation from software engineering model}
}

@inproceedings{10.1145/1985484.1985496,
author = {Rosa, Ricardo Erikson V.S. and Lucena, Vicente F.},
title = {Smart composition of reusable software components in mobile application product lines},
year = {2011},
isbn = {9781450305846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985484.1985496},
doi = {10.1145/1985484.1985496},
abstract = {Mobile application development opens up several challenges to developers. Among these challenges, possibly the most important one is the porting of applications to the heterogeneous devices available on the market. This requires mobile developers to create and maintain several versions of their applications in order to deal with particular features of each platform, including display size, development libraries, sensors, keypad layout, etc. The Software Product Lines (SPL) approach seems to be an useful technique to support mobile application development. A way to make SPL more effective is automating the software components composition for building mobile applications. We present a software infrastructure called AppSpotter that enables the dynamic and automated composition of software components of mobile applications taking into account the particular features of each mobile device. By means of the devices features, AppSpotter determines the components selection and composition of them to build customized mobile applications.},
booktitle = {Proceedings of the 2nd International Workshop on Product Line Approaches in Software Engineering},
pages = {45–49},
numpages = {5},
keywords = {reusable components, mobile applications, dynamic and automated composition},
location = {Waikiki, Honolulu, HI, USA},
series = {PLEASE '11}
}

@article{10.1016/j.infsof.2017.10.012,
author = {Budgen, David and Brereton, Pearl and Williams, Nikki and Drummond, Sarah},
title = {The contribution that empirical studies performed in industry make to the findings of systematic reviews},
year = {2018},
issue_date = {February 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {94},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.10.012},
doi = {10.1016/j.infsof.2017.10.012},
abstract = {ContextSystematic reviews can provide useful knowledge for software engineering practice, by aggregating and synthesising empirical studies related to a specific topic. ObjectiveWe sought to assess how far the findings of systematic reviews addressing practice-oriented topics have been derived from empirical studies that were performed in industry or that used industry data. MethodWe drew upon and augmented the data obtained from a tertiary study that performed a systematic review of systematic reviews published in the period up to the end of 2015, seeking to identify those with findings that are relevant for teaching and practice. For the supplementary analysis reported here, we then examined the profiles of the primary studies as reported in each systematic review. ResultsWe identified 48 systematic reviews as candidates for further analysis. The many differences that arise between systematic reviews, together with the incompleteness of reporting for these, mean that our counts should be treated as indicative rather than definitive. However, even when allowing for problems of classification, the findings from the majority of these systematic reviews were predominantly derived from using primary studies conducted in industry. There was also an emphasis upon the use of case studies, and a number of the systematic reviews also made some use of weaker experience or even opinion papers. ConclusionsPrimary studies from industry play an important role as inputs to systematic reviews. Using more rigorous industry-based primary studies can give greater authority to the findings of the systematic reviews, and should help with the creation of a corpus of sound empirical data to support evidence-informed decisions.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {234–244},
numpages = {11},
keywords = {Systematic review, Primary study, Industry study, Case study}
}

@inproceedings{10.1145/2897045.2897051,
author = {Perrouin, Gilles and Acher, Mathieu and Davril, Jean-Marc and Legay, Axel and Heymans, Patrick},
title = {A complexity tale: web configurators},
year = {2016},
isbn = {9781450341769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897045.2897051},
doi = {10.1145/2897045.2897051},
abstract = {Online configurators are basically everywhere. From physical goods (cars, clothes) to services (cloud solutions, insurances, etc.) such configurators have pervaded many areas of everyday life, in order to provide the customers products tailored to their needs. Being sometimes the only interfaces between product suppliers and consumers, much care has been devoted to the HCI aspects of configurators, aiming at offering an enjoyable buying experience. However, at the backend, the management of numerous and complex configuration options results from ad-hoc process rather than a systematic variability-aware engineering approach. We present our experience in analysing web configurators and formalising configuration options in terms of feature models or product configuration matrices. We also consider behavioural issues and perspectives on their architectural design.},
booktitle = {Proceedings of the 1st International Workshop on Variability and Complexity in Software Design},
pages = {28–31},
numpages = {4},
keywords = {web configurator, variability, complexity},
location = {Austin, Texas},
series = {VACE '16}
}

@article{10.1145/3464939,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat},
title = {Recommending Faulty Configurations for Interacting Systems Under Test Using Multi-objective Search},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3464939},
doi = {10.1145/3464939},
abstract = {Modern systems, such as cyber-physical systems, often consist of multiple products within/across product lines communicating with each other through information networks. Consequently, their runtime behaviors are influenced by product configurations and networks. Such systems play a vital role in our daily life; thus, ensuring their correctness by thorough testing becomes essential. However, testing these systems is particularly challenging due to a large number of possible configurations and limited available resources. Therefore, it is important and practically useful to test these systems with specific configurations under which products will most likely fail to communicate with each other. Motivated by this, we present a search-based configuration recommendation (SBCR) approach to recommend faulty configurations for the system under test (SUT) based on cross-product line (CPL) rules. CPL rules are soft constraints, constraining product configurations while indicating the most probable system states with a certain degree of confidence. In SBCR, we defined four search objectives based on CPL rules and combined them with six commonly applied search algorithms. To evaluate SBCR (i.e., SBCRNSGA-II, SBCRIBEA, SBCRMoCell, SBCRSPEA2, SBCRPAES, and SBCRSMPSO), we performed two case studies (Cisco and Jitsi) and conducted difference analyses. Results show that for both of the case studies, SBCR significantly outperformed random search-based configuration recommendation (RBCR) for 86% of the total comparisons based on six quality indicators, and 100% of the total comparisons based on the percentage of faulty configurations (PFC). Among the six variants of SBCR, SBCRSPEA2 outperformed the others in 85% of the total comparisons based on six quality indicators and 100% of the total comparisons based on PFC.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {53},
numpages = {36},
keywords = {testing, multi-objective search, mined rules, interacting products, configuration recommendation, Product line}
}

@article{10.1145/2629395,
author = {Jain, Radhika and Cao, Lan and Mohan, Kannan and Ramesh, Balasubramaniam},
title = {Situated Boundary Spanning: An Empirical Investigation of Requirements Engineering Practices in Product Family Development},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {2158-656X},
url = {https://doi.org/10.1145/2629395},
doi = {10.1145/2629395},
abstract = {Requirements Engineering (RE) faces considerable challenges that are often related to boundaries between various stakeholders involved in the software development process. These challenges may be addressed by boundary spanning practices. We examine how boundary spanning can be adapted to address RE challenges in Product Family Development (PFD), a context that involves complex RE. We study two different development approaches, namely, conventional and agile PFD, because these present considerably different challenges. Our findings from a multisite case study present boundary spanning as a solution to improve the quality of RE processes and highlight interesting differences in how boundary spanner roles and boundary objects are adapted in conventional and agile PFD.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = dec,
articleno = {16},
numpages = {29},
keywords = {requirements engineering, product family development, agile development, Boundary spanning}
}

@inproceedings{10.1145/1985793.1985856,
author = {She, Steven and Lotufo, Rafael and Berger, Thorsten and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof},
title = {Reverse engineering feature models},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985856},
doi = {10.1145/1985793.1985856},
abstract = {Feature models describe the common and variable characteristics of a product line. Their advantages are well recognized in product line methods. Unfortunately, creating a feature model for an existing project is time-consuming and requires substantial effort from a modeler.We present procedures for reverse engineering feature models based on a crucial heuristic for identifying parents - the major challenge of this task. We also automatically recover constructs such as feature groups, mandatory features, and implies/excludes edges. We evaluate the technique on two large-scale software product lines with existing reference feature models--the Linux and eCos kernels--and FreeBSD, a project without a feature model. Our heuristic is effective across all three projects by ranking the correct parent among the top results for a vast majority of features. The procedures effectively reduce the information a modeler has to consider from thousands of choices to typically five or less.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {461–470},
numpages = {10},
keywords = {variability modeling, feature similarity, feature models},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.5555/2666064.2666072,
author = {Boucher, Quentin and Abbasi, Ebrahim Khalil and Hubaux, Arnaud and Perrouin, Gilles and Acher, Mathieu and Heymans, Patrick},
title = {Towards more reliable configurators: a re-engineering perspective},
year = {2012},
isbn = {9781467317511},
publisher = {IEEE Press},
abstract = {Delivering configurable solutions, that is products tailored to the requirements of a particular customer, is a priority of most B2B and B2C markets. These markets now heavily rely on interactive configurators that help customers build complete and correct products. Reliability is thus a critical requirement for configurators. Yet, our experience in industry reveals that many configurators are developed in an ad hoc manner, raising correctness and maintenance issues. In this paper, we present a vision to re-engineering more reliable configurators and the challenges it poses. The first challenge is to reverse engineer from an existing configurator the variability information, including complex rules, and to consolidate it in a variability model, namely a feature model. The second challenge is to forward engineer a new configurator that uses the feature model to generate a customized graphical user interface and the underlying reasoning engine.},
booktitle = {Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering},
pages = {29–32},
numpages = {4},
keywords = {re-engineering, graphical user interface, configuration},
location = {Zurich, Switzerland},
series = {PLEASE '12}
}

@inproceedings{10.1145/1982185.1982473,
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
title = {A domain-specific language for managing feature models},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982473},
doi = {10.1145/1982185.1982473},
abstract = {Feature models are a popular formalism for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. To manage complexity, there is a need to separate, relate and compose several feature models while automating the reasoning on their compositions in order to enable rigorous SPL validation and configuration. In this paper, we propose a Domain-Specific Language (DSL) that is dedicated to the management of feature models and that complements existing tool support. Rationale for this language is discussed and its main constructs are presented through examples. We show how the DSL can be used to realize a non trivial scenario in which multiple SPLs are managed.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {1333–1340},
numpages = {8},
keywords = {product lines, domain-specific language, Feature models},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@article{10.1016/j.sysarc.2015.07.010,
author = {Meier, Matthias and Breddemann, Mark and Spinczyk, Olaf},
title = {Interfacing the hardware API with a feature-based operating system family},
year = {2015},
issue_date = {November 2015},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {61},
number = {10},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2015.07.010},
doi = {10.1016/j.sysarc.2015.07.010},
abstract = {Multiprocessor systems on a chip (MPSoCs) are a popular class of course-grained parallel computer architectures, which are very useful, because they support re-use of legacy software components and application-specific tailoring of hardware structures at the same time. Furthermore, model-driven design frameworks for MPSoCs such as Xilinx' EDK or our own LavA-framework facilitate very fast system development. However, in this paper we argue that these design frameworks are not ideal from the development process perspective. Instead, we propose a software-centric approach that is based on the hardware API concept. The API is a representation of hardware components on the software level, which is generated from a hardware meta-model. It allows us to automatically derive a hardware structure based on access patterns in software, revealed by a static code analysis. This trick reduces the number of hardware details the developer needs to deal with and avoids configuration inconsistencies between the hardware and software levels by design. Furthermore, we present how the development process can benefit from the hardware API, when the API is interfaced with a configurable operating system.},
journal = {J. Syst. Archit.},
month = nov,
pages = {531–538},
numpages = {8},
keywords = {Software-centric configuration, Operating system, MPSoC, Hardware representation, HW/SW co-design, FPGA}
}

@article{10.1016/j.jss.2012.10.270,
author = {Peng, Xin and Xing, Zhenchang and Tan, Xi and Yu, Yijun and Zhao, Wenyun},
title = {Improving feature location using structural similarity and iterative graph mapping},
year = {2013},
issue_date = {March, 2013},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {86},
number = {3},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2012.10.270},
doi = {10.1016/j.jss.2012.10.270},
abstract = {Locating program element(s) relevant to a particular feature is an important step in efficient maintenance of a software system. The existing feature location techniques analyse each feature independently and perform a one-time analysis after being provided an initial input. As a result, these techniques are sensitive to the quality of the input. In this paper, we propose to address the above issues in feature location using an iterative context-aware approach. The underlying intuition is that features are not independent of each other, and the structure of source code resembles the structure of features. The distinguishing characteristics of the proposed approach are: (1) it takes into account the structural similarity between a feature and a program element to determine feature-element relevance and (2) it employs an iterative process to propagate the relevance of the established mappings between a feature and a program element to the neighbouring features and program elements. We evaluate our approach using two different systems, DirectBank, a small-scale industry financial system, and Linux kernel, a large-scale open-source operating system. Our evaluation suggests that the proposed approach is more robust and can significantly increase the recall of feature location with only a minor decrease of precision.},
journal = {J. Syst. Softw.},
month = mar,
pages = {664–676},
numpages = {13},
keywords = {Traceability recovery, Structural similarity, Information retrieval, Feature location}
}

@inproceedings{10.5555/3242181.3242197,
author = {Nance, Richard E. and Overstreet, C. Michael},
title = {History of computer simulation software: an initial perspective},
year = {2017},
isbn = {9781538634271},
publisher = {IEEE Press},
abstract = {The evolution of computer simulation software until the mid-1980's is subsumed by descriptions of the history of simulation programming languages. Since that time, the entire complexion of simulation model design, development, execution, and sustainment has undergone a radical transition. The transition to a large degree stems from technology advances in hardware and software coupled with the increasing expectations of simulation modelers and end users. This study, covering the evolution in its entirety, represents an initial perspective on the transition based on an examination and analysis of the Winter Simulation Conference Archive and a partial set of simulation software surveys published in OR/MS Today. The results characterize the modeling and simulation software evolution since the mid-1980's in terms of newcomers, endurers, fads, fades, trends, and trajectories. Prominent among the conclusions are that commercial firms are driving the major advances and the marketplace is quite volatile.},
booktitle = {Proceedings of the 2017 Winter Simulation Conference},
articleno = {15},
numpages = {19},
location = {Las Vegas, Nevada},
series = {WSC '17}
}

@article{10.1016/j.jnca.2020.102534,
author = {Wang, Ye and Li, Qingbao and Chen, Zhifeng and Zhang, Ping and Zhang, Guimin},
title = {A Survey of Exploitation Techniques and Defenses for Program Data Attacks},
year = {2020},
issue_date = {Mar 2020},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {154},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2020.102534},
doi = {10.1016/j.jnca.2020.102534},
journal = {J. Netw. Comput. Appl.},
month = mar,
numpages = {16},
keywords = {PDA, Gadget, ROP, DOP, Data plane, Control plane}
}

@inproceedings{10.1145/3384544.3384585,
author = {Ferguson, Danielle and Albright, Yan and Lomsak, Daniel and Hanks, Tyler and Orr, Kevin and Ligatti, Jay},
title = {PoCo: A Language for Specifying Obligation-Based Policy Compositions},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384544.3384585},
doi = {10.1145/3384544.3384585},
abstract = {Existing security-policy-specification languages allow users to specify obligations, but challenges remain in the composition of complex obligations, including effective approaches for resolving conflicts between policies and obligations and allowing policies to react to other obligations. This paper presents PoCo, a policy-specification language and enforcement system for the principled composition of atomic-obligation policies. PoCo enables policies to interact meaningfully with other policies' obligations, thus preventing unexpected and insecure behaviors that can arise from partially executed obligations or obligations that execute actions in violation of other policies.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {331–338},
numpages = {8},
keywords = {policy specification, policy composition, obligations, Information security},
location = {Langkawi, Malaysia},
series = {ICSCA '20}
}

@inproceedings{10.1145/2462326.2462332,
author = {Quinton, Cl\'{e}ment and Haderer, Nicolas and Rouvoy, Romain and Duchien, Laurence},
title = {Towards multi-cloud configurations using feature models and ontologies},
year = {2013},
isbn = {9781450320504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462326.2462332},
doi = {10.1145/2462326.2462332},
abstract = {Configuration and customization choices arise due to the heterogeneous and scalable aspect of the cloud computing paradigm. To avoid being restricted to a given cloud and ensure application requirements, using several clouds to deploy a multi-cloud configuration is recommended but introduces several challenges due to the amount of providers and their intrinsic variability. In this paper, we present a model-driven approach based on Feature Models (FMs) originating from Software Product Lines (SPL) to handle cloud variability and then manage and create cloud configurations. We combine it with ontologies, used to model the various semantics of cloud systems. The approach takes into consideration application technical requirements as well as non-functional ones to provide a set of valid cloud or multi-cloud configurations and is implemented in a framework named SALOON.},
booktitle = {Proceedings of the 2013 International Workshop on Multi-Cloud Applications and Federated Clouds},
pages = {21–26},
numpages = {6},
keywords = {variability, ontology, multi-cloud, feature model, cloud computing},
location = {Prague, Czech Republic},
series = {MultiCloud '13}
}

@inproceedings{10.1145/1353482.1353492,
author = {Cacho, Nelio and Filho, Fernando Castor and Garcia, Alessandro and Figueiredo, Eduardo},
title = {EJFlow: taming exceptional control flows in aspect-oriented programming},
year = {2008},
isbn = {9781605580449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1353482.1353492},
doi = {10.1145/1353482.1353492},
abstract = {Many of the problems that stem from the use of exception handling are caused by the local way in which exceptions are handled. It demands that developers understand the source of an exception, the place where it is handled, and everything in between. As a consequence, exceptions easily get "out of control" and, as system development progresses, exceptional control flows become less well-understood, with potentially negative consequences for the program maintainability and reliability. This paper presents an innovative aspect-oriented model for exception handling implementation. In contrast to other exception handling mechanisms, our model provides abstractions to explicitly describe global views of exceptional control flows. As a result, this new model makes it possible to understand exception flows from an end-to-end perspective by looking at a single part of the program. Also, it leverages existing pointcut languages to make the association of handlers with normal code more flexible. The implementation of our proposed model, called EJFlow, extends the AspectJ programming language with the aim of promoting enhanced robustness and program modularization. We evaluate qualitatively and quantitatively the proposed exception handling model through a case study targeting a real mobile application.},
booktitle = {Proceedings of the 7th International Conference on Aspect-Oriented Software Development},
pages = {72–83},
numpages = {12},
keywords = {modularity, metrics, exception handling, exception control flow, aspect-oriented programming},
location = {Brussels, Belgium},
series = {AOSD '08}
}

@article{10.1007/s10270-015-0505-x,
author = {Abdelzad, Vahdat and Lethbridge, Timothy C.},
title = {Promoting traits into model-driven development},
year = {2017},
issue_date = {October   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0505-x},
doi = {10.1007/s10270-015-0505-x},
abstract = {Traits, as sets of behaviors, can provide a good mechanism for reusability. However, they are limited in important ways and are not present in widely used programming and modeling languages and hence are not readily available for use by mainstream developers. In this paper, we add UML associations and other modeling concepts to traits and apply them to Java and C++ through model-driven development. We also extend traits with required interfaces so dependencies at the semantics level become part of their usage, rather than simple syntactic capture. All this is accomplished in Umple, a textual modeling language based upon UML that allows adding programming constructs to the model. We applied the work to two case studies. The results show that we can promote traits to the modeling level along with the improvement in flexibility and reusability.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {997–1017},
numpages = {21},
keywords = {Umple, UML, Traits, Reusability, Modeling}
}

@article{10.5555/2873826.2874006,
author = {Hervieu, Aymeric and Marijan, Dusica and Gotlieb, Arnaud and Baudry, Benoit},
title = {Practical minimization of pairwise-covering test configurations using constraint programming},
year = {2016},
issue_date = {March 2016},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {71},
number = {C},
issn = {0950-5849},
abstract = {Context: Testing highly-configurable software systems is challenging due to a large number of test configurations that have to be carefully selected in order to reduce the testing effort as much as possible, while maintaining high software quality. Finding the smallest set of valid test configurations that ensure sufficient coverage of the system's feature interactions is thus the objective of validation engineers, especially when the execution of test configurations is costly or time-consuming. However, this problem is NP-hard in general and approximation algorithms have often been used to address it in practice.Objective: In this paper, we explore an alternative exact approach based on constraint programming that will allow engineers to increase the effectiveness of configuration testing while keeping the number of configurations as low as possible.Method: Our approach consists in using a (time-aware) minimization algorithm based on constraint programming. Given the amount of time, our solution generates a minimized set of valid test configurations that ensure coverage of all pairs of feature values (a.k.a. pairwise coverage). The approach has been implemented in a tool called PACOGEN.Results: PACOGEN was evaluated on 224 feature models in comparison with the two existing tools that are based on a greedy algorithm. For 79% of 224 feature models, PACOGEN generated up to 60% fewer test configurations than the competitor tools. We further evaluated PACOGEN in the case study of an industrial video conferencing product line with a feature model of 169 features, and found 60% fewer configurations compared with the manual approach followed by test engineers. The set of test configurations generated by PACOGEN decreased the time required by test engineers in manual test configuration by 85%, increasing the feature-pairs coverage at the same time.Conclusion: Our experimental evaluation concluded that optimal time-aware minimization of pairwise-covering test configurations is efficiently addressed using constraint programming techniques.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {129–146},
numpages = {18},
keywords = {Variability testing, Highly-configurable software systems, Constraint programming}
}

@article{10.1016/j.infsof.2006.11.003,
author = {Niemel\"{a}, Eila and Immonen, Anne},
title = {Capturing quality requirements of product family architecture},
year = {2007},
issue_date = {November, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {11–12},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.11.003},
doi = {10.1016/j.infsof.2006.11.003},
abstract = {Software quality is one of the major issues with software intensive systems. Moreover, quality is a critical success factor in software product families exploiting shared architecture and common components in a set of products. Our contribution is the QRF (Quality Requirements of a software Family) method, which explicitly focuses on how quality requirements have to be defined, represented and transformed to architectural models. The method has been applied to two experiments; one in a laboratory environment and the other in industry. The use of the QRF method is exemplified by the Distribution Service Platform (DiSeP), the laboratory experiment. The lessons learned are also based on our experiences of applying the method in industrial settings.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1107–1120},
numpages = {14},
keywords = {Traceability, Software product family, Software architecture, Quality requirement}
}

@inproceedings{10.1007/978-3-319-35122-3_8,
author = {Peng, Zhenlian and Wang, Jian and He, Keqing and Li, Hongtao},
title = {An Approach for Prioritizing Software Features Based on Node Centrality in Probability Network},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_8},
doi = {10.1007/978-3-319-35122-3_8},
abstract = {Due to the increasing complexity of software products as well as the restriction of the development budget and time, requirements prioritization, i.e., selecting more crucial requirements to be designed and developed firstly, has become increasingly important in the software development lifetime. Considering the fact that a feature in a feature model can be viewed as a set of closely related requirements, feature prioritization will contribute to requirements prioritization to a large extent. Therefore, how to measure the priority of features within a feature model becomes an important issue in requirements analysis. In this paper, a software feature prioritization approach is proposed, which utilizes the dependencies between features to build a feature probability network and measures feature prioritization through the nodes centrality in the network. Experiments conducted on real world feature models show that the proposed approach can accurately prioritize features in feature models.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {106–121},
numpages = {16},
keywords = {Feature probability network, Feature prioritization, Feature model, Centrality},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1007/978-3-642-31491-9_18,
author = {Behjati, Razieh and Nejati, Shiva and Yue, Tao and Gotlieb, Arnaud and Briand, Lionel},
title = {Model-based automated and guided configuration of embedded software systems},
year = {2012},
isbn = {9783642314902},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31491-9_18},
doi = {10.1007/978-3-642-31491-9_18},
abstract = {Configuring Integrated Control Systems (ICSs) is largely manual, time-consuming and error-prone. In this paper, we propose a model-based configuration approach that interactively guides engineers to configure software embedded in ICSs. Our approach verifies engineers' decisions at each configuration iteration, and further, automates some of the decisions. We use a constraint solver, SICStus Prolog, to automatically infer configuration decisions and to ensure the consistency of configuration data. We evaluated our approach by applying it to a real subsea oil production system. Specifically, we rebuilt a number of existing verified product configurations of our industry partner. Our experience shows that our approach successfully enforces consistency of configurations, can automatically infer up to 50% of the configuration decisions, and reduces the complexity of making configuration decisions.},
booktitle = {Proceedings of the 8th European Conference on Modelling Foundations and Applications},
pages = {226–243},
numpages = {18},
keywords = {product configuration, model-based software engineering, constraint satisfaction, UML/OCL},
location = {Kgs. Lyngby, Denmark},
series = {ECMFA'12}
}

@inproceedings{10.1007/978-3-319-04891-8_10,
author = {Meier, Matthias and Breddemann, Mark and Spinczyk, Olaf},
title = {Hardware APIs: A Software-Centric Approach for Automated Derivation of MPSoC Hardware Structures Based on Static Code Analysis},
year = {2014},
isbn = {9783319048901},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-04891-8_10},
doi = {10.1007/978-3-319-04891-8_10},
abstract = {Multiprocessor systems on a chip (MPSoCs) are a popular class of course-grained parallel computer architectures, which are very useful, because they support re-use of legacy software components and application-specific tailoring of hardware structures at the same time. Furthermore, model-driven design frameworks for MPSoCs such as Xilinx' EDK or our own LavA-framework facilitate very fast system development. However, in this paper we argue that these design frameworks are not ideal from the development process perspective. Instead, we propose a software-centric approach that is based on the hardware API concept. The API is a representation of hardware components on the software level, which is generated from a hardware meta-model. It allows us to automatically derive a hardware structure based on access patterns in software, revealed by a static code analysis. This trick reduces the number of hardware details the developer needs to deal with and avoids configuration inconsistencies between the hardware and software levels by design.},
booktitle = {Proceedings of the 27th International Conference on Architecture of Computing Systems  ARCS 2014 - Volume 8350},
pages = {111–122},
numpages = {12}
}

@inproceedings{10.5555/2486788.2486992,
author = {Xing, Zhenchang and Xue, Yinxing and Jarzabek, Stan},
title = {A large scale Linux-kernel based benchmark for feature location research},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Many software maintenance tasks require locating code units that implement a certain feature (termed as feature location). Feature location has been an active research area for more than two decades. However, there is lack of publicly available, large scale benchmarks for evaluating and comparing feature location approaches. In this paper, we present a Linux-Kernel based benchmark for feature location research (video: http://www.youtube.com/watch?feature=player_embedded&amp;v=_HihwRNeK3I). This benchmark is large scale and extensible. By providing rich feature and program information and accurate ground-truth links between features and code units, it supports the evaluation of a wide range of feature location approaches. It allows researchers to gain deeper insights into existing approaches and how they can be improved. It also enables communication and collaboration among different researchers.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1311–1314},
numpages = {4},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/2145204.2145402,
author = {Liu, Xiaoqing (Frank) and Barnes, Eric Christopher and Savolainen, Juha Erik},
title = {Conflict detection and resolution for product line design in a collaborative decision making environment},
year = {2012},
isbn = {9781450310864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2145204.2145402},
doi = {10.1145/2145204.2145402},
abstract = {Ensuring that the non-functional requirements (NFRs), of a system are satisfied is an essential task in software development. However, this task is complicated by the fact that many NFRs conflict with each other from multiple perspectives. It is essential to resolve conflicts collectively in a collaborative decision making process since stakeholders often disagree on how conflicts should be resolved. In this paper, we describe a method for dividing high-level NFR conflicts within a product line into more manageable sub-problems. Stakeholders make use of an argumentation based collaborative decision support system to determine which design alternatives provide the best trade-offs between NFRs. Finally, we present an empirical study in which the aforementioned system was used to resolve a single instance of an NFR conflict across 3 members of a product line. It shows that the system is effective in resolving conflicts in a collaborative decision process.},
booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
pages = {1327–1336},
numpages = {10},
keywords = {participatory/cooperative design, computer-mediated communication, collaborative software development, Collaboration architectures},
location = {Seattle, Washington, USA},
series = {CSCW '12}
}

@inproceedings{10.1145/1984674.1984677,
author = {Scacchi, Walt},
title = {Modding as a basis for developing game systems},
year = {2011},
isbn = {9781450305785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1984674.1984677},
doi = {10.1145/1984674.1984677},
abstract = {This paper seeks to briefly examine what is known so far about game mods and modding practices. Game modding has become a leading method for developing games by customizing extensions to game software. The research method in this study is observational and qualitative, so as to highlight current practices and issues that can be associated with software engineering foundations. Numerous examples of different game mods and modding practices are identified throughout.},
booktitle = {Proceedings of the 1st International Workshop on Games and Software Engineering},
pages = {5–8},
numpages = {4},
keywords = {software extension, game modding, computer games},
location = {Waikiki, Honolulu, HI, USA},
series = {GAS '11}
}

@article{10.1016/j.aei.2006.11.007,
author = {Asikainen, Timo and M\"{a}nnist\"{o}, Tomi and Soininen, Timo},
title = {Kumbang: A domain ontology for modelling variability in software product families},
year = {2007},
issue_date = {January, 2007},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {21},
number = {1},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2006.11.007},
doi = {10.1016/j.aei.2006.11.007},
abstract = {Variability is the ability of a system to be efficiently extended, changed, customised or configured for use in a particular context. There is an ever-growing demand for variability of software. Software product families are an important means for implementing software variability. We present a domain ontology called Kumbang for modelling the variability in software product families. Kumbang synthesises previous approaches to modelling variability in software product families. In addition, it incorporates modelling constructs developed in the product configuration domain for modelling the variability in non-software products. The modelling concepts include components and features with compositional structure and attributes, the interfaces of components and connections between them, and constraints. The semantics of Kumbang is rigorously described using natural language and a UML profile. We provide preliminary proof of concept for Kumbang: the domain ontology has been provided with a formal semantics by implementing a translation into a general-purpose knowledge representation language with formal semantics and inference support. A prototype tool for resolving variability has been implemented.},
journal = {Adv. Eng. Inform.},
month = jan,
pages = {23–40},
numpages = {18},
keywords = {Variability, Software product family, Software architecture, Modelling, Kumbang, Feature modelling}
}

@article{10.1016/j.scico.2010.06.005,
author = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
title = {Automatic library migration for the generation of hardware-in-the-loop models},
year = {2012},
issue_date = {February, 2012},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {77},
number = {2},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2010.06.005},
doi = {10.1016/j.scico.2010.06.005},
abstract = {Embedded systems are widely used in several applications nowadays. As they integrate hard- and software elements, their functionality and reliability are often tested by hardware-in-the-loop methods, in which the system under test runs in a simulated environment. Due to the rising complexity of the embedded functions, performance limitations and practicability reasons, the simulations are often specialized to test specific aspects of the embedded system and develop a high diversity by themselves. This diversity is difficult to manage for a user and results in erroneously selected test components and compatibility problems in the test configuration. This paper presents a generative programming approach that handles the diversity of test libraries. Compatibility issues are explicitly evaluated by a new interface concept. Furthermore, a novel model analyzer facilitates the efficient application in practice by migrating existing libraries. The approach is evaluated for an example from the automotive domain using MATLAB/Simulink.},
journal = {Sci. Comput. Program.},
month = feb,
pages = {83–95},
numpages = {13},
keywords = {Structural comparison, Library migration, Generative programming, Function-block-based design}
}

@inproceedings{10.1007/978-3-319-26844-6_3,
author = {Bauer, Veronika},
title = {Challenges of Structured Reuse Adoption -- Lessons Learned},
year = {2015},
isbn = {9783319268439},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-26844-6_3},
doi = {10.1007/978-3-319-26844-6_3},
abstract = {Adoption of structured reuse approaches in practice often poses multiple challenges. Research-industry collaborations are considered as suitable vehicle to mitigate adoption difficulties as well as to validate the applicability of scientific results. However, research co-operations with industry do not always live up\"{\i} \'{z}to the expectations of either of the partners. Unfortunately for researchers and practitioners alike, insights behind the scenes of failed adoption and cooperation are often difficult to obtain. This hinders discussions on lessons learned by organizations during the adoption process and delays improvements.This paper aims to mitigate this issue by presenting lessons learned from interviews we conducted with practitioners in the context of a study on software reuse in industry. The study covered a wide range of aspects, including the process of reuse adoption. One of the participating companies had undertaken two attempts to adopt a form of structured reuse. However, both attempts did not succeed as expected. In our study, we identified tacit assumptions that were related to the encountered difficulties and present the lessons learned from the adoption approach. Furthermore, we report strategies that helped us to overcome the scepticism caused by a previous unsuccessful guided collaboration.},
booktitle = {Proceedings of the 16th International Conference on Product-Focused Software Process Improvement - Volume 9459},
pages = {24–39},
numpages = {16},
location = {Bolzano, Italy},
series = {PROFES 2015}
}

@inproceedings{10.1145/2993236.2993248,
author = {Kowal, Matthias and Ananieva, Sofia and Th\"{u}m, Thomas},
title = {Explaining anomalies in feature models},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993248},
doi = {10.1145/2993236.2993248},
abstract = {The development of variable software, in general, and feature models, in particular, is an error-prone and time-consuming task. It gets increasingly more challenging with industrial-size models containing hundreds or thousands of features and constraints. Each change may lead to anomalies in the feature model such as making some features impossible to select. While the detection of anomalies is well-researched, giving explanations is still a challenge. Explanations must be as accurate and understandable as possible to support the developer in repairing the source of an error. We propose an efficient and generic algorithm for explaining different anomalies in feature models. Additionally, we achieve a benefit for the developer by computing short explanations expressed in a user-friendly manner and by emphasizing specific parts in explanations that are more likely to be the cause of an anomaly. We provide an open-source implementation in FeatureIDE and show its scalability for industrial-size feature models.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {132–143},
numpages = {12},
keywords = {Software Product Lines, Feature Models, Explanations, Anomalies},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@article{10.1007/s00291-012-0290-7,
author = {Lang, Jan Christian and Widjaja, Thomas},
title = {OREX-J: towards a universal software framework for the experimental analysis of optimization algorithms},
year = {2013},
issue_date = {July      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {3},
issn = {0171-6468},
url = {https://doi.org/10.1007/s00291-012-0290-7},
doi = {10.1007/s00291-012-0290-7},
abstract = {The Operations Research EXperiment Framework for Java (OREX-J) is an object-oriented software framework that helps users to design, implement and conduct computational experiments for the analysis of optimization algorithms. As it was designed in a generic way using object-oriented programming and design patterns, it is not limited to a specific class of optimization problems and algorithms. The purpose of the framework is to reduce the amount of manual labor required for conducting and evaluating computational experiments: OREX-J provides a generic, extensible data model for storing detailed data on an experimental design and its results. Those data can include algorithm parameters, test instance generator settings, the instances themselves, run-times, algorithm logs, solution properties, etc. All data are automatically saved in a relational database (MySQL, http://www.mysql.com/ ) by means of the object-relational mapping library Hibernate ( http://www.hibernate.org/ ). This simplifies the task of analyzing computational results, as even complex analyses can be performed using comparatively simple Structured Query Language (SQL) queries. Also, OREX-J simplifies the comparison of algorithms developed by different researchers: Instead of integrating other researchers' algorithms into proprietary test beds, researchers could use OREX-J as a common experiment framework. This paper describes the architecture and features of OREX-J and exemplifies its usage in a case study. OREX-J has already been used for experiments in three different areas: Algorithms and reformulations for mixed-integer programming models for dynamic lot-sizing with substitutions, a simulation-based optimization approach for a stochastic multi-location inventory control model, and an optimization model for software supplier selection and product portfolio planning.},
journal = {OR Spectr.},
month = jul,
pages = {735–769},
numpages = {35},
keywords = {Test bed, Software framework, Operations research methodology, Object-oriented design, Experimental analysis of algorithms, Design patterns}
}

@inproceedings{10.1145/2628136.2628155,
author = {Chen, Sheng and Erwig, Martin},
title = {Type-based parametric analysis of program families},
year = {2014},
isbn = {9781450328739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628136.2628155},
doi = {10.1145/2628136.2628155},
abstract = {Previous research on static analysis for program families has focused on lifting analyses for single, plain programs to program families by employing idiosyncratic representations. The lifting effort typically involves a significant amount of work for proving the correctness of the lifted algorithm and demonstrating its scalability. In this paper, we propose a parameterized static analysis framework for program families that can automatically lift a class of type-based static analyses for plain programs to program families. The framework consists of a parametric logical specification and a parametric variational constraint solver. We prove that a lifted algorithm is correct provided that the underlying analysis algorithm is correct. An evaluation of our framework has revealed an error in a previous manually lifted analysis. Moreover, performance tests indicate that the overhead incurred by the general framework is bounded by a factor of 2.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
pages = {39–51},
numpages = {13},
keywords = {variational types, static-analysis lifting, program families, constraint-based type system, choice calculus},
location = {Gothenburg, Sweden},
series = {ICFP '14}
}

@inproceedings{10.1145/1233341.1233348,
author = {Hunt, John M. and McGregor, John D.},
title = {When less is more: implementing optional features},
year = {2007},
isbn = {9781595936295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1233341.1233348},
doi = {10.1145/1233341.1233348},
abstract = {The ability to produce products that can be easily adapted to a variety of customers is becoming increasingly important. A key element for adaptable software products is the ability to include or omit features for different product variants. Even when a design method supports feature adaptation there remains the task of actually implementing the modules. In this paper we consider how to implement features in a product context using a variety of techniques and present an analysis of the tradeoffs involved in providing optional features. We will also discuss how to implement feature interactions to accommodate optional features. This paper provides specific advice about implementing program features, using the Java language enhanced with XVCL and AspectJ, when some of the features are optional and when some combinations of features exhibit interactions.},
booktitle = {Proceedings of the 45th Annual ACM Southeast Conference},
pages = {30–35},
numpages = {6},
keywords = {feature interaction, feature separation, java, reuse},
location = {Winston-Salem, North Carolina},
series = {ACMSE '07}
}

@inproceedings{10.1145/2425415.2425417,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Le Noir, J\'{e}r\^{o}me and J\'{e}z\'{e}quel, Jean-Marc},
title = {Customizing the common variability language semantics for your domain models},
year = {2012},
isbn = {9781450318099},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2425415.2425417},
doi = {10.1145/2425415.2425417},
abstract = {The Common Variability Language (CVL) provides a well-structured mechanism to express variability and to relate this variability to any MOF-compliant model. This characteristic allows users to define the materialization of a given CVL resolution/configuration. Using variation points, it is possible to express and manipulate the links between the variability abstraction model and the base model. However, the meaning of a given variation point can vary according to the semantics of each domain. For example, a variation point that excludes an element in the base model can lead to further operations, like excluding other elements which were associated to the deleted element, or even to reassign references to another model element. Therefore, it is necessary to address this semantic variability in order to align the materialization semantics to the base model semantics. In this paper, we show how Kermeta can be used to easily implement and customize the semantics of the CVL's variation points, according to the semantics of the base model domain.},
booktitle = {Proceedings of the VARiability for You Workshop: Variability Modeling Made Useful for Everyone},
pages = {3–8},
numpages = {6},
keywords = {variability modelling, semantics, extensibility, CVL},
location = {Innsbruck, Austria},
series = {VARY '12}
}

@book{10.5555/2669162,
author = {Felfernig, Alexander and Hotz, Lothar and Bagley, Claire and Tiihonen, Juha},
title = {Knowledge-based Configuration: From Research to Business Cases},
year = {2014},
isbn = {012415817X},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1},
abstract = {Knowledge-based Configuration incorporates knowledge representation formalisms to capture complex product models and reasoning methods to provide intelligent interactive behavior with the user. This book represents the first time that corporate and academic worlds collaborate integrating research and commercial benefits of knowledge-based configuration. Foundational interdisciplinary material is provided for composing models from increasingly complex products and services. Case studies, the latest research, and graphical knowledge representations that increase understanding of knowledge-based configuration provide a toolkit to continue to push the boundaries of what configurators can do and how they enable companies and customers to thrive.Includes detailed discussion of state-of-the art configuration knowledge engineering approaches such as automated testing and debugging, redundancy detection, and conflict management Provides an overview of the application of knowledge-based configuration technologies in the form of real-world case studies from SAP, Siemens, Kapsch, and more Explores the commercial benefits of knowledge-based configuration technologies to business sectors from services to industrial equipment Uses concepts that are based on an example personal computer configuration knowledge base that is represented in an UML-based graphical language}
}

@inproceedings{10.1145/2556624.2556644,
author = {Janota, Mikol\'{a}\v{s} and Botterweck, Goetz and Marques-Silva, Joao},
title = {On lazy and eager interactive reconfiguration},
year = {2014},
isbn = {9781450325561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556624.2556644},
doi = {10.1145/2556624.2556644},
abstract = {An interactive configuration tool needs to provide feedback to the user on possible further decisions while respecting constraints of the product being configured. In the presence of a large number of product features, it reduces the configuration effort if users can start from a default configuration and adapt only those features that are important to them. Hence, rather than completing an empty configuration (empty product), it is easier to move from one complete configuration to another (from one product to another). This paper shows how to provide tool support for this approach to interactive configuration. Two types of algorithms, based on recent advancements in SAT technology, are introduced: lazy and eager. While the eager provides more information to the user, the lazy scales to configuration models with tens of thousands of features. This is confirmed by an experimental evaluation carried out with the implemented prototype.},
booktitle = {Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {8},
numpages = {8},
keywords = {minimal correction sets, interactive configuration, SAT},
location = {Sophia Antipolis, France},
series = {VaMoS '14}
}

@article{10.1016/j.future.2019.03.037,
author = {Pourmasoumi, Asef and Kahani, Mohsen and Bagheri, Ebrahim},
title = {The evolutionary composition of desirable execution traces from event logs},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {98},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.03.037},
doi = {10.1016/j.future.2019.03.037},
journal = {Future Gener. Comput. Syst.},
month = sep,
pages = {78–103},
numpages = {26},
keywords = {Event logs, Optimization algorithms, Process improvement, Business process families}
}

@inproceedings{10.1007/11554844_8,
author = {Alves, Vander and Matos, Pedro and Cole, Leonardo and Borba, Paulo and Ramalho, Geber},
title = {Extracting and evolving mobile games product lines},
year = {2005},
isbn = {3540289364},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11554844_8},
doi = {10.1007/11554844_8},
abstract = {For some organizations, the proactive approach to product lines may be inadequate due to prohibitively high investment and risks. As an alternative, the extractive and the reactive approaches are incremental, offering moderate costs and risks, and therefore sometimes may be more appropriate. However, combining these two approaches demands a more detailed process at the implementation level. This paper presents a method for extracting a product line and evolving it, relying on a strategy that uses refactorings expressed in terms of simpler programming laws. The approach is evaluated with a case study in the domain of games for mobile devices, where variations are handled with aspect-oriented constructs.},
booktitle = {Proceedings of the 9th International Conference on Software Product Lines},
pages = {70–81},
numpages = {12},
location = {Rennes, France},
series = {SPLC'05}
}

@article{10.2478/v10143-009-0013-y,
author = {Kotovs, Vladimirs},
title = {Forty years of software reuse},
year = {2009},
issue_date = {1 2009},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {38},
number = {38},
issn = {1407-7493},
url = {https://doi.org/10.2478/v10143-009-0013-y},
doi = {10.2478/v10143-009-0013-y},
abstract = {Forty years of software reuseThis paper is an overview of software reuse, its origins, research areas and main historical contributions. Reuse as the process of using existing software artefacts and knowledge has more than 40-year long history, and is currently recognized as an important mechanism to improve software quality and development productivity. Main attention is paid to retrospective analysis of key researches in the area of software reuse. Starting from the seminal paper and the other earliest contributions the survey discusses important milestones in the evolution of initial ideas of component sub-industry to mature field of research in software engineering. Active areas of past researches being overviewed by this paper include reuse libraries, asset classification and selection, measurement and experimentation, design patterns and studies of systematic reuse. Separate attention is paid to consolidation of main benefits and obstacles of software reuse. The paper concludes important ideas emerging from the historical experience about multidisciplinary nature of reuse, necessity of software reuse process and the role of domain engineering. Overview of key aspects organizational, technical and economic important for establishing software reuse programs is given.},
journal = {Sci. J. Riga Tech. Univ.},
month = jan,
pages = {153–160},
numpages = {8},
keywords = {reusable assets, history of software reuse, aspects of systematic software reuse, Software reuse}
}

@inproceedings{10.1145/1449913.1449917,
author = {Rosenm\"{u}ller, Marko and Siegmund, Norbert and Saake, Gunter and Apel, Sven},
title = {Code generation to support static and dynamic composition of software product lines},
year = {2008},
isbn = {9781605582672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1449913.1449917},
doi = {10.1145/1449913.1449917},
abstract = {Software product lines (SPLs) are used to create tailor-made software products by managing and composing reusable assets. Generating a software product from the assets of an SPL is possible statically before runtime or dynamically at load-time or runtime. Both approaches have benefits and drawbacks with respect to composition flexibility, performance, and resource consumption. Which type of composition is preferable should be decided by taking the application scenario into account. Current tools and languages, however, force a programmer to decide between static and dynamic composition during development. In this paper, we present an approach that employs code generation to support static and dynamic composition of features of a single code base. We offer an implementation on top of FeatureC++, an extension of the C++ programming language that supports software composition based on features. To simplify dynamic composition and to avoid creation of invalid products we furthermore provide means to (1) validate the correctness of a composition at runtime, (2) automatically instantiate SPLs in case of stand-alone applications, and (3) automatically apply interaction code of crosscutting concerns.},
booktitle = {Proceedings of the 7th International Conference on Generative Programming and Component Engineering},
pages = {3–12},
numpages = {10},
keywords = {static feature binding, software product lines, feature-oriented programming, dynamic feature binding},
location = {Nashville, TN, USA},
series = {GPCE '08}
}

@inproceedings{10.1007/978-3-642-28872-2_18,
author = {Th\"{u}m, Thomas and Schaefer, Ina and Kuhlemann, Martin and Apel, Sven and Saake, Gunter},
title = {Applying design by contract to feature-oriented programming},
year = {2012},
isbn = {9783642288715},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-28872-2_18},
doi = {10.1007/978-3-642-28872-2_18},
abstract = {Feature-oriented programming (FOP) is an extension of ob- ject-oriented programming to support software variability by refining existing classes and methods. In order to increase the reliability of all implemented program variants, we integrate design by contract (DbC) with FOP. DbC is an approach to build reliable object-oriented software by specifying methods with contracts. Contracts are annotations that document and formally specify behavior, and can be used for formal verification of correctness or as test oracles. We present and discuss five approaches to define contracts of methods and their refinements in FOP. Furthermore, we share our insights gained by performing five case studies. This work is a foundation for research on the analysis of feature-oriented programs (e.g., for verifying functional correctness or for detecting feature interactions).},
booktitle = {Proceedings of the 15th International Conference on Fundamental Approaches to Software Engineering},
pages = {255–269},
numpages = {15},
location = {Tallinn, Estonia},
series = {FASE'12}
}

@article{10.1145/1629175.1629209,
author = {Witman, Paul D. and Ryan, Terry},
title = {Think big for reuse},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/1629175.1629209},
doi = {10.1145/1629175.1629209},
abstract = {IntroductionMany organizations are successful with software reuse at fine to medium granularities -- ranging from objects, subroutines, and components through software product lines. However, relatively little has been published on very large-grained reuse. One example of this type of large-grained reuse might be that of an entire Internet banking system (applications and infrastructure) reused in business units all over the world. In contrast, "large scale" software reuse in current research generally refers to systems that reuse a large number of smaller components, or that perhaps reuse subsystems. In this article, we explore a case of an organization with an internal development group that has been very successful with large-grained software reuse.BigFinancial, and the BigFinancial Technology Center (BTC) in particular, have created a number of software systems that have been reused in multiple businesses and in multiple countries. BigFinancial and BTC thus provided a rich source of data for case studies to look at the characteristics of those projects and why they have been successful, as well as to look at projects that have been less successful and to understand what has caused those results and what might be done differently to prevent issues in the future. The research is focused on technology, process, and organizational elements of the development process, rather than on specific product features and functions.Supporting reuse at a large-grained level may help to alleviate some of the issues that occur in more traditional reuse programs, which tend to be finer-grained. In particular, because BigFinancial was trying to gain commonality in business processes and operating models, reuse of large-grained components was more closely aligned with its business goals. This same effect may well not have happened with finer-grained reuse, due to the continued ability of business units to more readily pick and choose components for reuse.BTC is a technology development unit of BigFinancial, with operations in both the eastern and western US. Approximately 500 people are employed by BTC, reporting ultimately through a single line manager responsible to the Global Retail Business unit head of BigFinancial. BTC is organized to deliver both products and infrastructure components to BigFinancial, and its product line has through the years included consumer Internet banking services, teller systems, ATM software, and network management tools. BigFinancial has its U.S. operations headquartered in the eastern U.S., and employs more than 8,000 technologists worldwide.In cooperation with BTC, we selected three cases for further study from a pool of about 25. These cases were the Java Banking Toolkit (JBT) and its related application systems, the Worldwide Single Signon (WSSO) subsystem, and the BigFinancial Message Switch (BMS).},
journal = {Commun. ACM},
month = jan,
pages = {142–147},
numpages = {6}
}

@inproceedings{10.5555/1792838.1792842,
author = {Janota, Mikol\'{a}\v{s} and Botterweck, Goetz},
title = {Formal approach to integrating feature and architecture models},
year = {2008},
isbn = {3540787429},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {If we model a family of software applications with a feature model and an architecture model, we are describing the same subject from different perspectives. Hence, we are running the risk of inconsistencies. For instance, the feature model might allow feature configurations that are not realizable by the architecture.In this paper we tackle this problem by providing a formalization of dependencies between features and components. Further, we demonstrate that this formalization offers a better understanding of the modeled concepts. Moreover, we propose automated techniques that derive additional information and provide feedback to the user. Finally, we discuss how some of these techniques can be implemented.},
booktitle = {Proceedings of the Theory and Practice of Software, 11th International Conference on Fundamental Approaches to Software Engineering},
pages = {31–45},
numpages = {15},
location = {Budapest, Hungary},
series = {FASE'08/ETAPS'08}
}

@article{10.1016/j.parco.2014.07.004,
author = {Coetzee, P. and Leeke, M. and Jarvis, S.},
title = {Towards unified secure on- and off-line analytics at scale},
year = {2014},
issue_date = {December 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {10},
issn = {0167-8191},
url = {https://doi.org/10.1016/j.parco.2014.07.004},
doi = {10.1016/j.parco.2014.07.004},
abstract = {A domain specific language and runtime models for on- and off-line data analytics.Detailed analysis of CRUCIBLE's runtime performance in state-of-the-art environments.Development and detailed analysis of a set of runtime models for new environments.Performance comparison with native implementations demonstrating a 14 average performance gap.Formulation of a primitive in the DSL that permits an analytic to be run over multiple data sources. Data scientists have applied various analytic models and techniques to address the oft-cited problems of large volume, high velocity data rates and diversity in semantics. Such approaches have traditionally employed analytic techniques in a streaming or batch processing paradigm. This paper presents CRUCIBLE, a first-in-class framework for the analysis of large-scale datasets that exploits both streaming and batch paradigms in a unified manner. The CRUCIBLE framework includes a domain specific language for describing analyses as a set of communicating sequential processes, a common runtime model for analytic execution in multiple streamed and batch environments, and an approach to automating the management of cell-level security labelling that is applied uniformly across runtimes. This paper shows the applicability of CRUCIBLE to a variety of state-of-the-art analytic environments, and compares a range of runtime models for their scalability and performance against a series of native implementations. The work demonstrates the significant impact of runtime model selection, including improvements of between 2.3 and 480 between runtime models, with an average performance gap of just 14 between CRUCIBLE and a suite of equivalent native implementations.},
journal = {Parallel Comput.},
month = dec,
pages = {738–753},
numpages = {16},
keywords = {Streaming analysis, Hadoop, Domain specific languages, Data science, Data intensive computing, Analytics}
}

@inproceedings{10.1109/ESEM.2009.5316001,
author = {Barney, Sebastian and Wohlin, Claes and Aurum, Aybuke},
title = {Balancing software product investments},
year = {2009},
isbn = {9781424448425},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ESEM.2009.5316001},
doi = {10.1109/ESEM.2009.5316001},
abstract = {The long-term sustainability of a software product depends on more than developing features. Priorities are placed on aspects that support the development of software, like software product quality (eg. ISO 9126), project constraints — time and cost, and even the development of intellectual capital (IC). A greater focus on any one aspect takes priority from another, but as each aspects delivers a different type of value managers have trouble comparing and balancing these aspects. This paper presents a method to help determine the balance between key priorities in the software development process. The method is applied to a new case study, that also combines with results from previous studies. The results show it is possible to compare features, quality, time, cost and IC in a comprehensive way, with the case study showing that participants perceive a change from a shorter-term product perspective to a longer-term organisation beneficial to the business.},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
pages = {257–268},
numpages = {12},
series = {ESEM '09}
}

@article{10.4018/ijiit.2013100103,
author = {McLeod, Kenneth and Iskandar, D. N. F. Awang and Burger, Albert},
title = {Towards the Semantic Representation of Biological Images: From Pixels to Regions},
year = {2013},
issue_date = {October 2013},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {4},
issn = {1548-3657},
url = {https://doi.org/10.4018/ijiit.2013100103},
doi = {10.4018/ijiit.2013100103},
abstract = {Biomedical images and models contain vast amounts of information. Regrettably, much of this information is only accessible by domain experts. This paper describes a biological use case in which this situation occurs. Motivation is given for describing images, from this use case, semantically. Furthermore, links are provided to the medical domain, demonstrating the transferability of this work. Subsequently, it is shown that a semantic representation in which every pixel is featured is needlessly expensive. This motivates the discussion of more abstract renditions, which are dealt with next. As part of this, the paper discusses the suitability of existing technologies. In particular, Region Connection Calculus and one implementation of the W3C Geospatial Vocabulary are considered. It transpires that the abstract representations provide a basic description that enables the user to perform a subset of the desired queries. However, a more complex depiction is required for this use case.},
journal = {Int. J. Intell. Inf. Technol.},
month = oct,
pages = {35–54},
numpages = {20},
keywords = {Semantic Technologies, Qualitative Spatial Reasoning, Gene Expression, Biomedical Images, Biomedical Atlasing}
}

@article{10.1007/s10664-015-9364-x,
author = {Passos, Leonardo and Teixeira, Leopoldo and Dintzner, Nicolas and Apel, Sven and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof and Borba, Paulo and Guo, Jianmei},
title = {Coevolution of variability models and related software artifacts},
year = {2016},
issue_date = {August    2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9364-x},
doi = {10.1007/s10664-015-9364-x},
abstract = {Variant-rich software systems offer a large degree of customization, allowing users to configure the target system according to their preferences and needs. Facing high degrees of variability, these systems often employ variability models to explicitly capture user-configurable features (e.g., systems options) and the constraints they impose. The explicit representation of features allows them to be referenced in different variation points across different artifacts, enabling the latter to vary according to specific feature selections. In such settings, the evolution of variability models interplays with the evolution of related artifacts, requiring the two to evolve together, or coevolve. Interestingly, little is known about how such coevolution occurs in real-world systems, as existing research has focused mostly on variability evolution as it happens in variability models only. Furthermore, existing techniques supporting variability evolution are usually validated with randomly-generated variability models or evolution scenarios that do not stem from practice. As the community lacks a deep understanding of how variability evolution occurs in real-world systems and how it relates to the evolution of different kinds of software artifacts, it is not surprising that industry reports existing tools and solutions ineffective, as they do not handle the complexity found in practice. Attempting to mitigate this overall lack of knowledge and to support tool builders with insights on how variability models coevolve with other artifact types, we study a large and complex real-world variant-rich software system: the Linux kernel. Specifically, we extract variability-coevolution patterns capturing changes in the variability model of the Linux kernel with subsequent changes in Makefiles and C source code. From the analysis of the patterns, we report on findings concerning evolution principles found in the kernel, and we reveal deficiencies in existing tools and theory when handling changes captured by our patterns.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1744–1793},
numpages = {50},
keywords = {Variability, Software product lines, Patterns, Linux, Evolution}
}

@inproceedings{10.1145/2517208.2517224,
author = {Dhungana, Deepak and Falkner, Andreas and Haselb\"{o}ck, Alois},
title = {Generation of conjoint domain models for system-of-systems},
year = {2013},
isbn = {9781450323734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517208.2517224},
doi = {10.1145/2517208.2517224},
abstract = {Software solutions in complex environments, such as railway control systems or power plants, are assemblies of heterogeneous components, which are very large and complex systems themselves. Interplay of these systems requires a thorough design of a system-of-systems (SoS) encompassing the required interactions between the involved systems. One of the challenges lies in reconciliation of the domain data structures and runtime constraints to ensure consistency of the SoS behavior. In this paper, we present a generative approach that enables reconciliation of a common platform based on reusable domain models of the involved systems. This is comparable to a product line configuration problem where we generate a common platform model for all involved systems. We discuss the specific requirements for model composition in a SoS context and address them in our approach. In particular, our approach addresses the operational and managerial independence of the individual systems and offers appropriate modeling constructs. We report on our experiences of applying the approach in several real world projects and share the lessons learned.},
booktitle = {Proceedings of the 12th International Conference on Generative Programming: Concepts &amp; Experiences},
pages = {159–168},
numpages = {10},
keywords = {system-of-systems integration, platform alignment},
location = {Indianapolis, Indiana, USA},
series = {GPCE '13}
}

@inproceedings{10.1007/11561347_28,
author = {Czarnecki, Krzysztof and Antkiewicz, Micha\l{}},
title = {Mapping features to models: a template approach based on superimposed variants},
year = {2005},
isbn = {3540291385},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11561347_28},
doi = {10.1007/11561347_28},
abstract = {Although a feature model can represent commonalities and variabilities in a very concise taxonomic form, features in a feature model are merely symbols. Mapping features to other models, such as behavioral or data specifications, gives them semantics. In this paper, we propose a general template-based approach for mapping feature models to concise representations of variability in different kinds of other models. We show how the approach can be applied to UML 2.0 activity and class models and describe a prototype implementation.},
booktitle = {Proceedings of the 4th International Conference on Generative Programming and Component Engineering},
pages = {422–437},
numpages = {16},
location = {Tallinn, Estonia},
series = {GPCE'05}
}

@inproceedings{10.1145/2377816.2377820,
author = {Schuster, Sven and Schulze, Sandro},
title = {Object-oriented design in feature-oriented programming},
year = {2012},
isbn = {9781450313094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377816.2377820},
doi = {10.1145/2377816.2377820},
abstract = {Object-oriented programming is the state-of-the-art programming paradigm for developing large and complex software systems. To support the development of maintainable and evolvable code, a developer can rely on different mechanisms and concepts such as inheritance and design patterns. Recently, feature-oriented programming (FOP) gained attention, specifically for developing software product lines (SPLs). Although FOP is an own paradigm with dedicated language mechanisms, it partly relies on object-oriented programming. However, only little is known about feature-oriented design and how object-oriented design mechanisms and design principles are used within FOP. In this paper, we want to raise awareness on design patterns in FOP and stimulate discussion on related topics. To this end, we present an exemplary review of using OO design patterns in FOP and limitations thereof from our perspective. Subsequently, we formulate questions that are open and that we think are worth to discuss in the context of feature-oriented design.},
booktitle = {Proceedings of the 4th International Workshop on Feature-Oriented Software Development},
pages = {25–28},
numpages = {4},
keywords = {feature-oriented programming, design pattern},
location = {Dresden, Germany},
series = {FOSD '12}
}

@inproceedings{10.1007/978-3-030-26948-7_9,
author = {Bellare, Mihir and Ng, Ruth and Tackmann, Bj\"{o}rn},
title = {Nonces Are Noticed: AEAD Revisited},
year = {2019},
isbn = {978-3-030-26947-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26948-7_9},
doi = {10.1007/978-3-030-26948-7_9},
abstract = {We draw attention to a gap between theory and usage of nonce-based symmetric encryption, under which the way the former treats nonces can result in violation of privacy in the latter. We bridge the gap with a new treatment of nonce-based symmetric encryption that modifies the syntax (decryption no longer takes a nonce), upgrades the security goal (asking that not just messages, but also nonces, be hidden) and gives simple, efficient schemes conforming to the new definitions. We investigate both basic security (holding when nonces are not reused) and advanced security (misuse resistance, providing best-possible guarantees when nonces are reused).},
booktitle = {Advances in Cryptology – CRYPTO 2019: 39th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 18–22, 2019, Proceedings, Part I},
pages = {235–265},
numpages = {31},
location = {Santa Barbara, CA, USA}
}

@inproceedings{10.5555/2022115.2022137,
author = {Savolainen, Juha and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi},
title = {Eight practical considerations in applying feature modeling for product lines},
year = {2011},
isbn = {9783642213465},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling has enjoyed success as a widely used variability modeling method in companies utilizing product lines. A number of different feature modeling methods have been proposed with expanded notational concepts and ability to model various dependencies among features. Despite popular usage and relatively simple concepts, different feature modeling methods tend not to explicate their purposes and assumptions and, in particular, how exactly the model is intended to be used. Consequently, many practitioners have a hard time evaluating whether a particular method is good for their purposes. In this paper, we intend to discuss the practical considerations when applying feature models. On the one hand, discussion of these considerations in research papers would clarify the intent of a proposed method. On the other hand, the considerations could help practitioners in clarifying the guiding principles for their feature modeling. In total, we expose eight points of practical considerations that are rarely discussed in research papers. These observations are based our experience of practice and research carried out in close cooperation with several companies.},
booktitle = {Proceedings of the 12th International Conference on Top Productivity through Software Reuse},
pages = {192–206},
numpages = {15},
keywords = {software architecture, industrial experience, feature modeling},
location = {Pohang, South Korea},
series = {ICSR'11}
}

@article{10.1016/j.jss.2013.11.1121,
author = {Sutcliffe, Alistair and Papamargaritis, George},
title = {End-user development by application-domain configuration},
year = {2014},
issue_date = {May, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {91},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2013.11.1121},
doi = {10.1016/j.jss.2013.11.1121},
abstract = {An application generator/tailoring tool aimed at end users is described. It employs conceptual models of problem domains to drive configuration of an application generator suitable for a related set of applications, such as reservation and resource allocation. The tool supports a two-phase approach of configuring the general architecture for a domain, such as reservation-booking problems, then customisation and generation of specific applications. The tool also provides customisable natural language-style queries for spatial and temporal terms. Development and use of the tool to generate two applications, service engineer call allocation, and airline seat reservation, are reported with a specification exercise to configure the generic architecture to a new problem domain for monitoring-sensing applications. The application generator/tailoring tool is evaluated with novice end users and experts to demonstrate its effectiveness.},
journal = {J. Syst. Softw.},
month = may,
pages = {85–99},
numpages = {15},
keywords = {End-user development, Domain-oriented design, Application generation}
}

@inproceedings{10.1145/1944892.1944903,
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
title = {Managing feature models with familiar: a demonstration of the language and its tool support},
year = {2011},
isbn = {9781450305709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944892.1944903},
doi = {10.1145/1944892.1944903},
abstract = {Developing software product lines involves modeling a large number of features, usually using feature models, that represent different viewpoints, sub-systems or concerns of the software system. To manage complexity on a large scale, there is a need to separate, relate and compose several feature models while automating the reasoning on their compositions. This demonstration gives an overview of a Domain-Specific Language, familiar, that is dedicated to the management of feature models. Its comprehensive programming environment, based on Eclipse, is also described. It complements existing tool support (i.e., FeatureIDE).},
booktitle = {Proceedings of the 5th International Workshop on Variability Modeling of Software-Intensive Systems},
pages = {91–96},
numpages = {6},
keywords = {product lines, feature models, domain-specific language},
location = {Namur, Belgium},
series = {VaMoS '11}
}

@article{10.1145/3360575,
author = {Jangda, Abhinav and Pinckney, Donald and Brun, Yuriy and Guha, Arjun},
title = {Formal foundations of serverless computing},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360575},
doi = {10.1145/3360575},
abstract = {Serverless computing (also known as functions as a service) is a new cloud computing abstraction that makes it easier to write robust, large-scale web services. In serverless computing, programmers write what are called serverless functions, which are programs that respond to external events. When demand for the serverless function spikes, the platform automatically allocates additional hardware and manages load-balancing; when demand falls, the platform silently deallocates idle resources; and when the platform detects a failure, it transparently retries affected requests. In 2014, Amazon Web Services introduced the first serverless platform, AWS Lambda, and similar abstractions are now available on all major cloud computing platforms. Unfortunately, the serverless computing abstraction exposes several low-level operational details that make it hard for programmers to write and reason about their code. This paper sheds light on this problem by presenting λλ, an operational semantics of the essence of serverless computing. Despite being a small (half a page) core calculus, λλ models all the low-level details that serverless functions can observe. To show that λλ is useful, we present three applications. First, to ease reasoning about code, we present a simplified naive semantics of serverless execution and precisely characterize when the naive semantics and λλ coincide. Second, we augment λλ with a key-value store to allow reasoning about stateful serverless functions. Third, since a handful of serverless platforms support serverless function composition, we show how to extend λλ with a composition language and show that our implementation can outperform prior work.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {149},
numpages = {26},
keywords = {serverless computing, formal language semantics, distributed computing}
}

@inproceedings{10.1145/3239372.3239377,
author = {de Lara, Juan and Guerra, Esther and Chechik, Marsha and Salay, Rick},
title = {Model Transformation Product Lines},
year = {2018},
isbn = {9781450349499},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239372.3239377},
doi = {10.1145/3239372.3239377},
abstract = {Model transformations enable automation in Model-Driven Engineering (MDE) and are key to its success. The emphasis of MDE on using domain-specific languages has caused a proliferation of meta-models, many of them capturing variants of base languages. In this scenario, developing a transformation for a new meta-model is usually performed manually with no reuse, even if comparable transformations for similar meta-models exist. This is a suboptimal process that precludes a wider adoption of MDE in industry.To improve this situation, we propose applying ideas from software product lines to transformation engineering. Our proposal enables the definition of meta-model product lines to capture the variability within a domain, on top of which transformations can be defined in a modular way. We call this construction transformation product line (TPL), and propose mechanisms for their construction, extension and analysis. TPLs are supported by a tool, Merlin, which is agnostic to the transformation language and lifts analyses based on model finding to the TPL. Finally, we report on an evaluation showing the benefits of building and analysing TPLs compared to building and analysing each individual transformation.},
booktitle = {Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {67–77},
numpages = {11},
keywords = {Reusability, Product Lines, Model Transformations},
location = {Copenhagen, Denmark},
series = {MODELS '18}
}

@article{10.1016/j.infsof.2009.04.004,
author = {Mohagheghi, Parastoo and Dehlen, Vegard and Neple, Tor},
title = {Definitions and approaches to model quality in model-based software development - A review of literature},
year = {2009},
issue_date = {December, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {12},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.04.004},
doi = {10.1016/j.infsof.2009.04.004},
abstract = {More attention is paid to the quality of models along with the growing importance of modelling in software development. We performed a systematic review of studies discussing model quality published since 2000 to identify what model quality means and how it can be improved. From forty studies covered in the review, six model quality goals were identified; i.e., correctness, completeness, consistency, comprehensibility, confinement and changeability. We further present six practices proposed for developing high-quality models together with examples of empirical evidence. The contributions of the article are identifying and classifying definitions of model quality and identifying gaps for future research.},
journal = {Inf. Softw. Technol.},
month = dec,
pages = {1646–1669},
numpages = {24},
keywords = {UML, Systematic review, Modelling, Model-driven development, Model quality}
}

@inproceedings{10.1145/2554850.2554949,
author = {Beohar, Harsh and Mousavi, Mohammad Reza},
title = {Input-output conformance testing based on featured transition systems},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554949},
doi = {10.1145/2554850.2554949},
abstract = {We extend the theory of input-output conformance testing to the setting of software product lines. In particular, we allow for input-output featured transition systems to be used as the basis for generating test suites and test cases. We introduce refinement operators both at the level of models and at the level of test suites that allow for projecting them into a specific product configuration (or a product sub-line). We show that the two sorts of refinement are consistent and lead to the same set of test-cases.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1272–1278},
numpages = {7},
keywords = {software product lines, model based testing, input-output featured transition systems, input-output conformance testing},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.5555/2041790.2041811,
author = {Gamez, Nadia and Fuentes, Lidia and Arag\"{u}ez, Miguel A.},
title = {Autonomic computing driven by feature models and architecture in FamiWare},
year = {2011},
isbn = {9783642237973},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A wireless sensor network is an example of a system that should be able to adapt its sensor nodes to some context changes with minimum human intervention. This means that the architecture of the middleware for sensors must encapsulate a dynamic mechanism to allow reconfiguration. We present a novel approach to achieve self-adaptation based on software product lines and on the autonomic computing paradigm for the FamiWare middleware. FamiWare uses feature models to represent the potential middleware configurations at runtime. Each configuration is automatically mapped to the corresponding architectural representation of a specific middleware product. Following the autonomic computing principles, FamiWare defines a reconfiguration mechanism that switches from one architectural configuration to another by means of executing a plan. This is possible thanks to the loosely coupled architecture of FamiWare based on an event-based publish and subscribe mechanism. We evaluate our work by showing that the resource consumption and the overhead are not so critical compared with the benefits of providing this self-adaptation mechanism.},
booktitle = {Proceedings of the 5th European Conference on Software Architecture},
pages = {164–179},
numpages = {16},
keywords = {product lines architectures, models at runtime, middleware, feature models, event-based architectures, autonomic computing},
location = {Essen, Germany},
series = {ECSA'11}
}

@inproceedings{10.1007/11787044_25,
author = {Wagelaar, Dennis and Van Der Straeten, Ragnhild},
title = {A comparison of configuration techniques for model transformations},
year = {2006},
isbn = {3540359095},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11787044_25},
doi = {10.1007/11787044_25},
abstract = {MDA generally involves applying multiple model transformations. These transformations need to be applied in a particular configuration, depending on the targeted platform. Several techniques exist to manage the configuration of various software elements or components. These techniques focus on the composition rules of the various elements. A well-known application area of such techniques are Software Product Lines, in which the various features that make up a software product need to be configured. In this paper, we will investigate how several of these techniques can be applied to manage the configuration of model transformations in an MDA context.},
booktitle = {Proceedings of the Second European Conference on Model Driven Architecture: Foundations and Applications},
pages = {331–345},
numpages = {15},
location = {Bilbao, Spain},
series = {ECMDA-FA'06}
}

@inproceedings{10.5555/2814058.3252438,
author = {Cappelli, Claudia and Ferreira, Arnaldo Alves},
title = {Session details: Special Track - Experience Reports in Industry and Case Studies},
year = {2015},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
booktitle = {Proceedings of the Annual Conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1},
location = {Goiania, Goias, Brazil},
series = {SBSI '15}
}

@inbook{10.5555/2172290.2172300,
author = {Lohmann, Daniel and Spinczyk, Olaf and Schr\"{o}der-Preikschat, Wolfgang},
title = {Lean and efficient system software product lines: where aspects beat objects},
year = {2006},
isbn = {3540488901},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software development in the domain of embedded and deeply embedded systems is dominated by cost pressure and extremely limited hardware resources. As a result, modern concepts for separation of concerns and software reuse are widely ignored, as developers worry about the thereby induced memory and performance overhead. Especially object-oriented programming (OOP) is still little in demand. For the development of highly configurable fine-grained system software product lines, however, separation of concerns (SoC) is a crucial property. As the overhead of object-orientation is not acceptable in this domain, we propose aspect-oriented programming (AOP) as an alternative. Compared to OOP, AOP makes it possible to reach similar or even better separation of concerns with significantly smaller memory footprints. In a case study for an embedded system product line the memory costs for SoC could be reduced from 148–236% to 2–10% by using AOP instead of OOP.},
booktitle = {Transactions on Aspect-Oriented Software Development II},
pages = {227–255},
numpages = {29}
}

@article{10.1016/j.sysarc.2016.12.005,
author = {Stoicescu, Miruna and Fabre, Jean-Charles and Roy, Matthieu},
title = {Architecting resilient computing systems},
year = {2017},
issue_date = {February 2017},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {73},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2016.12.005},
doi = {10.1016/j.sysarc.2016.12.005},
abstract = {Evolution of systems during their operational life is mandatory and both updates and upgrades should not impair their dependability properties. Dependable systems must evolve to accommodate changes, such as new threats and undesirable events, application updates or variations in available resources. A system that remains dependable when facing changes is called resilient. In this paper, we present an innovative approach taking advantage of component-based software engineering technologies for tackling the on-line adaptation of fault tolerance mechanisms. We propose a development process that relies on two key factors: designing fault tolerance mechanisms for adaptation and leveraging a reflective component-based middleware enabling fine-grained control and modification of the software architecture at runtime. We thoroughly describe the methodology, the development of adaptive fault tolerance mechanisms and evaluate the approach in terms of performance and agility.},
journal = {J. Syst. Archit.},
month = feb,
pages = {6–16},
numpages = {11},
keywords = {Runtime reconfiguration, Fault tolerance, Dependability, Component-based middleware, Adaptivity}
}

@article{10.1016/j.infsof.2019.04.003,
author = {Rodrigues, Gabriel S. and Guimar\~{a}es, Felipe P. and Rodrigues, Gena\'{\i}na N. and Knauss, Alessia and de Ara\'{u}jo, Jo\~{a}o Paulo C. and Andrade, Hugo and Ali, Raian},
title = {GoalD: A Goal-Driven deployment framework for dynamic and heterogeneous computing environments},
year = {2019},
issue_date = {Jul 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {111},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.04.003},
doi = {10.1016/j.infsof.2019.04.003},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {159–176},
numpages = {18},
keywords = {Deployment planning, Heterogeneous computational resources, Contextual goal modelling, Autonomous deployment}
}

@inproceedings{10.1145/2661136.2661143,
author = {Walkingshaw, Eric and K\"{a}stner, Christian and Erwig, Martin and Apel, Sven and Bodden, Eric},
title = {Variational Data Structures: Exploring Tradeoffs in Computing with Variability},
year = {2014},
isbn = {9781450332101},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661136.2661143},
doi = {10.1145/2661136.2661143},
abstract = {Variation is everywhere, and in the construction and analysis of customizable software it is paramount. In this context, there arises a need for variational data structures for efficiently representing and computing with related variants of an underlying data type. So far, variational data structures have been explored and developed ad hoc. This paper is a first attempt and a call to action for systematic and foundational research in this area. Research on variational data structures will benefit not only customizable software, but many other application domains that must cope with variability. In this paper, we show how support for variation can be understood as a general and orthogonal property of data types, data structures, and algorithms. We begin a systematic exploration of basic variational data structures, exploring the tradeoffs among different implementations. Finally, we retrospectively analyze the design decisions in our own previous work where we have independently encountered problems requiring variational data structures.},
booktitle = {Proceedings of the 2014 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming &amp; Software},
pages = {213–226},
numpages = {14},
keywords = {variation, variability-aware analyses, software product lines, data structures, configurable software},
location = {Portland, Oregon, USA},
series = {Onward! 2014}
}

@article{10.1007/s10009-012-0225-2,
author = {Tartler, Reinhard and Sincero, Julio and Dietrich, Christian and Schr\"{o}der-Preikschat, Wolfgang and Lohmann, Daniel},
title = {Revealing and repairing configuration inconsistencies in large-scale system software},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-012-0225-2},
doi = {10.1007/s10009-012-0225-2},
abstract = {System software typically offers a large amount of compile-time options and variability. A good example is the Linux kernel, which provides more than 10,000 configurable features, growing rapidly. This allows users to tailor it with respect to a broad range of supported hardware architectures and application domains. From the maintenance point of view, compile-time configurability poses big challenges. The configuration model (the selectable features and their constraints as presented to the user) and the configurability that is actually implemented in the code have to be kept in sync, which, if performed manually, is a tedious and error-prone task. In the case of Linux, this has led to numerous defects in the source code, many of which are actual bugs. In order to ensure consistency between the variability expressed in the code and the configuration models, we propose an approach that extracts variability from both into propositional logic. This reveals inconsistencies between variability as expressed by the C Preprocessor (CPP) and an explicit variability model, which manifest themselves in seemingly conditional code that is in fact unconditional. We evaluate our approach with the Linux, for which our tool detects 1,766 configurability defects, which turned out as dead/superfluous source code and bugs. Our findings have led to numerous source-code improvements and bug fixes in Linux: 123 patches (49 merged) fix 364 defects, 147 of which have been confirmed by the corresponding Linux developers and 20 as fixing a previously unknown bug.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {531–551},
numpages = {21},
keywords = {Static analysis, Management, Maintenance, Linux, Experimentation, Configurability}
}

@article{10.1007/s00607-018-0679-5,
author = {Cai, Simin and Gallina, Barbara and Nystr\"{o}m, Dag and Seceleanu, Cristina},
title = {Data aggregation processes: a survey, a taxonomy, and design guidelines},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {101},
number = {10},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-018-0679-5},
doi = {10.1007/s00607-018-0679-5},
abstract = {Data aggregation processes are essential constituents for data management in modern computer systems, such as decision support systems and Internet of Things systems, many with timing constraints. Understanding the common and variable features of data aggregation processes, especially their implications to the time-related properties, is key to improving the quality of the designed system and reduce design effort. In this paper, we present a survey of data aggregation processes in a variety of application domains from literature. We investigate their common and variable features, which serves as the basis of our previously proposed taxonomy called DAGGTAX. By studying the implications of the DAGGTAX features, we formulate a set of constraints to be satisfied during design, which helps to check the correctness of the specifications and reduce the design space. We also provide a set of design heuristics that could help designers to decide the appropriate mechanisms for achieving the selected features. We apply DAGGTAX on industrial case studies, showing that DAGGTAX not only strengthens the understanding, but also serves as the foundation of a design tool which facilitates the model-driven design of data aggregation processes.},
journal = {Computing},
month = oct,
pages = {1397–1429},
numpages = {33},
keywords = {Data modeling, Real-time data management, Data aggregation taxonomy}
}

@inproceedings{10.1145/1326304.1326318,
author = {Smith, Thomas M. and Bond, Gregory W.},
title = {ECharts for SIP servlets: a state-machine programming environment for VoIP applications},
year = {2007},
isbn = {9781605580067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1326304.1326318},
doi = {10.1145/1326304.1326318},
abstract = {The development of telecommunication applications that require multiple call legs is often complex due to their event-driven nature as well as the significant amount of state that must be maintained. In general, the state associated with different call legs within an application instance differs and must be separately maintained; in addition, (non-call related) application state is often required. As a means of managing all the required state information, application developers often implement ad-hoc state machine programming constructs within the application.This paper describes an alternate approach, wherein the application logic is written in ECharts, an open-source state-machine programming language, and translated into SIP Servlet applications which can be deployed and executed on any standards-compliant container. This approach can yield great benefits for complex applications, including reusability, increased maintainability, and the prospect of program analysis.},
booktitle = {Proceedings of the 1st International Conference on Principles, Systems and Applications of IP Telecommunications},
pages = {89–98},
numpages = {10},
keywords = {telecommunications, state machine programming, VoIP applications, UML statecharts, SIP servlets, ECharts},
location = {New York City, New York},
series = {IPTComm '07}
}

@inproceedings{10.1145/1639950.1640002,
author = {Mendonca, Marcilio and Branco, Moises and Cowan, Donald},
title = {S.P.L.O.T.: software product lines online tools},
year = {2009},
isbn = {9781605587684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1639950.1640002},
doi = {10.1145/1639950.1640002},
abstract = {This paper introduces S.P.L.O.T., a Web-based reasoning and configuration system for Software Product Lines (SPLs). The system benefits from mature logic-based reasoning techniques such as SAT solvers and binary decision diagrams to provide efficient reasoning and interactive configuration services to SPL researchers and practitioners. In addition, the system provides a feature model repository containing real and generated models to encourage knowledge sharing among researchers in the field.},
booktitle = {Proceedings of the 24th ACM SIGPLAN Conference Companion on Object Oriented Programming Systems Languages and Applications},
pages = {761–762},
numpages = {2},
keywords = {software product lines, interactive configuration, feature models, feature model automated analysis, automated reasoning},
location = {Orlando, Florida, USA},
series = {OOPSLA '09}
}

@inproceedings{10.5555/646781.705927,
author = {Pulvermueller, Elke and Speck, Andreas and Coplien, James and D'Hondt, Maja and Meuter, Wolfgang De},
title = {Feature Interaction in Composed Systems},
year = {2001},
isbn = {3540436758},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The history of computer science has shown that decomposing software applications helps managing their complexity and facilitates reuse, but also bears challenging problems still unsolved, such as the assembly of the decomposed features when non-trivial feature interactions are involved. Examples of features include concerns or aspects, black box or white box components, and functional and non-functional requirements. Approaches such as object-oriented and component-based software development, as well as relatively new directions such as aspect-oriented programming, multi-dimensional separation of concerns and generative programming, all provide technical support for the definition and syntactical assembly of features, but fall short on the semantic level, for example in spotting meaningless or even faulty combinations. At previous ECOOPs, OOPSLAsand GCSEs dedicated events have been organised around the aforementioned technologies, where we experienced a growing awareness of this feature interaction problem. However, feature interaction is often merely dismissed as a secondary problem, percolating as an afterthought while other issues are being addressed. The intention of this workshop was to be the first co-ordinated effort to address the general problem of feature interaction in composed systems separately from other issues.},
booktitle = {Proceedings of the Workshops on Object-Oriented Technology},
pages = {86–97},
numpages = {12},
series = {ECOOP '01}
}

@article{10.1007/s10845-011-0544-2,
author = {Yang, Dong and Dong, Ming},
title = {Applying constraint satisfaction approach to solve product configuration problems with cardinality-based configuration rules},
year = {2013},
issue_date = {February  2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-011-0544-2},
doi = {10.1007/s10845-011-0544-2},
abstract = {In this paper, the product configuration problems that are characterized by cardinality-based configuration rules are dealt with. Novel configuration rules including FI and EI rules are presented to clarify the semantics of inclusion rules when cardinalities and hierarchies of products are encountered. Then, a configuration graph is proposed to visualize structural rules and configuration rules in product configuration problem. An encoding approach is elaborated to transform the configuration graph as a CSP (Constraint Satisfaction Problem). As a consequence, existing CSP solver, i.e. JCL (Java Constraint Library), is employed to implement the configuration system for product configuration problem with cardinality-related configuration rules. A case study of a bus configuration is used throughout this paper to illustrate the effectiveness of the presented approach.},
journal = {J. Intell. Manuf.},
month = feb,
pages = {99–111},
numpages = {13},
keywords = {Product configuration, Mass customization, Constraint satisfaction}
}

@article{10.1145/2439976.2439982,
author = {Tiwari, Rajeev and Goel, Noopur},
title = {Reuse: reducing test effort},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2439976.2439982},
doi = {10.1145/2439976.2439982},
abstract = {Testing effort consumes more than half of all development effort and is one of the important factors, which obstruct quality assurance. Software reuse enhances quality and productivity and at the same time reduces the time-to-market of the software products. As reuse applies to the development process, so too, it applies to the testing process. In this paper, we discuss reuse-oriented test approaches, which are used to reduce the testing effort. Further, we present the state-of-the-art in reuse-oriented test approaches employed in reuseoriented development processes. At the end of the current paper, we argue that the current trend is towards built-in test and model based testing in the applications developed through reusable software.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {1–11},
numpages = {11},
keywords = {test effort, software product lines, reuse-oriented test approaches, reusable test cases}
}

@article{10.5555/2594914.2594918,
author = {Campagna, Dario and Formisano, Andrea},
title = {Product and Production Process Modeling and Configuration},
year = {2013},
issue_date = {October 2013},
publisher = {IOS Press},
address = {NLD},
volume = {124},
number = {4},
issn = {0169-2968},
abstract = {Product configuration systems are an emerging technology that supports companies in deploying mass customization strategies. Such strategies need to cover the management of the whole customizable product cycle. Adding process modeling and configuration features to a product configurator may improve its ability to assist mass customization development. In this paper, we describe a modeling framework, PRODPROC, that allows one to model both a product and its production process. We first introduce our framework by describing how configurable products are modeled. Then, we describe the main features and capabilities offered to model production processes and to link them with the corresponding products models. The configuration task namely, the procedure that, from a configurable object/activity generates a configured product/process is then analyzed. We also outline a possible CSP-based implementation of a configurator. A comparison with some of the existing systems for product configuration and process modeling emphasizes that none of the considered system/tools offers the complete set of features supported by PRODPROC for interdependent product and process modeling/configuration.},
journal = {Fundam. Inf.},
month = oct,
pages = {403–425},
numpages = {23},
keywords = {Product And Process Modeling Languages, Configuration Of Product/Process Models}
}

@inproceedings{10.1145/508386.508395,
author = {Cardone, Richard and Brown, Adam and McDirmid, Sean and Lin, Calvin},
title = {Using mixins to build flexible widgets},
year = {2002},
isbn = {158113469X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/508386.508395},
doi = {10.1145/508386.508395},
abstract = {When it comes to software that runs on devices as varied as cell phones, PDAs and desktops, one size does not fit all. This paper describes how mixin layers, a kind of nested generic type, can be used to implement a graphical user interface library that can be configured to run on platforms with widely dissimilar capabilities. We describe the language support needed to incrementally build software in layers, and we describe how crosscutting concerns can be encapsulated within a layer. We then show how layers can be reconfigured to meet changing requirements. We also show how a new design pattern, the Sibling pattern, can be used with mixin layers to coordinate changes to multiple classes in the same inheritance hierarchy. When used appropriately, the Sibling pattern increases our ability to separate design concerns and to reuse code.},
booktitle = {Proceedings of the 1st International Conference on Aspect-Oriented Software Development},
pages = {76–85},
numpages = {10},
keywords = {parametric polymorphism, mixin, layers, embedded software, design pattern, GUI},
location = {Enschede, The Netherlands},
series = {AOSD '02}
}

@inproceedings{10.1145/1297846.1297969,
author = {Abi-Antoun, Marwan},
title = {Making frameworks work: a project retrospective},
year = {2007},
isbn = {9781595938657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1297846.1297969},
doi = {10.1145/1297846.1297969},
abstract = {Various issues make framework development harder than regular development. Building product lines and frameworks requires increased coordination and communication between stakeholders and across the organization.The difficulty of building the right abstractions ranges from understanding the domain models, selecting and evaluating the framework architecture, to designing the right interfaces, and adds to the complexity of a framework project.},
booktitle = {Companion to the 22nd ACM SIGPLAN Conference on Object-Oriented Programming Systems and Applications Companion},
pages = {1004–1018},
numpages = {15},
keywords = {product lines, object-oriented frameworks, experience report},
location = {Montreal, Quebec, Canada},
series = {OOPSLA '07}
}

@inproceedings{10.1145/2897053.2897062,
author = {McGee, Ethan T. and McGregor, John D.},
title = {Using dynamic adaptive systems in safety-critical domains},
year = {2016},
isbn = {9781450341875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897053.2897062},
doi = {10.1145/2897053.2897062},
abstract = {The development of safety-critical Cyber-Physical Systems (CPS) is expanding due to the Internet of Things' promise to make high-integrity applications and services part of everyday life. This expansion is seen in the dependencies some connected vehicles have on cloud services that provide guidance and accident avoidance / detection features. Such systems are safety-critical since failure could result in serious injury or death. Due to the severe consequences of failure, fault-tolerance, reliability and dependability should be primary driving qualities in the design and development of these systems. However, the cost of the analysis, evaluation and certification activities needed to ensure that the possibility of failure has been sufficiently mitigated is significantly higher than the cost of developing traditional software.Our group is exploring the addition of dynamic adaptive capabilities to safety-critical systems. We postulate that dynamic adaptivity could provide several enhancements to safety-critical systems. It would allow systems to reason about the environment within which they are sited and about their internal operation enabling decision making that is context-specific and appropriately prioritized. However, the addition of adaptivity with the associated overhead of reasoning is not without drawbacks particularly when hard real-time safety-critical systems are involved. In this brief position paper, we explore some of the questions and concerns that are raised when dynamic adaptive behavior is introduced into safety-critical systems as well as ways that the Architecture Analysis &amp; Design Language (AADL) can be used to model / analyze such systems.},
booktitle = {Proceedings of the 11th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {115–121},
numpages = {7},
keywords = {software product lines, safety critical systems, dynamic software product lines, dynamic adaptive systems},
location = {Austin, Texas},
series = {SEAMS '16}
}

@inproceedings{10.1145/1808937.1808943,
author = {Maman, Itay and Botterweck, Goetz},
title = {SPLGraph: towards a graph-based formalism for software product lines},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808943},
doi = {10.1145/1808937.1808943},
abstract = {This paper presents SPLGraph a graph-based model for Software Product Lines, including (1) a formal definition; (2) an algorithm that applies configuration decisions to an SPLGraph thus yielding a product specific graph; (3) a set of patterns for typical SPLGraph structures, such as Boolean operators, reuse of expressions, named configurations, optional and alternative features and staged configuration; and (4) an algorithm that infers product configuration per a variability point.SPLGraph is generic, simple, and self sustaining in the sense that an SPLGraph instance can apply variability to itself. These properties make SPLGraph a basis for a solid and complete formalism for Software Product Lines.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {40–47},
numpages = {8},
keywords = {variability modeling, software product lines, graph},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@article{10.14778/3007263.3007272,
author = {Jacques-Silva, Gabriela and Zheng, Fang and Debrunner, Daniel and Wu, Kun-Lung and Dogaru, Victor and Johnson, Eric and Spicer, Michael and Sariy\"{u}ce, Ahmet Erdem},
title = {Consistent regions: guaranteed tuple processing in IBM streams},
year = {2016},
issue_date = {September 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/3007263.3007272},
doi = {10.14778/3007263.3007272},
abstract = {Guaranteed tuple processing has become critically important for many streaming applications. This paper describes how we enabled IBM Streams, an enterprise-grade stream processing system, to provide data processing guarantees. Our solution goes from language-level abstractions to a runtime protocol. As a result, with a couple of simple annotations at the source code level, IBM Streams developers can define consistent regions, allowing any subgraph of their streaming application to achieve guaranteed tuple processing. At runtime, a consistent region periodically executes a variation of the Chandy-Lamport snapshot algorithm to establish a consistent global state for that region. The coupling of consistent states with data replay enables guaranteed tuple processing.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {1341–1352},
numpages = {12}
}

@article{10.1145/3280848,
author = {Pereira, Fernando Magno Quint\~{a}o and Leobas, Guilherme Vieira and Gamati\'{e}, Abdoulaye},
title = {Static Prediction of Silent Stores},
year = {2018},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3280848},
doi = {10.1145/3280848},
abstract = {A store operation is called “silent” if it writes in memory a value that is already there. The ability to detect silent stores is important, because they might indicate performance bugs, might enable code optimizations, and might reveal opportunities of automatic parallelization, for instance. Silent stores are traditionally detected via profiling tools. In this article, we depart from this methodology and instead explore the following question: is it possible to predict silentness by analyzing the syntax of programs? The process of building an answer to this question is interesting in itself, given the stochastic nature of silent stores, which depend on data and coding style. To build such an answer, we have developed a methodology to classify store operations in terms of syntactic features of programs. Based on such features, we develop different kinds of predictors, some of which go much beyond what any trivial approach could achieve. To illustrate how static prediction can be employed in practice, we use it to optimize programs running on nonvolatile memory systems.},
journal = {ACM Trans. Archit. Code Optim.},
month = nov,
articleno = {44},
numpages = {26},
keywords = {static analysis, nonvolatile memory, machine learning, code optimization, Silent stores}
}

@inproceedings{10.1145/1363686.1363715,
author = {Mendon\c{c}a, Marc\'{\i}lio and Bartolomei, Thiago Tonelli and Cowan, Donald},
title = {Decision-making coordination in collaborative product configuration},
year = {2008},
isbn = {9781595937537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1363686.1363715},
doi = {10.1145/1363686.1363715},
abstract = {In Software Product Lines (SPLs), product configuration is a decision-making process in which a group of stakeholders choose features for a product. Unfortunately, current configuration technology is essentially single-user-based in which user requirements are interpreted and translated into configuration decisions by a single role commonly referred to as the product manager. This process can be error-prone and time-consuming as it commonly requires back-and-forth interactions between the product manager and the stakeholders to cope with decision conflicts. In this paper, we propose an approach to Collaborative Product Configuration (CPC) that aims at providing effective support for coordinating teamwork decision-making in the context of product configuration. The approach builds on well-known concepts in the SPL arena such as feature models. The contributions of the paper include the CPC approach and the illustration of its application in a real-world product line.},
booktitle = {Proceedings of the 2008 ACM Symposium on Applied Computing},
pages = {108–113},
numpages = {6},
keywords = {workflows, work coordination, software product lines, feature models, collaborative product configuration},
location = {Fortaleza, Ceara, Brazil},
series = {SAC '08}
}

@inproceedings{10.5555/645417.652071,
author = {Bosch, Jan and H\"{o}gstr\"{o}m, Mattias},
title = {Product Instantiation in Software Product Lines: A Case Study},
year = {2000},
isbn = {3540425780},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product instantiation is one of the less frequently studied activities in the domain of software product lines. In this paper, we present the results of a case study at Axis Communication AB on product instantiation in an industrial product line, i.e. five problems and three issues. The problems are concerned the insufficiency of functional commonality, features spanning multiple components, the exclusion of unwanted features, the evolution of product line components and the handling of initialization code. The issues discuss architectural compliance versus product instantiation effort, quick-fixes versus properly engineered extensions and component instantiation support versus product instantiation effort. The identified problems and issues are based on the case study, but have been generalized to apply to a wider context.},
booktitle = {Proceedings of the Second International Symposium on Generative and Component-Based Software Engineering-Revised Papers},
pages = {147–162},
numpages = {16},
series = {GCSE '00}
}

@inproceedings{10.1145/268084.268194,
author = {Haddad, Hisham and Tesser, Herbert and Wartik, Steven},
title = {Megaprogramming education},
year = {1997},
isbn = {0897918894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/268084.268194},
doi = {10.1145/268084.268194},
abstract = {In the computer science field, educators face several obstacles when attempting to introduce rigorous software engineering concepts and practices into the curriculum. This paper addresses the issue of software engineering education and the role of megaprogramming in introductory courses for high school and college students. We highlight the need for, and the initial effort in megaprogramming education. We provide a brief description of developed materials and a proposed approach to integrate megaprogramming into high school computer science curriculum.},
booktitle = {Proceedings of the Twenty-Eighth SIGCSE Technical Symposium on Computer Science Education},
pages = {282–286},
numpages = {5},
location = {San Jose, California, USA},
series = {SIGCSE '97}
}

@inproceedings{10.1145/3180155.3180163,
author = {Guo, Jianmei and Shi, Kai},
title = {To preserve or not to preserve invalid solutions in search-based software engineering: a case study in software product lines},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180163},
doi = {10.1145/3180155.3180163},
abstract = {Multi-objective evolutionary algorithms (MOEAs) have been successfully applied for software product lines (SPLs) to search for optimal or near-optimal solutions that balance multiple objectives. However, MOEAs usually produce invalid solutions that violate the constraints predefined. As invalid solutions are unbuildable in practice, we debate the preservation of invalid solutions during the search. We conduct experiments on seven real-world SPLs, including five largest SPLs hitherto reported and two SPLs with realistic values and constraints of quality attributes. We identify three potential limitations of preserving invalid solutions. Furthermore, based on the state-of-the-art, we design five algorithm variants that adopt different evolutionary operators. By performance evaluation, we provide empirical guidance on how to preserve valid solutions. Our empirical study demonstrates that whether or not to preserve invalid solutions deserves more attention in the community, and in some cases, we have to preserve valid solutions all along the way.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1027–1038},
numpages = {12},
keywords = {constraint solving, multi-objective evolutionary algorithms, search-based software engineering, software product lines, validity},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1007/s10664-017-9557-6,
author = {Dintzner, Nicolas and Deursen, Arie and Pinzger, Martin},
title = {FEVER: An approach to analyze feature-oriented changes and artefact co-evolution in highly configurable systems},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9557-6},
doi = {10.1007/s10664-017-9557-6},
abstract = {The evolution of highly configurable systems is known to be a challenging task. Thorough understanding of configuration options their relationships, and their implementation in various types of artefacts (variability model, mapping, and implementation) is required to avoid compilation errors, invalid products, or dead code. Recent studies focusing on co-evolution of artefacts detailed feature-oriented change scenarios, describing how related artefacts might change over time. However, relying on manual analysis of commits, such work do not provide the means to obtain quantitative information on the frequency of described scenarios nor information on the exhaustiveness of the presented scenarios for the evolution of a large scale system. In this work, we propose FEVER and its instantiation for the Linux kernel. FEVER extracts detailed information on changes in variability models (KConfig files), assets (preprocessor based C code), and mappings (Makefiles). We apply this methodology to the Linux kernel and build a dataset comprised of 15 releases of the kernel history. We performed an evaluation of the FEVER approach by manually inspecting the data and compared it with commits in the system's history. The evaluation shows that FEVER accurately captures feature related changes for more than 85% of the 810 manually inspected commits. We use the collected data to reflect on occurrences of co-evolution in practice. Our analysis shows that complex co-evolution scenarios occur in every studied release but are not among the most frequent change scenarios, as they only occur for 8 to 13% of the evolving features. Moreover, only a minority of developers working on a given release will make changes to all artefacts related to a feature (between 10% and 13% of authors). While our conclusions are derived from observations on the evolution of the Linux kernel, we believe that they may have implications for tool developers as well as guide further research in the field of co-evolution of artefacts.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {905–952},
numpages = {48},
keywords = {Variability, Highly variable systems, Feature, Co-evolution}
}

@article{10.1007/s10845-014-0917-4,
author = {Alotaibi, Youseef},
title = {Business process modelling challenges and solutions: a literature review},
year = {2016},
issue_date = {August    2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {4},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-014-0917-4},
doi = {10.1007/s10845-014-0917-4},
abstract = {We have presented a review of the challenges facing business PM. These challenges are categorized into three challenges: (1) between business and IT, difficulty of deriving IT goals from business goals challenges; (2) security issues on business PM challenges; and (3) managing customer power, the rapidly changing business environment and business process (BP) challenges. Also, it presents the limitations of existing business PM frameworks. For example, in the first challenge, the existing literature is limited because they fail to capture the real business environment. Also, it is hard for IT analysts to understand BPs. In the second challenges, the existing methods of IS development fail to successfully integrate security during all development process stages and only deal with specific security requirements, goals and constraints. In the third challenges, no research has been conducted in the area of separating customers into different priority groups to provide services according to their required delivery time, payment history and feedback. Finally, we outline possible further research directions in the business PM domain. A systematic literature review method was used. Our review reports on academic publications on business PM challenges over the 13 years from 2000 to 2012. There are 31 journals as well as the IEEE and ACM databases being searched to identify relevant papers. Our systematic literature review results in that there are 53 journal papers as being the most relevant to our topic. In conclusion, it is not easy to create a good business PM. However, the research have to pay much attention on the area of creating successful business PM by creating secure business PM, manage customer power and create business PM where IT goals can be easily derived from business goals.},
journal = {J. Intell. Manuf.},
month = aug,
pages = {701–723},
numpages = {23},
keywords = {Security, Literature review, Customer power, Business process (BP), Business Process Modelling (PM), Business Process Management (BPM), Business PM challenges, Alignment}
}

@inproceedings{10.1145/1865875.1865881,
author = {Polzer, Andreas and Hedenetz, Bernd and Merschen, Daniel and Botterweck, Goetz and Thomas, Jacques and Kowalewski, Stefan},
title = {View-supported rollout and evolution of model-based ECU applications},
year = {2010},
isbn = {9781450301237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1865875.1865881},
doi = {10.1145/1865875.1865881},
abstract = {When applying model-based techniques to the engineering of embedded application software, a typical challenge is the complexity of dependencies between application elements. In many situations, e.g., during rollout of products or in the evolution of product lines, the understanding of these dependencies is a key capability. In this paper, we discuss how model-based techniques, in particular, model transformations can help to reduce the complexity of such analysis tasks. To this end, we realised a representation of Simulink models based on the Eclipse Modeling Framework (EMF). The resulting integration allows us to apply various model-based frameworks from the Eclipse ecosystem. On this basis we developed a view that increases the visibility of functional dependencies, which otherwise would have been hidden due to a lack of abstraction in the native Simulink representation. The provided analysis framework comes in handy, when such a model has to be modified. Consequently, the developer is supported in reusing existing models and avoiding errors. The concepts and techniques are illustrated with a running example, which is derived from a real industry model from Automotive Software Engineering.},
booktitle = {Proceedings of the 7th International Workshop on Model-Based Methodologies for Pervasive and Embedded Software},
pages = {37–44},
numpages = {8},
keywords = {variability, model-based development, model transformation, automotive software, Matlab Simulink, Epsilon translation language (ETL), ATLAS transformation language (ATL)},
location = {Antwerpen, Belgium},
series = {MOMPES '10}
}

@article{10.1109/TNET.2019.2925658,
author = {Liaskos, Christos and Tsioliaridou, Ageliki and Nie, Shuai and Pitsillides, Andreas and Ioannidis, Sotiris and Akyildiz, Ian F.},
title = {On the Network-Layer Modeling and Configuration of Programmable Wireless Environments},
year = {2019},
issue_date = {August 2019},
publisher = {IEEE Press},
volume = {27},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2019.2925658},
doi = {10.1109/TNET.2019.2925658},
abstract = {Programmable wireless environments enable the software-defined propagation of waves within them, yielding exceptional performance. Several building-block technologies have been implemented and evaluated at the physical layer in the past. The present work contributes a network-layer solution to configure such environments for multiple users and objectives, and for any underlying physical-layer technology. Supported objectives include any combination of Quality of Service and power transfer optimization, eavesdropping, and Doppler effect mitigation, in multi-cast or uni-cast settings. In addition, a graph-based model of programmable environments is proposed, which incorporates core physical observations and efficiently separates physical and networking concerns. The evaluation takes place in a specially developed simulation tool, and in a variety of environments, validating the model and reaching insights into the user capacity of programmable environments.},
journal = {IEEE/ACM Trans. Netw.},
month = aug,
pages = {1696–1713},
numpages = {18}
}

@book{10.5555/2911053,
author = {Mistrik, Ivan and Soley, Richard M. and Ali, Nour and Grundy, John and Tekinerdogan, Bedir},
title = {Software Quality Assurance: In Large Scale and Complex Software-intensive Systems},
year = {2015},
isbn = {0128023015},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Software Quality Assurance in Large Scale and Complex Software-intensive Systems presents novel and high-quality research related approaches that relate the quality of software architecture to system requirements, system architecture and enterprise-architecture, or software testing. Modern software has become complex and adaptable due to the emergence of globalization and new software technologies, devices and networks. These changes challenge both traditional software quality assurance techniques and software engineers to ensure software quality when building today (and tomorrows) adaptive, context-sensitive, and highly diverse applications. This edited volume presents state of the art techniques, methodologies, tools, best practices and guidelines for software quality assurance and offers guidance for future software engineering research and practice. Each contributed chapter considers the practical application of the topic through case studies, experiments, empirical validation, or systematic comparisons with other approaches already in practice. Topics of interest include, but are not limited, to: quality attributes of system/software architectures; aligning enterprise, system, and software architecture from the point of view of total quality; design decisions and their influence on the quality of system/software architecture; methods and processes for evaluating architecture quality; quality assessment of legacy systems and third party applications; lessons learned and empirical validation of theories and frameworks on architectural quality; empirical validation and testing for assessing architecture quality.Focused on quality assurance at all levels of software design and developmentCovers domain-specific software quality assurance issues e.g. for cloud, mobile, security, context-sensitive, mash-up and autonomic systemsExplains likely trade-offs from design decisions in the context of complex software system engineering and quality assuranceIncludes practical case studies of software quality assurance for complex, adaptive and context-critical systems}
}

@article{10.1145/1118890.1118892,
author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
title = {When and how to develop domain-specific languages},
year = {2005},
issue_date = {December 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/1118890.1118892},
doi = {10.1145/1118890.1118892},
abstract = {Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage.Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, we identify patterns in the decision, analysis, design, and implementation phases of DSL development. Our patterns improve and extend earlier work on DSL design patterns. We also discuss domain analysis tools and language development systems that may help to speed up DSL development. Finally, we present a number of open problems.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {316–344},
numpages = {29},
keywords = {language development system, domain analysis, application language, Domain-specific language}
}

@article{10.4018/IJISMD.2015070102,
author = {Hosseini, Mahmood and Phalp, Keith and Taylor, Jacqui and Ali, Raian},
title = {On the Configuration of Crowdsourcing Projects},
year = {2015},
issue_date = {July 2015},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {3},
issn = {1947-8186},
url = {https://doi.org/10.4018/IJISMD.2015070102},
doi = {10.4018/IJISMD.2015070102},
abstract = {Crowdsourcing is an emerging paradigm, facilitated by the ease and scale of online connectivity, which harnesses the power of the crowds to solve problems and contribute knowledge. Crowdsourcing has been tried in practice and there are several commercial general-purpose crowdsourcing platforms on the web. Although the paradigm feasibility and impact have become evident, we still lack engineering methods and principles which aid the construction of quality crowdsourcing-based solutions. One of these aspects is the compatibility between the various configuration choices of the elements of a crowdsourcing project. In a previous work, the authors surveyed the literature and extracted a taxonomy of the various features which describes each of the four pillars of crowdsourcing: the crowd, the crowdsourcer, the crowdsourced task and the crowdsourcing platform. In this paper, the authors study the inter-relations between these features when configuring a crowdsourcing project. They start with an initial template and then confirm and enhance it by an expert study which involves 37 experts who applied crowdsourcing in practice and published research results. Their study helps crowdsourcers and crowdsourcing platform developers to better understand the several peculiarities that may arise by combining these features and thus assist them in the configuration of crowdsourcing projects with more awareness.},
journal = {Int. J. Inf. Syst. Model. Des.},
month = jul,
pages = {27–45},
numpages = {19}
}

@article{10.1016/j.is.2005.05.003,
author = {Rosemann, M. and van der Aalst, W. M. P.},
title = {A configurable reference modelling language},
year = {2007},
issue_date = {March, 2007},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {32},
number = {1},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2005.05.003},
doi = {10.1016/j.is.2005.05.003},
abstract = {Enterprise Systems (ES) are comprehensive off-the-shelf packages that have to be configured to suit the requirements of an organization. Most ES solutions provide reference models that describe the functionality and structure of the system. However, these models do not capture the potential configuration alternatives. This paper discusses the shortcomings of current reference modelling languages using Event-Driven Process Chains (EPCs) as an example. We propose Configurable EPCs (C-EPCs) as an extended reference modelling language which allows capturing the core configuration patterns. A formalization of this language as well as examples for typical configurations are provided. A program of further research including the identification of a comprehensive list of configuration patterns, deriving possible notations for reference model configurations and testing the quality of these proposed extensions in experiments and focus groups is presented.},
journal = {Inf. Syst.},
month = mar,
pages = {1–23},
numpages = {23},
keywords = {Reference model, Event-Driven Process Chains, Enterprise systems, Configuration}
}

@inproceedings{10.1145/1866272.1866282,
author = {Kapova, Lucia and Goldschmidt, Thomas and Happe, Jens and Reussner, Ralf H.},
title = {Domain-specific templates for refinement transformations},
year = {2010},
isbn = {9781450302920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866272.1866282},
doi = {10.1145/1866272.1866282},
abstract = {Model transformations are a major instrument of model-driven software development. Especially in declarative transformation approaches, the structuring of transformations depends to a large extent on the structure of the source models and the generated artefacts. In many cases, similar code is written for transformations that deal with the same source or target metamodel. Writing such transformations can be simplified significantly if re-occurring parts within the transformation rules can be specified in a reusable way. Current approaches to transformation development include means for transformation reuse as well as inheritance. However, modularisation along the boundaries of different parts of domain metamodels is still lacking. Furthermore, the possibilities to reuse transformation fragments that re-occur in multiple transformations is limited. In this paper, we introduce domain-specific templates for refinement transformations with well-defined variation points. Transformation templates are based on known design patterns and enable a modular specification of refinement transformations and thus yield a simpler definition of transformations that can be grasped more easily and developed more efficiently. In addition, we present a real-world case study of transformation templates in the context of component based software architectures. The case study gives insight into the application of the presented approach.},
booktitle = {Proceedings of the First International Workshop on Model-Driven Interoperability},
pages = {69–78},
numpages = {10},
keywords = {templates, software architecture, refinement transformations, higher-order transformations},
location = {Oslo, Norway},
series = {MDI '10}
}

@inproceedings{10.1145/2486046.2486068,
author = {Scacchi, Walt and Alspaugh, Thomas A.},
title = {Processes in securing open architecture software systems},
year = {2013},
isbn = {9781450320627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2486046.2486068},
doi = {10.1145/2486046.2486068},
abstract = {Our goal is to identify and understand issues that arise in the development and evolution processes for securing open architecture (OA) software systems. OA software systems are those developed with a mix of closed source and open source software components that are configured via an explicit system architectural specification. Such a specification may serve as a reference model or product line model for a family of concurrently sustained OA system versions/variants. We employ a case study focusing on an OA software system whose security must be continually sustained throughout its ongoing development and evolution. We limit our focus to software processes surrounding the architectural design, continuous integration, release deployment, and evolution found in the OA system case study. We also focus on the role automated tools, software development support mechanisms, and development practices play in facilitating or constraining these processes through the case study. Our purpose is to identify issues that impinge on modeling (specification) and integration of these processes, and how automated tools mediate these processes, as emerging research problems areas for the software process research community. Finally, our study is informed by related research found in the prescriptive versus descriptive practice of these processes and tool usage in studies of conventional and open source software development projects.},
booktitle = {Proceedings of the 2013 International Conference on Software and System Process},
pages = {126–135},
numpages = {10},
keywords = {Open architecture, configuration, continuous software development, process integration, process modeling, security},
location = {San Francisco, CA, USA},
series = {ICSSP '13}
}

@article{10.14778/2367502.2367521,
author = {Jacques-Silva, Gabriela and Gedik, Bu\u{g}ra and Wagle, Rohit and Wu, Kun-Lung and Kumar, Vibhore},
title = {Building user-defined runtime adaptation routines for stream processing applications},
year = {2012},
issue_date = {August 2012},
publisher = {VLDB Endowment},
volume = {5},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2367502.2367521},
doi = {10.14778/2367502.2367521},
abstract = {Stream processing applications are deployed as continuous queries that run from the time of their submission until their cancellation. This deployment mode limits developers who need their applications to perform runtime adaptation, such as algorithmic adjustments, incremental job deployment, and application-specific failure recovery. Currently, developers do runtime adaptation by using external scripts and/or by inserting operators into the stream processing graph that are unrelated to the data processing logic. In this paper, we describe a component called orchestrator that allows users to write routines for automatically adapting the application to runtime conditions. Developers build an orchestrator by registering and handling events as well as specifying actuations. Events can be generated due to changes in the system state (e.g., application component failures), built-in system metrics (e.g., throughput of a connection), or custom application metrics (e.g., quality score). Once the orchestrator receives an event, users can take adaptation actions by using the orchestrator actuation APIs. We demonstrate the use of the orchestrator in IBM's System S in the context of three different applications, illustrating application adaptation to changes on the incoming data distribution, to application failures, and on-demand dynamic composition.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1826–1837},
numpages = {12}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/336512.336546,
author = {Lamsweerde, Axel van},
title = {Formal specification: a roadmap},
year = {2000},
isbn = {1581132530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/336512.336546},
doi = {10.1145/336512.336546},
booktitle = {Proceedings of the Conference on The Future of Software Engineering},
pages = {147–159},
numpages = {13},
location = {Limerick, Ireland},
series = {ICSE '00}
}

@inproceedings{10.1007/978-3-642-39038-8_28,
author = {Auerbach, Josh and Bacon, Dave F. and Cheng, Perry and Fink, Steve and Rabbah, Rodric},
title = {The shape of things to run: compiling complex stream graphs to reconfigurable hardware in lime},
year = {2013},
isbn = {9783642390371},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39038-8_28},
doi = {10.1007/978-3-642-39038-8_28},
abstract = {Reconfigurable hardware can deliver impressive performance for some applications, when a highly static hardware design closely matches application logic. Obliged to express efficient static hardware structures, hardware designers cannot currently employ abstractions using dynamic features of modern programming languages.We present the design and implementation of new features in the Lime programming language that admit construction of stream graphs of arbitrary shape using the expressive power of an imperative, object-oriented language. The Lime programmer marks computations destined for hardware, and the compiler statically checks these computations for repeatable structure. If the check succeeds, the system guarantees it can extract the static structure needed for hardware synthesis.We describe the language design in detail and present case studies of 10 Lime benchmarks, each successfully synthesized to a Xilinx Virtex 5 FPGA.},
booktitle = {Proceedings of the 27th European Conference on Object-Oriented Programming},
pages = {679–706},
numpages = {28},
location = {Montpellier, France},
series = {ECOOP'13}
}

@inproceedings{10.1145/1966445.1966451,
author = {Tartler, Reinhard and Lohmann, Daniel and Sincero, Julio and Schr\"{o}der-Preikschat, Wolfgang},
title = {Feature consistency in compile-time-configurable system software: facing the linux 10,000 feature problem},
year = {2011},
isbn = {9781450306348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966445.1966451},
doi = {10.1145/1966445.1966451},
abstract = {Much system software can be configured at compile time to tailor it with respect to a broad range of supported hardware architectures and application domains. A good example is the Linux kernel, which provides more than 10,000 configurable features, growing rapidly.From the maintenance point of view, compile-time configurability imposes big challenges. The configuration model (the selectable features and their constraints as presented to the user) and the configurability that is actually implemented in the code have to be kept in sync, which, if performed manually, is a tedious and error-prone task. In the case of Linux, this has led to numerous defects in the source code, many of which are actual bugs.We suggest an approach to automatically check for configurability-related implementation defects in large-scale configurable system software. The configurability is extracted from its various implementation sources and examined for inconsistencies, which manifest in seemingly conditional code that is in fact unconditional. We evaluate our approach with the latest version of Linux, for which our tool detects 1,776 configurability defects, which manifest as dead/superfluous source code and bugs. Our findings have led to numerous source-code improvements and bug fixes in Linux: 123 patches (49 merged) fix 364 defects, 147 of which have been confirmed by the corresponding Linux developers and 20 as fixing a new bug.},
booktitle = {Proceedings of the Sixth Conference on Computer Systems},
pages = {47–60},
numpages = {14},
keywords = {vamos, static analysis, maintenance, linux, configurability},
location = {Salzburg, Austria},
series = {EuroSys '11}
}

@article{10.1023/A:1013303202532,
author = {Port, Dan and Dincel, Ebru},
title = {Experiences Using Domain Specific Techniques within Multimedia Software Engineering},
year = {2001},
issue_date = {December 2001},
publisher = {J. C. Baltzer AG, Science Publishers},
address = {USA},
volume = {12},
number = {1},
issn = {1022-7091},
url = {https://doi.org/10.1023/A:1013303202532},
doi = {10.1023/A:1013303202532},
abstract = {Domain specific techniques take advantage of the commonalities among applications developed within a certain domain. They are known to improve quality and productivity by incorporating domain knowledge and previous project experiences and promote reuse. This paper describes six domain specific software engineering techniques for developing multimedia applications within the digital library domain. We provide examples of each technique from several projects in which they were used, how the techniques are used within general software engineering practice (in particular, MBASE), how the techniques address some of the particular challenges multimedia software engineering, and the positive impacts we have measured resulting from their use within a graduate level software engineering course.},
journal = {Ann. Softw. Eng.},
month = dec,
pages = {11–45},
numpages = {35}
}

@inproceedings{10.1007/11526988_9,
author = {A\ss{}mann, Uwe},
title = {Reuse in semantic applications},
year = {2005},
isbn = {3540278281},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11526988_9},
doi = {10.1007/11526988_9},
abstract = {Applications using semantic technology are not fundamentally different from other software products. As standard applications, they need a well-defined development process, an appropriate modelling technology, and, to decrease construction cost, a good reuse technology for models and components. This paper shows that employing ontologies can help to enlarge the reuse factor. Ontologies improve the refinement process in object-oriented software development, simplify design of product lines, improve interoperability in component-based systems, and help in service-based applications, such as web services. Hence, ontologies will play an important role in the future engineering of software products.},
booktitle = {Proceedings of the First International Conference on Reasoning Web},
pages = {290–304},
numpages = {15},
location = {Msida, Malta}
}

@inproceedings{10.1145/1621607.1621634,
author = {Kuhlemann, Martin and Batory, Don and K\"{a}stner, Christian},
title = {Safe composition of non-monotonic features},
year = {2009},
isbn = {9781605584942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1621607.1621634},
doi = {10.1145/1621607.1621634},
abstract = {Programs can be composed from features. We want to verify automatically that all legal combinations of features can be composed safely without errors. Prior work on this problem assumed that features add code monotonically. We generalize prior work to enable features to add and remove code, describe our analyses and implementation, and review case studies. We observe that more expressive features increase the complexity of developed programs rapidly -- up to the point where tools and automated concepts as presented in this paper are indispensable for verification.},
booktitle = {Proceedings of the Eighth International Conference on Generative Programming and Component Engineering},
pages = {177–186},
numpages = {10},
keywords = {safe composition, refactoring, feature-oriented programming, AHEAD},
location = {Denver, Colorado, USA},
series = {GPCE '09}
}

@article{10.1007/s10270-015-0503-z,
author = {Dur\'{a}n, Amador and Benavides, David and Segura, Sergio and Trinidad, Pablo and Ruiz-Cort\'{e}s, Antonio},
title = {FLAME: a formal framework for the automated analysis of software product lines validated by automated specification testing},
year = {2017},
issue_date = {October   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0503-z},
doi = {10.1007/s10270-015-0503-z},
abstract = {In a literature review on the last 20 years of automated analysis of feature models, the formalization of analysis operations was identified as the most relevant challenge in the field. This formalization could provide very valuable assets for tool developers such as a precise definition of the analysis operations and, what is more, a reference implementation, i.e., a trustworthy, not necessarily efficient implementation to compare different tools outputs. In this article, we present the FLAME framework as the result of facing this challenge. FLAME is a formal framework that can be used to formally specify not only feature models, but other variability modeling languages (VML s) as well. This reusability is achieved by its two-layered architecture. The abstract foundation layer is the bottom layer in which all VML-independent analysis operations and concepts are specified. On top of the foundation layer, a family of characteristic model layers--one for each VML to be formally specified--can be developed by redefining some abstract types and relations. The verification and validation of FLAME has followed a process in which formal verification has been performed traditionally by manual theorem proving, but validation has been performed by integrating our experience on metamorphic testing of variability analysis tools, something that has shown to be much more effective than manually designed test cases. To follow this automated, test-based validation approach, the specification of FLAME, written in Z, was translated into Prolog and 20,000 random tests were automatically generated and executed. Tests results helped to discover some inconsistencies not only in the formal specification, but also in the previous informal definitions of the analysis operations and in current analysis tools. After this process, the Prolog implementation of FLAME is being used as a reference implementation for some tool developers, some analysis operations have been formally specified for the first time with more generic semantics, and more VML s are being formally specified using FLAME.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1049–1082},
numpages = {34},
keywords = {Specification testing, Software product lines, Formal specification, Feature models}
}

@article{10.1016/j.jss.2007.08.036,
author = {Lucr\'{e}dio, Daniel and dos Santos Brito, Kellyton and Alvaro, Alexandre and Garcia, Vinicius Cardoso and de Almeida, Eduardo Santana and de Mattos Fortes, Renata Pontin and Meira, Silvio Lemos},
title = {Software reuse: The Brazilian industry scenario},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {6},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.08.036},
doi = {10.1016/j.jss.2007.08.036},
abstract = {This paper aims at identifying some of the key factors in adopting an organization-wide software reuse program. The factors are derived from practical experience reported by industry professionals, through a survey involving 57 Brazilian small, medium and large software organizations. Some of them produce software with commonality between applications, and have mature processes, while others successfully achieved reuse through isolated, ad hoc efforts. The paper compiles the answers from the survey participants, showing which factors were more associated with reuse success. Based on this relationship, a guide is presented, pointing out which factors should be more strongly considered by small, medium and large organizations attempting to establish a reuse program.},
journal = {J. Syst. Softw.},
month = jun,
pages = {996–1013},
numpages = {18},
keywords = {Survey, Software reuse, Reuse success factors, Best practices}
}

@article{10.1007/s10664-008-9069-5,
author = {Knodel, Jens and Muthig, Dirk and Naab, Matthias},
title = {An experiment on the role of graphical elements in architecture visualization},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9069-5},
doi = {10.1007/s10664-008-9069-5},
abstract = {The evolution and maintenance of large-scale software systems requires first an understanding of its architecture before delving into lower-level details. Tools facilitating the architecture comprehension tasks by visualization provide different sets of configurable, graphical elements to present information to their users. We conducted a controlled experiment that exemplifies the critical role of such graphical elements when aiming at understanding the architecture. In our setting, a different configuration of graphical elements had significant influence on program comprehension tasks. In particular, a 63% gain in effectiveness in architectural analysis tasks was achieved simply by changing the configuration of the graphical elements of the same tool. Based on the results, we claim that significant effort should be spent on the configuration of architecture visualization tools and that configurability should be a requirement for such tools.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {693–726},
numpages = {34},
keywords = {Visualization, SAVE, Program comprehension, Maintenance, Graphical elements, Experiment, Configurability, Architecture}
}

@article{10.5555/1127442.1127472,
author = {Linder, Stephen Paul and Abbott, David and Fromberger, Michael J.},
title = {An instructional scaffolding approach to teaching software design},
year = {2006},
issue_date = {June 2006},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {21},
number = {6},
issn = {1937-4771},
abstract = {Students often find introductory computer science courses boring and mechanical, leading many to drop from the major. Educators have suggested that bringing realistic design problems into the introductory courses would increase student retention and better prepare students for the major. However, the design and implementation of a solution to a realistic problem is often nontrivial and can therefore be very stressful to students. By using the pedagogical paradigm of scaffolding, this anxiety can be ameliorated. A prototypical design course is described where students implement solutions to progressively more difficult design problems. The solutions to these initial assignments are then continually refactored and used as the code-base for subsequent assignments and the culminating team project. The social interactions necessary for instructional scaffolding are facilitated by having each final project be unique, but similar enough to allow students to help each other. We describe the framework of assignments used in our course, including the capstone projects in which students develop computer vision-based systems that do things like read dice and poker hands, and sort M&amp;Ms.},
journal = {J. Comput. Sci. Coll.},
month = jun,
pages = {238–250},
numpages = {13}
}

@article{10.1145/279437.279454,
author = {Addy, Edward A.},
title = {Report from the first annual workshop on software architectures in product line acquisitions},
year = {1998},
issue_date = {May 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/279437.279454},
doi = {10.1145/279437.279454},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {32–39},
numpages = {8}
}

@inproceedings{10.5555/645435.757601,
author = {Czarnecki, Krzysztof and Bednasch, Thomas and Unger, Peter and Eisenecker, Ulrich W.},
title = {Generative Programming for Embedded Software: An Industrial Experience Report},
year = {2002},
isbn = {3540442847},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Physical products come in many variants, and so does the software embedded in them. The software embedded in a product variant usually has to be optimized to fit its limited memory and computing power. Generative programming is well suited for developing embedded software since it allows us to automatically produce variants of embedded software optimized for specific products. This paper reports on our experience in applying generative programming in the embedded domain. We propose an extended feature modeling notation, discuss tool support for feature modeling, describe a domain-independent system configuration editor, and comment on the applicability of static configuration in the area of embedded systems.},
booktitle = {Proceedings of the 1st ACM SIGPLAN/SIGSOFT Conference on Generative Programming and Component Engineering},
pages = {156–172},
numpages = {17},
series = {GPCE '02}
}

@inproceedings{10.5555/1892801.1892811,
author = {Dolstra, Eelco},
title = {Integrating software construction and software deployment},
year = {2003},
isbn = {3540140360},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Classically, software deployment is a process consisting of building the software, packaging it for distribution, and installing it at the target site. This approach has two problems. First, a package must be annotated with dependency information and other meta-data. This to some extent overlaps with component dependencies used in the build process. Second, the same source system can often be built into an often very large number of variants. The distributor must decide which element(s) of the variant space will be packaged, reducing the flexibility for the receiver of the package. In this paper we show how building and deployment can be integrated into a single formalism. We describe a build manager called Maak that can handle deployment through a sufficiently general module system. Through the sharing of generated files, a source distribution transparently turns into a binary distribution, removing the dichotomy between these two modes of deployment. In addition, the creation and deployment of variants becomes easy through the use of a simple functional language as the build formalism.},
booktitle = {Proceedings of the 2001 ICSE Workshops on SCM 2001, and SCM 2003 Conference on Software Configuration Management},
pages = {102–117},
numpages = {16},
location = {Toronto, Canada},
series = {SCM'01/SCM'03}
}

@inproceedings{10.1145/1868294.1868300,
author = {Sincero, Julio and Tartler, Reinhard and Lohmann, Daniel and Schr\"{o}der-Preikschat, Wolfgang},
title = {Efficient extraction and analysis of preprocessor-based variability},
year = {2010},
isbn = {9781450301541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868294.1868300},
doi = {10.1145/1868294.1868300},
abstract = {The C Preprocessor (CPP) is the tool of choice for the implementation of variability in many large-scale configurable software projects. Linux, probably the most-configurable piece of software ever, employs more than 10,000 preprocessor variables for this purpose. However, this de-facto variability tends to be "hidden in the code"; which on the long term leads to variability defects, such as dead code or inconsistencies with respect to the intended (modeled) variability of the software. This calls for tool support for the efficient extraction of (and reasoning over) CPP-based variability.We suggest a novel approach to extract CPP-based variability. Our tool transforms CPP-based variability in O(n) complexity into a propositional formula that "mimics" all valid effects of conditional compilation and can be analyzed with standard SAT or BDD packages.Our evaluation results demonstrate the scalability and practicability of the approach. A dead-block-analysis on the complete Linux source tree takes less than 30 minutes; we thereby have revealed 60 dead blocks, 2 of which meanwhile have been confirmed as new (and long-lasting) bugs; the rest is still under investigation.},
booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
pages = {33–42},
numpages = {10},
keywords = {variability, linux, conditional compilation},
location = {Eindhoven, The Netherlands},
series = {GPCE '10}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@article{10.1016/j.jss.2014.12.050,
author = {Kapitsaki, Georgia M. and Tselikas, Nikolaos D. and Foukarakis, Ioannis E.},
title = {An insight into license tools for open source software systems},
year = {2015},
issue_date = {April 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {102},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.12.050},
doi = {10.1016/j.jss.2014.12.050},
abstract = {We provide a licensing comparative overview of existing assistive approaches/tools.License identification tools present a more mature current state.License compliance requires the collaboration of various techniques.License graphs are useful in detecting license conflicts. Free/Libre/Open Source Software (FLOSS) has gained a lot of attention lately allowing organizations to incorporate third party source code into their implementations. When open source software libraries are used, software resources may be linked directly or indirectly with multiple open source licenses giving rise to potential license incompatibilities. Adequate support in license use is vital in order to avoid such violations and address how diverse licenses should be handled. In the current work we investigate software licensing giving a critical and comparative overview of existing assistive approaches and tools. These approaches are centered on three main categories: license information identification from source code and binaries, software metadata stored in code repositories, and license modeling and associated reasoning actions. We also give a formalization of the license compatibility problem and demonstrate the role of existing approaches in license use decisions.},
journal = {J. Syst. Softw.},
month = apr,
pages = {72–87},
numpages = {16},
keywords = {License identification, License compatibility, Free/Libre/Open Source Software}
}

@article{10.1145/2000791.2000794,
author = {Anvik, John and Murphy, Gail C.},
title = {Reducing the effort of bug report triage: Recommenders for development-oriented decisions},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/2000791.2000794},
doi = {10.1145/2000791.2000794},
abstract = {A key collaborative hub for many software development projects is the bug report repository. Although its use can improve the software development process in a number of ways, reports added to the repository need to be triaged. A triager determines if a report is meaningful. Meaningful reports are then organized for integration into the project's development process.To assist triagers with their work, this article presents a machine learning approach to create recommenders that assist with a variety of decisions aimed at streamlining the development process. The recommenders created with this approach are accurate; for instance, recommenders for which developer to assign a report that we have created using this approach have a precision between 70% and 98% over five open source projects. As the configuration of a recommender for a particular project can require substantial effort and be time consuming, we also present an approach to assist the configuration of such recommenders that significantly lowers the cost of putting a recommender in place for a project. We show that recommenders for which developer should fix a bug can be quickly configured with this approach and that the configured recommenders are within 15% precision of hand-tuned developer recommenders.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {10},
numpages = {35},
keywords = {task assignment, recommendation, machine learning, configuration assistance, Bug report triage}
}

@book{10.1145/3191315,
editor = {Kifer, Michael and Liu, Yanhong Annie},
title = {Declarative Logic Programming: Theory, Systems, and Applications},
year = {2018},
isbn = {9781970001990},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
volume = {20},
abstract = {Logic Programming (LP) is at the nexus of knowledge representation, AI, mathematical logic, databases, and programming languages. It allows programming to be more declarative, by specifying “what” to do instead of “how” to do it. This field is fascinating and intellectually stimulating due to the fundamental interplay among theory, systems, and applications brought about by logic. Several books cover the basics of LP but they focus mostly on the Prolog language. There is generally a lack of accessible collections of articles covering the key aspects of LP, such as the well-founded vs. stable semantics for negation, constraints, object-oriented LP, updates, probabilistic LP, and implementation methods, including top-down vs. bottom-up evaluation and tabling.For systems, the situation is even less satisfactory, lacking expositions of LP inference machinery that supports tabling and other state-of-the-art implementation techniques. There is also a dearth of articles about systems that support truly declarative languages, especially those that tie into first-order logic, mathematical programming, and constraint programming. Also rare are surveys of challenging application areas of LP, such as bioinformatics, natural language processing, verification, and planning, as well as analysis of LP applications based on language abstractions and implementations methods.The goal of this book is to help fill in the void in the literature with state-of-the-art surveys on key aspects of LP. Much attention was paid to making these surveys accessible to researchers, practitioners, and graduate students alike.}
}

@inproceedings{10.1145/239098.239108,
author = {Seiter, Linda M. and Palsberg, Jens and Lieberherr, Karl J.},
title = {Evolution of object behavior using context relations},
year = {1996},
isbn = {0897917979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/239098.239108},
doi = {10.1145/239098.239108},
abstract = {A collection of design patterns was described by Gamma, Helm, Johnson, and Vlissides in 1994. Recognizing that designs change, each pattern ensures that a certain system aspect can vary over time such as the operations that can be applied to an object or the algorithm of a method. The patterns are described by constructs such as the inheritance and reference relations, attempting to emulate more dynamic relationships. As a result, the design patterns demonstrate how awkward it is to program natural concepts of behavioral evolution when using a traditional object-oriented language.In this paper we present a new relation between classes: the context relation. It directly supports behavioral evolution, and it is meaningful at the analysis, design, and implementation level. At the design level we picture a context relation as a new form of arrow between classes. At the implementation level we use a small extension of C++. The basic idea is that if class C is context-related to a base class B, then B-objects can get their functionality dynamically altered by C-objects. Our language construct for doing this is a generalization of the method update in Abadi and Cardelli's imperative object calculus. A C-object may be explicitly attached to a B-object, or it may be implicitly attached to a group of B-objects for the duration of a method invocation. We demonstrate how the context relation can be used to easily model and program the Adapter, Bridge, Chain of Responsibility, Decorator, Iterator, Observer, State, Strategy, and Visitor patterns.},
booktitle = {Proceedings of the 4th ACM SIGSOFT Symposium on Foundations of Software Engineering},
pages = {46–57},
numpages = {12},
location = {San Francisco, California, USA},
series = {SIGSOFT '96}
}

@book{10.5555/2886235,
author = {Bird, Christian and Menzies, Tim and Zimmermann, Thomas},
title = {The Art and Science of Analyzing Software Data},
year = {2015},
isbn = {0124115195},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {The Art and Science of Analyzing Software Data provides valuable information on analysis techniques often used to derive insight from software data. This book shares best practices in the field generated by leading data scientists, collected from their experience training software engineering students and practitioners to master data science. The book covers topics such as the analysis of security data, code reviews, app stores, log files, and user telemetry, among others. It covers a wide variety of techniques such as co-change analysis, text analysis, topic analysis, and concept analysis, as well as advanced topics such as release planning and generation of source code comments. It includes stories from the trenches from expert data scientists illustrating how to apply data analysis in industry and open source, present results to stakeholders, and drive decisions.Presents best practices, hints, and tips to analyze data and apply tools in data science projectsPresents research methods and case studies that have emerged over the past few years to further understanding of software dataShares stories from the trenches of successful data science initiatives in industry}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@book{10.1145/2534860,
author = {Joint Task Force on Computing Curricula, Association for Computing Machinery (ACM) and IEEE Computer Society},
title = {Computer Science Curricula 2013: Curriculum Guidelines for Undergraduate Degree Programs in Computer Science},
year = {2013},
isbn = {9781450323093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@book{10.1145/3477355,
editor = {Jones, Cliff B. and Misra, Jayadev},
title = {Theories of Programming: The Life and Works of Tony Hoare},
year = {2021},
isbn = {9781450387286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {39},
abstract = {Sir Tony Hoare has had an enormous influence on computer science, from the Quicksort algorithm to the science of software development, concurrency and program verification. His contributions have been widely recognised: He was awarded the ACM’s Turing Award in 1980, the Kyoto Prize from the Inamori Foundation in 2000, and was knighted for “services to education and computer science” by Queen Elizabeth II of England in 2000.This book presents the essence of his various works—the quest for effective abstractions—both in his own words as well as chapters written by leading experts in the field, including many of his research collaborators. In addition, this volume contains biographical material, his Turing award lecture, the transcript of an interview and some of his seminal papers.Hoare’s foundational paper “An Axiomatic Basis for Computer Programming”, presented his approach, commonly known as Hoare Logic, for proving the correctness of programs by using logical assertions. Hoare Logic and subsequent developments have formed the basis of a wide variety of software verification efforts. Hoare was instrumental in proposing the Verified Software Initiative, a cooperative international project directed at the scientific challenges of large-scale software verification, encompassing theories, tools and experiments.Tony Hoare’s contributions to the theory and practice of concurrent software systems are equally impressive. The process algebra called Communicating Sequential Processes (CSP) has been one of the fundamental paradigms, both as a mathematical theory to reason about concurrent computation as well as the basis for the programming language occam. CSP served as a framework for exploring several ideas in denotational semantics such as powerdomains, as well as notions of abstraction and refinement. It is the basis for a series of industrial-strength tools which have been employed in a wide range of applications.This book also presents Hoare’s work in the last few decades. These works include a rigorous approach to specifications in software engineering practice, including procedural and data abstractions, data refinement, and a modular theory of designs. More recently, he has worked with collaborators to develop Unifying Theories of Programming (UTP). Their goal is to identify the common algebraic theories that lie at the core of sequential, concurrent, reactive and cyber-physical computations. Theories of Programming: The Life and Works of Tony Hoare’ is available as a printed book (DOI: ) and an on-line version. In addition to the book itself, a number of on-line resources might be of interest to readers:
A bibliography of Tony Hoare’s papers with clickable DOIs/URLs where available (ACM: INSERT URL)Appendix E of the book provides links to talks and interviews featuring Tony Hoare ()The Oxford archive of Hoare’s manuscripts:  
Supplementary Material: Tony Hoare’ is a PDF of additional material (not included in the book) containing the following:
Stories from a Life in Interesting Times (A transcription by Jayadev Misra of Tony Hoare’s acceptance speech for the 2000 Kyoto prize)Tony Hoare’s Heidelberg comments: (A transcription by Margaret Gray of Tony Hoare’s part in the 2020 Heidelberg event)Milestones in Tony’s Life and Work: A ‘cv’ of Tony Hoare prepared by Margaret GrayExtended version - ’Bernard Sufrin: Teaching at Belfast and Oxford’}
}

@inproceedings{10.1145/258993.259016,
author = {Grant, Brian and Mock, Markus and Philipose, Matthai and Chambers, Craig and Eggers, Susan J.},
title = {Annotation-directed run-time specialization in C},
year = {1997},
isbn = {0897919173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/258993.259016},
doi = {10.1145/258993.259016},
abstract = {We present the design of a dynamic compilation system for C. Directed by a few declarative user annotations specifying where and on what dynamic compilation is to take place, a binding time analysis computes the set of run-time constants at each program point in each annotated procedure's control flow graph; the analysis supports program-point-specific polyvariant division and specialization. The analysis results guide the construction of a specialized run-time specializer for each dynamically compiled region; the specializer supports various caching strategies for managing dynamically generated code and supports mixes of speculative and demand-driven specialization of dynamic branch successors. Most of the key cost/benefit trade-offs in the binding time analysis and the run-time specialize are open to user control through declarative policy annotations. Our design is being implemented in the context of art existing optimizing compiler.},
booktitle = {Proceedings of the 1997 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation},
pages = {163–178},
numpages = {16},
location = {Amsterdam, The Netherlands},
series = {PEPM '97}
}

@book{10.5555/1564784,
author = {Wang},
title = {System-on-Chip Test Architectures: Nanometer  Design for Testability},
year = {2007},
isbn = {9780080556802},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Modern electronics testing has a legacy of more than 40 years. The introduction of new technologies, especially nanometer technologies with 90nm or smaller geometry, has allowed the semiconductor industry to keep pace with the increased performance-capacity demands from consumers. As a result, semiconductor test costs have been growing steadily and typically amount to 40% of today's overall product cost. This book is a comprehensive guide to new VLSI Testing and Design-for-Testability techniques that will allow students, researchers, DFT practitioners, and VLSI designers to master quickly System-on-Chip Test architectures, for test debug and diagnosis of digital, memory, and analog/mixed-signal designs. KEY FEATURES * Emphasizes VLSI Test principles and Design for Testability architectures, with numerous illustrations/examples. * Most up-to-date coverage available, including Fault Tolerance, Low-Power Testing, Defect and Error Tolerance, Network-on-Chip (NOC) Testing, Software-Based Self-Testing, FPGA Testing, MEMS Testing, and System-In-Package (SIP) Testing, which are not yet available in any testing book. * Covers the entire spectrum of VLSI testing and DFT architectures, from digital and analog, to memory circuits, and fault diagnosis and self-repair from digital to memory circuits. * Discusses future nanotechnology test trends and challenges facing the nanometer design era; promising nanotechnology test techniques, including Quantum-Dots, Cellular Automata, Carbon-Nanotubes, and Hybrid Semiconductor/Nanowire/Molecular Computing. * Practical problems at the end of each chapter for students.}
}

@proceedings{10.1145/2951913,
title = {ICFP 2016: Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
year = {2016},
isbn = {9781450342193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nara, Japan}
}

