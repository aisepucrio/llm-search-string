@inproceedings{10.1145/3336294.3336321,
author = {Ghofrani, Javad and Kozegar, Ehsan and Fehlhaber, Anna Lena and Soorati, Mohammad Divband},
title = {Applying Product Line Engineering Concepts to Deep Neural Networks},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336321},
doi = {10.1145/3336294.3336321},
abstract = {Deep Neural Networks (DNNs) are increasingly being used as a machine learning solution thanks to the complexity of their architecture and hyperparameters-weights. A drawback is the excessive demand for massive computational power during the training process. Not only as a whole but parts of neural networks can also be in charge of certain functionalities. We present a novel challenge in an intersection between machine learning and variability management communities to reuse modules of DNNs without further training. Let us assume that we are given a DNN for image processing that recognizes cats and dogs. By extracting a part of the network, without additional training a new DNN should be divisible with the functionality of recognizing only cats. Existing research in variability management can offer a foundation for a product line of DNNs composing the reusable functionalities. An ideal solution can be evaluated based on its speed, granularity of determined functionalities, and the support for adding variability to the network. The challenge is decomposed in three subchallenges: feature extraction, feature abstraction, and the implementation of a product line of DNNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {72–77},
numpages = {6},
keywords = {variability, transfer learning, software product lines, machine learning, deep neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1007/978-3-319-35122-3_5,
author = {Schaefer, Ina and Seidl, Christoph and Cleophas, Loek and Watson, Bruce W.},
title = {Tax-PLEASE--Towards Taxonomy-Based Software Product Line Engineering},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_5},
doi = {10.1007/978-3-319-35122-3_5},
abstract = {Modern software systems, in particular in mobile and cloud-based applications, exist in many different variants in order to adapt to changing user requirements or application contexts. Software product line engineering allows developing these software systems by managed large-scale reuse in order to achieve shorter time to market. Traditional software product line engineering approaches use a domain variability model which only captures the configuration options of the product variants, but does not provide any guideline for designing and implementing reusable artifacts. In contrast, software taxonomies structure software domains from an abstract specification of the functionality to concrete implementable variants by successive correctness-preserving refinements. In this paper, we propose a novel software product line engineering process based on a taxonomy-based domain analysis. The taxonomy's hierarchy provides guidelines for designing and implementing the product line's reusable artifacts while at the same time specifying possible configuration options. By deriving reusable product line artifacts from a software taxonomy, the well-defined structuring of the reusable artifacts yields improved maintainability and evolvability of the product line.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {63–70},
numpages = {8},
keywords = {Taxonomy-Based Software Construction TABASCO, Software Product Line SPL},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1145/2970276.2970288,
author = {Schw\"{a}gerl, Felix and Westfechtel, Bernhard},
title = {SuperMod: tool support for collaborative filtered model-driven software product line engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970288},
doi = {10.1145/2970276.2970288},
abstract = {The increase in productivity implied by model-driven software product line engineering is weakened by the complexity exposed to the user having to manage a multi-variant model. Recently, a new paradigm has emerged: filtered software product line engineering transfers the established check-out/modify/commit workflow from version control to variability management, allowing to iteratively develop the multi-variant model in a single-variant view. This paper demonstrates SuperMod, a tool that supports collaborative filtered model-driven product line engineering, implemented for and with the Eclipse Modeling Framework. Concerning variability management, the tool offers capabilities for editing feature models and specifying feature configurations, both being well-known formalisms in product line engineering. Furthermore, collaborative editing of product lines is provided through distributed version control. The accompanying video shows that SuperMod seamlessly integrates into existing tool landscapes, reduces the complexity of multi-variant editing, automates a large part of variability management, and ensures consistency. A tool demonstration video is available here: http://youtu.be/5XOk3x5kjFc},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {822–827},
numpages = {6},
keywords = {version control, software product line engineering, filtered editing, Model-driven software engineering},
location = {Singapore, Singapore},
series = {ASE '16}
}

@inproceedings{10.1145/3233027.3233038,
author = {Martinez, Jabier and T\"{e}rnava, Xhevahire and Ziadi, Tewfik},
title = {Software product line extraction from variability-rich systems: the robocode case study},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233038},
doi = {10.1145/3233027.3233038},
abstract = {The engineering of a Software Product Line (SPL), either by creating it from scratch or through the re-engineering of existing variants, it uses to be a project that spans several years with a high investment. It is often hard to analyse and quantify this investment, especially in the context of extractive SPL adoption when the related software variants are independently created by different developers following different system architectures and implementation conventions. This paper reports an experience on the creation of an SPL by re-engineering system variants implemented around an educational game called Robocode. The objective of this game is to program a bot (a battle tank) that battles against the bots of other developers. The world-wide Robocode community creates and maintains a large base of knowledge and implementations that are mainly organized in terms of features, although not presented as an SPL. Therefore, a group of master students analysed this variability-rich domain and extracted a Robocode SPL. We present the results of such extraction augmented with an analysis and a quantification regarding the spent time and effort. We believe that the results and the a-posteriori analysis can provide insights on global challenges on SPL adoption. We also provide all the elements to SPL educators to reproduce the teaching activity, and we make available this SPL to be used for any research purpose.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {132–142},
numpages = {11},
keywords = {software product lines, robocode, reverse-engineering, extractive software product line adoption, education},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3336294.3336310,
author = {Rabiser, Rick and Schmid, Klaus and Becker, Martin and Botterweck, Goetz and Galster, Matthias and Groher, Iris and Weyns, Danny},
title = {Industrial and Academic Software Product Line Research at SPLC: Perceptions of the Community},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336310},
doi = {10.1145/3336294.3336310},
abstract = {We present preliminary insights into the perception of researchers and practitioners of the software product line (SPL) community on previous, current, and future research efforts. We were particularly interested in up-and-coming and outdated topics and whether the views of academics and industry researchers differ. Also, we compared the views of the community with the results of an earlier literature survey published at SPLC 2018. We conducted a questionnaire-based survey with attendees of SPLC 2018. We received 33 responses (about a third of the attendees) from both, very experienced attendees and younger researchers, and from academics as well as industry researchers. We report preliminary findings regarding popular and unpopular SPL topics, topics requiring further work, and industry versus academic researchers' views. Differences between academic and industry researchers become visible only when analyzing comments on open questions. Most importantly, while topics popular among respondents are also popular in the literature, topics respondents think require further work have often already been well researched. We conclude that the SPL community needs to do a better job preserving and communicating existing knowledge and particularly also needs to widen its scope.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {189–194},
numpages = {6},
keywords = {software product lines, industry, academia, SPLC},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3233027.3233029,
author = {Sree-Kumar, Anjali and Planas, Elena and Claris\'{o}, Robert},
title = {Extracting software product line feature models from natural language specifications},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233029},
doi = {10.1145/3233027.3233029},
abstract = {The specification of a family of software products may include documents written in natural language. Automatically extracting knowledge from these documents is a challenging problem that requires using Natural Language Processing (NLP) techniques. This knowledge can be formalized as a Feature Model (FM), a diagram capturing the key features and the relationships among them.In this paper, we first review previous works that have presented tools for extracting FMs from textual specifications and compare their strengths and limitations. Then, we propose a framework for feature and relationship extraction, which overcomes the identified limitations and is built upon state-of-the-art open-source NLP tools. This framework is evaluated against previous works using several case studies, showing improved results.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {43–53},
numpages = {11},
keywords = {software product line, requirements engineering, natural language processing, feature model extraction, NLTK},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2648511.2648513,
author = {Harman, M. and Jia, Y. and Krinke, J. and Langdon, W. B. and Petke, J. and Zhang, Y.},
title = {Search based software engineering for software product line engineering: a survey and directions for future work},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648513},
doi = {10.1145/2648511.2648513},
abstract = {This paper presents a survey of work on Search Based Software Engineering (SBSE) for Software Product Lines (SPLs). We have attempted to be comprehensive, in the sense that we have sought to include all papers that apply computational search techniques to problems in software product line engineering. Having surveyed the recent explosion in SBSE for SPL research activity, we highlight some directions for future work. We focus on suggestions for the development of recent advances in genetic improvement, showing how these might be exploited by SPL researchers and practitioners: Genetic improvement may grow new products with new functional and non-functional features and graft these into SPLs. It may also merge and parameterise multiple branches to cope with SPL branchmania.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {5–18},
numpages = {14},
keywords = {program synthesis, genetic programming, SPL, SBSE},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1145/3442389,
author = {Castro, Thiago and Teixeira, Leopoldo and Alves, Vander and Apel, Sven and Cordy, Maxime and Gheyi, Rohit},
title = {A Formal Framework of Software Product Line Analyses},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3442389},
doi = {10.1145/3442389},
abstract = {A number of product-line analysis approaches lift analyses such as type checking, model checking, and theorem proving from the level of single programs to the level of product lines. These approaches share concepts and mechanisms that suggest an unexplored potential for reuse of key analysis steps and properties, implementation, and verification efforts. Despite the availability of taxonomies synthesizing such approaches, there still remains the underlying problem of not being able to describe product-line analyses and their properties precisely and uniformly. We propose a formal framework that models product-line analyses in a compositional manner, providing an overall understanding of the space of family-based, feature-based, and product-based analysis strategies. It defines precisely how the different types of product-line analyses compose and inter-relate. To ensure soundness, we formalize the framework, providing mechanized specification and proofs of key concepts and properties of the individual analyses. The formalization provides unambiguous definitions of domain terminology and assumptions as well as solid evidence of key properties based on rigorous formal proofs. To qualitatively assess the generality of the framework, we discuss to what extent it describes five representative product-line analyses targeting the following properties: safety, performance, dataflow facts, security, and functional program properties.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {34},
numpages = {37},
keywords = {product-line analysis, Software product lines}
}

@inproceedings{10.1007/978-3-030-61362-4_5,
author = {Damiani, Ferruccio and Lienhardt, Michael and Paolini, Luca},
title = {On Slicing Software Product Line Signatures},
year = {2020},
isbn = {978-3-030-61361-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61362-4_5},
doi = {10.1007/978-3-030-61362-4_5},
abstract = {A Software Product Line (SPL) is a family of similar programs (called variants) generated from a common artifact base. Variability in an SPL can be documented in terms of abstract description of functionalities (called features): a feature model (FM) identifies each variant by a set of features (called a product). Delta-orientation is a flexible approach to implement SPLs. An SPL Signature (SPLS) is a variability-aware Application Programming Interface (API), i.e., an SPL where each variant is the API of a program. In this paper we introduce and formalize, by abstracting from SPL implementation approaches, the notion of slice of an SPLS K for a set of features F (i.e., an SPLS obtained from by K by hiding the features that are not in F). Moreover, we formulate the challenge of defining an efficient algorithm that, given a delta-oriented SPLS K and a set of features F, sreturns a delta-oriented SPLS that is an slice of K for F. Thus paving the way for further research on devising such an algorithm. The proposed notions are formalized for SPLs of programs written in an imperative version of Featherweight Java.},
booktitle = {Leveraging Applications of Formal Methods, Verification and Validation: Verification Principles: 9th International Symposium on Leveraging Applications of Formal Methods, ISoLA 2020, Rhodes, Greece, October 20–30, 2020, Proceedings, Part I},
pages = {81–102},
numpages = {22},
location = {Rhodes, Greece}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {software variability, software testing, software product line, quality assurance, machine learning},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3297156.3297203,
author = {Hasbi, Muhamad and Budiardjo, Eko K. and Wibowo, Wahyu C.},
title = {Reverse Engineering in Software Product Line - A Systematic Literature Review},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297203},
doi = {10.1145/3297156.3297203},
abstract = {Reverse engineering is the information extraction process on system by identifying and analyzing the components that are part of that system. We analyze existing research that related with reverse engineering process on software product line. There are two product line processes according to Software product line engineering framework they are domain engineering process and application engineering process. We investigate reverse engineering in domain engineering process (domain requirements, domain design, and domain realization, domain quality assurance). We performed a systematic literature review. A manual search resulting 71 papers considered for analysis. Results: The majority of reverse engineering studied in three domain activity in domain engineering process. That is requirement engineering, domain design and domain realization. There are inconsistent correlations between features in the reverse engineering process. These approaches extract features without constraints between its features. Conclusions: Reverse engineering methods are needed that are able to identify and maintain a consistent correlation between features in application engineering and domain engineering in the reverse engineering process. Finally, we provide gaps from existing research and show opportunities for future research.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {174–179},
numpages = {6},
keywords = {systematic review, software product line, domain engineering, Reverse engineering},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1007/978-3-319-35122-3_2,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Automated Composition of Service Mashups Through Software Product Line Engineering},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_2},
doi = {10.1007/978-3-319-35122-3_2},
abstract = {The growing number of online resources, including data and services, has motivated both researchers and practitioners to provide methods and tools for non-expert end-users to create desirable applications by putting these resources together leading to the so called mashups. In this paper, we focus on a class of mashups referred to as service mashups. A service mashup is built from existing services such that the developed service mashup offers added-value through new functionalities. We propose an approach which adopts concepts from software product line engineering and automated AI planning to support the automated composition of service mashups. One of the advantages of our work is that it allows non-experts to build and optimize desired mashups with little knowledge of service composition. We report on the results of the experimentation that we have performed which support the practicality and scalability of our proposed work.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {20–38},
numpages = {19},
keywords = {Workflow optimization, Software product lines, Service mashups, Planning, Feature model, Automated composition},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@article{10.1016/j.csi.2016.03.003,
author = {Afzal, Uzma and Mahmood, Tariq and Shaikh, Zubair},
title = {Intelligent software product line configurations},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {48},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2016.03.003},
doi = {10.1016/j.csi.2016.03.003},
abstract = {A software product line (SPL) is a set of industrial software-intensive systems for configuring similar software products in which personalized feature sets are configured by different business teams. The integration of these feature sets can generate inconsistencies that are typically resolved through manual deliberation. This is a time-consuming process and leads to a potential loss of business resources. Artificial intelligence (AI) techniques can provide the best solution to address this issue autonomously through more efficient configurations, lesser inconsistencies and optimized resources. This paper presents the first literature review of both research and industrial AI applications to SPL configuration issues. Our results reveal only 19 relevant research works which employ traditional AI techniques on small feature sets with no real-life testing or application in industry. We categorize these works in a typology by identifying 8 perspectives of SPL. We also show that only 2 standard industrial SPL tools employ AI in a limited way to resolve inconsistencies. To inject more interest and application in this domain, we motivate and present future research directions. Particularly, using real-world SPL data, we demonstrate how predictive analytics (a state of the art AI technique) can separately model inconsistent and consistent patterns, and then predict inconsistencies in advance to help SPL designers during the configuration of a product. Literature review of AI applications to SPL configuration issuesDevelop a taxonomy based on eight different problem domainsThis review shows use of logic, constraint satisfaction, reasoning, ontology and optimization.Several important future research directions are proposed.We justify advanced analytics and swarm intelligence as better future applications.},
journal = {Comput. Stand. Interfaces},
month = nov,
pages = {30–48},
numpages = {19},
keywords = {Software product line, Predictive analytics, Literature review, Industrial SPL tools, Inconsistencies, Automated feature selection, Artificial intelligence}
}

@inproceedings{10.1145/2934466.2934483,
author = {Richenhagen, Johannes and Rumpe, Bernhard and Schlo\ss{}er, Axel and Schulze, Christoph and Thissen, Kevin and von Wenckstern, Michael},
title = {Test-driven semantical similarity analysis for software product line extraction},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934483},
doi = {10.1145/2934466.2934483},
abstract = {Software product line engineering rests upon the assumption that a set of products share a common base of similar functionality. The correct identification of similarities between different products can be a time-intensive task. Hence, this paper proposes an automated semantical similarity analysis supporting software product line extraction and maintenance. Under the assumption of an already identified compatible interface, the degree of semantical similarity is identified based on provided test cases. Therefore, the analysis can also be applied in a test-driven development. This is done by translating available test sequences for both components into two I/O extended finite automata and performing an abstraction of the defined behavior until a simulation relation is established. The test-based approach avoids complexity issues regarding the state space explosion problem, a common issue in model checking. The proposed approach is applied on different variants and versions of industrially used software components provided by an automotive supplier to demonstrate the method's applicability.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {174–183},
numpages = {10},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3461001.3471152,
author = {Silva, Publio and Bezerra, Carla I. M. and Machado, Ivan},
title = {A machine learning model to classify the feature model maintainability},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471152},
doi = {10.1145/3461001.3471152},
abstract = {Software Product Lines (SPL) are generally specified using a Feature Model (FM), an artifact designed in the early stages of the SPL development life cycle. This artifact can quickly become too complex, which makes it challenging to maintain an SPL. Therefore, it is essential to evaluate the artifact's maintainability continuously. The literature brings some approaches that evaluate FM maintainability through the aggregation of maintainability measures. Machine Learning (ML) models can be used to create these approaches. They can aggregate the values of independent variables into a single target data, also called a dependent variable. Besides, when using white-box ML models, it is possible to interpret and explain the ML model results. This work proposes white-box ML models intending to classify the FM maintainability based on 15 measures. To build the models, we performed the following steps: (i) we compared two approaches to evaluate the FM maintainability through a human-based oracle of FM maintainability classifications; (ii) we used the best approach to pre-classify the ML training dataset; (iii) we generated three ML models and compared them against classification accuracy, precision, recall, F1 and AUC-ROC; and, (iv) we used the best model to create a mechanism capable of providing improvement indicators to domain engineers. The best model used the decision tree algorithm that obtained accuracy, precision, and recall of 0.81, F1-Score of 0.79, and AUC-ROC of 0.91. Using this model, we could reduce the number of measures needed to evaluate the FM maintainability from 15 to 9 measures.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {35–45},
numpages = {11},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1109/CEC48606.2020.9185675,
author = {Ibias, Alfredo and Llana, Luis},
title = {Feature Selection using Evolutionary Computation Techniques for Software Product Line Testing},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC48606.2020.9185675},
doi = {10.1109/CEC48606.2020.9185675},
abstract = {Software product lines are an excellent mechanism in the development of software. Testing software product lines is an intensive process where selecting the right features where to focus it can be a critical task. Selecting the best combination of features from a software product line is a complex problem addressed in the literature. In this paper, we address the problem of finding the combination of features with the highest probability of being requested from a software product line with probabilities. We use Evolutive Computation techniques to address this problem. Specifically, we use the Ant Colony Optimization algorithm to find the best combination of features. Our results report that our framework overcomes the limitations of the brute force algorithm.},
booktitle = {2020 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@inproceedings{10.5555/3504035.3504452,
author = {Khurana, Udayan and Samulowitz, Horst and Turaga, Deepak},
title = {Feature engineering for predictive modeling using reinforcement learning},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Feature engineering is a crucial step in the process of predictive modeling. It involves the transformation of given feature space, typically using mathematical functions, with the objective of reducing the modeling error for a given target. However, there is no well-defined basis for performing effective feature engineering. It involves domain knowledge, intuition, and most of all, a lengthy process of trial and error. The human attention involved in overseeing this process significantly influences the cost of model generation. We present a new framework to automate feature engineering. It is based on performance driven exploration of a transformation graph, which systematically and compactly captures the space of given options. A highly efficient exploration strategy is derived through reinforcement learning on past examples.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {417},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {clafer configurator, ClaferWiki, ClaferMOO visualizer, ClaferMOO, ClaferIG, Clafer},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3289402.3289504,
author = {Sebbaq, Hanane and Retbi, Asmaa and Idrissi, Mohammed Khalidi and Bennani, Samir},
title = {Software Product Line to overcome the variability issue in E-Learning: Systematic literature review},
year = {2018},
isbn = {9781450364621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289402.3289504},
doi = {10.1145/3289402.3289504},
abstract = {The disparity of educational technologies, pedagogies and learning styles implies a problem of variability when modeling E-learning systems. Furthermore, the current learning context, which has become very open and heterogeneous, raises the problem of automating the modeling, development and maintenance of personalized E-learning systems based on various pedagogies. For its part, the "Software Product Line" is a paradigm that aims to produce product families based on the principles of reuse, configuration and derivation. The main purpose of this literature review is to explore the different potential applications of "SPL" in the E-learning domain to figure out the problem of variability. We will adopt a protocol for a systematic review of literature, after which we will draw up an analysis report.},
booktitle = {Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications},
articleno = {4},
numpages = {8},
keywords = {variety, systematic literature review, scale, heterogeneity, Variability, Software Product line, E-learning},
location = {Rabat, Morocco},
series = {SITA'18}
}

@inproceedings{10.1145/2648511.2648537,
author = {Colanzi, Thelma Elita and Vergilio, Silvia Regina and Gimenes, Itana M. S. and Oizumi, Willian Nalepa},
title = {A search-based approach for software product line design},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648537},
doi = {10.1145/2648511.2648537},
abstract = {The Product Line Architecture (PLA) can be improved by taking into account key factors such as feature modularization, and by continuously evaluating its design according to metrics. Search-Based Software Engineering (SBSE) principles can be used to support an informed-design of PLAs. However, existing search-based design works address only traditional software design not considering intrinsic Software Product Line aspects. This paper presents MOA4PLA, a search-based approach to support the PLA design. It gives a multi-objective treatment to the design problem based on specific PLA metrics. A metamodel to represent the PLA and a novel search operator to improve feature modularization are proposed. Results point out that the application of MOA4PLA leads to PLA designs with well modularized features, contributing to improve features reusability and extensibility. It raises a set of solutions with different design trade-offs that can be used to improve the PLA design.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {237–241},
numpages = {5},
keywords = {software product lines, searchbased PLA design, multi-objective algorithms},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3336294.3336303,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and Ramos-Guti\'{e}rrez, Bel\'{e}n and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Process Mining to Unleash Variability Management: Discovering Configuration Workflows Using Logs},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336303},
doi = {10.1145/3336294.3336303},
abstract = {Variability models are used to build configurators. Configurators are programs that guide users through the configuration process to reach a desired configuration that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the elements that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suites stakeholders according to previous configurations. For example, when configuring a Linux distribution, the configuration process start by choosing the network or the graphic card, and then other packages with respect to a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), an automated technique that given a set of logs of previous configurations and a variability model can automatically assist to determine the configuration workflow that better fits the configuration logs generated by user activities. The technique is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Our proposal is validated using existing data from an ERP configuration environment showing its feasibility. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {265–276},
numpages = {12},
keywords = {variability, process mining, process discovery, configuration workflow, clustering},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10270-015-0479-8,
author = {Devroey, Xavier and Perrouin, Gilles and Cordy, Maxime and Samih, Hamza and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Statistical prioritization for software product line testing: an experience report},
year = {2017},
issue_date = {February  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-015-0479-8},
doi = {10.1007/s10270-015-0479-8},
abstract = {Software product lines (SPLs) are families of software systems sharing common assets and exhibiting variabilities specific to each product member of the family. Commonalities and variabilities are often represented as features organized in a feature model. Due to combinatorial explosion of the number of products induced by possible features combinations, exhaustive testing of SPLs is intractable. Therefore, sampling and prioritization techniques have been proposed to generate sorted lists of products based on coverage criteria or weights assigned to features. Solely based on the feature model, these techniques do not take into account behavioural usage of such products as a source of prioritization. In this paper, we assess the feasibility of integrating usage models into the testing process to derive statistical testing approaches for SPLs. Usage models are given as Markov chains, enabling prioritization of probable/rare behaviours. We used featured transition systems, compactly modelling variability and behaviour for SPLs, to determine which products are realizing prioritized behaviours. Statistical prioritization can achieve a significant reduction in the state space, and modelling efforts can be rewarded by better automation. In particular, we used MaTeLo, a statistical test cases generation suite developed at ALL4TEC. We assess feasibility criteria on two systems: Claroline, a configurable course management system, and Sferion™, an embedded system providing helicopter landing assistance.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {153–171},
numpages = {19},
keywords = {Statistical testing, Software product line testing, Prioritization, D.2.7, D.2.5}
}

@inproceedings{10.1145/3340531.3417448,
author = {Khurana, Udayan and Samulowitz, Horst},
title = {Autonomous Predictive Modeling via Reinforcement Learning},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3417448},
doi = {10.1145/3340531.3417448},
abstract = {Building a robust predictive model requires an array of steps such as data imputation, feature transformations, estimator selection, hyper-parameter search, ensemble construction, amongst others. Due to this vast, complex and heterogeneous space of operations, off-the-shelf optimization methods offer infeasible solutions for realistic response time requirements. In practice, much of the predictive modeling process is conducted by experienced data scientists, who selectively make use of available tools. Over time, they develop an understanding of the behavior of operators, and perform serial decision making under uncertainty, colloquially referred to as educated guesswork. With an unprecedented demand for application of supervised machine learning, there is a call for solutions that automatically search for a suitable combination of operators across these tasks while minimize the modeling error. We introduce a novel system called APRL (Autonomous Predictive modeler via Reinforcement Learning), that uses past experience through reinforcement learning to optimize sequential decision making from within a set of diverse actions under a budget constraint. Our experiments demonstrate the superiority of the proposed approach over known AutoML systems that utilize Bayesian optimization or genetic algorithms.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {3285–3288},
numpages = {4},
keywords = {reinforcement learning, data science automation, automated machine learning},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@article{10.1007/s10270-017-0614-9,
author = {Guizzo, Giovani and Colanzi, Thelma Elita and Vergilio, Silvia Regina},
title = {Applying design patterns in the search-based optimization of software product line architectures},
year = {2019},
issue_date = {Apr 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {2},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-017-0614-9},
doi = {10.1007/s10270-017-0614-9},
abstract = {The design of the product line architecture (PLA) is a difficult activity that can benefit from the application of design patterns and from the use of a search-based optimization approach, which is generally guided by different objectives related, for instance, to cohesion, coupling and PLA extensibility. The use of design patterns for PLAs is a recent research field, not completely explored yet. Some works apply the patterns manually and for a specific domain. Approaches to search-based PLA design do not consider the usage of these patterns. To allow such use, this paper introduces a mutation operator named “Pattern-Driven Mutation Operator” that includes methods to automatically identify suitable scopes and apply the patterns Strategy, Bridge and Mediator with the search-based approach multi-objective optimization approach for PLA. A metamodel is proposed to represent and identify suitable scopes to receive each one of the patterns, avoiding the introduction of architectural anomalies. Empirical results are also presented, showing evidences that the use of the proposed operator produces a greater diversity of solutions and improves the quality of the PLAs obtained in the search-based optimization process, regarding the values of software metrics.},
journal = {Softw. Syst. Model.},
month = apr,
pages = {1487–1512},
numpages = {26},
keywords = {Software product line architecture, Search-based software engineering, Design pattern}
}

@inproceedings{10.1145/3425269.3425278,
author = {Bindewald, Carlos Vinicius and Freire, Willian M. and Amaral, Aline M. M. Miotto and Colanzi, Thelma Elita},
title = {Supporting user preferences in search-based product line architecture design using Machine Learning},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425278},
doi = {10.1145/3425269.3425278},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line. PLA design requires intensive human effort as it involves several conflicting factors. In order to support this task, an interactive search-based approach, automated by a tool named OPLA-Tool, was proposed in a previous work. Through this tool the software architect evaluates the generated solutions during the optimization process. Considering that evaluating PLA is a complex task and search-based algorithms demand a high number of generations, the evaluation of all solutions in all generations cause human fatigue. In this work, we incorporated in OPLA-Tool a Machine Learning (ML) model to represent the architect in some moments during the optimization process aiming to decrease the architect's effort. Through the execution of a quantiqualitative exploratory study it was possible to demonstrate the reduction of the fatigue problem and that the solutions produced at the end of the process, in most cases, met the architect's needs.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {11–20},
numpages = {10},
keywords = {Product Line Architecture, Machine Learning, Human-computer interaction},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@article{10.1016/j.knosys.2019.104883,
author = {Ayala, Inmaculada and Amor, Mercedes and Horcas, Jose-Miguel and Fuentes, Lidia},
title = {A goal-driven software product line approach for evolving multi-agent systems in the Internet of Things},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {184},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.104883},
doi = {10.1016/j.knosys.2019.104883},
journal = {Know.-Based Syst.},
month = nov,
numpages = {18},
keywords = {GORE, Goal models, MAS-PL, Internet of Things, Evolution, Software product line}
}

@inproceedings{10.1145/3266237.3266275,
author = {Filho, Helson Luiz Jakubovski and Ferreira, Thiago Nascimento and Vergilio, Silvia Regina},
title = {Multiple objective test set selection for software product line testing: evaluating different preference-based algorithms},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266275},
doi = {10.1145/3266237.3266275},
abstract = {The selection of optimal test sets for Software Product Lines (SPLs) is a complex task impacted by many factors and that needs to consider the tester's preferences. To help in this task, Preference-based Evolutionary Multi-objective Algorithms (PEMOAs) have been explored. They use a Reference Point (RP), which represents the user preference and guides the search, resulting in a greater number of solutions in the ROI (Region of Interest). This region contains solutions that are more interesting from the tester's point of view. However, the explored PEMOAs have not been compared yet and the results reported in the literature do not consider many-objective formulations. Such an evaluation is important because in the presence of more than three objectives the performance of the algorithms may change and the number of solutions increases. Considering this fact, this work presents evaluation results of four PEMOAs for selection of products in the SPL testing considering cost, testing criteria coverage, products similarity, and the number of revealed faults, given by the mutation score. The PEMOAs present better performance than traditional algorithms, avoiding uninteresting solutions. We introduce a hyper-heuristic version of the PEMOA R-NSGA-II that presents the best results in a general case.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {162–171},
numpages = {10},
keywords = {software product line testing, search-based software engineering, preference-based multi-objective algorithms},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@inproceedings{10.1145/2362536.2362580,
author = {Hamza, Haitham S. and Martinez, Jabier and Thurimella, Anil Kumar and Deogun, Jitender S.},
title = {Third International Workshop on Knowledge-Oriented Product Line Engineering (KOPLE 2012)},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362580},
doi = {10.1145/2362536.2362580},
abstract = {Software Product Line Engineering (PLE) exploits systematic reuse by identifying and methodically reusing software artifacts to develop different but related software systems. Developing Product Lines requires analysis skills to identify, model, and encode domain and product knowledge into artifacts that can be systematically reused across the development life-cycle. As such, Knowledge plays a paramount role in the success of the various activities of PLE. The objective of the KOPLE workshop series is to bring together SPL researchers and practitioners from academia and industry to investigate the role of Knowledge in PLE. Knowledge is usually encapsulated in PL architectures in a tacit or implicit way, and this may appear to be sufficient for industry to implement successful product lines. Nevertheless, KOPLE also aims to become a discussion forum about techniques and methods to convert from tacit to explicit Knowledge in PLE and to process and use this Knowledge for optimizing and innovating PLE processes.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {292–293},
numpages = {2},
keywords = {tacit knowledge, software reuse, product lines, ontology, knowledge engineering, conceptual graphs},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3382025.3414976,
author = {Pereira, Juliana Alves and Martin, Hugo and Temple, Paul and Acher, Mathieu},
title = {Machine learning and configurable systems: a gentle introduction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414976},
doi = {10.1145/3382025.3414976},
abstract = {The goal of this tutorial is to give a gentle introduction to how machine learning can be used to support software product line configuration. This is our second practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance and bug prediction) on real-world systems (Linux, VaryLaTeX, x264). The material is designed for academics and practitioners with basic knowledge in software product lines and machine learning.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {40},
numpages = {1},
keywords = {software product lines, machine learning, configurable systems},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3461002.3473947,
author = {Pinnecke, Marcus},
title = {Product-lining the elinvar wealthtech microservice platform},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473947},
doi = {10.1145/3461002.3473947},
abstract = {Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {60–68},
numpages = {9},
keywords = {variability management, technologies and concepts, product families, microservice platforms, configuration management},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1007/s10664-014-9358-0,
author = {Koziolek, Heiko and Goldschmidt, Thomas and Gooijer, Thijmen and Domis, Dominik and Sehestedt, Stephan and Gamer, Thomas and Aleksy, Markus},
title = {Assessing software product line potential: an exploratory industrial case study},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9358-0},
doi = {10.1007/s10664-014-9358-0},
abstract = {Corporate organizations sometimes offer similar software products in certain domains due to former company mergers or due to the complexity of the organization. The functional overlap of such products is an opportunity for future systematic reuse to reduce software development and maintenance costs. Therefore, we have tailored existing domain analysis methods to our organization to identify commonalities and variabilities among such products and to assess the potential for software product line (SPL) approaches. As an exploratory case study, we report on our experiences and lessons learned from conducting the domain analysis in four application cases with large-scale software products. We learned that the outcome of a domain analysis was often a smaller integration scenario instead of an SPL and that business case calculations were less relevant for the stakeholders and managers from the business units during this phase. We also learned that architecture reconstruction using a simple block diagram notation aids domain analysis and that large parts of our approach were reusable across application cases.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {411–448},
numpages = {38},
keywords = {Software product lines, Domain analysis, Business case}
}

@article{10.1007/s10994-021-06091-7,
author = {S\"{u}rer, \"{O}zge and Apley, Daniel W. and Malthouse, Edward C.},
title = {Coefficient tree regression: fast, accurate and interpretable predictive modeling},
year = {2021},
issue_date = {Jul 2024},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {113},
number = {7},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-021-06091-7},
doi = {10.1007/s10994-021-06091-7},
abstract = {The proliferation of data collection technologies often results in large data sets with many observations and many variables. In practice, highly relevant engineered features are often groups of predictors that share a common regression coefficient (i.e., the predictors in the group affect the response only via their collective sum), where the groups are unknown in advance and must be discovered from the data. We propose an algorithm called coefficient tree regression (CTR) to discover the group structure and fit the resulting regression model. In this regard CTR is an automated way of engineering new features, each of which is the collective sum of the predictors within each group. The algorithm can be used when the number of variables is larger than, or smaller than, the number of observations. Creating new features that affect the response in a similar manner improves predictive modeling, especially in domains where the relationships between predictors are not known a priori. CTR borrows computational strategies from both linear regression (fast model updating when adding/modifying a feature in the model) and regression trees (fast partitioning to form and split groups) to achieve outstanding computational and predictive performance. Finding features that represent hidden groups of predictors (i.e., a hidden ontology) that impact the response only via their sum also has major interpretability advantages, which we demonstrate with a real data example of predicting political affiliations with television viewing habits. In numerical comparisons over a variety of examples, we demonstrate that both computational expense and predictive performance are far superior to existing methods that create features as groups of predictors. Moreover, CTR has overall predictive performance that is comparable to or slightly better than the regular lasso method, which we include as a reference benchmark for comparison even though it is non-group-based, in addition to having substantial computational and interpretive advantages over lasso.},
journal = {Mach. Learn.},
month = nov,
pages = {4723–4759},
numpages = {37},
keywords = {Aggregation, Group structure, Ontology, Feature engineering}
}

@article{10.1007/s10664-016-9494-9,
author = {Li, Xuelin and Wong, W. Eric and Gao, Ruizhi and Hu, Linghuan and Hosono, Shigeru},
title = {Genetic Algorithm-based Test Generation for Software Product Line with the Integration of Fault Localization Techniques},
year = {2018},
issue_date = {February  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9494-9},
doi = {10.1007/s10664-016-9494-9},
abstract = {In response to the highly competitive market and the pressure to cost-effectively release good-quality software, companies have adopted the concept of software product line to reduce development cost. However, testing and debugging of each product, even from the same family, is still done independently. This can be very expensive. To solve this problem, we need to explore how test cases generated for one product can be used for another product. We propose a genetic algorithm-based framework which integrates software fault localization techniques and focuses on reusing test specifications and input values whenever feasible. Case studies using four software product lines and eight fault localization techniques were conducted to demonstrate the effectiveness of our framework. Discussions on factors that may affect the effectiveness of the proposed framework is also presented. Our results indicate that test cases generated in such a way can be easily reused (with appropriate conversion) between different products of the same family and help reduce the overall testing and debugging cost.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {1–51},
numpages = {51},
keywords = {Test generation, Software product line, Genetic algorithm, EXAM score, Debugging/fault localization, Coverage}
}

@inproceedings{10.1145/3336294.3342383,
author = {Martin, Hugo and Pereira, Juliana Alves and Acher, Mathieu and Temple, Paul},
title = {Machine Learning and Configurable Systems: A Gentle Introduction},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3342383},
doi = {10.1145/3336294.3342383},
abstract = {The goal of this tutorial is to give an introduction to how machine learning can be used to support activities related to the engineering of configurable systems and software product lines. To the best of our knowledge, this is the first practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance prediction) on real-world systems (VaryLaTeX, x264).},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {325–326},
numpages = {2},
keywords = {software product lines, machine learning, configurable systems},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2364412.2364425,
author = {Cordy, Maxime and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel},
title = {Towards an incremental automata-based approach for software product-line model checking},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364425},
doi = {10.1145/2364412.2364425},
abstract = {Most model-checking algorithms are based on automata theory. For instance, determining whether or not a transition system satisfies a Linear Temporal Logic (LTL) formula requires computing strongly connected component of its transition graph. In Software Product-Line (SPL) engineering, the model checking problem is more complex due to the huge amount of software products that may compose the line. Indeed, one has to determine the exact subset of those products that do not satisfy an intended property. Efficient dedicated verification methods have been recently developed to answer this problem. However, most of them does not allow incremental verification. In this paper, we introduce an automata-based incremental approach for SPL model checking. Our method makes use of previous results to determine whether or not the addition of conservative features (i.e., features that do not remove behaviour from the system) preserves the satisfaction of properties expressed in LTL. We provide a detailed description of the approach and propose algorithms that implement it. We discuss how our method can be combined with SPL dedicated verification methods, viz. Featured Transition Systems.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {74–81},
numpages = {8},
keywords = {software product lines, modularity, model checking},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1007/978-3-030-86230-5_19,
author = {Monteiro, Mariana and Louren\c{c}o, Nuno and Pereira, Francisco B.},
title = {FERMAT: Feature Engineering with Grammatical Evolution},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_19},
doi = {10.1007/978-3-030-86230-5_19},
abstract = {Feature engineering is a key step in a machine learning study. We propose FERMAT, a grammatical evolution framework for the automatic discovery of an optimal set of engineered features, with enhanced ability to characterize data. The framework contains a grammar specifying the original features and possible operations that can be applied to data. The optimization process searches for a transformation strategy to apply to the original dataset, aiming at creating a novel characterization composed by a combination of original and engineered attributes. FERMAT was applied to two real-world drug development datasets and results reveal that the framework is able to craft novel representations for data that foster the predictive ability of tree-based regression models.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {239–251},
numpages = {13},
keywords = {Drug development, Grammatical evolution, Feature engineering}
}

@inproceedings{10.1145/2739482.2764650,
author = {Karimpour, Reza and Ruhe, Guenther},
title = {A Search Based Approach Towards Robust Optimization in Software Product Line Scoping},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2764650},
doi = {10.1145/2739482.2764650},
abstract = {Software product line (SPL) scoping is important for planning upfront investment. One challenge with scoping comes from inaccuracies in estimated parameters and uncertainty in environment. In this paper, a method to incorporate uncertainty in SPL scoping optimization and its application to generate robust solutions is proposed. We model scoping optimization as a multi-objective problem with profit and stability as heuristics. To evaluate our proposal, a number of experiments are conducted. Analysis of results show that both performance stability and feasibility stability were improved providing the product line manager enhanced decision-making support.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1415–1416},
numpages = {2},
keywords = {uncertainty, software product line portfolio scoping, robust optimization, multi-objective},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.1109/CEC.2018.8477803,
author = {Luiz Jakubovski Filho, Helson and Nascimento Ferreira, Thiago and Regina Vergilio, Silvia},
title = {Incorporating User Preferences in a Software Product Line Testing Hyper-Heuristic Approach},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC.2018.8477803},
doi = {10.1109/CEC.2018.8477803},
abstract = {To perform the variability testing of Software Product Lines (SPLs) a set of products, represented in the Feature Model (FM), should be selected. Such selection is impacted by conflicting factors and has been efficiently solved by Evolutionary Multi-objective Algorithms in combination with hyper-heuristics. However, many times there is a cost budget or coverage level to be satisfied during the test, which are difficult to be incorporated as objective functions. Due to this, the choice of the best solution to be used in practice is not always easy. To deal with this situation, this paper introduces a preference-based hyper-heuristic approach to solve this problem. The approach implements the preference-based algorithm r-NSGA-II working with the random and FRRMAB selection methods. This last one uses a reward function based on r-dominance concept that takes into consideration a Reference Point provided by the tester. Our approach outperforms existing approaches, as well as the traditional algorithm r-NSGA-II, generating a reduced number of non-interesting solutions from the tester's point of view, that is, considering the provided Region of Interest (ROI).},
booktitle = {2018 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1–8},
numpages = {8},
location = {Rio de Janeiro, Brazil}
}

@inproceedings{10.1145/3168365.3168373,
author = {Pereira, Juliana Alves and Schulze, Sandro and Krieter, Sebastian and Ribeiro, M\'{a}rcio and Saake, Gunter},
title = {A Context-Aware Recommender System for Extended Software Product Line Configurations},
year = {2018},
isbn = {9781450353984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168365.3168373},
doi = {10.1145/3168365.3168373},
abstract = {Mass customization of standardized products has become a trend to succeed in today's market environment. Software Product Lines (SPLs) address this trend by describing a family of software products that share a common set of features. However, choosing the appropriate set of features that matches a user's individual interests is hampered due to the overwhelming amount of possible SPL configurations. Recommender systems can address this challenge by filtering the number of configurations and suggesting a suitable set of features for the user's requirements. In this paper, we propose a context-aware recommender system for predicting feature selections in an extended SPL configuration scenario, i.e. taking nonfunctional properties of features into consideration. We present an empirical evaluation based on a large real-world dataset of configurations derived from industrial experience in the Enterprise Resource Planning domain. Our results indicate significant improvements in the predictive accuracy of our context-aware recommendation approach over a state-of-the-art binary-based approach.},
booktitle = {Proceedings of the 12th International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {97–104},
numpages = {8},
keywords = {Software Product Lines, Recommender Systems, Non-Functional Properties, Feature Model, Configuration},
location = {Madrid, Spain},
series = {VAMOS '18}
}

@inproceedings{10.1145/3001867.3001872,
author = {Lity, Sascha and Kowal, Matthias and Schaefer, Ina},
title = {Higher-order delta modeling for software product line evolution},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001872},
doi = {10.1145/3001867.3001872},
abstract = {In software product lines (SPL), i.e., a family of similar software systems sharing common and variable artifacts, modeling evolution and reasoning about it is challenging, as not only a single system, but rather a set of system variants as well as their interdependencies change. An integrated modeling formalism for variability and evolution is required to allow the capturing of evolution operations that are applied to SPL artifacts, and to facilitate the impact analysis of evolution on the artifact level. Delta modeling is a flexible transformational variability modeling approach, where the variability and commonality between variants are explicitly documented and analyzable by means of transformations modeled as deltas. In this paper, we lift the notion of delta modeling to capture both, variability and evolution, by deltas. We evolve a delta model specifying a set of variants by applying higher-order deltas. A higher-order delta encapsulates evolution operations, i.e., additions, removals, or modifications of deltas, and transforms a delta model in its new version. In this way, we capture the complete evolution history of delta-oriented SPLs by higher-order delta models. By analyzing each higher-order delta application, we are further able to reason about the impact and, thus, the changes to the specified set of variants. We prototypically implement our formalism and show its applicability using a system from the automation engineering domain.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {39–48},
numpages = {10},
keywords = {Software Product Lines, Software Evolution, Delta Modeling},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@inproceedings{10.1145/3233027.3233047,
author = {El-Sharkawy, Sascha and Dhar, Saura Jyoti and Krafczyk, Adam and Duszynski, Slawomir and Beichter, Tobias and Schmid, Klaus},
title = {Reverse engineering variability in an industrial product line: observations and lessons learned},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233047},
doi = {10.1145/3233027.3233047},
abstract = {Ideally, a variability model is a correct and complete representation of product line features and constraints among them. Together with a mapping between features and code, this ensures that only valid products can be configured and derived. However, in practice the modeled constraints might be neither complete nor correct, which causes problems in the configuration and product derivation phases. This paper presents an approach to reverse engineer variability constraints from the implementation, and thus improve the correctness and completeness of variability models.We extended the concept of feature effect analysis [22] to extract variability constraints from code artifacts of the Bosch PS-EC large-scale product line. We present an industrial application of the approach and discuss its required modifications to handle non-Boolean variability and heterogeneous artifact types.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {215–225},
numpages = {11},
keywords = {variability modeling, static analysis, software product lines, reverse engineering},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2851613.2851964,
author = {Cool, Benjamin and Knieke, Christoph and Rausch, Andreas and Schindler, Mirco and Strasser, Arthur and Vogel, Martin and Brox, Oliver and Jauns-Seyfried, Stefanie},
title = {From product architectures to a managed automotive software product line architecture},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851964},
doi = {10.1145/2851613.2851964},
abstract = {To keep the software development for vehicles cost efficient, software components are reused for different variants as well as for succeeding generations. Furthermore, cost reductions are achieved by software sharing between the Original Equipment Manufacturer (OEM) and the suppliers. However, as a consequence of the blackboxed view caused by software sharing, no common detailed software product line architecture specification for the Electronic Control Unit (ECU) software exists, as it would be required for analyzing the quality of the product line architecture, planning changes on the product line architecture, checking the compliance between the product architecture and the product line architecture, and therefore, avoiding architecture erosion. Thus, after several product generations, software erosion is growing steadily, resulting in an increasing effort of reusing software components, and planning of further development. Here, we propose an approach for repairing an eroded software consisting of a set of product architectures by applying strategies for recovery and discovery of the product line architecture. Furthermore, we give a methodology for a long-term manageable, plannable, and reuseable software product line architecture for automotive software systems.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1350–1353},
numpages = {4},
keywords = {architecture evolution, architecture quality measures, automotive, software erosion, software product lines},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/2889443.2889451,
author = {Cafeo, Bruno B. P. and Hunsen, Claus and Garcia, Alessandro and Apel, Sven and Lee, Jaejoon},
title = {Segregating feature interfaces to support software product line maintenance},
year = {2016},
isbn = {9781450339957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889443.2889451},
doi = {10.1145/2889443.2889451},
abstract = {Although software product lines are widely used in practice, their maintenance is challenging. Features as units of behaviour can be heavily scattered across the source code of a product line, hindering modular reasoning. To alleviate this problem, feature interfaces aim at enhancing modular reasoning about features. However, considering all members of a feature interface is often cumbersome, especially due to the large number of members arising in practice. To address this problem, we present an approach to group members of a feature interface based on their mutual dependencies. We argue that often only a subset of all interface members is relevant to a maintenance task. Therefore, we propose a graph representation that is able to capture the collaboration between members and apply a clustering algorithm to it to group highly-related members and segregate non-related members. On a set of ten versions of a real-world product line, we evaluate the effectiveness of our approach, by comparing the two types of feature interfaces (segregated vs. original interfaces) with co-change information from the version-control system. We found a potential reduction of 62% of the interface members to be considered during maintenance. This way, the effort to reason about features can be reduced.},
booktitle = {Proceedings of the 15th International Conference on Modularity},
pages = {1–12},
numpages = {12},
keywords = {Software Product Lines, Feature Interface, Feature Dependencies},
location = {M\'{a}laga, Spain},
series = {MODULARITY 2016}
}

@article{10.1109/TCBB.2021.3089682,
author = {Wang, Shuwen and Zhu, Xingquan},
title = {Predictive Modeling of Hospital Readmission: Challenges and Solutions},
year = {2021},
issue_date = {Sept.-Oct. 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {5},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3089682},
doi = {10.1109/TCBB.2021.3089682},
abstract = {Hospital readmission prediction is a study to learn models from historical medical data to predict probability of a patient returning to hospital in a certain period, &lt;italic&gt;e.g.&lt;/italic&gt; 30 or 90 days, after the discharge. The motivation is to help health providers deliver better treatment and post-discharge strategies, lower the hospital readmission rate, and eventually reduce the medical costs. Due to inherent complexity of diseases and healthcare ecosystems, modeling hospital readmission is facing many challenges. By now, a variety of methods have been developed, but existing literature fails to deliver a complete picture to answer some fundamental questions, such as what are the main challenges and solutions in modeling hospital readmission; what are typical features/models used for readmission prediction; how to achieve meaningful and transparent predictions for decision making; and what are possible conflicts when deploying predictive approaches for real-world usages. In this paper, we systematically review computational models for hospital readmission prediction, and propose a taxonomy of challenges featuring four main categories: (1) data variety and complexity; (2) data imbalance, locality and privacy; (3) model interpretability; and (4) model implementation. The review summarizes methods in each category, and highlights technical solutions proposed to address the challenges. In addition, a review of datasets and resources available for hospital readmission modeling also provides firsthand materials to support researchers and practitioners to design new approaches for effective and efficient hospital readmission prediction.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jun,
pages = {2975–2995},
numpages = {21}
}

@inproceedings{10.1145/1808937.1808942,
author = {Estublier, Jacky and Dieng, Idrissa A. and Leveque, Thomas},
title = {Software product line evolution: the Selecta system},
year = {2010},
isbn = {9781605589688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808937.1808942},
doi = {10.1145/1808937.1808942},
abstract = {The current technology gives little room for the different kinds of evolution needed for any software product line (SPL): evolution of the associated engineering environment, evolution of the market and SPL scope, evolution of the products and variability. The paper describes how these different evolution needs are addressed in the CADSE and Selecta systems. The solution we propose uses metamodeling and generation for the engineering environment evolution, composition for scope and market evolution, a component database and a selection language for the product and variability evolution. The paper presents the Selecta system and shortly discusses the experience.},
booktitle = {Proceedings of the 2010 ICSE Workshop on Product Line Approaches in Software Engineering},
pages = {32–39},
numpages = {8},
keywords = {software environments, product lines, product families, evolution, IDE},
location = {Cape Town, South Africa},
series = {PLEASE '10}
}

@article{10.1007/s10515-014-0160-4,
author = {Devine, Thomas and Goseva-Popstojanova, Katerina and Krishnan, Sandeep and Lutz, Robyn R.},
title = {Assessment and cross-product prediction of software product line quality: accounting for reuse across products, over multiple releases},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-014-0160-4},
doi = {10.1007/s10515-014-0160-4},
abstract = {The goals of cross-product reuse in a software product line (SPL) are to mitigate production costs and improve the quality. In addition to reuse across products, due to the evolutionary development process, a SPL also exhibits reuse across releases. In this paper, we empirically explore how the two types of reuse--reuse across products and reuse across releases--affect the quality of a SPL and our ability to accurately predict fault proneness. We measure the quality in terms of post-release faults and consider different levels of reuse across products (i.e., common, high-reuse variation, low-reuse variation, and single-use packages), over multiple releases. Assessment results showed that quality improved for common, low-reuse variation, and single-use packages as they evolved across releases. Surprisingly, within each release, among preexisting (`old') packages, the cross-product reuse did not affect the change and fault proneness. Cross-product predictions based on pre-release data accurately ranked the packages according to their post-release faults and predicted the 20 % most faulty packages. The predictions benefited from data available for other products in the product line, with models producing better results (1) when making predictions on smaller products (consisting mostly of common packages) rather than on larger products and (2) when trained on larger products rather than on smaller products.},
journal = {Automated Software Engg.},
month = jun,
pages = {253–302},
numpages = {50},
keywords = {Software product lines, Longitudinal study, Fault proneness prediction, Cross-release reuse, Cross-product reuse, Cross-product prediction, Assessment}
}

@inproceedings{10.1145/2791060.2791110,
author = {McVoy, Larry},
title = {Preliminary product line support in BitKeeper},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791110},
doi = {10.1145/2791060.2791110},
abstract = {One of the challenges of implementing a product line process is finding the appropriate tools for automation. One of our larger customers was implementing a product line process by-hand in a labor intensive and fragile way. We collaborated with them to evolve our distributed version control system, BitKeeper, into a tool that could handle their performance and product line requirements. The resulting product line generated several complex CPUs (around a billion transistors each).In this paper, we describe their by-hand process for producing different variations of a computer processor; we'll provide some background on the distributed version control system they were using; we'll describe the architectural changes implemented in BitKeeper for supporting product line work flows; we'll describe some of the changes we did to increase performance and provide some benchmark results comparing BitKeeper to Git, and we'll describe the work flow resulting from using the new architecture to replace their by-hand process.In the final section we'll discuss the current limitations of the existing tool, and describe how we plan on evolving it to overcome those limitations.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {245–252},
numpages = {8},
keywords = {version control, software product lines, configuration management, code reuse},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1007/s11227-021-03708-5,
author = {Taranto-Vera, Gilda and Galindo-Villard\'{o}n, Purificaci\'{o}n and Merch\'{a}n-S\'{a}nchez-Jara, Javier and Salazar-Pozo, Julio and Moreno-Salazar, Alex and Salazar-Villalva, Vanessa},
title = {Algorithms and software for data mining and machine learning: a critical comparative view from a systematic review of the literature},
year = {2021},
issue_date = {Oct 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {10},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-021-03708-5},
doi = {10.1007/s11227-021-03708-5},
abstract = {Today, a greater generation of information is produced as a consequence of the technological development of society. The Internet has facilitated the access and extraction of this information, thus pursuing the automatic discovery of the knowledge contained within. In this context, data mining aims to discover patterns, profiles and trends of a large volume of data, for which multiple learning techniques are available. The selection of which technique to use depends on the type of result desired to obtain and the data that are available, considering that the algorithms for these tasks date mostly from the early twentieth century and are now the basis of these new technologies. The aim of this study is to show the development of these techniques in the field of scientific research and to present the evolution of algorithms and software for data mining in recent years. To this end, the systematic literature review methodology was applied, as it is considered a systematic process that identifies, evaluates, and interprets the work of researchers in a chosen field. As a result, we present a comparative analysis of the most outstanding software: Alteryx, TIBCO Data Science, RapidMiner and WEKA, their capacities for data mining processes and a description of the algorithms and techniques of machine learning that are currently on the rise.},
journal = {J. Supercomput.},
month = oct,
pages = {11481–11513},
numpages = {33},
keywords = {Performance evaluation, Software tools, Systematic literature review, Algorithms, Machine learning techniques, Data mining}
}

@inproceedings{10.1145/2791060.2791106,
author = {Smiley, Karen and Schmidt, Werner and Dagnino, Aldo},
title = {Evolving an industrial analytics product line architecture},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791106},
doi = {10.1145/2791060.2791106},
abstract = {This paper focuses on an industrial experience with software product lines of analytics-enabled solutions, specifically the evolution of the software product line architecture for a Subject Matter Expert Workbench toolset which supports analytic plugins for multiple software product lines. As context, the toolset product line was intended for integration of expert knowledge into a family of industrial asset health applications at runtime. The toolset architecture is now being evolved to build and manage plugins for multiple Industrial Analytics solutions (software systems and services) beyond asset health. This evolution is driving changes in the desired architecture qualities of the toolset; widening the stakeholder pool and influencing priorities; affecting the architecture tradeoffs and decisions; and triggering updates to the product line architecture, the guidance for applying it, and the current prototype of the toolset. We describe our experiences in handling this evolution, assess lessons learned, and discuss potential relevance to other product line scenarios.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {263–272},
numpages = {10},
keywords = {software product line, reusability, performance, knowledge, interoperability, industrial analytics, extensibility, asset health},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.infsof.2012.09.007,
author = {Guana, Victor and Correal, Dario},
title = {Improving software product line configuration: A quality attribute-driven approach},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.09.007},
doi = {10.1016/j.infsof.2012.09.007},
abstract = {Context: During the definition of software product lines (SPLs) it is necessary to choose the components that appropriately fulfil a product's intended functionalities, including its quality requirements (i.e., security, performance, scalability). The selection of the appropriate set of assets from many possible combinations is usually done manually, turning this process into a complex, time-consuming, and error-prone task. Objective: Our main objective is to determine whether, with the use of modeling tools, we can simplify and automate the definition process of a SPL, improving the selection process of reusable assets. Method: We developed a model-driven strategy based on the identification of critical points (sensitivity points) inside the SPL architecture. This strategy automatically selects the components that appropriately match the product's functional and quality requirements. We validated our approach experimenting with different real configuration and derivation scenarios in a mobile healthcare SPL where we have worked during the last three years. Results: Through our SPL experiment, we established that our approach improved in nearly 98% the selection of reusable assets when compared with the unassisted analysis selection. However, using our approach there is an increment in the time required for the configuration corresponding to the learning curve of the proposed tools. Conclusion: We can conclude that our domain-specific modeling approach significantly improves the software architect's decision making when selecting the most suitable combinations of reusable components in the context of a SPL.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {541–562},
numpages = {22},
keywords = {Variability management, Software architecture, Sensitivity points, Quality evaluation, Model driven - software product lines, Domain specific modeling}
}

@article{10.1016/j.future.2019.07.056,
author = {F. de S. Soares, Elton and V. Campos, Carlos Alberto and C. de Lucena, Sidney},
title = {Online travel mode detection method using automated machine learning and feature engineering},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {101},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.07.056},
doi = {10.1016/j.future.2019.07.056},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {1201–1212},
numpages = {12},
keywords = {Intelligent transportation systems, Smart mobility, Automated machine learning, Feature engineering, Travel mode detection}
}

@article{10.1007/s10207-019-00434-1,
author = {Aamir, Muhammad and Zaidi, Syed Mustafa Ali},
title = {DDoS attack detection with feature engineering and machine learning: the framework and performance evaluation},
year = {2019},
issue_date = {Dec 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1615-5262},
url = {https://doi.org/10.1007/s10207-019-00434-1},
doi = {10.1007/s10207-019-00434-1},
abstract = {This paper applies an organized flow of feature engineering and machine learning to detect distributed denial-of-service (DDoS) attacks. Feature engineering has a focus to obtain the datasets of different dimensions with significant features, using feature selection methods of backward elimination, chi2, and information gain scores. Different supervised machine learning models are applied on the feature-engineered datasets to demonstrate the adaptability of datasets for machine learning under optimal tuning of parameters within given sets of values. The results show that substantial feature reduction is possible to make DDoS detection faster and optimized with minimal performance hit. The paper proposes a strategic-level framework which incorporates the necessary elements of feature engineering and machine learning with a defined flow of experimentation. The models are also validated with cross-validation and evaluated for area-under-curve analyses. It provides comprehensive solutions which can be trusted to avoid the overfitting and collinearity problems of data while detecting DDoS attacks. In the case study of DDoS datasets, K-nearest neighbors algorithm overall exhibits the best performance followed by support vector machine, whereas low-dimensional datasets of discrete feature types perform better under the Random Forest model as compared to high dimensions with numerical features. The accuracy scores of dataset with the lowest number of features remain competitive with other datasets under all machine learning models, leading to a substantially reduced processing overhead. The experiments show that approximately 68% reduction in the feature space is possible with an impact of only about 0.03% on accuracy.},
journal = {Int. J. Inf. Secur.},
month = dec,
pages = {761–785},
numpages = {25},
keywords = {Neural network, Machine learning, Feature selection, Feature engineering, denial-of-service, DDoS attacks, Cyber security}
}

@inproceedings{10.1007/978-3-030-77967-2_48,
author = {Elkhovskaya, Liubov and Kovalchuk, Sergey},
title = {Feature Engineering with Process Mining Technique for Patient State Predictions},
year = {2021},
isbn = {978-3-030-77966-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77967-2_48},
doi = {10.1007/978-3-030-77967-2_48},
abstract = {Process mining is an emerging study area adopting a data-driven approach and classical model-based process analysis. Process mining techniques are applicable in different domains and may represent standalone tools or integrated solutions within other fields. In this paper, we propose an approach based on a meta-states concept to extract additional features from discovered process models for predictive modelling. We show how a simple assumption about cyclic process behaviours can not only help to structure and interpret the process model but to be used in machine learning tasks. We demonstrate the proposed approach for hypertension control status prognosis within a remote monitoring program. The results are potential for medical diagnosis and model interpretation.},
booktitle = {Computational Science – ICCS 2021: 21st International Conference, Krakow, Poland, June 16–18, 2021, Proceedings, Part III},
pages = {584–592},
numpages = {9},
keywords = {Health status prediction, Feature engineering, Machine learning, Process discovery, Process mining},
location = {Krakow, Poland}
}

@article{10.1145/3485062,
author = {Allen, Becky and McGough, Andrew Stephen and Devlin, Marie},
title = {Toward a Framework for Teaching Artificial Intelligence to a Higher Education Audience},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
url = {https://doi.org/10.1145/3485062},
doi = {10.1145/3485062},
abstract = {Artificial Intelligence and its sub-disciplines are becoming increasingly relevant in numerous areas of academia as well as industry and can now be considered a core area of Computer Science [84]. The Higher Education sector are offering more courses in Machine Learning and Artificial Intelligence than ever before. However, there is a lack of research pertaining to best practices for teaching in this complex domain that heavily relies on both computing and mathematical knowledge. We conducted a literature review and qualitative study with students and Higher Education lecturers from a range of educational institutions, with an aim to determine what might constitute best practices in this area in Higher Education. We hypothesised that confidence, mathematics anxiety, and differences in student educational background were key factors here. We then investigated the issues surrounding these and whether they inhibit the acquisition of knowledge and skills pertaining to the theoretical basis of artificial intelligence and machine learning. This article shares the insights from both students and lecturers with experience in the field of AI and machine learning education, with the aim to inform prospective pedagogies and studies within this domain and move toward a framework for best practice in teaching and learning of these topics.},
journal = {ACM Trans. Comput. Educ.},
month = nov,
articleno = {15},
numpages = {29},
keywords = {self-efficacy, pedagogy, Artificial intelligence}
}

@article{10.1016/j.eswa.2021.114591,
author = {Jahangir, Rashid and Teh, Ying Wah and Nweke, Henry Friday and Mujtaba, Ghulam and Al-Garadi, Mohammed Ali and Ali, Ihsan},
title = {Speaker identification through artificial intelligence techniques: A comprehensive review and research challenges},
year = {2021},
issue_date = {Jun 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114591},
doi = {10.1016/j.eswa.2021.114591},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {29},
keywords = {Speech databases, Deep learning, Artificial Intelligence, Acoustic features, Survey, Speaker identification}
}

@article{10.1016/j.compbiomed.2021.104517,
author = {Kreimeyer, Kory and Dang, Oanh and Spiker, Jonathan and Mu\~{n}oz, Monica A. and Rosner, Gary and Ball, Robert and Botsis, Taxiarchis},
title = {Feature engineering and machine learning for causality assessment in pharmacovigilance: Lessons learned from application to the FDA Adverse Event Reporting System},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104517},
doi = {10.1016/j.compbiomed.2021.104517},
journal = {Comput. Biol. Med.},
month = aug,
numpages = {9},
keywords = {Pharmacovigilance, Case classification, Clinical natural language processing, Decision support, Causality assessment}
}

@inproceedings{10.1145/1629716.1629720,
author = {Chae, Wonseok and Blume, Matthias},
title = {Language support for feature-oriented product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629720},
doi = {10.1145/1629716.1629720},
abstract = {Product line engineering is an emerging paradigm of developing a family of products. While product line analysis and design mainly focus on reasoning about commonality and variability of family members, product line implementation gives its attention to mechanisms of managing variability. In many cases, however, product line methods do not impose any specific synthesis mechanisms on product line implementation, so implementation details are left to developers. In our previous work, we adopted feature-oriented product line engineering to build a family of compilers and managed variations using the Standard ML module system. We demonstrated the applicability of this module system to product line implementation. Although we have benefited from the product line engineering paradigm, it mostly served us as a design paradigm to change the way we think about a set of closely related compilers, not to change the way we build them. The problem was that Standard ML did not fully realize this paradigm at the code level, which caused some difficulties when we were developing a set of compilers.In this paper, we address such issues with a language-based solution. MLPolyR is our choice of an implementation language. It supports three different programming styles. First, its first-class cases facilitate composable extensions at the expression levels. Second, its module language provides extensible and parameterized modules, which make large-scale extensible programming possible. Third, its macro system simplifies specification and composition of feature related code. We will show how the combination of these language features work together to facilitate the product line engineering paradigm.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {3–10},
numpages = {8},
keywords = {feature-oriented programming, product line engineering},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@article{10.1007/s11219-020-09522-1,
author = {Bhushan, Megha and Negi, Arun and Samant, Piyush and Goel, Shivani and Kumar, Ajay},
title = {A classification and systematic review of product line feature model defects},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09522-1},
doi = {10.1007/s11219-020-09522-1},
abstract = {Product line (PL)-based development is a thriving research area to develop software-intensive systems. Feature models (FMs) facilitate derivation of valid products from a PL by managing commonalities and variabilities among software products. However, the researchers in academia as well as in the industries experience difficulties in quality assessment of FMs. The increasing complexity and size of FMs may lead to defects, which outweigh the benefits of PL. This paper provides a systematic literature review and key research issues related to the FM defects in PL. We derive a typology of FM defects according to their level of importance. The information on defects’ identification and explanations are provided with formalization. Further, corrective explanations are presented which incorporates various techniques used to fix defects with their implementation. This information would help software engineering community by enabling developers or modelers to find the types of defects and their causes and to choose an appropriate technique to fix defects in order to produce defect-free products from FMs, thereby enhancing the overall quality of PL-based development.},
journal = {Software Quality Journal},
month = dec,
pages = {1507–1550},
numpages = {44},
keywords = {Quality, Product line model, Defect, Software product line, Feature model}
}

@inproceedings{10.1145/3442520.3442529,
author = {Barut, Onur and Zhu, Rebecca and Luo, Yan and Zhang, Tong},
title = {TLS Encrypted Application Classification Using Machine Learning with Flow Feature Engineering},
year = {2021},
isbn = {9781450389037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442520.3442529},
doi = {10.1145/3442520.3442529},
abstract = {Network traffic classification has become increasingly important as the number of devices connected to the Internet is rapidly growing. Proportionally, the amount of encrypted traffic is also increasing, making payload based classification methods obsolete. Consequently, machine learning approaches have become crucial when user privacy is concerned. For this purpose, we propose an accurate, fast, and privacy preserved encrypted traffic classification approach with engineered flow feature extraction and appropriate feature selection. The proposed scheme achieves a 0.92899 macro-average F1 score and a 0.88313 macro-averaged mAP score for the encrypted traffic classification of Audio, Email, Chat, and Video classes derived from the non-vpn2016 dataset. Further experiments on the mixed non-encrypted and encrypted flow dataset with a data augmentation method called Synthetic Minority Over-Sampling Technique are conducted and the results are discussed for TLS-encrypted and mixed flows.},
booktitle = {Proceedings of the 2020 10th International Conference on Communication and Network Security},
pages = {32–41},
numpages = {10},
keywords = {machine learning, flow feature extraction, feature selection, encrypted traffic analysis, deep learning},
location = {Tokyo, Japan},
series = {ICCNS '20}
}

@inproceedings{10.1145/3410886.3410898,
author = {Ebiele, Jaures and Ansah-Narh, Theophilus and Djiokap, Steve and Proven-Adzri, Emmanuel and Atemkeng, Marcellin},
title = {Conventional Machine Learning based on Feature Engineering for Detecting Pneumonia from Chest X-rays},
year = {2020},
isbn = {9781450388474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410886.3410898},
doi = {10.1145/3410886.3410898},
abstract = {Chest X-ray is the standard approach used to diagnose pneumonia and other chest diseases. Early diagnosis of the disease is very relevant in the life of people, but analyzing X-ray images can be complicated and needs the competence of a radiographer. In this paper, we demonstrate the potential of detecting the disease in chest X-rays using conventional machine learning classifiers. The principal component analysis is used for the data dimensionality reduction and features extraction then the extracted features are used to train several model classifiers. We obtained an accuracy of , using of the principal explained variance.},
booktitle = {Conference of the South African Institute of Computer Scientists and Information Technologists 2020},
pages = {149–155},
numpages = {7},
keywords = {supervised learning., principal component analysis, feature extraction, chest X-rays, Pneumonia},
location = {Cape Town, South Africa},
series = {SAICSIT '20}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using machine learning to infer constraints for product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {variability modeling, software testing, software product lines, machine learning, constraints and variability mining},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {rule mining, product line, multi-objective search, machine learning, configuration},
location = {Berlin, Germany},
series = {GECCO '17}
}

@article{10.1007/s10462-018-09679-z,
author = {Nguyen, Giang and Dlugolinsky, Stefan and Bob\'{a}k, Martin and Tran, Viet and L\'{o}pez Garc\'{\i}a, \'{A}lvaro and Heredia, Ignacio and Mal\'{\i}k, Peter and Hluch?, Ladislav},
title = {Machine Learning and Deep Learning frameworks and libraries for large-scale data mining: a survey},
year = {2019},
issue_date = {June      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-018-09679-z},
doi = {10.1007/s10462-018-09679-z},
abstract = {The combined impact of new computing resources and techniques with an increasing avalanche of large datasets, is transforming many research areas and may lead to technological breakthroughs that can be used by billions of people. In the recent years, Machine Learning and especially its subfield Deep Learning have seen impressive advances. Techniques developed within these two fields are now able to analyze and learn from huge amounts of real world examples in a disparate formats. While the number of Machine Learning algorithms is extensive and growing, their implementations through frameworks and libraries is also extensive and growing too. The software development in this field is fast paced with a large number of open-source software coming from the academy, industry, start-ups or wider open-source communities. This survey presents a recent time-slide comprehensive overview with comparisons as well as trends in development and usage of cutting-edge Artificial Intelligence software. It also provides an overview of massive parallelism support that is capable of scaling computation effectively and efficiently in the era of Big Data.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {77–124},
numpages = {48},
keywords = {Parallel processing, Machine Learning, Large-scale data mining, Intensive computing, Graphics processing unit (GPU), Deep Learning, Artificial Intelligence software}
}

@inproceedings{10.1145/3442391.3442407,
author = {Sree-Kumar, Anjali and Planas, Elena and Claris\'{o}, Robert},
title = {Validating Feature Models With Respect to Textual Product Line Specifications},
year = {2021},
isbn = {9781450388245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442391.3442407},
doi = {10.1145/3442391.3442407},
abstract = {Feature models (FM) are a valuable resource in the analysis of software product lines (SPL). They provide a visual abstraction of the variation points in a family of related software products. FMs can be manually created by domain experts or extracted (semi-) automatically from textual documents such as product descriptions or requirements specifications. Nevertheless, there is no way to measure the accuracy of a FM with respect to the information described in the source documents. This paper proposes a method to quantify and visualize whether the elements in a FM (features and relationships) conform to the information available in a set of specification documents. Both the correctness (choice of representative elements) and completeness (no missing elements) of the FM are considered. Designers can use this feedback to fix defects in the FM or to detect incomplete or inconsistent information in the source documents.},
booktitle = {Proceedings of the 15th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {15},
numpages = {10},
keywords = {Software Product Line, Requirements Engineering, Natural Language Processing, Machine Learning, Feature Model Validation},
location = {Krems, Austria},
series = {VaMoS '21}
}

@inproceedings{10.1145/2430502.2430529,
author = {Zhang, Bo and Becker, Martin},
title = {Mining complex feature correlations from software product line configurations},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430529},
doi = {10.1145/2430502.2430529},
abstract = {As a Software Product Line (SPL) evolves with increasing number of features and feature values, the feature correlations become extremely intricate, and the specifications of these correlations tend to be either incomplete or inconsistent with their realizations, causing misconfigurations in practice. In order to guide product configuration processes, we present a solution framework to recover complex feature correlations from existing product configurations. These correlations are further pruned automatically and validated by domain experts. During implementation, we use association mining techniques to automatically extract strong association rules as potential feature correlations. This approach is evaluated using a large-scale industrial SPL in the embedded system domain, and finally we identify a large number of complex feature correlations.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {19},
numpages = {7},
keywords = {product line configuration, feature correlation, association mining},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1007/978-3-642-33176-3_7,
author = {ter Beek, Maurice H. and Muccini, Henry and Pelliccione, Patrizio},
title = {Assume-guarantee testing of evolving software product line architectures},
year = {2012},
isbn = {9783642331756},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33176-3_7},
doi = {10.1007/978-3-642-33176-3_7},
abstract = {Despite some work on testing software product lines, maintaining the quality of products when a software product line evolves is still an open problem. In this paper, we propose a novel assume-guarantee testing approach as a solution to the following research question: how can we verify the correct functioning of products of an software product line when core components evolve? The underlying idea is to retest only some of the products that conform to the software product line architecture and to infer, using assume-guarantee reasoning, the correctness of the other products. Assume-guarantee reasoning moreover permits the retesting of only those components that are affected by the changes.},
booktitle = {Proceedings of the 4th International Conference on Software Engineering for Resilient Systems},
pages = {91–105},
numpages = {15},
keywords = {software testing, evolving software product lines, compositional verification, assume-guarantee testing},
location = {Pisa, Italy},
series = {SERENE'12}
}

@article{10.1016/j.ipm.2021.102600,
author = {Chia, Zheng Lin and Ptaszynski, Michal and Masui, Fumito and Leliwa, Gniewosz and Wroczynski, Michal},
title = {Machine Learning and feature engineering-based study into sarcasm and irony classification with application to cyberbullying detection},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {58},
number = {4},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2021.102600},
doi = {10.1016/j.ipm.2021.102600},
journal = {Inf. Process. Manage.},
month = jul,
numpages = {12},
keywords = {Machine Learning, Sarcasm detection, Irony detection}
}

@inproceedings{10.1109/ASE.2009.16,
author = {Lauenroth, Kim and Pohl, Klaus and Toehning, Simon},
title = {Model Checking of Domain Artifacts in Product Line Engineering},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.16},
doi = {10.1109/ASE.2009.16},
abstract = {In product line engineering individual products are derived from the domain artifacts of the product line. The reuse of the domain artifacts is constraint by the product line variability. Since domain artifacts are reused in several products, product line engineering benefits from the verification of domain artifacts. For verifying development artifacts, model checking is a well-established technique in single system development. However, existing model checking approaches do not incorporate the product line variability and are hence of limited use for verifying domain artifacts. In this paper we present an extended model checking approach which takes the product line variability into account when verifying domain artifacts. Our approach is thus able to verify that every permissible product (specified with I/O-automata) which can be derived from the product line fulfills the specified properties (specified with CTL). Moreover, we use two examples to validate the applicability of our approach and report on the preliminary validation results.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {269–280},
numpages = {12},
keywords = {Variability, Product Line Engineering, Model Checking, Domain Artifact Verification},
series = {ASE '09}
}

@article{10.5555/2747015.2747184,
author = {da Silva, Ivonei Freitas and da Mota Silveira Neto, Paulo Anselmo and O'Leary, P\'{a}draig and de Almeida, Eduardo Santana and Meira, Silvio Romero de Lemos},
title = {Software product line scoping and requirements engineering in a small and medium-sized enterprise},
year = {2014},
issue_date = {February 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {88},
number = {C},
issn = {0164-1212},
abstract = {HighlightsWe described a detailed qualitative study on software product line scoping and requirements engineering.We examine weaknesses regarding the iterativeness, adaptability, and communication.Agile methods can mitigate the iterativeness, adaptability, and communication weaknesses. Software product line (SPL) engineering has been applied in several domains, especially in large-scale software development. Given the benefits experienced and reported, SPL engineering has increasingly garnered interest from small to medium-sized companies. It is possible to find a wide range of studies reporting on the challenges of running a SPL project in large companies. However, very little reports exist that consider the situation for small to medium-sized enterprises and these studies try develop universal truths for SPL without lessons learned from empirical evidence need to be contextualized. This study is a step towards bridging this gap in contextual evidence by characterizing the weaknesses discovered in the scoping (SC) and requirements (RE) disciplines of SPL. Moreover, in this study we conducted a case study in a small to medium sized enterprises (SMEs) to justify the use of agile methods when introducing the SPL SC and RE disciplines through the characterization of their bottlenecks. The results of the characterization indicated that ineffective communication and collaboration, long iteration cycles, and the absence of adaptability and flexibility can increase the effort and reduce motivation during project development. These issues can be mitigated by agile methods.},
journal = {J. Syst. Softw.},
month = feb,
pages = {189–206},
numpages = {18},
keywords = {Software product line scoping, Requirements engineering, Agile methods}
}

@article{10.1007/s00521-020-05529-8,
author = {Ma, Zhengjing and Mei, Gang and Piccialli, Francesco},
title = {Machine learning for landslides prevention: a survey},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {17},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05529-8},
doi = {10.1007/s00521-020-05529-8},
abstract = {Landslides are one of the most critical categories of natural disasters worldwide and induce severely destructive outcomes to human life and the overall economic system. To reduce its negative effects, landslides prevention has become an urgent task, which includes investigating landslide-related information and predicting potential landslides. Machine learning is a state-of-the-art analytics tool that has been widely used in landslides prevention. This paper presents a comprehensive survey of relevant research on machine learning applied in landslides prevention, mainly focusing on (1) landslides detection based on images, (2) landslides susceptibility assessment, and (3) the development of landslide warning systems. Moreover, this paper discusses the current challenges and potential opportunities in the application of machine learning algorithms for landslides prevention.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {10881–10907},
numpages = {27},
keywords = {Deep learning, Unsupervised learning, Supervised learning, Machine learning, Landslides prevention, Natural disasters}
}

@inproceedings{10.1145/3377930.3390215,
author = {Silva, Diego Fernandes da and Okada, Luiz Fernando and Colanzi, Thelma Elita and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Enhancing search-based product line design with crossover operators},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377930.3390215},
doi = {10.1145/3377930.3390215},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line. PLA designing has been formulated as a multi-objective optimization problem and successfully solved by a state-of-the-art search-based approach. However, the majority of empirical studies optimize PLA designs without applying one of the fundamental genetic operators: the crossover. An operator for PLA design, named Feature-driven Crossover, was proposed in a previous study. In spite of the promising results, this operator occasionally generated incomplete solutions. To overcome these limitations, this paper aims to enhance the search-based PLA design optimization by improving the Feature-driven Crossover and introducing a novel crossover operator specific for PLA design. The proposed operators were evaluated in two well-studied PLA designs, using three experimental configurations of NSGA-II in comparison with a baseline that uses only mutation operators. Empirical results show the usefulness and efficiency of the presented operators on reaching consistent solutions. We also observed that the two operators complement each other, leading to PLA design solutions with better feature modularization than the baseline experiment.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {1250–1258},
numpages = {9},
keywords = {software product line, software architecture, recombination operators, multi-objective evolutionary algorithm},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@article{10.1016/j.artmed.2021.102198,
author = {Peralta, Maxime and Jannin, Pierre and Baxter, John S.H.},
title = {Machine learning in deep brain stimulation: A systematic review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {122},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102198},
doi = {10.1016/j.artmed.2021.102198},
journal = {Artif. Intell. Med.},
month = dec,
numpages = {13},
keywords = {Machine learning, Deep brain stimulation, Systematic review}
}

@article{10.1016/j.neunet.2021.04.010,
author = {Chen, Yanping and Yang, Weizhe and Wang, Kai and Qin, Yongbin and Huang, Ruizhang and Zheng, Qinghua},
title = {A neuralized feature engineering method for entity relation extraction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {141},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2021.04.010},
doi = {10.1016/j.neunet.2021.04.010},
journal = {Neural Netw.},
month = sep,
pages = {249–260},
numpages = {12},
keywords = {Relation extraction, Feature combination, Feature engineering}
}

@inproceedings{10.1007/978-3-030-87722-4_6,
author = {Mahapatra, Dwarikanath and Kuanar, Shiba and Bozorgtabar, Behzad and Ge, Zongyuan},
title = {Self-supervised Learning of Inter-label Geometric Relationships for Gleason Grade Segmentation},
year = {2021},
isbn = {978-3-030-87721-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87722-4_6},
doi = {10.1007/978-3-030-87722-4_6},
abstract = {Segmentation of Prostate Cancer (PCa) tissues from Gleason graded histopathology images is vital for accurate diagnosis. Although deep learning (DL) based segmentation methods achieve state-of-the-art accuracy, they rely on large datasets with manual annotations. We propose a method to synthesize PCa histopathology images by learning the geometrical relationship between different disease labels using self-supervised learning. Manual segmentation maps from the training set are used to train a Shape Restoration Network (ShaRe-Net) that predicts missing mask segments in a self-supervised manner. Using DenseUNet as the backbone generator architecture we incorporate latent variable sampling to inject diversity in the image generation process and thus improve robustness. Experimental results demonstrate the superiority of our method over competing image synthesis methods for segmentation tasks. Ablation studies show the benefits of integrating geometry and diversity in generating high-quality images. Our self-supervised approach with limited class-labeled data achieves better performance than fully supervised learning.},
booktitle = {Domain Adaptation and Representation Transfer, and Affordable Healthcare and AI for Resource Diverse Global Health: Third MICCAI Workshop, DART 2021, and First MICCAI Workshop, FAIR 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27 and October 1, 2021, Proceedings},
pages = {57–67},
numpages = {11},
keywords = {GANs, Geometric modeling, Self-supervised learning},
location = {Strasbourg, France}
}

@inproceedings{10.1109/ASE.2015.106,
author = {Pietsch, Christopher and Kehrer, Timo and Kelter, Udo and Reuling, Dennis and Ohrndorf, Manuel},
title = {SiPL: a delta-based modeling framework for software product line engineering},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.106},
doi = {10.1109/ASE.2015.106},
abstract = {Model-based development has become a widely-used approach to implement software, e.g. for embedded systems. Models replace source code as primary executable artifacts in these cases. Software product line technologies for these domains must be able to generate models as instances of an SPL. This need is addressed among others by an implementation technology for SPLs known as delta modeling. Current approaches to delta modeling require deltas to be written manually using delta languages, and they offer only very limited support for creating and testing a network of deltas. This paper presents a new approach to delta modeling and a supporting tool suite: the abstract notion of a delta is refined to be a consistency-preserving edit script which is generated by comparing two models. The rich structure of edit scripts allows us to detect conflicts and further relations between deltas statically and to implement restructurings in delta sets such as the merging of two deltas. We illustrate the tooling using a case study.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {852–857},
numpages = {6},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1007/s10664-019-09787-6,
author = {Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp and Ziadi, Tewfik and Robin, Jacques and Martinez, Jabier},
title = {The state of adoption and the challenges of systematic variability management in industry},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09787-6},
doi = {10.1007/s10664-019-09787-6},
abstract = {Handling large-scale software variability is still a challenge for many organizations. After decades of research on variability management concepts, many industrial organizations have introduced techniques known from research, but still lament that pure textbook approaches are not applicable or efficient. For instance, software product line engineering—an approach to systematically develop portfolios of products—is difficult to adopt given the high upfront investments; and even when adopted, organizations are challenged by evolving their complex product lines. Consequently, the research community now mainly focuses on re-engineering and evolution techniques for product lines; yet, understanding the current state of adoption and the industrial challenges for organizations is necessary to conceive effective techniques. In this multiple-case study, we analyze the current adoption of variability management techniques in twelve medium- to large-scale industrial cases in domains such as automotive, aerospace or railway systems. We identify the current state of variability management, emphasizing the techniques and concepts they adopted. We elicit the needs and challenges expressed for these cases, triangulated with results from a literature review. We believe our results help to understand the current state of adoption and shed light on gaps to address in industrial practice.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {1755–1797},
numpages = {43},
keywords = {Challenges, Multiple-case study, Software product lines, Variability management}
}

@article{10.1016/j.datak.2021.101909,
author = {Maass, Wolfgang and Storey, Veda C.},
title = {Pairing conceptual modeling with machine learning},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {134},
number = {C},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2021.101909},
doi = {10.1016/j.datak.2021.101909},
journal = {Data Knowl. Eng.},
month = jul,
numpages = {35},
keywords = {Artificial intelligence, Framework for incorporating conceptual modeling into data science projects, Database management, Models, Methodologies and tools, Machine learning, Conceptual modeling}
}

@article{10.1016/j.asoc.2020.106612,
author = {Kaieski, Naira and da Costa, Cristiano Andr\'{e} and da Rosa Righi, Rodrigo and Lora, Priscila Schmidt and Eskofier, Bj\"{o}rn},
title = {Application of artificial intelligence methods in vital signs analysis of hospitalized patients: A systematic literature review},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106612},
doi = {10.1016/j.asoc.2020.106612},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {20},
keywords = {Vital signs, Health informatics, Machine learning, Artificial intelligence}
}

@article{10.1007/s10462-020-09910-w,
author = {Nath, Aneesh G. and Udmale, Sandeep S. and Singh, Sanjay Kumar},
title = {Role of artificial intelligence in rotor fault diagnosis: a comprehensive review},
year = {2021},
issue_date = {Apr 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09910-w},
doi = {10.1007/s10462-020-09910-w},
abstract = {Artificial intelligence (AI)-based rotor fault diagnosis (RFD) poses a variety of challenges to the prognostics and health management (PHM) of the Industry 4.0 revolution. Rotor faults have drawn more attention from the AI research community in terms of utilizing fault-specific characteristics in its feature engineering, compared to any other rotating machinery faults. While the rotor faults, specifically structural rotor faults (SRF), have proven to be the root cause of most of the rotating machinery issues, the research in this field largely revolves around bearing and gear faults. Within this scenario, this paper is the first of its kind to attempt to review and define the role of AI in RFD and provides an all-encompassing review of rotor faults for the researchers and academics. In addition, this study is unique in three ways: (i) it emphasizes the use of fault-specific characteristic features with AI, (ii) it is grounded in fault-wise analysis rather than component-wise analysis with appropriate fault categorization, and (iii) it portrays the current research and analysis in accordance with different phases of an AI-based RFD framework. Finally, the section on future research directions is aimed at bridging the gap between a laboratory-based solution and a real-world industrial solution for RFD.},
journal = {Artif. Intell. Rev.},
month = apr,
pages = {2609–2668},
numpages = {60},
keywords = {Machine health monitoring, Artificial intelligence, Structural rotor faults, Rotating machinery fault diagnosis}
}

@article{10.1016/j.infsof.2012.11.008,
author = {Krishnan, Sandeep and Strasburg, Chris and Lutz, Robyn R. and Goseva-Popstojanova, Katerina and Dorman, Karin S.},
title = {Predicting failure-proneness in an evolving software product line},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.11.008},
doi = {10.1016/j.infsof.2012.11.008},
abstract = {ContextPrevious work by researchers on 3years of early data for an Eclipse product has identified some predictors of failure-prone files that work well. Eclipse has also been used previously by researchers to study characteristics of product line software. ObjectiveThe work reported here investigates whether classification-based prediction of failure-prone files improves as the product line evolves. MethodThis investigation first repeats, to the extent possible, the previous study and then extends it by including four more recent years of data, comparing the prominent predictors with the previous results. The research then looks at the data for three additional Eclipse products as they evolve over time. The analysis compares results from three different types of datasets with alternative data collection and prediction periods. ResultsOur experiments with a variety of learners show that the difference between the performance of J48, used in this work, and the other top learners is not statistically significant. Furthermore, new results show that the effectiveness of classification significantly depends on the data collection period and prediction period. The study identifies change metrics that are prominent predictors across all four releases of all four products in the product line for the three different types of datasets. From the product line perspective, prediction of failure-prone files for the four products studied in the Eclipse product line shows statistically significant improvement in accuracy but not in recall across releases. ConclusionAs the product line matures, the learner performance improves significantly for two of the three datasets, but not for prediction of post-release failure-prone files using only pre-release change data. This suggests that it may be difficult to detect failure-prone files in the evolving product line. At least in part, this may be due to the continuous change, even for commonalities and high-reuse variation components, which we previously have shown to exist.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1479–1495},
numpages = {17},
keywords = {Software product lines, Reuse, Prediction, Post-release defects, Failure-prone files, Change metrics}
}

@article{10.1007/s10515-011-0099-7,
author = {Bagheri, Ebrahim and Ensan, Faezeh and Gasevic, Dragan},
title = {Decision support for the software product line domain engineering lifecycle},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0099-7},
doi = {10.1007/s10515-011-0099-7},
abstract = {Software product line engineering is a paradigm that advocates the reusability of software engineering assets and the rapid development of new applications for a target domain. These objectives are achieved by capturing the commonalities and variabilities between the applications of the target domain and through the development of comprehensive and variability-covering feature models. The feature models developed within the software product line development process need to cover the relevant features and aspects of the target domain. In other words, the feature models should be elaborate representations of the feature space of that domain. Given that feature models, i.e., software product line feature models, are developed mostly by domain analysts by sifting through domain documentation, corporate records and transcribed interviews, the process is a cumbersome and error-prone one. In this paper, we propose a decision support platform that assists domain analysts throughout the domain engineering lifecycle by: (1) automatically performing natural language processing tasks over domain documents and identifying important information for the domain analysts such as the features and integrity constraints that exist in the domain documents; (2) providing a collaboration platform around the domain documents such that multiple domain analysts can collaborate with each other during the process using a Wiki; (3) formulating semantic links between domain terminology with external widely used ontologies such as WordNet in order to disambiguate the terms used in domain documents; and (4) developing traceability links between the unstructured information available in the domain documents and their formal counterparts within the formal feature model representations. Results obtained from our controlled experimentations show that the decision support platform is effective in increasing the performance of the domain analysts during the domain engineering lifecycle in terms of both the coverage and accuracy measures.},
journal = {Automated Software Engg.},
month = sep,
pages = {335–377},
numpages = {43},
keywords = {Software product lines, NLP model inference, Feature models, Domain engineering}
}

@inproceedings{10.1145/3349341.3349504,
author = {Huang, Chunfang and Wang, Xiangrong},
title = {Financial Innovation Based on Artificial Intelligence Technologies},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349504},
doi = {10.1145/3349341.3349504},
abstract = {Nowadays, the degree of the heated topic of artificial intelligence in the world reaches a new height. Due to the breakthrough of deep learning algorithm based on neural network, the level of artificial intelligence technologies has been enhanced significantly. The global financial industry is quietly changing under the catalysis of artificial intelligence. The frontier artificial intelligence technologies, such as the technology of expert system, machine learning and knowledge discovery in database are combed to explore the financial applications of artificial intelligence. Based on these key technologies, this paper proposed three applications of artificial intelligence in the financial field, including intelligent investment adviser, transaction forecast and financial regulation, discusses the key technologies of artificial intelligence and financial innovation products based on these technologies, such as the functions of the transaction prediction system based on artificial intelligence technologies include forecast analysis, index statistics, stock analysis and information retrieval, etc. The structures of the systems are drawn and the design principles are provided. Finally, to guard the safety of the applications of artificial intelligence, the paper gives the suggestions of enhancing identity authentication, introducing monitoring measures and limiting autonomy degree.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {750–754},
numpages = {5},
keywords = {Transaction Forecast, Machine Learning, Intelligent Investment Adviser, Financial Regulation, Deep Learning},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@article{10.1016/j.jss.2019.05.001,
author = {Kicsi, Andr\'{a}s and Csuvik, Viktor and Vid\'{a}cs, L\'{a}szl\'{o} and Horv\'{a}th, Ferenc and Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy, Tibor and Kocsis, Ferenc},
title = {Feature analysis using information retrieval, community detection and structural analysis methods in product line adoption},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {155},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.05.001},
doi = {10.1016/j.jss.2019.05.001},
journal = {J. Syst. Softw.},
month = sep,
pages = {70–90},
numpages = {21},
keywords = {Community detection, Information retrieval, Feature extraction, Software product line}
}

@inproceedings{10.1145/3382025.3414943,
author = {Th\"{u}m, Thomas},
title = {A BDD for Linux? the knowledge compilation challenge for variability},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414943},
doi = {10.1145/3382025.3414943},
abstract = {What is the number of valid configurations for Linux? How to generate uniform random samples for Linux? Can we create a binary decision diagram for Linux? It seems that the product-line community tries hard to answer such questions for Linux and other configurable systems. However, attempts are often not published due to the publication bias (i.e., unsuccessful attempts are not published). As a consequence, researchers keep trying by potentially spending redundant effort. The goal of this challenge is to guide research on these computationally complex problems and to foster the exchange between researchers and practitioners.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {16},
numpages = {6},
keywords = {software product line, software configuration, satisfiability solving, product configuration, knownledge compilation, feature models, decision models, configurable system, binary decision diagrams, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3468891.3468903,
author = {Kim, Eunhye and Jung, Hoon},
title = {Feature Engineering-based Short-Term Prediction Model for Postal Parcel Logistics},
year = {2021},
isbn = {9781450389402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468891.3468903},
doi = {10.1145/3468891.3468903},
abstract = {Postal logistics organizations are characterized as having high labor intensity and short response times. These characteristics, along with rapid change in mail volume traffic, make load scheduling a fundamental concern. Load analysis of major postal infrastructures such as post offices, sorting centers, exchange centers, and delivery stations is required for optimal postal logistics operation. Especially, the performance of postal traffic forecasting is essential for optimizing the resource operation by accurate load analysis. Therefore, this paper addresses a demand forecasting problem for parcel logistics. The main purpose of this paper is to describe a machine learning approach for predicting short-term traffic of postal parcel based on feature engineering and to introduce an application to on-site logistics service of Korea Post. The proposed method consists of three main phases. First, the characteristics of the postal traffic are analyzed and calendar and volume-based features are generated. Second, multiple regression models by the clusters resulted from feature engineering are developed. Finally, individual models for level 4 and level 5 delivery stations are constructed to reinforce prediction accuracy. The experiment shows the advantage in terms of forecasting performance. Comparing with other techniques, experimental results show that the proposed scheme improves the average performance up to 50.1%.},
booktitle = {Proceedings of the 2021 6th International Conference on Machine Learning Technologies},
pages = {82–89},
numpages = {8},
keywords = {Short-term prediction, Postal traffic, Machine learning approach, Feature engineering},
location = {Jeju Island, Republic of Korea},
series = {ICMLT '21}
}

@article{10.1016/j.procs.2021.10.038,
author = {Zhukova, Irina V. and Derevitskii, Ilia V. and Matveev, Georgy A. and Golikova, Tatiana I. and Babenko, Alina Yu.},
title = {Predictive Modeling for Decision Support in the Tasks of Selecting the Drug for Obesity Treatment},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {193},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.10.038},
doi = {10.1016/j.procs.2021.10.038},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {371–381},
numpages = {11},
keywords = {Drug Therapy, DSS, Weight-Reducing-Therapy, Machine Learning, Obesity}
}

@article{10.1007/s11219-010-9127-2,
author = {Bagheri, Ebrahim and Gasevic, Dragan},
title = {Assessing the maintainability of software product line feature models using structural metrics},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9127-2},
doi = {10.1007/s11219-010-9127-2},
abstract = {A software product line is a unified representation of a set of conceptually similar software systems that share many common features and satisfy the requirements of a particular domain. Within the context of software product lines, feature models are tree-like structures that are widely used for modeling and representing the inherent commonality and variability of software product lines. Given the fact that many different software systems can be spawned from a single software product line, it can be anticipated that a low-quality design can ripple through to many spawned software systems. Therefore, the need for early indicators of external quality attributes is recognized in order to avoid the implications of defective and low-quality design during the late stages of production. In this paper, we propose a set of structural metrics for software product line feature models and theoretically validate them using valid measurement-theoretic principles. Further, we investigate through controlled experimentation whether these structural metrics can be good predictors (early indicators) of the three main subcharacteristics of maintainability: analyzability, changeability, and understandability. More specifically, a four-step analysis is conducted: (1) investigating whether feature model structural metrics are correlated with feature model maintainability through the employment of classical statistical correlation techniques; (2) understanding how well each of the structural metrics can serve as discriminatory references for maintainability; (3) identifying the sufficient set of structural metrics for evaluating each of the subcharacteristics of maintainability; and (4) evaluating how well different prediction models based on the proposed structural metrics can perform in indicating the maintainability of a feature model. Results obtained from the controlled experiment support the idea that useful prediction models can be built for the purpose of evaluating feature model maintainability using early structural metrics. Some of the structural metrics show significant correlation with the subjective perception of the subjects about the maintainability of the feature models.},
journal = {Software Quality Journal},
month = sep,
pages = {579–612},
numpages = {34},
keywords = {Structural complexity, Software product line, Software prediction model, Quality attributes, Maintainability, Feature model, Controlled experimentation}
}

@article{10.1007/s10994-021-05959-y,
author = {Cerqueira, Vitor and Moniz, Nuno and Soares, Carlos},
title = {VEST: automatic feature engineering for forecasting},
year = {2021},
issue_date = {Jul 2024},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {113},
number = {7},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-021-05959-y},
doi = {10.1007/s10994-021-05959-y},
abstract = {Time series forecasting is a challenging task with applications in a wide range of domains. Auto-regression is one of the most common approaches to address these problems. Accordingly, observations are modelled by multiple regression using their past lags as predictor variables. We investigate the extension of auto-regressive processes using statistics which summarise the recent past dynamics of time series. The result of our research is a novel framework called VEST, designed to perform feature engineering using univariate and numeric time series automatically. The proposed approach works in three main steps. First, recent observations are mapped onto different representations. Second, each representation is summarised by statistical functions. Finally, a filter is applied for feature selection. We discovered that combining the features generated by VEST with auto-regression significantly improves forecasting performance in a database composed by 90 time series with high sampling frequency. However, we also found that there are no improvements when the framework is applied for multi-step forecasting or in time series with low sample size. VEST is publicly available online.},
journal = {Mach. Learn.},
month = apr,
pages = {4523–4545},
numpages = {23},
keywords = {Time series forecasting, Feature engineering, Automatic machine learning}
}

@article{10.1016/j.jss.2007.12.797,
author = {Ajila, Samuel A. and Kaba, Ali B.},
title = {Evolution support mechanisms for software product line process},
year = {2008},
issue_date = {October, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {10},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.12.797},
doi = {10.1016/j.jss.2007.12.797},
abstract = {Software product family process evolution needs specific support for incremental change. Product line process evolution involves in addition to identifying new requirements the building of a meta-process describing the migration from the old process to the new one. This paper presents basic mechanisms to support software product line process evolution. These mechanisms share four strategies - change identification, change impact, change propagation, and change validation. It also examines three kinds of evolution processes - architecture, product line, and product. In addition, change management mechanisms are identified. Specifically we propose support mechanisms for static local entity evolution and complex entity evolution including transient evolution process. An evolution model prototype based on dependency relationships structure of the various product line artifacts is developed.},
journal = {J. Syst. Softw.},
month = oct,
pages = {1784–1801},
numpages = {18},
keywords = {Use case modeling, Transient process, Software product line process evolution, Software development process, Product line architecture, Meta-process, Feature-based object oriented model}
}

@inproceedings{10.1145/3487923.3487938,
author = {Chindove, Hatitye and Brown, Dane},
title = {Adaptive Machine Learning Based Network Intrusion Detection},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487923.3487938},
doi = {10.1145/3487923.3487938},
abstract = {Network intrusion detection system (NIDS) adoption is essential for mitigating computer network attacks in various scenarios. However, the increasing complexity of computer networks and attacks make it challenging to classify network traffic. Machine learning (ML) techniques in a NIDS can be affected by different scenarios, and thus the recency, size and applicability of datasets are vital factors to consider when selecting and tuning a machine learning classifier. The proposed approach evaluates relatively new datasets constructed such that they depict real-world scenarios. It includes analyses of dataset balancing and sampling, feature engineering and systematic ML-based NIDS model tuning focused on the adaptive improvement of intrusion detection. A comparison between machine learning classifiers forms part of the evaluation process. Results on the proposed approach model effectiveness for NIDS are discussed. Recurrent neural networks and random forests models consistently achieved high f1-score results with macro f1-scores of 0.73 and 0.87 for the CICIDS 2017 dataset; and 0.73 and 0.72 against the CICIDS 2018 dataset, respectively.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {15},
numpages = {6},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@article{10.1016/j.artmed.2021.102165,
author = {de Siqueira, Vilson Soares and Borges, Mois\'{e}s Marcos and Furtado, Rog\'{e}rio Gomes and Dourado, Colandy Nunes and da Costa, Ronaldo Martins},
title = {Artificial intelligence applied to support medical decisions for the automatic analysis of echocardiogram images: A systematic review},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102165},
doi = {10.1016/j.artmed.2021.102165},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {19},
keywords = {Deep Learning, Machine Learning, Echocardiography, Echocardiogram}
}

@inproceedings{10.1145/3447548.3470817,
author = {Gupta, Nitin and Mujumdar, Shashank and Patel, Hima and Masuda, Satoshi and Panwar, Naveen and Bandyopadhyay, Sambaran and Mehta, Sameep and Guttula, Shanmukha and Afzal, Shazia and Sharma Mittal, Ruhi and Munigala, Vitobha},
title = {Data Quality for Machine Learning Tasks},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470817},
doi = {10.1145/3447548.3470817},
abstract = {The quality of training data has a huge impact on the efficiency, accuracy and complexity of machine learning tasks. Data remains susceptible to errors or irregularities that may be introduced during collection, aggregation or annotation stage. This necessitates profiling and assessment of data to understand its suitability for machine learning tasks and failure to do so can result in inaccurate analytics and unreliable decisions. While researchers and practitioners have focused on improving the quality of models, there are limited efforts towards improving the data quality.Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance. This tutorial highlights the importance of analysing data quality in terms of its value for ML applications. Finding the data quality issues in data helps different personas like data stewards, data scientists, subject matter experts, or machine learning scientists to get relevant data insights and take remedial actions to rectify any issue. This tutorial surveys all the important data quality related approaches for structured, unstructured and spatio-temporal domains discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4040–4041},
numpages = {2},
keywords = {quality metrics, machine learning, data quality},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1007/s42979-021-00592-x,
author = {Sarker, Iqbal H.},
title = {Machine Learning: Algorithms, Real-World Applications and Research Directions},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00592-x},
doi = {10.1007/s42979-021-00592-x},
abstract = {In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated&nbsp;applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity&nbsp;systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this paper aims to serve as a reference point for both academia and industry professionals as well as for decision-makers&nbsp;in various real-world situations and&nbsp;application areas, particularly from the technical point of view.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {21},
keywords = {Machine learning, Deep learning, Artificial intelligence, Data science, Data-driven decision-making, Predictive analytics, Intelligent applications}
}

@article{10.1007/s11219-011-9156-5,
author = {Roos-Frantz, Fabricia and Benavides, David and Ruiz-Cort\'{e}s, Antonio and Heuer, Andr\'{e} and Lauenroth, Kim},
title = {Quality-aware analysis in product line engineering with the orthogonal variability model},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9156-5},
doi = {10.1007/s11219-011-9156-5},
abstract = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e.g., CPU and memory consumption) and constraints on these attributes (e.g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e.g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i.e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e.g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions.},
journal = {Software Quality Journal},
month = sep,
pages = {519–565},
numpages = {47},
keywords = {Software product lines, Quality-aware analysis, Quality modelling, Orthogonal variability model, Automated analysis}
}

@inproceedings{10.1145/1858996.1859021,
author = {Kim, Chang Hwan Peter and Batory, Don and Khurshid, Sarfraz},
title = {Eliminating products to test in a software product line},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859021},
doi = {10.1145/1858996.1859021},
abstract = {A Software Product Line (SPL) is a family of programs where each program is defined by a unique combination of features. Developing a set of programs with commonalities and variabilities in this way can significantly reduce both the time and cost of software development. However, as the number of programs may be exponential in the number of features, testing an SPL, the phase to which the majority of software development is dedicated, becomes especially challenging [12].Indeed, scale is the biggest challenge in testing or checking the properties of programs in a product line. Even a product line with just 10 optional features has over a thousand (210) distinct programs. As an example of a situation where every program must be considered, suppose that every program of an SPL outputs a String that each feature might modify.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {139–142},
numpages = {4},
keywords = {testing, static analysis, software product lines, feature oriented programming},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1007/978-3-030-87897-9_37,
author = {Zolotareva, Ekaterina},
title = {Aiding Long-Term Investment Decisions with XGBoost Machine Learning Model},
year = {2021},
isbn = {978-3-030-87896-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87897-9_37},
doi = {10.1007/978-3-030-87897-9_37},
abstract = {The ability to identify stock market trends has obvious advantages for investors. Buying stock on the upward trend (as well as selling it in case of downward movement) results in profit. Accordingly, the start and endpoints of the trend are the optimal points for entering and leaving the market. The research concentrates on recognizing stock market long-term upward and downward trends. The key results are obtained with the use of gradient boosting algorithms, XGBoost in particular. The raw data is represented by time series with basic stock market quotes with periods labelled by experts as «Trend» or «Flat». The features are then obtained via various data transformations, aiming to catch implicit factors resulting in the change of stock direction. Modelling is done in two stages: stage one aims to detect endpoints of tendencies (i.e. “sliding windows”), stage two recognizes the tendency itself inside the window. The research addresses such issues as imbalanced datasets and contradicting labels, as well as the need for specific quality metrics to keep up with practical applicability. The model can be used to design an investment strategy though further research in feature engineering and fine calibration is required. This is the reduced version of the research, full text can be found on  (arXiv: 2104.09341).},
booktitle = {Artificial Intelligence and Soft Computing: 20th International Conference, ICAISC 2021, Virtual Event, June 21–23, 2021, Proceedings, Part II},
pages = {414–427},
numpages = {14},
keywords = {Expert opinion, Stock market trends, XGBoost}
}

@inproceedings{10.1145/3425269.3425276,
author = {Silva, Publio and Bezerra, Carla I. M. and Lima, Rafael and Machado, Ivan},
title = {Classifying Feature Models Maintainability based on Machine Learning Algorithms},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425276},
doi = {10.1145/3425269.3425276},
abstract = {Maintenance in the context of SPLs is a topic of interest, and that still needs further investigation. There are several ways to evaluate the maintainability of a feature model (FM), one of which is a manual or automated analysis of quality measures. However, the use of measures does not allow to evaluate the FM quality as a whole, as each measure considers a specific characteristic of FM. In general, the measures have wide ranges of values and do not have a clear definition of what is appropriate and inappropriate. In this context, the goal of this work is to investigate the use of machine learning techniques to classify the feature model maintainability. The research questions investigated in the study were: (i) how could machine learning techniques aid to classify FMs maintainability; and, (ii) which FM classification model has the best accuracy and precision. In this work, we proposed an approach for FM maintainability classification using machine learning technics. For that, we used a dataset of 15 FM maintainability measures calculated for 326 FMs, and we used machine learning algorithms to clustering. After this, we used thresholds to evaluate the general maintainability of each cluster. With this, we built 5 maintainability classification models that have been evaluated with the accuracy and precision metrics.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@phdthesis{10.5555/AAI28865638,
author = {Rendleman, Michael C. and A., Braun, Terry and M., Buatti, John and Guadalupe, Canahuate, and J, Smith, Brian},
advisor = {L, Casavant, Thomas},
title = {Representative Random Sampling for Feature Engineering of -Omics Data: Using Machine Learning to Identify Biomarkers for Head and Neck Squamous Cell Carcinoma},
year = {2021},
isbn = {9798790625770},
publisher = {The University of Iowa},
abstract = {High-dimensional cancer data can be burdensome to analyze, with complex relationships between molecular measurements, clinical diagnostics, and treatment outcomes. Data-driven computational approaches may be key to identifying research targets with potential clinical or research use, also known as biomarkers. To this end, we designed a framework for engineering and identifying biomarkers for survival model building, applying a variety of established and novel feature engineering methods on publicly available Head and Neck Squamous Cell Carcinoma (HNSCC) data. This dataset includes over 500 cases and spans numerous data types including clinical data, RNA sequencing, and tumor-normal DNA variation. Given the limited size of the dataset, a specialized sampling technique was devised to increase reliability of performance estimation with less computation. Traditionally, resampling methods such as cross validation or repeated holdout have been used to estimate model performance, as they produce more robust estimates. Because exploratory evaluations in the feature selection framework required an intractable manual inspection and assessment process, we propose employing a novel holdout sampling procedure, Representative Random Sampling (RRS). RRS first quantizes the continuous outcome into equipopulous bins of minimum size and then selects the holdout set via stratified sampling. Utilizing thorough simulations on synthetic molecular data, we have determined that this approach yields at least modest reductions in error and bias when compared to standard holdout, though direct cross validation may still be significantly more effective at reducing error and bias. Additionally, model selection has a large effect on error and bias estimation: RRS produced the most consistent decreases in error and bias with random forest-based models. Using RRS, a two-stage analysis framework enables evaluation and selection of prospective biomarker features which are then applied to survival modeling. Thousands of raw and processed molecular features were assessed on their ability to predict clinical diagnostics and patient survival, ultimately supporting a predictive survival model that outperformed corresponding clinical models. Model analysis demonstrated associations between patient outcomes and biological pathways and processes, several of which are the subject of recent and ongoing oncology research in HNSCC and other cancers. Additionally, unsupervised transformations of RNA expression data facilitated by denoising autoencoders (DAE) were found to strengthen prognostic models against overfitting and in predictive performance.},
note = {AAI28865638}
}

@inproceedings{10.1007/978-3-030-68780-9_13,
author = {Kanevski, Mikhail and Laib, Mohamed},
title = {Unsupervised Learning of High Dimensional Environmental Data Using Local Fractality Concept},
year = {2021},
isbn = {978-3-030-68779-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68780-9_13},
doi = {10.1007/978-3-030-68780-9_13},
abstract = {The research deals with an exploration of high dimensional environmental data using unsupervised learning algorithms and the concept of local fractality. The proposed methodology is applied to geospatial data used for the wind speed prediction in a complex mountainous region. It is shown, that the approach provides important additional information on data manifold useful in data analysis, data visualisation and predictive modelling.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part VI},
pages = {130–138},
numpages = {9},
keywords = {Fractals, Environmental data, Unsupervised learning}
}

@inproceedings{10.1145/3461002.3473948,
author = {Xu, Hao and Baarir, Souheib and Ziadi, Tewfik and Hillah, Lom Messan and Essodaigui, Siham and Bossu, Yves},
title = {Optimisation for the product configuration system of Renault: towards an integration of symmetries},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473948},
doi = {10.1145/3461002.3473948},
abstract = {The problem of configuring model variability is widespread in many different domains. Renault, a leading french automobile manufacturer, has developed its technology internally to model vehicle diversity. This technology relies on the approach known as knowledge compilation. Since its inception, continuous progress has been made in the tool while monitoring the latest developments from the software field and academia. However, the growing number of vehicle models brings potential risks and higher requirements for the tool. This paper presents a short reminder of Renault's technology principles and the improvements we intend to achieve by analyzing and leveraging notable data features of Renault problem instances. In particular, the aim is to exploit symmetry properties.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {86–90},
numpages = {5},
keywords = {symmetries, product line, knowledge compilation, SAT},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3447548.3469452,
author = {Wang, Tao and Koch, Patrick and Wujek, Brett and Liu, Jun and Li, Hai},
title = {The Fifth International Workshop on Automation in Machine Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3469452},
doi = {10.1145/3447548.3469452},
abstract = {The Fifth International Workshop on Automation in Machine Learning aims to identify opportunities and challenges for automation in machine learning, to provide an opportunity for researchers to discuss best practices for automation in machine learning potentially leading to definition of standards, and to provide a forum for researchers to speak out and debate on different ideas in automation in machine learning. The workshop agenda includes four invited keynote speakers and four accepted paper presentations chosen from a peer review process. A panel discussion will close out the workshop to allow for an engaging and interactive exchange of thoughts and ideas on AutoML.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4163–4164},
numpages = {2},
keywords = {neural architecture search, machine learning, hyperparameter optimization, automation, AutoML},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1145/3490519,
author = {Xie, Zhongwei and Liu, Ling and Wu, Yanzhao and Zhong, Luo and Li, Lin},
title = {Learning Text-image Joint Embedding for Efficient Cross-modal Retrieval with Deep Feature Engineering},
year = {2021},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/3490519},
doi = {10.1145/3490519},
abstract = {This article introduces a two-phase deep feature engineering framework for efficient learning of semantics enhanced joint embedding, which clearly separates the deep feature engineering in data preprocessing from training the text-image joint embedding model. We use the Recipe1M dataset for the technical description and empirical validation. In preprocessing, we perform deep feature engineering by combining deep feature engineering with semantic context features derived from raw text-image input data. We leverage LSTM to identify key terms, deep NLP models from the BERT family, TextRank, or TF-IDF to produce ranking scores for key terms before generating the vector representation for each key term by using Word2vec. We leverage Wide ResNet50 and Word2vec to extract and encode the image category semantics of food images to help semantic alignment of the learned recipe and image embeddings in the joint latent space. In joint embedding learning, we perform deep feature engineering by optimizing the batch-hard triplet loss function with soft-margin and double negative sampling, taking into account also the category-based alignment loss and discriminator-based alignment loss. Extensive experiments demonstrate that our SEJE approach with deep feature engineering significantly outperforms the state-of-the-art approaches.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
articleno = {74},
numpages = {27},
keywords = {multi-modal learning, deep feature engineering, Cross-modal retrieval}
}

@article{10.1016/j.eswa.2021.114820,
author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
title = {Machine Learning for industrial applications: A comprehensive literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114820},
doi = {10.1016/j.eswa.2021.114820},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {29},
keywords = {Operation management, Machine Learning, Deep Learning, Industrial applications, Literature review}
}

@inproceedings{10.1145/3297280.3297479,
author = {Ne\v{s}i\'{c}, Damir and Nyberg, Mattias and Gallina, Barbara},
title = {Constructing product-line safety cases from contract-based specifications},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297479},
doi = {10.1145/3297280.3297479},
abstract = {Safety cases are used to argue that safety-critical systems satisfy the requirements that are determined to mitigate the potential hazards in the systems operating environment. Although typically a manual task, safety cases have been successfully created for systems without many configuration options. However, in highly configurable systems, typically developed as a Product Line (PL), arguing about each possible configuration, and ensuring the completeness of the safety case are still open research problems. This paper presents a novel and general approach, based on Contract-Based Specification (CBS), for the construction of a safety case for an arbitrary PL. Starting from a general CBS framework, we present a PL extensions that allows expressing configurable systems and preserves the properties of the original CBS framework. Then, we define the transformation from arbitrary PL models, created using extended CBS framework, to a safety case argumentation-structure, expressed using the Goal Structuring Notation. Finally, the approach is exemplified on a simplified, but real, and currently produced system by Scania CV AB.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2022–2031},
numpages = {10},
keywords = {contract-based specification, product line engineering, safety case},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3461001.3474452,
author = {He\ss{}, Tobias and Sundermann, Chico and Th\"{u}m, Thomas},
title = {On the scalability of building binary decision diagrams for current feature models},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3474452},
doi = {10.1145/3461001.3474452},
abstract = {Binary decision diagrams (BDD) have been proposed for numerous product-line analyses. These analyses typically exploit properties unique to decision diagrams, such as negation in constant time and space. Furthermore, the existence of a BDD representing the configuration space of a product line removes the need to employ SAT or #SAT solvers for their analysis. Recent work has shown that the performance of state-of-the-art BDD libraries is significantly lower than previously reported and hypothesized. In this work, we provide an assessment of the state-of-the-art of BDD scalability in this domain and explain why previous results on the scalability of BDDs do not apply to more recent product-line instances.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {131–135},
numpages = {5},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-030-87013-3_36,
author = {Ojajuni, Opeyemi and Ayeni, Foluso and Akodu, Olagunju and Ekanoye, Femi and Adewole, Samson and Ayo, Timothy and Misra, Sanjay and Mbarika, Victor},
title = {Predicting Student Academic Performance Using Machine Learning},
year = {2021},
isbn = {978-3-030-87012-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87013-3_36},
doi = {10.1007/978-3-030-87013-3_36},
abstract = {The introduction of the Internet of Things (IoT), Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Big Data have paved the way for research focused on improving the student learning experience and help to address challenges faced by the education system. Machine Learning technology analyzes data to recognize patterns and use them to make predictions. This paper introduces a ML model that classify and predict student academic success by utilizing supervised ML algorithms like Random Forest, Support Vector Machines, Gradient boosting, Decision Tree, Logistic Regression, Regression, Extreme Gradient Boosting (XGBoost), and Deep Learning. This paper aims to predict student’s academic success based on historical data and identify the key factors that affect student academic success. Thus, the proposed approach offers a solution to predict student academic performance efficiently and accurately by comparing several ML models to the Deep Learning model. Results show that the Extreme Gradient Boosting (XGBoost) can predict student academic performance with an accuracy of 97.12%. Furthermore, results showed significant social and demographic features that affect student academic success. This study concludes that applying Machine Learning technology in the classroom will help educators identify gaps in student learning and enable early detection of underperforming students, thus empowering educators with informed decision-making.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part IX},
pages = {481–491},
numpages = {11},
keywords = {Convolutional Neutral Networks (CNN), Data analytics, Educational data mining, Student academic performance, Deep learning, Machine learning},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3382025.3414952,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Gasca, Rafael M. and Carmona-Fombella, Jose Antonio and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa},
title = {AMADEUS: towards the AutoMAteD secUrity teSting},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414952},
doi = {10.1145/3382025.3414952},
abstract = {The proper configuration of systems has become a fundamental factor to avoid cybersecurity risks. Thereby, the analysis of cybersecurity vulnerabilities is a mandatory task, but the number of vulnerabilities and system configurations that can be threatened is extremely high. In this paper, we propose a method that uses software product line techniques to analyse the vulnerable configuration of the systems. We propose a solution, entitled AMADEUS, to enable and support the automatic analysis and testing of cybersecurity vulnerabilities of configuration systems based on feature models. AMADEUS is a holistic solution that is able to automate the analysis of the specific infrastructures in the organisations, the existing vulnerabilities, and the possible configurations extracted from the vulnerability repositories. By using this information, AMADEUS generates automatically the feature models, that are used for reasoning capabilities to extract knowledge, such as to determine attack vectors with certain features. AMADEUS has been validated by demonstrating the capacities of feature models to support the threat scenario, in which a wide variety of vulnerabilities extracted from a real repository are involved. Furthermore, we open the door to new applications where software product line engineering and cybersecurity can be empowered.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {11},
numpages = {12},
keywords = {vulnerable configuration, vulnerabilities, testing, reasoning, pentesting, feature model, cybersecurity},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/1985441.1985458,
author = {Krishnan, Sandeep and Lutz, Robyn R. and Go\v{s}eva-Popstojanova, Katerina},
title = {Empirical evaluation of reliability improvement in an evolving software product line},
year = {2011},
isbn = {9781450305747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985441.1985458},
doi = {10.1145/1985441.1985458},
abstract = {Reliability is important to software product-line developers since many product lines require reliable operation. It is typically assumed that as a software product line matures, its reliability improves. Since post-deployment failures impact reliability, we study this claim on an open-source software product line, Eclipse. We investigate the failure trend of common components (reused across all products), highreuse variation components (reused in five or six products) and low-reuse variation components (reused in one or two products) as Eclipse evolves. We also study how much the common and variation components change over time both in terms of addition of new files and modification of existing files. Quantitative results from mining and analysis of the Eclipse bug and release repositories show that as the product line evolves, fewer serious failures occur in components implementing commonality, and that these components also exhibit less change over time. These results were roughly as expected. However, contrary to expectation, components implementing variations, even when reused in five or more products, continue to evolve fairly rapidly. Perhaps as a result, the number of severe failures in variation components shows no uniform pattern of decrease over time. The paper describes and discusses this and related results.},
booktitle = {Proceedings of the 8th Working Conference on Mining Software Repositories},
pages = {103–112},
numpages = {10},
keywords = {software product lines, reuse, reliability, failures, change},
location = {Waikiki, Honolulu, HI, USA},
series = {MSR '11}
}

@inproceedings{10.1007/978-3-030-60239-0_3,
author = {Zhao, Wenqian and Li, Xiangxiang and Rong, Guoping and Lin, Mufeng and Lin, Chen and Yang, Yifan},
title = {DAFEE: A Scalable Distributed Automatic Feature Engineering Algorithm for Relational Datasets},
year = {2020},
isbn = {978-3-030-60238-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60239-0_3},
doi = {10.1007/978-3-030-60239-0_3},
abstract = {Automatic feature engineering aims to construct informative features automatically and reduce manual labor for machine learning applications. The majority of existing approaches are designed to handle tasks with only one data source, which are less applicable to real scenarios. In this paper, we present a distributed automatic feature engineering algorithm, DAFEE, to generate features among multiple large-scale relational datasets. Starting from the target table, the algorithm uses a Breadth-First-Search type algorithm to find its related tables and constructs advanced high-order features that are remarkably effective in practical applications. Moreover, DAFEE implements a feature selection method to reduce the computational cost and improve predictive performance. Furthermore, it is highly optimized to process a massive volume of data. Experimental results demonstrate that it can significantly improve the predictive performance by 7% compared to SOTA algorithms.},
booktitle = {Algorithms and Architectures for Parallel Processing: 20th International Conference, ICA3PP 2020, New York City, NY, USA, October 2–4, 2020, Proceedings, Part II},
pages = {32–46},
numpages = {15},
keywords = {Machine learning, Feature selection, Big data, Relational dataset, Automatic feature engineering, AutoML},
location = {New York, NY, USA}
}

@inproceedings{10.1007/978-3-030-72610-2_10,
author = {Kazyulina, Marina and Babii, Aleksandr and Malafeev, Alexey},
title = {Emotion Classification in Russian: Feature Engineering and Analysis},
year = {2020},
isbn = {978-3-030-72609-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-72610-2_10},
doi = {10.1007/978-3-030-72610-2_10},
abstract = {In this paper, we address the issue of identifying emotions in Russian informal text messages. For this purpose, a new large dataset of text messages from the most popular Russian messaging/social networking services (Telegram, VK) was compiled semi-automatically. Emojis contained in the text messages were used to annotate the data for emotions expressed. This paper proposes an integrated approach to text-based emotion classification combining linguistic methods and machine learning. This approach relies on morphological, lexical, and stylistic features of the text. Furthermore, the level of expressiveness was considered as well. As a result, an emotion classification model demonstrating near-human performance was designed. In this paper, we also report on the importance of different linguistic features of the text messages for the task of automatic emotive analysis. Additionally, we perform error analysis and discover ways to improve the model in the future.},
booktitle = {Analysis of Images, Social Networks and Texts: 9th International Conference, AIST 2020, Skolkovo, Moscow, Russia, October 15–16, 2020, Revised Selected Papers},
pages = {135–148},
numpages = {14},
keywords = {Natural language processing, Sentiment analysis, Emotiveness, Emotion identification, Machine learning},
location = {Moscow, Russia}
}

@inproceedings{10.1609/aaai.v33i01.33014237,
author = {Li, Yu-Feng and Wang, Hai and Wei, Tong and Tu, Wei-Wei},
title = {Towards automated semi-supervised learning},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33014237},
doi = {10.1609/aaai.v33i01.33014237},
abstract = {Automated Machine Learning (AutoML) aims to build an appropriate machine learning model for any unseen dataset automatically, i.e., without human intervention. Great efforts have been devoted on AutoML while they typically focus on supervised learning. In many applications, however, semi-supervised learning (SSL) are widespread and current AutoML systems could not well address SSL problems. In this paper, we propose to present an automated learning system for SSL (AUTO-SSL). First, meta-learning with enhanced meta-features is employed to quickly suggest some instantiations of the SSL techniques which are likely to perform quite well. Second, a large margin separation method is proposed to fine-tune the hyperparameters and more importantly, alleviate performance deterioration. The basic idea is that, if a certain hyperparameter owns a high quality, its predictive results on unlabeled data may have a large margin separation. Extensive empirical results over 200 cases demonstrate that our proposal on one side achieves highly competitive or better performance compared to the state-of-the-art AutoML system AUTO-SKLEARN and classical SSL techniques, on the other side unlike classical SSL techniques which often significantly degenerate performance, our proposal seldom suffers from such deficiency.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {520},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.5555/2004685.2005507,
author = {Engstr\"{o}m, Emelie and Runeson, Per},
title = {Decision Support for Test Management and Scope Selection in a Software Product Line Context},
year = {2011},
isbn = {9780769543451},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In large software organizations with a product line development approach, system test planning and scope selection is a complex tasks for which tool support is needed. Due to repeated testing: across different testing levels, over time (test for regression) as well as of different variants, the risk of double testing is large as well as the risk of overlooking important tests, hidden by the huge amount of possible tests. This paper discusses the need and challenges of providing decision support for test planning and test selection in a product line context, and highlights possible paths towards a pragmatic implementation of context-specific decision support of various levels of automation. With existing regression testing approaches it is possible to provide automated decision support in a few specific cases, while test management in general may be supported through visualization of test execution coverage, the testing space and the delta between the sufficiently tested system and the system under test. A better understanding of the real world context and how to map research results to the same is needed.},
booktitle = {Proceedings of the 2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops},
pages = {262–265},
numpages = {4},
keywords = {visualization, test selection, test coverage, software product line testing, regression testing, decision support},
series = {ICSTW '11}
}

@inproceedings{10.1007/978-3-030-96068-1_1,
author = {Liu, Rex and Ramli, Albara Ah and Zhang, Huanle and Henricson, Erik and Liu, Xin},
title = {An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence},
year = {2021},
isbn = {978-3-030-96067-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-96068-1_1},
doi = {10.1007/978-3-030-96068-1_1},
abstract = {With the rapid development of the internet of things (IoT) and artificial intelligence (AI) technologies, human activity recognition (HAR) has been applied in a variety of domains such as security and surveillance, human-robot interaction, and entertainment. Even though a number of surveys and review papers have been published, there is a lack of HAR overview papers focusing on healthcare applications that use wearable sensors. Therefore, we fill in the gap by presenting this overview paper. In particular, we present our projects to illustrate the system design of HAR applications for healthcare. Our projects include early mobility identification of human activities for intensive care unit (ICU) patients and gait analysis of Duchenne muscular dystrophy (DMD) patients. We cover essential components of designing HAR systems including sensor factors (e.g., type, number, and placement location), AI model selection (e.g., classical machine learning models versus deep learning models), and feature engineering. In addition, we highlight the challenges of such healthcare-oriented HAR systems and propose several research opportunities for both the medical and the computer science community.},
booktitle = {Internet of Things – ICIOT 2021: 6th International Conference, Held as Part of the Services Conference Federation, SCF 2021, Virtual Event, December 10–14, 2021, Proceedings},
pages = {1–14},
numpages = {14},
keywords = {Wearable sensors, Artificial intelligence (AI), Internet of things (IoT), Healthcare, Human activity recognition (HAR)}
}

@inproceedings{10.1145/3279996.3280014,
author = {Oliv\'{e}, David Monlla\'{o} and Huynh, Du Q. and Reynolds, Mark and Dougiamas, Martin and Wiese, Damyon},
title = {A supervised learning framework for learning management systems},
year = {2018},
isbn = {9781450365369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3279996.3280014},
doi = {10.1145/3279996.3280014},
abstract = {Educational Data Mining (EDM) and Learning Analytics (LA) focus on data analysis of learners in the context of educational settings like Moodle, a Learning Management System (LMS). Both EDM and LA aim to understand learners and optimise learning processes. Predictive modelling serve a key role in optimising learning processes. Learning Analytics in an LMS covers many different aspects: finding students at risk of abandoning a course, predicting students failing a quiz or students not reaching the end of a lesson in less than 15 minutes. Thus, there are multiple prediction models that can be explored. The prediction models can target at the course also. For instance, will this course engage learners? Will this forum be useful to the students of this course? To ease the evaluation and usage of Supervised Learning prediction models in LMS, we abstract the key elements of prediction models and we build an analytics framework for Moodle, one of the most popular Learning management Systems available in the market. Our software framework manages the complete cycle that predictive models follow until they are used in production, which includes calculations of features and labels from the LMS database raw data, normalization, feature engineering, model evaluation and a production-ready mode to generate insights for users from predictions. Apart from the software framework we also present a use case that serves as an example: A prediction model which is able to identify students at risk of abandoning a course with a 92% in accuracy using past versions of the course as training data.},
booktitle = {Proceedings of the First International Conference on Data Science, E-Learning and Information Systems},
articleno = {18},
numpages = {8},
keywords = {supervised learning, neural networks, moodle, machine learning, learning management systems, learning analytics, educational data mining},
location = {Madrid, Spain},
series = {DATA '18}
}

@article{10.1145/3479587,
author = {Zagalsky, Alexey and Te'eni, Dov and Yahav, Inbal and Schwartz, David G. and Silverman, Gahl and Cohen, Daniel and Mann, Yossi and Lewinsky, Dafna},
title = {The Design of Reciprocal Learning Between Human and Artificial Intelligence},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479587},
doi = {10.1145/3479587},
abstract = {The need for advanced automation and artificial intelligence (AI) in various fields, including text classification, has dramatically increased in the last decade, leaving us critically dependent on their performance and reliability. Yet, as we increasingly rely more on AI applications, their algorithms are becoming more nuanced, more complex, and less understandable precisely at a time we need to understand them better and trust them to perform as expected. Text classification in the medical and cybersecurity domains is a good example of a task where we may wish to keep the human in the loop. Human experts lack the capacity to deal with the high volume and velocity of data that needs to be classified, and ML techniques are often unexplainable and lack the ability to capture the required context needed to make the right decision and take action. We propose a new abstract configuration of Human-Machine Learning (HML) that focuses on reciprocal learning, where the human and the AI are collaborating partners. We employ design-science research (DSR) to learn and design an application of the HML configuration, which incorporates software to support combining human and artificial intelligences. We define the HML configuration by its conceptual components and their function. We then describe the development of a system called Fusion that supports human-machine reciprocal learning. Using two case studies of text classification from the cyber domain, we evaluate Fusion and the proposed HML approach, demonstrating benefits and challenges. Our results show a clear ability of domain experts to improve the ML classification performance over time, while both human and machine, collaboratively, develop their conceptualization, i.e., their knowledge of classification. We generalize our insights from the DSR process as actionable principles for researchers and designers of 'human in the learning loop' systems. We conclude the paper by discussing HML configurations and the challenge of capturing and representing knowledge gained jointly by human and machine, an area we feel has great potential.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {443},
numpages = {36},
keywords = {AI, accuracy, context, cyber-security, explainabilitiy, feedback, human intelligence, text classification}
}

@article{10.1561/2200000081,
author = {Holden, Sean B.},
title = {Machine Learning for Automated Theorem Proving: Learning to Solve SAT and QSAT},
year = {2021},
issue_date = {Nov 2021},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {14},
number = {6},
issn = {1935-8237},
url = {https://doi.org/10.1561/2200000081},
doi = {10.1561/2200000081},
abstract = {The decision problem for Boolean satisfiability, generally
    referred to as SAT, is the archetypal NP-complete problem,
    and encodings of many problems of practical interest exist
    allowing them to be treated as SAT problems. Its generalization
    to quantified SAT (QSAT) is PSPACE-complete, and
    is useful for the same reason. Despite the computational
    complexity of SAT and QSAT, methods have been developed
    allowing large instances to be solved within reasonable
    resource constraints. These techniques have largely exploited
    algorithmic developments; however machine learning also
    exerts a significant influence in the development of state-ofthe-
    art solvers. Here, the application of machine learning
    is delicate, as in many cases, even if a relevant learning
    problem can be solved, it may be that incorporating the
    result into a SAT or QSAT solver is counterproductive, because
    the run-time of such solvers can be sensitive to small
    implementation changes. The application of better machine
    learning methods in this area is thus an ongoing challenge,
    with characteristics unique to the field. This work provides
    a comprehensive review of the research to date on incorporating
    machine learning into SAT and QSAT solvers, as a
    resource for those interested in further advancing the field.},
journal = {Found. Trends Mach. Learn.},
month = nov,
pages = {807–989},
numpages = {187}
}

@inproceedings{10.1145/2649387.2649407,
author = {Singh, Anima and Nadkarni, Girish and Guttag, John and Bottinger, Erwin},
title = {Leveraging hierarchy in medical codes for predictive modeling},
year = {2014},
isbn = {9781450328944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2649387.2649407},
doi = {10.1145/2649387.2649407},
abstract = {ICD-9 codes are among the most important patient information recorded in electronic health records. They have been shown to be useful for predictive modeling of different adverse outcomes in patients, including diabetes and heart failure. An important characteristic of ICD-9 codes is the hierarchical relationships among different codes. Nevertheless, the most common feature representation used to incorporate ICD-9 codes in predictive models disregards the structural relationships.In this paper, we explore different methods to leverage the hierarchical structure in ICD-9 codes with the goal of improving performance of predictive models. We compare methods that leverage hierarchy by 1) incorporating the information during feature construction, 2) using a learning algorithm that addresses the structure in the ICD-9 codes when building a model, or 3) doing both. We propose and evaluate a novel feature engineering approach to leverage hierarchy, while simultaneously reducing feature dimensionality.Our experiments indicate that significant improvement in predictive performance can be achieved by properly exploiting ICD-9 hierarchy. Using two clinical tasks: predicting chronic kidney disease progression (Task-CKD), and predicting incident heart failure (Task-HF), we show that methods that use hierarchy outperform the conventional approach in F-score (0.44 vs 0.36 for Task-HF and 0.40 vs 0.37 for Task-CKD) and relative risk (4.6 vs 3.3 for Task-HF and 5.9 vs 3.8 for Task-CKD).},
booktitle = {Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
pages = {96–103},
numpages = {8},
keywords = {predictive modeling, machine learning in healthcare and medicine, feature hierarchy, ICD-9 codes},
location = {Newport Beach, California},
series = {BCB '14}
}

@article{10.1016/j.patrec.2021.07.019,
author = {Deng, Xiaoheng and Jiang, Ping and Zhao, Dezheng and Huang, Rong and Shen, Hailan},
title = {Effective semi-supervised learning for structured data using Embedding GANs},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {151},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2021.07.019},
doi = {10.1016/j.patrec.2021.07.019},
journal = {Pattern Recogn. Lett.},
month = nov,
pages = {127–134},
numpages = {8},
keywords = {Structured data, Semi-supervised learning, Embedding, GAN}
}

@article{10.1145/3092566,
author = {Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza},
title = {Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092566},
doi = {10.1145/3092566},
abstract = {Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {56},
numpages = {36},
keywords = {survey, software vulnerability discovery, software security, review, machine-learning, data-mining, Software vulnerability analysis}
}

@inproceedings{10.1145/2857546.2857608,
author = {Rahmat, Azizah and Kassim, Suzana and Selamat, Mohd Hasan and Hassan, Sa'adah},
title = {Actor in Multi Product Line},
year = {2016},
isbn = {9781450341424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2857546.2857608},
doi = {10.1145/2857546.2857608},
abstract = {Software product line (SPL) involved variability modeling in domain engineering that will be matched to the respected application engineering. Several researches existed within the scope of mapping from reference architecture (RA) in domain engineering to system architecture in application engineering within the same domain. However, the mapping of cross domain RA or Multi Product Line (MPL) required more systematic mapping due to the several participating product line architecture (PLA) that will further instantiated to specific system architecture. The objective of this paper was to propose an actor-oriented approach in the mapping process of reference architecture, product line architecture and system architecture of MPL. Since the reference architecture consisted of several components, the scope of this research was within the functional decomposition or source code level. The experiment was involving the runtime behavior of the java code. The code with actor-oriented approach had shown the least amount of time taken to complete the main method compared to the non-actor-oriented approach. In conclusion, actor-oriented approach performs better performance in the mapping of reference architecture to product line architecture and system architecture. For future work, the consistency of the mapping will be evaluated.},
booktitle = {Proceedings of the 10th International Conference on Ubiquitous Information Management and Communication},
articleno = {61},
numpages = {8},
keywords = {reference architecture, multi product line, cross-domain reference architecture, actor, Software product line},
location = {Danang, Viet Nam},
series = {IMCOM '16}
}

@inproceedings{10.1007/978-3-030-59817-4_6,
author = {Abadi, Eden and Hazan, Itay},
title = {Improved Feature Engineering for Free-Text Keystroke Dynamics},
year = {2020},
isbn = {978-3-030-59816-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59817-4_6},
doi = {10.1007/978-3-030-59817-4_6},
abstract = {Free-text keystroke dynamics is a method of verifying users’ identity based on their unique pattern of typing a spontaneous text on a keyboard. When applied in remote systems, it can add an additional layer of security that can detect compromised accounts. Therefore, service providers can be more certain that remote systems accounts would not be compromised by malicious attackers. Free-text keystroke dynamics usually involve the extraction of n-graphs, which represent the latency between n consecutive events. These n-graphs are then integrated with one of the various existing machine learning algorithms. To the best of our knowledge, n-graphs are the most widely used feature engineering for free text keystroke dynamics. We present extended-n-graphs, an improved version of the commonly used n-graphs, based on several extended metrics that outperform the traditionally used basic n-graphs. Our technique was evaluated on top of the gradient boosting algorithm, best performing algorithm on basic n-graphs and several additional algorithms such as random forest, K-NN, SVM and MLP. Our empirical results show encouraging 4% improvement in the Area Under the Curve (AUC) when evaluated on a publicly used benchmark.},
booktitle = {Security and Trust Management: 16th International Workshop, STM 2020, Guildford, UK, September 17–18, 2020, Proceedings},
pages = {93–105},
numpages = {13},
keywords = {Feature engineering, Free text, Keystroke dynamics},
location = {Guildford, United Kingdom}
}

@article{10.1016/j.asoc.2020.107023,
author = {Ligthart, Alexander and Catal, Cagatay and Tekinerdogan, Bedir},
title = {Analyzing the effectiveness of semi-supervised learning approaches for opinion spam classification},
year = {2021},
issue_date = {Mar 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {101},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.107023},
doi = {10.1016/j.asoc.2020.107023},
journal = {Appl. Soft Comput.},
month = mar,
numpages = {12},
keywords = {Machine learning, Semi-supervised learning, Fake reviews, Opinion spam detection}
}

@inproceedings{10.1007/978-3-030-81097-9_7,
author = {Shan, Ruocheng and Youssef, Abdou},
title = {Towards Math Terms Disambiguation Using Machine Learning},
year = {2021},
isbn = {978-3-030-81096-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-81097-9_7},
doi = {10.1007/978-3-030-81097-9_7},
abstract = {Word disambiguation has been an important task in natural language processing. However, the problem of disambiguation is still less explored in mathematical text. Similar to natural languages, some math terms are not assigned a unique interpretation. As math text is an important part of the scientific literature, an accurate and efficient way of performing disambiguation of math terms will be a significant contribution. In this paper, we present some investigations on math-term disambiguation using machine learning. All experimental data are selected from the DLMF dataset. Our experiments consist of 3 steps: (1) create a labeled dataset of math equations (from the DLMF) where the instances are (math token, token meaning) pairs, grouped by equation; (2) build machine learning models and train them using our labeled dataset, and (3) evaluate and compare the performance of our models using different evaluation metrics. Our results show that machine learning is an effective approach to math-term disambiguation. The accuracy of our models ranges from 70% to 85%. There is potential for considerable improvements once we have much larger labeled datasets with more balanced classes.},
booktitle = {Intelligent Computer Mathematics: 14th International Conference, CICM 2021, Timisoara, Romania, July 26–31, 2021, Proceedings},
pages = {90–106},
numpages = {17},
keywords = {Machine Learning, Mathematical equations, Disambiguation, [inline-graphic not available: see fulltext], Math-term},
location = {Timisoara, Romania}
}

@article{10.1145/3466690,
author = {Zokaeinikoo, Maryam and Kazemian, Pooyan and Mitra, Prasenjit and Kumara, Soundar},
title = {AIDCOV: An Interpretable Artificial Intelligence Model for Detection of COVID-19 from Chest Radiography Images},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/3466690},
doi = {10.1145/3466690},
abstract = {As the Coronavirus Disease 2019 (COVID-19) pandemic continues to grow globally, testing to detect COVID-19 and isolating individuals who test positive remains the primary strategy for preventing community spread of the disease. Therefore, automatic and accurate detection of COVID-19 using medical imaging modalities, which are more widely available and accessible, can be beneficial as an alternative diagnostic tool. In this study, an Artificial Intelligence model for Detection of COVID-19 (AIDCOV) is developed to classify chest radiography images as belonging to a person with either COVID-19, other infections, or no pneumonia (i.e., normal). The hierarchical structure in AIDCOV captures the dependencies among features and improves model performance while an attention mechanism makes the model interpretable and transparent. We used several publicly available datasets of both computed tomography (CT) and X-ray modalities. The main public dataset for chest X-ray images contains 475 COVID-19 samples, 3949 samples from other viral/bacterial infections, and 1583 normal samples. Our model achieves a mean cross-validation accuracy of 98.4%. AIDCOV has a sensitivity of 99.8%, a specificity of 100%, and an F1-score of 99.8% in detecting COVID-19 from X-ray images on that dataset. Using a large dataset of CT images, our model obtained mean cross-validation accuracy and sensitivity of 98.8% and 99.4%, respectively. Additionally, our interpretable model can distinguish subtle signs of infection within each radiography image. Assuming these results hold up in larger datasets obtained from a variety of patients over the world, AIDCOV can be used in conjunction with or instead of RT-PCR testing (where RT-PCR testing is unavailable) to detect and isolate individuals with COVID-19, prevent onward transmission to the general population and healthcare workers, and highlight the areas in the lungs that show signs of COVID-related damage.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = oct,
articleno = {29},
numpages = {20},
keywords = {pneumonia, chest X-ray, chest CT, transfer learning, convolutional neural networks, attention, deep learning, artificial intelligence, COVID-19}
}

@article{10.1016/j.jbi.2015.10.006,
author = {Jung, Kenneth and Shah, Nigam H.},
title = {Implications of non-stationarity on predictive modeling using EHRs},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {58},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2015.10.006},
doi = {10.1016/j.jbi.2015.10.006},
abstract = {Display Omitted We study the effect of non-stationarity on predictive models of wound healing.Different types of non-stationarity are simulated by different splits of the dataset.Estimates of model performance change under different types of non-stationarity.Researchers should account for non-stationarity during model development. The rapidly increasing volume of clinical information captured in Electronic Health Records (EHRs) has led to the application of increasingly sophisticated models for purposes such as disease subtype discovery and predictive modeling. However, increasing adoption of EHRs implies that in the near future, much of the data available for such purposes will be from a time period during which both the practice of medicine and the clinical use of EHRs are in flux due to historic changes in both technology and incentives. In this work, we explore the implications of this phenomenon, called non-stationarity, on predictive modeling. We focus on the problem of predicting delayed wound healing using data available in the EHR during the first week of care in outpatient wound care centers, using a large dataset covering over 150,000 individual wounds and 59,958 patients seen over a period of four years. We manipulate the degree of non-stationarity seen by the model development process by changing the way data is split into training and test sets. We demonstrate that non-stationarity can lead to quite different conclusions regarding the relative merits of different models with respect to predictive power and calibration of their posterior probabilities. Under the non-stationarity exhibited in this dataset, the performance advantage of complex methods such as stacking relative to the best simple classifier disappears. Ignoring non-stationarity can thus lead to sub-optimal model selection in this task.},
journal = {J. of Biomedical Informatics},
month = dec,
pages = {168–174},
numpages = {7},
keywords = {Wound healing, Prognostic model, Predictive model, Machine learning, Data mining}
}

@article{10.1016/j.compbiomed.2020.104043,
author = {Jamthikar, Ankush D. and Gupta, Deep and Saba, Luca and Khanna, Narendra N. and Viskovic, Klaudija and Mavrogeni, Sophie and Laird, John R. and Sattar, Naveed and Johri, Amer M. and Pareek, Gyan and Miner, Martin and Sfikakis, Petros P. and Protogerou, Athanasios and Viswanathan, Vijay and Sharma, Aditya and Kitas, George D. and Nicolaides, Andrew and Kolluri, Raghu and Suri, Jasjit S.},
title = {Artificial intelligence framework for predictive cardiovascular and stroke risk assessment models: A narrative review of integrated approaches using carotid ultrasound},
year = {2020},
issue_date = {Nov 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {126},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2020.104043},
doi = {10.1016/j.compbiomed.2020.104043},
journal = {Comput. Biol. Med.},
month = nov,
numpages = {20},
keywords = {Artificial intelligence-based risk assessment, Integrated models, Statistical risk calculator, 10-Year risk, Stroke, Cardiovascular disease, Atherosclerosis}
}

@article{10.1016/j.artmed.2021.102157,
author = {Hoyos, William and Aguilar, Jose and Toro, Mauricio},
title = {Dengue models based on machine learning techniques: A systematic literature review},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {119},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102157},
doi = {10.1016/j.artmed.2021.102157},
journal = {Artif. Intell. Med.},
month = sep,
numpages = {16},
keywords = {Machine learning, Intervention model, Epidemic model, Diagnostic model, Dengue, SS, CRF, BTS, ALT, GLM, RMSE, DBSI, GT, MSE, KNN, AI, CoI, HI, BI, LiR, MAE, SARIMAX, SOM, GWR, BRT, GBM, CART, GAM, LASSO, APRI, DT, DNA, SVM, VEGF, FL, IL-10, TNFα, IL-1β, S1P, PAF, RF, CI, OR, AUC, SE, PSO, MCS, MLP, ANN, LoR, PRISMA, SLR, DSS, SD, WHO, DENV}
}

@inproceedings{10.1007/978-3-030-47426-3_63,
author = {Zhang, Jianyu and Hao, Jianye and Fogelman-Souli\'{e}, Fran\c{c}oise},
title = {Cross-data Automatic Feature Engineering via Meta-learning and Reinforcement Learning},
year = {2020},
isbn = {978-3-030-47425-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-47426-3_63},
doi = {10.1007/978-3-030-47426-3_63},
abstract = {Feature Engineering (FE) is one of the most beneficial, yet most difficult and time-consuming tasks of machine learning projects, and requires strong expert knowledge. It is thus significant to design generalized ways to perform FE. The primary difficulties arise from the multiform information to consider, the potentially infinite number of possible features and the high computational cost of feature generation and evaluation. We present a framework called Cross-data Automatic Feature Engineering Machine (CAFEM), which formalizes the FE problem as an optimization problem over a Feature Transformation Graph (FTG). CAFEM contains two components: a FE learner (FeL) that learns fine-grained FE strategies on one single dataset by Double Deep Q-learning (DDQN) and a Cross-data Component (CdC) that speeds up FE learning on an unseen dataset by the generalized FE policies learned by Meta-Learning on a collection of datasets. We compare the performance of FeL with several existing state-of-the-art automatic FE techniques on a large collection of datasets. It shows that FeL outperforms existing approaches and is robust on the selection of learning algorithms. Further experiments also show that CdC can not only speed up FE learning but also increase learning performance.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020, Singapore, May 11–14, 2020, Proceedings, Part I},
pages = {818–829},
numpages = {12},
location = {Singapore, Singapore}
}

@inproceedings{10.5555/3172077.3172240,
author = {Nargesian, Fatemeh and Samulowitz, Horst and Khurana, Udayan and Khalil, Elias B. and Turaga, Deepak},
title = {Learning feature engineering for classification},
year = {2017},
isbn = {9780999241103},
publisher = {AAAI Press},
abstract = {Feature engineering  is the task of improving predictive modelling performance on a dataset by transforming its feature space. Existing approaches to automate this process rely on either transformed feature space exploration through evaluation-guided search, or explicit expansion of datasets with all transformed features followed by feature selection. Such approaches incur high computational costs in runtime and/or memory. We present a novel technique, called  Learning Feature Engineering  (LFE), for automating feature engineering in classification tasks. LFE is based on learning the effectiveness of applying a  transformation  (e.g., arithmetic or aggregate operators) on numerical features, from past feature engineering experiences. Given a new dataset, LFE recommends a set of useful transformations to be applied on features without relying on model evaluation or explicit feature expansion and selection. Using a collection of datasets, we train a set of neural networks, which aim at predicting the transformation that impacts classification performance positively. Our empirical results show that LFE outperforms other feature engineering approaches for an overwhelming majority (89%) of the datasets from various sources while incurring a substantially lower computational cost.},
booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence},
pages = {2529–2535},
numpages = {7},
location = {Melbourne, Australia},
series = {IJCAI'17}
}

@article{10.1007/s10462-020-09814-9,
author = {Gangavarapu, Tushaar and Jaidhar, C. D. and Chanduka, Bhabesh},
title = {Applicability of machine learning in spam and phishing email filtering: review and approaches},
year = {2020},
issue_date = {Oct 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {7},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09814-9},
doi = {10.1007/s10462-020-09814-9},
abstract = {With the influx of technological advancements and the increased simplicity in communication, especially through emails, the upsurge in the volume of unsolicited bulk emails (UBEs) has become a severe threat to global security and economy. Spam emails not only waste users’ time, but also consume a lot of network bandwidth, and may also include malware as executable files. Alternatively, phishing emails falsely claim users’ personal information to facilitate identity theft and are comparatively more dangerous. Thus, there is an intrinsic need for the development of more robust and dependable UBE filters that facilitate automatic detection of such emails. There are several countermeasures to spam and phishing, including blacklisting and content-based filtering. However, in addition to content-based features, behavior-based features are well-suited in the detection of UBEs. Machine learning models are being extensively used by leading internet service providers like Yahoo, Gmail, and Outlook, to filter and classify UBEs successfully. There are far too many options to consider, owing to the need to facilitate UBE detection and the recent advances in this domain. In this paper, we aim at elucidating on the way of extracting email content and behavior-based features, what features are appropriate in the detection of UBEs, and the selection of the most discriminating feature set. Furthermore, to accurately handle the menace of UBEs, we facilitate an exhaustive comparative study using several state-of-the-art machine learning algorithms. Our proposed models resulted in an overall accuracy of 99% in the classification of UBEs. The text is accompanied by snippets of Python code, to enable the reader to implement the approaches elucidated in this paper.},
journal = {Artif. Intell. Rev.},
month = oct,
pages = {5019–5081},
numpages = {63},
keywords = {Spam, Python, Phishing, Machine learning, Feature engineering}
}

@article{10.1016/j.compeleceng.2021.107329,
author = {Oprea, Simona-Vasilica and B\^{a}ra, Adela},
title = {Machine learning classification algorithms and anomaly detection in conventional meters and Tunisian electricity consumption large datasets},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107329},
doi = {10.1016/j.compeleceng.2021.107329},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {17},
keywords = {Conventional meter, Probability density function, Feature engineering, Fraud detection, Machine learning}
}

@article{10.1145/3430376,
author = {K., Mythili and Narwaria, Manish},
title = {Assessment of Machine Learning-Based Audiovisual Quality Predictors: Why Uncertainty Matters},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3430376},
doi = {10.1145/3430376},
abstract = {Quality assessment of audiovisual (AV) signals is important from the perspective of system design, optimization, and management of a modern multimedia communication system. However, automatic prediction of AV quality via the use of computational models remains challenging. In this context, machine learning (ML) appears to be an attractive alternative to the traditional approaches. This is especially when such assessment needs to be made in no-reference (i.e., the original signal is unavailable) fashion. While development of ML-based quality predictors is desirable, we argue that proper assessment and validation of such predictors is also crucial before they can be deployed in practice. To this end, we raise some fundamental questions about the current approach of ML-based model development for AV quality assessment and signal processing for multimedia communication in general. We also identify specific limitations associated with the current validation strategy which have implications on analysis and comparison of ML-based quality predictors. These include a lack of consideration of: (a) data uncertainty, (b) domain knowledge, (c) explicit learning ability of the trained model, and (d) interpretability of the resultant model. Therefore, the primary goal of this article is to shed some light into mentioned factors. Our analysis and proposed recommendations are of particular importance in the light of significant interests in ML methods for multimedia signal processing (specifically in cases where human-labeled data is used), and a lack of discussion of mentioned issues in existing literature.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = apr,
articleno = {45},
numpages = {22},
keywords = {validation, uncertainty, machine learning, Audiovisual quality}
}

@inproceedings{10.1145/3148011.3154473,
author = {Atzmueller, Martin and Sternberg, Eric},
title = {Mixed-Initiative Feature Engineering Using Knowledge Graphs},
year = {2017},
isbn = {9781450355537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148011.3154473},
doi = {10.1145/3148011.3154473},
abstract = {This paper proposes a mixed-initiative feature engineering approach using explicit knowledge captured in a knowledge graph complemented by a novel interactive visualization method. Using the explicitly captured relations and dependencies between concepts and their properties, feature engineering is enabled in a semi-automatic way. Furthermore, the results (and decisions) obtained throughout the process can be utilized for refining the features and the knowledge graph. Analytical requirements can then be conveniently captured for feature engineering -- enabling integrated semantics-driven data analysis and machine learning.},
booktitle = {Proceedings of the 9th Knowledge Capture Conference},
articleno = {46},
numpages = {4},
keywords = {machine learning, knowledge graph, feature engineering},
location = {Austin, TX, USA},
series = {K-CAP '17}
}

@inproceedings{10.1145/3195836.3195853,
author = {Alami, Adam and Dittrich, Yvonne and W\k{a}sowski, Andrzej},
title = {Influencers of quality assurance in an open source community},
year = {2018},
isbn = {9781450357258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195836.3195853},
doi = {10.1145/3195836.3195853},
abstract = {ROS (Robot Operating System) is an open source community in robotics that is developing standard robotics operating system facilities such as hardware abstraction, low-level device control, communication middleware, and a wide range of software components for robotics functionality. This paper studies the quality assurance practices of the ROS community. We use qualitative methods to understand how ideology, priorities of the community, culture, sustainability, complexity, and adaptability of the community affect the implementation of quality assurance practices. Our analysis suggests that software engineering practices require social and cultural alignment and adaptation to the community particularities to achieve seamless implementation in open source environments. This alignment should be incorporated into the design and implementation of quality assurance practices in open source communities.},
booktitle = {Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {61–68},
numpages = {8},
keywords = {quality assurance, open source software, OSS community},
location = {Gothenburg, Sweden},
series = {CHASE '18}
}

@article{10.1145/2853073.2853082,
author = {Soujanya, K. L.S. and AnandaRao, A.},
title = {A Generic Framework for Configuration Management of SPL and Controlling Evolution of Complex Software Products},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853082},
doi = {10.1145/2853073.2853082},
abstract = {Efficient configuration management system is crucial for the success of any software product line (SPL). Due to ever changing needs of customers, SPL undergoes constant changes that are to be tracked in real time. In the context of customer-driven development, anticipation and change management are to be given paramount importance. It demands implementation of software variability that drives home changed, extended and customized configurations besides economy at scale. Moreover, the emergence of distributed technologies, the unprecedented growth of component based, serviceoriented systems throw ever increasing challenges to software product line configuration management. Derivation of a new product is a dynamic process in software product line that should consider functionality and quality attributes. Very few approaches are found on configuration management (CM) of SPL though CM is enough matured for traditional products. They are tailor made and inadequate to provide a general solution. Stated differently, a comprehensive approach for SPL configuration management and product derivation is still to be desired. In this paper, we proposed a framework that guides in doing so besides helping in SPL definitions in generic way. Our framework facilitates SPL configuration management and product derivation based on critical path analysis, weight computation and feedback. We proposed two algorithms namely Quality Driven Product Derivation (QDPD) and Composition Analysis algorithm for generating satisfied compositions and to find best possible composition respectively. The usage of weights and critical path analysis improves quality of product derivation. The framework is extensible and flexible thus it can be leveraged with variability-aware design patterns and ontology. We built a prototype that demonstrates the proof of concept. We tested our approach with Dr. School product line. The results reveal that the framework supports configuration management of SPL and derivation of high quality product in the product line. We evaluated results with ground truth to establish significance of our implementation},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–10},
numpages = {10},
keywords = {weighted approach, product derivation, critical path analysis, configuration management, Software product line}
}

@article{10.1287/opre.2018.1825,
author = {Bertsimas, Dimitris and Mi\v{s}i\'{c}, Velibor V.},
title = {Exact First-Choice Product Line Optimization},
year = {2019},
issue_date = {May-June 2019},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {67},
number = {3},
issn = {0030-364X},
url = {https://doi.org/10.1287/opre.2018.1825},
doi = {10.1287/opre.2018.1825},
abstract = {Which products should a firm offer based on its customers’ preferences? This is the question posed in the problem of product line design, a well-studied and notoriously difficult problem that is central in marketing science. In “Exact First-Choice Product Line Optimization” by Dimitris Bertsimas and Velibor V. Mi\v{s}i\'{c}, the authors propose a new approach for solving this problem when segments of customers choose products according to a ranking. They propose a new mixed-integer optimization model of the problem, which they show to be tighter than prior formulations, and a solution approach based on Benders decomposition, which exploits the surprising fact that the subproblem can be solved efficiently for both integer and fractional master solutions. A well-known product line instance based on a conjoint data set of over 3,000 products and 300 respondents, which required a week of computation time to solve in prior work, is solved by the authors’ approach in just over 10 minutes.A fundamental problem faced by firms is that of product line design: given a set of candidate products that may be offered to a collection of customers, what subset of those products should be offered to maximize the profit that is realized when customers make purchases according to their preferences? In this paper, we consider the product line design problem when customers choose according to a first-choice rule and present a new mixed-integer optimization formulation of the problem. We theoretically analyze the strength of our formulation and show that it is stronger than alternative formulations that have been proposed in the literature, thus contributing to a unified understanding of the different formulations for this problem. We also present a novel solution approach for solving our formulation at scale, based on Benders decomposition, which exploits the surprising fact that Benders cuts for both the relaxation and the integer problem can be generated in a computationally efficient manner. We demonstrate the value of our formulation and Benders decomposition approach through two sets of experiments. In the first, we use synthetic instances to show that our formulation is computationally tractable and can be solved an order of magnitude faster for small- to medium-scale instances than the alternate, previously proposed formulations. In the second, we consider a previously studied product line design instance based on a real conjoint data set, involving over 3,000 candidate products and over 300 respondents. We show that this problem, which required a week of computation time to solve in prior work, is solved by our approach to full optimality in approximately 10 minutes.The e-companion is available at .},
journal = {Oper. Res.},
month = may,
pages = {651–670},
numpages = {20},
keywords = {Benders decomposition, mixed-integer optimization, first-choice models, product line design}
}

@inproceedings{10.1145/2020390.2020397,
author = {Krishnan, Sandeep and Strasburg, Chris and Lutz, Robyn R. and Go\v{s}eva-Popstojanova, Katerina},
title = {Are change metrics good predictors for an evolving software product line?},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020397},
doi = {10.1145/2020390.2020397},
abstract = {Background: Previous research on three years of early data for an Eclipse product identified some predictors of failure-prone files that work well for that data set. Additionally, Eclipse has been used to explore characteristics of product line software in previous research.Aims: To assess whether change metrics are good predictors of failure-prone files over time for the family of products in the evolving Eclipse product line.Method: We repeat, to the extent possible, the decision tree portion of the prior study to assess our ability to replicate the method, and then extend it by including four more recent years of data. We compare the most prominent predictors with the previous study's results. We then look at the data for three additional Eclipse products as they evolved over time. We explore whether the set of good predictors change over time for one product and whether the set differs among products.Results: We find that change metrics are consistently good and incrementally better predictors across the evolving products in Eclipse. There is also some consistency regarding which change metrics are the best predictors.Conclusion: Change metrics are good predictors for failure-prone files for the Eclipse product line. A small subset of these change metrics is fairly stable and consistent across products and releases.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {7},
numpages = {10},
keywords = {change metrics, failure-prone files, post-release defects, prediction, reuse, software product lines},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/3447548.3470804,
author = {Wang, Xin and Zhu, Wenwu},
title = {Automated Machine Learning on Graph},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470804},
doi = {10.1145/3447548.3470804},
abstract = {Machine learning on graphs has been extensively studiedin both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attentions from the research community. In this tutorial, we discuss AutoML on graphs, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. To the best of our knowledge, this tutorial is the first to systematically and comprehensively review automated machine learning on graphs, possessing a great potential to draw a large amount of interests in the community.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4082–4083},
numpages = {2},
keywords = {graph representation learning, automl},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1007/978-3-031-08421-8_41,
author = {Giorgio, Lazzarinetti and Nicola, Massarenti and Fabio, Sgr\`{o} and Andrea, Salafia},
title = {Continuous Defect Prediction in CI/CD Pipelines: A Machine Learning-Based Framework},
year = {2021},
isbn = {978-3-031-08420-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08421-8_41},
doi = {10.1007/978-3-031-08421-8_41},
abstract = {Recent advances in information technology has led to an increasing number of applications to be developed and maintained daily by product teams. Ensuring that a software application works as expected and that it is absent of bugs requires a lot of time and resources. Thanks to the recent adoption of DevOps methodologies, it is often the case where code commits and application builds are centralized and standardized. Thanks to this new approach, it is now possible to retrieve log and build data to ease the development and management operations of product teams. However, even if such approaches include code control to detect unit or integration errors, they do not check for the presence of logical bugs that can raise after code builds. For such reasons in this work we propose a framework for continuous defect prediction based on machine learning algorithms trained on a publicly available dataset. The framework is composed of a machine learning model for detecting the presence of logical bugs in code on the basis of the available data generated by DevOps tools and a dashboard to monitor the software projects status. We also describe the serverless architecture we designed for hosting the aforementioned framework.},
booktitle = {AIxIA 2021 – Advances in Artificial Intelligence: 20th International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1–3, 2021, Revised Selected Papers},
pages = {591–606},
numpages = {16},
keywords = {Continuous integration, DevOps, Machine learning, Continuous defect prediction}
}

@inproceedings{10.1145/3461002.3473070,
author = {Acher, Mathieu and Perrouin, Gilles and Cordy, Maxime},
title = {BURST: a benchmarking platform for uniform random sampling techniques},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473070},
doi = {10.1145/3461002.3473070},
abstract = {We present BURST, a benchmarking platform for uniform random sampling techniques. With BURST, researchers have a flexible, controlled environment in which they can evaluate the scalability and uniformity of their sampling. BURST comes with an extensive --- and extensible --- benchmark dataset comprising 128 feature models, including challenging, real-world models of the Linux kernel. BURST takes as inputs a sampling tool, a set of feature models and a sampling budget. It automatically translates any feature model of the set in DIMACS and invokes the sampling tool to generate the budgeted number of samples. To evaluate the scalability of the sampling tool, BURST measures the time the tool needs to produce the requested sample. To evaluate the uniformity of the produced sample, BURST integrates the state-of-the-art and proven statistical test Barbarik. We envision BURST to become the starting point of a standardisation initiative of sampling tool evaluation. Given the huge interest of research for sampling algorithms and tools, this initiative would have the potential to reach and crosscut multiple research communities including AI, ML, SAT and SPL.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {36–40},
numpages = {5},
keywords = {variability model, software product lines, sampling, configurable systems, benchmark, SAT},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3382025.3414967,
author = {Lima, Jackson A. Prado and Mendon\c{c}a, Willian D. F. and Vergilio, Silvia R. and Assun\c{c}\~{a}o, Wesley K. G.},
title = {Learning-based prioritization of test cases in continuous integration of highly-configurable software},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414967},
doi = {10.1145/3382025.3414967},
abstract = {Continuous Integration (CI) is a practice widely adopted in the industry to allow frequent integration of code changes. During the CI process, many test cases are executed multiple times a day, subject to time constraints. In this scenario, a learning-based approach, named COLEMAN, has been successfully applied. COLEMAN allows earlier execution of the most promising test cases to reveal faults. This approach considers CI particularities such as time budget and volatility of test cases, related to the fact that test cases can be added/removed along the CI cycles. In the CI of Highly Configuration System (HCS), many product variants must be tested, each one with different configuration options, but having test cases that are common to or reused from other variants. In this context, we found, by analogy, another particularity, the volatility of variants, that is, some variants can be included/discontinued along CI cycles. Considering this context, this work introduces two strategies for the application of COLEMAN in the CI of HCS: the Variant Test Set Strategy (VTS) that relies on the test set specific for each variant, and the Whole Test Set Strategy (WST) that prioritizes the test set composed by the union of the test cases of all variants. Both strategies are evaluated in a real-world HCS, considering three test budgets. The results show that the proposed strategies are applicable regarding the time spent for prioritization. They perform similarly regarding early fault detection, but WTS better mitigates the problem of beginning without knowledge, and is more suitable when a new variant to be tested is added.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {31},
numpages = {11},
keywords = {test case prioritization, software product line, family of products, continuous integration},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/2934466.2946047,
author = {Li, Li and Martinez, Jabier and Ziadi, Tewfik and Bissyand\'{e}, Tegawend\'{e} F. and Klein, Jacques and Traon, Yves Le},
title = {Mining families of android applications for extractive SPL adoption},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2946047},
doi = {10.1145/2934466.2946047},
abstract = {The myriads of smart phones around the globe gave rise to a vast proliferation of mobile applications. These applications target an increasing number of user profiles and tasks. In this context, Android is a leading technology for their development and on-line markets are the main means for their distribution. In this paper we motivate, from two perspectives, the mining of these markets with the objective to identify families of apps variants in the wild. The first perspective is related to research activities where building realistic case studies for evaluating extractive SPL adoption techniques are needed. The second is related to a large-scale, world-wide and time-aware study of reuse practice in an industry which is now flourishing among all others within the software engineering community. This study is relevant to assess potential for SPLE practices adoption. We present initial implementations of the mining process and we discuss analyses of variant families.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {271–275},
numpages = {5},
keywords = {software product line engineering, reverse engineering, mining software repositories, appvariants, android},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3382025.3414968,
author = {Li, Yang and Schulze, Sandro and Scherrebeck, Helene Hvidegaard and Fogdal, Thomas Sorensen},
title = {Automated extraction of domain knowledge in practice: the case of feature extraction from requirements at danfoss},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414968},
doi = {10.1145/3382025.3414968},
abstract = {Software product line supports structured reuse of software artifacts in order to realize the maintenance and evolution of the typically large number of variants, which promotes the industrialization of software development, especially for software-intensive products. However, for a legacy system, it is non-trivial to gain information about commonalities and differences of the variants. Meanwhile, software requirements specifications as the initial artifacts can be used to achieve this information to generate a domain model. Unfortunately, manually analyzing these requirements is time-consuming and inefficient. To address this problem, we explored the usage of feature extraction techniques to automatically extract domain knowledge from requirements to assist domain engineers. In detail, we applied Doc2Vec and a clustering algorithm to process the requirements for achieving the initial feature tree. Moreover, we utilized key words/phrases extraction techniques to provide key information to domain engineers for further analyzing the extraction results. In particular, we developed a GUI to support the extraction process. The empirical evaluation indicates that most of the extracted features and terms are beneficial to improve the process of feature extraction.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {4},
numpages = {11},
keywords = {software product lines, reverse engineering, requirement documents, feature extraction},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3383219.3383229,
author = {Li, Yang and Schulze, Sandro and Xu, Jiahua},
title = {Feature Terms Prediction: A Feasible Way to Indicate the Notion of Features in Software Product Line},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383229},
doi = {10.1145/3383219.3383229},
abstract = {In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way. Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature. Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature. Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis. In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms. To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset. Subsequently, we apply seven commonly used machine algorithms to train prediction models on the labeled dataset. We then use these prediction models to predict feature terms from the requirements belonging to the other two different domains. Our results show that (1) feature terms can be predicted with high accuracy of ≈ 90% within a domain (2) prediction across domains leads to a decreased but still good accuracy (≈ 80%), and (3) machine learning algorithms perform differently.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {90–99},
numpages = {10},
keywords = {Software Product Lines, Requirement Documents, Feature Terms Identification, Feature Extraction},
location = {Trondheim, Norway},
series = {EASE '20}
}

@book{10.5555/2911053,
author = {Mistrik, Ivan and Soley, Richard M. and Ali, Nour and Grundy, John and Tekinerdogan, Bedir},
title = {Software Quality Assurance: In Large Scale and Complex Software-intensive Systems},
year = {2015},
isbn = {0128023015},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Software Quality Assurance in Large Scale and Complex Software-intensive Systems presents novel and high-quality research related approaches that relate the quality of software architecture to system requirements, system architecture and enterprise-architecture, or software testing. Modern software has become complex and adaptable due to the emergence of globalization and new software technologies, devices and networks. These changes challenge both traditional software quality assurance techniques and software engineers to ensure software quality when building today (and tomorrows) adaptive, context-sensitive, and highly diverse applications. This edited volume presents state of the art techniques, methodologies, tools, best practices and guidelines for software quality assurance and offers guidance for future software engineering research and practice. Each contributed chapter considers the practical application of the topic through case studies, experiments, empirical validation, or systematic comparisons with other approaches already in practice. Topics of interest include, but are not limited, to: quality attributes of system/software architectures; aligning enterprise, system, and software architecture from the point of view of total quality; design decisions and their influence on the quality of system/software architecture; methods and processes for evaluating architecture quality; quality assessment of legacy systems and third party applications; lessons learned and empirical validation of theories and frameworks on architectural quality; empirical validation and testing for assessing architecture quality.Focused on quality assurance at all levels of software design and developmentCovers domain-specific software quality assurance issues e.g. for cloud, mobile, security, context-sensitive, mash-up and autonomic systemsExplains likely trade-offs from design decisions in the context of complex software system engineering and quality assuranceIncludes practical case studies of software quality assurance for complex, adaptive and context-critical systems}
}

@article{10.1016/j.future.2020.09.015,
author = {Falah, Ahmed and Pan, Lei and Huda, Shamsul and Pokhrel, Shiva Raj and Anwar, Adnan},
title = {Improving malicious PDF classifier with feature engineering: A data-driven approach},
year = {2021},
issue_date = {Feb 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {115},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2020.09.015},
doi = {10.1016/j.future.2020.09.015},
journal = {Future Gener. Comput. Syst.},
month = feb,
pages = {314–326},
numpages = {13},
keywords = {00-01, 99-00, Feature engineering, Feature aggregation, Machine learning, Malicious PDF, Malware analysis}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00014,
author = {Idowu, Samuel and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Asset management in machine learning: a survey},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00014},
doi = {10.1109/ICSE-SEIP52600.2021.00014},
abstract = {Machine Learning (ML) techniques are becoming essential components of many software systems today, causing an increasing need to adapt traditional software engineering practices and tools to the development of ML-based software systems. This need is especially pronounced due to the challenges associated with the large-scale development and deployment of ML systems. Among the most commonly reported challenges during the development, production, and operation of ML-based systems are experiment management, dependency management, monitoring, and logging of ML assets. In recent years, we have seen several efforts to address these challenges as witnessed by an increasing number of tools for tracking and managing ML experiments and their assets. To facilitate research and practice on engineering intelligent systems, it is essential to understand the nature of the current tool support for managing ML assets. What kind of support is provided? What asset types are tracked? What operations are offered to users for managing those assets? We discuss and position ML asset management as an important discipline that provides methods and tools for ML assets as structures and the ML development activities as their operations. We present a feature-based survey of 17 tools with ML asset management support identified in a systematic search. We overview these tools' features for managing the different types of assets used for engineering ML-based systems and performing experiments. We found that most of the asset management support depends on traditional version control systems, while only a few tools support an asset granularity level that differentiates between important ML assets, such as datasets and models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {51–60},
numpages = {10},
keywords = {machine learning, asset management, SE4AI},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1145/3418981.3418984,
author = {Nerurkar, Pranav and Busnel, Yann and Ludinard, Romaric and Shah, Kunjal and Bhirud, Sunil and Patel, Dhiren},
title = {Detecting Illicit Entities in Bitcoin using Supervised Learning of Ensemble Decision Trees},
year = {2020},
isbn = {9781450387705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3418981.3418984},
doi = {10.1145/3418981.3418984},
abstract = {Since its inception in 2009, Bitcoin has been mired in controversies for providing a haven for illegal activities. Several types of illicit users hide behind the blanket of anonymity. Uncovering these entities is key for forensic investigations. Current methods utilize machine learning for identifying these illicit entities. However, the existing approaches only focus on a limited category of illicit users. The current paper proposes to address the issue by implementing an ensemble of decision trees for supervised learning. More parameters allow the ensemble model to learn discriminating features that can categorize multiple groups of illicit users from licit users. To evaluate the model, a dataset of 2059 real-life entities on Bitcoin was extracted from the Blockchain. Nine features were engineered to train the model for segregating 28 different licit-illicit categories of users. The proposed model provided a reliable tool for forensic study. Empirical evaluation of the proposed model vis-a-vis three existing benchmark models was performed to highlight its efficacy. Experiments showed that the specificity and sensitivity of the proposed model were comparable to other models.},
booktitle = {Proceedings of the 10th International Conference on Information Communication and Management},
pages = {25–30},
numpages = {6},
keywords = {Supervised Learning, Fraud detection, Data Mining, Bitcoin},
location = {Paris, France},
series = {ICICM '20}
}

@inproceedings{10.1145/3463677.3463714,
author = {Young, Matthew and Himmelreich, Johannes and Honcharov, Danylo and Soundarajan, Sucheta},
title = {The Right Tool for The Job? Assessing the Use of Artificial Intelligence for Identifying Administrative Errors},
year = {2021},
isbn = {9781450384926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463677.3463714},
doi = {10.1145/3463677.3463714},
abstract = {This article explores the extent to which machine learning can be used to detect administrative errors. It concentrates on administrative errors in unemployment insurance (UI) decisions, which give rise to a public values conflict between efficiency and effectiveness. This conflict is first described and then highlighted in the history of the US UI regime. Machine learning may not only mitigate this conflict but it may also help to combat fraud and reduce the backlog of claims associated with economic crises such as the COVID-19 pandemic. The article uses data about improper UI payments throughout the US from 2002 through 2018 to analyze the accuracy of random forests and deep learning models. We find that a random forest model using gradient descent boosting is more accurate, along several measures, than every deep learning model tested. This finding could be explained by the goodness-of-fit between the machine learning method and the available data. Alternatively, deep learning performance could be attenuated by necessary limits to publicly-accessible claims data.},
booktitle = {Proceedings of the 22nd Annual International Conference on Digital Government Research},
pages = {15–26},
numpages = {12},
keywords = {AI, Administrative Errors, Public Administration, Social Policy, Unemployment Insurance},
location = {Omaha, NE, USA},
series = {dg.o '21}
}

@article{10.1016/j.jss.2018.05.069,
author = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
title = {Self-adaptation of service compositions through product line reconfiguration},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.05.069},
doi = {10.1016/j.jss.2018.05.069},
journal = {J. Syst. Softw.},
month = oct,
pages = {84–105},
numpages = {22},
keywords = {Self adaptation, Software product lines, Feature model, Service composition}
}

@inproceedings{10.1145/3307630.3342413,
author = {Arcaini, Paolo and Gargantini, Angelo and Radavelli, Marco},
title = {A Process for Fault-Driven Repair of Constraints Among Features},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342413},
doi = {10.1145/3307630.3342413},
abstract = {The variability of a Software Product Line is usually both described in the problem space (by using a variability model) and in the solution space (i.e., the system implementation). If the two spaces are not aligned, wrong decisions can be done regarding the system configuration. In this work, we consider the case in which the variability model is not aligned with the solution space, and we propose an approach to automatically repair (possibly) faulty constraints in variability models. The approach takes as input a variability model and a set of combinations of features that trigger conformance faults between the model and the real system, and produces the repaired set of constraints as output. The approach consists of three major phases. First, it generates a test suite and identifies the condition triggering the faults. Then, it modifies the constraints of the variability model according to the type of faults. Lastly, it uses a logic minimization method to simplify the modified constraints. We evaluate the process on variability models of 7 applications of various sizes. An empirical analysis on these models shows that our approach can effectively repair constraints among features in an automated way.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {73–81},
numpages = {9},
keywords = {variability model, system evolution, fault, automatic repair},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s10586-021-03313-4,
author = {Lin, Frank Yeong-Sung and Hsiao, Chiu-Han and Zhang, Si-Yuan and Rung, Yi-Ping and Chen, Yu-Xuan},
title = {Cross-device matching approaches: word embedding and supervised learning},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03313-4},
doi = {10.1007/s10586-021-03313-4},
abstract = {Due to the rapid development of diversified technology, people may use multiple electronic devices, such as personal computers, tablets, and smartphones, to connect to the Internet in their daily lives. Switching between devices enables a user to use e-commerce on various platforms. The complexity of consumer behavior is directly proportional to the number of involved devices. Additionally, since the personal privacy regulations nowadays are getting more strict, the user data on the Internet starts to be anonymous. Thus, determining how the devices are related is an indispensable step in achieving precision marketing or developing customized applications. In this research, the dataset provided by the CIKM Cup 2016 Challenge is used. The representation of a device is created by extracting features from browsing logs. The computation cost is reduced by filtering candidates of a target device instead of comparing them in pairs. Latent semantic indexing representations and techniques of supervised learning are used to accomplish filtering. Performing word embedding can turn literature semantic into vectors through an unsupervised neural ensemble. The addition of feature engineering on the input vectors of supervised classification can enhance the classifier’s discrimination. The classification is used to determine the probability of any two instances belonging to the same user. The significant benefit of the implementation is to form the sequences mentioned above by a cross-device linking mechanism to provide a baseline for aligning with the computation limitation and boosting the performance.},
journal = {Cluster Computing},
month = dec,
pages = {3043–3053},
numpages = {11},
keywords = {Supervised learning, Word embedding, Latent semantic indexing, Cross-device tracking}
}

@inproceedings{10.1145/3359992.3366641,
author = {Bhatia, Randeep and Benno, Steven and Esteban, Jairo and Lakshman, T. V. and Grogan, John},
title = {Unsupervised machine learning for network-centric anomaly detection in IoT},
year = {2019},
isbn = {9781450369992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359992.3366641},
doi = {10.1145/3359992.3366641},
abstract = {Industry 4.0 holds the promise of greater automation and productivity but also introduces new security risks to critical industrial control systems from unsecured devices and machines. Networks need to play a larger role in stopping attacks before they disrupt essential infrastructure as host-centric IT security solutions, such as anti-virus and software patching, have been ineffective in preventing IoT devices from getting compromised. We propose a network-centric, behavior-learning based, anomaly detection approach for securing such vulnerable environments. We demonstrate that the predictability of TCP traffic from IoT devices can be exploited to detect different types of DDoS attacks in real-time, using unsupervised machine learning (ML). From a small set of features, our ML classifier can separate normal and anomalous traffic. Our approach can be incorporated in a larger system for identifying compromised end-points despite IP spoofing, thus allowing the use of SDN-based mechanisms for blocking attack traffic close to the source. Compared to supervised ML methods, our unsupervised ML approaches are easier to instrument and are more effective in detecting new and unseen attacks.},
booktitle = {Proceedings of the 3rd ACM CoNEXT Workshop on Big DAta, Machine Learning and Artificial Intelligence for Data Communication Networks},
pages = {42–48},
numpages = {7},
keywords = {Unsupervised Learning, Networks, Machine Learning, IoT, DDoS, Anomaly Detection},
location = {Orlando, FL, USA},
series = {Big-DAMA '19}
}

@inproceedings{10.1007/978-3-030-02925-8_22,
author = {Zhang, Jianyu and Fogelman-Souli\'{e}, Fran\c{c}oise and Largeron, Christine},
title = {Towards Automatic Complex Feature Engineering},
year = {2018},
isbn = {978-3-030-02924-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-02925-8_22},
doi = {10.1007/978-3-030-02925-8_22},
abstract = {Feature engineering is one of the most difficult and time-consuming tasks in data mining projects, and requires strong expert knowledge. Existing feature engineering techniques tend to use limited numbers of simple feature transformation methods and validate on simple datasets (small volume, simple structure), obviously limiting the benefits of feature engineering. In this paper, we propose a general Automatic Feature Engineering Machine framework (AFEM for short), which defines families of complex features and introduces them one family at a time (block bottom-up). We show that this framework covers most of the existing features used in the literature and allows us to efficiently generate complex feature families: in particular, local time, social network and representation-based families for relational and graph datasets, as well as composition of features. We validate our approach on two large realistic competitions datasets and a recommendation system task with social network. In the first two tasks, AFEM automatically reached ranks 15 and 12 compared to human teams; in the last task, it achieved 1.5% regression error reduction, compared to best results in the literature. Furthermore, in the context of big data and web applications, by balancing computation time and number of features/performance, in one case, we could reduce 2/3 computation time with only 0.2% AUC performance loss. Our code is publicly available on GitHub ().},
booktitle = {Web Information Systems Engineering – WISE 2018: 19th International Conference, Dubai, United Arab Emirates, November 12-15, 2018, Proceedings, Part II},
pages = {312–322},
numpages = {11},
keywords = {Feature engineering, Machine learning for the web, Social network computing, Big data, Web application},
location = {Dubai, United Arab Emirates}
}

@inproceedings{10.1145/2362536.2362548,
author = {Soltani, Samaneh and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on functional and non-functional requirements},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362548},
doi = {10.1145/2362536.2362548},
abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {56–65},
numpages = {10},
keywords = {software product line engineering, planning techniques, feature model, configuration, artificial intelligence},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3428690.3429172,
author = {Khadivizand, Sam and Beheshti, Amin and Sobhanmanesh, Fariborz and Sheng, Quan Z. and Istanbouli, Elias and Wood, Steven and Pezaro, Damon},
title = {Towards intelligent feature engineering for risk-based customer segmentation in banking},
year = {2021},
isbn = {9781450389242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428690.3429172},
doi = {10.1145/3428690.3429172},
abstract = {Business Processes, i.e., a set of coordinated tasks and activities to achieve a business goal, and their continuous improvements are key to the operation of any organization. In banking, business processes are increasingly dynamic as various technologies have made dynamic processes more prevalent. For example, customer segmentation, i.e., the process of grouping related customers based on common activities and behaviors, could be a data-driven and knowledge-intensive process. In this paper, we present an intelligent data-driven pipeline composed of a set of processing elements to move customers' data from one system to another, transforming the data into the contextualized data and knowledge along the way. The goal is to present a novel intelligent customer segmentation process which automates the feature engineering, i.e., the process of using (banking) domain knowledge to extract features from raw data via data mining techniques, in the banking domain. We adopt a typical scenario for analyzing customer transaction records, to highlight how the presented approach can significantly improve the quality of risk-based customer segmentation in the absence of feature engineering.},
booktitle = {Proceedings of the 18th International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {74–83},
numpages = {10},
keywords = {risk-based customer segmentation, feature engineering, business process, banking processes},
location = {Chiang Mai, Thailand},
series = {MoMM '20}
}

@article{10.1016/j.cosrev.2021.100395,
author = {T.K., Balaji and Annavarapu, Chandra Sekhara Rao and Bablani, Annushree},
title = {Machine learning algorithms for social media analysis: A survey},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100395},
doi = {10.1016/j.cosrev.2021.100395},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {32},
keywords = {Applications of social media analysis, Social network analysis, Machine learning, Social Media}
}

@article{10.1007/s11063-020-10400-x,
author = {Kanjilal, Ria and Uysal, Ismail},
title = {The Future of Human Activity Recognition: Deep Learning or Feature Engineering?},
year = {2021},
issue_date = {Feb 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {1},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10400-x},
doi = {10.1007/s11063-020-10400-x},
abstract = {A significant gap exists in our knowledge of how domain-specific feature extraction compares to unsupervised feature learning in the latent space of a deep neural network for a range of temporal applications including human activity recognition (HAR). This paper aims to address this gap specifically for fall detection and motion recognition using acceleration data. To ensure reproducibility, we use a publicly available dataset, UniMiB-SHAR, with a well-established history in the HAR literature. We methodically analyze the performance of 64 different combinations of (i) learning representations (in the form of raw temporal data or extracted features), (ii) traditional and modern classifiers with different topologies on (iii) both binary (fall detection) and multi-class (daily activities of living) datasets. We report and discuss our findings and conclude that while feature engineering may still be competitive for HAR, trainable front-ends of modern deep learning algorithms can benefit from raw temporal data especially in large quantities. In fact, this paper claims state-of-the-art where we significantly outperform the most recent literature on this dataset in both activity recognition (88.41% vs. 98.02%) and fall detection (98.71% vs. 99.82%) using raw temporal input.},
journal = {Neural Process. Lett.},
month = feb,
pages = {561–579},
numpages = {19},
keywords = {One-dimensional convolutional neural network, Recurrent neural network-long short-term memory, Artificial neural network, Feature engineering, Deep learning, Healthcare, Human activity recognition}
}

@inproceedings{10.1145/3236405.3236426,
author = {Belarbi, Maouaheb},
title = {A methodological framework to enable the generation of code from DSML in SPL},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236426},
doi = {10.1145/3236405.3236426},
abstract = {Software Product Line has acquired a significant momentum at the end of the 1990ies since it allows the production of variable software systems corresponding to the same domain portfolio. The effectiveness of the derivation process depends on how well variability is defined and implemented which is a crucial topic area that was addressed among two essential trends: On the one hand, starting from Domain Specific Modelling Language to express domain requirements and automate the code generation with Model-Driven Engineering techniques and on the second hand, exploiting the soar of variability mechanisms.In this context, the current research presents a method that unifies the two aforementioned approaches to cover the overall strategies by defining a framework that allows a better code generation in terms of documentation, maintainability, rapidity,etc. The starting point is the usage of the Domain Specific Modelling Language to represent the stakeholders requirements. Then, the resulting meta-model will be converted into one our several Feature Diagrams on which variability mechanisms can be applied to generate all the family products.A preliminary experiment has been undertaken to design the methodology of the proposed software factory in a meta-model. The validation task was evaluated with an academic use case called HandiWeb developed to facilitate handicap persons access to the internet. The first results allow us to put the hand on the key challenges that must be resolved by the proposed methodology.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {64–71},
numpages = {8},
keywords = {variability, software factory, methodology, SPL, DSML},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/3461002.3473073,
author = {Pett, Tobias and Krieter, Sebastian and Th\"{u}m, Thomas and Lochau, Malte and Schaefer, Ina},
title = {AutoSMP: an evaluation platform for sampling algorithms},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473073},
doi = {10.1145/3461002.3473073},
abstract = {Testing configurable systems is a challenging task due to the combinatorial explosion problem. Sampling is a promising approach to reduce the testing effort for product-based systems by finding a small but still representative subset (i.e., a sample) of all configurations for testing. The quality of a generated sample wrt. evaluation criteria such as run time of sample generation, feature coverage, sample size, and sampling stability depends on the subject systems and the sampling algorithm. Choosing the right sampling algorithm for practical applications is challenging because each sampling algorithm fulfills the evaluation criteria to a different degree. Researchers keep developing new sampling algorithms with improved performance or unique properties to satisfy application-specific requirements. Comparing sampling algorithms is therefore a necessary task for researchers. However, this task needs a lot of effort because of missing accessibility of existing algorithm implementations and benchmarks. Our platform AutoSMP eases practitioners and researchers lifes by automatically executing sampling algorithms on predefined benchmarks and evaluating the sampling results wrt. specific user requirements. In this paper, we introduce the open-source application of AutoSMP and a set of predefined benchmarks as well as a set of T-wise sampling algorithms as examples.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {41–44},
numpages = {4},
keywords = {sampling evalutaion, sampling, product lines},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@inproceedings{10.1145/3487664.3487740,
author = {Rouhollahi, Zeinab and Beheshti, Amin and Mousaeirad, Salman and Goluguri, Srinivasa Reddy},
title = {Towards Proactive Financial Crime and Fraud Detectionthrough Artificial Intelligence and RegTech Technologies},
year = {2022},
isbn = {9781450395564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487664.3487740},
doi = {10.1145/3487664.3487740},
abstract = {Recently, financial institutes have been dealing with an increase in financial crimes. In this context, financial services firms started to improve their vigilance and use new technologies and approaches to identify and predict financial fraud and crime possibilities. This task is challenging as institutions need to upgrade their data and analytics capabilities to enable new technologies such as Artificial Intelligence (AI) to predict and detect financial crimes. In this paper, we put a step towards AI-enabled financial crime detection in general and money laundering detection in particular to address this challenge. We study and analyse the recent works done in financial crime detection and present a novel model to detect money laundering cases with minimum human intervention needs.},
booktitle = {The 23rd International Conference on Information Integration and Web Intelligence},
pages = {538–546},
numpages = {9},
keywords = {Financial Fraud Detection, Data Analysis, Classification, Anti Money Laundering, Anomaly Detection},
location = {Linz, Austria},
series = {iiWAS2021}
}

@inproceedings{10.1145/2815782.2815799,
author = {Schaefer, Ina and Seidl, Christoph and Cleophas, Loek and Watson, Bruce W.},
title = {SPLicing TABASCO: Custom-Tailored Software Product Line Variants from Taxonomy-Based Toolkits},
year = {2015},
isbn = {9781450336833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815782.2815799},
doi = {10.1145/2815782.2815799},
abstract = {Taxonomy-Based Software Construction (TABASCO) applies extensive domain analyses to create conceptual hierarchies of algorithmic domains. Those are used as basis for the implementation of software toolkits. The monolithic structure of TABASCO-based toolkits restricts their adoption on resource-constrained or special-purpose devices. In this paper, we address this problem by applying Software Product Line (SPL) techniques to TABASCO-based toolkits: We use software taxonomies as input to creating a conceptual representation of variability as feature models of an SPL. We apply the variability realization mechanism delta modeling to transform realization artifacts, such as source code, to only contain elements for a particular selection of features. Our method is suitable for proactive, reactive and extractive SPL development so that it supports a seamless adoption and evolution of an SPL approach for TABASCO-based toolkits. We demonstrate the feasibility of the method with three case studies by proactively, reactively and extractively transforming TABASCO-based toolkits to SPLs, which allow derivation of variants with custom-tailored functionality.},
booktitle = {Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists},
articleno = {34},
numpages = {10},
keywords = {Taxonomy-Based Software Construction (TABASCO) toolkit, Software Product Line (SPL) adoption},
location = {Stellenbosch, South Africa},
series = {SAICSIT '15}
}

@inproceedings{10.1007/978-3-030-79463-7_40,
author = {Odyurt, Uraz and Sapra, Dolly and Pimentel, Andy D.},
title = {The Choice of AI Matters: Alternative Machine Learning Approaches for CPS Anomalies},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_40},
doi = {10.1007/978-3-030-79463-7_40},
abstract = {We compare the pros and cons of two Artificial Intelligence (AI) solutions, addressing the anomaly detection and identification challenge in industrial Cyber-Physical Systems (CPS). We demonstrate how our current approach, Advanced DL, based on Convolutional Neural Networks (CNN) differs from a previous one, Classic ML. Though both workflows prove to result in highly accurate classification of anomalies, Classic ML is superior in this regard with 99.23% accuracy against 94.85%. This comes at a cost, as Classic ML requires total insight and expertise regarding the system under scrutiny and heavy amounts of feature engineering, while Advanced DL treats the data as a black box, minimising the effort. At the same time, we show that finding the best performing CNN model design is not trivial. We present a quantitative comparison of both workflows in terms of elapsed times for training, validation and preprocessing, alongside discussions on qualitative aspects. Such a comparison, involving analysis of workflows for the given use-case, is of independent interest. We find the choice of AI solution to be use-case dependent.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {474–484},
numpages = {11},
keywords = {Industrial cyber-physical systems, Anomaly identification, Behavioural passports, Convolutional neural network, Machine learning},
location = {Kuala Lumpur, Malaysia}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Quality assurance, Machine learning, Software testing, Software variability, Configurable system, Software product line}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {prediction, feature, defect, classification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@article{10.14778/3461535.3463474,
author = {Salazar, Ricardo and Neutatz, Felix and Abedjan, Ziawasch},
title = {Automated feature engineering for algorithmic fairness},
year = {2021},
issue_date = {May 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3461535.3463474},
doi = {10.14778/3461535.3463474},
abstract = {One of the fundamental problems of machine ethics is to avoid the perpetuation and amplification of discrimination through machine learning applications. In particular, it is desired to exclude the influence of attributes with sensitive information, such as gender or race, and other causally related attributes on the machine learning task. The state-of-the-art bias reduction algorithm Capuchin breaks the causality chain of such attributes by adding and removing tuples. However, this horizontal approach can be considered invasive because it changes the data distribution. A vertical approach would be to prune sensitive features entirely. While this would ensure fairness without tampering with the data, it could also hurt the machine learning accuracy. Therefore, we propose a novel multi-objective feature selection strategy that leverages feature construction to generate more features that lead to both high accuracy and fairness. On three well-known datasets, our system achieves higher accuracy than other fairness-aware approaches while maintaining similar or higher fairness.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {1694–1702},
numpages = {9}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using multi-objective search and machine learning to infer rules constraining product configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.},
journal = {Automated Software Engg.},
month = jun,
pages = {1–62},
numpages = {62},
keywords = {Interacting products, Machine learning, Multi-objective search, Rule mining, Configuration, Product line}
}

@article{10.1145/3478088,
author = {Islam, Md. Rabiul and Sakamoto, Shuji and Yamada, Yoshihiro and Vargo, Andrew W. and Iwata, Motoi and Iwamura, Masakazu and Kise, Koichi},
title = {Self-supervised Learning for Reading Activity Classification},
year = {2021},
issue_date = {Sept 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
url = {https://doi.org/10.1145/3478088},
doi = {10.1145/3478088},
abstract = {Reading analysis can relay information about user's confidence and habits and can be used to construct useful feedback. A lack of labeled data inhibits the effective application of fully-supervised Deep Learning (DL) for automatic reading analysis. We propose a Self-supervised Learning (SSL) method for reading analysis. Previously, SSL has been effective in physical human activity recognition (HAR) tasks, but it has not been applied to cognitive HAR tasks like reading. We first evaluate the proposed method on a four-class classification task on reading detection using electrooculography datasets, followed by an evaluation of a two-class classification task of confidence estimation on multiple-choice questions using eye-tracking datasets. Fully-supervised DL and support vector machines (SVMs) are used as comparisons for the proposed SSL method. The results show that the proposed SSL method is superior to the fully-supervised DL and SVM for both tasks, especially when training data is scarce. This result indicates the proposed method is the superior choice for reading analysis tasks. These results are important for informing the design of automatic reading analysis platforms.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {105},
numpages = {22},
keywords = {reading detection, reading analysis, fully-supervised deep learning, confidence estimation, Self-supervised learning}
}

@article{10.1007/s42979-019-0017-9,
author = {Masabo, Emmanuel and Kaawaase, Kyanda Swaib and Sansa-Otim, Julianne and Ngubiri, John and Hanyurwimfura, Damien},
title = {Improvement of Malware Classification Using Hybrid Feature Engineering},
year = {2019},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {1},
url = {https://doi.org/10.1007/s42979-019-0017-9},
doi = {10.1007/s42979-019-0017-9},
abstract = {Polymorphic malware has evolved as a major threat in Computer Systems. Their creation technology is constantly evolving using sophisticated tactics to create multiple instances of the existing ones. Current solutions are not yet able to sufficiently address this problem. They are mostly signature based; however, a changing malware means a changing signature. They, therefore, easily evade detection. Classifying them into their respective families is also hard, thus making elimination harder. In this paper, we propose a new feature engineering (NFE) approach for a better classification of polymorphic malware based on a hybrid of structural and behavioural features. We use accuracy, recall, precision, and F score to evaluate our approach. We achieve an improvement of 12% on accuracy between raw features and NFE features. We also demonstrated the robustness of NFE on feature selection as compared to other feature selection techniques.},
journal = {SN Comput. Sci.},
month = aug,
numpages = {14},
keywords = {Feature engineering, Machine learning, Polymorphic malware, Malware classification}
}

@inproceedings{10.1145/3461001.3471155,
author = {Martin, Hugo and Acher, Mathieu and Pereira, Juliana Alves and J\'{e}z\'{e}quel, Jean-Marc},
title = {A comparison of performance specialization learning for configurable systems},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471155},
doi = {10.1145/3461001.3471155},
abstract = {The specialization of the configuration space of a software system has been considered for targeting specific configuration profiles, usages, deployment scenarios, or hardware settings. The challenge is to find constraints among options' values that only retain configurations meeting a performance objective. Since the exponential nature of configurable systems makes a manual specialization unpractical, several approaches have considered its automation using machine learning, i.e., measuring a sample of configurations and then learning what options' values should be constrained. Even focusing on learning techniques based on decision trees for their built-in explainability, there is still a wide range of possible approaches that need to be evaluated, i.e., how accurate is the specialization with regards to sampling size, performance thresholds, and kinds of configurable systems. In this paper, we compare six learning techniques: three variants of decision trees (including a novel algorithm) with and without the use of model-based feature selection. We first perform a study on 8 configurable systems considered in previous related works and show that the accuracy reaches more than 90% and that feature selection can improve the results in the majority of cases. We then perform a study on the Linux kernel and show that these techniques performs as well as on the other systems. Overall, our results show that there is no one-size-fits-all learning variant (though high accuracy can be achieved): we present guidelines and discuss tradeoffs.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {46–57},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3461001.3471144,
author = {Uta, Mathias and Felfernig, Alexander and Le, Viet-Man and Popescu, Andrei and Tran, Thi Ngoc Trang and Helic, Denis},
title = {Evaluating recommender systems in feature model configuration},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471144},
doi = {10.1145/3461001.3471144},
abstract = {Configurators can be evaluated in various ways such as efficiency and completeness of solution search, optimality of the proposed solutions, usability of configurator user interfaces, and configuration consistency. Due to the increasing size and complexity of feature models, the integration of recommendation algorithms with feature model configurators becomes relevant. In this paper, we show how the output of a recommender system can be evaluated within the scope of feature model configuration scenarios. Overall, we argue that the discussed ways of measuring recommendation quality help developers to gain a broader view on evaluation techniques in constraint-based recommendation domains.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {58–63},
numpages = {6},
keywords = {recommender systems, feature models, evaluation, configuration},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1145/2000799.2000803,
author = {Dehlinger, Josh and Lutz, Robyn R.},
title = {Gaia-PL: A Product Line Engineering Approach for Efficiently Designing Multiagent Systems},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/2000799.2000803},
doi = {10.1145/2000799.2000803},
abstract = {Agent-oriented software engineering (AOSE) has provided powerful and natural, high-level abstractions in which software developers can understand, model and develop complex, distributed systems. Yet, the realization of AOSE partially depends on whether agent-based software systems can achieve reductions in development time and cost similar to other reuse-conscious development methods. Specifically, AOSE does not adequately address requirements specifications as reusable assets. Software product line engineering is a reuse technology that supports the systematic development of a set of similar software systems through understanding, controlling, and managing their common, core characteristics and their differing variation points. In this article, we present an extension to the Gaia AOSE methodology, named Gaia-PL (Gaia-Product Line), for agent-based distributed software systems that enables requirements specifications to be easily reused. We show how our methodology uses a product line perspective to promote reuse in agent-based software systems early in the development life cycle so that software assets can be reused throughout system development and evolution. We also present results from an application to show how Gaia-PL provided reuse that reduced the design and development effort for a large, multiagent system.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {17},
numpages = {27},
keywords = {software product line engineering, Agent-oriented software engineering}
}

@inproceedings{10.1007/978-3-030-66843-3_21,
author = {Booth, Thomas C. and Akpinar, Bernice and Roman, Andrei and Shuaib, Haris and Luis, Aysha and Chelliah, Alysha and Al Busaidi, Ayisha and Mirchandani, Ayesha and Alparslan, Burcu and Mansoor, Nina and Ashkan, Keyoumars and Ourselin, Sebastien and Modat, Marc},
title = {Machine Learning and Glioblastoma: Treatment Response Monitoring Biomarkers in 2021},
year = {2020},
isbn = {978-3-030-66842-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-66843-3_21},
doi = {10.1007/978-3-030-66843-3_21},
abstract = {The aim of the systematic review was to assess recently published studies on diagnostic test accuracy of glioblastoma treatment response monitoring biomarkers in adults, developed through machine learning (ML). Articles published 09/2018–09/2020 were searched for using MEDLINE, EMBASE, and the Cochrane Register. Included study participants were adult patients with high grade glioma who had undergone standard treatment (maximal resection, radiotherapy with concomitant and adjuvant temozolomide) and subsequently underwent follow-up imaging to determine treatment response status (specifically, distinguishing progression/recurrence from progression/recurrence mimics - the target condition). Risk of bias and applicability was assessed with QUADAS 2 methodology. Contingency tables were created for hold-out test sets and recall, specificity, precision, F1-score, balanced accuracy calculated. Fifteen studies were included with 1038 patients in training sets and 233 in test sets. To determine whether there was progression or a mimic, the reference standard combination of follow-up imaging and histopathology at re-operation was applied in 67% (10/15) of studies. External hold-out test sets were used in 27% (4/15) to give ranges of diagnostic accuracy measures: recall = 0.70–1.00; specificity = 0.67–0.90; precision = 0.78–0.88; F1 score = 0.74–0.94; balanced accuracy = 0.74–0.83; AUC = 0.80–0.85. The small numbers of patient included in studies, the high risk of bias and concerns of applicability in the study designs (particularly in relation to the reference standard and patient selection due to confounding), and the low level of evidence, suggest that limited conclusions can be drawn from the data. There is likely good diagnostic performance of machine learning models that use MRI features to distinguish between progression and mimics. The diagnostic performance of ML using implicit features did not appear to be superior to ML using explicit features. There are a range of ML-based solutions poised to become treatment response monitoring biomarkers for glioblastoma. To achieve this, the development and validation of ML models require large, well-annotated datasets where the potential for confounding in the study design has been carefully considered. Therefore, multidisciplinary efforts and multicentre collaborations are necessary.},
booktitle = {Machine Learning in Clinical Neuroimaging and Radiogenomics in Neuro-Oncology: Third International Workshop, MLCN 2020, and Second International Workshop, RNO-AI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings},
pages = {212–228},
numpages = {17},
keywords = {Biomarkers, Diagnostic monitoring, Machine learning, Neuro-oncology},
location = {Lima, Peru}
}

@inproceedings{10.1145/2791060.2791086,
author = {Martinez, Jabier and Ziadi, Tewfik and Bissyand\'{e}, Tegawend\'{e} F. and Klein, Jacques and Le Traon, Yves},
title = {Bottom-up adoption of software product lines: a generic and extensible approach},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791086},
doi = {10.1145/2791060.2791086},
abstract = {Although Software Product Lines are recurrently praised as an efficient paradigm for systematic reuse, practical adoption remains challenging. For bottom-up Software Product Line adoption, where a set of artefact variants already exists, practitioners lack end-to-end support for chaining (1) feature identification, (2) feature location, (3) feature constraints discovery, as well as (4) reengineering approaches. This challenge can be overcome if there exists a set of principles for building a framework to integrate various algorithms and to support different artefact types. In this paper, we propose the principles of such a framework and we provide insights on how it can be extended with adapters, algorithms and visualisations enabling their use in different scenarios. We describe its realization in BUT4Reuse (Bottom--Up Technologies for Reuse) and we assess its generic and extensible properties by implementing a variety of extensions. We further empirically assess the complexity of integration by reproducing case studies from the literature. Finally, we present an experiment where users realize a bottom-up Software Product Line adoption building on the case study of Eclipse variants.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {101–110},
numpages = {10},
keywords = {software product line engineering, reverse engineering, mining existing assets},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.cmpb.2021.106304,
author = {Olthof, A.W. and Shouche, P. and Fennema, E.M. and IJpma, F.F.A. and Koolstra, R.H.C. and Stirler, V.M.A. and van Ooijen, P.M.A. and Cornelissen, L.J.},
title = {Machine learning based natural language processing of radiology reports in orthopaedic trauma},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {208},
number = {C},
issn = {0169-2607},
url = {https://doi.org/10.1016/j.cmpb.2021.106304},
doi = {10.1016/j.cmpb.2021.106304},
journal = {Comput. Methods Prog. Biomed.},
month = sep,
numpages = {9},
keywords = {Orthopaedic trauma, Radiology, Informatics, Machine learning, Natural language processing, (MeSH)}
}

@inproceedings{10.1145/3447548.3467177,
author = {Hardt, Michaela and Chen, Xiaoguang and Cheng, Xiaoyi and Donini, Michele and Gelman, Jason and Gollaprolu, Satish and He, John and Larroy, Pedro and Liu, Xinyu and McCarthy, Nick and Rathi, Ashish and Rees, Scott and Siva, Ankit and Tsai, ErhYuan and Vasist, Keerthan and Yilmaz, Pinar and Zafar, Muhammad Bilal and Das, Sanjiv and Haas, Kevin and Hill, Tyler and Kenthapadi, Krishnaram},
title = {Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467177},
doi = {10.1145/3447548.3467177},
abstract = {Understanding the predictions made by machine learning (ML) models and their potential biases remains a challenging and labor-intensive task that depends on the application, the dataset, and the specific model. We present Amazon SageMaker Clarify, an explainability feature for Amazon SageMaker that launched in December 2020, providing insights into data and ML models by identifying biases and explaining predictions. It is deeply integrated into Amazon SageMaker, a fully managed service that enables data scientists and developers to build, train, and deploy ML models at any scale. Clarify supports bias detection and feature importance computation across the ML lifecycle, during data preparation, model evaluation, and post-deployment monitoring. We outline the desiderata derived from customer input, the modular architecture, and the methodology for bias and explanation computations. Further, we describe the technical challenges encountered and the tradeoffs we had to make. For illustration, we discuss two customer use cases. We present our deployment results including qualitative customer feedback and a quantitative evaluation. Finally, we summarize lessons learned, and discuss best practices for the successful adoption of fairness and explanation tools in practice.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2974–2983},
numpages = {10},
keywords = {machine learning, fairness, explainability},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1007/978-3-030-78292-4_19,
author = {Kent, Carmel and Chaudhry, Muhammad Ali and Cukurova, Mutlu and Bashir, Ibrahim and Pickard, Hannah and Jenkins, Chris and du Boulay, Benedict and Moeini, Anissa and Luckin, Rosemary},
title = {Machine Learning Models and Their Development Process as Learning Affordances for Humans},
year = {2021},
isbn = {978-3-030-78291-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78292-4_19},
doi = {10.1007/978-3-030-78292-4_19},
abstract = {This paper explores the relationship between unsupervised machine learning models, and the mental models of those who develop or use them. In particular, we consider unsupervised models, as well as the ‘organisational co-learning process’ that creates them, as learning affordances. The co-learning process involves inputs originating both from the human participants’ shared semantics, as well as from the data. By combining these, the process as well as the resulting computational models afford a newly shaped mental model, which is potentially more resistant to the biases of human mental models. We illustrate this organisational co-learning process with a case study involving unsupervised modelling via commonly used methods such as dimension reduction and clustering. Our case study describes how a trading and training company engaged in the co-learning process, and how its mental models of trading behavior were shaped (and afforded) by the resulting unsupervised machine learning model. The paper argues that this kind of co-learning process can play a significant role in human learning, by shaping and safeguarding participants’ mental models, precisely because the models are unsupervised, and thus potentially lead to learning from unexpected or inexplicit patterns.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part I},
pages = {228–240},
numpages = {13},
keywords = {Co-learning process, Unsupervised machine learning, Learners’ mental models},
location = {Utrecht, The Netherlands}
}

@inproceedings{10.1145/3468891.3468896,
author = {Xu, Chenghan},
title = {Image-based Candlestick Pattern Classification with Machine Learning},
year = {2021},
isbn = {9781450389402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468891.3468896},
doi = {10.1145/3468891.3468896},
abstract = {Financial markets, such as the stock market, bond market and foreign exchange market, are important channels for fund transfer. As a graphical analysis tool, candlestick charts use graphs to display the open, high, low, and close prices in a specific period. In the past, there have been attempts to identify the characteristics of candlesticks based on Gramian Angular Field (GAF) images, but they are not perfect. In this study, we implemented Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), AdaBoost, Random Forest (RF) and XGBoost models, we found that the use of deep learning models is not the best choice for the recognition of candlestick features based on GAF images. Comparing these models, MLP and CNN are better than AdaBoost and RF, but worse than XGBoost. Our results show that for the candlestick pattern classification problem based on GAF images, it is unnecessary to use complex CNNs and traditional machine learning models can also achieve satisfactory results with much less computation resources.},
booktitle = {Proceedings of the 2021 6th International Conference on Machine Learning Technologies},
pages = {26–33},
numpages = {8},
keywords = {Pattern Classification, Machine Learning, Deep Learning, Candlestick},
location = {Jeju Island, Republic of Korea},
series = {ICMLT '21}
}

@article{10.1007/s10845-020-01706-7,
author = {Cui, Lu-jun and Sun, Man-ying and Cao, Yan-long and Zhao, Qi-jian and Zeng, Wen-han and Guo, Shi-rui},
title = {A novel tolerance geometric method based on machine learning},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01706-7},
doi = {10.1007/s10845-020-01706-7},
abstract = {In most cases, designers must manually specify geometric tolerance types and values when designing mechanical products. For the same nominal geometry, different designers may specify different types and values of geometric tolerances. To reduce the uncertainty and realize the tolerance specification automatically, a tolerance specification method based on machine learning is proposed. The innovation of this paper is to find out the information that affects geometric tolerances selection and use machine learning methods to generate tolerance specifications. The realization of tolerance specifications is changed from rule-driven to data-driven. In this paper, feature engineering is performed on the data for the application scenarios of tolerance specifications, which improves the performance of the machine learning model. This approach firstly considers the past tolerance specification schemes as cases and sets up the cases to the tolerance specification database which contains information such as datum reference frame, positional relationship, spatial relationship, and product cost. Then perform feature engineering on the data and established machine learning algorithm to convert the tolerance specification problem into an optimization problem. Finally, a gear reducer as a case study is given to verify the method. The results are evaluated with three different machine learning evaluation indicators and made a comparison with the tolerance specification method in the industry. The final results show that the machine learning algorithm can automatically generate tolerance specifications, and after feature engineering, the accuracy of the tolerance specification results is improved.},
journal = {J. Intell. Manuf.},
month = mar,
pages = {799–821},
numpages = {23},
keywords = {Optimization problem, Feature engineering, Machine learning, Tolerance specification, Computer-aided tolerancing (CAT)}
}

@inproceedings{10.1145/3447654.3447659,
author = {Sneha, Monica and Arya, Arti and Agarwal, Pooja},
title = {Ransomware Detection techniques in the Dawn of Artificial Intelligence: A Survey},
year = {2021},
isbn = {9781450388566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447654.3447659},
doi = {10.1145/3447654.3447659},
abstract = {Ransomware is a class of malware that gains unauthorized admittance to organizational and personal assets and blocks their access to legitimate users and staff. It accomplishes this by encrypting the algorithms with a strong encryption technique. The Hacker demands a ransom to allow access to the asset and revert the control to the authorized organizations. Many individuals and Organizations have been victim to such Ransomware Attacks. With the mounting growth of technology, such attacks have increased exponentially and the need for adequate preventive techniques are also increasing. This paper reviews the current state-of-the-art Ransomware detection techniques implemented to resist such attacks. While most surveys focus on ransomware detection using Machine learning techniques, this survey concentrates on Ransomware techniques that apply the sub-domains of Artificial Intelligence. This paper reviews detection techniques that employ Machine Learning, Deep Learning and Natural Language Processing techniques, which are sub-fields of AI for ransomware detection. Though the reviewed works have good detection rates, a few open concerns are identified and discussed. The primary objective of the review is to highlight concerns of the proposed system that prevent it from becoming effective in real-time systems.},
booktitle = {Proceedings of the 2020 9th International Conference on Networks, Communication and Computing},
pages = {26–33},
numpages = {8},
keywords = {Ransomware Detection, Natural language processing, Machine Learning Techniques},
location = {Tokyo, Japan},
series = {ICNCC '20}
}

@article{10.1016/j.jnca.2020.102576,
author = {Gu, Rentao and Yang, Zeyuan and Ji, Yuefeng},
title = {Machine learning for intelligent optical networks: A comprehensive survey},
year = {2020},
issue_date = {May 2020},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {157},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2020.102576},
doi = {10.1016/j.jnca.2020.102576},
journal = {J. Netw. Comput. Appl.},
month = may,
numpages = {22},
keywords = {Reinforcement learning, Neural networks, Optical performance monitoring, Resource management, Machine learning, Optical networks}
}

@article{10.1007/s10489-020-02048-w,
author = {Nerurkar, Pranav and Bhirud, Sunil and Patel, Dhiren and Ludinard, Romaric and Busnel, Yann and Kumari, Saru},
title = {Supervised learning model for identifying illegal activities in Bitcoin},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {6},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02048-w},
doi = {10.1007/s10489-020-02048-w},
abstract = {Since its inception in 2009, Bitcoin is mired in controversies for providing a haven for illegal activities. Several types of illicit users hide behind the blanket of anonymity. Uncovering these entities is key for forensic investigations. Current methods utilize machine learning for identifying these illicit entities. However, the existing approaches only focus on a limited category of illicit users. The current paper proposes to address the issue by implementing an ensemble of decision trees for supervised learning. More parameters allow the ensemble model to learn discriminating features that can categorize multiple groups of illicit users from licit users. To evaluate the model, a dataset of 1216 real-life entities on Bitcoin was extracted from the Blockchain. Nine Features were engineered to train the model for segregating 16 different licit-illicit categories of users. The proposed model provided a reliable tool for forensic study. Empirical evaluation of the proposed model vis-a-vis three existing benchmark models was performed to highlight its efficacy. Experiments showed that the specificity and sensitivity of the proposed model were comparable to other models. Due to higher parameters of the ensemble tree model, the classification accuracy was 0.91, with 95% CI - 0.8727, 0.9477. This was better than SVM and Logistic Regression, the two popular models in the literature and comparable to the Random Forest and XGBOOST model. CPU and RAM utilization were also monitored to demonstrate the usefulness of the proposed work for real-world deployment. RAM utilization for the proposed model was higher by 30-45% compared to the other three models. Hence, the proposed model is resource-intensive as it has higher parameters than the other three models. Higher parameters also result in higher accuracy of predictions.},
journal = {Applied Intelligence},
month = jun,
pages = {3824–3843},
numpages = {20},
keywords = {Exploratory data analysis, Fraud detection, Bitcoin}
}

@inproceedings{10.1145/3307630.3342704,
author = {Ca\~{n}ete, Angel},
title = {Energy Efficient Assignment and Deployment of Tasks in Structurally Variable Infrastructures},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342704},
doi = {10.1145/3307630.3342704},
abstract = {The importance of cyber-physical systems is growing very fast, being part of the Internet of Things vision. These devices generate data that could collapse the network and can not be assumed by the cloud. New technologies like Mobile Cloud Computing and Mobile Edge Computing are taking importance as solution for this issue. The idea is offloading some tasks to devices situated closer to the user device, reducing network congestion and improving applications performance (e.g., in terms of latency and energy). However, the variability of the target devices' features and processing tasks' requirements is very diverse, being difficult to decide which device is more adequate to deploy and run such processing tasks. Once decided, task offloading used to be done manually. Then, it is necessary a method to automatize the task assignation and deployment process. In this thesis we propose to model the structural variability of the deployment infrastructure and applications using feature models, on the basis of a SPL engineering process. Combining SPL methodology with Edge Computing, the deployment of applications is addressed as the derivation of a product. The data of the valid configurations is used by a task assignment framework, which determines the optimal tasks offloading solution in different network devices, and the resources of them that should be assigned to each task/user. Our solution provides the most energy and latency efficient deployment solution, accomplishing the QoS requirements of the application in the process.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {222–229},
numpages = {8},
keywords = {software product line, optimisation, mobile edge computing, mobile cloud computing, latency, energy efficiency},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1007/978-3-030-55789-8_21,
author = {Schranz, Thomas and Schweiger, Gerald and Pabst, Siegfried and Wotawa, Franz},
title = {Machine Learning for Water Supply Supervision},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_21},
doi = {10.1007/978-3-030-55789-8_21},
abstract = {In an industrial setting water supply systems can be complex. Constructing physical models for fault diagnosis or prediction requires extensive knowledge about the system’s components and characteristics. Through advances in embedded computing, consumption meter data is often readily available. This data can be used to construct black box models that describe system behavior and highlight irregularities such as leakages. In this paper we discuss the application of artificial intelligence to the task of identifying irregular consumption patterns. We describe and evaluate data models based on neural networks and decision trees that were used for consumption prediction in buildings at the Graz University of Technology.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {238–249},
numpages = {12},
keywords = {Data science, Fault diagnosis, Machine learning},
location = {Kitakyushu, Japan}
}

@inproceedings{10.1007/978-3-030-70866-5_3,
author = {Mohammedi, El-Heithem and Lavinal, Emmanuel and Fleury, Guillaume},
title = {Configuration Faults Detection in IP Virtual Private Networks Based on Machine Learning},
year = {2020},
isbn = {978-3-030-70865-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-70866-5_3},
doi = {10.1007/978-3-030-70866-5_3},
abstract = {Network incidents are largely due to configuration errors, particularly within network service providers who manage large complex networks. Such providers offer virtual private networks to their customers to interconnect their remote sites and provide Internet access. The growing demand for virtual private networks leads service providers to search for novel scalable approaches to locate incidents arising from configuration faults. In this paper, we propose a machine learning approach that aims to locate customer connectivity issues coming from configurations errors, in a BGP/MPLS IP virtual private network architecture. We feed the learning model with valid and faulty configuration data and train it using three algorithms: decision tree, random forest and multi-layer perceptron. Since failures can occur on several routers, we consider the learning problem as a supervised multi-label classification problem, where each customer router is represented by a unique label. We carry out our experiments on three network sizes containing different types of configuration errors. Results show that multi-layer perceptron has a better accuracy in detecting faults than the other algorithms, making it a potential candidate to validate offline network configurations before online deployment.},
booktitle = {Machine Learning for Networking: Third International Conference, MLN 2020, Paris, France, November 24–26, 2020, Revised Selected Papers},
pages = {40–56},
numpages = {17},
keywords = {BGP/MPLS networks, Virtual private networks, Machine learning, Configuration faults detection},
location = {Paris, France}
}

@inproceedings{10.1145/3236405.3236427,
author = {Li, Yang},
title = {Feature and variability extraction from natural language software requirements specifications},
year = {2018},
isbn = {9781450359450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236405.3236427},
doi = {10.1145/3236405.3236427},
abstract = {Extracting feature and variability from requirement specifications is an indispensable activity to support systematic integration related single software systems into Software Product Line (SPL). Performing variability extraction is time-consuming and inefficient, since massive textual requirements need to be analyzed and classified. Despite the improvement of automatically features and relationships extraction techniques, existing approaches are not able to provide high accuracy and applicability in real-world scenarios. The aim of my doctoral research is to develop an automated technique for extracting features and variability which provides reliable solutions to simplify the work of domain analysis. I carefully analyzed the state of the art and identified main limitations so far: accuracy and automation. Based on these insights, I am developing a methodology to address this challenges by making use of advanced Natural Language Processing (NLP) and machine learning techniques. In addition, I plan to design reasonable case study to evaluate the proposed approaches and empirical study to investigate usability in practice.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 2},
pages = {72–78},
numpages = {7},
keywords = {variability extraction, software product lines, reverse engineering, requirement documents, feature identification},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1007/978-3-030-79457-6_52,
author = {Dedabrishvili, Mariam and Dundua, Besik and Mamaiashvili, Natia},
title = {Smartphone Sensor-Based Fall Detection Using Machine Learning Algorithms},
year = {2021},
isbn = {978-3-030-79456-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79457-6_52},
doi = {10.1007/978-3-030-79457-6_52},
abstract = {Human Activity Recognition and particularly detection of abnormal activities such as falls have become a point of interest to many researchers worldwide since falls are considered to be one of the leading causes of injury and death, especially in the elderly population. The prompt intervention of caregivers in critical situations can significantly improve the autonomy and well-being of individuals living alone and those who require remote monitoring. This paper presents a study of accelerometer and gyroscope data retrieved from smartphone embedded sensors, using iOS-based devices. In the project framework there was developed a mobile application for data collection with the following fall type and fall-like activities: Falling Right, Falling Left, Falling Forward, Falling Backward, Sitting Fast, and Jumping. The collected dataset has passed the preprocessing phase and afterward was classified using different Machine Learning algorithms, namely, by Decision Trees, Random Forest, Logistic Regression, k-Nearest Neighbour, XGBoost, LightGBM, and Pytorch Neural Network. Unlike other similar studies, during the experimental setting, volunteers were asked to have smartphones freely in their pockets without tightening and fixing them on the body. This natural way of keeping a mobile device is quite challenging in terms of noisiness however it is more comfortable to wearers and causes fewer constraints. The obtained results are promising that encourages us to continue working with the aim to reach sufficient accuracy along with building a real-time application for potential users.},
booktitle = {Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part I},
pages = {609–620},
numpages = {12},
keywords = {Mobile applications, Smartphone embedded sensors, Data classification, Data preprocessing, Fall detection},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1007/978-3-030-91608-4_26,
author = {Ferreira, Lu\'{\i}s and Pilastri, Andr\'{e} and Sousa, V\'{\i}tor and Romano, Filipe and Cortez, Paulo},
title = {Prediction of Maintenance Equipment Failures Using Automated Machine Learning},
year = {2021},
isbn = {978-3-030-91607-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91608-4_26},
doi = {10.1007/978-3-030-91608-4_26},
abstract = {Predictive maintenance is a key area that is benefiting from the Industry 4.0 advent. Recently, there have been several attempts to use Machine Learning (ML) in order to optimize the maintenance of equipments and their repairs, with most of these approaches assuming an expert-based ML modeling. In this paper, we explore an Automated Machine Learning (AutoML) approach to address a predictive maintenance task related to a Portuguese software company. Using recently collected data from one of the company clients, we firstly performed a benchmark comparison study that included four open-source modern AutoML technologies to predict the number of days until the next failure of an equipment and also determine if the equipments will fail in a fixed amount of days. Overall, the results were very close among all AutoML tools, with AutoGluon obtaining the best results for all ML tasks. Then, the best AutoML predictive results were compared with a manual ML modeling approach that used the same dataset. The results achieved by the AutoML approach outperformed the manual method, thus demonstrating the quality of the automated modeling for the predictive maintenance domain.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2021: 22nd International Conference, IDEAL 2021, Manchester, UK, November 25–27, 2021, Proceedings},
pages = {259–267},
numpages = {9},
keywords = {Automated machine learning, Predictive maintenance, Supervised learning},
location = {Manchester, United Kingdom}
}

@article{10.1147/JRD.2019.2900638,
author = {Dillenberger, D. N. and Novotny, P. and Zhang, Q. and Jayachandran, P. and Gupta, H. and Hans, S. and Verma, D. and Chakraborty, S. and Thomas, J. J. and Walli, M. M. and Vaculin, R. and Sarpatwar, K.},
title = {Blockchain analytics and artificial intelligence},
year = {2019},
issue_date = {March/May 2019},
publisher = {IBM Corp.},
address = {USA},
volume = {63},
number = {2–3},
issn = {0018-8646},
url = {https://doi.org/10.1147/JRD.2019.2900638},
doi = {10.1147/JRD.2019.2900638},
abstract = {Blockchain records track information about financial payments, movements of products through supply chains, identity verification information, and many other assets. Analytics on this data can provide provenance histories, predictive planning, fraud identification, and regulatory compliance. In this paper, we describe analytics engines connected to blockchains to provide easy-touse configurable dashboards, predictive models, provenance histories, and compliance checking. We also describe how blockchain data can be combined with external data sources for secure and private analytics, enable artificial intelligence (AI) model creation over geographically dispersed data, and create a history of model creation enabling provenance and lineage tracking for trusted AI.},
journal = {IBM J. Res. Dev.},
month = mar,
articleno = {6},
numpages = {14}
}

@article{10.1504/ijhpsa.2021.121025,
author = {Xie, Linjiang and Hang, Feilu and Guo, Wei and Lv, Yao and Ou, Wei and Shibly, F.H.A.},
title = {Network security defence system based on artificial intelligence and big data technology},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {3–4},
issn = {1751-6528},
url = {https://doi.org/10.1504/ijhpsa.2021.121025},
doi = {10.1504/ijhpsa.2021.121025},
abstract = {Communication network security is a defence against unwanted system modifications to access files and folders within a computer network. The increasing overlap between the physical and virtual realms of improved communication poses a problem of cybersecurity. In this research, the big data analytics-based security system (BDASS) has been proposed to improve the communication network's security defence system with artificial intelligence (AI). The big data sets representing multiple categories of data are used in big data analysis methods. AI offers algorithms that can think or learn and strengthen their behaviour. Automated systems currently are built on syntactic rules that are not necessarily sufficiently sophisticated to handle the degree of difficulty in the communication network system. The BDASS model achieves a less computation time ratio of 21.3%, misbehaviour detection ratio of 97.5%, attack prediction accuracy ratio of 95.6%, possibility ratio of 96.4%, and success rate of 98.7% compared to other methods.},
journal = {Int. J. High Perform. Syst. Archit.},
month = jan,
pages = {140–151},
numpages = {11},
keywords = {cyber security, communication network security, big data analytics based security system, BDASS, big data analytics, artificial intelligence}
}

@article{10.1016/j.compbiolchem.2021.107529,
author = {Druchok, Maksym and Yarish, Dzvenymyra and Garkot, Sofiya and Nikolaienko, Tymofii and Gurbych, Oleksandr},
title = {Ensembling machine learning models to boost molecular affinity prediction},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {93},
number = {C},
issn = {1476-9271},
url = {https://doi.org/10.1016/j.compbiolchem.2021.107529},
doi = {10.1016/j.compbiolchem.2021.107529},
journal = {Comput. Biol. Chem.},
month = aug,
numpages = {11},
keywords = {Deep neural networks, Machine learning, Ensembled prediction, Human thrombin, Binding affinity}
}

@article{10.1287/opre.2016.1546,
author = {Bertsimas, Dimitris and Mi\v{s}i\'{c}, Velibor V.},
title = {Robust Product Line Design},
year = {2017},
issue_date = {January-February 2017},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {65},
number = {1},
issn = {0030-364X},
url = {https://doi.org/10.1287/opre.2016.1546},
doi = {10.1287/opre.2016.1546},
abstract = {The majority of approaches to product line design that have been proposed by marketing scientists assume that the underlying choice model that describes how the customer population will respond to a new product line is known precisely. In reality, however, marketers do not precisely know how the customer population will respond and can only obtain an estimate of the choice model from limited conjoint data. In this paper, we propose a new type of optimization approach for product line design under uncertainty. Our approach is based on the paradigm of robust optimization where, rather than optimizing the expected revenue with respect to a single model, one optimizes the worst-case expected revenue with respect to an uncertainty set of models. This framework allows us to account for parameter uncertainty, when we may be confident about the type of model structure but not about the values of the parameters, and structural uncertainty, when we may not even be confident about the right model structure to use to describe the customer population. Through computational experiments with a real conjoint data set, we demonstrate the benefits of our approach in addressing parameter and structural uncertainty. With regard to parameter uncertainty, we show that product lines designed without accounting for parameter uncertainty are fragile and can experience worst-case revenue losses as high as 23%, and that the robust product line can significantly outperform the nominal product line in the worst case, with relative improvements of up to 14%. With regard to structural uncertainty, we similarly show that product lines that are designed for a single model structure can be highly suboptimal under other structures (worst-case losses of up to 37%), while a product line that optimizes against the worst of a set of structurally distinct models can outperform single model product lines by as much as 55% in the worst case and can guarantee good aggregate performance over structurally distinct models.},
journal = {Oper. Res.},
month = feb,
pages = {19–37},
numpages = {19},
keywords = {model uncertainty, structural uncertainty, parameter uncertainty, robust optimization, product line design}
}

@inproceedings{10.1109/AST.2017.7,
author = {Al-Hajjaji, Mustafa and Kr\"{u}ger, Jacob and Schulze, Sandro and Leich, Thomas and Saake, Gunter},
title = {Efficient product-line testing using cluster-based product prioritization},
year = {2017},
isbn = {9781538615485},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2017.7},
doi = {10.1109/AST.2017.7},
abstract = {A software product-line comprises a set of products that share a common set of features. These features can be reused to customize a product to satisfy specific needs of certain customers or markets. As the number of possible products increases exponentially for new features, testing all products is infeasible. Existing testing approaches reduce their effort by restricting the number of products (sampling) and improve their effectiveness by considering the order of tests (prioritization). In this paper, we propose a cluster-based prioritization technique to sample similar products with respect to the feature selection. We evaluate our approach using feature models of different sizes and show that cluster-based prioritization can enhance the effectiveness of product-line testing.},
booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
pages = {16–22},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {AST '17}
}

@article{10.1007/s10618-021-00748-6,
author = {Hu, Yifan and Hu, Changwei and Tran, Thanh and Kasturi, Tejaswi and Joseph, Elizabeth and Gillingham, Matt},
title = {What’s in a name? – gender classification of names with character based machine learning models},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {35},
number = {4},
issn = {1384-5810},
url = {https://doi.org/10.1007/s10618-021-00748-6},
doi = {10.1007/s10618-021-00748-6},
abstract = {Gender information is no longer a mandatory input when registering for an account at many leading Internet companies. However, prediction of demographic information such as gender and age remains an important task, especially in intervention of unintentional gender/age bias in recommender systems. Therefore it is necessary to infer the gender of those users who did not to provide this information during registration. We consider the problem of predicting the gender of registered users based on their declared name. By analyzing the first names of 100M+ users, we found that genders can be very effectively classified using the composition of the name strings. We propose a number of character based machine learning models, and demonstrate that our models are able to infer the gender of users with much higher accuracy than baseline models. Moreover, we show that using the last names in addition to the first names improves classification performance further.},
journal = {Data Min. Knowl. Discov.},
month = jul,
pages = {1537–1563},
numpages = {27},
keywords = {Gender, Demography, Character-based machine learning model, Neural network, Natural language processing}
}

@article{10.4018/IJWSR.2019010103,
author = {Sun, Chang-ai and Wang, Zhen and Wang, Ke and Xue, Tieheng and Aiello, Marco},
title = {Adaptive BPEL Service Compositions via Variability Management: A Methodology and Supporting Platform},
year = {2019},
issue_date = {January 2019},
publisher = {IGI Global},
address = {USA},
volume = {16},
number = {1},
issn = {1545-7362},
url = {https://doi.org/10.4018/IJWSR.2019010103},
doi = {10.4018/IJWSR.2019010103},
abstract = {Service-Oriented Architectures are a popular development paradigm to enable distributed applications constructed from independent web services. When coordinated, web services are an infrastructure to fulfill dynamic and vertical integration of business. They may face frequent changes of both requirements and execution environments. Static and predefined service compositions using business process execution language BPEL are not able to cater for such rapid and unpredictable context shifts. The authors propose a variability management-based adaptive and configurable service composition approach that treats changes as first-class citizens and consists of identifying, expressing, realizing, and managing changes of service compositions. The proposed approach is realized with a language called VxBPEL to support variability in service compositions and a platform for design, execution, analysis, and maintenance of VxBPEL-based service compositions. Four case studies validate the feasibility of the proposed approach while exhibiting good performance of the supporting platform.},
journal = {Int. J. Web Serv. Res.},
month = jan,
pages = {37–69},
numpages = {33},
keywords = {Variability Management, Service Oriented Architectures, Service Composition, Business Process Execution Language, Adaptive Systems}
}

@inproceedings{10.1145/3447548.3467088,
author = {Luo, Zhipeng and He, Zhixing and Wang, Jin and Dong, Manqing and Huang, Jianqiang and Chen, Mingjian and Zheng, Bohang},
title = {AutoSmart: An Efficient and Automatic Machine Learning Framework for Temporal Relational Data},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467088},
doi = {10.1145/3447548.3467088},
abstract = {Temporal relational data, perhaps the most commonly used data type in industrial machine learning applications, needs labor-intensive feature engineering and data analyzing for giving precise model predictions. An automatic machine learning framework is needed to ease the manual efforts in fine-tuning the models so that the experts can focus more on other problems that really need humans' engagement such as problem definition, deployment, and business services. However, there are three main challenges for building automatic solutions for temporal relational data: 1) how to effectively and automatically mining useful information from the multiple tables and the relations from them? 2) how to be self-adjustable to control the time and memory consumption within a certain budget? and 3) how to give generic solutions to a wide range of tasks? In this work, we propose our solution that successfully addresses the above issues in an end-to-end automatic way. The proposed framework, AutoSmart, is the winning solution to the KDD Cup 2019 of the AutoML Track, which is one of the largest AutoML competition to date (860 teams with around 4,955 submissions). The framework includes automatic data processing, table merging, feature engineering, and model tuning, with a time and memory controller for efficiently and automatically formulating the models. The proposed framework outperforms the baseline solution significantly on several datasets in various domains.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3976–3984},
numpages = {9},
keywords = {temporal data, relational data, AutoML},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1016/j.aei.2019.101013,
author = {Bilal, Muhammad and Oyedele, Lukumon O.},
title = {Guidelines for applied machine learning in construction industry—A case of profit margins estimation},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.101013},
doi = {10.1016/j.aei.2019.101013},
journal = {Adv. Eng. Inform.},
month = jan,
numpages = {17},
keywords = {Predictive modelling, Interpretable machine learning, Construction simulation tool, Profit margin forecasting, Applied machine learning}
}

@article{10.1016/j.cl.2018.01.003,
author = {Pereira, Juliana Alves and Matuszyk, Pawel and Krieter, Sebastian and Spiliopoulou, Myra and Saake, Gunter},
title = {Personalized recommender systems for product-line configuration processes},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {54},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2018.01.003},
doi = {10.1016/j.cl.2018.01.003},
journal = {Comput. Lang. Syst. Struct.},
month = dec,
pages = {451–471},
numpages = {21},
keywords = {Personalized recommendations, Recommender systems, Product-line configuration, Feature model, Product lines}
}

@article{10.1145/3453444,
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
title = {Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453444},
doi = {10.1145/3453444},
abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML, i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {111},
numpages = {39},
keywords = {safety-critical systems, machine learning workflow, assurance evidence, assurance, Machine learning lifecycle}
}

@inproceedings{10.1145/3409334.3452064,
author = {Stephanos, Dembe Koi and Husari, Ghaith and Bennett, Brian T. and Stephanos, Emma},
title = {Machine learning predictive analytics for player movement prediction in NBA: applications, opportunities, and challenges},
year = {2021},
isbn = {9781450380683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409334.3452064},
doi = {10.1145/3409334.3452064},
abstract = {Recently, strategies of National Basketball Association (NBA) teams have evolved with the skillsets of players and the emergence of advanced analytics. This has led to a more free-flowing game in which traditional positions and play calls have been replaced with player archetypes and read-and-react offensives that operate off a variety of isolated actions. The introduction of position tracking technology by SportVU has aided the analysis of these patterns by offering a vast dataset of on-court behavior. There have been numerous attempts to identify and classify patterns by evaluating the outcomes of offensive and defensive strategies associated with actions within this dataset, a job currently done manually by reviewing game tape. Some of these classification attempts have used supervised techniques that begin with labeled sets of plays and feature sets to automate the detection of future cases. Increasingly, however, deep learning approaches such as convolutional neural networks have been used in conjunction with player trajectory images generated from positional data. This enables classification to occur in a bottom-up manner, potentially discerning unexpected patterns. Others have shifted focus from classification, instead using this positional data to evaluate the success of a given possession based on spatial factors such as defender proximity and player factors such as role or skillset. While play/action detection, classification and analysis have each been addressed in literature, a comprehensive approach that accounts for modern trends is still lacking. In this paper, we discuss various approaches to action detection and analysis and ultimately propose an outline for a deep learning approach of identification and analysis resulting in a queryable dataset complete with shot evaluations, thus combining multiple contributions into a serviceable tool capable of assisting and automating much of the work currently done by NBA professionals.},
booktitle = {Proceedings of the 2021 ACM Southeast Conference},
pages = {2–8},
numpages = {7},
keywords = {NBA video analysis, action recognition, clustering, data mining, machine learning, predictive analytics, survey},
location = {Virtual Event, USA},
series = {ACMSE '21}
}

@inproceedings{10.1145/3474717.3484253,
author = {Shi, Yunzhi and Biswas, Raj and Noori, Mehdi and Kilberry, Michael and Oram, John and Mays, Joe and Kharude, Sachin and Rao, Dinesh and Chen, Xin},
title = {Predicting Road Accident Risk Using Geospatial Data and Machine Learning (Demo Paper)},
year = {2021},
isbn = {9781450386647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474717.3484253},
doi = {10.1145/3474717.3484253},
abstract = {Over 100 fatalities and more than 8000 injuries are reported on average every day in the US caused by motor vehicle accidents. In order to provide drivers a safer travel plan, we present a machine learning powered risk profiler for road segments using geo-spatial data. We built an end-to-end pipeline to extract static road features from map data and combined them with other data such as weather and traffic patterns. Our approach proposes novel methods for data pre-processing and feature engineering using statistical and clustering methods. Our model achieves significant performance improvement for risk prediction using hyper-parameter optimization (HPO) and the open source AutoGluon library to optimize the ML model. Finally, an enduser visualization interface is developed in the form of interactive maps. The results indicate 31% improvement in model performance compared to baseline when model is applied to a new geo location. We tested this approach on six major cities in the US. The findings of this research will provide users a tool to quantitatively assess accident risk at road segment level.},
booktitle = {Proceedings of the 29th International Conference on Advances in Geographic Information Systems},
pages = {512–515},
numpages = {4},
keywords = {Traffic accidents, Prediction, Machine Learning, Classification},
location = {Beijing, China},
series = {SIGSPATIAL '21}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {machine learning, data leakage, data breach, advanced persistent threat, Data exfiltration}
}

@inproceedings{10.1109/MODELS-C.2019.00029,
author = {Pilarski, Sebastian and Staniszewski, Martin and Villeneuve, Frederic and Varro, Daniel},
title = {On artificial intelligence for simulation and design space exploration in gas turbine design},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00029},
doi = {10.1109/MODELS-C.2019.00029},
abstract = {Gas turbine design is a process that requires designing many interrelated subsystems, e.g., performance, secondary air system, air compression, or combustion. Subsystem models are created by various engineering design tools. During the design process there exists an extraordinary amount of generated data resulting from created models, simulation, and engine field tests. This data can be leveraged by artificial intelligence techniques such as machine learning to help accelerate the exploration of the large design spaces existing in the complex system of a gas engine.This paper presents a vision and road map of integrating such AIs and preliminary ideas on relevant AI models for such use cases. We explore increasing the realistic nature of existing simulations, approximating simulations to avoid excess computation, and cumulative effect modeling.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems Companion},
pages = {170–174},
numpages = {5},
keywords = {artificial intelligence, computational intelligence, computer aided engineering, intelligent systems, internal combustion engines, knowledge engineering, learning systems, machine learning, prediction methods},
location = {Munich, Germany},
series = {MODELS '19 Companion}
}

@article{10.1016/j.cmpb.2021.106329,
author = {Ventrella, Piervincenzo and Delgrossi, Giovanni and Ferrario, Gianmichele and Righetti, Marco and Masseroli, Marco},
title = {Supervised machine learning for the assessment of Chronic Kidney Disease advancement},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {209},
number = {C},
issn = {0169-2607},
url = {https://doi.org/10.1016/j.cmpb.2021.106329},
doi = {10.1016/j.cmpb.2021.106329},
journal = {Comput. Methods Prog. Biomed.},
month = sep,
numpages = {9},
keywords = {chronicity management, personalized care, predicting renal failure, supervised machine learning, Chronic Kidney Disease}
}

@article{10.1613/jair.1.11854,
author = {Z\"{o}ller, Marc-Andr\'{e} and Huber, Marco F.},
title = {Benchmark and Survey of Automated Machine Learning Frameworks},
year = {2021},
issue_date = {May 2021},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {70},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.11854},
doi = {10.1613/jair.1.11854},
abstract = {Machine learning (ML) has become a vital part in many aspects of our daily life. However, building well performing machine learning applications requires highly specialized data scientists and domain experts. Automated machine learning (AutoML) aims to reduce the demand for data scientists by enabling domain experts to build machine learning applications automatically without extensive knowledge of statistics and machine learning. This paper is a combination of a survey on current AutoML methods and a benchmark of popular AutoML frameworks on real data sets. Driven by the selected frameworks for evaluation, we summarize and review important AutoML techniques and methods concerning every step in building an ML pipeline. The selected AutoML frameworks are evaluated on 137 data sets from established AutoML benchmark suites.},
journal = {J. Artif. Int. Res.},
month = may,
pages = {409–472},
numpages = {64}
}

@inproceedings{10.1145/3233027.3233031,
author = {Kaindl, Hermann and Kramer, Stefan and Hoch, Ralph},
title = {An inductive learning perspective on automated generation of feature models from given product specifications},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233031},
doi = {10.1145/3233027.3233031},
abstract = {For explicit representation of commonality and variability of a product line, a feature model is mostly used. An open question is how a feature model can be inductively learned in an automated way from a limited number of given product specifications in terms of features.We propose to address this problem through machine learning, more precisely inductive generalization from examples. However, no counter-examples are assumed to exist. Basically, a feature model needs to be complete with respect to all the given example specifications. First results indicate the feasibility of this approach, even for generating hierarchies, but many open challenges remain.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {25–30},
numpages = {6},
keywords = {machine learning, inductive generalization from examples, generating feature models},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1007/978-3-030-86514-6_19,
author = {Theeuwes, Nikki and van Houtum, Geert-Jan and Zhang, Yingqian},
title = {Improving Ambulance Dispatching with Machine Learning and Simulation},
year = {2021},
isbn = {978-3-030-86513-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86514-6_19},
doi = {10.1007/978-3-030-86514-6_19},
abstract = {As an industry where performance improvements can save lives, but resources are often scarce, emergency medical services (EMS) providers continuously look for ways to deploy available resources more efficiently. In this paper, we report a case study executed at a Dutch EMS region to improve ambulance dispatching. We first capture the way in which dispatch human agents currently make decisions on which ambulance to dispatch to a request. We build a decision tree based on historical data to learn human agents’ dispatch decisions. Then, insights from the fitted decision tree are used to enrich the commonly assumed closest-idle dispatch policy. Subsequently, we use the captured dispatch policy as input to a discrete event simulation to investigate two enhancements to current practices and evaluate their performance relative to the current policy. Our results show that complementing the current dispatch policy with redispatching and reevaluation policies yields an improvement of the on-time performance of highly urgent ambulance requests of 0.77% points. The performance gain is significant, which is equivalent to adding additional seven weekly ambulance shifts.},
booktitle = {Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part IV},
pages = {302–318},
numpages = {17},
keywords = {Logistics, Discrete event simulation, Decision trees, Machine learning, Ambulance dispatching},
location = {Bilbao, Spain}
}

@inproceedings{10.1007/978-3-030-75765-6_4,
author = {Czekalski, Stanis\l{}aw and Morzy, Miko\l{}aj},
title = {Similarity Forests Revisited: A Swiss Army Knife for Machine Learning},
year = {2021},
isbn = {978-3-030-75764-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-75765-6_4},
doi = {10.1007/978-3-030-75765-6_4},
abstract = {Random Forests are one of the most reliable and robust general-purpose machine learning algorithms. They provide very competitive baselines for more complex algorithms. Recently, a new algorithm has been introduced into the family of decision tree learners – Similarity Forests, aiming at mitigating some of the well-known deficiencies of Random Forests. In this paper we extend the originally proposed Similarity Forests algorithm to one-class classification, multi-class classification, regression and metric learning tasks. We also introduce two new criteria for split evaluation in regression learning. The results of conducted experiments show that Similarity Forests can be a competitive alternative to Random Forests, in particular, when high quality data representation is difficult to obtain.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II},
pages = {42–53},
numpages = {12},
keywords = {Similarity forests, Random forests, Decision trees}
}

@inproceedings{10.1145/3461002.3473066,
author = {Fortz, Sophie},
title = {LIFTS: learning featured transition systems},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473066},
doi = {10.1145/3461002.3473066},
abstract = {This PhD project aims to automatically learn transition systems capturing the behaviour of a whole family of software-based systems. Reasoning at the family level yields important economies of scale and quality improvements for a broad range of systems such as software product lines, adaptive and configurable systems. Yet, to fully benefit from the above advantages, a model of the system family's behaviour is necessary. Such a model is often prohibitively expensive to create manually due to the number of variants. For large long-lived systems with outdated specifications or for systems that continuously adapt, the modelling cost is even higher. Therefore, this PhD proposes to automate the learning of such models from existing artefacts. To advance research at a fundamental level, our learning target are Featured Transition Systems (FTS), an abstract formalism that can be used to provide a pivot semantics to a range of variability-aware state-based modelling languages. The main research questions addressed by this PhD project are: (1) Can we learn variability-aware models efficiently? (2) Can we learn FTS in a black-box fashion? (i.e., with access to execution logs but not to source code); (3) Can we learn FTS in a white/grey-box testing fashion? (i.e., with access to source code); and (4) How do the proposed techniques scale in practice?},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {1–6},
numpages = {6},
keywords = {variability mining, software product lines, model learning, featured transition systems, active automata learning},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.advengsoft.2021.103029,
author = {Nagy, Enik\H{o} and Lovas, R\'{o}bert and Pintye, Istv\'{a}n and Hajnal, \'{A}kos and Kacsuk, P\'{e}ter},
title = {Cloud-agnostic architectures for machine learning based on Apache Spark},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {159},
number = {C},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2021.103029},
doi = {10.1016/j.advengsoft.2021.103029},
journal = {Adv. Eng. Softw.},
month = sep,
numpages = {9},
keywords = {Spark, Stream processing, Distributed computing, Orchestration, Cloud computing, Machine learning, Artificial intelligence, Big data, Reference architectures}
}

@article{10.1016/j.cosrev.2020.100341,
author = {Kotsiopoulos, Thanasis and Sarigiannidis, Panagiotis and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
title = {Machine Learning and Deep Learning in smart manufacturing: The Smart Grid paradigm},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100341},
doi = {10.1016/j.cosrev.2020.100341},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {25},
keywords = {Smart Grid, Industrial AI, Deep Learning, Machine Learning, Industry 4.0}
}

@article{10.3233/JIFS-202874,
author = {Pavan Kumar, C.S. and Dhinesh Babu, L.D.},
title = {Fuzzy based feature engineering architecture for sentiment analysis of medical discussion over online social networks},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202874},
doi = {10.3233/JIFS-202874},
abstract = {Sentiment analysis is widely used to retrieve the hidden sentiments in medical discussions over Online Social Networking platforms such as Twitter, Facebook, Instagram. People often tend to convey their feelings concerning their medical problems over social media platforms. Practitioners and health care workers have started to observe these discussions to assess the impact of health-related issues among the people. This helps in providing better care to improve the quality of life. Dementia is a serious disease in western countries like the United States of America and the United Kingdom, and the respective governments are providing facilities to the affected people. There is much chatter over social media platforms concerning the patients’ care, healthy measures to be followed to avoid disease, check early indications. These chatters have to be carefully monitored to help the officials take necessary precautions for the betterment of the affected. A novel Feature engineering architecture that involves feature-split for sentiment analysis of medical chatter over online social networks with the pipeline is proposed that can be used on any Machine Learning model. The proposed model used the fuzzy membership function in refining the outputs. The machine learning model has obtained sentiment score is subjected to fuzzification and defuzzification by using the trapezoid membership function and center of sums method, respectively. Three datasets are considered for comparison of the proposed and the regular model. The proposed approach delivered better results than the normal approach and is proved to be an effective approach for sentiment analysis of medical discussions over online social networks.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {11749–11761},
numpages = {13},
keywords = {trapezoid membership function, feature engineering, feature-split, FDA, machine learning, sentiment analysis, Dementia}
}

@inproceedings{10.1145/3369114.3369125,
author = {Cinar, Utku Kubilay},
title = {Combining Domain Knowledge &amp; Machine Learning: Making Predictions using Boosting Techniques},
year = {2020},
isbn = {9781450372534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369114.3369125},
doi = {10.1145/3369114.3369125},
abstract = {The latest hit on technology is the information and telecommunication novelties. Internet and big data are important source of information in order to understand this vast majority of the upcoming knowledge. Websites are progressively expanding and making it available to everyone who has access. Modern economic systems are built on data or knowledge. Thus, tech companies gather huge data and exercise their powers to digitalize the information to capture and utilize the knowledge within their reach. Information management enables firms to improve customer satisfaction, increase revenue, understand customer behavior, mitigate risk assessment, making a multidisciplinary approach. Another approach is to be able to identify business strategies. Information management researches (using machine learning algorithm) can help the field to discover what is significant on a customer behavior and reduce costs to its clients. Over the recent years, information management and machine learning algorithms are getting more and more close and on topic. Since, information management and machine learning intensely concerns with domain knowledge. Artificial Intelligence allows the machines to accumulate knowledge and adapts it. Information management and machine learning are affected by several factors such as business strategies, customer behavior, effectively using knowledge. Therefore, pulling only a single topic will not be enough to capture meaningful information from a huge chunk. Machine learning, and information systems also have the potential to help organizations in financial aspects. XG-Boost is one of the algorithms under the Decision-Trees equipped with boosting techniques similar to Microsoft's Light GBM algorithm. In recent years, XG-Boost algorithm has gained huge popularity due to its easy to use, speed, and performance. The aim of this paper is to show the use of the data in order to predict house prices XG-Boost algorithm and Neural Network model. The main goal here is to estimate the house prices using domain knowledge and machine learning algorithms. RMSE criteria was preferred. This paper suggests a generic way to gather knowledge on a very specific domain. Following the achieved result, the house price was estimated by processing the domain info through the machine learning algorithm here presented.},
booktitle = {Proceedings of the 3rd International Conference on Advances in Artificial Intelligence},
pages = {9–13},
numpages = {5},
keywords = {xgboost, machine learning, information, domain knowledge, capturing, AI solutions},
location = {Istanbul, Turkey},
series = {ICAAI '19}
}

@article{10.1109/TASLP.2021.3133189,
author = {Wu, Haibin and Li, Xu and Liu, Andy T. and Wu, Zhiyong and Meng, Helen and Lee, Hung-Yi},
title = {Improving the Adversarial Robustness for Speaker Verification by Self-Supervised Learning},
year = {2021},
issue_date = {2022},
publisher = {IEEE Press},
volume = {30},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2021.3133189},
doi = {10.1109/TASLP.2021.3133189},
abstract = {Previous works have shown that automatic speaker verification (ASV) is seriously vulnerable to malicious spoofing attacks, such as replay, synthetic speech, and recently emerged adversarial attacks. Great efforts have been dedicated to defending ASV against replay and synthetic speech; however, only a few approaches have been explored to deal with adversarial attacks. All the existing approaches to tackle adversarial attacks for ASV require the knowledge for adversarial samples generation, but it is impractical for defenders to know the exact attack algorithms that are applied by the in-the-wild attackers. This work is among the first to perform adversarial defense for ASV without knowing the specific attack algorithms. Inspired by self-supervised learning models (SSLMs) that possess the merits of alleviating the superficial noise in the inputs and reconstructing clean samples from the interrupted ones, this work regards adversarial perturbations as one kind of noise and conducts adversarial defense for ASV by SSLMs. Specifically, we propose to perform adversarial defense from two perspectives: 1) adversarial perturbation purification and 2) adversarial perturbation detection. The purification module aims at alleviating the adversarial perturbations in the samples and pulling the contaminated adversarial inputs back towards the decision boundary. Experimental results show that our proposed purification module effectively counters adversarial attacks and outperforms traditional filters from both alleviating the adversarial noise and maintaining the performance of genuine samples. The detection module aims at detecting adversarial samples from genuine ones based on the statistical properties of ASV scores derived by a unique ASV integrating with different number of SSLMs. Experimental results show that our detection module helps shield the ASV by detecting adversarial samples. Both purification and detection methods are helpful for defending against different kinds of attack algorithms. Moreover, since there is no common metric for evaluating the ASV performance under adversarial attacks, this work also formalizes evaluation metrics for adversarial defense considering both purification and detection based approaches into account. We sincerely encourage future works to benchmark their approaches based on the proposed evaluation framework.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = dec,
pages = {202–217},
numpages = {16}
}

@inproceedings{10.1145/3340435.3342718,
author = {Diosan, Laura and Motogna, Simona},
title = {Artificial intelligence meets software engineering in the classroom},
year = {2019},
isbn = {9781450368520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340435.3342718},
doi = {10.1145/3340435.3342718},
abstract = {We aimed to assess the reliability of teaching Artificial Intelligencefor Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements.We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence},
pages = {35–38},
numpages = {4},
keywords = {theory and algorithms for application domain, Software engineering education, Software creation},
location = {Tallinn, Estonia},
series = {EASEAI 2019}
}

@article{10.1016/j.ipm.2020.102206,
author = {Zhou, Sijia and Li, Xin},
title = {Feature engineering vs. deep learning for paper section identification: Toward applications in Chinese medical literature},
year = {2020},
issue_date = {May 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {57},
number = {3},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2020.102206},
doi = {10.1016/j.ipm.2020.102206},
journal = {Inf. Process. Manage.},
month = may,
numpages = {16},
keywords = {Chinese medicinal literature, Deep learning, Feature engineering, Section identification}
}

@inproceedings{10.1145/3351095.3375624,
author = {Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, Jos\'{e} M. F. and Eckersley, Peter},
title = {Explainable machine learning in deployment},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3375624},
doi = {10.1145/3351095.3375624},
abstract = {Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {648–657},
numpages = {10},
keywords = {deployed systems, explainability, machine learning, qualitative study, transparency},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@inproceedings{10.1145/3185089.3185117,
author = {Fahmy, Syahrul and Deraman, Aziz and Yahaya, Jamaiah H.},
title = {The Role of Human in Software Configuration Management},
year = {2018},
isbn = {9781450354141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185089.3185117},
doi = {10.1145/3185089.3185117},
abstract = {Two common problems in software development projects are falling behind schedule and software that does not fulfil its purpose. These problems can be attributed to on-going changes made to software products especially during development and maintenance, leading to more work than initially anticipated, diminishing quality as new changes are implemented. One approach for addressing these problems is through a systematic Software Configuration Management (SCM) process. However, after more than 50 years after its inception, these problems are still prevalent in software development, questioning the effectiveness of SCM implementation by software organizations. Although guided by international standards, industry best practices, and array of tools to support its implementation, the role of human has received little attention (if any), in mainstream SCM research, compared to other areas in software engineering. As such, this research project challenges the traditional view of SCM and puts forth a notion of People-Centric SCM, a holistic approach for managing changes to software products, focused on human rather than tools, and that is based on existing standards and best practices. The model and assessment framework were validated by means of Subject Matter Expert reviews and 5 case studies involving 9 software practitioners from the public sector, higher education institutions and the private sector in Malaysia, in addition to 2 international experts. Results of the validation demonstrated the soundness of the model, the plausibility of the assessment framework, and the practically of the People-Centric SCM approach to software organizations.},
booktitle = {Proceedings of the 2018 7th International Conference on Software and Computer Applications},
pages = {56–60},
numpages = {5},
keywords = {Software Quality, Software Engineering, Software Configuration Management},
location = {Kuantan, Malaysia},
series = {ICSCA '18}
}

@inbook{10.1145/3447404.3447414,
author = {Chatzilygeroudis, Konstantinos and Hatzilygeroudis, Ioannis and Perikos, Isidoros},
title = {Machine Learning Basics},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447414},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {143–193},
numpages = {51}
}

@inproceedings{10.1145/3437963.3441736,
author = {Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
title = {Theoretical Understandings of Product Embedding for E-commerce Machine Learning},
year = {2021},
isbn = {9781450382977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437963.3441736},
doi = {10.1145/3437963.3441736},
abstract = {Product embeddings have been heavily investigated in the past few years, serving as the cornerstone for a broad range of machine learning applications in e-commerce. Despite the empirical success of product embeddings, little is known on how and why they work from the theoretical standpoint. Analogous results from the natural language processing (NLP) often rely on domain-specific properties that are not transferable to the e-commerce setting, and the downstream tasks often focus on different aspects of the embeddings. We take an e-commerce-oriented view of the product embeddings and reveal a complete theoretical view from both the representation learning and the learning theory perspective. We prove that product embeddings trained by the widely-adopted skip-gram negative sampling algorithm and its variants are sufficient dimension reduction regarding a critical product relatedness measure. The generalization performance in the downstream machine learning task is controlled by the alignment between the embeddings and the product relatedness measure. Following the theoretical discoveries, we conduct exploratory experiments that supports our theoretical insights for the product embeddings.},
booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
pages = {256–264},
numpages = {9},
keywords = {sufficient dimension reduction, representation learning, product relation, machine learning theory, information theory},
location = {Virtual Event, Israel},
series = {WSDM '21}
}

@inproceedings{10.1145/3297280.3297586,
author = {Lucas, Yvan and Portier, Pierre-Edouard and Laporte, L\'{e}a and Calabretto, Sylvie and Caelen, Olivier and He-Guelton, Liyun and Granitzer, Michael},
title = {Multiple perspectives HMM-based feature engineering for credit card fraud detection},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297586},
doi = {10.1145/3297280.3297586},
abstract = {Machine learning and data mining techniques have been used extensively in order to detect credit card frauds. However, most studies consider credit card transactions as isolated events and not as a sequence of transactions.In this article, we model a sequence of credit card transactions from three different perspectives, namely (i) does the sequence contain a Fraud? (ii) Is the sequence obtained by fixing the card-holder or the payment terminal? (iii) Is it a sequence of spent amount or of elapsed time between the current and previous transactions? Combinations of the three binary perspectives give eight sets of sequences from the (training) set of transactions. Each one of these sets is modelled with a Hidden Markov Model (HMM). Each HMM associates a likelihood to a transaction given its sequence of previous transactions. These likelihoods are used as additional features in a Random Forest classifier for fraud detection. This multiple perspectives HMM-based approach enables an automatic feature engineering in order to model the sequential properties of the dataset with respect to the classification task. This strategy allows for a 15% increase in the precision-recall AUC compared to the state of the art feature engineering strategy for credit card fraud detection.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1359–1361},
numpages = {3},
keywords = {credit card fraud detection, hidden Markov models, machine learning, random forest, sequence classification},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@article{10.1155/2021/4907754,
author = {Kong, Zixiao and Xue, Jingfeng and Wang, Yong and Huang, Lu and Niu, Zequn and Li, Feng and Meng, Weizhi},
title = {A Survey on Adversarial Attack in the Age of Artificial Intelligence},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/4907754},
doi = {10.1155/2021/4907754},
abstract = {With the rapid evolution of the Internet, the application of artificial intelligence fields is more and more extensive, and the era of AI has come. At the same time, adversarial attacks in the AI field are also frequent. Therefore, the research into adversarial attack security is extremely urgent. An increasing number of researchers are working in this field. We provide a comprehensive review of the theories and methods that enable researchers to enter the field of adversarial attack. This article is according to the “Why? → What? → How?” research line for elaboration. Firstly, we explain the significance of adversarial attack. Then, we introduce the concepts, types, and hazards of adversarial attack. Finally, we review the typical attack algorithms and defense techniques in each application area. Facing the increasingly complex neural network model, this paper focuses on the fields of image, text, and malicious code and focuses on the adversarial attack classifications and methods of these three data types, so that researchers can quickly find their own type of study. At the end of this review, we also raised some discussions and open issues and compared them with other similar reviews.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {22}
}

@article{10.1016/j.eswa.2021.114897,
author = {Ochella, Sunday and Shafiee, Mahmood and Sansom, Chris},
title = {Adopting machine learning and condition monitoring P-F curves in determining and prioritizing high-value assets for life extension},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {176},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114897},
doi = {10.1016/j.eswa.2021.114897},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {17},
keywords = {Machine learning, Data mining, Potential failure interval factor, K-means clustering, Life-extension, Remaining useful life, Condition monitoring}
}

@inproceedings{10.1145/3422392.3422498,
author = {Freire, Willian Marques and Massago, Mamoru and Zavadski, Arthur Cattaneo and Malachini, Aline Maria and Amaral, Miotto and Colanzi, Thelma Elita},
title = {OPLA-Tool v2.0: a Tool for Product Line Architecture Design Optimization},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422498},
doi = {10.1145/3422392.3422498},
abstract = {The Multi-objective Optimization Approach for Product Line Architecture Design (MOA4PLA) is the seminal approach that successfully optimizes Product Line Architecture (PLA) design using search algorithms. The tool named OPLA-Tool was developed in order to automate the use of MOA4PLA. Over time, the customization of the tool to suit the needs of new research and application scenarios led to several problems. The main problems identified in the original version of OPLA-Tool are environment configuration, maintainability and usability problems, and PLA design modeling and visualization. Such problems motivated the development of a new version of this tool: OPLA-Tool v2.0, presented in this work. In this version, those problems were solved by the source code refactoring, migration to a web-based graphical user interface (GUI) and inclusion of a new support tool for PLA modeling and visualization. Furthermore, OPLA-Tool v2.0 has new functionalities, such as new objective functions, new search operators, intelligent interaction with users during the optimization process, multi-user authentication and simultaneous execution of several experiments to PLA optimization. Such a new version of OPLA-Tool is an important achievement to PLA design optimization as it provides an easier and more complete way to automate this task.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {818–823},
numpages = {6},
keywords = {Software product line, multi-objective evolutionary algorithms, product line architecture},
location = {Natal, Brazil},
series = {SBES '20}
}

@article{10.1007/s10462-020-09948-w,
author = {Injadat, MohammadNoor and Moubayed, Abdallah and Nassif, Ali Bou and Shami, Abdallah},
title = {Machine learning towards intelligent systems: applications, challenges, and opportunities},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09948-w},
doi = {10.1007/s10462-020-09948-w},
abstract = {The emergence and continued reliance on the Internet and related technologies has resulted in the generation of large amounts of data that can be made available for analyses. However, humans do not possess the cognitive capabilities to understand such large amounts of data. Machine learning (ML) provides a mechanism for humans to process large amounts of data, gain insights about the behavior of the data, and make more informed decision based on the resulting analysis. ML has applications in various fields. This review focuses on some of the fields and applications such as education, healthcare, network security, banking and finance, and social media. Within these fields, there are multiple unique challenges that exist. However, ML can provide solutions to these challenges, as well as create further research opportunities. Accordingly, this work surveys some of the challenges facing the aforementioned fields and presents some of the previous literature works that tackled them. Moreover, it suggests several research opportunities that benefit from the use of ML to address these challenges.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3299–3348},
numpages = {50},
keywords = {Research opportunities, Application fields, Data analytics, Machine learning}
}

@article{10.1016/j.infsof.2012.07.010,
author = {Buchmann, Thomas and Dotor, Alexander and Westfechtel, Bernhard},
title = {MOD2-SCM: A model-driven product line for software configuration management systems},
year = {2013},
issue_date = {March, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.07.010},
doi = {10.1016/j.infsof.2012.07.010},
abstract = {Context: Software Configuration Management (SCM) is the discipline of controlling the evolution of large and complex software systems. Over the years many different SCM systems sharing similar concepts have been implemented from scratch. Since these concepts usually are hard-wired into the respective program code, reuse is hardly possible. Objective: Our objective is to create a model-driven product line for SCM systems. By explicitly describing the different concepts using models, reuse can be performed on the modeling level. Since models are executable, the need for manual programming is eliminated. Furthermore, by providing a library of loosely coupled modules, we intend to support flexible composition of SCM systems. Method: We developed a method and a tool set for model-driven software product line engineering which we applied to the SCM domain. For domain analysis, we applied the FORM method, resulting in a layered feature model for SCM systems. Furthermore, we developed an executable object-oriented domain model which was annotated with features from the feature model. A specific SCM system is configured by selecting features from the feature model and elements of the domain model realizing these features. Results: Due to the orthogonality of both feature model and domain model, a very large number of SCM systems may be configured. We tested our approach by creating instances of the product line which mimic wide-spread systems such as CVS, GIT, Mercurial, and Subversion. Conclusion: The experiences gained from this project demonstrate the feasibility of our approach to model-driven software product line engineering. Furthermore, our work advances the state of the art in the domain of SCM systems since it support the modular composition of SCM systems at the model rather than the code level.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {630–650},
numpages = {21},
keywords = {Software product line engineering, Software configuration management, Model-driven software engineering, Model transformation, Feature models, Executable models, Code generation}
}

@inproceedings{10.1145/2791060.2791096,
author = {F\'{e}derle, \'{E}dipo Luis and do Nascimento Ferreira, Thiago and Colanzi, Thelma Elita and Vergilio, Silvia Regina},
title = {OPLA-tool: a support tool for search-based product line architecture design},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791096},
doi = {10.1145/2791060.2791096},
abstract = {The Product Line Architecture (PLA) design is a complex task, influenced by many factors such as feature modularization and PLA extensibility, which are usually evaluated according to different metrics. Hence, the PLA design is an optimization problem and problems like that have been successfully solved in the Search-Based Software Engineering (SBSE) area, by using metaheuristics such as Genetic Algorithm. Considering this fact, this paper introduces a tool named OPLA-Tool, conceived to provide computer support to a search-based approach for PLA design. OPLA-Tool implements all the steps necessary to use multi-objective optimization algorithms, including PLA transformations and visualization through a graphical interface. OPLA-Tool receives as input a PLA at the class diagram level, and produces a set of good alternative diagrams in terms of cohesion, feature modularization and reduction of crosscutting concerns.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {370–373},
numpages = {4},
keywords = {search-based software engineering, product line architecture design, multi-objective evolutionary algorithms},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1007/978-3-030-71158-0_14,
author = {Ferreira, Lu\'{\i}s and Pilastri, Andr\'{e} and Martins, Carlos and Santos, Pedro and Cortez, Paulo},
title = {A Scalable and Automated Machine Learning Framework to Support Risk Management},
year = {2020},
isbn = {978-3-030-71157-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-71158-0_14},
doi = {10.1007/978-3-030-71158-0_14},
abstract = {Due to the growth of data and widespread usage of Machine Learning (ML) by non-experts, automation and scalability are becoming key issues for ML. This paper presents an automated and scalable framework for ML that requires minimum human input. We designed the framework for the domain of telecommunications risk management. This domain often requires non-ML-experts to continuously update supervised learning models that are trained on huge amounts of data. Thus, the framework uses Automated Machine Learning (AutoML), to select and tune the ML models, and distributed ML, to deal with Big Data. The modules included in the framework are task detection (to detect classification or regression), data preprocessing, feature selection, model training, and deployment. In this paper, we focus the experiments on the model training module. We first analyze the capabilities of eight AutoML tools: Auto-Gluon, Auto-Keras, Auto-Sklearn, Auto-Weka, H2O AutoML, Rminer, TPOT, and TransmogrifAI. Then, to select the tool for model training, we performed a benchmark with the only two tools that address a distributed ML (H2O AutoML and TransmogrifAI). The experiments used three real-world datasets from the telecommunications domain (churn, event forecasting, and fraud detection), as provided by an analytics company. The experiments allowed us to measure the computational effort and predictive capability of the AutoML tools. Both tools obtained high-quality results and did not present substantial predictive differences. Nevertheless, H2O AutoML was selected by the analytics company for the model training module, since it was considered a more mature technology that presented a more interesting set of features (e.g., integration with more platforms). After choosing H2O AutoML for the ML training, we selected the technologies for the remaining components of the architecture (e.g., data preprocessing and web interface).},
booktitle = {Agents and Artificial Intelligence: 12th International Conference, ICAART 2020, Valletta, Malta, February 22–24, 2020, Revised Selected Papers},
pages = {291–307},
numpages = {17},
keywords = {Risk management, Supervised learning, Distributed machine learning, Automated machine learning},
location = {Valletta, Malta}
}

@article{10.1504/ijwgs.2021.118395,
author = {Mousavi, Mitra and Rezazadeh, Javad and Sianaki, Omid Ameri},
title = {Machine learning applications for fog computing in IoT: a survey},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1741-1106},
url = {https://doi.org/10.1504/ijwgs.2021.118395},
doi = {10.1504/ijwgs.2021.118395},
abstract = {Today, internet of things (IoT) has become an important paradigm. Everyday increasing number of IoT applications and services emerge. Smart devices connected by the IoT generate significant amounts of data. Analysis IoT sensor data using machine learning algorithms is a key to achieve useful information for prediction, classification, data association and data conceptualisation. Offloading input data to cloud servers leads to increased communication costs. Undertaking data analytics at the network edge using fog computing enables the rapid processing of incoming data for real-time response. In this paper, we examine the results of using different machine learning algorithms on fog nodes based on existing research. These results are low latency, high accuracy and low bandwidth. Also, this work presents the current fog computing architecture which consists of different layers that distribute computing, storage, control and networking and finally we investigate the challenges and open issues related to the deployment of machine learning on fog nodes.},
journal = {Int. J. Web Grid Serv.},
month = jan,
pages = {293–320},
numpages = {27},
keywords = {fog-based machine learning, machine learning, fog computing, IoT, internet of things}
}

@article{10.1145/3377869,
author = {Burton, Ren\'{e}e},
title = {Unsupervised Learning Techniques for Malware Characterization: Understanding Certain DNS-based DDoS Attacks},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
url = {https://doi.org/10.1145/3377869},
doi = {10.1145/3377869},
abstract = {This article details data science research in the area of Cyber Threat Intelligence applied to a specific type of Distributed Denial of Service (DDoS) attack. We study a DDoS technique prevalent in the Domain Name System (DNS) for which little malware have been recovered. Using data from a globally distributed set of a passive collectors (pDNS), we create a statistical classifier to identify these attacks and then use unsupervised learning to investigate the attack events and the malware that generates them. The first known major study of this technique, this work demonstrates that current attacks have little resemblance to earlier published descriptions and identifies several features of the attacks. Through a combination of text and time-series features, we are able to characterize the dominant malware and demonstrate that the number of global-scale attack systems is relatively small.},
journal = {Digital Threats},
month = aug,
articleno = {14},
numpages = {26},
keywords = {threat intelligence, malware, ddos attacks, data science, clustering, botnet, Domain name service (DNS)}
}

@inproceedings{10.1007/978-3-030-74251-5_19,
author = {Verbruggen, Gust and Van Wolputte, Elia and Duman\v{c}i\'{c}, Sebastijan and De Raedt, Luc},
title = {avatar—Automated Feature Wrangling for Machine Learning},
year = {2021},
isbn = {978-3-030-74250-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-74251-5_19},
doi = {10.1007/978-3-030-74251-5_19},
abstract = {A large part of the time invested in data science is spent on manual preparation of data. Transforming wrongly formatted columns into useful features takes up a significant part of this time. We present the avatar algorithm for automatically learning programs that perform this type of feature wrangling. Instead of relying on users to guide the wrangling process, avatar directly uses the predictive performance of machine learning models to measure its progress during wrangling. We use datasets from Kaggle to show that avatar improves raw data for prediction, and square it off against human data scientists.},
booktitle = {Advances in Intelligent Data Analysis XIX: 19th International Symposium on Intelligent Data Analysis, IDA 2021, Porto, Portugal, April 26–28, 2021, Proceedings},
pages = {235–247},
numpages = {13},
keywords = {Machine learning, Program synthesis, Data wrangling},
location = {Porto, Portugal}
}

@inproceedings{10.1145/3404555.3404565,
author = {Lee, Chun-Hsiang and Li, Zhaofeng and Lu, Xu and Chen, Tiyun and Yang, Saisai and Wu, Chao},
title = {Multi-Tenant Machine Learning Platform Based on Kubernetes},
year = {2020},
isbn = {9781450377089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404555.3404565},
doi = {10.1145/3404555.3404565},
abstract = {In this paper, we propose a flexible and scalable machine learning architecture based on Kubernetes that can support simultaneous use by huge numbers of users. Its utilization of computing resources is superior to virtual-machine-based architectures because of its container-level resource isolation and highperformance orchestration mechanism. We also describe the implementation of several important features that are designed to simplify the entire modeling lifecycle for machine learning developers. Real case studies for machine learning model development are presented that demonstrates the effectiveness of the platform in reducing the barriers to machine learning.},
booktitle = {Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence},
pages = {5–12},
numpages = {8},
keywords = {machine learning platform, kubernetes, Cloud-native},
location = {Tianjin, China},
series = {ICCAI '20}
}

@article{10.1016/j.compeleceng.2021.107397,
author = {Jain, Praphula Kumar and Yekun, Ephrem Admasu and Pamula, Rajendra and Srivastava, Gautam},
title = {Consumer recommendation prediction in online reviews using Cuckoo optimized machine learning models},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {95},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107397},
doi = {10.1016/j.compeleceng.2021.107397},
journal = {Comput. Electr. Eng.},
month = oct,
numpages = {10},
keywords = {Extreme gradient boosting, Recommendation prediction, Sentiment analysis, Machine learning, Cuckoo Search, Online reviews}
}

@inproceedings{10.1145/3448016.3457566,
author = {Xin, Doris and Miao, Hui and Parameswaran, Aditya and Polyzotis, Neoklis},
title = {Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457566},
doi = {10.1145/3448016.3457566},
abstract = {Machine learning (ML) is now commonplace, powering data-driven applications in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple times on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for optimization, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can reduce wasted computation cost by 50% without compromising the model deployment cadence.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {2639–2652},
numpages = {14},
keywords = {machine learning pipelines, data management},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@article{10.4018/IJRSDA.20210101.oa1,
author = {Sanyal, Shisna and Desarkar, Anindta and Das, Uttam Kumar and Chaudhuri, Chitrita},
title = {Feature Engineering Techniques to Improve Identification Accuracy for Offline Signature Case-Bases},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {7},
number = {1},
issn = {2334-4598},
url = {https://doi.org/10.4018/IJRSDA.20210101.oa1},
doi = {10.4018/IJRSDA.20210101.oa1},
abstract = {Handwritten signatures have been widely acclaimed for personal identification viability in educated human society. But, the astronomical growth of population in recent years warrant developing  mechanized systems to remove the tedium and bias associated with manual checking. Here the proposed system, performing identification with Nearest Neighbor matching between offline signature images collected temporally. The raw images and their extracted features are preserved using Case Based Reasoning and Feature Engineering principles. Image patterns are captured through standard global and local features, along with  some profitable indigenously developed features. Outlier feature values, on detection, are automatically replaced by their nearest statistically determined limit values. Search space reduction possibilities within the case base are probed on a few selected key features, applying Hierarchical clustering and Dendogram representation. Signature identification accuracy is found promising when compared with other machine learning techniques and a few existing well known approaches.},
journal = {Int. J. Rough Sets Data Anal.},
month = jan,
pages = {1–19},
numpages = {19}
}

@article{10.1016/j.jnca.2019.102526,
author = {Gibert, Daniel and Mateu, Carles and Planes, Jordi},
title = {The rise of machine learning for detection and classification of malware: Research developments, trends and challenges},
year = {2020},
issue_date = {Mar 2020},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {153},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2019.102526},
doi = {10.1016/j.jnca.2019.102526},
journal = {J. Netw. Comput. Appl.},
month = mar,
numpages = {22},
keywords = {Multimodal learning, Deep learning, Machine learning, Feature engineering, Malware detection}
}

@article{10.1145/3447556.3447567,
author = {Chen, Yi-Wei and Song, Qingquan and Hu, Xia},
title = {Techniques for Automated Machine Learning},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/3447556.3447567},
doi = {10.1145/3447556.3447567},
abstract = {Automated machine learning (AutoML) aims to find optimal machine learning solutions automatically given a problem description, its task type, and datasets. It could release the burden of data scientists from the multifarious manual tuning process and enable the access of domain experts to the off-the-shelf machine learning solutions without extensive experience. In this paper, we portray AutoML as a bi-level optimization problem, where one problem is nested within another to search the optimum in the search space, and review the current developments of AutoML in terms of three categories, automated feature engineering (AutoFE), automated model and hyperparameter tuning (AutoMHT), and automated deep learning (AutoDL). Stateof- the-art techniques in the three categories are presented. The iterative solver is proposed to generalize AutoML techniques. We summarize popular AutoML frameworks and conclude with current open challenges of AutoML.},
journal = {SIGKDD Explor. Newsl.},
month = jan,
pages = {35–50},
numpages = {16}
}

@article{10.1016/j.dss.2021.113556,
author = {Gosiewska, Alicja and Kozak, Anna and Biecek, Przemys\l{}aw},
title = {Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {150},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2021.113556},
doi = {10.1016/j.dss.2021.113556},
journal = {Decis. Support Syst.},
month = nov,
numpages = {10},
keywords = {Decision-making, Feature engineering, Machine learning, Interpretability}
}

@inproceedings{10.1145/3460418.3479379,
author = {Dogan, Gulustan and Sturdivant, Jonathan Daniel and Ari, Seyda and Kurpiewski, Evan},
title = {Locomotion-Transportation Recognition via LSTM and GPS Derived Feature Engineering from Cell Phone Data},
year = {2021},
isbn = {9781450384612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460418.3479379},
doi = {10.1145/3460418.3479379},
abstract = {This paper was put forth to test the notion of detecting forms of locomotion from various radio frequency data for the 2021 SHL recognition challenge. The model for team Seahawks was created to determine one of 8 different modes of locomotion from the testing dataset which contained data from GPS, WiFi, and cell tower signal data. We found the GPS location to be the most important data especially in combination with some feature engineering to produce the direction and speed of the cell phone in question. These new features were added to the dataset which was subsequently fed into an LSTM based model for evaluation and classification as the dataset was in a time-series format. This resulted in an overall accuracy of.89 on the validation set. This points to the likelihood that the detection of mode of transportation from radio frequency signals of a cell phone is a definite possibility and could be achieved via deep learning and other ML methods.},
booktitle = {Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
pages = {359–362},
numpages = {4},
keywords = {Time Series Data, LSTM, Human Activity Recognition, GPS, Feature Engineering, Classification},
location = {Virtual, USA},
series = {UbiComp/ISWC '21 Adjunct}
}

@inproceedings{10.1007/978-3-030-79457-6_42,
author = {Quang, Do Nguyet and Selamat, Ali and Krejcar, Ondrej},
title = {Recent Research on Phishing Detection Through Machine Learning Algorithm},
year = {2021},
isbn = {978-3-030-79456-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79457-6_42},
doi = {10.1007/978-3-030-79457-6_42},
abstract = {The rapid growth of emerging technologies, smart devices, 5G communication, etc. have contributed to the accumulation of data, hence introducing the big data era. Big data imposes a variety of challenges associated with machine learning, especially in phishing detection. Therefore, this paper aims to provide an analysis and summary of current research in phishing detection through machine learning for big data. To achieve this goal, this study adopted a systematic literature review (SLR) technique and critically analyzed a total of 30 papers from various journals and conference proceedings. These papers were selected from previous studies in five different databases on content published between 2018 and January 2021. The results obtained from this study reveal a limited number of research works that comprehensively reviewed the feasibility of applying both machine learning and big data technologies in the context of phishing detection.},
booktitle = {Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part I},
pages = {495–508},
numpages = {14},
keywords = {Big data, Machine learning (ML), Phishing detection, Cybersecurity},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3383455.3422555,
author = {Mehta, Dhagash and Desai, Dhruv and Pradeep, Jithin},
title = {Machine learning fund categorizations},
year = {2021},
isbn = {9781450375849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383455.3422555},
doi = {10.1145/3383455.3422555},
abstract = {Given the surge in popularity of mutual funds (including exchange-traded funds (ETFs)) as a diversified financial investment, a vast variety of mutual funds from various investment management firms and diversification strategies have become available in the market. Identifying similar mutual funds among such a wide landscape of mutual funds has become more important than ever because of many applications ranging from sales and marketing to portfolio replication, portfolio diversification and tax loss harvesting. The current best method is data-vendor provided categorization which usually relies on curation by human experts with the help of available data. In this work, we establish that an industry wide well-regarded categorization system is learnable using machine learning and largely reproducible, and in turn constructing a truly data-driven categorization. We discuss the intellectual challenges in learning this man-made system, our results and their implications.},
booktitle = {Proceedings of the First ACM International Conference on AI in Finance},
articleno = {13},
numpages = {8},
keywords = {mutual funds, machine learning, categorization},
location = {New York, New York},
series = {ICAIF '20}
}

@inproceedings{10.1145/3437914.3437974,
author = {Allen, Becky and Devlin, Marie and McGough, A.Stephen},
title = {Using the One Minute Paper to Gain Insight into Potential Threshold Concepts in Artificial Intelligence Courses},
year = {2021},
isbn = {9781450389594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437914.3437974},
doi = {10.1145/3437914.3437974},
abstract = {Interest in Artificial Intelligence (AI) and the popularity of such courses has increased over the past few years, as a consequence higher education (HE) institutions are now offering courses in such fields. However, there is a current lack of research relating to best practice for teaching this complex topic area which encompasses both computing and mathematics knowledge. This paper outlines an initial study that set out to determine the threshold concepts within this domain through use of the One Minute Paper technique with students currently studying AI. Our results identified a number of specific models which students found troublesome including the support vector machine, recurrent neural network and the multilayer perceptron. The results indicated that topics related to deep learning were more complex for the students to fully comprehend and students may require greater in-depth tuition and alternative support mechanisms in this area in particular. Further investigation is needed to determine the heterogeneity of content delivered on courses relating to AI as well as additional studies at other HE institutions to gather more data on potential threshold concepts and the best methods to teach them.},
booktitle = {Proceedings of the 5th Conference on Computing Education Practice},
pages = {21–24},
numpages = {4},
keywords = {Threshold Concepts, Higher Education, Artificial Intelligence},
location = {Durham, United Kingdom},
series = {CEP '21}
}

@article{10.1007/s11128-021-03037-9,
author = {Goes, Caio B. D. and Canabarro, Askery and Duzzioni, Eduardo I. and Maciel, Thiago O.},
title = {Automated machine learning can classify bound entangled states with tomograms},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3},
issn = {1570-0755},
url = {https://doi.org/10.1007/s11128-021-03037-9},
doi = {10.1007/s11128-021-03037-9},
abstract = {For quantum systems with total dimension greater than six, the positive partial transposition (PPT) criterion is necessary but not sufficient to decide the non-separability of quantum states. Here, we present an automated machine learning approach to classify random states of two qutrits as separable or entangled even when the PPT criterion fails. We successfully applied our framework using enough data to perform a complete quantum state tomography and without any direct measurement of its entanglement. In addition, we could also estimate the generalized robustness of entanglement with regression techniques and use it to validate our classifiers.},
journal = {Quantum Information Processing},
month = mar,
numpages = {18},
keywords = {Automated machine learning, Bound entanglement, PPT}
}

@article{10.1007/s10916-018-1003-9,
author = {Lan, Kun and Wang, Dan-Tong and Fong, Simon and Liu, Lian-Sheng and Wong, Kelvin K. and Dey, Nilanjan},
title = {A Survey of Data Mining and Deep Learning in Bioinformatics},
year = {2018},
issue_date = {August    2018},
publisher = {Plenum Press},
address = {USA},
volume = {42},
number = {8},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-018-1003-9},
doi = {10.1007/s10916-018-1003-9},
abstract = {The fields of medicine science and health informatics have made great progress recently and have led to in-depth analytics that is demanded by generation, collection and accumulation of massive data. Meanwhile, we are entering a new period where novel technologies are starting to analyze and explore knowledge from tremendous amount of data, bringing limitless potential for information growth. One fact that cannot be ignored is that the techniques of machine learning and deep learning applications play a more significant role in the success of bioinformatics exploration from biological data point of view, and a linkage is emphasized and established to bridge these two data analytics techniques and bioinformatics in both industry and academia. This survey concentrates on the review of recent researches using data mining and deep learning approaches for analyzing the specific domain knowledge of bioinformatics. The authors give a brief but pithy summarization of numerous data mining algorithms used for preprocessing, classification and clustering as well as various optimized neural network architectures in deep learning methods, and their advantages and disadvantages in the practical applications are also discussed and compared in terms of their industrial usage. It is believed that in this review paper, valuable insights are provided for those who are dedicated to start using data analytics methods in bioinformatics.},
journal = {J. Med. Syst.},
month = aug,
pages = {1–20},
numpages = {20},
keywords = {Machine learning, Deep learning, Data mining, Biomedicine, Bioinformatics}
}

@inproceedings{10.1145/3407703.3407725,
author = {Lu, Lei and Tao, Luo and Yining, Wang and Jiahui, Han and Jianfeng, Li},
title = {Research on Osteoporosis Risk Assessment Based on Semi-supervised Machine Learning},
year = {2020},
isbn = {9781450377270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407703.3407725},
doi = {10.1145/3407703.3407725},
abstract = {In this paper, we propose a semi-supervised machine learning method for osteoporosis risk assessment. Existing osteoporosis risk assessment models have problems of low accuracy, and cannot utilize large amounts of unlabeled data. In order to improve the accuracy of diagnosis, the method comprehensively considers the osteoporosis-related questionnaire data and bone image data, and fuses the multi-modal features extracted from them. Feature engineering and Word2vec are used to extract numerical and text features from questionnaires, respectively. CNN is used to extract image features from BMD images. Considering the difficulty of obtaining labeled medical data, we build a self-training semi-supervised model based on XGBoost to classify and evaluate osteoporosis, which uses both labeled and unlabeled data for obtaining better generalization capabilities. Besides, in view of the fact that the questionnaire data has plenty of outliers and missing data, we remove outliers based on a DBSCAN algorithm and propose an improved PKNN algorithm to impute the missing data. Experimental results show that the proposed improved semi-supervised method achieves an accuracy of 0.78 in osteoporosis risk assessment and has obvious advantages compared with other methods.},
booktitle = {Proceedings of the 2020 Artificial Intelligence and Complex Systems Conference},
pages = {114–120},
numpages = {7},
keywords = {Semi-supervised, Osteoporosis, Feature fusion},
location = {Wuhan, China},
series = {AICSconf '20}
}

@article{10.1016/j.jbi.2019.103257,
author = {Beunza, Juan-Jose and Puertas, Enrique and Garc\'{\i}a-Ovejero, Ester and Villalba, Gema and Condes, Emilia and Koleva, Gergana and Hurtado, Cristian and Landecho, Manuel F.},
title = {Comparison of machine learning algorithms for clinical event prediction (risk of coronary heart disease)},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {97},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2019.103257},
doi = {10.1016/j.jbi.2019.103257},
journal = {J. of Biomedical Informatics},
month = sep,
numpages = {6},
keywords = {NA, NPV, PPV, SP, SE, AUC, ACC, ML, Diagnostic techniques and procedures, Area under curve, Research techniques, Support vector machines, Supervised machine learning, Machine learning}
}

@inproceedings{10.1007/978-3-030-86230-5_4,
author = {Fares, Ahmed A. and Vasconcelos, Fabio and Mendes-Moreira, Joao and Ferreira, Carlos},
title = {Predicting Predawn Leaf Water Potential up to Seven Days Using Machine Learning},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_4},
doi = {10.1007/978-3-030-86230-5_4},
abstract = {Sustainable agricultural production requires a controlled usage of water, nutrients, and minerals from the environment. Different strategies of plant irrigation are being studied to control the quantity and quality balance of the fruits. Regarding efficient irrigation, particularly in deficit irrigation strategies, it is essential to act according to water stress status in the plant. For example, in the vine, to improve the quality of the grapes, the plants are deprived of water until they reach particular water stress before re-watered in specified phenological stages. The water status inside the plant is estimated by measuring either the Leaf Potential during the Predawn or soil water potential, along with the root zones. Measuring soil water potential has the advantage of being independent of diurnal atmospheric variations. However, this method has many logistic problems, making it very hard to apply along all the yard, especially the big ones. In this study, the Predawn Leaf Water Potential (PLWP) is daily predicted by Machine Learning models using data such as grapes variety, soil characteristics, irrigation schedules, and meteorological data. The benefits of these techniques are the reduction of the manual work of measuring PLWP and the capacity to implement those models on a larger scale by predicting PLWP up&nbsp;to 7&nbsp;days which should enhance the ability to optimize the irrigation plan while the quantity and quality of the crop are under control.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {39–50},
numpages = {12},
keywords = {Machine Learning, Leaf Water Potential, Precision agriculture}
}

@inproceedings{10.1145/3461001.3471142,
author = {Gu\'{e}gain, \'{E}douard and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {On reducing the energy consumption of software product lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471142},
doi = {10.1145/3461001.3471142},
abstract = {Along the last decade, several studies considered green software design as a key development concern to improve the energy efficiency of software. Yet, few techniques address this concern for Software Product Lines (SPL). In this paper, we therefore introduce two approaches to measure and reduce the energy consumption of a SPL by analyzing a limited set of products sampled from this SPL. While the first approach relies on the analysis of individual feature consumptions, the second one takes feature interactions into account to better mitigate energy consumption of resulting products.Our experimental results on a real-world SPL indicate that both approaches succeed to produce significant energy improvements on a large number of products, while consumption data was modeled from a small set of sampled products. Furthermore, we show that taking feature interactions into account leads to more products improved with higher energy savings per product.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {89–99},
numpages = {11},
keywords = {software product lines, mitigation, measurement, energy, consumption},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3448016.3457295,
author = {Neutatz, Felix and Biessmann, Felix and Abedjan, Ziawasch},
title = {Enforcing Constraints for Machine Learning Systems via Declarative Feature Selection: An Experimental Study},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457295},
doi = {10.1145/3448016.3457295},
abstract = {Responsible usage of Machine Learning (ML) systems in practice does not only require enforcing high prediction quality, but also accounting for other constraints, such as fairness, privacy, or execution time. One way to address multiple user-specified constraints on ML systems is feature selection. Yet, optimizing feature selection strategies for multiple metrics is difficult to implement and has been underrepresented in previous experimental studies. Here, we propose Declarative Feature Selection (DFS) to simplify the design and validation of ML systems satisfying diverse user-specified constraints. We benchmark and evaluate a representative series of feature selection algorithms. From our extensive experimental results, we derive concrete suggestions on when to use which strategy and show that a meta-learning-driven optimizer can accurately predict the right strategy for an ML task at hand. These results demonstrate that feature selection can help to build ML systems that meet combinations of user-specified constraints, independent of the ML methods used.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {1345–1358},
numpages = {14},
keywords = {robustness, privacy, meta learning, machine learning, feature selection, fairness, declarative ml, declarative machine learning, declarative feature selection, bias, DFS},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@article{10.1155/2021/6129210,
author = {Akhtar, Muhammad Shoaib and Feng, Tao and Karuppiah, Marimuthu},
title = {Deep Learning-Based Framework for the Detection of Cyberattack Using Feature Engineering},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/6129210},
doi = {10.1155/2021/6129210},
abstract = {Digital systems are changing to security systems in contemporary days. It is time for the digital system to have sufficient security to defend against threats and attacks. The intrusion detection system can identify an anomaly from an external or internal source in the network system. Many kinds of threats are present, that is, active and passive. These dangers could lead to anomalies in the system by which data can be attacked and taken by attackers from the beginning to the destination. Machine learning nowadays is a developing topic; its applications are wide. We can forecast the future through machine learning and classify the right class. In this paper, we employed the new binary and multiclass classification model of Convolutional Neural Networks (CNNs) to identify the anomaly of the network system. In this respect, we used the NSLKDD dataset. Our model uses a Convolutional Neural Network (CNN) to conduct binary and multiclass classification. In both datasets, we build a DL-based DoS detection model. We focus on the DoS category in the most extensively used IDS dataset, KDD. As the name implies, CNN is the most extensively used the DL model for image recognition. Adding a pooling layer to the convolution layer minimizes the size of the feature data extracted from the image while maintaining I/O and spatial information. The CNN model has shown the promising results of multiclass and binary classification in terms of validation loss of 0.0012 at 11th epochs and validation accuracy of 98% and 99%, respectively.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/2491627.2491629,
author = {Clements, Paul and Krueger, Charles and Shepherd, James and Winkler, Andrew},
title = {A PLE-based auditing method for protecting restricted content in derived products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491629},
doi = {10.1145/2491627.2491629},
abstract = {Many organizations that produce a portfolio of products for different customers need to ensure that sensitive or restricted content that may appear in some products must not appear in others. Examples of this need include complying with statutes in different countries of sale, protection of intellectual property developed specifically for one customer, and more. For organizations operating under these requirements and producing their products under a product line engineering paradigm that relies on automation in product derivation, there is a need for a method to ensure that the content restrictions have been met in the derived products. This paper describes an auditing method that meets this need. It was created for use in the Second Generation Product Line Engineering approach that is being applied by Lockheed Martin in their AEGIS ship combat system product line.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {218–226},
numpages = {9},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product derivation, product configurator, product baselines, product audit, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@article{10.1016/j.future.2021.07.005,
author = {Zhao, Shajunyi and Ge, Dongyuan and Zhao, Jingfeng and Xiang, Wenjiang},
title = {Fingerprint pre-processing and feature engineering to enhance agricultural products categorization},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {125},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2021.07.005},
doi = {10.1016/j.future.2021.07.005},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {944–948},
numpages = {5},
keywords = {Identification system, Embedded clip, Agriculture products, Feature extraction, Fingerprint}
}

@article{10.1016/j.asoc.2021.107896,
author = {Abedi, M. and Naser, M.Z.},
title = {         RAI: Rapid, Autonomous and Intelligent machine learning approach to identify fire-vulnerable bridges},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107896},
doi = {10.1016/j.asoc.2021.107896},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {12},
keywords = {Deep learning, Classification, Machine learning, Fire, Bridges}
}

@article{10.1177/0165551516684296,
author = {Herzallah, Wafa and Faris, Hossam and Adwan, Omar},
title = {Feature engineering for detecting spammers on Twitter},
year = {2018},
issue_date = {4 2018},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {44},
number = {2},
issn = {0165-5515},
url = {https://doi.org/10.1177/0165551516684296},
doi = {10.1177/0165551516684296},
abstract = {Twitter is a social networking website that has gained a lot of popularity around the world in the last decade. This popularity made Twitter a common target for spammers and malicious users to spread unwanted advertisements, viruses and phishing attacks. In this article, we review the latest research works to determine the most effective features that were investigated for spam detection in the literature. These features are collected to build a comprehensive data set that can be used to develop more robust and accurate spammer detection models. The new data set is tested using popular classifiers Naive Bayes, support vector machines, multilayer perceptron neural networks, Decision Trees, Random forests and k-Nearest Neighbour. The prediction performance of these classifiers is evaluated and compared based on different evaluation metrics. Moreover, a further analysis is carried out to identify the features that have higher impact on the accuracy of spam detection. Three different techniques are used and compared for this analysis: change of mean square error CoM, information gain IG and Relief-F method. Top five features identified by each technique are used again to build the detection models. Experimental results show that most of the developed classifiers obtained high evaluation results based on the comprehensive data set constructed in this work. Experiments also reveal the important role of some features like the reputation of the account, average length of the tweet, average mention per tweet, age of the account, and the average time between posts in the process of identifying spammers in the social network.},
journal = {J. Inf. Sci.},
month = apr,
pages = {230–247},
numpages = {18},
keywords = {spammers, spam features, spam, feature engineering, detection, Twitter, Classifiers}
}

@inproceedings{10.1145/3462462.3468879,
author = {Makrynioti, Nantia and Ley-Wild, Ruy and Vassalos, Vasilis},
title = {Machine learning in SQL by translation to TensorFlow},
year = {2021},
isbn = {9781450384865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462462.3468879},
doi = {10.1145/3462462.3468879},
abstract = {We present sql4ml, a framework for expressing machine learning (ML) algorithms in a relational database management system (RDBMS). The user writes the objective function of an ML model as a SQL query, then sql4ml translates the query into an equivalent TensorFlow (TF) graph, which can be automatically differentiated and optimized to learn the model weights. Sql4ml makes the database a unified programming environment for feature engineering, learning/inference, and evaluating models. The proposed approach is more expressive than using ready-made ML algorithms, but abstracts away the details of the training process. We present the architecture of sql4ml and describe the method for translating an objective function in SQL to a TensorFlow representation. We show how recent ideas from Factorized ML [7] can be leveraged to efficiently move data between a database and an ML framework. Finally, we present experimental results regarding both the proposed translation and the optimization techniques for data transfer. Our results show that translation time is negligible compared to time for data processing, and that the optimization techniques achieve up to 50% improvement in the export runtime and up to 85% decrease in the size of the exported data.},
booktitle = {Proceedings of the Fifth Workshop on Data Management for End-To-End Machine Learning},
articleno = {2},
numpages = {11},
keywords = {mathematical optimization problems, TensorFlow, SQL, RDBMS},
location = {Virtual Event, China},
series = {DEEM '21}
}

@inproceedings{10.1007/978-3-030-91814-9_8,
author = {de Almeida, Breno L\'{\i}vio Silva and Queiroz, Alvaro Pedroso and Santos, Anderson Paulo Avila and Bonidia, Robson Parmezan and da Rocha, Ulisses Nunes and Sanches, Danilo Sipoli and de Carvalho, Andr\'{e} Carlos Ponce de Leon Ferreira},
title = {Feature Importance Analysis of Non-coding DNA/RNA Sequences Based on Machine Learning Approaches},
year = {2021},
isbn = {978-3-030-91813-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91814-9_8},
doi = {10.1007/978-3-030-91814-9_8},
abstract = {Non-coding sequences have been gained increasing space in scientific areas related to bioinformatics, due to essential roles played in different biological processes. Elucidating the function of these non-coding regions is a relevant challenge, which has been addressed by several Machine Learning (ML) studies in various fields of ncRNA, e.g., small non-coding RNAs (sRNAs) and Circular RNAs (circRNAs). The identification of these biological sequences is possible through feature engineering techniques, which can help point out specifics in different types of problems with ML. Thereby, there are recent studies focusing on interpretable computational methods, i.e., the best features based on feature importance analysis. For that reason, in this study we have proposed to explore different features descriptors and the degree of importance involved for classification task, using two case studies: (1) prediction of sRNAs in Bacteria and (2) prediction of circRNA in Humans. We developed a general pipeline using hybrid feature vectors with mathematical and conventional descriptors. In addition, these vectors were generated with MathFeature package and feature selection techniques in both case studies. Finally, our experiments results reported high predictive performance and the relevance of combining conventional and mathematical descriptors in different organisms.},
booktitle = {Advances in Bioinformatics and Computational Biology: 14th Brazilian Symposium on Bioinformatics, BSB 2021, Virtual Event, November 22–26, 2021, Proceedings},
pages = {81–92},
numpages = {12},
keywords = {MathFeature, Feature importance, Feature extraction, Small RNA, Machine learning}
}

@article{10.1287/mksc.2019.1160,
author = {Xu, Zibin and Dukes, Anthony},
title = {Product Line Design Under Preference Uncertainty Using Aggregate Consumer Data},
year = {2019},
issue_date = {July-August 2019},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {38},
number = {4},
issn = {1526-548X},
url = {https://doi.org/10.1287/mksc.2019.1160},
doi = {10.1287/mksc.2019.1160},
abstract = {This research studies the product line design problem when consumers are subject to perceptual errors in assessing their intrinsic preferences.This research studies the product line design problem when consumers are subject to perceptual errors in assessing their intrinsic preferences. If perceptual errors are driven by common variables, then a firm may use aggregate consumer data (e.g., conjoint studies or anonymous usage data) to deduce the errors and infer the consumer preferences. In this way, we develop microfoundations necessary to show when and how the firm can understand consumer preferences better than consumers themselves, a situation we call superior knowledge. But is superior knowledge ever unprofitable? How should the firm with superior knowledge design its product line? Do consumers receive more-relevant products or simply have more surplus extracted? Can data collection help consumers make better choices? Our results suggest that consumers’ rational suspicions may prevent the firm from exploiting its superior knowledge. In addition, the burden of signaling may force the firm to offer efficient quality for its products. Therefore, allowing the firm to collect aggregate consumer data may be strictly Pareto improving.},
journal = {Marketing Science},
month = jul,
pages = {669–689},
numpages = {21},
keywords = {signaling model, perceptual error, uninformed preference, superior knowledge, product line design, consumer data collection}
}

@article{10.1155/2021/7890923,
author = {Pan, Xiaohui and Yau, Wei-Chuen},
title = {Quantitative Analysis and Prediction of Global Terrorist Attacks Based on Machine Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/7890923},
doi = {10.1155/2021/7890923},
abstract = {Terrorist attacks pose a great threat to global security, and their analysis and prediction are imperative. Considering the high frequency of terrorist attacks and the inherent difficulty in finding related terrorist organizations, we propose a classification framework based on ensemble learning for classifying and predicting terrorist organizations. The framework includes data preprocessing, data splitting, five classifier prediction models, and model evaluation. Based on a quantitative statistical analysis of terrorist organization activities in GTD from 1970 to 2017 and feature selection using the SelectKBest method in scikit learn, we constructed five classification and prediction models of terrorist organizations, namely, decision tree, bagging, random forest, extra tree, and XGBoost, and utilized a 10-fold cross-validation method to verify the performance and stability of the proposed model. Experimental results showed that the five models achieved excellent performance. The XGBoost and random forest models achieved the best accuracies (97.16% and 96.82%, respectively) of predicting 32 terrorist organizations with the highest attack frequencies. The proposed classifier framework is useful for the accurate and efficient prediction of terrorist organizations responsible for attacks and can be extended to predict all terrorist organizations.},
journal = {Sci. Program.},
month = jan,
numpages = {15}
}

@inproceedings{10.1145/3460418.3479374,
author = {Zhu, Yida and Luo, Haiyong and Guo, Song and Zhao, Fang},
title = {Data Mining for Transportation Mode Recognition from Radio-data},
year = {2021},
isbn = {9781450384612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460418.3479374},
doi = {10.1145/3460418.3479374},
abstract = {The rapid development of urban information techniques, mobile sensors, and artificial intelligence can help to generate solutions for transportation mode recognition (TMR). The Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge organized at the UbiComp 2021 presents a large and realistic dataset with different activities. Different from the previous three years that aimed at transportation mode recognition from the motion sensors, the goal of this year is to recognize 8 modes of locomotion and transportation (activities) in a user-independent manner based on radio-data, including GPS reception, GPS location, WiFi reception, and GSM cell tower scans. In this paper, our team (We can fly) summarizes our submission to the competition. We first preprocess the data, divide the sample time window and deal with missing values, and then extract 303 features from the given sensor, and finally feed these features into the LightGBM classifier. In the experiment, we utilized the training datasets to train our model and achieved macro-F1 score of 0.665 on the valid datasets.},
booktitle = {Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
pages = {423–427},
numpages = {5},
keywords = {Transportation mode recognition, Smartphone, Machine learning, LightGBM, Activity recognition},
location = {Virtual, USA},
series = {UbiComp/ISWC '21 Adjunct}
}

@inproceedings{10.1007/978-3-030-64583-0_44,
author = {Carta, Salvatore and Recupero, Diego Reforgiato and Saia, Roberto and Stanciu, Maria Madalina},
title = {A General Approach for Risk Controlled Trading Based on Machine Learning and Statistical Arbitrage},
year = {2020},
isbn = {978-3-030-64582-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64583-0_44},
doi = {10.1007/978-3-030-64583-0_44},
abstract = {Nowadays, machine learning usage has gained significant interest in financial time series prediction, hence being a promise land for financial applications such as algorithmic trading. In this setting, this paper proposes a general approach based on an ensemble of regression algorithms and dynamic asset selection applied to the well-known statistical arbitrage trading strategy. Several extremely heterogeneous state-of-the-art machine learning algorithms, exploiting different feature selection processes in input, are used as base components of the ensemble, which is in charge to forecast the return of each of the considered stocks. Before being used as an input to the arbitrage mechanism, the final ranking of the assets takes also into account a quality assurance mechanism that prunes the stocks with poor forecasting accuracy in the previous periods. The approach has a general application for any risk balanced trading strategy aiming to exploit different financial assets. It was evaluated implementing an intra-day trading statistical arbitrage on the stocks of the S&amp;P500 index. Our approach outperforms each single base regressor we adopted, which we considered as baselines. More important, it also outperforms Buy-and-hold of S&amp;P500 Index, both during financial turmoil such as the global financial crisis, and also during the massive market growth in the recent years.},
booktitle = {Machine Learning, Optimization, and Data Science: 6th International Conference, LOD 2020, Siena, Italy, July 19–23, 2020, Revised Selected Papers, Part I},
pages = {489–503},
numpages = {15},
keywords = {Ensemble learning, Statistical arbitrage, Machine learning, Stock market forecast},
location = {Siena, Italy}
}

@inproceedings{10.1145/1147249.1147254,
author = {Fischbein, Dario and Uchitel, Sebastian and Braberman, Victor},
title = {A foundation for behavioural conformance in software product line architectures},
year = {2006},
isbn = {1595934596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1147249.1147254},
doi = {10.1145/1147249.1147254},
abstract = {Software product lines or families represent an emerging paradigm that is enabling companies to engineer applications with similar functionality and user requirements more effectively. Behaviour modelling at the architecture level has the potential for supporting behaviour analysis of entire product lines, as well as defining optional and variable behaviour for different products of a family. However, to do so rigorously, a well defined notion of behavioural conformance of a product to its product line must exist. In this paper we provide a discussion on the shortcomings of traditional behaviour modelling formalisms such as Labelled Transition Systems for characterising conformance and propose Modal Transition Systems as an alternative. We discuss existing semantics for such models, exposing their limitations and finally propose a novel semantics for Modal Transition Systems, branching semantics, that can provide the formal underpinning for a notion of behaviour conformance for software product line architectures.},
booktitle = {Proceedings of the ISSTA 2006 Workshop on Role of Software Architecture for Testing and Analysis},
pages = {39–48},
numpages = {10},
location = {Portland, Maine},
series = {ROSATEA '06}
}

@article{10.1016/j.ipm.2021.102555,
author = {\.{Z}bikowski, Kamil and Antosiuk, Piotr},
title = {A machine learning, bias-free approach for predicting business success using Crunchbase data},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {58},
number = {4},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2021.102555},
doi = {10.1016/j.ipm.2021.102555},
journal = {Inf. Process. Manage.},
month = jul,
numpages = {18},
keywords = {Look-ahead bias, Crunchbase, XGBoost, Supervised learning, Startups}
}

@article{10.1016/j.eswa.2018.09.056,
author = {Itani, Sarah and Lecron, Fabian and Fortemps, Philippe},
title = {Specifics of medical data mining for diagnosis aid: A survey},
year = {2019},
issue_date = {Mar 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {118},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.09.056},
doi = {10.1016/j.eswa.2018.09.056},
journal = {Expert Syst. Appl.},
month = mar,
pages = {300–314},
numpages = {15},
keywords = {Explainable artificial intelligence, Diagnosis aid, Medicine, Data mining}
}

@inproceedings{10.1007/978-3-030-38961-1_35,
author = {Haq, Ikram Ul and Gondal, Iqbal and Vamplew, Peter},
title = {Enhancing Model Performance for Fraud Detection by Feature Engineering and Compact Unified Expressions},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_35},
doi = {10.1007/978-3-030-38961-1_35},
abstract = {The performance of machine learning models can be improved in a variety of ways including segmentation, treating missing and outlier values, feature engineering, feature selection, multiple algorithms, algorithm tuning/compactness and ensemble methods. Feature engineering and compactness of the model can have a significant impact on the algorithm’s performance but usually requires detailed domain knowledge. Accuracy and compactness of machine learning models are equally important for optimal memory and storage needs. The research in this paper focuses on feature engineering and compactness of rulesets. Compactness of the ruleset can make the algorithm more efficient and derivation of new features makes the dataset high dimensional potentially resulting in higher accuracy. We have developed a technique to enhance model’s performance with feature engineering and compact unified expressions for dataset of unknown domain using profile models approach. Classification accuracy is compared using well-known classifiers (Decision Tree, Ripple Down Rule and RandomForest). This technique is applied on fraud analysis bank dataset and multiple synthetic bank datasets. Empirical evaluation has shown that not only the ruleset size of training and prediction dataset is reduced but performance is also improved in other performance metrics including classification accuracy. In this paper, the transformed data is used for the experimental validation and development of fraud detection technique, but it can be used in other domains as well especially for scalable and distributed systems.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {399–409},
numpages = {11},
keywords = {RDR, Situated profiles, Ruleset, Compactness, Categorical data, Feature engineering, Unified expressions, Fraud detection, Model performance},
location = {Melbourne, VIC, Australia}
}

@article{10.1016/j.eswa.2021.115716,
author = {Yun, Kyung Keun and Yoon, Sang Won and Won, Daehan},
title = {Prediction of stock price direction using a hybrid GA-XGBoost algorithm with a three-stage feature engineering process},
year = {2022},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {186},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115716},
doi = {10.1016/j.eswa.2021.115716},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {21},
keywords = {Genetic algorithm, XGBoost feature selection, Technical indicators, Blessing of dimensionality, Curse of dimensionality, Feature set expansion, Optimal feature set}
}

@article{10.1016/j.eswa.2020.114161,
author = {Houssein, Essam H. and Emam, Marwa M. and Ali, Abdelmgeid A. and Suganthan, Ponnuthurai Nagaratnam},
title = {Deep and machine learning techniques for medical imaging-based breast cancer: A comprehensive review},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114161},
doi = {10.1016/j.eswa.2020.114161},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {20},
keywords = {Thermography images, Ultrasound images, Mammogram images, Medical imaging modalities, Magnetic resonance imaging (MRI), Machine learning, Histological images, Deep learning, Computer-aided diagnosis system (CAD), Convolutional neural network, Breast cancer classification}
}

@inproceedings{10.1145/3461001.3471149,
author = {Lesoil, Luc and Acher, Mathieu and T\'{e}rnava, Xhevahire and Blouin, Arnaud and J\'{e}z\'{e}quel, Jean-Marc},
title = {The interplay of compile-time and run-time options for performance prediction},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471149},
doi = {10.1145/3461001.3471149},
abstract = {Many software projects are configurable through compile-time options (e.g., using ./configure) and also through run-time options (e.g., command-line parameters, fed to the software at execution time). Several works have shown how to predict the effect of run-time options on performance. However it is yet to be studied how these prediction models behave when the software is built with different compile-time options. For instance, is the best run-time configuration always the best w.r.t. the chosen compilation options? In this paper, we investigate the effect of compile-time options on the performance distributions of 4 software systems. There are cases where the compiler layer effect is linear which is an opportunity to generalize performance models or to tune and measure runtime performance at lower cost. We also prove there can exist an interplay by exhibiting a case where compile-time options significantly alter the performance distributions of a configurable system.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {100–111},
numpages = {12},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-030-60884-2_7,
author = {Espinosa, Ricardo and Ponce, Hiram and Guti\'{e}rrez, Sebasti\'{a}n and Hern\'{a}ndez, Eluney},
title = {Click Event Sound Detection Using Machine Learning in Automotive Industry},
year = {2020},
isbn = {978-3-030-60883-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60884-2_7},
doi = {10.1007/978-3-030-60884-2_7},
abstract = {Artificial intelligence has been playing an important role when it comes to the automotive industry and its quality of assemblies in the production line, this is because since the arrival of the industry 4.0 it has been subject to change and continuous improvement. In the past, we’ve observed how many machine learning architectures have been used to create environmental sound classification systems in order to improve traditional systems, thus overcoming efficiency issues with great results. In this work, we present a machine learning solution/approach for click event sound detection using audio sensors that are used in the assembly of electric harnesses for engines, this being done on an automotive production line, where we divided our workflow into: data collection, pre-processing, feature extraction, training and inference and finally the detection of the click event sounds. We created a dataset that is composed by 25,000 audio files that have an average duration of 0.025 seconds per click sound with the purpose of training a Multi-layer Perceptron and bring it into the inference phase. In order to test this approach, we’ve performed various implementations in a laboratory and in the real automotive industry. We obtained 95.23% in F1-Score Metric in a laboratory, while in real conditions, we obtained less reliable results, as 84.00% as the best results.},
booktitle = {Advances in Soft Computing: 19th Mexican International Conference on Artificial Intelligence, MICAI 2020, Mexico City, Mexico, October 12–17, 2020, Proceedings, Part I},
pages = {88–103},
numpages = {16},
keywords = {Supervised learning, Signal spectral characteristics, Neural network, MLP, Machine learning, Feature extraction, Events sound recognition, Audio signal processing},
location = {Mexico City, Mexico}
}

@inproceedings{10.1145/3336294.3336315,
author = {Wolschke, Christian and Becker, Martin and Schneickert, S\"{o}ren and Adler, Rasmus and MacGregor, John},
title = {Industrial Perspective on Reuse of Safety Artifacts in Software Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336315},
doi = {10.1145/3336294.3336315},
abstract = {In the future, safety-critical industrial products will have to be maintained and variants will have to be produced. In order to do this economically, the safety artifacts of the components should also be reused. At present, however, it is still unclear how this reuse could take place. Moreover this reuse is complicated, by the different situations in the various industries involved and by the corresponding standards applied.Current industrial practice for certification processes relies on a component-based view of reuse. We investigate the possibilities of product lines with managed processes for reuse also across multiple domains.In order to identify the challenges and possible solutions, we conducted interviews with industry partners from the domains of ICT, Rail, Automotive, and Industrial Automation, and from small- and medium-sized enterprises to large organizations. The semi-structured interviews identified the characteristics of current safety engineering processes, the handling of general variety and reuse, the approach followed for safety artifacts, and the need for improvement.In addition, a detailed literature survey summarizes existing approaches. We investigate which modularity concepts exist for dealing with safety, how variability concepts integrate safety, by which means process models can consider safety, and how safety cases are evolved while maintenance takes place. An overview of similar research projects complements the analysis.The identified challenges and potential solution proposals show how safety is related to Software Product Lines.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {143–154},
numpages = {12},
keywords = {safety standards, safety reuse, product line certification, open source certification, modular safety},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2983990.2984000,
author = {Hanappi, Oliver and Hummer, Waldemar and Dustdar, Schahram},
title = {Asserting reliable convergence for configuration management scripts},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983990.2984000},
doi = {10.1145/2983990.2984000},
abstract = {The rise of elastically scaling applications that frequently deploy new machines has led to the adoption of DevOps practices across the cloud engineering stack. So-called configuration management tools utilize scripts that are based on declarative resource descriptions and make the system converge to the desired state. It is crucial for convergent configurations to be able to gracefully handle transient faults, e.g., network outages when downloading and installing software packages. In this paper we introduce a conceptual framework for asserting reliable convergence in configuration management. Based on a formal definition of configuration scripts and their resources, we utilize state transition graphs to test whether a script makes the system converge to the desired state under different conditions. In our generalized model, configuration actions are partially ordered, often resulting in prohibitively many possible execution orders. To reduce this problem space, we define and analyze a property called preservation, and we show that if preservation holds for all pairs of resources, then convergence holds for the entire configuration. Our implementation builds on Puppet, but the approach is equally applicable to other frameworks like Chef, Ansible, etc. We perform a comprehensive evaluation based on real world Puppet scripts and show the effectiveness of the approach. Our tool is able to detect all idempotence and convergence related issues in a set of existing Puppet scripts with known issues as well as some hitherto undiscovered bugs in a large random sample of scripts.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {328–343},
numpages = {16},
keywords = {Testing, System Configuration Scripts, Puppet, Idempotence, DevOps, Declarative Language, Convergence, Configuration Management},
location = {Amsterdam, Netherlands},
series = {OOPSLA 2016}
}

@article{10.1007/s42979-021-00776-5,
author = {Vakadkar, Kaushik and Purkayastha, Diya and Krishnan, Deepa},
title = {Detection of Autism Spectrum Disorder in Children Using Machine Learning Techniques},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {5},
url = {https://doi.org/10.1007/s42979-021-00776-5},
doi = {10.1007/s42979-021-00776-5},
abstract = {Autism Spectrum Disorder (ASD) is a neurological disorder which might have a lifelong impact on the language learning, speech, cognitive, and social skills of an individual. Its symptoms usually show up in the developmental stages, i.e., within the first two years after birth, and it impacts around 1% of the population globally [. Accessed 25 Dec 2019]. ASD is mainly caused by genetics or by environmental factors; however, its conditions can be improved by detecting and treating it at earlier stages. In the current times, clinical standardized tests are the only methods which are being used, to diagnose ASD. This not only requires prolonged diagnostic time but also faces a steep increase in medical costs. To improve the precision and time required for diagnosis, machine learning techniques are being used to complement the conventional methods. We have applied models such as Support Vector Machines (SVM), Random Forest Classifier (RFC), Na\"{\i}ve Bayes (NB), Logistic Regression (LR), and KNN to our dataset and constructed predictive models based on the outcome. The main objective of our paper is to thus determine if the child is susceptible to ASD in its nascent stages, which would help streamline the diagnosis process. Based on our results, Logistic Regression gives the highest accuracy for our selected dataset.},
journal = {SN Comput. Sci.},
month = jul,
numpages = {9},
keywords = {Autism spectrum disorder, Machine learning, Dataset, Preprocessing, Encoding, SVM, KNN, Random forest, Logistic regression, Confusion matrix, Precision, Recall, F1 score, Accuracy}
}

@article{10.1016/j.jbi.2020.103655,
author = {Markus, Aniek F. and Kors, Jan A. and Rijnbeek, Peter R.},
title = {The role of explainability in creating trustworthy artificial intelligence for health care: A comprehensive survey of the terminology, design choices, and evaluation strategies},
year = {2021},
issue_date = {Jan 2021},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {113},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2020.103655},
doi = {10.1016/j.jbi.2020.103655},
journal = {J. of Biomedical Informatics},
month = jan,
numpages = {11},
keywords = {Post-hoc explanation, Explainable modelling, Interpretability, Trustworthy artificial intelligence, Explainable artificial intelligence}
}

@article{10.1145/3451179,
author = {Huang, Guyue and Hu, Jingbo and He, Yifan and Liu, Jialong and Ma, Mingyuan and Shen, Zhaoyang and Wu, Juejian and Xu, Yuanfan and Zhang, Hengrui and Zhong, Kai and Ning, Xuefei and Ma, Yuzhe and Yang, Haoyu and Yu, Bei and Yang, Huazhong and Wang, Yu},
title = {Machine Learning for Electronic Design Automation: A Survey},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3451179},
doi = {10.1145/3451179},
abstract = {With the down-scaling of CMOS technology, the design complexity of very large-scale integrated is increasing. Although the application of machine learning (ML) techniques in electronic design automation (EDA) can trace its history back to the 1990s, the recent breakthrough of ML and the increasing complexity of EDA tasks have aroused more interest in incorporating ML to solve EDA tasks. In this article, we present a comprehensive review of existing ML for EDA studies, organized following the EDA hierarchy.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jun,
articleno = {40},
numpages = {46},
keywords = {neural networks, machine learning, Electronic design automation}
}

@inproceedings{10.1007/978-3-030-68799-1_19,
author = {Khan, Hanif and Asghar, Muhammad Usama and Asghar, Muhammad Zubair and Srivastava, Gautam and Maddikunta, Praveen Kumar Reddy and Gadekallu, Thippa Reddy},
title = {Fake Review Classification Using Supervised Machine Learning},
year = {2021},
isbn = {978-3-030-68798-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68799-1_19},
doi = {10.1007/978-3-030-68799-1_19},
abstract = {The revolution of social media has propelled the online community to take advantage of online reviews for not only posting feedback about the products, services, and other issues but also assists individuals to analyze user’s feedback for making purchase decisions, and companies for improving the quality of manufactured goods. However, the propagation of fake reviews has become an alarming issue, as it deceives online users while purchasing and promotes or demotes the reputation of competing brands. In this work, we propose a supervised learning-based technique for the detection of fake reviews from the online textual content. The study employs machine learning classifiers for bifurcating fake and genuine reviews. Experimental results are evaluated against different evaluation measures and the performance of the proposed system is compared with baseline works.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part IV},
pages = {269–288},
numpages = {20},
keywords = {Machine learning, Fake reviews, Social networks}
}

@inproceedings{10.1145/3382026.3431246,
author = {Kenner, Andy},
title = {Model-Based Evaluation of Vulnerabilities in Software Systems},
year = {2020},
isbn = {9781450375702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382026.3431246},
doi = {10.1145/3382026.3431246},
abstract = {Vulnerabilities in software systems result from faults, which occur at different stages in a software's life cycle, for example, in the design (i.e., undesired feature-interactions), the development (i.e., buffer overflows), or the operation (i.e., configuration errors). Various databases provide detailed information about vulnerabilities in software systems or the way to exploit it, but face severe limitations. The information is scattered across these databases, fluctuates in quality and granularity, and provides only an insight into a single vulnerability per entry. Even for a single software system it is challenging for any security-related stakeholder to determine the threat level, which consists of all vulnerabilities of the software system and its environment (i.e., operating system). Manual vulnerability management is feasible only to a limited extend if we want to identify all configurations that are affected by vulnerabilities, or determine a system's threat level and the resulting risk we have to deal with. For variant-rich systems, we also have to deal with variability, allowing different stakeholders to understand the threats to their particular setup. To deal with this variability, we propose vulnerability feature models, which offer a homogeneous view on all vulnerabilities of a software system. These models and the resulting analyses offer advantages in many disciplines of the vulnerability management process. In this paper, we report the research plan for our project, in which we focus on the model-based evaluation of vulnerabilities. This includes research objectives that take into account the design of vulnerability feature models, their application in the process of vulnerability management, and the impact of evolution, discovery, and verification of vulnerabilities.},
booktitle = {Proceedings of the 24th ACM International Systems and Software Product Line Conference - Volume B},
pages = {112–119},
numpages = {8},
keywords = {Vulnerability Analysis and Management, Vulnerability, Variability Model, Feature Model, Exploit},
location = {Montreal, QC, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3460620.3460738,
author = {Manasrah, Anood and Alkayem, Aisha and Qasaimeh, Malik and Nofal, Samer},
title = {Assessment of Machine Learning Security: The Case of Healthcare Data},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460620.3460738},
doi = {10.1145/3460620.3460738},
abstract = {With technological advances and the use of the Internet everywhere, And the widespread use of machine learning has become important to pay attention to security in all areas of life, especially in the healthcare field, many concerns have arisen regarding the security of patient confidential data in health systems. As it became possible to change patient data, which would lead to a change in data accuracy or to data theft, which would lead to a violation of the safety system in the field of health care. In this paper, a health system was studied in a hospital in Jordan after collecting information on 769 records for pregnant diabetics. The analysis used Python to test the accuracy of this information and improve the performance of the model being created using machine learning algorithms, including decision trees and random forests. Since patient information in any health system has been exposed to many threats and weaknesses, the main goal was to reduce them, and obtain accurate information with good performance and excellent quality, to avoid compromising health rights and data protection for patients.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {91–98},
numpages = {8},
keywords = {threats and vulnerabilities, pregnant diabetes, machine learning, algorithm tuning, Security, Python},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@article{10.1016/j.eswa.2020.114195,
author = {Cebollada, Sergio and Pay\'{a}, Luis and Flores, Mar\'{\i}a and Peidr\'{o}, Adri\'{a}n and Reinoso, Oscar},
title = {A state-of-the-art review on mobile robotics tasks using artificial intelligence and visual data},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114195},
doi = {10.1016/j.eswa.2020.114195},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {21},
keywords = {Exploration, SLAM, Navigation, Localization, Mapping, Artificial intelligence, Visual information, Mobile robotics}
}

@inproceedings{10.1145/3233027.3233033,
author = {Li, Yang and Schulze, Sandro and Saake, Gunter},
title = {Reverse engineering variability from requirement documents based on probabilistic relevance and word embedding},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233033},
doi = {10.1145/3233027.3233033},
abstract = {Feature and variability extraction from different artifacts is an indispensable activity to support systematic integration of single software systems and Software Product Line (SPL). Beyond manually extracting variability, a variety of approaches, such as feature location in source code and feature extraction in requirements, has been proposed to provide an automatic identification of features and their variation points. Compared with source code, requirements contain more complete variability information and provide traceability links to other artifacts from early development phases. In this paper, we propose a method to automatically extract features and relationships based on a probabilistic relevance and word embedding. In particular, our technique consists of three steps: First, we apply word2vec to obtain a prediction model, which we use to determine the word level similarity of requirements. Second, based on word level similarity and the significance of a word in a domain, we compute the requirements level similarity using probabilistic relevance. Third, we adopt hierarchical clustering to group features and we define four criteria to detect variation points between identified features. We perform a case study to evaluate the usability and robustness of our method and to compare it with the results of other related approaches. Initial results reveal that our approach identifies the majority of features correctly and also extracts variability information with reasonable accuracy.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {121–131},
numpages = {11},
keywords = {variability extraction, software product lines, reverse engineering, requirement documents, feature identification},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s00146-020-00985-1,
author = {\v{S}abi\'{c}, Edin and Keeley, David and Henderson, Bailey and Nannemann, Sara},
title = {Healthcare and anomaly detection: using machine learning to predict anomalies in heart rate data},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {36},
number = {1},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-020-00985-1},
doi = {10.1007/s00146-020-00985-1},
abstract = {The application of machine learning algorithms to healthcare data can enhance patient care while also reducing healthcare worker cognitive load. These algorithms can be used to detect anomalous physiological readings, potentially leading to expedited emergency response or new knowledge about the development of a health condition. However, while there has been much research conducted in assessing the performance of anomaly detection algorithms on well-known public datasets, there is less conceptual comparison across unsupervised and supervised performance on physiological data. Moreover, while heart rate data are both ubiquitous and noninvasive, there has been little research specifically for anomaly detection of this type of data. Considering that heart rate data are indicative of both potential health complications and an individual’s physical activity, this is a rich source of largely overlooked data. To this end, we employed and evaluated five machine learning algorithms, two of which are unsupervised and the remaining three supervised, in their ability to detect anomalies in heart rate data. These algorithms were then evaluated on real heart rate data. Findings supported the effectiveness of local outlier factor and random forests algorithms in the task of heart rate anomaly detection, as each model generalized well from their training on simulated heart rate data to real world heart rate data. Furthermore, results support that simulated data can help configure algorithms to a degree of performance when real labeled data are not available and that this type of learning might be especially helpful in initial deployment of a system without prior data.},
journal = {AI Soc.},
month = mar,
pages = {149–158},
numpages = {10},
keywords = {Machine learning, Heart rate, Healthcare, Anomaly detection}
}

@inproceedings{10.1145/3336294.3336306,
author = {Ghamizi, Salah and Cordy, Maxime and Papadakis, Mike and Traon, Yves Le},
title = {Automated Search for Configurations of Convolutional Neural Network Architectures},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336306},
doi = {10.1145/3336294.3336306},
abstract = {Convolutional Neural Networks (CNNs) are intensively used to solve a wide variety of complex problems. Although powerful, such systems require manual configuration and tuning. To this end, we view CNNs as configurable systems and propose an end-to-end framework that allows the configuration, evaluation and automated search for CNN architectures. Therefore, our contribution is threefold. First, we model the variability of CNN architectures with a Feature Model (FM) that generalizes over existing architectures. Each valid configuration of the FM corresponds to a valid CNN model that can be built and trained. Second, we implement, on top of Tensorflow, an automated procedure to deploy, train and evaluate the performance of a configured model. Third, we propose a method to search for configurations and demonstrate that it leads to good CNN models. We evaluate our method by applying it on image classification tasks (MNIST, CIFAR-10) and show that, with limited amount of computation and training, our method can identify high-performing architectures (with high accuracy). We also demonstrate that we outperform existing state-of-the-art architectures handcrafted by ML researchers. Our FM and framework have been released to support replication and future research.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {119–130},
numpages = {12},
keywords = {neural architecture search, feature model, configuration search, NAS, AutoML},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3307630.3342419,
author = {Ghofrani, Javad and Kozegar, Ehsan and Bozorgmehr, Arezoo and Soorati, Mohammad Divband},
title = {Reusability in Artificial Neural Networks: An Empirical Study},
year = {2019},
isbn = {9781450366687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307630.3342419},
doi = {10.1145/3307630.3342419},
abstract = {Machine learning, especially deep learning has aroused interests of researchers and practitioners for the last few years in development of intelligent systems such as speech, natural language, and image processing. Software solutions based on machine learning techniques attract more attention as alternatives to conventional software systems. In this paper, we investigate how reusability techniques are applied in implementation of artificial neural networks (ANNs). We conducted an empirical study with an online survey among experts with experience in developing solutions with ANNs. We analyze the feedback of more than 100 experts to our survey. The results show existing challenges and some of the applied solutions in an intersection between reusability and ANNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B},
pages = {122–129},
numpages = {8},
keywords = {systematic reuse, survey, reusability, empirical study, artificial neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/2791060.2791103,
author = {Mazo, Ra\'{u}l and Mu\~{n}oz-Fern\'{a}ndez, Juan C. and Rinc\'{o}n, Luisa and Salinesi, Camille and Tamura, Gabriel},
title = {VariaMos: an extensible tool for engineering (dynamic) product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791103},
doi = {10.1145/2791060.2791103},
abstract = {This paper presents the new release of VariaMos, a Java-based tool for defining variability modeling languages, modeling (dynamic) product lines and cyber-physical self-adaptive systems, and supporting automated verification, analysis, configuration and simulation of these models. In particular, we describe the characteristics of this new version regarding its first release: (1) the capability to create languages for modeling systems with variability, even with different views; (2) the capability to use the created language to model (dynamic) product lines; (3) the capability to analyze and configure these models according to the changing context and requirements; and (4) the capability to execute them over several simulation scenarios. Finally, we show how to use VariaMos with an example, and we compare it with other tools found in the literature.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {374–379},
numpages = {6},
keywords = {variability, tool, simulation, product line engineering, dynamic product line models, constraints},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.jss.2021.111031,
author = {Giray, G\"{o}rkem},
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111031},
doi = {10.1016/j.jss.2021.111031},
journal = {J. Syst. Softw.},
month = oct,
numpages = {35},
keywords = {Systematic literature review, Deep learning, Machine learning, Software process, Software development, Software engineering}
}

@inproceedings{10.1145/3340531.3412737,
author = {Zhou, Baifan and Svetashova, Yulia and Byeon, Seongsu and Pychynski, Tim and Mikut, Ralf and Kharlamov, Evgeny},
title = {Predicting Quality of Automated Welding with Machine Learning and Semantics: A Bosch Case Study},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412737},
doi = {10.1145/3340531.3412737},
abstract = {Manufacturing of car bodies heavily relies on demanding welding processes of joining body parts together that introduce thousands of joining welding spots in each car. Quality monitoring for these spots impacts production efficiency and cost. In this paper we develop an ML pipeline to predict the spot quality before the actual welding happens. This pipeline is based on a Feature Engineering~(FE) approach to manually design features using domain knowledge. We evaluated the pipeline with two datasets from industrial plants, achieving very promising results with prediction errors around 2%. Then, we develop an approach to semantically enhance FE pipelines in order to automate the ML process without compromising the prediction accuracy and to facilitate generalisation and transfer of FE-based models to other datasets and processes. Our ML pipeline has been deployed offline on various Bosch manufacturing datasets in a controlled environment since early 2019 and evaluated.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {2933–2940},
numpages = {8},
keywords = {semantic technology, resistance spot welding, quality monitoring, machine learning},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@inproceedings{10.1145/3380446.3430643,
author = {Krishnamurthy, Prashanth and Basak Chowdhury, Animesh and Tan, Benjamin and Khorrami, Farshad and Karri, Ramesh},
title = {Explaining and Interpreting Machine Learning CAD Decisions: An IC Testing Case Study},
year = {2020},
isbn = {9781450375191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380446.3430643},
doi = {10.1145/3380446.3430643},
abstract = {We provide a methodology to explain and interpret machine learning decisions in Computer-Aided Design (CAD) flows. We demonstrate the efficacy of the methodology to the VLSI testing case. Such a tool will provide designers with insight into the "black box" machine learning models/classifiers through human readable sentences based on normally understood design rules or new design rules. The methodology builds on an intrinsically explainable, rule-based ML framework, called Sentences in Feature Subsets (SiFS), to mine human readable decision rules from empirical data sets. SiFS derives decision rules as compact Boolean logic sentences involving subsets of features in the input data. The approach is applied to test point insertion problem in circuits and compared to the ground truth and traditional design rules.},
booktitle = {Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD},
pages = {129–134},
numpages = {6},
keywords = {test-point insertion, interpretable machine learning, IC testing},
location = {Virtual Event, Iceland},
series = {MLCAD '20}
}

@inproceedings{10.5555/1885639.1885642,
author = {Bagheri, Ebrahim and Di Noia, Tommaso and Ragone, Azzurra and Gasevic, Dragan},
title = {Configuring software product line feature models based on Stakeholders' soft and hard requirements},
year = {2010},
isbn = {3642155782},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Feature modeling is a technique for capturing commonality and variability. Feature models symbolize a representation of the possible application configuration space, and can be customized based on specific domain requirements and stakeholder goals. Most feature model configuration processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called P(N). Furthermore, we formalize the representation of soft constraints in fuzzy P(N) and explain how semi-automated feature model configuration is performed. The model configuration derivation process that we propose respects the soundness and completeness properties.},
booktitle = {Proceedings of the 14th International Conference on Software Product Lines: Going Beyond},
pages = {16–31},
numpages = {16},
location = {Jeju Island, South Korea},
series = {SPLC'10}
}

@phdthesis{10.5555/AAI28540512,
author = {Weidner, Luke Morgan},
advisor = {Gabriel, Walton,},
title = {Generalized Machine-Learning-Based Point Cloud Classification for Natural and Cut Slopes},
year = {2021},
isbn = {9798460412105},
publisher = {Colorado School of Mines},
address = {USA},
abstract = {Processing and interpretation of 3D point cloud datasets is often a limiting factor for their use in geohazard engineering projects, prompting a growing interest in supervised Machine Learning (ML) algorithms to automatically extract objects of interest. Objects might include rock outcrops, vegetation, components of vegetation, or other natural features. However, ML methods are subject to several well-known limitations that require a significant degree of expertise on the part of the user to address. Two key issues include the "generalization gap", which describes the often significant performance difference between validation and testing, and the danger of ascribing a degree of infallibility and superior performance to black-box ML algorithms where none exists in reality. Geological engineering studies to date have not considered these issues in any detail, despite their critical importance for successful, justified models where lives could be at stake. This thesis provides a comprehensive critical evaluation of using ML-based techniques to interpret point clouds of natural and cut slopes consisting of a variety of materials, focused on the two issues mentioned above.A first-of-its-kind database of 12 manually annotated lidar and photogrammetry datasets is compiled, and ML models are developed to accurately classify lidar and photogrammetry derived point clouds. Next, a variety of tests are performed to empirically quantify the generalization gap. Finally, the framework is applied to a landslide monitoring case study, where ML is used to automatically extract tree trunks.Generalization test results show that many factors contribute to the generalization gap, including feature engineering, lighting conditions, geologic setting, geomorphology, point density, and occlusions. Due to these factors, in some cases up to 50% or more of possible model configurations produce unacceptable classification results. However, it is shown that making informed choices while building and interpreting a classifier can greatly improve the likelihood of success. Thus ML is not a panacea, but it is undoubtedly a valuable addition to the geological engineer's toolbox.},
note = {AAI28540512}
}

@article{10.1016/j.compbiomed.2021.104210,
author = {Suri, Jasjit S. and Agarwal, Sushant and Gupta, Suneet K. and Puvvula, Anudeep and Biswas, Mainak and Saba, Luca and Bit, Arindam and Tandel, Gopal S. and Agarwal, Mohit and Patrick, Anubhav and Faa, Gavino and Singh, Inder M. and Oberleitner, Ronald and Turk, Monika and Chadha, Paramjit S. and Johri, Amer M. and Miguel Sanches, J. and Khanna, Narendra N. and Viskovic, Klaudija and Mavrogeni, Sophie and Laird, John R. and Pareek, Gyan and Miner, Martin and Sobel, David W. and Balestrieri, Antonella and Sfikakis, Petros P. and Tsoulfas, George and Protogerou, Athanasios and Misra, Durga Prasanna and Agarwal, Vikas and Kitas, George D. and Ahluwalia, Puneet and Teji, Jagjit and Al-Maini, Mustafa and Dhanjil, Surinder K. and Sockalingam, Meyypan and Saxena, Ajit and Nicolaides, Andrew and Sharma, Aditya and Rathore, Vijay and Ajuluchukwu, Janet N.A. and Fatemi, Mostafa and Alizad, Azra and Viswanathan, Vijay and Krishnan, P.K. and Naidu, Subbaram},
title = {A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence},
year = {2021},
issue_date = {Mar 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {130},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104210},
doi = {10.1016/j.compbiomed.2021.104210},
journal = {Comput. Biol. Med.},
month = mar,
numpages = {21},
keywords = {COVID-19, ARDS, Comorbidity, Medical imaging, CT, X-ray, US, Artificial intelligence, Deep learning, Machine learning, Transfer learning, Ultrasound}
}

@inproceedings{10.1145/3461001.3471146,
author = {Horcas, Jose-Miguel and Galindo, Jos\'{e} A. and Heradio, Ruben and Fernandez-Amoros, David and Benavides, David},
title = {Monte Carlo tree search for feature model analyses: a general framework for decision-making},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471146},
doi = {10.1145/3461001.3471146},
abstract = {The colossal solution spaces of most configurable systems make intractable their exhaustive exploration. Accordingly, relevant analyses remain open research problems. There exist analyses alternatives such as SAT solving or constraint programming. However, none of them have explored simulation-based methods. Monte Carlo-based decision making is a simulation-based method for dealing with colossal solution spaces using randomness. This paper proposes a conceptual framework that tackles various of those analyses using Monte Carlo methods, which have proven to succeed in vast search spaces (e.g., game theory). Our general framework is described formally, and its flexibility to cope with a diversity of analysis problems is discussed (e.g., finding defective configurations, feature model reverse engineering or getting optimal performance configurations). Additionally, we present a Python implementation of the framework that shows the feasibility of our proposal. With this contribution, we envision that different problems can be addressed using Monte Carlo simulations and that our framework can be used to advance the state of the art a step forward.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {190–201},
numpages = {12},
keywords = {variability modeling, software product lines, monte carlo tree search, feature models, configurable systems},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1007/s10664-021-09994-0,
author = {Vitui, Arthur and Chen, Tse-Hsun (Peter)},
title = {MLASP: Machine learning assisted capacity planning: An industrial experience report},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09994-0},
doi = {10.1007/s10664-021-09994-0},
abstract = {In industrial environments it is critical to find out the capacity of a system and plan for a deployment layout that meets the production traffic demands. The system capacity is influenced by both the performance of the system’s constituting components and the physical environment setup. In a large system, the configuration parameters of individual components give the flexibility to developers and load test engineers to tune system performance without changing the source code. However, due to the large search space, estimating the capacity of the system given different configuration values is a challenging and costly process. In this paper, we propose an approach, called MLASP, that uses machine learning models to predict the system key performance indicators (i.e., KPIs), such as throughput, given a set of features made off configuration parameter values, including server cluster setup, to help engineers in capacity planning for production environments. Under the same load, we evaluate MLASP on two large-scale mission-critical enterprise systems developed by Ericsson and on one open-source system. We find that: 1) MLASP can predict the system throughput with a very high accuracy. The difference between the predicted and the actual throughput is less than 1%; and 2) By using only a small subset of the training data (e.g., 3% of the entire data for the open-source system), MLASP can still predict the throughput accurately. We also document our experience of successfully integrating the approach into an industrial setting. In summary, this paper highlights the benefits and potential of using machine learning models to assist load test engineers in capacity planning.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {27},
keywords = {Deep learning, Machine learning, Performance testing, Capacity testing, Load testing}
}

@article{10.1007/s10639-021-10570-8,
author = {Gresse von Wangenheim, Christiane and Hauck, Jean C. R. and Pacheco, Fernando S. and Bertonceli Bueno, Matheus F.},
title = {Visual tools for teaching machine learning in K-12: A ten-year systematic mapping},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1360-2357},
url = {https://doi.org/10.1007/s10639-021-10570-8},
doi = {10.1007/s10639-021-10570-8},
abstract = {Teaching Machine Learning in school helps students to be better prepared for a society rapidly changing due to the impact of Artificial Intelligence. This requires age-appropriate tools that allow students to develop a comprehensive understanding of Machine Learning in order to become creators of smart solutions. Following the trend of visual languages for introducing algorithms and programming in K-12, we present a ten-year systematic mapping of emerging visual tools that support the teaching of Machine Learning at this educational stage and analyze the tools concerning their educational characteristics, support for the development of ML models as well as their deployment and how the tools have been developed and evaluated. As a result, we encountered 16 tools targeting students mostly as part of short duration extracurricular activities. Tools mainly support the interactive development of ML models for image recognition tasks using supervised learning covering basic steps of the ML process. Being integrated into popular block-based programming languages (primarily Scratch and App Inventor), they also support the deployment of the created ML models as part of games or mobile applications. Findings indicate that the tools can effectively leverage students’ understanding of Machine Learning, however, further studies regarding the design of the tools concerning educational aspects are required to better guide their effective adoption in schools and their enhancement to support the learning process more comprehensively.},
journal = {Education and Information Technologies},
month = sep,
pages = {5733–5778},
numpages = {46},
keywords = {Visual tool, Machine learning, Computing education, K-12}
}

@inproceedings{10.1007/978-3-030-68007-7_6,
author = {Rjoob, Khaled and Bond, Raymond and Finlay, Dewar and McGilligan, Victoria and Leslie, Stephen J. and Rababah, Ali and Iftikhar, Aleeha and Guldenring, Daniel and Knoery, Charles and McShane, Anne and Peace, Aaron},
title = {Towards Explainable Artificial Intelligence and Explanation User Interfaces to Open the ‘Black Box’ of Automated ECG Interpretation},
year = {2020},
isbn = {978-3-030-68006-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68007-7_6},
doi = {10.1007/978-3-030-68007-7_6},
abstract = {This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system.},
booktitle = {Advanced Visual Interfaces. Supporting Artificial Intelligence and Big Data Applications: AVI 2020 Workshops, AVI-BDA and ITAVIS, Ischia, Italy, June 9, 2020 and September 29, 2020, Revised Selected Papers},
pages = {96–108},
numpages = {13},
keywords = {Explainable AI (XAI), ECG interpretation, Artificial intelligence (AI)}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00034,
author = {Lwakatare, Lucy Ellen and R\r{a}nge, Ellinor and Crnkovic, Ivica and Bosch, Jan},
title = {On the experiences of adopting automated data validation in an industrial machine learning project},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00034},
doi = {10.1109/ICSE-SEIP52600.2021.00034},
abstract = {Background: Data errors are a common challenge in machine learning (ML) projects and generally cause significant performance degradation in ML-enabled software systems. To ensure early detection of erroneous data and avoid training ML models using bad data, research and industrial practice suggest incorporating a data validation process and tool in ML system development process.Aim: The study investigates the adoption of a data validation process and tool in industrial ML projects. The data validation process demands significant engineering resources for tool development and maintenance. Thus, it is important to identify the best practices for their adoption especially by development teams that are in the early phases of deploying ML-enabled software systems.Method: Action research was conducted at a large-software intensive organization in telecommunications, specifically within the analytics R&amp;D organization for an ML use case of classifying faults from returned hardware telecommunication devices.Results: Based on the evaluation results and learning from our action research, we identified three best practices, three benefits, and two barriers to adopting the data validation process and tool in ML projects. We also propose a data validation framework (DVF) for systematizing the adoption of a data validation process.Conclusions: The results show that adopting a data validation process and tool in ML projects is an effective approach of testing ML-enabled software systems. It requires having an overview of the level of data (feature, dataset, cross-dataset, data stream) at which certain data quality tests can be applied.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {248–257},
numpages = {10},
keywords = {software engineering, machine learning, data validation, data quality, data errors},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1007/s00521-021-06438-0,
author = {Selvam, Santhosh Kumar and Rajendran, Chandrasekharan},
title = {tofee-tree: automatic feature engineering framework for modeling trend-cycle in time series forecasting},
year = {2021},
issue_date = {Jun 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06438-0},
doi = {10.1007/s00521-021-06438-0},
abstract = {Most time series forecasting tasks using Artificial Neural Networks (ANNs) relegate trend-cycle modeling to a simple preprocessing step. In this work, we propose an automatic feature engineering framework for modeling the trend-cycle (tofee-tree) in time series forecasting. The first stage of the framework automatically creates over 286 deterministic linear and nonlinear engineered features to model the trend-cycle. These features are based only on the time of observation and length of the time series, making them domain-agnostic. In the second stage of the framework, a SHapley Additive exPlanations&nbsp;(SHAP)—based feature selection procedure using Light Gradient Boosted Machine (LightGBM) selects the most relevant features. These relevant features can be used for forecasting with ANNs in addition to the auto-regressive lags. Two popular ANNs—Multi-Layer Perceptron (MLP) and Long Short Term Memory network (LSTM) are used to evaluate our proposed tofee-tree framework. Comparisons against two empirical studies using the M3 competition dataset show that the proposed framework improved the overall Symmetric Mean Absolute Percentage Error (SMAPE) in the one-step, medium- and long-term. The relative improvement in one-step SMAPE is 3% for MLP and 23% for LSTM. We also show that the residual seasonality left after deseasonalization can be modeled using the tofee-tree framework.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {11563–11582},
numpages = {20},
keywords = {Long short term memory network, Multi-layer perceptron, Time series forecasting, Feature engineering}
}

@inproceedings{10.1007/978-3-030-46133-1_54,
author = {Borrison, Reuben and Kl\"{o}pper, Benjamin and Saini, Sunil},
title = {Industrial Event Log Analyzer - Self-service Data Mining for Domain Experts},
year = {2019},
isbn = {978-3-030-46132-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-46133-1_54},
doi = {10.1007/978-3-030-46133-1_54},
abstract = {Industrial applications of machine learning rely heavily on deep domain knowledge that data scientist and machine learning expert usually do not have. Iterative and time-consuming communication between machine learning expert and domain expert are the consequence. In this demo, we introduce a semi-functional mock-up that demonstrates how a system can guide domain users through a machine learning process if the scope of problem and data type are narrowed done.},
booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, W\"{u}rzburg, Germany, September 16–20, 2019, Proceedings, Part III},
pages = {794–798},
numpages = {5},
keywords = {Data mining tools, Domain experts, Industrial use case},
location = {W\"{u}rzburg, Germany}
}

@article{10.1007/s00521-021-05749-6,
author = {Karlos, Stamatis and Aridas, Christos and Kanas, Vasileios G. and Kotsiantis, Sotiris},
title = {Classification of acoustical signals by combining active learning strategies with semi-supervised learning schemes},
year = {2021},
issue_date = {Jan 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05749-6},
doi = {10.1007/s00521-021-05749-6},
abstract = {In real-world cases, handling both labeled and unlabeled data has raised the interest of several Data Scientists and Machine Learning engineers, leading to several demonstrations that apply data-augmenting approaches in order to obtain a robust and, at the same time, accurate enough learning behavior. The main reason is the existence of much unlabeled data that are ignored by conventional supervised approaches, reducing the chance of enriching the final formatted hypothesis. However, the majority of the proposed methods that operate using both kinds of these data are oriented toward exploiting only one category of these algorithms, without combining their strategies. Since the most popular of them regarding the classification task are Active and Semi-supervised Learning approaches, we aim to design a framework that combines both of them trying to fuse their advantages during the main core of the learning process. Thus, we conduct an empirical evaluation of such a combinatory approach over three problems, which stem from various fields but are all tackled through the use of acoustical signals, operating under the pool-based scenario: gender identification, emotion detection and automatic speaker recognition. Into the proposed combinatory framework, which operates under training sets with small cardinality, our results prove the benefits of adopting such kind of semi-automated approaches regarding both the achieved predictive correctness when reduced consumption of resources takes place, as well as the smoothness of the learning convergence. Several learners have been examined for reaching to more general conclusions, and a variant of self-training scheme has been also examined.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {3–20},
numpages = {18},
keywords = {Combined learning framework, Self-training scheme, Active learning queries, Acoustical signal classification, Data augmentation techniques, Semi-automated approaches}
}

@inproceedings{10.1007/978-3-030-97774-0_12,
author = {Saeed, Amr M. H. and Wang, Danghui and Alnedhari, Hamas A. M. and Mei, Kuizhi and Wang, Jihe},
title = {A Survey of Machine Learning and Deep Learning Based DGA Detection Techniques},
year = {2022},
isbn = {978-3-030-97773-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-97774-0_12},
doi = {10.1007/978-3-030-97774-0_12},
abstract = {Botnets are the most commonly used mechanisms for current cyberattacks such as DDoS, ransomware, email spamming, phishing data, etc. Botnets deploy the Domain Generation Algorithm (DGA) to conceal domain names of Command &amp; Control (C&amp;C) servers by generating several fake domain names. A sophisticated DGA can circumvent the traditional detection methods and successfully communicate with the C&amp;C. Several detection methods like DNS sinkhole, DNS filtering and DNS logs analysis have been intensively studied to neutralize DGA. However, these methods have a high noise rate and require a massive amount of computational resources. To tackle this issue, several researchers leveraged Machine learning (ML) and Deep Learning (DL) algorithms to develop lightweight and cost-effective detection methods. The purpose of this paper is to investigate and evaluate the DGA detection methods based on ML/DL published in the last three years. After analyzing the relevant literature strengths and limitations, we conclude that low detection speed, encrypted DNS sensitivity, data imbalance sensitivity, and low detection accuracy with variant or unknown DGA are most likely the current research trends and opportunities. As far as we know, this survey is the first of its kind to discuss DGA detection techniques based on ML/DL in-depth, as well as analysis of their limitations and future trends.},
booktitle = {Smart Computing and Communication: 6th International Conference, SmartCom 2021, New York City, NY, USA, December 29–31, 2021, Proceedings},
pages = {133–143},
numpages = {11},
keywords = {Botnet detection, DGA detection, Cybersecurity challenges, Domain generation algorithm},
location = {New York, NY, USA}
}

@article{10.1016/j.cviu.2018.08.003,
author = {Redondo-Cabrera, Carolina and Lopez-Sastre, Roberto},
title = {Unsupervised learning from videos using temporal coherency deep networks},
year = {2019},
issue_date = {Feb 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {179},
number = {C},
issn = {1077-3142},
url = {https://doi.org/10.1016/j.cviu.2018.08.003},
doi = {10.1016/j.cviu.2018.08.003},
journal = {Comput. Vis. Image Underst.},
month = feb,
pages = {79–89},
numpages = {11},
keywords = {41A05, 41A10, 65D05, 65D17, Unsupervised learning, Action discovery, Action recognition, Object recognition, Deep learning}
}

@inproceedings{10.1145/3233027.3236404,
author = {Gazzillo, Paul and Koc, Ugur and Nguyen, ThanhVu and Wei, Shiyi},
title = {Localizing configurations in highly-configurable systems},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3236404},
doi = {10.1145/3233027.3236404},
abstract = {The complexity of configurable systems has grown immensely, and it is only getting more complex. Such systems are a challenge for software testing and maintenance, because bugs and other defects can and do appear in any configuration. One common requirement for many development tasks is to identify the configurations that lead to a given defect or some other program behavior. We distill this requirement down to a challenge question: given a program location in a source file, what are valid configurations that include the location? The key obstacle is scalability. When there are thousands of configuration options, enumerating all combinations is exponential and infeasible. We provide a set of target programs of increasing difficulty and variations on the challenge question so that submitters of all experience levels can try out solutions. Our hope is to engage the community and stimulate new and interesting approaches to the problem of analyzing configurations.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {269–273},
numpages = {5},
keywords = {configurations, program analysis, testing, variability},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1007/978-3-030-90785-3_16,
author = {Wang, Baoping and Wang, Wennan and Zhu, Linkai and Liu, Wenjian},
title = {Research on Cross-Project Software Defect Prediction Based on Machine Learning},
year = {2021},
isbn = {978-3-030-90784-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90785-3_16},
doi = {10.1007/978-3-030-90785-3_16},
abstract = {In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.},
booktitle = {Advances in Web-Based Learning – ICWL 2021: 20th International Conference, ICWL 2021, Macau, China, November 13–14, 2021, Proceedings},
pages = {160–165},
numpages = {6},
keywords = {Machine learning, Software defect prediction model, Metric},
location = {Macau, China}
}

@article{10.1145/3364222,
author = {Beigi, Ghazaleh and Tang, Jiliang and Liu, Huan},
title = {Social Science–guided Feature Engineering: A Novel Approach to Signed Link Analysis},
year = {2020},
issue_date = {February 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3364222},
doi = {10.1145/3364222},
abstract = {Many real-world relations can be represented by signed networks with positive links (e.g., friendships and trust) and negative links (e.g., foes and distrust). Link prediction helps advance tasks in social network analysis such as recommendation systems. Most existing work on link analysis focuses on unsigned social networks. The existence of negative links piques research interests in investigating whether properties and principles of signed networks differ from those of unsigned networks and mandates dedicated efforts on link analysis for signed social networks. Recent findings suggest that properties of signed networks substantially differ from those of unsigned networks and negative links can be of significant help in signed link analysis in complementary ways. In this article, we center our discussion on a challenging problem of signed link analysis. Signed link analysis faces the problem of data sparsity, i.e., only a small percentage of signed links are given. This problem can even get worse when negative links are much sparser than positive ones as users are inclined more toward positive disposition rather than negative. We investigate how we can take advantage of other sources of information for signed link analysis. This research is mainly guided by three social science theories, Emotional Information, Diffusion of Innovations, and Individual Personality. Guided by these, we extract three categories of related features and leverage them for signed link analysis. Experiments show the significance of the features gleaned from social theories for signed link prediction and addressing the data sparsity challenge.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {11},
numpages = {27},
keywords = {Signed link analysis, data sparsity, diffusion of innovation, emotional information, feature engineering, individual personality, social theory}
}

@article{10.1007/s11042-021-10778-3,
author = {Dami, Sina and Esterabi, Mohammad},
title = {Predicting stock returns of Tehran exchange using LSTM neural network and feature engineering technique},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {13},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-10778-3},
doi = {10.1007/s11042-021-10778-3},
abstract = {Prediction is defined as the expression of events that will occur in the future, before they occur, based on scientific and logical principles and rules. Due to the importance of financial markets for economic activists, prediction in this field has received much attention from scholars. Prediction of the stock market, as one of the largest financial markets can be very profitable to the predictors. The dynamic and complexity of the market has added to its appeal to researchers. To date, many researchers have reported good returns for prediction in this market using neural network methods. In this paper, we attempted to obtain better results on Tehran Stock Exchange by using their findings and by applying the Long Short-Term Memory (LSTM) deep neural network. In the area of feature engineering, we have tried to reduce the number of features using AutoEncoder-based feature selection to improve stock returns and reduce prediction error. To evaluate the proposed method, a return measure that is closer to the real world of stock trading was used. Experimental results showed that using the proposed method yielded a better output with a lower error mean.},
journal = {Multimedia Tools Appl.},
month = may,
pages = {19947–19970},
numpages = {24},
keywords = {AutoEncoder, Long short-term memory (LSTM), Deep neural networks, Feature engineering, Stock return prediction}
}

@inproceedings{10.5555/3306127.3332095,
author = {Zhang, Jianyu and Hao, Jianye and Fogelman-Souli\'{e}, Fran\c{c}oise and Wang, Zan},
title = {Automatic Feature Engineering by Deep Reinforcement Learning},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We present a framework calledLearning Automatic Feature Engineering Machine (LAFEM), which formalizes theFeature Engineering (FE) problem as an optimization problem over aHeterogeneous Transformation Graph (HTG). We propose a Deep Q-learning on HTG to support efficient learning of fine-grained and generalized FE policies that can transfer knowledge of engineering "good" features from a collection of datasets to other unseen datasets.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2312–2314},
numpages = {3},
keywords = {deep learning, feature generation, innovative agents and multiagent applications},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/2934466.2934484,
author = {Vasilevskiy, Anatoly and Chauvel, Franck and Haugen, \O{}ystein},
title = {Toward robust product realisation in software product lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934484},
doi = {10.1145/2934466.2934484},
abstract = {Product derivation is a building process of products from selected features in software product lines (SPLs). Realisation paves the way for automatic product derivation. A realisation defines a mapping between abstract features in a feature tree and their implementation artefacts in a model, and therefore governs the derivation of a new product. We experience that a realisation is not always straightforward and robust against modifications in the model. In the paper, we introduce an approach to build robust realisations. It consists of automated planning techniques and a layered architecture to yield a product. We demonstrate how our approach can leverage modern means of software design, development and validation. We evaluate the approach on a use-case provided by an industry partner and compare our technique to the existing realisation layer in the Base Variability Resolution (BVR) language.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {184–193},
numpages = {10},
keywords = {automated planning, bvr, fragment substitution, model, product derivation, product line, realisation, variation point},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1016/j.compag.2016.08.015,
author = {Bocca, Felipe F. and Rodrigues, Luiz Henrique Antunes},
title = {The effect of tuning, feature engineering, and feature selection in data mining applied to rainfed sugarcane yield modelling},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {128},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2016.08.015},
doi = {10.1016/j.compag.2016.08.015},
abstract = {Data-mining techniques were applied to data from sugarcane production.The impact of different approaches to include weather data was evaluated.The RReliefF algorithm is used to evaluate feature engineering.We evaluated the impact of tuning, feature selection, and feature engineering in error.Sixty-six combinations were evaluated to quantify the impacts on model performance. Crop yield models can assist decision makers within any agro-industrial supply chain, even with regard to decisions that are unrelated to the crop production. Considering the characteristics of the mechanisms and data related to yield, data mining techniques are suitable candidates for modelling. The use of these techniques within a context with feature engineering, feature selection, and proper tuning can further improve performance beyond a simple replacement of multiple linear regression. To evaluate the impact of the different steps in the mentioned context, we evaluated sugarcane (Saccharum spp.) yield modelling with data obtained from a sugarcane mill. For a combination of six techniques, tuning, feature selection, and feature engineering, leading to 66 combinations, we assessed final model performance. Average performance across combinations resulted in a mean absolute error (MAE) of 6.42Mgha-1. Using different techniques led to a range of MAE from 4.57 to 8.80Mgha-1 on average. The best and worst performances for an individual model were MAEs of 4.11 and 9.00Mgha-1. Models with lower performance were close to simply predicting yield from the average yield for each number of cuts (MAE of 9.86Mgha-1). Tuning and feature engineering reduced the MAE on average by 1.17 and 0.64Mgha-1, respectively. Feature selection removed nearly 40% of the features but increased the MAE by 0.19Mgha-1. The performance of models was improved by simple strategies such as decomposing weather attributes and detailing fertilisation. Evaluation of feature importance provided by the RReliefF feature selection algorithm was used to explain the performance gains. If empirical models are needed, they will rely on using advanced techniques, but they will need proper algorithm tuning and feature engineering to extract most of the information from datasets. Based on the results, we recommend following the presented workflow for the development of yield models.},
journal = {Comput. Electron. Agric.},
month = oct,
pages = {67–76},
numpages = {10},
keywords = {Artificial neural networks, Boosted regression trees, Machine learning, Random forest, Regression trees, Support vector machines}
}

@article{10.1016/j.infsof.2021.106573,
author = {Zhang, Fanlong and Khoo, Siau-cheng},
title = {An empirical study on clone consistency prediction based on machine learning},
year = {2021},
issue_date = {Aug 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {136},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106573},
doi = {10.1016/j.infsof.2021.106573},
journal = {Inf. Softw. Technol.},
month = aug,
numpages = {16},
keywords = {Code clones, Clone consistent change, Clone consistency prediction, Software maintenance, Machine learning}
}

@inproceedings{10.5555/3504035.3504233,
author = {Takahama, Ryusuke and Baba, Yukino and Shimizu, Nobuyuki and Fujita, Sumio and Kashima, Hisashi},
title = {AdaFlock: adaptive feature discovery for human-in-the-loop predictive modeling},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Feature engineering is the key to successful application of machine learning algorithms to real-world data. The discovery of informative features often requires domain knowledge or human inspiration, and data scientists expend a certain amount of effort into exploring feature spaces. Crowdsourcing is considered a promising approach for allowing many people to be involved in feature engineering; however, there is a demand for a sophisticated strategy that enables us to acquire good features at a reasonable crowdsourcing cost. In this paper, we present a novel algorithm called AdaFlock to efficiently obtain informative features through crowdsourcing. AdaFlock is inspired by AdaBoost, which iteratively trains classifiers by increasing the weights of samples misclassified by previous classifiers. AdaFlock iteratively generates informative features; at each iteration of AdaFlock, crowdsourcing workers are shown samples selected according to the classification errors of the current classifiers and are asked to generate new features that are helpful for correctly classifying the given examples. The results of our experiments conducted using real datasets indicate that AdaFlock successfully discovers informative features with fewer iterations and achieves high classification accuracy.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {198},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@article{10.1016/j.compbiomed.2019.103346,
author = {Alizadehsani, Roohallah and Abdar, Moloud and Roshanzamir, Mohamad and Khosravi, Abbas and Kebria, Parham M. and Khozeimeh, Fahime and Nahavandi, Saeid and Sarrafzadegan, Nizal and Acharya, U. Rajendra},
title = {Machine learning-based coronary artery disease diagnosis: A comprehensive review},
year = {2019},
issue_date = {Aug 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {111},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2019.103346},
doi = {10.1016/j.compbiomed.2019.103346},
journal = {Comput. Biol. Med.},
month = aug,
numpages = {14},
keywords = {CAD diagnosis, Machine learning, Data mining, Feature selection}
}

@inproceedings{10.1609/aaai.v33i01.33017699,
author = {Qian, Hangwei and Pan, Sinno Jialin and Miao, Chunyan},
title = {Distribution-based semi-supervised learning for activity recognition},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33017699},
doi = {10.1609/aaai.v33i01.33017699},
abstract = {Supervised learning methods have been widely applied to activity recognition. The prevalent success of existing methods, however, has two crucial prerequisites: proper feature extraction and sufficient labeled training data. The former is important to differentiate activities, while the latter is crucial to build a precise learning model. These two prerequisites have become bottlenecks to make existing methods more practical. Most existing feature extraction methods highly depend on domain knowledge, while labeled data requires intensive human annotation effort. Therefore, in this paper, we propose a novel method, named Distribution-based Semi-Supervised Learning, to tackle the aforementioned limitations. The proposed method is capable of automatically extracting powerful features with no domain knowledge required, meanwhile, alleviating the heavy annotation effort through semi-supervised learning. Specifically, we treat data stream of sensor readings received in a period as a distribution, and map all training distributions, including labeled and unlabeled, into a reproducing kernel Hilbert space (RKHS) using the kernel mean embedding technique. The RKHS is further altered by exploiting the underlying geometry structure of the unlabeled distributions. Finally, in the altered RKHS, a classifier is trained with the labeled distributions. We conduct extensive experiments on three public datasets to verify the effectiveness of our method compared with state-of-the-art baselines.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {945},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1145/3421937.3421970,
author = {Enayati, Moein and Farahani, Nasibeh Zanjirani and Skubic, Marjorie},
title = {Machine Learning Approach for Motion Artifact Detection in Ballistocardiogram Signals},
year = {2021},
isbn = {9781450375320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421937.3421970},
doi = {10.1145/3421937.3421970},
abstract = {With the current increase in cardiovascular disease and the complexities they create, especially for aging seniors, we are working on in-home and non-invasive techniques to monitor vital signs for early detection of health conditions. Ballistocardiography has shown to be useful for long-term evaluation of myocardial strength. We have previously reported the successful utilization of our hydraulic bed sensor in the estimation of heart rate, sleep posture, and blood pressure. However, bed sensors used in naturalistic settings such as the home are known to be highly susceptible to motion artifacts.In this paper, the state-of-the-art methods for motion artifact detection and reduction are reviewed, and a new sequential machine learning approach is proposed. The proposed method is based on 53 novel features extracted jointly from time and frequency domains for noise detection. Our experiments show detection accuracy and sensitivities as high as 99%. Data were collected in two separate IRB approved data collections, one with 16-minute sequences from 25 subjects in the lab and the other with 5 sets of overnight data collected at a sleep center.},
booktitle = {Proceedings of the 14th EAI International Conference on Pervasive Computing Technologies for Healthcare},
pages = {406–410},
numpages = {5},
keywords = {Ballistocardiography, Feature Engineering, Machine Learning, Motion Artifact Detection},
location = {Atlanta, GA, USA},
series = {PervasiveHealth '20}
}

@article{10.1016/j.compind.2021.103510,
author = {Crawford, Bryn and Sourki, Reza and Khayyam, Hamid and S. Milani, Abbas},
title = {A machine learning framework with dataset-knowledgeability pre-assessment and a local decision-boundary crispness score: An industry 4.0-based case study on composite autoclave manufacturing},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103510},
doi = {10.1016/j.compind.2021.103510},
journal = {Comput. Ind.},
month = nov,
numpages = {13},
keywords = {Machine learning, Anomaly detection, Model explainability, Knowledge engineering, Quality control, Industry 4.0, Composite}
}

@inproceedings{10.1007/978-3-030-52200-1_29,
author = {Brown, Christopher W. and Daves, Glenn Christopher},
title = {Applying Machine Learning to Heuristics for Real Polynomial Constraint Solving},
year = {2020},
isbn = {978-3-030-52199-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-52200-1_29},
doi = {10.1007/978-3-030-52200-1_29},
abstract = {This paper considers the application of machine learning to automatically generating heuristics for real polynomial constraint solvers. We consider a specific choice-point in the algorithm for constructing an open Non-uniform Cylindrical Algebraic Decomposition (NuCAD) for a conjunction of constraints, and we learn a heuristic for making that choice. Experiments demonstrate the effectiveness of the learned heuristic. We hope that the approach we take to learning this heuristic, which is not a natural fit to machine learning, can be applied effectively to other choices in constraint solving algorithms.},
booktitle = {Mathematical Software – ICMS 2020: 7th International Conference, Braunschweig, Germany, July 13–16, 2020, Proceedings},
pages = {292–301},
numpages = {10},
keywords = {Machine learning, Non-linear polynomial constraints},
location = {Braunschweig, Germany}
}

@inproceedings{10.1145/3446132.3446407,
author = {Yan, Jianzhuo and Geng, Yanan and Xu, Hongxia and Yu, Yongchuan and Tan, Shaofeng and He, Dongdong},
title = {Research on Named Entity Recognition in Chinese EMR Based on Semi-Supervised Learning with Dual Selected Strategy},
year = {2021},
isbn = {9781450388115},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3446132.3446407},
doi = {10.1145/3446132.3446407},
abstract = {With the construction of the electronic medical record system, medical record data begins to accumulate, and how to extract essential information from these resources has become a concern. And named entity recognition(NER) is the first step. With the help of doctors, we built a small Chinese electronic medical record annotation corpus. But the NER supervision method requires a large amount of manually labeled corpus. So to reduce the cost of it and make better use of the unlabeled corpus, this paper proposes a semi-supervised Chinese electronic medical record NER model based on ALBERT-BiLSTM-CRF which named CEMRNER. The model uses a Bidirectional Long Short Term Memory network (BiLSTM) and a Conditional Random Field model (CRF) to train the data and introduces the pre-training language model ALBERT to solve the problem of Chinese representation. At the same time, we propose a dual selected strategy to select the high confidence samples and expand the training set. The dual strategy can ensure the accuracy i automatically labeled data, and reduce the error iteration in semi-supervised learning. The experiment and analysis show that compared with other models, this method is more accurate and comprehensive. The precision, recall rate, and F1Score are 85.45%, 87.81%, and 86.61%, respectively. The paper proves that using a semi-supervised method and pre-training ALBERT can improve the accuracy of recognition under the condition of less labeled data.},
booktitle = {Proceedings of the 2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence},
articleno = {80},
numpages = {10},
keywords = {ALBERT, BiLSTM, CRF, dual selected strategy, named entity recognition, semi-supervised learning},
location = {Sanya, China},
series = {ACAI '20}
}

@article{10.1007/s00521-019-04051-w,
author = {Vellido, Alfredo},
title = {The importance of interpretability and visualization in machine learning for applications in medicine and health care},
year = {2020},
issue_date = {Dec 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {24},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04051-w},
doi = {10.1007/s00521-019-04051-w},
abstract = {In a short period of time, many areas of science have made a sharp transition towards data-dependent methods. In some cases, this process has been enabled by simultaneous advances in data acquisition and the development of networked system technologies. This new situation is particularly clear in the life sciences, where data overabundance has sparked a flurry of new methodologies for data management and analysis. This can be seen as a perfect scenario for the use of machine learning and computational intelligence techniques to address problems in which more traditional data analysis approaches might struggle. But, this scenario also poses some serious challenges. One of them is model interpretability and explainability, especially for complex nonlinear models. In some areas such as medicine and health care, not addressing such challenge might seriously limit the chances of adoption, in real practice, of computer-based systems that rely on machine learning and computational intelligence methods for data analysis. In this paper, we reflect on recent investigations about the interpretability and explainability of machine learning methods and discuss their impact on medicine and health care. We pay specific attention to one of the ways in which interpretability and explainability in this context can be addressed, which is through data and model visualization. We argue that, beyond improving model interpretability as a goal in itself, we need to integrate the medical experts in the design of data analysis interpretation strategies. Otherwise, machine learning is unlikely to become a part of routine clinical and health care practice.},
journal = {Neural Comput. Appl.},
month = dec,
pages = {18069–18083},
numpages = {15},
keywords = {Interpretability, Explainability, Machine learning, Visualization, Medicine, Health care}
}

@article{10.1016/j.artmed.2019.101723,
author = {Liu, Tianyu and Fan, Wenhui and Wu, Cheng},
title = {A hybrid machine learning approach to cerebral stroke prediction based on imbalanced medical dataset},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {101},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2019.101723},
doi = {10.1016/j.artmed.2019.101723},
journal = {Artif. Intell. Med.},
month = nov,
numpages = {9},
keywords = {Stroke prediction, Clinical decision, Class imbalance, Hybrid machine learning, AutoHPO}
}

@phdthesis{10.5555/AAI27738093,
author = {Yang, Mingyue and Papernot, Nicolas and Rose, Jonathan and Scardovi, Luca},
advisor = {David, Lie,},
title = {Using Machine Learning to Detect Software Vulnerabilities},
year = {2020},
isbn = {9798662395312},
publisher = {University of Toronto (Canada)},
abstract = {Although automatically finding software vulnerabilities is an important problem, existing code analysis tools are not effective enough at finding vulnerabilities. Lightweight static analysis tools are imprecise, while expensive symbolic execution strategies do not scale. Dynamic analysis techniques such as fuzzing can only verify the executed path in programs, and it is impractical to explore all paths in the program using dynamic analysis.As a result, we propose machine learning to detect software vulnerabilities: this approach is more precise than lightweight static analysis, but less expensive than symbolic execution. We evaluate two machine learning strategies: coarse-grained statistical model and fine-grained raw feature representation. The statistical model requires less data but does not capture all relationships in code. The raw feature representation learns subtle relationships in programs and does not require manual feature engineering, but needs more training samples to work well.},
note = {AAI27738093}
}

@article{10.1007/s10922-020-09566-5,
author = {Safari Khatouni, Ali and Seddigh, Nabil and Nandy, Biswajit and Zincir-Heywood, Nur},
title = {Machine Learning Based Classification Accuracy of Encrypted Service Channels: Analysis of Various Factors},
year = {2021},
issue_date = {Jan 2021},
publisher = {Plenum Press},
address = {USA},
volume = {29},
number = {1},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09566-5},
doi = {10.1007/s10922-020-09566-5},
abstract = {Visibility into network traffic is a key requirement for different security and network monitoring tools. Recent trends in the evolution of Internet traffic present a challenge for traditional traffic analysis methods to achieve accurate classification of Internet traffic including Voice over IP (VoIP), text messaging, video, and audio services among others. A key aspect of this trend is the rising levels of encrypted multiple service channels where the payload is opaque to middleboxes in the network. In such scenarios, traditional approaches such as Deep Packet Inspection (DPI) or examination of Port numbers are unable to achieve the classification accuracy required. This work investigates Machine Learning-based network traffic classifiers as a means of accurately classifying encrypted multiple service channels. The study carries out a thorough study which (i) proposes and evaluates two machine learning-based frameworks for multiple service channels analysis; (ii) undertakes feature engineering to identify the minimum number of features required to obtain high accuracy while reducing the effects of over-fitting; (iii) explores the portability and robustness of the frameworks trained models under different network conditions: location, time, and volume; and (iv) collects and analyzes a large-scale dataset including nine classes of services, for benchmarking purposes.},
journal = {J. Netw. Syst. Manage.},
month = jan,
numpages = {27},
keywords = {Multiple service channels, Encrypted traffic classification, Encrypted traffic analysis, Feature selection, Robust traffic classifier, Machine Learning based traffic analysis}
}

@inproceedings{10.1145/2939672.2939696,
author = {Singh, Gursimran and Srikant, Shashank and Aggarwal, Varun},
title = {Question Independent Grading using Machine Learning: The Case of Computer Program Grading},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939696},
doi = {10.1145/2939672.2939696},
abstract = {Learning supervised models to grade open-ended responses is an expensive process. A model has to be trained for every prompt/question separately, which in turn requires graded samples. In automatic programming evaluation specifically, the focus of this work, this issue is amplified. The models have to be trained not only for every question but also for every language the question is offered in. Moreover, the availability and time taken by experts to create a labeled set of programs for each question is a major bottleneck in scaling such a system. We address this issue by presenting a method to grade computer programs which requires no manually assigned labeled samples for grading responses to a new, unseen question. We extend our previous work [25] wherein we introduced a grammar of features to learn question specific models. In this work, we propose a method to transform those features into a set of features that maintain their structural relation with the labels across questions. Using these features we learn one supervised model, across questions for a given language, which can then be applied to an ungraded response to an unseen question. We show that our method rivals the performance of both, question specific models and the consensus among human experts while substantially outperforming extant ways of evaluating codes. We demonstrate the system single s value by deploying it to grade programs in a high stakes assessment. The learning from this work is transferable to other grading tasks such as math question grading and also provides a new variation to the supervised learning approach.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {263–272},
numpages = {10},
keywords = {MOOC, automatic grading, feature engineering, one-class learning, question independent learning, recruitment, supervised learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3219819.3219838,
author = {Goh, Garrett B. and Siegel, Charles and Vishnu, Abhinav and Hodas, Nathan},
title = {Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for Transferable Chemical Property Prediction},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219838},
doi = {10.1145/3219819.3219838},
abstract = {With access to large datasets, deep neural networks (DNN) have achieved human-level accuracy in image and speech recognition tasks. However, in chemistry data is inherently small and fragmented. In this work, we develop an approach of using rule-based knowledge for training ChemNet, a transferable and generalizable deep neural network for chemical property prediction that learns in a weak-supervised manner from large unlabeled chemical databases. When coupled with transfer learning approaches to predict other smaller datasets for chemical properties that it was not originally trained on, we show that ChemNet's accuracy outperforms contemporary DNN models that were trained using conventional supervised learning. Furthermore, we demonstrate that the ChemNet pre-training approach is equally effective on both CNN (Chemception) and RNN (SMILES2vec) models, indicating that this approach is network architecture agnostic and is effective across multiple data modalities. Our results indicate a pre-trained ChemNet that incorporates chemistry domain knowledge and enables the development of generalizable neural networks for more accurate prediction of novel chemical properties.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {302–310},
numpages = {9},
keywords = {bioinformatics, cheminformatics, computer vision, natural language processing, transfer learning, weak supervised learning},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/3394486.3406706,
author = {Mueller, Jonas and Shi, Xingjian and Smola, Alexander},
title = {Faster, Simpler, More Accurate: Practical Automated Machine Learning with Tabular, Text, and Image Data},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3406706},
doi = {10.1145/3394486.3406706},
abstract = {Automated machine learning (AutoML) offers the promise of translating raw data into accurate predictions with just a few lines of code. Rather than relying on human time/effort and manual experimentation, models can be improved by simply letting the AutoML system run for more time. In this hands-on tutorial, we demonstrate fundamental techniques that enable powerful AutoML. We consider standard supervised learning tasks on various types of data including tables, text, images, as well as multi-modal data comprised of multiple types. Rather than technical descriptions of how individual ML models work, we emphasize how to best use models within an overall ML pipeline that takes in raw training data and outputs pre-dictions for test data. A major focus of our tutorial is on automating deep learning, a class of powerful techniques that are cumbersome to manage manually. Despite this, hardly any educational material describes their successful automation. Each topic covered in the tutorial is accompanied by a hands-on Jupyter notebook that implements best practices (which will be available on Github before and after the tutorial). Most of this code is adopted from AutoGluon (autogluon.mxnet.io), a recent AutoML toolkit for automated deep learning that is both state-of-the-art and easy-to-use.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3509–3510},
numpages = {2},
keywords = {automl, computer vision, deep learning, natural language, structured data, supervised learning},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1016/j.cose.2021.102414,
author = {Alhogail, Areej and Alsabih, Afrah},
title = {Applying machine learning and natural language processing to detect phishing email},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {110},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102414},
doi = {10.1016/j.cose.2021.102414},
journal = {Comput. Secur.},
month = nov,
numpages = {11},
keywords = {Phishing Email detection, Deep learning, Natural language processinyg, Information security, Graph conventional network}
}

@article{10.1016/j.future.2020.01.017,
author = {Maia, Jos\'{e} and Severiano, Carlos Alberto and Guimar\~{a}es, Frederico Gadelha and de Castro, Cristiano Leite and Lemos, Andr\'{e} Paim and Fonseca Galindo, Juan Camilo and Weiss Cohen, Miri},
title = {Evolving clustering algorithm based on mixture of typicalities for stream data mining},
year = {2020},
issue_date = {May 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2020.01.017},
doi = {10.1016/j.future.2020.01.017},
journal = {Future Gener. Comput. Syst.},
month = may,
pages = {672–684},
numpages = {13},
keywords = {Evolving fuzzy systems, Stream data mining, Concept drift, Data stream, Clustering}
}

@inproceedings{10.1145/3388440.3412420,
author = {Kosfeld, Tim and McMillan, Jonathan and DiPaolo, Richard J. and Hou, Jie and Ahn, Tae-Hyuk},
title = {Performance Evaluation of Viral Infection Diagnosis using T-Cell Receptor Sequence and Artificial Intelligence},
year = {2020},
isbn = {9781450379649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388440.3412420},
doi = {10.1145/3388440.3412420},
abstract = {The adaptive immune system expresses millions of different receptors that detect and fight pathogens encountered throughout life. These receptors are encoded by unique DNA sequences that allow immune cells to express millions of different receptors. High-throughput sequencing and analyses of immune cell receptor sequences present a unique opportunity to inform our understanding of immunological responses to infections and to evaluate vaccine efficacy. Even after the infection is eliminated, pathogen-specific immune cells and their receptor sequences are present at higher frequencies than prior to infection, and their increase in frequency prevents secondary infections. As a result of their persistence in the body, they may be useful for diagnosing infections and evaluating vaccine efficacy as a stable biomarker. However, this process requires thorough analysis of massive datasets at an accuracy beyond traditional statistical tests to diagnose infectious statuses based on sequence analyses. Here we evaluate various machine learning and deep learning algorithms to measure the performance of the identification and diagnosis of specific viral infections or vaccination statuses using the publicly available mouse (monkeypox infection and smallpox vaccination) and human (cytomegalovirus serostatus) T-cell receptor sequenced datasets. Our intensive experiments hold the potential for effective screening of disease status, including recently encountered strains like the ongoing SARS-CoV-2 pandemic.},
booktitle = {Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {35},
numpages = {10},
keywords = {T-cell receptor sequencing, deep learning, diagnosis, infectious disease, machine learning, vaccination},
location = {Virtual Event, USA},
series = {BCB '20}
}

@article{10.1007/s00500-021-06105-5,
author = {Aslam, Bilal and Zafar, Adeel and Khalil, Umer},
title = {Development of integrated deep learning and machine learning algorithm for the assessment of landslide hazard potential},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06105-5},
doi = {10.1007/s00500-021-06105-5},
abstract = {In mountainous regions subjected to landslides, susceptibility mapping of these geohazards is necessary for averting and alleviating perilous dangers. The present study applies an integrated methodology for assessing landslide susceptibility of northern Pakistan (Mansehra and Muzaffarabad districts). Three orthodox machine learning (ML) classification techniques, including support vector machine (SVM), logistic regression (LR), and random forest (RF), are integrated with convolutional neural network (CNN) used. For training and testing of the models, spatial datasets consisting of 3251 sites of historical slopes are used in a ratio of 70:30. Initially, a total of 16 influencing factors for landslide modelling were established. The training dataset specifically constructs three hybrid models CNN-SVM, CNN-LR, and CNN-RF. Then, final susceptibility maps (LSMs) will be built using these trained models. These models will be implemented. For having a comparison, the LSMs are also prepared using the considered ML models individually. In the end, multiple statistical methods are used to validate and compare the performance of these models. The results of the analysis have revealed the efficiency of applying the projected ML models by combining them with the CNN technique. Therefore, in other sensitive regions with comparable geo-environmental conditions, the future hybrid designs can be used effectively for landslide susceptibility studies.},
journal = {Soft Comput.},
month = nov,
pages = {13493–13512},
numpages = {20},
keywords = {Northern Pakistan, Spatial datasets, Feature extraction, Orthodox machine learning, Landslide susceptibility maps, CNN}
}

@inproceedings{10.1145/3097983.3098001,
author = {Wang, Suhang and Aggarwal, Charu and Liu, Huan},
title = {Randomized Feature Engineering as a Fast and Accurate Alternative to Kernel Methods},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098001},
doi = {10.1145/3097983.3098001},
abstract = {Feature engineering has found increasing interest in recent years because of its ability to improve the effectiveness of various machine learning models. Although tailored feature engineering methods have been designed for various domains, there are few that simulate the consistent effectiveness of kernel methods. At the core, the success of kernel methods is achieved by using similarity functions that emphasize local variations in similarity. Unfortunately, this ability comes at the price of the high level of computational resources required and the inflexibility of the representation as it only provides the similarity of two data points instead of vector representations of each data point; while the vector representations can be readily used as input to facilitate various models for different tasks. Furthermore, kernel methods are also highly susceptible to overfitting and noise and it cannot capture the variety of data locality. In this paper, we first analyze the inner working and weaknesses of kernel method, which serves as guidance for designing feature engineering. With the guidance, we explore the use of randomized methods for feature engineering by capturing multi-granular locality of data. This approach has the merit of being time and space efficient for feature construction. Furthermore, the approach is resistant to overfitting and noise because the randomized approach naturally enables fast and robust ensemble methods. Extensive experiments on a number of real world datasets are conducted to show the effectiveness of the approach for various tasks such as clustering, classification and outlier detection.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {485–494},
numpages = {10},
keywords = {randomized feature engineering, unsupervised feature learning},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@article{10.4018/IJEHMC.20220701.oa1,
author = {Gupta, Charu and Gaur, Dev and Agrawal, Prateek and Virmani, Deepali},
title = {HuDA_COVID Human Disposition Analysis During COVID-19 Using Machine Learning},
year = {2021},
issue_date = {Jul 2021},
publisher = {IGI Global},
address = {USA},
volume = {13},
number = {2},
issn = {1947-315X},
url = {https://doi.org/10.4018/IJEHMC.20220701.oa1},
doi = {10.4018/IJEHMC.20220701.oa1},
abstract = {Coronavirus has greatly impacted various aspects of human life, including human psychology &amp; human disposition. In this paper, we attempted to analyze the impact of the COVID-19 pandemic on human health. We propose Human Disposition Analysis during COVID-19 using machine learning (HuDA_COVID), where factors such as age, employment, addiction, stress level are studied for human disposition analysis. A mass survey is conducted on individuals of various age groups, regions &amp; professions, and the methodology achieved varied accuracy ranges of 87.5% to 98%. The study shows people are worried about lockdown, work &amp; relationships. Furthermore, 23% of the respondents have not had any effect. 45% and 32% have had positive and negative effects, respectively. It is a novel study in human disposition analysis in COVID-19 where a novel weighted assignment indicating the health status is also proposed. HuDA_COVID clearly indicates a need for a methodical approach towards the human psychological needs to help the social organizations formulating holistic interventions for affected individuals.},
journal = {Int. J. E-Health Med. Commun.},
month = sep,
pages = {1–15},
numpages = {15},
keywords = {ANN, Coronavirus, Data Classification, Decision Tree, Human Psychology, Machine Learning, Random Forest, SVM}
}

@article{10.1016/j.jbi.2019.103185,
author = {Badger, Jonathan and LaRose, Eric and Mayer, John and Bashiri, Fereshteh and Page, David and Peissig, Peggy},
title = {Machine learning for phenotyping opioid overdose events},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {94},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2019.103185},
doi = {10.1016/j.jbi.2019.103185},
journal = {J. of Biomedical Informatics},
month = jun,
numpages = {11},
keywords = {Machine learning, Opioid, Phenotype, Overdose, Electronic health record}
}

@inproceedings{10.1007/978-3-030-26072-9_25,
author = {Li, Maolong and Yang, Qiang and He, Fuzhen and Li, Zhixu and Zhao, Pengpeng and Zhao, Lei and Chen, Zhigang},
title = {An Unsupervised Learning Approach for NER Based on Online Encyclopedia},
year = {2019},
isbn = {978-3-030-26071-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26072-9_25},
doi = {10.1007/978-3-030-26072-9_25},
abstract = {Named Entity Recognition (NER) is a core task of NLP. State-of-art supervised NER models rely heavily on a large amount of high-quality annotated data, which is quite expensive to obtain. Various existing ways have been proposed to reduce the heavy reliance on large training data, but only with limited effect. In this paper, we propose a novel way to make full use of the weakly-annotated texts in encyclopedia pages for exactly unsupervised NER learning, which is expected to provide an opportunity to train the NER model with no manually-labeled data at all. Briefly, we roughly divide the sentences of encyclopedia pages into two parts simply according to the density of inner url links contained in each sentence. While a relatively small number of sentences with dense links are used directly for training the NER model initially, the left sentences with sparse links are then smartly selected for gradually promoting the model in several self-training iterations. Given the limited number of sentences with dense links for training, a data augmentation method is proposed, which could generate a lot more training data with the help of the structured data of encyclopedia to greatly augment the training effect. Besides, in the iterative self-training step, we propose to utilize a graph model to help estimate the labeled quality of these sentences with sparse links, among which those with the highest labeled quality would be put into our training set for updating the model in the next iteration. Our empirical study shows that the NER model trained with our unsupervised learning approach could perform even better than several state-of-art models fully trained on newswires data.},
booktitle = {Web and Big Data: Third International Joint Conference, APWeb-WAIM 2019, Chengdu, China, August 1–3, 2019, Proceedings, Part I},
pages = {329–344},
numpages = {16},
keywords = {Named entity recognition, Data augmentation, Enhanced self-training},
location = {Chengdu, China}
}

@inproceedings{10.1145/3460319.3464844,
author = {Dutta, Saikat and Selvam, Jeeva and Jain, Aryaman and Misailovic, Sasa},
title = {TERA: optimizing stochastic regression tests in machine learning projects},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464844},
doi = {10.1145/3460319.3464844},
abstract = {The stochastic nature of many Machine Learning (ML) algorithms makes testing of ML tools and libraries challenging. ML algorithms allow a developer to control their accuracy and run-time through a set of hyper-parameters, which are typically manually selected in tests. This choice is often too conservative and leads to slow test executions, thereby increasing the cost of regression testing.  We propose TERA, the first automated technique for reducing the cost of regression testing in Machine Learning tools and libraries(jointly referred to as projects) without making the tests more flaky. TERA solves the problem of exploring the trade-off space between execution time of the test and its flakiness as an instance of Stochastic Optimization over the space of algorithm hyper-parameters. TERA presents how to leverage statistical convergence-testing techniques to estimate the level of flakiness of the test for a specific choice of hyper-parameters during optimization.  We evaluate TERA on a corpus of 160 tests selected from 15 popular machine learning projects. Overall, TERA obtains a geo-mean speedup of 2.23x over the original tests, for the minimum passing probability threshold of 99%. We also show that the new tests did not reduce fault detection ability through a mutation study and a study on a set of 12 historical build failures in studied projects.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {413–426},
numpages = {14},
keywords = {Bayesian Optimization, Machine Learning, Software Testing, Test Optimization},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/3233027.3233030,
author = {Weckesser, Markus and Kluge, Roland and Pfannem\"{u}ller, Martin and Matth\'{e}, Michael and Sch\"{u}rr, Andy and Becker, Christian},
title = {Optimal reconfiguration of dynamic software product lines based on performance-influence models},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233030},
doi = {10.1145/3233027.3233030},
abstract = {Today's adaptive software systems (i) are often highly configurable product lines, exhibiting hundreds of potentially conflicting configuration options; (ii) are context dependent, forcing the system to reconfigure to ever-changing contextual situations at runtime; (iii) need to fulfill context-dependent performance goals by optimizing measurable nonfunctional properties. Usually, a large number of consistent configurations exists for a given context, and each consistent configuration may perform differently with regard to the current context and performance goal(s). Therefore, it is crucial to consider nonfunctional properties for identifying an appropriate configuration. Existing black-box approaches for estimating the performance of configurations provide no means for determining context-sensitive reconfiguration decisions at runtime that are both consistent and optimal, and hardly allow for combining multiple context-dependent quality goals. In this paper, we propose a comprehensive approach based on Dynamic Software Product Lines (DSPL) for obtaining consistent and optimal reconfiguration decisions. We use training data obtained from simulations to learn performance-influence models. A novel integrated runtime representation captures both consistency properties and the learned performance-influence models. Our solution provides the flexibility to define multiple context-dependent performance goals. We have implemented our approach as a standalone component. Based on an Internet-of-Things case study using adaptive wireless sensor networks, we evaluate our approach with regard to effectiveness, efficiency, and applicability.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {98–109},
numpages = {12},
keywords = {dynamic software product lines, machine learning, performance-influence models},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1007/s11042-020-10067-5,
author = {\"{O}zer, \c{C}a\u{g}da\c{s} and \c{C}evik, Taner and G\"{u}rhanl\i{}, Ahmet},
title = {A machine learning-based framework for predicting game server load},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-10067-5},
doi = {10.1007/s11042-020-10067-5},
abstract = {Server load prediction can be utilized for load-balancing and load-sharing in distributed systems. The use of machine learning (ML) algorithms for load estimation in distributed system applications can increase the availability and performance of servers. Hence, a number of machine learning algorithms have been applied thus far for server load estimation. This study focuses on increasing the performance of game servers by accurately predicting the workload of game servers in short, medium and long term prediction situations. While doing this, various machine learning techniques have been applied and the algorithms that give the best results are presented. In terms of implementation, companies using their servers and data centers can try to increase their level of satisfaction by using these algorithms. A prediction model is developed and the estimation performances of a number of fundamental ML methods i.e., Na\"{\i}ve Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), Support Vector Machine (SVM), Fast Large Margin (FLM), Convolutional Neural Network CNN are analyzed. The data used during the training stage is obtained by listening to the TCP/IP packet traffic and the real-data is extracted by performing an extensive analysis of the total transferred-data that includes also the payload. In the analysis phase, the goodput is considered in order to reveal exact resource requirements. Comprehensive simulations are performed under various conditions for high accuracy performance analysis. Experimental results indicate that the proposed ML-based prediction shows promising performance in terms of load prediction when compared to the common approaches present in the literature.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {9527–9546},
numpages = {20},
keywords = {Machine learning, Load prediction, Game server}
}

@article{10.1016/j.comcom.2020.02.007,
author = {E, Sathishkumar V and Park, Jangwoo and Cho, Yongyun},
title = {Using data mining techniques for bike sharing demand prediction in metropolitan city},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {153},
number = {C},
issn = {0140-3664},
url = {https://doi.org/10.1016/j.comcom.2020.02.007},
doi = {10.1016/j.comcom.2020.02.007},
journal = {Comput. Commun.},
month = mar,
pages = {353–366},
numpages = {14},
keywords = {Data mining, Predictive analytics, Public bikes, Regression, Bike sharing demand}
}

@inbook{10.1145/3447404.3447415,
author = {McMenemy, David},
title = {Ethical Issues in Machine Learning},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447415},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {195–196},
numpages = {2}
}

@inproceedings{10.1145/3324884.3415281,
author = {Abdelkader, Hala},
title = {Towards robust production machine learning systems: managing dataset shift},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3415281},
doi = {10.1145/3324884.3415281},
abstract = {The advances in machine learning (ML) have stimulated the integration of their capabilities into software systems. However, there is a tangible gap between software engineering and machine learning practices, that is delaying the progress of intelligent services development. Software organisations are devoting effort to adjust the software engineering processes and practices to facilitate the integration of machine learning models. Machine learning researchers as well are focusing on improving the interpretability of machine learning models to support overall system robustness. Our research focuses on bridging this gap through a methodology that evaluates the robustness of machine learning-enabled software engineering systems. In particular, this methodology will automate the evaluation of the robustness properties of software systems against dataset shift problems in ML. It will also feature a notification mechanism that facilitates the debugging of ML components.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1164–1166},
numpages = {3},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1007/978-3-030-86271-8_49,
author = {Gigante, Diogo and Oliveira, Pedro and Fernandes, Bruno and Lopes, Frederico and Novais, Paulo},
title = {Unsupervised Learning Approach for pH Anomaly Detection in Wastewater Treatment Plants},
year = {2021},
isbn = {978-3-030-86270-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86271-8_49},
doi = {10.1007/978-3-030-86271-8_49},
abstract = {Sustainability has been a concern for society over the past few decades, preserving natural resources being one of the main themes. Among the various natural resources, water was one of them. The treatment of residual waters for future reuse and release to the environment is a fundamental task performed by Wastewater Treatment Plants (WWTP). Hence, to guarantee the quality of the treated effluent in a WWTP, continuous control and monitoring of abnormal events in the substances present in this water resource are necessary. One of the most critical substances is the pH that represents the measurement of the hydrogen ion activity. Therefore, this work presents an approach with a conception, tune and evaluation of several candidate models, based on two Machine Learning algorithms, namely Isolation Forests (iF) and One-Class Support Vector Machines (OCSVM), to detect anomalies in the pH on the effluent of a multi-municipal WWTP. The OCSVM-based model presents better performance than iF-based with an approximate 0.884 of Area Under The Curve - Receiver Operating Characteristics (AUC-ROC).},
booktitle = {Hybrid Artificial Intelligent Systems: 16th International Conference, HAIS 2021, Bilbao, Spain, September 22–24, 2021, Proceedings},
pages = {588–599},
numpages = {12},
keywords = {Anomaly detection, Isolation Forest, One-Class Support Vector Machine, pH, Wastewater Treatment Plants},
location = {Bilbao, Spain}
}

@inproceedings{10.1007/978-3-030-41407-8_22,
author = {Duan, Yeheng and Ma, Long-Long and Han, Xianpei and Sun, Le and Dong, Bin and Jiang, Shanshan},
title = {External Knowledge-Based Weakly Supervised Learning Approach on Chinese Clinical Named Entity Recognition},
year = {2019},
isbn = {978-3-030-41406-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41407-8_22},
doi = {10.1007/978-3-030-41407-8_22},
abstract = {Automatic extraction of clinical named entities, such as body parts, drugs and surgeries, has been of great significance to understand clinical texts. Deep neural networks approaches have achieved remarkable success in named entity recognition task recently. However, most of these approaches train models from large, high-quality and labor-consuming labeled data. In order to reduce the labeling costs, we propose a weakly supervised learning method for clinical named entity recognition (CNER) tasks. We use a small amount of labeled data as seed corpus, and propose a bootstrapping method integrating external knowledge to iteratively generate the labels for unlabeled data. The external knowledge consists of domain specific dictionaries as well as a bunch of handcraft rules. We conduct experiments on CCKS-2018 CNER task dataset and our approach achieves competitive results comparing to the supervised approach with fully labeled data.},
booktitle = {Semantic Technology: 9th Joint International Conference, JIST 2019, Hangzhou, China, November 25–27, 2019, Proceedings},
pages = {336–352},
numpages = {17},
keywords = {Named entity recognition, Weakly supervised learning, External knowledge},
location = {Hangzhou, China}
}

@article{10.1016/j.future.2019.06.022,
author = {Raza, Muhammad and Hussain, Farookh Khadeer and Hussain, Omar Khadeer and Zhao, Ming and Rehman, Zia ur},
title = {A comparative analysis of machine learning models for quality pillar assessment of SaaS services by multi-class text classification of users’ reviews},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {101},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.06.022},
doi = {10.1016/j.future.2019.06.022},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {341–371},
numpages = {31},
keywords = {SaaS, Quality pillars, User reviews, Text classification, Machine learning approaches}
}

@article{10.3233/JIFS-202269,
author = {Ayyub, Kashif and Iqbal, Saqib and Nisar, Muhammad Wasif and Ahmad, Saima Gulzar and Munir, Ehsan Ullah},
title = {Stance detection using diverse feature sets based on machine learning techniques},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202269},
doi = {10.3233/JIFS-202269},
abstract = {&nbsp;Sentiment analysis is the field that analyzes sentiments, and opinions of people about entities such as products, businesses, and events. As opinions influence the people’s behaviors, it has numerous applications in real life such as marketing, politics, social media etc. Stance detection is the sub-field of sentiment analysis. The stance classification aims to automatically identify from the source text, whether the source is in favor, neutral, or opposed to the target. This research study proposed a framework to explore the performance of the conventional (NB, DT, SVM), ensemble learning (RF, AdaBoost) and deep learning-based (DBN, CNN-LSTM, and RNN) machine learning techniques. The proposed method is feature centric and extracted the (sentiment, content, tweet specific and part-of-speech) features from both datasets of SemEval2016 and SemEval2017. The proposed study has also explored the role of deep features such as GloVe and Word2Vec for stance classification which has not received attention yet for stance detection. Some base line features such as Bag of words, N-gram, TF-IDF are also extracted from both datasets to compare the proposed features along with deep features. The proposed features are ranked using feature ranking methods such as (information gain, gain ration and relief-f). Further, the results are evaluated using standard performance evaluation measures for stance classification with existing studies. The calculated results show that the proposed feature sets including sentiment, (part-of-speech, content, and tweet specific) are helpful for stance classification when applied with SVM and GloVe a deep feature has given the best results when applied with deep learning method RNN.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {9721–9740},
numpages = {20},
keywords = {Stance classification, deep learning, deep features, sentiment analysis, content based}
}

@inproceedings{10.1145/3485768.3485775,
author = {Cruz Paulino, Joshua Lois and Antoja Almirol, Lexter Carl and Cruz Favila, Jun Marco and Loria Aquino, Kent Alvin Gerald and Hernandez De La Cruz, Angelica and Roxas, Rachel Edita},
title = {Multilingual Sentiment Analysis on Short Text Document Using Semi-Supervised Machine Learning},
year = {2021},
isbn = {9781450390156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485768.3485775},
doi = {10.1145/3485768.3485775},
abstract = {Sentiment analysis is a task of identifying the sentiments in text which is often applied to analyzing text in social media, customer feedbacks, and product reviews. Various studies have explored how sentiment analysis can automatically done by using machine learning techniques. However, there has been few attempts in implementing sentiment analysis on multilingual text. Furthermore, most of the existing works uses labelled data to train and develop machine learning models for sentiment analysis. Using labelled data are often expensive and time consuming. In this study, a sentiment analysis model for multilingual text using semi-supervised machine learning was explored. The data used is composed of 50,788 tweets about COVID-19, these are cleaned by removing unnecessary characters, stop words, and emojis. After cleaning, the language of each tweet was identified, all tweets that are not written in Filipino or English were removed from the dataset. Afterwards, the tweets were all translated in English in preparation for the annotation phase. This study used an open-source tool, TextBlob, in annotating the tweets. TextBlob outputs the polarity of the text in vector representation. The TextBlob annotation were then validated by human experts through an inter-rater agreement. The level of agreement between the human annotations and TextBlob annotations have a substantial agreement with 0.78 Fleiss’ Kappa value. Classifier models were developed using various machine learning algorithms. Based on the results of the experiment, SVC is the best performing model with count vectorizer as feature with an accuracy, precision, recall, and F1-score of 95%. For future work, fine tuning hyperparameters to optimize the models can be considered.},
booktitle = {2021 5th International Conference on E-Society, E-Education and E-Technology},
pages = {164–170},
numpages = {7},
keywords = {Deep learning, Machine learning, Sentiment analysis, multilingual text},
location = {Taipei, Taiwan},
series = {ICSET 2021}
}

@article{10.1007/s10994-018-5747-8,
author = {Berrar, Daniel and Lopes, Philippe and Dubitzky, Werner},
title = {Incorporating domain knowledge in machine learning for soccer outcome prediction},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {108},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-018-5747-8},
doi = {10.1007/s10994-018-5747-8},
abstract = {The task of the 2017 Soccer Prediction Challenge was to use machine learning to predict the outcome of future soccer matches based on a data set describing the match outcomes of 216,743 past soccer matches. One of the goals of the Challenge was to gauge where the limits of predictability lie with this type of commonly available data. Another goal was to pose a real-world machine learning challenge with a fixed time line, involving the prediction of real future events. Here, we present two novel ideas for integrating soccer domain knowledge into the modeling process. Based on these ideas, we developed two new feature engineering methods for match outcome prediction, which we denote as recency feature extraction and rating feature learning. Using these methods, we constructed two learning sets from the Challenge data. The top-ranking model of the 2017 Soccer Prediction Challenge was our k-nearest neighbor model trained on the rating feature learning set. In further experiments, we could slightly improve on this performance with an ensemble of extreme gradient boosted trees (XGBoost). Our study suggests that a key factor in soccer match outcome prediction lies in the successful incorporation of domain knowledge into the machine learning modeling process.},
journal = {Mach. Learn.},
month = jan,
pages = {97–126},
numpages = {30},
keywords = {2017 Soccer Prediction Challenge, Feature engineering, k-NN, Knowledge representation, Open International Soccer Database, Rating feature learning, Recency feature extraction, Soccer analytics, XGBoost}
}

@inproceedings{10.1145/2491627.2491646,
author = {Marijan, Dusica and Gotlieb, Arnaud and Sen, Sagar and Hervieu, Aymeric},
title = {Practical pairwise testing for software product lines},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491646},
doi = {10.1145/2491627.2491646},
abstract = {One key challenge for software product lines is efficiently managing variability throughout their lifecycle. In this paper, we address the problem of variability in software product lines testing. We (1) identify a set of issues that must be addressed to make software product line testing work in practice and (2) provide a framework that combines a set of techniques to solve these issues. The framework integrates feature modelling, combinatorial interaction testing and constraint programming techniques. First, we extract variability in a software product line as a feature model with specified feature interdependencies. We then employ an algorithm that generates a minimal set of valid test cases covering all 2-way feature interactions for a given time interval. Furthermore, we evaluate the framework on an industrial SPL and show that using the framework saves time and provides better test coverage. In particular, our experiments show that the framework improves industrial testing practice in terms of (i) 17% smaller set of test cases that are (a) valid and (b) guarantee all 2-way feature coverage (as opposite to 19.2% 2-way feature coverage in the hand made test set), and (ii) full flexibility and adjustment of test generation to available testing time.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {227–235},
numpages = {9},
keywords = {feature modelling, software product lines, variability management},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/3195106.3195133,
author = {Fan, Chenchen and Cui, Zechen and Zhong, Xiaofeng},
title = {House Prices Prediction with Machine Learning Algorithms},
year = {2018},
isbn = {9781450363532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195106.3195133},
doi = {10.1145/3195106.3195133},
abstract = {Based on the data set compiled by D. D. Cock and the competition run by kaggle.com, we propose a house prices prediction algorithm in Ames, lowa by deliberating on data processing, feature engineering and combination forecasting. Our prediction ranks the 35th of the total 2221 results on the public leaderboard of Kaggle.com and the RMSE of predicted results after taking logarithm from all the test data is 0.12019, which shows good performance and small of over-fitting.},
booktitle = {Proceedings of the 2018 10th International Conference on Machine Learning and Computing},
pages = {6–10},
numpages = {5},
keywords = {Combination Forecasting, House Prices Prediction, Kaggle Competition, Machine Learning Algorithms},
location = {Macau, China},
series = {ICMLC '18}
}

@article{10.1016/j.eswa.2021.115728,
author = {Su, Miao and Peng, Hui and Li, Shaofan},
title = {A visualized bibliometric analysis of mapping research trends of machine learning in engineering (MLE)},
year = {2022},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {186},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115728},
doi = {10.1016/j.eswa.2021.115728},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {11},
keywords = {Artificial intelligence, Engineering, Bibliometric analysis, VOSviewer, Research hotspots}
}

@inproceedings{10.1145/3326937.3341262,
author = {Hu, Kai and Wang, Joey and Liu, Yong and Chen, Datong},
title = {Automatic feature engineering from very high dimensional event logs using deep neural networks},
year = {2019},
isbn = {9781450367837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326937.3341262},
doi = {10.1145/3326937.3341262},
abstract = {As communication networks have grown, event logs have increased in both size and complexity at a very fast rate. Thus, mining event logs has become very challenging due to their high variety and volume. The traditional solution to model raw event logs is to transform the raw logs into features with fewer dimensions through manual feature engineering. However, feature engineering is very time-consuming, and its quality is highly dependent on data scientists' domain knowledge. Furthermore, repeatedly preprocessing event logs significantly delays the scoring process, which must scan all items in the logs.In this paper, we present our recent study on mining high-dimensional event logs using deep neural networks. We propose a Midway Neural Network (MNN) to avoid both manual feature engineering and the re-preprocessing of event logs. MNN embeds an input feature vector from a particular time window into a dense representation and memorizes these midway representations for incremental training and prediction. The experimental results demonstrated that the proposed method minimized human intervention, decreased the time for training and scoring, and decreased the memory and storage costs while maintaining a similar modeling performance compared to traditional solutions. We hope that our insights and knowledge can inspire colleagues who are working on similar problems.},
booktitle = {Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data},
articleno = {13},
numpages = {9},
keywords = {automatic feature engineering, deep neural networks, incremental scoring, mining event logs},
location = {Anchorage, Alaska},
series = {DLP-KDD '19}
}

@inproceedings{10.1109/ICSE43902.2021.00138,
author = {Wang, Song and Shrestha, Nishtha and Subburaman, Abarna Kucheri and Wang, Junjie and Wei, Moshi and Nagappan, Nachiappan},
title = {Automatic Unit Test Generation for Machine Learning Libraries: How Far Are We?},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00138},
doi = {10.1109/ICSE43902.2021.00138},
abstract = {Automatic unit test generation that explores the input space and produces effective test cases for given programs have been studied for decades. Many unit test generation tools that can help generate unit test cases with high structural coverage over a program have been examined. However, the fact that existing test generation tools are mainly evaluated on general software programs calls into question about its practical effectiveness and usefulness for machine learning libraries, which are statistically-orientated and have fundamentally different nature and construction from general software projects.In this paper, we set out to investigate the effectiveness of existing unit test generation techniques on machine learning libraries. To investigate this issue, we conducted an empirical study on five widely-used machine learning libraries with two popular unit test case generation tools, i.e., EVOSUITE and Randoop. We find that (1) most of the machine learning libraries do not maintain a high-quality unit test suite regarding commonly applied quality metrics such as code coverage (on average is 34.1%) and mutation score (on average is 21.3%), (2) unit test case generation tools, i.e., EVOSUITE and Randoop, lead to clear improvements in code coverage and mutation score, however, the improvement is limited, and (3) there exist common patterns in the uncovered code across the five machine learning libraries that can be used to improve unit test case generation tasks.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {Empirical software engineering, test case generation, testing machine learning libraries},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1007/978-3-030-33749-0_14,
author = {Vazquez-Nava, Roberto Carlos and Gonzalez-Mendoza, Miguel and Herrera-Alacantara, Oscar and Hernandez-Gress, Neil},
title = {Early Anomalous Vehicular Traffic Detection Through Spectral Techniques and Unsupervised Learning Models},
year = {2019},
isbn = {978-3-030-33748-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33749-0_14},
doi = {10.1007/978-3-030-33749-0_14},
abstract = {Smart Mobility seeks to meet urban requirements within a city and solve the urban mobility problems, one of them is related with vehicular traffic. The anomalous vehicular traffic is an unexpected change in the day-to-day vehicular traffic caused by different reasons, such as an accident, an event, road works or a natural disaster. An early detection of anomalous vehicular traffic allows to alert drivers of the anomaly and can make better decisions during their journey. The current solutions for this problem are mainly focused on the development of new algorithms, without giving enough importance to the extraction of underlying information from vehicular traffic, and even more, when this is a univariate time series and it is not possible to obtain other context features that describes its behavior. To address this issue, we propose a methodology for temporary, spectral and aggregation features and an unsupervised learning model to detect anomalous vehicular traffic. The methodology was evaluated in a real vehicular traffic database. Experimental results show that by using spectral attributes the detection of anomalous vehicular traffic, the Isolation Forest obtains the best results.},
booktitle = {Advances in Soft Computing: 18th Mexican International Conference on Artificial Intelligence, MICAI 2019, Xalapa, Mexico, October 27 – November 2, 2019, Proceedings},
pages = {162–175},
numpages = {14},
keywords = {Anomalous vehicular traffic, Smart Mobility, Digital filters, Unsupervised models},
location = {Xalapa, Mexico}
}

@article{10.1016/j.neucom.2018.12.012,
author = {Li, Yawen and Yang, Liu and Yang, Bohan and Wang, Ning and Wu, Tian},
title = {Application of interpretable machine learning models for the intelligent decision},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {333},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.12.012},
doi = {10.1016/j.neucom.2018.12.012},
journal = {Neurocomput.},
month = mar,
pages = {273–283},
numpages = {11},
keywords = {Machine learning, XGBoost, R&amp;D investments, Firm size, Innovation performance}
}

@inproceedings{10.1145/3350768.3351993,
author = {Bindewald, Carlos Vinicius and Freire, Willian M. and Amaral, Aline M. M. Miotto and Colanzi, Thelma Elita},
title = {Towards the support of user preferences in search-based product line architecture design: an exploratory study},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3351993},
doi = {10.1145/3350768.3351993},
abstract = {Software Product Lines (SPLs) is a reuse approach in which a family of products is generalized in a common architecture that can be adapted to different clients. The Product Line Architecture (PLA) is one of the most important artifacts of a SPL. PLA design requires great human effort as it involves several factors that are usually in conflict. To ease this task, PLA design can be formulated as an optimization problem with many factors, i.e, as a multi-objective optimization problem. In this context, the MOA4PLA approach was proposed to optimize PLA design using search algorithms and metrics specific to the context. This approach supported by OPLA-Tool has already been used in several works demonstrating its applicability. However, MOA4PLA does not take into account aspects that are subjective, such as the preferences of a particular Decision Maker (DM). To do so, this paper presents a proposal to incorporate the user preferences in the optimization process performed by MOA4PLA, through an interactive process in which the DM subjectively evaluates the solutions in processing time. Thus, the solutions generated can be better suited to the DM's needs or preferences. In order to allow the user interaction, modifications were made in MOA4PLA and implemented in the OPLA-Tool. Aiming at an initial validation of the proposal, an exploratory study was carried out, composed of two experiments: a qualitative and a quantitative. These experiments were realized with the participation of a software architect. Empirical results pointed out that the proposed interactive process enables the generation of PLAs that are in accordance with the architect's preferences. Another significant contribution are the lessons learned on how to improve the interactive process.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {387–396},
numpages = {10},
keywords = {Human-computer interaction, Multi-Objective Optimization, Product Line Architecture},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1109/WAIN52551.2021.00021,
author = {Serban, Alex and van der Blom, Koen and Hoos, Holger and Visser, Joost},
title = {Practices for Engineering Trustworthy Machine Learning Applications},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/WAIN52551.2021.00021},
doi = {10.1109/WAIN52551.2021.00021},
abstract = {Following the recent surge in adoption of machine learning (ML), the negative impact that improper use of ML can have on users and society is now also widely recognised. To address this issue, policy makers and other stakeholders, such as the European Commission or NIST, have proposed high-level guidelines aiming to promote trustworthy ML (i.e., lawful, ethical and robust). However, these guidelines do not specify actions to be taken by those involved in building ML systems. In this paper, we argue that guidelines related to the development of trustworthy ML can be translated to operational practices, and should become part of the ML development life cycle. Towards this goal, we ran a multi-vocal literature review, and mined operational practices from white and grey literature. Moreover, we launched a global survey to measure practice adoption and the effects of these practices. In total, we identified 14 new practices, and used them to complement an existing catalogue of ML engineering practices. Initial analysis of the survey results reveals that so far, practice adoption for trustworthy ML is relatively low. In particular, practices related to assuring security of ML components have very low adoption. Other practices enjoy slightly larger adoption, such as providing explanations to users. Our extended practice catalogue can be used by ML development teams to bridge the gap between high-level guidelines and actual development of trustworthy ML systems; it is open for review and contributions.},
booktitle = {2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)},
pages = {97–100},
numpages = {4},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3437802.3437816,
author = {Oreshin, Svyatoslav and Filchenkov, Andrey and Petrusha, Polina and Krasheninnikov, Egor and Panfilov, Alexander and Glukhov, Igor and Kaliberda, Yulia and Masalskiy, Daniil and Serdyukov, Alexey and Kazakovtsev, Vladimir and Khlopotov, Maksim and Podolenchuk, Timofey and Smetannikov, Ivan and Kozlova, Daria},
title = {Implementing a Machine Learning Approach to Predicting Students’ Academic Outcomes},
year = {2021},
isbn = {9781450388054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437802.3437816},
doi = {10.1145/3437802.3437816},
abstract = {This research is dedicated to the problem of transforming ”linear” educational systems of higher education institutions into a new paradigm of person-centered, blended and individual education. This paper investigates role, application, and challenges of applying AI to predict the academic performance traditional of students: dropouts, GPA, publication activity and other indicators to decrease dropouts and make the learning process more personalized and adaptive. In the first part, we overview the process of data mining using internal university’s resources (LMS and other systems) and open source data from students’ social networks. Such an aggregation allows describing each student by socio-demographic and psychometric features. Further, we demonstrate how we can dynamically monitor students’ activities during the learning process to supplement the resulting features. In the second part of our research, we propose various static and dynamic targets for predictive models and demonstrate the results of predictions and comparisons of several predictive models. The research is based on the information on data processing of more than 20000 students in 2013-2019.},
booktitle = {Proceedings of the 2020 1st International Conference on Control, Robotics and Intelligent System},
pages = {78–83},
numpages = {6},
keywords = {Artificial Intelligence, Educational Analytics, Learning analytics, Smart University},
location = {Xiamen, China},
series = {CCRIS '20}
}

@inproceedings{10.5555/3507788.3507798,
author = {Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Garcon, Sylvain and Tauseef, Qasim},
title = {Failure prediction using machine learning in IBM WebSphere liberty continuous integration environment},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing complexity and dependencies of software have increased the importance of testing to ensure that frequent changes do not adversely affect existing functionality. Moreover, continuous integration comes with unique challenges associated with maintaining a stable build environment. Several studies have shown that the testing environment becomes more efficient with proper test case prioritization techniques. However, an application's dynamic behavior makes it challenging to derive test case prioritization techniques for achieving optimal results. With the advance of machine learning, the context of an application execution can be analyzed to select and prioritize test suites more efficiently.Test suite prioritization techniques aim to reorder test suites' execution to deliver high quality, maintainable software at lower costs to meet specific objectives such as revealing failures earlier. The state-of-the-art techniques on test prioritization in a continuous integration environment focus on relatively small, single-language, unit-tested projects. This paper compares and analyzes Machine learning-based test suite prioritization technique on two large-scale dataset collected from a continuous integration environment Google and IBM respectively. We optimize hyperparameters and report on experiments' findings by using different machine learning algorithms for test suite prioritization. Our optimized algorithms prioritize test suites with 93% accuracy on average and require 20% fewer test suites to detect 80% of the failures than the test suites prioritized randomly.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {CI, continuous integration, machine learning, test prioritization},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1155/2021/9933481,
author = {Ghaderzadeh, Mustafa and Asadi, Farkhondeh and Hosseini, Azamossadat and Bashash, Davood and Abolghasemi, Hassan and Roshanpour, Arash and Wang, Pengwei},
title = {Machine Learning in Detection and Classification of Leukemia Using Smear Blood Images: A Systematic Review},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/9933481},
doi = {10.1155/2021/9933481},
abstract = {Introduction. The early detection and diagnosis of leukemia, i.e., the precise differentiation of malignant leukocytes with minimum costs in the early stages of the disease, is a major problem in the domain of disease diagnosis. Despite the high prevalence of leukemia, there is a shortage of flow cytometry equipment, and the methods available at laboratory diagnostic centers are time-consuming. Motivated by the capabilities of machine learning (machine learning (ML)) in disease diagnosis, the present systematic review was conducted to review the studies aiming to discover and classify leukemia by using machine learning. Methods. A systematic search in four databases (PubMed, Scopus, Web of Science, and ScienceDirect) and Google Scholar was performed via a search strategy using Machine Learning (ML), leukemia, peripheral blood smear (PBS) image, detection, diagnosis, and classification as the keywords. Initially, 116 articles were retrieved. After applying the inclusion and exclusion criteria, 16 articles remained as the population of the study. Results. This review study presents a comprehensive and systematic view of the status of all published ML-based leukemia detection and classification models that process PBS images. The average accuracy of the ML methods applied in PBS image analysis to detect leukemia was &gt;97%, indicating that the use of ML could lead to extraordinary outcomes in leukemia detection from PBS images. Among all ML techniques, deep learning (DL) achieved higher precision and sensitivity in detecting different cases of leukemia, compared to its precedents. ML has many applications in analyzing different types of leukemia images, but the use of ML algorithms to detect acute lymphoblastic leukemia (ALL) has attracted the greatest attention in the fields of hematology and artificial intelligence. Conclusion. Using the ML method to process leukemia smear images can improve accuracy, reduce diagnosis time, and provide faster, cheaper, and safer diagnostic services. In addition to the current diagnostic methods, clinical and laboratory experts can also adopt ML methods in laboratory applications and tools.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@inproceedings{10.1145/3106195.3106201,
author = {Kim, Jongwook and Batory, Don and Dig, Danny},
title = {Refactoring Java Software Product Lines},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106201},
doi = {10.1145/3106195.3106201},
abstract = {Refactoring is a staple of Object-Oriented (OO) program development. It should be a staple of OO Software Product Line (SPL) development too. X15 is the first tool to support the refactoring of Java SPL codebases. X15 (1) uses Java custom annotations to encode variability in feature-based Java SPLs, (2) projects a view of an SPL product (a program that corresponds to a legal SPL configuration), and (3) allows programmers to edit and refactor the product, propagating changes back to the SPL codebase. Case studies apply 2316 refactorings in 8 public Java SPLs and show that X15 is as efficient, expressive, and scalable as a state-of-the-art feature-unaware Java refactoring engine.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {59–68},
numpages = {10},
keywords = {refactoring, software product lines},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1007/s11633-020-1233-4,
author = {Aljanabi, Maryam and Shkoukani, Mohammad and Hijjawi, Mohammad},
title = {Ground-level Ozone Prediction Using Machine Learning Techniques: A Case Study in Amman, Jordan},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {5},
issn = {1476-8186},
url = {https://doi.org/10.1007/s11633-020-1233-4},
doi = {10.1007/s11633-020-1233-4},
abstract = {Air pollution is one of the most serious hazards to humans' health nowadays, it is an invisible killer that takes many human lives every year. There are many pollutants existing in the atmosphere today, ozone being one of the most threatening pollutants. It can cause serious health damage such as wheezing, asthma, inflammation, and early mortality rates. Although air pollution could be forecasted using chemical and physical models, machine learning techniques showed promising results in this area, especially artificial neural networks. Despite its importance, there has not been any research on predicting ground-level ozone in Jordan. In this paper, we build a model for predicting ozone concentration for the next day in Amman, Jordan using a mixture of meteorological and seasonal variables of the previous day. We compare a multi-layer perceptron neural network (MLP), support vector regression (SVR), decision tree regression (DTR), and extreme gradient boosting (XGBoost) algorithms. We also explore the effect of applying various smoothing filters on the time-series data such as moving average, Holt-Winters smoothing and Savitzky-Golay filters. We find that MLP outperformed the other algorithms and that using Savitzky-Golay improved the results by 50% for coefficient of determination (R2) and 80% for root mean square error (RMSE) and mean absolute error (MAE). Another point we focus on is the variables required to predict ozone concentration. In order to reduce the time required for prediction, we perform feature selection which greatly reduces the time by 91% as well as shrinking the number of features required for prediction to the previous day values of ozone, humidity, and temperature. The final model scored 98.653% for R2, 1.016 ppb for RMSE and 0.800 ppb for MAE.},
journal = {Int. J. Autom. Comput.},
month = oct,
pages = {667–677},
numpages = {11},
keywords = {Ozone prediction, machine learning, neural networks, supervised learning, regression}
}

@article{10.1145/3437479.3437485,
author = {Yoo, Shin and Aleti, Aldeida and Turhan, Burak and Minku, Leandro L. and Miranskyy, Andriy and Meri\c{c}li, \c{C}etin},
title = {The 8th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3437479.3437485},
doi = {10.1145/3437479.3437485},
abstract = {The International Workshop on Realizing Arti cial Intelligence Synergies in Software Engineering (RAISE) aims to present the state of the art in the crossover between Software Engineering and Arti cial Intelligence. This workshop explored not only the appli- cation of AI techniques to SE problems but also the application of SE techniques to AI problems. Software has become critical for realizing functions central to our society. For example, software is essential for nancial and transport systems, energy generation and distribution systems, and safety-critical medical applications. Software development costs trillions of dollars each year yet, still, many of our software engineering methods remain mostly man- ual. If we can improve software production by smarter AI-based methods, even by small margins, then this would improve a crit- ical component of the international infrastructure, while freeing up tens of billions of dollars for other tasks.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {23–24},
numpages = {2}
}

@article{10.1145/3356773.3356813,
author = {Marijan, Dusica and Shang, Weiyi and Shukla, Rakesh},
title = {Implications of Resurgence in Artificial Intelligence for Research Collaborations in Software Engineering},
year = {2020},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3356773.3356813},
doi = {10.1145/3356773.3356813},
abstract = {Challenges of implementing successful research collaborations between industry and academia in software engineering are varied and many. Differing timelines, metrics, expectations, and perceptions of these two communities are some common obstacles, which need be analyzed and discussed, to discover synergies and strengthen collaborations between researchers and practitioners. In this report, we present insights from the 6th International Workshop on Software Engineering Research and Industrial Practice held at the International Conference on Software Engineering 2019. Specifically, one particular topic dominated the discussion - the resurgence of artificial intelligence and machine learning algorithms in software engineering research and industry practice, and its implications for the collaboration between these two communities. We present takeaways from keynote talks on this subject, insights from paper presentations, and findings from the discussion session.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {68–70},
numpages = {3},
keywords = {industry-academia collaboration, innovation, research collaboration, software engineering, technology transfer}
}

@article{10.1016/j.cose.2016.01.006,
author = {Davis, Jonathan J. and Foo, Ernest},
title = {Automated feature engineering for HTTP tunnel detection},
year = {2016},
issue_date = {June 2016},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {59},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2016.01.006},
doi = {10.1016/j.cose.2016.01.006},
abstract = {Generating discriminative input features is a key requirement for achieving highly accurate classifiers. The process of generating features from raw data is known as feature engineering and it can take significant manual effort. In this paper we propose automated feature engineering to derive a suite of additional features from a given set of basic features with the aim of both improving classifier accuracy through discriminative features, and to assist data scientists through automation. Our implementation is specific to HTTP computer network traffic. To measure the effectiveness of our proposal, we compare the performance of a supervised machine learning classifier built with automated feature engineering versus one using human-guided features. The classifier addresses a problem in computer network security, namely the detection of HTTP tunnels. We use Bro to process network traffic into base features and then apply automated feature engineering to calculate a larger set of derived features. The derived features are calculated without favour to any base feature and include entropy, length and N-grams for all string features, and counts and averages over time for all numeric features. Feature selection is then used to find the most relevant subset of these features. Testing showed that both classifiers achieved a detection rate above 99.93% at a false positive rate below 0.01%. For our datasets, we conclude that automated feature engineering can provide the advantages of increasing classifier development speed and reducing development technical difficulties through the removal of manual feature engineering. These are achieved while also maintaining classification accuracy.},
journal = {Comput. Secur.},
month = jun,
pages = {166–185},
numpages = {20},
keywords = {Bro, Feature engineering, HTTP, Supervised machine learning, Tunnel detection}
}

@inproceedings{10.1145/3291801.3291829,
author = {Hong, Xianbin and Wong, Prudence and Liu, Dawei and Guan, Sheng-Uei and Man, Ka Lok and Huang, Xin},
title = {Lifelong Machine Learning: Outlook and Direction},
year = {2018},
isbn = {9781450364768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291801.3291829},
doi = {10.1145/3291801.3291829},
abstract = {The Lifelong machine learning is an advanced machine learning paradigm and also is the key to the stronger AI. In this paper, we review the development history of the lifelong machine learning and evaluate the current stage. The aim, definition and main components of it is introduced. In addition, the bottleneck and possible solution also is discussed and the further development waypoint is proposed.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Research},
pages = {76–79},
numpages = {4},
keywords = {Big Data, Classification, Lifelong Machine Learning, Natural Language Processing},
location = {Weihai, China},
series = {ICBDR '18}
}

@inproceedings{10.1145/3475738.3480943,
author = {Mosaner, Raphael and Leopoldseder, David and Stadler, Lukas and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Using machine learning to predict the code size impact of duplication heuristics in a dynamic compiler},
year = {2021},
isbn = {9781450386753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475738.3480943},
doi = {10.1145/3475738.3480943},
abstract = {Code duplication is a major opportunity to enable optimizations in subsequent compiler phases. However, duplicating code prematurely or too liberally can result in tremendous code size increases. Thus, modern compilers use trade-offs between estimated costs in terms of code size increase and benefits in terms of performance increase. In the context of this ongoing research project, we propose the use of machine learning to provide trade-off functions with accurate predictions for code size impact. To evaluate our approach, we implemented a neural network predictor in the GraalVM compiler and compared its performance against a human-crafted, highly tuned heuristic. First results show promising performance improvements, leading to code size reductions of more than 10% for several benchmarks. Additionally, we present an assistance mode for finding flaws in the human-crafted heuristic, leading to improvements for the duplication optimization itself.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Managed Programming Languages and Runtimes},
pages = {127–135},
numpages = {9},
keywords = {Code Duplication, Dynamic Compiler, Heuristics, Machine Learning, Neural Networks, Optimization, Regression},
location = {M\"{u}nster, Germany},
series = {MPLR 2021}
}

@article{10.1007/s00766-018-0292-3,
author = {Montgomery, Lloyd and Damian, Daniela and Bulmer, Tyson and Quader, Shaikh},
title = {Customer support ticket escalation prediction using feature engineering},
year = {2018},
issue_date = {Sep 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {3},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-018-0292-3},
doi = {10.1007/s00766-018-0292-3},
abstract = {Understanding and keeping the customer happy is a central tenet of requirements engineering. Strategies to gather, analyze, and negotiate requirements are complemented by efforts to manage customer input after products have been deployed. For the latter, support tickets are key in allowing customers to submit their issues, bug reports, and feature requests. If insufficient attention is given to support issues, however, their escalation to management becomes time-consuming and expensive, especially for large organizations managing hundreds of customers and thousands of support tickets. Our work provides a step toward simplifying the job of support analysts and managers, particularly in predicting the risk of escalating support tickets. In a field study at our large industrial partner, IBM, we used a design science research methodology to characterize the support process and data available to IBM analysts in managing escalations. In a design science methodology, we used feature engineering to translate our understanding of support analysts’ expert knowledge of their customers into features of a support ticket model. We then implemented these features into a machine learning model to predict support ticket escalations. We trained and evaluated our machine learning model on over 2.5 million support tickets and 10,000 escalations, obtaining a recall of 87.36% and an 88.23% reduction in the workload for support analysts looking to identify support tickets at risk of escalation. Further on-site evaluations, through a prototype tool we developed to implement our machine learning techniques in practice, showed more efficient weekly support ticket management meetings. Finally, in addition to these research evaluation activities, we compared the performance of our support ticket model with that of a model developed with no feature engineering; the support ticket model features outperformed the non-engineered model. The artifacts created in this research are designed to serve as a starting place for organizations interested in predicting support ticket escalations, and for future researchers to build on to advance research in escalation prediction.},
journal = {Requir. Eng.},
month = sep,
pages = {333–355},
numpages = {23},
keywords = {Customer relationship management, Machine learning, Escalation prediction, Customer support ticket, Design science research}
}

@inproceedings{10.1145/2791060.2791066,
author = {Dhungana, Deepak and Falkner, Andreas and Haselb\"{o}ck, Alois and Schreiner, Herwig},
title = {Smart factory product lines: a configuration perspective on smart production ecosystems},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791066},
doi = {10.1145/2791060.2791066},
abstract = {Smart production aims to increase the flexibility of the production processes and be more efficient in the use of resources. Two important pillars of this initiative are "smart products" and "smart factories". From the perspective of product line engineering, these can be seen as two product lines (product line of factories and product line of goods) that need to be integrated for a common systems engineering approach. In this paper, we look at this problem from the perspective of configuration technologies, outline the research challenges in this area and illustrate our vision using an industrial example. The factory product line goes hand-in-hand with the product line of the products to be manufactured. Future research in product line engineering needs to consider an ecosystem of a multitude of stakeholders - e.g., factory component vendors, product designers, factory owners/operators and end-consumers.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {201–210},
numpages = {10},
keywords = {product and production configuration, product line of factories, smart factory, smart product, smart production},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1145/3231535.3231538,
author = {Banerjee, Snehasis and Chattopadhyay, Tanushyam and Pal, Arpan and Garain, Utpal},
title = {Automation of feature engineering for IoT analytics},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
url = {https://doi.org/10.1145/3231535.3231538},
doi = {10.1145/3231535.3231538},
abstract = {This paper presents an approach for automation of interpretable feature selection for Internet Of Things Analytics (IoTA) using machine learning (ML) techniques. Authors have conducted a survey over different people involved in different IoTA based application development tasks. The survey reveals that feature selection is the most time consuming and niche skill demanding part of the entire workflow. This paper shows how feature selection is successfully automated without sacrificing the decision making accuracy and thereby reducing the project completion time and cost of hiring expensive resources. Several pattern recognition principles and state of art (SoA) ML techniques are followed to design the overall approach for the proposed automation. Three data sets are considered to establish the proof-of-concept. Experimental results show that the proposed automation is able to reduce the time for feature selection to 2 days instead of 4 -- 6 months which would have been required in absence of the automation. This reduction in time is achieved without any sacrifice in the accuracy of the decision making process. Proposed method is also compared against Multi Layer Perceptron (MLP) model as most of the state of the art works on IoTA uses MLP based Deep Learning. Moreover the feature selection method is compared against SoA feature reduction technique namely Principal Component Analysis (PCA) and its variants. The results obtained show that the proposed method is effective.},
journal = {SIGBED Rev.},
month = jun,
pages = {24–30},
numpages = {7},
keywords = {IoT analytics, feature engineering, information processing on sensor data, sensor signal analytics}
}

@inproceedings{10.1145/3439961.3439971,
author = {Correia, Jo\~{a}o Lucas and Pereira, Juliana Alves and Mello, Rafael and Garcia, Alessandro and Fonseca, Baldoino and Ribeiro, M\'{a}rcio and Gheyi, Rohit and Kalinowski, Marcos and Cerqueira, Renato and Tiengo, Willy},
title = {Brazilian Data Scientists: Revealing their Challenges and Practices on Machine Learning Model Development},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439971},
doi = {10.1145/3439961.3439971},
abstract = {Data scientists often develop machine learning models to solve a variety of problems in the industry and academy. To build these models, these professionals usually perform activities that are also performed in the traditional software development lifecycle, such as eliciting and implementing requirements. One might argue that data scientists could rely on the engineering of traditional software development to build machine learning models. However, machine learning development presents certain characteristics, which may raise challenges that lead to the need for adopting new practices. The literature lacks in characterizing this knowledge from the perspective of the data scientists. In this paper, we characterize challenges and practices addressing the engineering of machine learning models that deserve attention from the research community. To this end, we performed a qualitative study with eight data scientists across five different companies having different levels of experience in developing machine learning models. Our findings suggest that: (i) data processing and feature engineering are the most challenging stages in the development of machine learning models; (ii) it is essential synergy between data scientists and domain experts in most of stages; and (iii) the development of machine learning models lacks the support of a well-engineered process.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {10},
numpages = {10},
keywords = {Empirical Study, Machine Learning, Practitioner, Software Engineering},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.4018/JGIM.20220701.oa1,
author = {Wu, Chia-Huei and Wu, Zongxiao and Zang, Cong and Deng, Zilin and Shao, Xuefeng and Liu, Wei},
title = {Improving Customer Value Index and Consumption Forecasts Using a Weighted RFM Model and Machine Learning Algorithms},
year = {2021},
issue_date = {Aug 2021},
publisher = {IGI Global},
address = {USA},
volume = {30},
number = {3},
issn = {1062-7375},
url = {https://doi.org/10.4018/JGIM.20220701.oa1},
doi = {10.4018/JGIM.20220701.oa1},
abstract = {Collecting and mining customer consumption data are crucial to assess customer value and predict customer consumption behaviors. This paper proposes a new procedure, based on an improved Random Forest Model by: adding a new indicator, joining the RFMS-based method to a K-means algorithm with the Entropy Weight Method applied in computing the customer value index, classifying customers to different categories, and then constructing a consumption forecasting model whose RMSE is the smallest in all kinds of data mining models. The results show that identifying customers by this improved RMF model and customer value index facilitates customer profiling, and forecasting customer consumption enables the development of more precise marketing strategies.},
journal = {J. Glob. Inf. Manage.},
month = aug,
pages = {1–23},
numpages = {23},
keywords = {Computing, Consumer, Consumption Forecast, Data Mining, K-Means Clustering Analysis, Marketing Strategy, Random Forest Model, RFM Model}
}

@inproceedings{10.1007/978-3-030-66412-1_28,
author = {Kujawska, Hanna and Slavkovik, Marija and R\"{u}ckmann, Jan-Joachim},
title = {Predicting the Winners of Borda, Kemeny and Dodgson Elections with Supervised Machine Learning},
year = {2020},
isbn = {978-3-030-66411-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-66412-1_28},
doi = {10.1007/978-3-030-66412-1_28},
abstract = {Voting methods are widely used in collective decision making, not only among people but also for the purposes of artificial agents. Computing the winners of voting for some voting methods like Borda count is computationally easy, while for others, like Kemeny and Dodgson, this is a computationally hard problem. The question we explore here is can winners of Kemeny and Dodgson elections be predicted using supervised machine learning methods? We explore this question empirically using common machine learning methods like XGBoost, Linear Support Vector Machines, Multilayer Perceptron and regularized linear classifiers with stochastic gradient descent. We analyze elections of 20 alternatives and 25 voters and build models that predict the winners of the Borda, Kemeny and Dodgson methods. We find that, as expected, Borda winners are predictable with high accuracy (99%), while for Kemeny and Dodgson the best accuracy we could obtain is 85% for Kemeny and 89% for Dodgson.},
booktitle = {Multi-Agent Systems and Agreement Technologies: 17th European Conference, EUMAS 2020, and 7th International Conference, AT 2020, Thessaloniki, Greece, September 14-15, 2020, Revised Selected Papers},
pages = {440–458},
numpages = {19},
keywords = {Computational social choice, Voting, Machine learning application}
}

@article{10.1016/j.cageo.2019.02.002,
author = {Sudakov, Oleg and Burnaev, Evgeny and Koroteev, Dmitry},
title = {Driving digital rock towards machine learning: Predicting permeability with gradient boosting and deep neural networks},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {127},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2019.02.002},
doi = {10.1016/j.cageo.2019.02.002},
journal = {Comput. Geosci.},
month = jun,
pages = {91–98},
numpages = {8},
keywords = {Digital rock, Machine learning, Artificial neural networks, Permeability prediction, Gradient boosting}
}

@article{10.1155/2021/6634811,
author = {Mahbooba, Basim and Timilsina, Mohan and Sahal, Radhya and Serrano, Martin and Khalil, Ahmed Mostafa},
title = {Explainable Artificial Intelligence (XAI) to Enhance Trust Management in Intrusion Detection Systems Using Decision Tree Model},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6634811},
doi = {10.1155/2021/6634811},
abstract = {Despite the growing popularity of machine learning models in the cyber-security applications (e.g., an intrusion detection system (IDS)), most of these models are perceived as a black-box. The eXplainable Artificial Intelligence (XAI) has become increasingly important to interpret the machine learning models to enhance trust management by allowing human experts to understand the underlying data evidence and causal reasoning. According to IDS, the critical role of trust management is to understand the impact of the malicious data to detect any intrusion in the system. The previous studies focused more on the accuracy of the various classification algorithms for trust in IDS. They do not often provide insights into their behavior and reasoning provided by the sophisticated algorithm. Therefore, in this paper, we have addressed XAI concept to enhance trust management by exploring the decision tree model in the area of IDS. We use simple decision tree algorithms that can be easily read and even resemble a human approach to decision-making by splitting the choice into many small subchoices for IDS. We experimented with this approach by extracting rules in a widely used KDD benchmark dataset. We also compared the accuracy of the decision tree approach with the other state-of-the-art algorithms.},
journal = {Complex.},
month = jan,
numpages = {11}
}

@inproceedings{10.1145/3448218.3448238,
author = {Yu, Yuhang},
title = {Review of the Application of Machine Learning in Rumor Detection},
year = {2021},
isbn = {9781450388870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448218.3448238},
doi = {10.1145/3448218.3448238},
abstract = {Because of the convenience of the social platform, the spread of the rumors has become more and more serious. Rumors will not only propagate misinformation but may also affect people's normal lives and even cause panic among the people. Many researchers have explored the machine learning techniques to detect the rumors automatically. In this survey, we will discuss these machine learning models from four perspectives: (1) the datasets used in training and verifying the models, (2) the features to detect the rumors, (3) the algorithms of rumor detection, (4) the metrics used to evaluate the results of the models. After reviewing the past work of rumor detection models, we highlight some rumor detection development directions at the end of the survey.},
booktitle = {Proceedings of the 5th International Conference on Control Engineering and Artificial Intelligence},
pages = {46–52},
numpages = {7},
location = {Sanya, China},
series = {CCEAI '21}
}

@article{10.1016/j.eswa.2017.02.036,
author = {Viegas, Rita and Salgado, Ctia M. and Curto, Srgio and Carvalho, Joo P. and Vieira, Susana M. and Finkelstein, Stan N.},
title = {Daily prediction of ICU readmissions using feature engineering and ensemble fuzzy modeling},
year = {2017},
issue_date = {August 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {79},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.02.036},
doi = {10.1016/j.eswa.2017.02.036},
abstract = {This research is focused on the prediction of ICU readmissions using fuzzy modeling and feature selection approaches. There are a number of published scores for assessing the risk of readmissions, but their poor predictive performance renders them unsuitable for implementation in the clinical setting. In this work, we propose the use of feature engineering and advanced computational intelligence techniques to improve the performance of current models. In particular, we propose an approach that relies on transforming raw vital signs, laboratory results and demographic information into more informative pieces of data, selecting a subset of relevant and nonredundant variables and applying fuzzy ensemble modeling to the featureengineered data for deriving important nonlinear relations between variables. Different criteria for selecting the best predictor from the ensemble and novel evaluation measures are explored. In particular, the area under the sensitivity curve and area under the specificity curve are investigated. The ensemble approach combined with feature transformation and feature selection showed increased performance, being able to predict early readmissions with an AUC of 0.77 0.02. To the best of our knowledge, this is the first computational intelligence technique allowing the prediction of readmissions in a daily basis. The high balance between sensitivity and specificity shows its strength and suitability for the management of the patient discharge decision making process.},
journal = {Expert Syst. Appl.},
month = aug,
pages = {244–253},
numpages = {10},
keywords = {Ensemble modeling, Feature engineering, Fuzzy clustering, ICU, Readmissions}
}

@inbook{10.5555/3454287.3455252,
author = {Jeong, Jisoo and Lee, Seungeui and Kim, Jeesoo and Kwak, Nojun},
title = {Consistency-based semi-supervised learning for object detection},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Making a precise annotation in a large dataset is crucial to the performance of object detection. While the object detection task requires a huge number of annotated samples to guarantee its performance, placing bounding boxes for every object in each sample is time-consuming and costs a lot. To alleviate this problem, we propose a Consistency-based Semi-supervised learning method for object Detection (CSD), which is a way of using consistency constraints as a tool for enhancing detection performance by making full use of available unlabeled data. Specifically, the consistency constraint is applied not only for object classification but also for the localization. We also proposed Background Elimination (BE) to avoid the negative effect of the predominant backgrounds on the detection performance. We have evaluated the proposed CSD both in single-stage and two-stage detectors and the results show the effectiveness of our method.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {965},
numpages = {10}
}

@article{10.1155/2019/1306039,
author = {Hern\'{a}ndez-Blanco, Antonio and Herrera-Flores, Boris and Tom\'{a}s, David and Navarro-Colorado, Borja and Natella, Roberto},
title = {A Systematic Review of Deep Learning Approaches to Educational Data Mining},
year = {2019},
issue_date = {2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2019},
issn = {1076-2787},
url = {https://doi.org/10.1155/2019/1306039},
doi = {10.1155/2019/1306039},
abstract = {Educational Data Mining (EDM) is a research field that focuses on the application of data mining, machine learning, and statistical methods to detect patterns in large collections of educational data. Different machine learning techniques have been applied in this field over the years, but it has been recently that Deep Learning has gained increasing attention in the educational domain. Deep Learning is a machine learning method based on neural network architectures with multiple layers of processing units, which has been successfully applied to a broad set of problems in the areas of image recognition and natural language processing. This paper surveys the research carried out in Deep Learning techniques applied to EDM, from its origins to the present day. The main goals of this study are to identify the EDM tasks that have benefited from Deep Learning and those that are pending to be explored, to describe the main datasets used, to provide an overview of the key concepts, main architectures, and configurations of Deep Learning and its applications to EDM, and to discuss current state-of-the-art and future directions on this area of research.},
journal = {Complex.},
month = jan,
numpages = {22}
}

@inproceedings{10.1145/3379597.3387461,
author = {Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David},
title = {A Machine Learning Approach for Vulnerability Curation},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387461},
doi = {10.1145/3379597.3387461},
abstract = {Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {32–42},
numpages = {11},
keywords = {application security, classifiers ensemble, machine learning, open-source software, self-training},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1007/978-3-030-58666-9_2,
author = {Akkiraju, Rama and Sinha, Vibha and Xu, Anbang and Mahmud, Jalal and Gundecha, Pritam and Liu, Zhe and Liu, Xiaotong and Schumacher, John},
title = {Characterizing Machine Learning Processes: A Maturity Framework},
year = {2020},
isbn = {978-3-030-58665-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58666-9_2},
doi = {10.1007/978-3-030-58666-9_2},
abstract = {Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises. For example, existing machine learning processes cannot address how to define business use cases for an AI application, how to convert business requirements from product managers into data requirements for data scientists, and how to continuously improve AI applications in term of accuracy and fairness, how to customize general purpose machine learning models with industry, domain, and use case specific data to make them more accurate for specific situations etc. Making AI work for enterprises requires special considerations, tools, methods and processes. In this paper we present a maturity framework for machine learning model lifecycle management for enterprises. Our framework is a re-interpretation of the software Capability Maturity Model (CMM) for machine learning model development process. We present a set of best practices from authors’ personal experience of building large scale real-world machine learning models to help organizations achieve higher levels of maturity independent of their starting point.},
booktitle = {Business Process Management: 18th International Conference, BPM 2020, Seville, Spain, September 13–18, 2020, Proceedings},
pages = {17–31},
numpages = {15},
keywords = {Machine learning models, Maturity model, Maturity framework, AI model life cycle management},
location = {Seville, Spain}
}

@inproceedings{10.1145/3318464.3389715,
author = {Derakhshan, Behrouz and Rezaei Mahdiraji, Alireza and Abedjan, Ziawasch and Rabl, Tilmann and Markl, Volker},
title = {Optimizing Machine Learning Workloads in Collaborative Environments},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3389715},
doi = {10.1145/3318464.3389715},
abstract = {Effective collaboration among data scientists results in high-quality and efficient machine learning (ML) workloads. In a collaborative environment, such as Kaggle or Google Colabratory, users typically re-execute or modify published scripts to recreate or improve the result. This introduces many redundant data processing and model training operations. Reusing the data generated by the redundant operations leads to the more efficient execution of future workloads. However, existing collaborative environments lack a data management component for storing and reusing the result of previously executed operations. In this paper, we present a system to optimize the execution of ML workloads in collaborative environments by reusing previously performed operations and their results. We utilize a so-called Experiment Graph (EG) to store the artifacts, i.e., raw and intermediate data or ML models, as vertices and operations of ML workloads as edges. In theory, the size of EG can become unnecessarily large, while the storage budget might be limited. At the same time, for some artifacts, the overall storage and retrieval cost might outweigh the recomputation cost. To address this issue, we propose two algorithms for materializing artifacts based on their likelihood of future reuse. Given the materialized artifacts inside EG, we devise a linear-time reuse algorithm to find the optimal execution plan for incoming ML workloads. Our reuse algorithm only incurs a negligible overhead and scales for the high number of incoming ML workloads in collaborative environments. Our experiments show that we improve the run-time by one order of magnitude for repeated execution of the workloads and 50% for the execution of modified workloads in collaborative environments.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {1701–1716},
numpages = {16},
keywords = {collaborative ML, machine learning, materialization and reuse},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@inproceedings{10.1007/978-3-319-96136-1_23,
author = {Hines, Christine and Youssef, Abdou},
title = {Machine Learning Applied to Point-of-Sale Fraud Detection},
year = {2018},
isbn = {978-3-319-96135-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-96136-1_23},
doi = {10.1007/978-3-319-96136-1_23},
abstract = {This paper applies machine learning (ML) techniques including neural networks, support vector machines Random Forest, and Adaboost to detecting insider fraud in restaurant point-of-sales data. With considerable engineering of the features, and by applying under-sampling techniques we show that ML techniques deliver very high fraud-detection performance. In particular, RandomForest can achieve 91% or better across all metrics when using a model trained on one restaurant to detect fraud in a separate restaurant. However, there must be sufficient fraud samples in the model for this to occur. Knowledge and techniques from this research could be used to develop a low-cost product to automate fraud detection for restaurant owners.},
booktitle = {Machine Learning and Data Mining in Pattern Recognition: 14th International Conference, MLDM 2018, New York, NY, USA, July 15-19, 2018, Proceedings, Part I},
pages = {283–295},
numpages = {13},
keywords = {Machine learning, Classification, Outlier detection, Fraud detection, Point-of-sale data},
location = {New York, NY, USA}
}

@article{10.1504/ijbidm.2021.111744,
author = {Scheidler, Anne Antonia and Rabe, Markus},
title = {Integral verification and validation for knowledge discovery procedure models},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {1},
issn = {1743-8195},
url = {https://doi.org/10.1504/ijbidm.2021.111744},
doi = {10.1504/ijbidm.2021.111744},
abstract = {This paper explains why the knowledge discovery in database (KDD) procedure models lacks verification and validation (V&amp;V) mechanisms and introduces an approach for integral V&amp;V. Based on a generic model for knowledge discovery, a structure named 'KDD triangle model' is presented. This model has a modular design and can be adapted for other KDD procedure models. This has the benefit of allowing existing projects for improving their quality assurance in knowledge discovery. In this paper, the different phases of the developed triangle model for KDD are discussed. One special focus is on the phase results and related testing mechanisms. This paper also describes possible V&amp;V techniques for the developed integral V&amp;V mechanism to ensure direct applicability of the model.},
journal = {Int. J. Bus. Intell. Data Min.},
month = jan,
pages = {73–87},
numpages = {14},
keywords = {knowledge discovery in databases, KDD, data mining, procedure model, verification and validation, quality assurance}
}

@article{10.1016/j.jnca.2021.103186,
author = {Cheng, Qiumei and Wu, Chunming and Zhou, Haifeng and Kong, Dezhang and Zhang, Dong and Xing, Junchi and Ruan, Wei},
title = {Machine learning based malicious payload identification in software-defined networking},
year = {2021},
issue_date = {Oct 2021},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {192},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2021.103186},
doi = {10.1016/j.jnca.2021.103186},
journal = {J. Netw. Comput. Appl.},
month = oct,
numpages = {12},
keywords = {Software-defined networking, Deep packet inspection, Machine learning, Linear prediction}
}

@article{10.1145/3359786,
author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
title = {Techniques for interpretable machine learning},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/3359786},
doi = {10.1145/3359786},
abstract = {Uncovering the mysterious ways machine learning models make decisions.},
journal = {Commun. ACM},
month = dec,
pages = {68–77},
numpages = {10}
}

@article{10.1016/j.compbiomed.2021.104798,
author = {Torres, Noelia and Trujillo, Leonardo and Maldonado, Yazmin and Vera, Carlos},
title = {Correction of the travel time estimation for ambulances of the red cross Tijuana using machine learning},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {137},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104798},
doi = {10.1016/j.compbiomed.2021.104798},
journal = {Comput. Biol. Med.},
month = oct,
numpages = {13},
keywords = {Emergency medical services, Mapping systems, Ambulance travel time, Machine learning}
}

@inproceedings{10.1145/3397536.3422349,
author = {Xie, Boyi and Xu, Jeri and Jung, Jungkyo and Yun, Sang-Ho and Zeng, Eric and Brooks, Edward M. and Dolk, Michaela and Narasimhalu, Lokeshkumar},
title = {Machine Learning on Satellite Radar Images to Estimate Damages After Natural Disasters},
year = {2020},
isbn = {9781450380195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397536.3422349},
doi = {10.1145/3397536.3422349},
abstract = {Satellite radar imaging from SAR (Synthetic Aperture Radar) is a remote sensing technology that captures ground surface level changes at a relatively high resolution. This technology has been used in many applications, one of which is the estimation of damages after natural disasters, such as wildfire, earthquake, and hurricane events. An efficient and accurate assessment of damages after natural catastrophe events allows public and private sectors to quickly respond in order to mitigate losses and to better prepare for disaster relief. Advances in machine learning and image processing techniques can be applied to this dataset to survey large areas and estimate property damages. In this paper, we introduce a machine learning-based approach for taking satellite radar images and geographical data as inputs to classify the damage status of individual buildings after a major wildfire event. We believe the demonstration of this damage estimation methodology and its application to real world natural disaster events will have a high potential to improve social resilience.},
booktitle = {Proceedings of the 28th International Conference on Advances in Geographic Information Systems},
pages = {461–464},
numpages = {4},
keywords = {Machine learning, SAR remote sensing, damage assessment},
location = {Seattle, WA, USA},
series = {SIGSPATIAL '20}
}

@inproceedings{10.1145/3336294.3336295,
author = {Beek, Maurice H. ter and Damiani, Ferruccio and Lienhardt, Michael and Mazzanti, Franco and Paolini, Luca},
title = {Static Analysis of Featured Transition Systems},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336295},
doi = {10.1145/3336294.3336295},
abstract = {A Featured Transition System (FTS) is a formal behavioural model for software product lines, which represents the behaviour of all the products of an SPL in a single compact structure by associating transitions with features that condition their existence in products. In general, an FTS may contain featured transitions that are unreachable in any product (so called dead transitions) or, on the contrary, mandatorily present in all products for which their source state is reachable (so called false optional transitions), as well as states from which only for certain products progress is possible (so called hidden deadlocks). In this paper, we provide algorithms to analyse an FTS for such ambiguities and to transform an ambiguous FTS into an unambiguous FTS. The scope of our approach is twofold. First and foremost, an ambiguous model is typically undesired as it gives an unclear idea of the SPL. Second, an unambiguous FTS paves the way for efficient family-based model checking. We apply our approach to illustrative examples from the literature.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {39–51},
numpages = {13},
keywords = {behavioural model, featured transition systems, formal specification, software product lines, static analysis},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1016/j.eswa.2021.114942,
author = {Li, Hao and Misra, Siddharth},
title = {Robust machine-learning workflow for subsurface geomechanical characterization and comparison against popular empirical correlations},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {177},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114942},
doi = {10.1016/j.eswa.2021.114942},
journal = {Expert Syst. Appl.},
month = sep,
numpages = {16},
keywords = {Machine Learning, Geomechanical, Sonic, Oil and Gas, Neural Network}
}

@article{10.1155/2021/5478157,
author = {Rezayi, Sorayya and Mohammadzadeh, Niloofar and Bouraghi, Hamid and Saeedi, Soheila and Mohammadpour, Ali and Cecotti, Hubert},
title = {Timely Diagnosis of Acute Lymphoblastic Leukemia Using Artificial Intelligence-Oriented Deep Learning Methods},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5478157},
doi = {10.1155/2021/5478157},
abstract = {Background. Leukemia is fatal cancer in both children and adults and is divided into acute and chronic. Acute lymphoblastic leukemia (ALL) is a subtype of this cancer. Early diagnosis of this disease can have a significant impact on the treatment of this disease. Computational intelligence-oriented techniques can be used to help physicians identify and classify ALL rapidly. Materials and Method. In this study, the utilized dataset was collected from a CodaLab competition to classify leukemic cells from normal cells in microscopic images. Two famous deep learning networks, including residual neural network (ResNet-50) and VGG-16 were employed. These two networks are already trained by our assigned parameters, meaning we did not use the stored weights; we adjusted the weights and learning parameters too. Also, a convolutional network with ten convolutional layers and 2∗2 max-pooling layers—with strides 2—was proposed, and six common machine learning techniques were developed to classify acute lymphoblastic leukemia into two classes. Results. The validation accuracies (the mean accuracy of training and test networks for 100 training cycles) of the ResNet-50, VGG-16, and the proposed convolutional network were found to be 81.63%, 84.62%, and 82.10%, respectively. Among applied machine learning methods, the lowest obtained accuracy was related to multilayer perceptron (27.33%) and highest for random forest (81.72%). Conclusion. This study showed that the proposed convolutional neural network has optimal accuracy in the diagnosis of ALL. By comparing various convolutional neural networks and machine learning methods in diagnosing this disease, the convolutional neural network achieved good performance and optimal execution time without latency. This proposed network is less complex than the two pretrained networks and can be employed by pathologists and physicians in clinical systems for leukemia diagnosis.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {12}
}

@article{10.1016/j.jbi.2021.103791,
author = {Dairi, Abdelkader and Harrou, Fouzi and Zeroual, Abdelhafid and Hittawe, Mohamad Mazen and Sun, Ying},
title = {Comparative study of machine learning methods for COVID-19 transmission forecasting},
year = {2021},
issue_date = {Jun 2021},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {118},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2021.103791},
doi = {10.1016/j.jbi.2021.103791},
journal = {J. of Biomedical Informatics},
month = jun,
numpages = {12},
keywords = {COVID-19, Hybrid deep learning, short-term forecasting, LSTM-CNN, GAN-GRU}
}

@article{10.1007/s42979-020-00444-0,
author = {Yin, Yuehan and Alqahtani, Yahya and Feng, Jinjuan Heidi and Chakraborty, Joyram and McGuire, Michael P.},
title = {Classification of Eye Tracking Data in Visual Information Processing Tasks Using Convolutional Neural Networks and Feature Engineering},
year = {2021},
issue_date = {Apr 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {2},
url = {https://doi.org/10.1007/s42979-020-00444-0},
doi = {10.1007/s42979-020-00444-0},
abstract = {Eye tracking technology has been adopted in numerous studies in the field of human–computer interaction (HCI) to understand visual and display-based information processing as well as the underlying cognitive processes employed by users when navigating a computer interface. Analyzing eye tracking data can also help identify interaction patterns with regard to salient regions of an information display. Deep learning technology is increasingly being used in the analysis of eye tracking data by allowing for the classification of large amounts of eye tracking results. In this paper, eye tracking data and convolutional neural networks (CNNs) were used to perform a classification task to predict three types of information presentation methods. As a first step, a number of data preprocessing and feature engineering approaches were applied to eye tracking data collected through a controlled visual information processing experiment. The resulting data were used as input for the comparison of four CNN models with different architectures. In this experiment, two CNN models were effective in classifying the information presentations with overall accuracy greater than 80%.},
journal = {SN Comput. Sci.},
month = jan,
numpages = {26},
keywords = {Eye tracking, HCI, CNN, Deep learning, Feature engineering}
}

@article{10.1016/j.future.2019.08.029,
author = {Lucas, Yvan and Portier, Pierre-Edouard and Laporte, L\'{e}a and He-Guelton, Liyun and Caelen, Olivier and Granitzer, Michael and Calabretto, Sylvie},
title = {Towards automated feature engineering for credit card fraud detection using multi-perspective HMMs},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.08.029},
doi = {10.1016/j.future.2019.08.029},
journal = {Future Gener. Comput. Syst.},
month = jan,
pages = {393–402},
numpages = {10}
}

@inproceedings{10.5555/3507788.3507808,
author = {Tan, Waikeat and Alhamid, Mohammed and Kalil, Mohamad and Yang, Ronghao and Corvinelli, Vincent and Zuzarte, Calisto and Finnie, Liam},
title = {Query predicate selectivity using machine learning in Db2®},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The accuracy of cardinality estimation or the number of rows flowing through the query execution plan operators plays an important role in SQL query optimization. Cost-based optimizers depend on cardinality estimation to evaluate execution costs to select an optimal access plan. Achieving accurate cardinality estimation is difficult or expensive on tables that have correlated or skewed columns. Inaccurate cardinality estimation can lead to slow or unstable query performance. Although collecting statistics on multiple column combinations can minimize estimation errors with multiple predicates, it is hard to cover all column combinations. This paper presents a novel integrated approach using Machine Learning (ML) to learn and approximate the multivariate Cumulative Frequency Function (CFF) of column values, which is used to estimate cardinality for predicates with various relational operators. The key idea is that a model can learn the distribution of the data in the relation and can be used to predict cardinality for the query predicates accurately. The CFF model is also extended to estimate join cardinalities between tables. Experimental results demonstrate a significant improvement of cardinality estimation accuracy, computation efficiency, and amount of input required to train the model. Integration with the traditional optimizer is key to a smooth transition towards use in a production environment. This paper covers earlier technology previews shipped with Db2®.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {143–152},
numpages = {10},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1007/s11042-019-7379-9,
author = {Sajedi, Hedieh and Mohammadipanah, Fatemeh and Rahimi, Seyyed Amir},
title = {Actinobacterial strains recognition by Machine learning methods},
year = {2019},
issue_date = {Jul 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {14},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-019-7379-9},
doi = {10.1007/s11042-019-7379-9},
abstract = {Recognition of actinobacterial species on solid culture plates is an error-prone and time-consuming process which retard all the down-stream process after the isolation step. In this paper, we propose an optimized solution for the mentioned problem by using machine learning and image processing algorithms to diminish the cost and time and increase the accuracy of the detection. Three methods are compared in this paper for actinobacterial strains recognition. In the first method, two-level wavelet transform is applied on images of actinobacterial strains and statistical texture features are computed from wavelet subbands. Furthermore, some statistical color features are calculated from color information. In consequence, Principle Component Analysis (PCA) is employed for dimension reduction and finally, a Multi-Layer Perceptron (MLP) neural network was used for classification. In the second method, a Convolution Neural Network (CNN) is used to extract the features automatically. In the third method, transfer learning is employed for feature extraction and classfication. The first method is evaluated on two databases, UTMC.V1.DB and UTMC.V2.DB, and the accuracy obtained between 80.8% to 80.1%, respectively. Employing CNN as the feature extractor improved the accuracy about 4%. Transfer learnig results 85.96% accuracy on the UTMC.V2.DB and 91.90% on the subclasses of UTMC.V2.DB. The experiments have shown that using transfer learning of DCNN of type ResNet has better performance compared to the pervious methods. The proposed methods are universal and can be used for recognition of other circle-like colony-shape microorganisms. In particular, giving limited and unbalanced training data, which is a common failure in biological data sets, the proposed methods harbor remarkable accuracy. The data augmentation methods showed to be efficient and practical for the current purpose along with being easy to be implemented and integrated.},
journal = {Multimedia Tools Appl.},
month = jul,
pages = {20285–20307},
numpages = {23},
keywords = {Actinobacterial strains, Colony features, Deep neural network, Image processing, ResNet, Transfer learning}
}

@article{10.1016/j.compbiomed.2021.104500,
author = {Quintero, Yullis and Ardila, Douglas and Camargo, Edgar and Rivas, Francklin and Aguilar, Jose},
title = {Machine learning models for the prediction of the SEIRD variables for the COVID-19 pandemic based on a deep dependence analysis of variables},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {134},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104500},
doi = {10.1016/j.compbiomed.2021.104500},
journal = {Comput. Biol. Med.},
month = jul,
numpages = {20},
keywords = {Machine learning, COVID-19, Prediction model, Data dependence analysis}
}

@inproceedings{10.5555/3382225.3382283,
author = {Helmstetter, Stefan and Paulheim, Heiko},
title = {Weakly supervised learning for fake news detection on Twitter},
year = {2020},
isbn = {9781538660515},
publisher = {IEEE Press},
abstract = {The problem of automatic detection of fake news in social media, e.g., on Twitter, has recently drawn some attention. Although, from a technical perspective, it can be regarded as a straight-forward, binary classification problem, the major challenge is the collection of large enough training corpora, since manual annotation of tweets as fake or non-fake news is an expensive and tedious endeavor. In this paper, we discuss a weakly supervised approach, which automatically collects a large-scale, but very noisy training dataset comprising hundreds of thousands of tweets. During collection, we automatically label tweets by their source, i.e., trustworthy or untrustworthy source, and train a classifier on this dataset. We then use that classifier for a different classification target, i.e., the classification of fake and non-fake tweets. Although the labels are not accurate according to the new classification target (not all tweets by an untrustworthy source need to be fake news, and vice versa), we show that despite this unclean inaccurate dataset, it is possible to detect fake news with an F1 score of up to 0.9.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {274–277},
numpages = {4},
keywords = {Twitter, classification, fake news, machine learning, weak supervision},
location = {Barcelona, Spain},
series = {ASONAM '18}
}

@article{10.5555/3512469.3512479,
author = {Prabhakar, Shyam P. and Jololian, Leon},
title = {Developing a machine learning course for anomaly detection},
year = {2021},
issue_date = {October 2021},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {37},
number = {1},
issn = {1937-4771},
abstract = {Machine learning has shown its effectiveness in solving many problems for which traditional algorithmic solutions are not easy to find. For the past decade, we observed the rapid emergence of machine learning courses throughout the curricula. However, the focus of many machine learning courses is predominantly on introducing basic algorithms, such as linear regression, logistic regression, neural networks, and K-nearest neighbors, to name a few. There is limited emphasis on data wrangling, the process by which cleaning and unifying messy and complex data sets for easy access and analysis. In this paper, we discuss the introduction of special topics in a course on machine learning geared towards two major ideas: a) data processing techniques, b) introduction to real world scenario with anomaly detection in datasets using machine learning classifier techniques, and b) the augmentation of the data by introducing new data synthetically created. The objective is to raise awareness of the importance of the pre-processing of the data ensuring the quality of the results obtained in the post-processing stage. The work on this paper was a joint collaboration between the University of Alabama at Birmingham and IBM, where the authors currently work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {84–91},
numpages = {8}
}

@inproceedings{10.1145/3336294.3336307,
author = {Damasceno, Carlos Diego N. and Mousavi, Mohammad Reza and Simao, Adenilso},
title = {Learning from Difference: An Automated Approach for Learning Family Models from Software Product Lines},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336307},
doi = {10.1145/3336294.3336307},
abstract = {Substantial effort has been spent on extending specification notations and their associated reasoning techniques to software product lines (SPLs). Family-based analysis techniques operate on a single artifact, referred to as a family model, that is annotated with variability constraints. This modeling approach paves the way for efficient model-based testing and model checking for SPLs. Albeit reasonably efficient, the creation and maintenance of family models tend to be time consuming and error-prone, especially if there are crosscutting features. To tackle this issue, we introduce FFSMDiff, a fully automated technique to learn featured finite state machines (FFSM), a family-based formalism that unifies Mealy Machines from SPLs into a single representation. Our technique incorporates variability to compare and merge Mealy machines and annotate states and transitions with feature constraints. We evaluate our technique using 34 products derived from three different SPLs. Our results support the hypothesis that families of Mealy machines can be effectively merged into succinct FFSMs with fewer states, especially if there is high feature sharing among products. These indicate that FFSMDiff is an efficient family-based model learning technique.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {52–63},
numpages = {12},
keywords = {150% model, family model, model learning, software product lines},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1155/2021/9976306,
author = {Wang, Wei and Wu, Wenqing},
title = {Using Machine Learning Algorithms to Recognize Shuttlecock Movements},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/9976306},
doi = {10.1155/2021/9976306},
abstract = {Shuttlecock is an excellent traditional national sport in China. Because of its simplicity, convenience, and fun, it is loved by the broad masses of people, especially teenagers and children. The development of shuttlecock sports into a confrontational event is not long, and it takes a period of research to master the tactics and strategies of shuttlecock sports. Based on this, this article proposes the use of machine learning algorithms to recognize the movement of shuttlecock movements, aiming to provide more theoretical and technical support for shuttlecock competitions by identifying features through actions with the assistance of technical algorithms. This paper uses literature research methods, model methods, comparative analysis methods, and other methods to deeply study the motion characteristics of shuttlecock motion, the key algorithms of machine learning algorithms, and other theories and construct the shuttlecock motion recognition based on multiview clustering algorithm. The model analyzes the robustness and accuracy of the machine learning algorithm and other algorithms, such as a variety of performance comparisons, and the results of the shuttlecock motion recognition image. For the key movements of shuttlecock movement, disk, stretch, hook, wipe, knock, and abduction, the algorithm proposed in this paper has a good movement recognition rate, which can reach 91.2%. Although several similar actions can be recognized well, the average recognition accuracy rate can exceed 75%, and even through continuous image capture, the number of occurrences of the action can be automatically analyzed, which is beneficial to athletes. And the coach can better analyze tactics and research strategies.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {13}
}

@phdthesis{10.5555/1354508,
author = {Dehlinger, Joshua Jon},
advisor = {Lutz, Robyn R.},
title = {Incorporating product-line engineering techniques into agent-oriented software engineering for efficiently building safety-critical, multi-agent systems},
year = {2007},
isbn = {9780549154877},
publisher = {Iowa State University},
address = {USA},
abstract = {Safety-critical, agent-based systems are being developed without mechanisms and analysis techniques to discover, analyze and verify software requirements and prevent potential hazards. Agent-oriented, software-based approaches have provided powerful and natural high-level abstractions in which software developers can understand, model and develop complex, distributed systems. Yet, the realization of agent-oriented software development partially depends upon whether agent-based software systems can achieve reductions in development time and cost similar to other reuse-conscious software development methods. Further, agent-oriented software engineering (AOSE) currently does not adequately address: (1)&nbsp;requirements (specification) reuse in a way that is amenable to the reduction of the development cost by utilizing reusable assets, and (2)&nbsp;analysis techniques to evaluate safety. This dissertation offers our AOSE methodology, Gaia-PL (Gaia-Product Line) for open, agent-based distributed software systems to capture requirements specifications that can be easily reused. Our methodology uses a product-line perspective to promote reuse in agent-based, software systems early in the development lifecycle so that software assets can be reused throughout the development lifecycle and system evolution. The main contribution of this work is a requirements specification pattern that captures the dynamically changing design configurations of agents. Reuse is achieved by adopting a product-line approach into AOSE. Requirements specifications reuse is the ability to easily use previously defined requirements specifications from an earlier system and apply them to a new, slightly different system. This can significantly reduce the development time and cost of building an agent-based system.For safety-critical agent-based systems, this dissertation incorporates reuse-oriented safety analysis methods for AOSE to allow the discovery of new safety requirements and the verification that the design satisfies the safety requirements. Specifically, Product-Line Software Fault Tree Analysis (PL-SFTA) and its automated tool, PLFaultCAT (  P roduct-  L ine  Fault  Tree  C reation and  A nalysis  T ool), have been created to provide the technique and tool support for the safety analysis of safety-critical software product lines. The PL-SFTA allows for the identification of new safety requirements and the analysis of safety-critical requirements and requirement interactions. An AOSE-adapted Software Failure Modes, Effects and Criticality Analysis (SFMECA) technique has been created to support the derivation of a safety analysis asset using the specifications of Gaia-PL allowing for the identification of possible hazard scenarios and the failure points of specific agent roles. Using the assets generated via PL-SFTA and SFMECA, Bi-Directional Safety Analysis (BDSA) is shown to aid in the completeness of PL-SFTA and SFMECA, help verify the safety properties and strengthen the safety case when safety compliance to safety standards of the multi-agent system is necessary.Results from an application to a large, safety-critical, multi-agent system product-line show that Gaia-PL provides strong reuse capabilities. Evaluation of the Gaia-PL methodology used in conjunction with the PL-SFTA, SFMECA and BDSA safety analysis techniques shows that safety analysis of an agent-based software system is feasible, reusable and efficient.},
note = {AAI3274890}
}

@inproceedings{10.1007/978-3-319-92043-6_55,
author = {Singh, Neetu and Bellathanda Kaverappa, Chengappa and Joshi, Jehan D.},
title = {Data Mining for Prevention of Crimes},
year = {2018},
isbn = {978-3-319-92042-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-92043-6_55},
doi = {10.1007/978-3-319-92043-6_55},
abstract = {Preemptive measures are of utmost importance for crime prevention. Law enforcement agencies need to have an agile approach to solve everchanging crimes. Data analytics has proven to be an effective deterrent in the field of crime data analysis. Various countries like the United States of America have benefitted by this approach. The Government of India has also taken an initiative to implement data analytics to facilitate crime prevention measures. In this research paper, we have used R Studio, an open source data mining tool to perform the data analysis on the crime dataset shared by the Gujarat Police Department. To develop predictive model and study crime patterns we used various supervised and unsupervised data mining techniques such as Multiple Linear Regression, K-Means Clustering and Association Rules Analysis. The scope of this research paper is to showcase the effectiveness of data mining in the domain of crime prevention. In addition, an effort has been put forth to help the Gujarat Police Department to analyze their crime records and provide meaningful insights for decision making to solve the cases recorded.},
booktitle = {Human Interface and the Management of Information. Interaction, Visualization, and Analytics: 20th International Conference, HIMI 2018, Held as Part of HCI International 2018, Las Vegas, NV, USA, July 15-20, 2018, Proceedings, Part I},
pages = {705–717},
numpages = {13},
keywords = {Data mining, Predictive model, Process modelling, Crime analysis},
location = {Las Vegas, NV, USA}
}

@article{10.1145/3465171,
author = {Miao, Yuantian and Chen, Chao and Pan, Lei and Han, Qing-Long and Zhang, Jun and Xiang, Yang},
title = {Machine Learning–based Cyber Attacks Targeting on Controlled Information: A Survey},
year = {2021},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3465171},
doi = {10.1145/3465171},
abstract = {Stealing attack against controlled information, along with the increasing number of information leakage incidents, has become an emerging cyber security threat in recent years. Due to the booming development and deployment of advanced analytics solutions, novel stealing attacks utilize machine learning (ML) algorithms to achieve high success rate and cause a lot of damage. Detecting and defending against such attacks is challenging and urgent so governments, organizations, and individuals should attach great importance to the ML-based stealing attacks. This survey presents the recent advances in this new type of attack and corresponding countermeasures. The ML-based stealing attack is reviewed in perspectives of three categories of targeted controlled information, including controlled user activities, controlled ML model-related information, and controlled authentication information. Recent publications are summarized to generalize an overarching attack methodology and to derive the limitations and future directions of ML-based stealing attacks. Furthermore, countermeasures are proposed towards developing effective protections from three aspects—detection, disruption, and isolation.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {139},
numpages = {36},
keywords = {Cyber attacks, controlled information, cyber security, information leakage, machine learning}
}

@inproceedings{10.1109/SEAMS.2019.00015,
author = {Jamshidi, Pooyan and C\'{a}mara, Javier and Schmerl, Bradley and K\"{a}stner, Christian and Garlan, David},
title = {Machine learning meets quantitative planning: enabling self-adaptation in autonomous robots},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2019.00015},
doi = {10.1109/SEAMS.2019.00015},
abstract = {Modern cyber-physical systems (e.g., robotics systems) are typically composed of physical and software components, the characteristics of which are likely to change over time. Assumptions about parts of the system made at design time may not hold at run time, especially when a system is deployed for long periods (e.g., over decades). Self-adaptation is designed to find reconfigurations of systems to handle such run-time inconsistencies. Planners can be used to find and enact optimal reconfigurations in such an evolving context. However, for systems that are highly configurable, such planning becomes intractable due to the size of the adaptation space. To overcome this challenge, in this paper we explore an approach that (a) uses machine learning to find Pareto-optimal configurations without needing to explore every configuration and (b) restricts the search space to such configurations to make planning tractable. We explore this in the context of robot missions that need to consider task timeliness and energy consumption. An independent evaluation shows that our approach results in high-quality adaptation plans in uncertain and adversarial environments.},
booktitle = {Proceedings of the 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {39–50},
numpages = {12},
keywords = {artificial intelligence, machine learning, quantitative planning, robotics systems, self-adaptive systems},
location = {Montreal, Quebec, Canada},
series = {SEAMS '19}
}

@article{10.1016/j.artmed.2019.101752,
author = {Sharma, Prerna and Choudhary, Krishna and Gupta, Kshitij and Chawla, Rahul and Gupta, Deepak and Sharma, Arun},
title = {Artificial plant optimization algorithm to detect heart rate &amp; presence of heart disease using machine learning},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {102},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2019.101752},
doi = {10.1016/j.artmed.2019.101752},
journal = {Artif. Intell. Med.},
month = jan,
numpages = {14},
keywords = {Modified artificial plant optimization algorithm, Machine learning, Savitzky-Golay filter, Extreme gradient boosting, Artificial neural network}
}

@inproceedings{10.1145/3318464.3386146,
author = {Smith, Micah J. and Sala, Carles and Kanter, James Max and Veeramachaneni, Kalyan},
title = {The Machine Learning Bazaar: Harnessing the ML Ecosystem for Effective System Development},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3386146},
doi = {10.1145/3318464.3386146},
abstract = {As machine learning is applied more widely, data scientists often struggle to find or create end-to-end machine learning systems for specific tasks. The proliferation of libraries and frameworks and the complexity of the tasks have led to the emergence of "pipeline jungles" - brittle, ad hoc ML systems. To address these problems, we introduce the Machine Learning Bazaar, a new framework for developing machine learning and automated machine learning software systems. First, we introduce ML primitives, a unified API and specification for data processing and ML components from different software libraries. Next, we compose primitives into usable ML pipelines, abstracting away glue code, data flow, and data storage. We further pair these pipelines with a hierarchy of AutoML strategies - Bayesian optimization and bandit learning. We use these components to create a general-purpose, multi-task, end-to-end AutoML system that provides solutions to a variety of data modalities (image, text, graph, tabular, relational, etc.) and problem types (classification, regression, anomaly detection, graph matching, etc.). We demonstrate 5 real-world use cases and 2 case studies of our approach. Finally, we present an evaluation suite of 456 real-world ML tasks and describe the characteristics of 2.5 million pipelines searched over this task suite.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {785–800},
numpages = {16},
keywords = {AutoML, ML pipelines, ML primitives, machine learning, software development},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@article{10.1007/s42979-021-00856-6,
author = {El Mezouari, Asmae and El Fazziki, Abdelaziz and Sadgal, Mohammed},
title = {Hadoop–Spark Framework for Machine Learning-Based Smart Irrigation Planning},
year = {2021},
issue_date = {Jan 2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {3},
number = {1},
url = {https://doi.org/10.1007/s42979-021-00856-6},
doi = {10.1007/s42979-021-00856-6},
abstract = {Up-to-date, given the expanding increase of the population and the development of human daily lifestyles, the expenditure of freshwater resources increments progressively. It appears that there is a need to optimize at least the consumption of fresh water in agriculture. For this reason, novel various irrigation technologies have been deployed in this context like drip irrigation, flood irrigation, and decision support systems to come up with the constraints of climate changes that decrease the water availability but it is still limited. Therefore, the majority of researchers are working until today on automating the irrigation systems. These smart systems rely mainly on the advances of information technologies like the internet of things, big data, and machine learning for aligning irrigations with climatic changes. Besides, integrating the predictive process helps in anticipating and adapting to the climatic constraints in agriculture, using meticulous soil and environment dependencies analysis based on features’ prediction. In this paper, we enriched our proposed flexible online learning (OL) framework designed for promoting irrigation decisions based on soil characteristics analysis and prediction. We shed the light on a comparative study of four predictive methods, in particular, the auto-regressive moving average, the eXtreme Gradient Boosting, the random forest, and the deep artificial neural networks implemented inside the Hadoop/Spark environment to predict the humidity of the soil, relying on soil temperature and time in several depths. In the end, we discussed the precision of these models in various conditions.},
journal = {SN Comput. Sci.},
month = oct,
numpages = {10},
keywords = {Irrigation planning, Time series, Hadoop, Spark, Machine learning, Big data}
}

@article{10.1007/s00521-021-05704-5,
author = {Rathore, Heena and Mohamed, Amr and Guizani, Mohsen and Rathore, Shailendra},
title = {Neuro-fuzzy analytics in athlete development (NueroFATH): a machine learning approach},
year = {2021},
issue_date = {Nov 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {33},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05704-5},
doi = {10.1007/s00521-021-05704-5},
abstract = {Athletes represent the apex of physical capacity filling in a social picture of performance and build. In light of the fundamental contrasts in athletic capacities required for different games, each game demands an alternate body type standard. Because of the decent variety of these body types, each can have an altogether different body standard. Nowadays, a large number of athletes participate in assessments and a large number of human hours are spent on playing out these assessments every year. These assessments are performed to check the physical strength of athletes and evaluate them for different games. This paper presents a machine learning approach to the physical assessment of athletes known as NueroFATH. The proposed NueroFATH approach relies on neuro-fuzzy analytics that involves the deployment of neural networks and fuzzy c-means techniques to predict the athletes for the potential of winning medals. This can be achieved using athletes’ physical assessment parameters. The goal of this study is not only to identify the athletes based on which group they fall into (gold/silver/bronze), but also to understand which physical characteristic is important to identify them and categorize them in a medal group. It was determined that features, namely height, body mass, body mass index, 40&nbsp;m and vertical jump are the most important for achieving 98.40% accuracy for athletes to classify them in the gold category when they are in the bronze category. Unsupervised learning showed that features, namely body mass, body mass index, vertical jump, med ball, 40&nbsp;m, peak oxygen content, peak height velocity have the highest variability. We can achieve upto 97.06% accuracy when features, i.e., body mass, body mass index, vertical jump, med ball, 40&nbsp;m, peak oxygen content, peak height velocity were used.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {23697–23710},
numpages = {14},
keywords = {Neuro-fuzzy analytics, Machine learning, Multilayer perceptron model, Fuzzy c-means, Athletes}
}

@inproceedings{10.1145/3406601.3406602,
author = {Rouzbahman, Masha and Jovicic, Alexandra and Wang, Lu and Zucherman, Leon and Abul-Basher, Zahid and Charoenkitkarn, Nipon and Chignell, Mark},
title = {Data Mining Methods for Optimizing Feature Extraction and Model Selection},
year = {2020},
isbn = {9781450377591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406601.3406602},
doi = {10.1145/3406601.3406602},
abstract = {How can we carry out on-the-fly data mining on massive amounts of data, to make relevant predictions, based on data for similar observations to the one currently under consideration? In this paper we show the benefit of using large numbers of computationally efficient analyses to tune the feature extraction, and prediction, steps in data mining, using cross-validated prediction accuracy as the evaluative criterion. Different feature extraction strategies are also compared in terms of their predictive effectiveness in this context. While the research reported here focused on clinical prediction of healthcare outcomes, the results should have broader implications for large scale data mining in general.},
booktitle = {Proceedings of the 11th International Conference on Advances in Information Technology},
articleno = {1},
numpages = {8},
keywords = {Clustering, Data Mining, Feature Extraction, Health Informatics, Information Engineering, Regression},
location = {Bangkok, Thailand},
series = {IAIT '20}
}

@article{10.1007/s00180-020-00970-8,
author = {Sambasivan, Rajiv and Das, Sourish and Sahu, Sujit K.},
title = {A Bayesian perspective of statistical machine learning for big data},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {35},
number = {3},
issn = {0943-4062},
url = {https://doi.org/10.1007/s00180-020-00970-8},
doi = {10.1007/s00180-020-00970-8},
abstract = {Statistical Machine Learning (SML) refers to a body of algorithms and methods by which computers are allowed to discover important features of input data sets which are often very large in size. The very task of feature discovery from data is essentially the meaning of the keyword ‘learning’ in SML. Theoretical justifications for the effectiveness of the SML algorithms are underpinned by sound principles from different disciplines, such as Computer Science and Statistics. The theoretical underpinnings particularly justified by statistical inference methods are together termed as statistical learning theory. This paper provides a review of SML from a Bayesian decision theoretic point of view—where we argue that many SML techniques are closely connected to making inference by using the so called Bayesian paradigm. We discuss many important SML techniques such as supervised and unsupervised learning, deep learning, online learning and Gaussian processes especially in the context of very large data sets where these are often employed. We present a dictionary which maps the key concepts of SML from Computer Science and Statistics. We illustrate the SML techniques with three moderately large data sets where we also discuss many practical implementation issues. Thus the review is especially targeted at statisticians and computer scientists who are aspiring to understand and apply SML for moderately large to big data sets.},
journal = {Comput. Stat.},
month = sep,
pages = {893–930},
numpages = {38},
keywords = {Bayesian methods, Big data, Machine learning, Statistical learning}
}

@inproceedings{10.1145/3303772.3303795,
author = {Ding, Mucong and Yang, Kai and Yeung, Dit-Yan and Pong, Ting-Chuen},
title = {Effective Feature Learning with Unsupervised Learning for Improving the Predictive Models in Massive Open Online Courses},
year = {2019},
isbn = {9781450362566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3303772.3303795},
doi = {10.1145/3303772.3303795},
abstract = {The effectiveness of learning in massive open online courses (MOOCs) can be significantly enhanced by introducing personalized intervention schemes which rely on building predictive models of student learning behaviors such as some engagement or performance indicators. A major challenge that has to be addressed when building such models is to design handcrafted features that are effective for the prediction task at hand. In this paper, we make the first attempt to solve the feature learning problem by taking the unsupervised learning approach to learn a compact representation of the raw features with a large degree of redundancy. Specifically, in order to capture the underlying learning patterns in the content domain and the temporal nature of the clickstream data, we train a modified auto-encoder (AE) combined with the long short-term memory (LSTM) network to obtain a fixed-length embedding for each input sequence. When compared with the original features, the new features that correspond to the embedding obtained by the modified LSTM-AE are not only more parsimonious but also more discriminative for our prediction task. Using simple supervised learning models, the learned features can improve the prediction accuracy by up to 17% compared with the supervised neural networks and reduce overfitting to the dominant low-performing group of students, specifically in the task of predicting students' performance. Our approach is generic in the sense that it is not restricted to a specific supervised learning model nor a specific prediction task for MOOC learning analytics.},
booktitle = {Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge},
pages = {135–144},
numpages = {10},
keywords = {Autoencoder, Dimensionality Reduction, Feature Learning, Learning Behavior, Long Short-Term Memory, Unsupervised Learning},
location = {Tempe, AZ, USA},
series = {LAK19}
}

@article{10.1007/s10922-020-09512-5,
author = {Le, Duc C. and Zincir-Heywood, Nur},
title = {A Frontier: Dependable, Reliable and Secure Machine Learning for Network/System Management},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09512-5},
doi = {10.1007/s10922-020-09512-5},
abstract = {Modern networks and systems pose many challenges to traditional management approaches. Not only the number of devices and the volume of network traffic are increasing exponentially, but also new network protocols and technologies require new techniques and strategies for monitoring controlling and managing up and coming networks and systems. Moreover, machine learning has recently found its successful applications in many fields due to its capability to learn from data to automatically infer patterns for network analytics. Thus, the deployment of machine learning in network and system management has become imminent. This work provides a review of the applications of machine learning in network and system management. Based on this review, we aim to present the current opportunities and challenges in and highlight the need for dependable, reliable and secure machine learning for network and system management.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {827–849},
numpages = {23},
keywords = {Network and system management, Reliable and dependable machine learning, Secure machine learning}
}

@inproceedings{10.5555/3338290.3338338,
author = {Porokhnenko, Iuliia and Polezhaev, Petr and Shukhman, Alexander},
title = {Machine Learning Approaches to Choose Heroes in Dota 2},
year = {2019},
publisher = {FRUCT Oy},
address = {Helsinki, Uusimaa, FIN},
abstract = {The winning in the multiplayer online game Dota 2 for teams is a sum of many factors. One of the most significant of them is the right choice of heroes for the team. It is possible to predict a match result based on the chosen heroes for both teams. This paper considers different approaches to predicting results of a match using machine learning methods to solve the classification problem. The experimental comparison of predictive classification models was done, including the optimization of their hyperparameters. It showed that the best classification models are linear regression, linear support vector machine, as well as neural network with Softplus and Sigmoid activation functions. The fastest of them is the linear regression model, so it is best suited for practical implementation.},
booktitle = {Proceedings of the 24th Conference of Open Innovations Association FRUCT},
articleno = {48},
numpages = {6},
keywords = {classification models, eSports, machine learning, multiplayer online game},
location = {Moscow, Russia},
series = {FRUCT'24}
}

@inproceedings{10.1145/3132498.3133834,
author = {Santos, Marcelo C. B. and Colanzi, Thelma E. and Amaral, Aline M. M. M. and OliveiraJr, Edson},
title = {Preliminary study on the correlation of objective functions to optimize product-line architectures},
year = {2017},
isbn = {9781450353250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132498.3133834},
doi = {10.1145/3132498.3133834},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line (SPL). The Multi-Objective Approach for PLA Design (MOA4PLA) aims at optimizing the PLA design by using search algorithms easing the design activity. From an original PLA, MOA4PLA automatically obtains alternative designs to improve the original one in terms of the objectives selected for optimization. The use of search algorithms is an incipient research topic, which includes several open research questions. The evaluation model of MOA4PLA is composed of various objective functions, which use software metrics to evaluate different factors that influence on the PLA design. However, the simultaneous optimization of all objective functions is a computationally complex task. In this sense, it is worthwhile to investigate the possible correlation between objective functions because the discovery of correlated functions allows to reduce the number of objectives to be optimized by the search algorithm. Hence, in this paper we perform a preliminary study to investigate the correlation among five objective functions related to metrics that provide indicators on conventional architectural properties, such as coupling, cohesion and size. To accomplish the objective of this paper, four controlled experiments were carried out with four different PLA designs. Empirical results provide preliminary evidence that two pairs of functions are positively correlated and two other pairs of functions are negatively correlated. From such findings, several guidelines were derived to help architects to both reduce and select the objectives related to conventional architectural properties to be tackled during the PLA design optimization.},
booktitle = {Proceedings of the 11th Brazilian Symposium on Software Components, Architectures, and Reuse},
articleno = {11},
numpages = {10},
keywords = {correlation study, product-line architecture, search-based software engineering},
location = {Fortaleza, Cear\'{a}, Brazil},
series = {SBCARS '17}
}

@inproceedings{10.1145/2019136.2019173,
author = {Fukuda, Takeshi and Atarashi, Yoshitaka and Yoshimura, Kentaro},
title = {An approach to evaluate time-dependent changes in feature constraints},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019173},
doi = {10.1145/2019136.2019173},
abstract = {Feature selections mining is the process of discovering potentially feature associations and constraints in data. Especially, mining from time-series data obtains feature constraint trends. In this paper, we describe an approach to evaluate feature constraint trends and present results of two case studies. Feature selections mining was applied to a product transactions database at Hitachi. The product transactions had 148 optional features, and 8,372 products were derived from the product line. Both case studies focus on transaction-time periods: time series and time intervals. Feature selections mining discovered feature constraints around 100 rules in each study, and determined they constantly change.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {33},
numpages = {5},
keywords = {embedded systems, feature modeling, industry case study, software product line engineering},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1145/3328932,
author = {Saeed, Aaqib and Ozcelebi, Tanir and Lukkien, Johan},
title = {Multi-task Self-Supervised Learning for Human Activity Detection},
year = {2019},
issue_date = {June 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3328932},
doi = {10.1145/3328932},
abstract = {Deep learning methods are successfully used in applications pertaining to ubiquitous computing, pervasive intelligence, health, and well-being. Specifically, the area of human activity recognition (HAR) is primarily transformed by the convolutional and recurrent neural networks, thanks to their ability to learn semantic representations directly from raw input. However, in order to extract generalizable features massive amounts of well-curated data are required, which is a notoriously challenging task; hindered by privacy issues and annotation costs. Therefore, unsupervised representation learning (i.e., learning without manually labeling the instances) is of prime importance to leverage the vast amount of unlabeled data produced by smart devices. In this work, we propose a novel self-supervised technique for feature learning from sensory data that does not require access to any form of semantic labels, i.e., activity classes. We learn a multi-task temporal convolutional network to recognize transformations applied on an input signal. By exploiting these transformations, we demonstrate that simple auxiliary tasks of the binary classification result in a strong supervisory signal for extracting useful features for the down-stream task. We extensively evaluate the proposed approach on several publicly available datasets for smartphone-based HAR in unsupervised, semi-supervised and transfer learning settings. Our method achieves performance levels superior to or comparable with fully-supervised networks trained directly with activity labels, and it performs significantly better than unsupervised learning through autoencoders. Notably, for the semi-supervised case, the self-supervised features substantially boost the detection rate by attaining a kappa score between 0.7 - 0.8 with only 10 labeled examples per class. We get similar impressive performance even if the features are transferred from a different data source. Self-supervision drastically reduces the requirement of labeled activity data, effectively narrowing the gap between supervised and unsupervised techniques for learning meaningful representations. While this paper focuses on HAR as the application domain, the proposed approach is general and could be applied to a wide variety of problems in other areas.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {61},
numpages = {30},
keywords = {Self-supervised learning, deep learning, human activity recognition, multi-task learning, representation learning, semi-supervised learning, temporal convolutional neural networks, transfer learning}
}

@article{10.1016/j.knosys.2021.107164,
author = {Han, Yuzhang and Modaresnezhad, Minoo and Nemati, Hamid},
title = {An Adaptive Machine Learning System for predicting recurrence of child maltreatment: A routine activity theory perspective},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {227},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107164},
doi = {10.1016/j.knosys.2021.107164},
journal = {Know.-Based Syst.},
month = sep,
numpages = {19},
keywords = {Adaptive machine learning system, Predictive risk modeling, Routine activity theory, Child maltreatment, Big data}
}

@article{10.1007/s00779-016-0963-3,
author = {Assem, Haytham and Xu, Lei and Buda, Teodora Sandra and O'sullivan, Declan},
title = {Machine learning as a service for enabling Internet of Things and People},
year = {2016},
issue_date = {November  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {6},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-016-0963-3},
doi = {10.1007/s00779-016-0963-3},
abstract = {The future Internet is expected to connect billions of people, things and services having the potential to deliver a new set of applications by deriving new insights from the data generated from these diverse data sources. This highly interconnected global network brings new types of challenges in analysing and making sense of data. This is why machine learning is expected to be a crucial technology in the future, in making sense of data, in improving business and decision making, and in doing so, providing the potential to solve a wide range of problems in health care, telecommunications, urban computing, and others. Machine learning algorithms can learn how to perform certain tasks by generalizing examples from a range of sampling. This is a totally different paradigm than traditional programming language approaches, which are based on writing programs that process data to produce an output. However, choosing a suitable machine learning algorithm for a particular application requires a substantial amount of time and effort that is hard to undertake even with excellent research papers and textbooks. In order to reduce the time and effort, this paper introduces the TCDC (train, compare, decide, and change) approach, which can be thought as a `Machine Learning as a Service' approach, to aid machine learning researchers and practitioners to choose the optimum machine learning model to use for achieving the best trade-off between accuracy and interpretability, computational complexity, and ease of implementation. The paper includes the results of testing and evaluating the recommenders based on the TCDC approach (in comparison with the traditional default approach) applied to 12 datasets that are available as open-source datasets drawn from diverse domains including health care, agriculture, aerodynamics and others. Our results indicate that the proposed approach selects the best model in terms of predictive accuracy in 62.5 % for regression tests performed and 75 % for classification tests.},
journal = {Personal Ubiquitous Comput.},
month = nov,
pages = {899–914},
numpages = {16},
keywords = {Classification models, Machine learning, Predictive modelling, Regression models, Supervised learning}
}

@article{10.14778/3007263.3007318,
author = {Chaoji, Vineet and Rastogi, Rajeev and Roy, Gourav},
title = {Machine learning in the real world},
year = {2016},
issue_date = {September 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/3007263.3007318},
doi = {10.14778/3007263.3007318},
abstract = {Machine Learning (ML) has become a mature technology that is being applied to a wide range of business problems such as web search, online advertising, product recommendations, object recognition, and so on. As a result, it has become imperative for researchers and practitioners to have a fundamental understanding of ML concepts and practical knowledge of end-to-end modeling. This tutorial takes a hands-on approach to introducing the audience to machine learning. The first part of the tutorial gives a broad overview and discusses some of the key concepts within machine learning. The second part of the tutorial takes the audience through the end-to-end modeling pipeline for a real-world income prediction problem.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {1597–1600},
numpages = {4}
}

@article{10.1016/j.procs.2019.02.010,
author = {Merembayev, Timur and Yunussov, Rassul and Yedilkhan, Amirgaliyev},
title = {Machine Learning Algorithms for Stratigraphy Classification on Uranium Deposits},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {150},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.02.010},
doi = {10.1016/j.procs.2019.02.010},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {46–52},
numpages = {7},
keywords = {stratigraphy, classification, machine learning, uranium deposit, geophysics logging data}
}

@article{10.1016/j.cose.2020.102159,
author = {Gibert, Daniel and Mateu, Carles and Planes, Jordi and Marques-Silva, Joao},
title = {Auditing static machine learning anti-Malware tools against metamorphic attacks},
year = {2021},
issue_date = {Mar 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {102},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2020.102159},
doi = {10.1016/j.cose.2020.102159},
journal = {Comput. Secur.},
month = mar,
numpages = {23},
keywords = {Malware analysis, Malware classification, Software obfuscation, N-Gram extraction, Machine learning, Deep learning}
}

@article{10.1007/s10660-020-09409-0,
author = {Pan, Hong and Zhou, Hanxun},
title = {Study on convolutional neural network and its application in data mining and sales forecasting for E-commerce},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {2},
issn = {1389-5753},
url = {https://doi.org/10.1007/s10660-020-09409-0},
doi = {10.1007/s10660-020-09409-0},
abstract = {In recent years, the rapid development of e-commerce has brought great convenience to people. Compared with traditional business environment, e-commerce is more dynamic and complex, which brings many challenges. Data mining technology can help people better deal with these challenges. Traditional data mining technology cannot effectively use the massive data in the electricity supplier, it relies on the time-consuming and labour-consuming characteristic engineering, and the obtained model is not scalable. Convolutional neural network can effectively use a large amount of data, and can automatically extract effective features from the original data, with higher availability. In this paper, convolutional neural network is used to mine e-commerce data to achieve the prediction of commodity sales. First, this article combines the inherent nature of the relevant merchandise information with the original cargo log data that can be converted into a specific “data frame” format. Raw log data includes items sold over a long period of time, price, quantity view, browse, search, search, times collected, number of items added to cart, and many other metrics. Then, convolutional neural network is applied to extract effective features on the data frame. Finally, the final layer of the convolutional neural network uses these features to predict sales of goods. This method can automatically extract effective features from the original structured time series data by convolutional neural network, and further use these features to achieve sales forecast. The validity of the proposed algorithm is verified on the real e-commerce data set.},
journal = {Electronic Commerce Research},
month = jun,
pages = {297–320},
numpages = {24},
keywords = {Convolutional neural network, E-commerce, Data mining, Sales forecasting}
}

@inproceedings{10.1007/978-3-319-96133-0_28,
author = {Cisty, Milan and Soldanova, Veronika},
title = {Flow Prediction Versus Flow Simulation Using Machine Learning Algorithms},
year = {2018},
isbn = {978-3-319-96132-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-96133-0_28},
doi = {10.1007/978-3-319-96133-0_28},
abstract = {The paper deals with differences between two types of machine learning river flow modelling, i.e., their simulation and prediction. In this paper, “simulation” means a determination of river flows from only meteorological data. The second type of modelling, i.e., prediction, additionally includes preceding flows in the input data. Preceding flows are known at the time of making a prediction. For this reason, i.e., because less input data serve for the simulation, it is a more difficult task than the prediction, and its degree of precision is also usually lower. The authors focused on the improvement of flow simulation methodology, i.e., the determination of river flows only from climate data. Several machine learning models were tested for this purpose, and their results are compared in the paper with a conceptual hydrological model. Three options were evaluated in the paper for the improvement of the precision of the machine learning type of flows simulation: (1) the effect of the use of different types of models, (2) the impact from the expansion of input data utilizing feature engineering, and (3) improving the accuracy of the simulation by applying an ensemble paradigm. An increased degree of precision (approximately 12%) of the flow simulation was obtained after the incorporation of the above methodological enhancements to the computations (when compared to standard hydrological methods). The authors believe that the proposed methodology will be a promising alternative to the usual hydrological simulation, and it would be useful to test it in an extended study in which more streams would be evaluated.},
booktitle = {Machine Learning and Data Mining in Pattern Recognition: 14th International Conference, MLDM 2018, New York, NY, USA, July 15-19, 2018, Proceedings, Part II},
pages = {369–382},
numpages = {14},
keywords = {Flow simulation, Flow prediction, Data-driven methods},
location = {New York, NY, USA}
}

@article{10.1016/j.pmcj.2013.07.004,
author = {Zhu, Yin and Zhong, Erheng and Lu, Zhongqi and Yang, Qiang},
title = {Feature engineering for semantic place prediction},
year = {2013},
issue_date = {December, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {9},
number = {6},
issn = {1574-1192},
url = {https://doi.org/10.1016/j.pmcj.2013.07.004},
doi = {10.1016/j.pmcj.2013.07.004},
abstract = {We present in this paper our winning solution to Dedicated Task 1 in Nokia Mobile Data Challenge (MDC). MDC Task 1 is to infer the semantic category of a place based on the smartphone sensing data obtained at that place. We approach this task in a standard supervised learning setting: we extract discriminative features from the sensor data and use state-of-the-art classifiers (SVM, Logistic Regression and Decision Tree Family) to build classification models. We have found that feature engineering, or in other words, constructing features using human heuristics, is very effective for this task. In particular, we have proposed a novel feature engineering technique, Conditional Feature (CF), a general framework for domain-specific feature construction. In total, we have generated 2,796,200 features and in our final five submissions we use feature selection to select 100 to 2000 features. One of our key findings is that features conditioned on fine-granularity time intervals, e.g. every 30 min, are most effective. Our best 10-fold CV accuracy on training set is 75.1% by Gradient Boosted Trees, and the second best accuracy is 74.6% by L1-regularized Logistic Regression. Besides the good performance, we also report briefly our experience of using F# language for large-scale (~70 GB raw text data) conditional feature construction.},
journal = {Pervasive Mob. Comput.},
month = dec,
pages = {772–783},
numpages = {12},
keywords = {Classification, Domain knowledge, Feature engineering, Feature selection}
}

@inproceedings{10.1007/978-3-030-26619-6_16,
author = {Tello, Ghalia and Gianini, Gabriele and Mizouni, Rabeb and Damiani, Ernesto},
title = {Machine Learning-Based Framework for Log-Lifting in Business Process Mining Applications},
year = {2019},
isbn = {978-3-030-26618-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26619-6_16},
doi = {10.1007/978-3-030-26619-6_16},
abstract = {Real-life event logs are typically much less structured and more complex than the predefined business activities they refer to. Most of the existing process mining techniques assume that there is a one-to-one mapping between process model activities and events recorded during process execution. Unfortunately, event logs and process model activities are defined at different levels of granularity. The challenges posed by this discrepancy can be addressed by means of log-lifting. In this work we develop a machine-learning-based framework aimed at bridging the abstraction level gap between logs and process models. The proposed framework operates of two main phases: log segmentation and machine-learning-based classification. The purpose of the segmentation phase is to identify the potential segment separators in a flow of low-level events, in which each segment corresponds to an unknown high-level activity. For this, we propose a segmentation algorithm based on maximum likelihood with n-gram analysis. In the second phase, event segments are mapped into their corresponding high-level activities using a supervised machine learning technique. Several machine learning classification methods are explored including ANNs, SVMs, and random forest. We demonstrate the applicability of our framework using a real-life event log provided by the SAP company. The results obtained show that a machine learning approach based on the random forest algorithm outperforms the other methods with an accuracy of 96.4%. The testing time was found to be around 0.01s, which makes the algorithm a good candidate for real-time deployment scenarios.},
booktitle = {Business Process Management: 17th International Conference, BPM 2019, Vienna, Austria, September 1–6, 2019, Proceedings},
pages = {232–249},
numpages = {18},
keywords = {Process mining, Segmentation, Log lifting, Machine learning},
location = {Vienna, Austria}
}

@inproceedings{10.1007/978-3-030-64148-1_12,
author = {Lwakatare, Lucy Ellen and Crnkovic, Ivica and R\r{a}nge, Ellinor and Bosch, Jan},
title = {From a Data Science Driven Process to a Continuous Delivery Process for Machine Learning Systems},
year = {2020},
isbn = {978-3-030-64147-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64148-1_12},
doi = {10.1007/978-3-030-64148-1_12},
abstract = {Development of machine learning (ML) enabled applications in real-world settings is challenging and requires the consideration of sound software engineering (SE) principles and practices. A large body of knowledge exists on the use of modern approaches to developing traditional software components, but not ML components. Using exploratory case study approach, this study investigates the adoption and use of existing software development approaches, specifically continuous delivery (CD), to development of ML components. Research data was collected using a multivocal literature review (MLR) and focus group technique with ten practitioners involved in developing ML-enabled systems at a large telecommunication company. The results of our MLR show that companies do not outright apply CD to the development of ML components rather as a result of improving their development practices and infrastructure over time. A process improvement conceptual model, that includes the description of CD application to ML components is developed and initially validated in the study.},
booktitle = {Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings},
pages = {185–201},
numpages = {17},
keywords = {Machine learning system, Software process, Continuous delivery},
location = {Turin, Italy}
}

@article{10.5555/3512469.3512478,
author = {Bowman, Anthony D. and Jololian, Leon},
title = {A conceptual framework for an introductory machine learning course},
year = {2021},
issue_date = {October 2021},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {37},
number = {1},
issn = {1937-4771},
abstract = {Historically, computer science curricula have largely focused on the development of algorithmic solutions. However, in recent years a new paradigm has emerged which focuses on machine learning as a data-driven approach to problem solving. To better equip students with the background needed for this emerging method of problem solving, the curricula would benefit from including a greater emphasis on the concepts frequently found in a data-driven workflow. Furthermore, continued advances in hardware should be considered to exploit parallelism in computations. Other concepts from machine learning include data cleaning, feature engineering, and concurrency in computation. In this paper, we propose a conceptual framework for an introductory course in machine learning with a data-driven workflow. With this framework, students will be exposed to the high-level design and concepts of data-driven development, gradually equipping them with the tools to fully grasp the machine learning paradigm. Further research is ongoing to construct a development environment that supports this framework for full adoption of the machine learning paradigm.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {78–83},
numpages = {6}
}

@article{10.1016/j.inffus.2018.10.005,
author = {Diez-Olivan, Alberto and Del Ser, Javier and Galar, Diego and Sierra, Basilio},
title = {Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.10.005},
doi = {10.1016/j.inffus.2018.10.005},
journal = {Inf. Fusion},
month = oct,
pages = {92–111},
numpages = {20},
keywords = {Data-driven prognosis, Data fusion, Machine learning, Industry 4.0, ANFIS, ANNs, BPNN, DBN, DWT, EM, EWMA, FFT, FPCA, GMM, GRBMs, GRNN, HMM, kNN, KDE, LAD, LOF, PCA, PoF, RBM, RNN, SARMA, SBM, SOM-MQE, SVMs, VCM}
}

@article{10.1155/2021/1057371,
author = {Yang, Yinghui and cheikhrouhou, omar},
title = {The Potential Energy of Artificial Intelligence Technology in University Education Reform from the Perspective of Communication Science},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/1057371},
doi = {10.1155/2021/1057371},
abstract = {In today’s rapid development of science and technology, science is everywhere in people’s lives, and science communication is everywhere. Science and communication are not only not far away but also very close. Since machine learning algorithms with deep learning as a theme have achieved great success in the fields of vision and speech recognition, as well as the large amount of data resources that cloud computing, big data, and other technologies can provide, the development speed of artificial intelligence has been greatly improved, and it has had a significant impact in various industries in the society, and the country has put forward the concept of intelligent education for this purpose. However, there have been few systematic discussions on the combination of artificial intelligence with education and teaching. Therefore, this article uses artificial intelligence technology to study the potential energy space of artificial intelligence technology in college education reform from the perspective of science communication, designs and implements an online education platform for colleges and universities, and conducts a trial of platform use in a domestic college and universities. Some teachers and students conduct a satisfaction survey after the platform is used, and the conclusions show that whether in the teacher group or the student group, most teachers and students are relatively satisfied with the online education platform designed in this article. The reform of college education includes many aspects. This article is a research study on the form of college education, changing from traditional offline education to online platform education. This research can provide a certain reference for the reform of college education.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {7}
}

@article{10.1016/j.compbiomed.2021.104289,
author = {Tabaie, Azade and Orenstein, Evan W. and Nemati, Shamim and Basu, Rajit K. and Kandaswamy, Swaminathan and Clifford, Gari D. and Kamaleswaran, Rishikesan},
title = {Predicting presumed serious infection among hospitalized children on central venous lines with machine learning},
year = {2021},
issue_date = {May 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104289},
doi = {10.1016/j.compbiomed.2021.104289},
journal = {Comput. Biol. Med.},
month = may,
numpages = {7},
keywords = {Machine learning, Infection, CLABSI, Predictive model, Sepsis}
}

@inproceedings{10.1145/3468218.3469049,
author = {Pawlak, Jered and Li, Yuchen and Price, Joshua and Wright, Matthew and Al Shamaileh, Khair and Niyaz, Quamar and Devabhaktuni, Vijay},
title = {A Machine Learning Approach for Detecting and Classifying Jamming Attacks Against OFDM-based UAVs},
year = {2021},
isbn = {9781450385619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468218.3469049},
doi = {10.1145/3468218.3469049},
abstract = {In this paper, a machine learning (ML) approach is proposed to detect and classify jamming attacks on unmanned aerial vehicles (UAVs). Four attack types are implemented using software-defined radio (SDR); namely, barrage, single-tone, successive-pulse, and protocol-aware jamming. Each type is launched against a drone that uses orthogonal frequency division multiplexing (OFDM) communication to qualitatively analyze its impacts considering jamming range, complexity, and severity. Then, an SDR is utilized in proximity to the drone and in systematic testing scenarios to record the radiometric parameters before and after each attack is launched. Signal-to-noise ratio (SNR), energy threshold, and several OFDM parameters are exploited as features and fed to six ML algorithms to explore and enable autonomous jamming detection/classification. The algorithms are quantitatively evaluated with metrics including detection and false alarm rates to evaluate the received signals and facilitate efficient decision-making for improved reception integrity and reliability. The resulting ML approach detects and classifies jamming with an accuracy of 92.2% and a false-alarm rate of 1.35%.},
booktitle = {Proceedings of the 3rd ACM Workshop on Wireless Security and Machine Learning},
pages = {1–6},
numpages = {6},
keywords = {Jamming, machine learning (ML), orthogonal frequency division multiplexing (OFDM), software-defined radio (SDR), unmanned aerial vehicles (UAVs)},
location = {Abu Dhabi, United Arab Emirates},
series = {WiseML '21}
}

@article{10.1007/s11276-021-02565-7,
author = {Sharshembiev, Kumar and Yoo, Seong-Moo and Elmahdi, Elbasher},
title = {Protocol misbehavior detection framework using machine learning classification in vehicular Ad Hoc networks},
year = {2021},
issue_date = {Apr 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {3},
issn = {1022-0038},
url = {https://doi.org/10.1007/s11276-021-02565-7},
doi = {10.1007/s11276-021-02565-7},
abstract = {A novel approach is proposed to detect protocol misbehavior using state-of-the-art machine learning frameworks and entropy. Nodes in Vehicular Ad Hoc Networks (VANETs) use broadcast protocols to efficiently disseminate safety information, but nodes do not always behave according to the routing protocols. Misbehavior can be caused by a targeted attack, where an attacking vehicle can intentionally send or route malicious packets to harm. Due to the dynamic nature of nodes in VANETs and routing complexity, unintentional misbehavior can also happen due to hardware or software failures in the vehicle. We are not concerned with the targeted attacks, but rather explore how the unintentional misbehavior, which can cause statistical multi-hop routing protocols to operate as basic flooding protocols, can be detected and accurately classified. These methods and detection techniques are based on the IEEE 802.11p MAC layer and weighted p-persistence multi-hop routing protocol. The linear classification was done using the TensorFlow framework and evaluations were performed using the VEINS simulator using the p-persistence broadcast protocol in a US city area.},
journal = {Wirel. Netw.},
month = apr,
pages = {2103–2118},
numpages = {16},
keywords = {IEEE 802.11p, Linear classification, Logistic regression, Misbehaving node, Probabilistic broadcast protocols, Vehicular ad hoc networks}
}

@inproceedings{10.1609/aaai.v33i01.33011158,
author = {Solinas, Christopher and Rebstock, Douglas and Buro, Michael},
title = {Improving search with supervised learning in trick-based card games},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33011158},
doi = {10.1609/aaai.v33i01.33011158},
abstract = {In trick-taking card games, a two-step process of state sampling and evaluation is widely used to approximate move values. While the evaluation component is vital, the accuracy of move value estimates is also fundamentally linked to how well the sampling distribution corresponds the true distribution. Despite this, recent work in trick-taking card game AI has mainly focused on improving evaluation algorithms with limited work on improving sampling. In this paper, we focus on the effect of sampling on the strength of a player and propose a novel method of sampling more realistic states given move history. In particular, we use predictions about locations of individual cards made by a deep neural network — trained on data from human gameplay — in order to sample likely worlds for evaluation. This technique, used in conjunction with Perfect Information Monte Carlo (PIMC) search, provides a substantial increase in cardplay strength in the popular trick-taking card game of Skat.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {143},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@article{10.1504/ijhpsa.2020.111561,
author = {Cheng, Yusong and Lyu, Lei and Wenxin, Jin and Wang, Chenhui},
title = {Data mining model based on user reviews and star ratings},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {2–3},
issn = {1751-6528},
url = {https://doi.org/10.1504/ijhpsa.2020.111561},
doi = {10.1504/ijhpsa.2020.111561},
abstract = {With the rapid development of e-commerce, the research on sentiment analysis of online reviews has been paid more and more attention. This paper presents an Aspect-Level Sentiment Analysis Method based on long short-term memory (LSTM) and boot-strapping, which performs semantic mining and prediction on time-based data patterns and data combinations of text, star rating and helpful votes. A high prediction accuracy rate is obtained in the open data set. Compared with the traditional methods, which single analysis comment or evaluation, merchants can gain a deeper understanding of user feedback from sentiment analysis.},
journal = {Int. J. High Perform. Syst. Archit.},
month = jan,
pages = {107–116},
numpages = {9},
keywords = {LSTM, long short-term memory, boot-strapping, word2vec, aspect-level sentiment analysis, comment text, user online reviews, star ratings, online review helpfulness}
}

@article{10.1145/3034827,
author = {Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
title = {CASE Tool Support for Variability Management in Software Product Lines},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3034827},
doi = {10.1145/3034827},
abstract = {Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools’ characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {14},
numpages = {45},
keywords = {Software engineering, computer-aided software engineering, software variability}
}

@article{10.1016/j.cam.2019.112395,
author = {Chen, Zheshi and Li, Chunhong and Sun, Wenjun},
title = {Bitcoin price prediction using machine learning: An approach to sample dimension engineering},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {365},
number = {C},
issn = {0377-0427},
url = {https://doi.org/10.1016/j.cam.2019.112395},
doi = {10.1016/j.cam.2019.112395},
journal = {J. Comput. Appl. Math.},
month = feb,
numpages = {13},
keywords = {Sample dimension engineering, Occam’s Razor principle, Bitcoin price prediction, Machine learning algorithms}
}

@article{10.1145/3450288,
author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
title = {A Systematic Literature Review on Federated Machine Learning: From a Software Engineering Perspective},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450288},
doi = {10.1145/3450288},
abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {95},
numpages = {39},
keywords = {Federated learning, distributed learning, edge learning, privacy, software engineering, systematic literature review}
}

@inproceedings{10.1145/3299869.3314050,
author = {Agrawal, Pulkit and Arya, Rajat and Bindal, Aanchal and Bhatia, Sandeep and Gagneja, Anupriya and Godlewski, Joseph and Low, Yucheng and Muss, Timothy and Paliwal, Mudit Manu and Raman, Sethu and Shah, Vishrut and Shen, Bochao and Sugden, Laura and Zhao, Kaiyu and Wu, Ming-Chuan},
title = {Data Platform for Machine Learning},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3314050},
doi = {10.1145/3299869.3314050},
abstract = {In this paper, we present a purpose-built data management system, MLdp, for all machine learning (ML) datasets. ML applications pose some unique requirements different from common conventional data processing applications, including but not limited to: data lineage and provenance tracking, rich data semantics and formats, integration with diverse ML frameworks and access patterns, trial-and-error driven data exploration and evolution, rapid experimentation, reproducibility of the model training, strict compliance and privacy regulations, etc. Current ML systems/services, often named MLaaS, to-date focus on the ML algorithms, and offer no integrated data management system. Instead, they require users to bring their own data and to manage their own data on either blob storage or on file systems. The burdens of data management tasks, such as versioning and access control, fall onto the users, and not all compliance features, such as terms of use, privacy measures, and auditing, are available. MLdp offers a minimalist and flexible data model for all varieties of data, strong version management to guarantee re-producibility of ML experiments, and integration with major ML frameworks. MLdp also maintains the data provenance to help users track lineage and dependencies among data versions and models in their ML pipelines. In addition to table-stake features, such as security, availability and scalability, MLdp's internal design choices are strongly influenced by the goal to support rapid ML experiment iterations, which cycle through data discovery, data exploration, feature engineering, model training, model evaluation, and back to data discovery. The contributions of this paper are: 1) to recognize the needs and to call out the requirements of an ML data platform, 2) to share our experiences in building MLdp by adopting existing database technologies to the new problem as well as by devising new solutions, and 3) to call for actions from our communities on future challenges.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {1803–1816},
numpages = {14},
keywords = {data platform, data streaming access, data version control, dataset management for machine learning, physical data layout},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}

@inproceedings{10.1007/978-3-030-30244-3_10,
author = {Khoza, Sibusiso C. and Grobler, Jacomine},
title = {Comparing Machine Learning and Statistical Process Control for Predicting Manufacturing Performance},
year = {2019},
isbn = {978-3-030-30243-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30244-3_10},
doi = {10.1007/978-3-030-30244-3_10},
abstract = {Quality has become one of the most important factors in the success of manufacturing companies. In this paper, the use of machine learning algorithms in quality control is compared to the use of statistical process monitoring, a classical quality management technique. The test dataset has a large number of features, which requires the use of principal component analysis and clustering to isolate the data into potential process groups. A Random Forest, Support Vector Machine and Naive Bayes algorithms were used to predict when the manufacturing process is out of control. The Random Forest algorithm performed significantly better than both the Naive Bayes and SVM algorithms in all 3 clusters of the dataset. The results were benchmarked against Hotelling’s  control charts which were trained using 80% of each cluster dataset and tested on the remaining 20%. In comparison with Hotelling’s  multivariate statistical process monitoring charts, the Random Forest algorithm still emerges as the better quality control method.},
booktitle = {Progress in Artificial Intelligence: 19th EPIA Conference on Artificial Intelligence, EPIA 2019, Vila Real, Portugal, September 3–6, 2019, Proceedings, Part II},
pages = {108–119},
numpages = {12},
location = {Vila Real, Portugal}
}

@inproceedings{10.1145/3468264.3468536,
author = {Biswas, Sumon and Rajan, Hridesh},
title = {Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468536},
doi = {10.1145/3468264.3468536},
abstract = {In recent years, many incidents have been reported where machine learning models exhibited discrimination among people based on race, sex, age, etc. Research has been conducted to measure and mitigate unfairness in machine learning models. For a machine learning task, it is a common practice to build a pipeline that includes an ordered set of data preprocessing stages followed by a classifier. However, most of the research on fairness has considered a single classifier based prediction task. What are the fairness impacts of the preprocessing stages in machine learning pipeline? Furthermore, studies showed that often the root cause of unfairness is ingrained in the data itself, rather than the model. But no research has been conducted to measure the unfairness caused by a specific transformation made in the data preprocessing stage. In this paper, we introduced the causal method of fairness to reason about the fairness impact of data preprocessing stages in ML pipeline. We leveraged existing metrics to define the fairness measures of the stages. Then we conducted a detailed fairness evaluation of the preprocessing stages in 37 pipelines collected from three different sources. Our results show that certain data transformers are causing the model to exhibit unfairness. We identified a number of fairness patterns in several categories of data transformers. Finally, we showed how the local fairness of a preprocessing stage composes in the global fairness of the pipeline. We used the fairness composition to choose appropriate downstream transformer that mitigates unfairness in the machine learning pipeline.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {981–993},
numpages = {13},
keywords = {fairness, machine learning, models, pipeline, preprocessing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3449726.3463174,
author = {Dasariraju, Satvik and Urbanowicz, Ryan J.},
title = {RARE: evolutionary feature engineering for rare-variant bin discovery},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3463174},
doi = {10.1145/3449726.3463174},
abstract = {Features with rare states, such as rare genetic variants, pose a significant challenge for both statistical and machine learning analyses due to limited detection power and uncertainty surrounding the nature of their role (e.g., additive, heterogeneous, or epistatic) in predicting outcomes such as disease phenotype. Rare variant 'bins' (RVBs) hold the potential to increase association detection power. However, previously proposed binning approaches relied on prior-knowledge assumptions, instead of data-driven techniques, and ignored the potential for multivariate interactions. We present the Relevant Association Rare-variant-bin Evolver (RARE), the first evolutionary algorithm for automatically constructing and evaluating RVBs with either univariate or epistatic associations. We evaluate RARE's ability to correctly bin simulated rare-variant associations over a variety of algorithmic and dataset scenarios. Specifically, we examine (1) ability to detect RVBs of univariate effect (with or without noise), (2) using fixed vs. adaptable bins sizes, (3) employing expert knowledge to initialize bins, and (4) ability to detect RVBs interacting with a separate common variant. We present preliminary results demonstrating the feasibility, efficacy, and limitations of this proposed rare-variant feature engineering algorithm.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1335–1343},
numpages = {9},
keywords = {binning, epistasis, evolutionary algorithm, feature engineering, rare variants, relief-based algorithm},
location = {Lille, France},
series = {GECCO '21}
}

@article{10.1007/s10664-020-09808-9,
author = {Agrawal, Amritanshu and Menzies, Tim and Minku, Leandro L. and Wagner, Markus and Yu, Zhe},
title = {Better software analytics via “DUO”: Data mining algorithms using/used-by optimizers},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09808-9},
doi = {10.1007/s10664-020-09808-9},
abstract = {This paper claims that a new field of empirical software engineering research and practice is emerging: data mining using/used-by optimizers for empirical studies, or DUO. For example, data miners can generate models that are explored by optimizers. Also, optimizers can advise how to best adjust the control parameters of a data miner. This combined approach acts like an agent leaning over the shoulder of an analyst that advises “ask this question next” or “ignore that problem, it is not relevant to your goals”. Further, those agents can help us build “better” predictive models, where “better” can be either greater predictive accuracy or faster modeling time (which, in turn, enables the exploration of a wider range of options). We also caution that the era of papers that just use data miners is coming to an end. Results obtained from an unoptimized data miner can be quickly refuted, just by applying an optimizer to produce a different (and better performing) model. Our conclusion, hence, is that for software analytics it is possible, useful and necessary to combine data mining and optimization using DUO.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {2099–2136},
numpages = {38},
keywords = {Software analytics, Data mining, Optimization, Evolutionary algorithms}
}

@inproceedings{10.1145/3097983.3098163,
author = {Anderson, Blake and McGrew, David},
title = {Machine Learning for Encrypted Malware Traffic Classification: Accounting for Noisy Labels and Non-Stationarity},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098163},
doi = {10.1145/3097983.3098163},
abstract = {The application of machine learning for the detection of malicious network traffic has been well researched over the past several decades; it is particularly appealing when the traffic is encrypted because traditional pattern-matching approaches cannot be used. Unfortunately, the promise of machine learning has been slow to materialize in the network security domain. In this paper, we highlight two primary reasons why this is the case: inaccurate ground truth and a highly non-stationary data distribution. To demonstrate and understand the effect that these pitfalls have on popular machine learning algorithms, we design and carry out experiments that show how six common algorithms perform when confronted with real network data. With our experimental results, we identify the situations in which certain classes of algorithms underperform on the task of encrypted malware traffic classification. We offer concrete recommendations for practitioners given the real-world constraints outlined. From an algorithmic perspective, we find that the random forest ensemble method outperformed competing methods. More importantly, feature engineering was decisive; we found that iterating on the initial feature set, and including features suggested by domain experts, had a much greater impact on the performance of the classification system. For example, linear regression using the more expressive feature set easily outperformed the random forest method using a standard network traffic representation on all criteria considered. Our analysis is based on millions of TLS encrypted sessions collected over 12 months from a commercial malware sandbox and two geographically distinct, large enterprise networks.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1723–1732},
numpages = {10},
keywords = {machine learning, malware detection, network security, tls},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3183713.3197387,
author = {Dong, Xin Luna and Rekatsinas, Theodoros},
title = {Data Integration and Machine Learning: A Natural Synergy},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183713.3197387},
doi = {10.1145/3183713.3197387},
abstract = {There is now more data to analyze than ever before. As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
pages = {1645–1650},
numpages = {6},
keywords = {data enrichment, data integration, machine learning},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@inproceedings{10.1145/2815400.2815401,
author = {Tang, Chunqiang and Kooburat, Thawan and Venkatachalam, Pradeep and Chander, Akshay and Wen, Zhe and Narayanan, Aravind and Dowell, Patrick and Karl, Robert},
title = {Holistic configuration management at Facebook},
year = {2015},
isbn = {9781450338349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815400.2815401},
doi = {10.1145/2815400.2815401},
abstract = {Facebook's web site and mobile apps are very dynamic. Every day, they undergo thousands of online configuration changes, and execute trillions of configuration checks to personalize the product features experienced by hundreds of million of daily active users. For example, configuration changes help manage the rollouts of new product features, perform A/B testing experiments on mobile devices to identify the best echo-canceling parameters for VoIP, rebalance the load across global regions, and deploy the latest machine learning models to improve News Feed ranking. This paper gives a comprehensive description of the use cases, design, implementation, and usage statistics of a suite of tools that manage Facebook's configuration end-to-end, including the frontend products, backend systems, and mobile apps.},
booktitle = {Proceedings of the 25th Symposium on Operating Systems Principles},
pages = {328–343},
numpages = {16},
location = {Monterey, California},
series = {SOSP '15}
}

@inproceedings{10.1109/WAIN52551.2021.00028,
author = {Lewis, Grace A. and Bellomo, Stephany and Ozkaya, Ipek},
title = {Characterizing and Detecting Mismatch in Machine-Learning-Enabled Systems},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/WAIN52551.2021.00028},
doi = {10.1109/WAIN52551.2021.00028},
abstract = {Increasing availability of machine learning (ML) frameworks and tools, as well as their promise to improve solutions to data-driven decision problems, has resulted in popularity of using ML techniques in software systems. However, end-to-end development of ML-enabled systems, as well as their seamless deployment and operations, remain a challenge. One reason is that development and deployment of ML-enabled systems involves three distinct workflows, perspectives, and roles, which include data science, software engineering, and operations. These three distinct perspectives, when misaligned due to incorrect assumptions, cause ML mismatches which can result in failed systems. We conducted an interview and survey study where we collected and validated common types of mismatches that occur in end-to-end development of ML-enabled systems. Our analysis shows that how each role prioritizes the importance of relevant mismatches varies, potentially contributing to these mismatched assumptions. In addition, the mismatch categories we identified can be specified as machine readable descriptors contributing to improved ML-enabled system development. In this paper, we report our findings and their implications for improving end-to-end ML-enabled system development.},
booktitle = {2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)},
pages = {133–140},
numpages = {8},
location = {Madrid, Spain}
}

@article{10.1016/j.dss.2021.113559,
author = {Irarr\'{a}zaval, Mar\'{\i}a Elisa and Maldonado, Sebasti\'{a}n and P\'{e}rez, Juan and Vairetti, Carla},
title = {Telecom traffic pumping analytics via explainable data science},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {150},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2021.113559},
doi = {10.1016/j.dss.2021.113559},
journal = {Decis. Support Syst.},
month = nov,
numpages = {14},
keywords = {Fraud prediction, Unsupervised learning, Interpretable machine learning, EXplainable AI (XAI), Telecommunications}
}

@inproceedings{10.1145/2364412.2364422,
author = {Damiani, Ferruccio and Owe, Olaf and Dovland, Johan and Schaefer, Ina and Johnsen, Einar Broch and Yu, Ingrid Chieh},
title = {A transformational proof system for delta-oriented programming},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364422},
doi = {10.1145/2364412.2364422},
abstract = {Delta-oriented programming is a modular, yet flexible technique to implement software product lines. To efficiently verify the specifications of all possible product variants of a product line, it is usually infeasible to generate all product variants and to verify them individually. To counter this problem, we propose a transformational proof system in which the specifications in a delta module describe changes to previous specifications. Our approach allows each delta module to be verified in isolation, based on symbolic assumptions for calls to methods which may be in other delta modules. When product variants are generated from delta modules, these assumptions are instantiated by the actual guarantees of the methods in the considered product variant and used to derive the specifications of this product variant.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {53–60},
numpages = {8},
keywords = {program verification, proof system, software product line},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s10664-021-09955-7,
author = {Daoudi, Nadia and Allix, Kevin and Bissyand\'{e}, Tegawend\'{e} F. and Klein, Jacques},
title = {Lessons Learnt on Reproducibility in Machine Learning Based Android Malware Detection},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09955-7},
doi = {10.1007/s10664-021-09955-7},
abstract = {A well-known curse of computer security research is that it often produces systems that, while technically sound, fail operationally. To overcome this curse, the community generally seeks to assess proposed systems under a variety of settings in order to make explicit every potential bias. In this respect, recently, research achievements on machine learning based malware detection are being considered for thorough evaluation by the community. Such an effort of comprehensive evaluation supposes first and foremost the possibility to perform an independent reproduction study in order to sharpen evaluations presented by approaches’ authors. The question Can published approaches actually be reproduced? thus becomes paramount despite the little interest such mundane and practical aspects seem to attract in the malware detection field. In this paper, we attempt a complete reproduction of five Android Malware Detectors from the literature and discuss to what extent they are “reproducible”. Notably, we provide insights on the implications around the guesswork that may be required to finalise a working implementation. Finally, we discuss how barriers to reproduction could be lifted, and how the malware detection field would benefit from stronger reproducibility standards—like many various fields already have.},
journal = {Empirical Softw. Engg.},
month = jul,
numpages = {53},
keywords = {Android malware dection, Machine learning, Reproducibility, Replicability}
}

@inproceedings{10.1145/3230833.3232818,
author = {Anton, Simon Duque and Kanoor, Suneetha and Fraunholz, Daniel and Schotten, Hans Dieter},
title = {Evaluation of Machine Learning-based Anomaly Detection Algorithms on an Industrial Modbus/TCP Data Set},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3232818},
doi = {10.1145/3230833.3232818},
abstract = {In the context of the Industrial Internet of Things, communication technology, originally used in home and office environments, is introduced into industrial applications. Commercial off-the-shelf products, as well as unified and well-established communication protocols make this technology easy to integrate and use. Furthermore, productivity is increased in comparison to classic industrial control by making systems easier to manage, set up and configure. Unfortunately, most attack surfaces of home and office environments are introduced into industrial applications as well, which usually have very few security mechanisms in place. Over the last years, several technologies tackling that issue have been researched. In this work, machine learning-based anomaly detection algorithms are employed to find malicious traffic in a synthetically generated data set of Modbus/TCP communication of a fictitious industrial scenario. The applied algorithms are Support Vector Machine (SVM), Random Forest, k-nearest neighbour and k-means clustering. Due to the synthetic data set, supervised learning is possible. Support Vector Machine and k-nearest neighbour perform well with different data sets, while k-nearest neighbour and k-means clustering do not perform satisfactorily.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {41},
numpages = {9},
keywords = {Anomaly Detection, IT-Security, Industrial, Machine Learning, Modbus},
location = {Hamburg, Germany},
series = {ARES '18}
}

@inproceedings{10.1145/3445970.3451155,
author = {Kundu, Partha Pratim and Anatharaman, Lux and Truong-Huu, Tram},
title = {An Empirical Evaluation of Automated Machine Learning Techniques for Malware Detection},
year = {2021},
isbn = {9781450383202},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445970.3451155},
doi = {10.1145/3445970.3451155},
abstract = {Nowadays, it is increasingly difficult even for a machine learning expert to incorporate all of the recent best practices into their modeling due to the fast development of state-of-the-art machine learning techniques. For the applications that handle big data sets, the complexity of the problem of choosing the best performing model with the best hyper-parameter setting becomes harder. In this work, we present an empirical evaluation of automated machine learning (AutoML) frameworks or techniques that aim to optimize hyper-parameters for machine learning models to achieve the best achievable performance. We apply AutoML techniques to the malware detection problem, which requires achieving the true positive rate as high as possible while reducing the false positive rate as low as possible. We adopt two AutoML frameworks, namely AutoGluon-Tabular and Microsoft Neural Network Intelligence (NNI) to optimize hyper-parameters of a Light Gradient Boosted Machine (LightGBM) model for classifying malware samples. We carry out extensive experiments on two data sets. The first data set is a publicly available data set (EMBER data set), that has been used as a benchmarking data set for many malware detection works. The second data set is a private data set we have acquired from a security company that provides recently-collected malware samples. We provide empirical analysis and performance comparison of the two AutoML frameworks. The experimental results show that AutoML frameworks could identify the set of hyper-parameters that significantly outperform the performance of the model with the known best performing hyper-parameter setting and improve the performance of a LightGBM classifier with respect to the true positive rate from $86.8%$ to $90%$ at $0.1%$ of false positive rate on EMBER data set and from $80.8%$ to $87.4%$ on the private data set.},
booktitle = {Proceedings of the 2021 ACM Workshop on Security and Privacy Analytics},
pages = {75–81},
numpages = {7},
keywords = {automated machine learning, hyper-parameter optimization, malware detection},
location = {Virtual Event, USA},
series = {IWSPA '21}
}

@inproceedings{10.1007/978-3-030-03496-2_31,
author = {Tall\'{o}n-Ballesteros, Antonio J. and Tuba, Milan and Xue, Bing and Hashimoto, Takako},
title = {Feature Selection and Interpretable Feature Transformation: A Preliminary Study on Feature Engineering for Classification Algorithms},
year = {2018},
isbn = {978-3-030-03495-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-03496-2_31},
doi = {10.1007/978-3-030-03496-2_31},
abstract = {This paper explores the limitation of consistency-based measures in the context of feature selection. These kinds of filters are not very widespread in large-dimensionality problems. Typically, the number of selected of attributes is very small and the ability to do right predictions is a drawback. The principal contribution of this work is the introduction of a new approach within feature engineering to create new attributes after the feature selection stage. The experimentation on multi-class problems with a feature space in the order of tens of thousands shed light on that some improvements took place with the new proposal. As a final insight, some new relationships were discovered due to the combined application of feature selection and feature transformation. Additionally, a new measure for classification problems which relates the number of features and the number of classes or labels is also proposed.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2018: 19th International Conference,  Madrid, Spain, November 21–23, 2018, Proceedings, Part II},
pages = {280–287},
numpages = {8},
keywords = {Classification, Feature engineering, Feature selection, Data mining, Feature discovery, Feature transformation},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3318299.3318345,
author = {Li, ZhanJun and Shao, Yan},
title = {A Survey of Feature Selection for Vulnerability Prediction Using Feature-based Machine Learning},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318345},
doi = {10.1145/3318299.3318345},
abstract = {This paper summarized the basic process of software vulnerability prediction using feature-based machine learning for the first time. In addition to sorting out the related types and basis of vulnerability features definition, the advantages and disadvantages of different methods are compared. Finally, this paper analyzed the difficulties and challenges in this research field, and put forward some suggestions for future work.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {36–42},
numpages = {7},
keywords = {Software vulnerability prediction, feature, machine learning},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1016/j.artmed.2019.07.004,
author = {Li, Xiaowei and Zhang, Xin and Zhu, Jing and Mao, Wandeng and Sun, Shuting and Wang, Zihan and Xia, Chen and Hu, Bin},
title = {Depression recognition using machine learning methods with different feature generation strategies},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {99},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2019.07.004},
doi = {10.1016/j.artmed.2019.07.004},
journal = {Artif. Intell. Med.},
month = aug,
numpages = {15},
keywords = {Depression, EEG, Ensemble model, Deep learning}
}

@inproceedings{10.1145/3301275.3302280,
author = {Arendt, Dustin and Saldanha, Emily and Wesslen, Ryan and Volkova, Svitlana and Dou, Wenwen},
title = {Towards rapid interactive machine learning: evaluating tradeoffs of classification without representation},
year = {2019},
isbn = {9781450362726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301275.3302280},
doi = {10.1145/3301275.3302280},
abstract = {Our contribution is the design and evaluation of an interactive machine learning interface that rapidly provides the user with model feedback after every interaction. To address visual scalability, this interface communicates with the user via a "tip of the iceberg" approach, where the user interacts with a small set of recommended instances for each class. To address computational scalability, we developed an O(n) classification algorithm that incorporates user feedback incrementally, and without consulting the data's underlying representation matrix. Our computational evaluation showed that this algorithm has similar accuracy to several off-the-shelf classification algorithms with small amounts of labeled data. Empirical evaluation revealed that users performed better using our design compared to an equivalent active learning setup.},
booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
pages = {591–602},
numpages = {12},
keywords = {active learning, hierarchical clustering, interactive machine learning, representation-free classifier, transduction learning, visual interactive labeling},
location = {Marina del Ray, California},
series = {IUI '19}
}

@inproceedings{10.1007/978-3-030-26250-1_32,
author = {Robin, Jacques and Mazo, Raul and Madeira, Henrique and Barbosa, Raul and Diaz, Daniel and Abreu, Salvador},
title = {A Self-certifiable Architecture for Critical Systems Powered by Probabilistic Logic Artificial Intelligence},
year = {2019},
isbn = {978-3-030-26249-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26250-1_32},
doi = {10.1007/978-3-030-26250-1_32},
abstract = {We present a versatile architecture for AI-powered self-adaptive self-certifiable critical systems. It aims at supporting semi-automated low-cost re-certification for self-adaptive systems after each adaptation of their behavior to a persistent change in their operational environment throughout their lifecycle.},
booktitle = {Computer Safety, Reliability, and Security: SAFECOMP 2019 Workshops, ASSURE, DECSoS, SASSUR, STRIVE, and WAISE, Turku, Finland, September 10, 2019, Proceedings},
pages = {391–397},
numpages = {7},
keywords = {AI certification, Autonomic architecture, Argumentation, Rule-based constraint solving, Probabilistic logic machine learning},
location = {Turku, Finland}
}

@article{10.1016/j.envsoft.2021.105170,
author = {Cui, Tao and Pagendam, Dan and Gilfedder, Mat},
title = {Gaussian process machine learning and Kriging for groundwater salinity interpolation},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {144},
number = {C},
issn = {1364-8152},
url = {https://doi.org/10.1016/j.envsoft.2021.105170},
doi = {10.1016/j.envsoft.2021.105170},
journal = {Environ. Model. Softw.},
month = oct,
numpages = {12},
keywords = {Groundwater salinity, Airborne electromagnetic (AEM), Musgrave Province Australia, Cokriging}
}

@inproceedings{10.1145/3148055.3149270,
author = {Wang, Jonathan and Wu, Kesheng and Sim, Alex and Hwangbo, Seongwook},
title = {Feature Engineering and Classification Models for Partial Discharge Events in Power Transformers},
year = {2017},
isbn = {9781450355490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148055.3149270},
doi = {10.1145/3148055.3149270},
abstract = {To ensure the reliability of power transformers, they are monitored for partial discharge (PD) events, which are symptoms of trans- former failure. Our goal is to classify PDs to gain an understanding of the location of failure. We develop a small set of features and a stacking ensemble that outperform larger feature sets and other models in both accuracy and variaTo ensure the reliability of power transformers, they are monitored for partial discharge (PD) events, which are symptoms of transformer failure. Our goal is to classify PDs to gain an understanding of the location of failure. We develop a small set of features and a stacking ensemble that outperform larger feature sets and other models in both accuracy and variance.nce.},
booktitle = {Proceedings of the Fourth IEEE/ACM International Conference on Big Data Computing, Applications and Technologies},
pages = {269–270},
numpages = {2},
keywords = {classification, ensemble, feature engineering, machine learning},
location = {Austin, Texas, USA},
series = {BDCAT '17}
}

@inproceedings{10.1145/3443279.3443299,
author = {Xiao, Rui and Guo, Wenbin and Zhang, Yunchun and Ma, Xiaoyan and Jiang, Jiaqi},
title = {Machine Learning-based Automated Essay Scoring System for Chinese Proficiency Test (HSK)},
year = {2021},
isbn = {9781450377607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3443279.3443299},
doi = {10.1145/3443279.3443299},
abstract = {Automated essay scoring (AES) gains momentum recently in English-based environment. However, the development of Chinese AES system is slow and fruitless. Many foreign students participate in the Chinese Proficiency Test (HSK) so a HSK automated essay scoring system (HSK AES) is in high demand. To develop an effective and reliable HSK AES system, this paper proposes three machine learning and deep learning models that take HSK essays as input. We apply Word2vec and TF-IDF (term frequency-inverse document frequency) methods to extract important features from the original essays. Three machine learning models, including XGBoost, one deep neural network with flatten and dense layer and another deep neural network with LSTM (long short-term memory) and dense layer, are trained. The experimental results show that XGBoost with TF-IDF outperforms the other two models with the lowest MAE (mean absolute error) as 6.7%. We also prove that deep neural networks either with LSTM (long short-term memory) or with flatten perform unsatisfactory on HSK AES.},
booktitle = {Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval},
pages = {18–23},
numpages = {6},
keywords = {Automated essay scoring, Chinese Proficiency Test (HSK), machine learning, natural language processing},
location = {Seoul, Republic of Korea},
series = {NLPIR '20}
}

@inproceedings{10.1145/3109729.3109758,
author = {Ben Snaiba, Ziad and de Vink, Erik P. and Willemse, Tim A.C.},
title = {Family-Based Model Checking of SPL based on mCRL2},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109758},
doi = {10.1145/3109729.3109758},
abstract = {We discuss how the general-purpose model checker mCRL2 can be used for family-based verification of behavioral properties of software product lines. This is achieved by exploiting a feature-oriented extension of the modal μ-calculus for the specification of SPL properties, and for its model checking by encoding it back into the logic of mCRL2. Using the example of the well-known minepump SPL an illustration of the possibilities of the approach is given.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {13–16},
numpages = {4},
keywords = {Family-based model checking, Software Product Lines, mCRL2},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1007/s10916-019-1418-y,
author = {Klute, Brian and Homb, Andrew and Chen, Wei and Stelpflug, Aaron},
title = {Predicting Outpatient Appointment Demand Using Machine Learning and Traditional Methods},
year = {2019},
issue_date = {Sep 2019},
publisher = {Plenum Press},
address = {USA},
volume = {43},
number = {9},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-019-1418-y},
doi = {10.1007/s10916-019-1418-y},
abstract = {Traditional methods have long been used for clinical demand forecasting. Machine learning methods represent the next evolution in forecasting, but model choice and optimization remain challenging for achieving optimal results. To determine the best method to predict demand for outpatient appointments comparing machine learning and traditional methods, this retrospective study analyzed “appointment requests” at a major outpatient department in a destination medical center. Two separate locations (A and B) were assessed with 20 traditional, hybrid (traditional + machine learning) and machine learning methods to determine the best forecasting outcome (lowest Forecast Standard Error, FSE). Data characteristics from both datasets were examined. 20 forecasting models were then assessed and compared for the best result. Location A’s data displayed a cyclical and non-trending pattern while Location B’s displayed a cyclical and trending pattern. Both Location A and B yielded the feature engineered XGBoost model (machine learning) with the lowest out-of-sample FSE. It is important to carefully analyze and understand the underlying data set pattern and then test a variety of traditional, machine learning, and hybrid prediction methods to achieve optimal predictive results. Additionally, the use of feature engineering or hybrid methods can augment the usefulness of machine learning methods.},
journal = {J. Med. Syst.},
month = sep,
pages = {1–10},
numpages = {10},
keywords = {Machine learning, Traditional methods, Outpatient appointment, Forecasting}
}

@inproceedings{10.1145/3501409.3501576,
author = {Han, Ao and Zhao, Zhenyu and Feng, Chaochao and Zhang, Shuzheng},
title = {Stage-based Path Delay Prediction with Customized Machine Learning Technique},
year = {2022},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501576},
doi = {10.1145/3501409.3501576},
abstract = {Static timing analysis is an important timing analysis technique in the physical design process of integrated circuits, facing the challenge of speed and accuracy trade-off in advanced nodes. Expensive and burdensome path-based analysis (PBA) forces designers to adopt faster graph-based analysis (GBA) in more early flows at the cost of pessimism. Existing work focuses on reducing pessimism but ignores the degree of optimism. In this paper, we propose a stage-based delay model based on machine learning technique with customized loss function to rapidly generate predicted PBA timing results from the pessimistic GBA timing report with considering the asymmetric loss. The model could also enable the designers to identify the false violation path in GBA report with less time cost to reduce the over-design and margin in post-route optimization phase. Experimental results demonstrate that the mean absolute error of predicted PBA slack divergence reduces 66.7%~79.8% compared to GBA-PBA slack divergence (from 17.79ps to 5.92ps and 3.6ps) with about 3X runtime overhead reduction on a 28nm industrial ASIC for each corner. It can also correct about 75.6% false violation paths in GBA timing report.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {926–933},
numpages = {8},
keywords = {Customized machine learning, False violation path calibration, PBA prediction, Static timing analysis},
location = {Xiamen, China},
series = {EITCE '21}
}

@inproceedings{10.5555/3504035.3505100,
author = {Samareh, Aven and Jin, Yan and Wang, Zhangyang and Chang, Xiangyu and Huang, Shuai},
title = {Predicting depression severity by multi-modal feature engineering and fusion},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {We present our preliminary work to determine if patient's vocal acoustic, linguistic, and facial patterns could predict clinical ratings of depression severity, namely Patient Health Questionnaire depression scale (PHQ-8). We proposed a multi-modal fusion model that combines three different modalities: audio, video, and text features. By training over the AVEC2017 dataset, our proposed model outperforms each single-modality prediction model, and surpasses the dataset baseline with a nice margin.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1065},
numpages = {2},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@article{10.1016/j.procs.2018.08.100,
author = {Zykov, Sergey V. and Shumsky, Leonid D. and Tykushin, Anatoly V. and Tormasov, Alexander G.},
title = {Applicative-based automatic configuration management for virtual machines},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {126},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.08.100},
doi = {10.1016/j.procs.2018.08.100},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1771–1778},
numpages = {8},
keywords = {virtual machine, automatic configuration, applicative computing}
}

@inproceedings{10.1145/3106195.3106202,
author = {Wille, David and Wehling, Kenny and Seidl, Christoph and Pluchator, Martin and Schaefer, Ina},
title = {Variability Mining of Technical Architectures},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106202},
doi = {10.1145/3106195.3106202},
abstract = {Technical architectures (TAs) represent the computing infrastructure of a company with all its hardware and software components. Over the course of time, the number of TAs grows with the companies' requirements and usually a large variety of TAs has to be maintained. Core challenge is the missing information on relations between the existing variants of TAs, which complicates reuse of solutions across systems. However, identifying these relations is an expensive task as architects have to manually analyze each TA individually. Restructuring the existing TAs poses severe risks as often sufficient information is not available (e.g., due to time constraints). To avoid failures in productive systems and resulting loss of profit, companies continue to create new solutions without restructuring existing ones. This increased variability in TAs represents technical debt. In this paper, we adapt the idea of variability mining from the software product line domain and present an efficient and automatic mining algorithm to identify the common and varying parts of TAs by analyzing a potentially arbitrary number of TAs in parallel. Using the identified variability information, architects are capable of analyzing the relations of TAs, identifying reuse potential, and making well-founded maintenance decisions. We show the feasibility and scalability of our approach by applying it to a real-world industrial case study with large sets of TAs.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {39–48},
numpages = {10},
keywords = {enterprise architecture, technical architecture, variability mining},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1007/978-3-030-78710-3_64,
author = {Rodrigo, Miguel and Pagano, Benjamin and Takur, Sumiran and Liberos, Alejandro and Sebasti\'{a}n, Rafael and Narayan, Sanjiv M.},
title = {Intra-cardiac Signatures of Atrial Arrhythmias Identified by Machine Learning and Traditional Features},
year = {2021},
isbn = {978-3-030-78709-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78710-3_64},
doi = {10.1007/978-3-030-78710-3_64},
abstract = {Intracardiac devices separate atrial arrhythmias (AA) from sinus rhythm (SR) using electrogram (EGM) features such as rate, that are imperfect. We hypothesized that machine learning could improve this classification.In 71 persistent AF patients (50 male, 65 ± 11 years) we recorded unipolar and bipolar intracardiac EGMs for 1&nbsp;min prior to ablation, providing 50,190 unipolar and 44,490 bipolar non-overlapping 4&nbsp;s segments. We developed custom deep learning models to detect SR or AA, with 10-fold cross-validation, compared to classical analyses of cycle length (CL), Dominant Frequency (DF) and autocorrelation.Classical analyses of single features were modestly effective with AUC ranging from 0.91 (DF) to 0.70 for other rate metrics. Performance increased by combining features linearly (AUC 0.991/0.987 for unipolar/bipolar), by Bagged Trees (0.995/0.991) or K-Nearest Neighbors (0.985/0.991). Convolutional deep learning of raw EGMs with no feature engineering provided improved AUC of 0.998/0.995 to separate AA from SR.Deep learning of raw EGMs outperforms classic rule-based classifiers of SR or AA. This could improve device diagnosis, and the logic developed by deep learning could shed novel insights into EGM analyses beyond current classification based on EGM features and rules.},
booktitle = {Functional Imaging and Modeling of the Heart: 11th International Conference, FIMH 2021, Stanford, CA, USA, June 21-25, 2021, Proceedings},
pages = {671–678},
numpages = {8},
keywords = {Atrial arrhythmias, Machine learning, Signal features},
location = {Stanford, CA, USA}
}

@article{10.1007/s11192-021-03951-w,
author = {Mihaljevi\'{c}, Helena and Santamar\'{\i}a, Luc\'{\i}a},
title = {Disambiguation of author entities in ADS using supervised learning and graph theory methods},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {126},
number = {5},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-021-03951-w},
doi = {10.1007/s11192-021-03951-w},
abstract = {Disambiguation of authors in digital libraries is essential for many tasks, including efficient bibliographical searches and scientometric analyses to the level of individuals. The question of how to link documents written by the same person has been given much attention by academic publishers and information retrieval researchers alike. Usual approaches rely on publications’ metadata such as affiliations, email addresses, co-authors, or scholarly topics. Lack of homogeneity in the structure of bibliographic collections and discipline-specific dissimilarities between them make the creation of general-purpose disambiguators arduous. We present an algorithm to disambiguate authorships in the Astrophysics Data System (ADS) following an established semi-supervised approach of training a classifier on authorship pairs and clustering the resulting graphs. Due to the lack of high-signal features such as email addresses and citations, we engineer additional content- and location-based features via text embeddings and named-entity recognition. We train various nonlinear tree-based classifiers and detect communities from the resulting weighted graphs through label propagation, a fast yet efficient algorithm that requires no tuning. The resulting procedure reaches reasonable complexity and offers possibilities for interpretation. We apply our method to the creation of author entities in a recent ADS snapshot. The algorithm is evaluated on 39 manually-labeled author blocks comprising 9545 authorships from 562 author profiles. Our best approach utilizes the Random Forest classifier and yields a micro- and macro-averaged BCubed F1 score of 0.95 and 0.87, respectively. We release our code and labeled data publicly to foster the development of further disambiguation procedures for ADS.},
journal = {Scientometrics},
month = may,
pages = {3893–3917},
numpages = {25},
keywords = {Author name disambiguation, Record linkage, Supervised learning, Label Propagation, Information retrieval, Digital libraries}
}

@inproceedings{10.1145/3341620.3341634,
author = {Alsaqabi, Anadil and Aldhubayi, Fatimah and Albahli, Saleh},
title = {Using Machine Learning for Prediction of Factors Affecting Crimes in Saudi Arabia},
year = {2019},
isbn = {9781450360913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341620.3341634},
doi = {10.1145/3341620.3341634},
abstract = {Crime rates are expected to increase in the whole world as the growth of many complex factors like: unemployment, poverty, weather, violent ideologies and religion and etc. Obviously crimes have negatively influenced the development of society, economic progress and reputation of a nation. Hence, Analyzing large volume of data with machine learning algorithms can be used to predict the crime distribution over an area to provide indicators of specific areas which may become a criminal hotspot. The aim of this paper is to predict factors that most affected crimes in Saudi Arabia by developing a machine learning model to predict an acceptable output value. Our results show that Factor Analysis of Mixed Data (FAMD) as features selection methods showed more accurate on machine learning classifiers rather than Principal Component Analysis (PCA) method. Na\"{\i}ve Bayes classifier perform better than other classifiers on both features selections methods with accuracy 97.53% for FAMD and PCA equals to 97.10%.},
booktitle = {Proceedings of the 2019 International Conference on Big Data Engineering},
pages = {57–62},
numpages = {6},
keywords = {Crime Category, Crime prediction, Machine learning, Predictive model},
location = {Hong Kong, Hong Kong},
series = {BDE '19}
}

@article{10.1016/j.cmpb.2019.104992,
author = {Abdar, Moloud and Ksi\k{a}\.{z}ek, Wojciech and Acharya, U Rajendra and Tan, Ru-San and Makarenkov, Vladimir and P\l{}awiak, Pawe\l{}},
title = {A new machine learning technique for an accurate diagnosis of coronary artery disease},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {179},
number = {C},
issn = {0169-2607},
url = {https://doi.org/10.1016/j.cmpb.2019.104992},
doi = {10.1016/j.cmpb.2019.104992},
journal = {Comput. Methods Prog. Biomed.},
month = oct,
numpages = {11},
keywords = {Coronary artery disease (CAD), Machine learning, Normalization, Genetic algorithm, Particle swarm optimization, Feature selection, Classification}
}

@inproceedings{10.1145/3449726.3461420,
author = {Picek, Stjepan and Jakobovic, Domagoj},
title = {Evolutionary computation and machine learning in cryptology},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3461420},
doi = {10.1145/3449726.3461420},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1089–1118},
numpages = {30},
location = {Lille, France},
series = {GECCO '21}
}

@inproceedings{10.1145/3419635.3419716,
author = {Jinping, Lu and Zhi, Tang and Jian, Mao and Zhiling, Gu and Jiemin, Zhang},
title = {Mixed-Models Method Based on Machine Learning in Detecting WebShell Attack},
year = {2020},
isbn = {9781450387729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419635.3419716},
doi = {10.1145/3419635.3419716},
abstract = {WebShell is a command execution environment in the form of web files and also a remote administration tool in web containers. However, it is also a web page backdoor for attackers. Malicious WebShell endangers safety of the Web services. Traditional detection methods, which suitable for general WebShell attack scripts, are based on rule matching. Effectively detecting mutant WebShell has become a great difficulty in computer security worldwide. Mutant scripts of PHP WebShell are the most numerous, complicated and difficult to detect in all kinds of mutant WebShell. This paper proposed a mixed model based on Machine Learning that is used to detect WebShell in different classifications. Using many feature engineering and sample balancing algorithms, the model mixes Machine Learning algorithms of Random Forest (RF) and Convolutional Neural Networks (CNN). It proposed a practicable intelligent solution for mutant WebShell attack detection with the optimized precision rate over 97%.},
booktitle = {Proceedings of the 2020 International Conference on Computers, Information Processing and Advanced Education},
pages = {251–259},
numpages = {9},
keywords = {Feature Extraction, Machine Learning, Opcode, Sample Balancing, WebShell},
location = {Ottawa, ON, Canada},
series = {CIPAE 2020}
}

@article{10.1007/s00165-013-0276-5,
author = {Sampath, Prahladavaradan},
title = {An elementary theory of product-line variations},
year = {2014},
issue_date = {Jul 2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {4},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-013-0276-5},
doi = {10.1007/s00165-013-0276-5},
abstract = {The primary aim of a software product-line is to maximise reuse of software components by managing the variability in component functionalities and product configurations. Feature oriented domain analysis (FODA) diagrams are a formalism for modelling the variability in a software product-line, and are used as a tool for managing a product-line and planning its evolution. This paper presents an elementary theory of variations in a product-line, leading up to a technique for extracting FODA diagrams from legacy product-lines. The theory is elementary in the sense that it is built using very simple mathematical structures, making minimal assumptions on the structure of product-lines. Examples drawn from the automotive domain are used to illustrate the theoretical developments.},
journal = {Form. Asp. Comput.},
month = jul,
pages = {695–727},
numpages = {33},
keywords = {SPLE, FODA, Formal concept analysis, Lattice theory}
}

@inproceedings{10.1145/3106195.3106207,
author = {Li, Yang and Schulze, Sandro and Saake, Gunter},
title = {Reverse Engineering Variability from Natural Language Documents: A Systematic Literature Review},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106207},
doi = {10.1145/3106195.3106207},
abstract = {Identifying features and their relations (i.e., variation points) is crucial in the process of migrating single software systems to software product lines (SPL). Various approaches have been proposed to perform feature extraction automatically from different artifacts, for instance, feature location in legacy code. Usually such approaches a) omit variability information and b) rely on artifacts that reside in advanced phases of the development process, thus, being only of limited usefulness in the context of SPLs. In contrast, feature and variability extraction from natural language (NL) documents is more favorable, because a mapping to several other artifacts is usually established from the very beginning. In this paper, we provide a multi-dimensional overview of approaches for feature and variability extraction from NL documents by means of a systematic literature review (SLR). We selected 25 primary studies and carefully evaluated them regarding different aspects such as techniques used, tool support, or accuracy of the results. In a nutshell, our key insights are that i) standard NLP techniques are commonly used, ii) post-processing often includes clustering &amp; machine learning algorithms, iii) only in rare cases, the approaches support variability extraction, iv) tool support, apart from text pre-processing is often not available, and v) many approaches lack a comprehensive evaluation. Based on these observations, we derive future challenges, arguing that more effort need to be invested for making such approaches applicable in practice.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {133–142},
numpages = {10},
keywords = {Feature Identification, Natural Language Documents, Reverse Engineering, Software Product Lines, Systematic Literature Review, Variability Extraction},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3356401.3356409,
author = {Mai, Tieu Long and Navet, Nicolas and Migge, J\"{o}rn},
title = {On the use of supervised machine learning for assessing schedulability: application to ethernet TSN},
year = {2019},
isbn = {9781450372237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3356401.3356409},
doi = {10.1145/3356401.3356409},
abstract = {In this work, we ask if Machine Learning (ML) can provide a viable alternative to conventional schedulability analysis to determine whether a real-time Ethernet network meets a set of timing constraints. Otherwise said, can an algorithm learn what makes it difficult for a system to be feasible and predict whether a configuration will be feasible without executing a schedulability analysis? To get insights into this question, we apply a standard supervised ML technique, k-nearest neighbors (k-NN), and compare its accuracy and running times against precise and approximate schedulability analyses developed in Network-Calculus. The experiments consider different TSN scheduling solutions based on priority levels combined for one of them with traffic shaping. The results obtained on an automotive network topology suggest that k-NN is efficient at predicting the feasibility of realistic TSN networks, with an accuracy ranging from 91.8% to 95.9% depending on the exact TSN scheduling mechanism and a speedup of 190 over schedulability analysis for 106 configurations. Unlike schedulability analysis, ML leads however to a certain rate "false positives" (i.e., configurations deemed feasible while they are not). Nonetheless ML-based feasibility assessment techniques offer new trade-offs between accuracy and computation time that are especially interesting in contexts such as design-space exploration where false positives can be tolerated during the exploration process.},
booktitle = {Proceedings of the 27th International Conference on Real-Time Networks and Systems},
pages = {143–153},
numpages = {11},
keywords = {machine learning, schedulability analysis, time sensitive networking (TSN), timing verification},
location = {Toulouse, France},
series = {RTNS '19}
}

@inproceedings{10.1145/2993236.2993249,
author = {Pereira, Juliana Alves and Matuszyk, Pawel and Krieter, Sebastian and Spiliopoulou, Myra and Saake, Gunter},
title = {A feature-based personalized recommender system for product-line configuration},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993249},
doi = {10.1145/2993236.2993249},
abstract = {Today’s competitive marketplace requires the industry to understand unique and particular needs of their customers. Product line practices enable companies to create individual products for every customer by providing an interdependent set of features. Users configure personalized products by consecutively selecting desired features based on their individual needs. However, as most features are interdependent, users must understand the impact of their gradual selections in order to make valid decisions. Thus, especially when dealing with large feature models, specialized assistance is needed to guide the users in configuring their product. Recently, recommender systems have proved to be an appropriate mean to assist users in finding information and making decisions. In this paper, we propose an advanced feature recommender system that provides personalized recommendations to users. In detail, we offer four main contributions: (i) We provide a recommender system that suggests relevant features to ease the decision-making process. (ii) Based on this system, we provide visual support to users that guides them through the decision-making process and allows them to focus on valid and relevant parts of the configuration space. (iii) We provide an interactive open-source configurator tool encompassing all those features. (iv) In order to demonstrate the performance of our approach, we compare three different recommender algorithms in two real case studies derived from business experience.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {120–131},
numpages = {12},
keywords = {Personalized Recommendations, Product-Line Configuration, Recommenders, Software Product Lines},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@inproceedings{10.5555/3291291.3291307,
author = {Lopez, Eduardo and Sartipi, Kamran},
title = {Feature engineering in big data for detection of information systems misuse},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {The increasing availability of very large volumes of digital data (i.e. Big Data) enables many interesting research streams on a wide variety of phenomena. However, there has been a paucity of Big Data sets in the area of cybersecurity in information systems, as organizations are reluctant to share data that may provide too much unrestricted visibility into their operations. In this study, we explore the use of a real-life, anonymized, very large dataset containing user behavior - as captured in log files - including both regular usage as well as misuse, typifying the dynamics found in a situation with compromised user credentials. Through the experiment, we validate that the existence of a large user behavior dataset in itself does not necessarily guarantee that abnormal behaviors can be found. It is essential that researchers apply deep domain knowledge, critical thinking and practical focus to ensure the data can produce the knowledge required for the ultimate objective of detecting an insider's threat. In this paper we develop, formulate and calculate the features that best represent user behavior in the underlying information systems, maintaining a parsimonious balance between complexity, resource demands and detection effectiveness. We test the use of a classification model that proves the usefulness and aplicability of the features extracted.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {145–156},
numpages = {12},
keywords = {anomaly detection, big data security, feature engineering, insider's threat, predicting misuse},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1145/3233027.3233036,
author = {Hamza, Mostafa and Walker, Robert J. and Elaasar, Maged},
title = {CIAhelper: towards change impact analysis in delta-oriented software product lines},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233036},
doi = {10.1145/3233027.3233036},
abstract = {Change is inevitable for software systems to deal with the evolving environment surrounding them, and applying changes requires careful design and implementation not to break existing functionalities. Evolution in software product lines (SPLs) is more complex compared to evolution for individual products: a change applied to a single feature might affect all the products in the whole product family. In this paper we present an approach for change impact analysis in delta-oriented programming (DOP), an existing language aimed at supporting SPLs. We propose the CIAHelper tool to identify dependencies within a DOP program, by analyzing the semantics of both the code artifacts and variability models to construct a directed dependency graph. We also consider how the source code history could be used to enhance the recall of detecting the affected artifacts given a change proposal. We evaluate our approach by means of five case studies on two different DOP SPLs.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {31–42},
numpages = {12},
keywords = {change impact analysis, code assets, delta-oriented programming, feature model, variability model},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.1016/j.future.2019.07.059,
author = {Baryannis, George and Dani, Samir and Antoniou, Grigoris},
title = {Predicting supply chain risks using machine learning: The trade-off between performance and interpretability},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {101},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.07.059},
doi = {10.1016/j.future.2019.07.059},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {993–1004},
numpages = {12},
keywords = {Supply chain risk management, Risk analysis, Risk prediction, Machine learning, Interpretability}
}

@inproceedings{10.1145/3109729.3109745,
author = {Markiegi, Urtzi},
title = {Test optimisation for Highly-Configurable Cyber-Physical Systems},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109745},
doi = {10.1145/3109729.3109745},
abstract = {Cyber-Physical Systems (CPS) have become one of the core-enabling technologies for multiple domains, such as manufacturing, healthcare, energy and transportation. Furthermore, these domains are demanding CPS to be highly-configurable in order to respond to multiple and changing market requirements. Testing these Highly-Configurable Cyber-Physical Systems (HCCPS) is challenging. First, when working with CPSs, considerable time is required in order to tackle physical processes during testing. And secondly, in highly-configurable systems, a large number of system variants need to be tested. Consequently, reducing HCCPS testing time is essential.In this context, a research work is presented to reduce the overall testing time of HCCPS, focusing on a merged strategy of product and test cases optimisation. In particular, two approaches are proposed in order to achieve the testing time reduction. The first approach aims to reduce the HCCPS testing time by an iterative allocation of products and test cases. The second approach aims to reduce the HCCPS testing time by a feedback driven dynamic and iterative allocation of products and test cases.A preliminary experiment has been undertaken to test the iterative allocation approach. In this experiment, products to be tested are selected and prioritised. Next, multiple testing iterations are perform until the time-budget is consumed. In each iteration a small number of test cases are allocated for each of the products to be tested. The experiment was evaluated with an academic HCCPS and preliminary results suggest that the proposed approach reduces the fault detection time when compared with traditional approaches.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {139–144},
numpages = {6},
keywords = {Cyber-Physical Systems, Fault Detection, Highly-Configurable Systems, Product Line Testing, Search-Based Software Engineering, Software Engineering},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1145/3294008,
author = {Fiebrink, Rebecca},
title = {Machine Learning Education for Artists, Musicians, and Other Creative Practitioners},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
url = {https://doi.org/10.1145/3294008},
doi = {10.1145/3294008},
abstract = {This article aims to lay a foundation for the research and practice of machine learning education for creative practitioners. It begins by arguing that it is important to teach machine learning to creative practitioners and to conduct research about this teaching, drawing on related work in creative machine learning, creative computing education, and machine learning education. It then draws on research about design processes in engineering and creative practice to motivate a set of learning objectives for students who wish to design new creative artifacts with machine learning. The article then draws on education research and knowledge of creative computing practices to propose a set of teaching strategies that can be used to support creative computing students in achieving these objectives. Explanations of these strategies are accompanied by concrete descriptions of how they have been employed to develop new lectures and activities, and to design new experiential learning and scaffolding technologies, for teaching some of the first courses in the world focused on teaching machine learning to creative practitioners. The article subsequently draws on data collected from these courses—an online course as well as undergraduate and masters-level courses taught at a university—to begin to understand how this curriculum supported student learning, to understand learners’ challenges and mistakes, and to inform future teaching and research.},
journal = {ACM Trans. Comput. Educ.},
month = sep,
articleno = {31},
numpages = {32},
keywords = {Machine learning education, STEAM, creative computing}
}

@article{10.1007/s10489-020-02160-x,
author = {G. Mart\'{\i}n, Alejandro and Fern\'{a}ndez-Isabel, Alberto and Mart\'{\i}n de Diego, Isaac and Beltr\'{a}n, Marta},
title = {A survey for user behavior analysis based on machine learning techniques: current models and applications},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02160-x},
doi = {10.1007/s10489-020-02160-x},
abstract = {Significant research has been carried out in the field of User Behavior Analysis, focused on understanding, modeling and predicting past, present and future behaviors of users. However, the heterogeneity of the approaches makes their comprehension very complicated. Thus, domain and Machine Learning experts have to work together to achieve their objectives. The main motivation for this work is to obtain an understanding of this field by providing a categorization of state-of-the-art works grouping them based on specific features. This paper presents a comprehensive survey of the existing literature in the areas of Cybersecurity, Networks, Safety and Health, and Service Delivery Improvement. The survey is organized based on four different topic-based features which categorize existing works: keywords, application domain, Machine Learning algorithm, and data type. This paper aims to thoroughly analyze the existing references, to promote the dissemination of state-of-the-art approaches discussing their strong and weak points, and to identify open challenges and prospective future research directions. In addition, 127 discussed papers have been scored and ranked according to relevance-based features: paper reputation, maximum author reputation, novelty, innovation and data quality. Both types of features, topic-based and relevance-based have been combined to build a similarity metric enabling a rich visualization of all considered publications. The obtained graphic representation provides a guide of recent advancements in User Behavior Analysis by topic, highlighting the most relevant ones.},
journal = {Applied Intelligence},
month = aug,
pages = {6029–6055},
numpages = {27},
keywords = {User behavior analysis, Behavioral analytics, Survey, Machine learning, Topic-based features, Relevance-based features}
}

@article{10.1007/s11277-021-08186-9,
author = {Sharma, Sahil and Kumar, Vijay},
title = {Performance Evaluation of Machine Learning Based Face Recognition Techniques},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {118},
number = {4},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08186-9},
doi = {10.1007/s11277-021-08186-9},
abstract = {The robustness of machine-learning model-based face recognition techniques to image processing attacks using the quantization of extracted features is presented. Recently developed face recognition techniques based on machine learning models have been outperformed over traditional face recognition techniques. An efficient face recognition technology should be able to resist various image processing attacks. This paper presents the simulation results by evaluating ten variants of machine-learning-based face recognition techniques on ten well-known image processing attacks. The quality of face recognition techniques has been assessed on recognition accuracy. The performance has been evaluated on two well-known face databases viz. Bosphorus and University of Milano Bicocca (UMB) face database. The experimental results reveal that the Subspace discriminant ensemble-based face recognition model has consistently performed in most image processing attacks. All image processing attacks have been visually verified and presented.},
journal = {Wirel. Pers. Commun.},
month = jun,
pages = {3403–3433},
numpages = {31},
keywords = {Enhancement attacks, Geometric attacks, Noise attacks, Classification, Quantization, HOG, Face recognition}
}

@inproceedings{10.1007/978-3-030-62466-8_33,
author = {Svetashova, Yulia and Zhou, Baifan and Pychynski, Tim and Schmidt, Stefan and Sure-Vetter, York and Mikut, Ralf and Kharlamov, Evgeny},
title = {Ontology-Enhanced Machine Learning: A Bosch Use Case of Welding Quality Monitoring},
year = {2020},
isbn = {978-3-030-62465-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62466-8_33},
doi = {10.1007/978-3-030-62466-8_33},
abstract = {In the automotive industry, welding is a critical process of automated manufacturing and its quality monitoring is important. IoT technologies behind automated factories enable adoption of Machine Learning (ML) approaches for quality monitoring. Development of such ML models requires collaborative work of experts from different areas, including data scientists, engineers, process experts, and managers. The asymmetry of their backgrounds, the high variety and diversity of data relevant for quality monitoring pose significant challenges for ML modeling. In this work, we address these challenges by empowering ML-based quality monitoring methods with semantic technologies. We propose a system, called SemML, for ontology-enhanced ML pipeline development. It has several novel components and relies on ontologies and ontology templates for task negotiation and for data and ML feature annotation. We evaluated SemML on the Bosch use-case of electric resistance welding with very promising results.},
booktitle = {The Semantic Web – ISWC 2020: 19th International Semantic Web Conference, Athens, Greece, November 2–6, 2020, Proceedings, Part II},
pages = {531–550},
numpages = {20},
location = {Athens, Greece}
}

@inproceedings{10.1007/978-3-030-49435-3_12,
author = {Zschornack Rodrigues Saraiva, Felipe and Linhares Coelho da Silva, Ticiana and Fernandes de Mac\^{e}do, Jos\'{e} Ant\^{o}nio},
title = {Aspect Term Extraction Using Deep Learning Model with Minimal Feature Engineering},
year = {2020},
isbn = {978-3-030-49434-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-49435-3_12},
doi = {10.1007/978-3-030-49435-3_12},
abstract = {With the explosive growth of social media on the Web, opinion mining has been extensively investigated and consists of the automatic identification and extraction of opinions, emotions, and sentiments from text and multimedia data. One of the tasks involved in opinion mining is Aspect Term Extraction (ATE) which aims at identifying aspects (attributes or characteristics) that have been explicitly evaluated in a sentence or a document. For example, in the sentence “The picture quality of this camera is amazing”, the aspect term is “picture quality”. This work proposes POS-AttWD-BLSTM-CRF, a neural network architecture using a deep learning model, and minimal feature engineering, to solve the problem of ATE in opinionated documents. The proposed architecture consists of a BLSTM-CRF classifier that uses the part-of-speech tag (POS tags) as an additional feature, along with a BLSTM encoder with an attention mechanism to allow the incorporation of another relevant feature: the grammatical relations between words. The experiments show that the proposed architecture achieves promising results with minimal feature engineering comparing to the state-of-the-art solutions.},
booktitle = {Advanced Information Systems Engineering: 32nd International Conference, CAiSE 2020, Grenoble, France, June 8–12, 2020, Proceedings},
pages = {185–198},
numpages = {14},
keywords = {Aspect term extraction, Encoder, Attention mechanism, Word dependencies, Bidirectional long short-term memory, Conditional random fields},
location = {Grenoble, France}
}

@inproceedings{10.1007/978-3-030-77980-1_28,
author = {Bobek, Szymon and Mozolewski, Maciej and Nalepa, Grzegorz J.},
title = {Explanation-Driven Model Stacking},
year = {2021},
isbn = {978-3-030-77979-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77980-1_28},
doi = {10.1007/978-3-030-77980-1_28},
abstract = {With advances of artificial intelligence (AI), there is a growing need for provisioning of transparency and accountability to AI systems. These properties can be achieved with eXplainable AI (XAI) methods, extensively developed over the last few years with relation for machine learning (ML) models. However, the practical usage of XAI is limited nowadays in most of the cases to the feature engineering phase of the data mining (DM) process. We argue that explainability as a property of a system should be used along with other quality metrics such as accuracy, precision, recall in order to deliver better AI models. In this paper we present a method that allows for weighted ML model stacking and demonstrates its practical use in an illustrative example.},
booktitle = {Computational Science – ICCS 2021: 21st International Conference, Krakow, Poland, June 16–18, 2021, Proceedings, Part VI},
pages = {361–371},
numpages = {11},
keywords = {Explainability, Machine learning, Optimization},
location = {Krakow, Poland}
}

@article{10.1016/j.cmpb.2021.106180,
author = {De Brouwer, Edward and Becker, Thijs and Moreau, Yves and Havrdova, Eva Kubala and Trojano, Maria and Eichau, Sara and Ozakbas, Serkan and Onofrj, Marco and Grammond, Pierre and Kuhle, Jens and Kappos, Ludwig and Sola, Patrizia and Cartechini, Elisabetta and Lechner-Scott, Jeannette and Alroughani, Raed and Gerlach, Oliver and Kalincik, Tomas and Granella, Franco and Grand'Maison, Francois and Bergamaschi, Roberto and Jos\'{e} S\'{a}, Maria and Van Wijmeersch, Bart and Soysal, Aysun and Sanchez-Menoyo, Jose Luis and Solaro, Claudio and Boz, Cavit and Iuliano, Gerardo and Buzzard, Katherine and Aguera-Morales, Eduardo and Terzi, Murat and Trivio, Tamara Castillo and Spitaleri, Daniele and Van Pesch, Vincent and Shaygannejad, Vahid and Moore, Fraser and Oreja-Guevara, Celia and Maimone, Davide and Gouider, Riadh and Csepany, Tunde and Ramo-Tello, Cristina and Peeters, Liesbet},
title = {Longitudinal machine learning modeling of MS patient trajectories improves predictions of disability progression},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {208},
number = {C},
issn = {0169-2607},
url = {https://doi.org/10.1016/j.cmpb.2021.106180},
doi = {10.1016/j.cmpb.2021.106180},
journal = {Comput. Methods Prog. Biomed.},
month = sep,
numpages = {14},
keywords = {Multiple sclerosis, Machine learning, Longitudinal data, Recurrent neural networks, Electronic health records, Disability progression, Real-world data}
}

@article{10.1016/j.knosys.2017.02.020,
author = {Prez-Ortiz, M. and Gutirrez, P.A. and Aylln-Tern, M.D. and Heaton, N. and Ciria, R. and Briceo, J. and Hervs-Martnez, C.},
title = {Synthetic semi-supervised learning in imbalanced domains},
year = {2017},
issue_date = {May 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {123},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2017.02.020},
doi = {10.1016/j.knosys.2017.02.020},
abstract = {Liver transplantation is a promising and widely-accepted treatment for patients with terminal liver disease. However, transplantation is restricted by the lack of suitable donors, resulting in significant waiting list deaths. This paper proposes a novel donor-recipient allocation system that uses machine learning to predict graft survival after transplantation using a dataset comprised of donor-recipient pairs from the Kings College Hospital (United Kingdom). The main novelty of the system is that it tackles the imbalanced nature of the dataset by considering semi-supervised learning, analysing its potential for obtaining more robust and equitable models in liver transplantation. We propose two different sources of unsupervised data for this specific problem (recent transplants and virtual donor-recipient pairs) and two methods for using these data during model construction (a semi-supervised algorithm and a label propagation scheme). The virtual pairs and the label propagation method are shown to alleviate the imbalanced distribution. The results of our experiments show that the use of synthetic and real unsupervised information helps to improve and stabilise the performance of the model and leads to fairer decisions with respect to the use of only supervised data. Moreover, the best model is combined with the Model for End-stage Liver Disease score (MELD), which is at the moment the most popular assignation methodology worldwide. By doing this, our decision-support system considers both the compatibility of the donor and the recipient (by our prediction system) and the recipient severity (via the MELD score), supporting then the principles of fairness and benefit.},
journal = {Know.-Based Syst.},
month = may,
pages = {75–87},
numpages = {13},
keywords = {Imbalanced classification, Liver transplantation, Machine learning, Semi-supervised learning, Support vector machines, Survival analysis, Transplant recipient}
}

@inproceedings{10.1145/3430984.3430999,
author = {Moghe, Ritwik Prashant and Rathee, Sunil and Nayak, Bharath and Adusumilli, Kranthi Mitra},
title = {Machine Learning based Batching Prediction System for Food&nbsp;Delivery},
year = {2021},
isbn = {9781450388177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430984.3430999},
doi = {10.1145/3430984.3430999},
abstract = {Delivery time estimates are an important factor for online food delivery platforms. These platforms also depend on batching - delivering two orders together - to increase efficiency and reduce cost. In this paper we propose a novel system for enhanced delivery time estimates for batched orders. The system is based on multiple machine learning algorithms that work together to make the predictions. We observe that the system leads to an increase in the number of times the food is delivered within the estimated delivery times by about 6%.},
booktitle = {Proceedings of the 3rd ACM India Joint International Conference on Data Science &amp; Management of Data (8th ACM IKDD CODS &amp; 26th COMAD)},
pages = {316–322},
numpages = {7},
keywords = {Customer Experience, Deep Learning, Food Delivery, Machine Learning, Zero Inflated Regression},
location = {Bangalore, India},
series = {CODS-COMAD '21}
}

@article{10.1007/s11192-019-03131-x,
author = {Nie, Yubing and Zhu, Yifan and Lin, Qika and Zhang, Sifan and Shi, Pengfei and Niu, Zhendong},
title = {Academic rising star prediction via scholar's evaluation model and machine learning techniques},
year = {2019},
issue_date = {Aug 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {120},
number = {2},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-019-03131-x},
doi = {10.1007/s11192-019-03131-x},
abstract = {Predicting future academic rising stars provides a useful reference for research communities, such as offering decision support to recruit young researchers in research institutes. Academic rising stars prediction is considered to be a classification or regression task in the field of machine learning. Traditional methods of building label information for this task are only based on the increment of citation count, which cannot adequately reflect the evolution of a scholar's academic influence. In this paper, we first propose a non-iterative hierarchical weighted evaluation model based on the quality of citing papers and the influence of co-authors. Second, we label each young scholar by the increment of the impact score from our evaluation model in the classification task, aiming at better describing the change of a scholar's impact from more angles. Finally, different groups of features that can determine if a scholar will be a rising star are extracted, and various classification models are utilized to fit the classification relationships. The experimental results on the ArnetMiner dataset verify the feasibility of the prediction task based on our label construction method. We also find that the venue features are the best indicators for rising stars prediction in our experiments.},
journal = {Scientometrics},
month = aug,
pages = {461–476},
numpages = {16},
keywords = {Academic evaluation, Classification, Impact prediction, Rising stars}
}

@inproceedings{10.1007/978-3-030-10801-4_38,
author = {Varshosaz, Mahsa and Mousavi, Mohammad Reza},
title = {Comparative Expressiveness of Product Line Calculus of Communicating Systems and 1-Selecting Modal Transition Systems},
year = {2019},
isbn = {978-3-030-10800-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-10801-4_38},
doi = {10.1007/978-3-030-10801-4_38},
abstract = {Product line calculus of communicating systems (PL-CCSs) is a process calculus proposed to model the behavior of software product lines. Modal transition systems (MTSs) are also used to model variability in behavioral models. MTSs are known to be strictly less expressive than PL-CCS. In this paper, we show that the extension of MTSs with hyper transitions by Fecher and Schmidt, called 1-selecting modal transition systems (1MTSs), closes this expressiveness gap. To this end, we propose a novel notion of refinement for 1MTSs that makes them more suitable for specifying variability for software product lines and prove its various essential properties.},
booktitle = {SOFSEM 2019: Theory and Practice of Computer Science: 45th International Conference on Current Trends in Theory and Practice of Computer Science, Nov\'{y} Smokovec, Slovakia, January 27-30, 2019, Proceedings},
pages = {490–503},
numpages = {14},
keywords = {Product line calculus of communicating systems (PL-CCS), Modal transition system (MTSs), 1-selecting modal transition system (1MTS), Comparative expressiveness},
location = {Nov\'{y} Smokovec, Slovakia}
}

@article{10.1007/s11042-021-11036-2,
author = {Sood, Shivani and Singh, Harjeet},
title = {Computer Vision and Machine Learning based approaches for Food Security: A Review},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {18},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-11036-2},
doi = {10.1007/s11042-021-11036-2},
abstract = {With the rapidly increase of population every day, it has become a major issue to fulfill everyone’s need for food products (i.e., vegetables, fruits, milk, wheat, etc.) due to limited production of food products. Moreover, healthy food utilization among people is the foremost requirement. The major factors that affect the food system includes increasing food shortage, decreasing quality, wastage, and loss of food products, limited natural resources, etc. This article addresses the various computer vision and machine learning based techniques, used to minimize the aforementioned issues. Image processing has become an effective technique for the analysis of many research applications. This study intends to focus on analysis of image processing based applications in food products and agriculture field. Such applications help in decision making , disease prediction, classification, fruit sorting, soil quality measurement, etc. Moreover, a comprehensive review has been accomplished for various computer vision and statistical approaches used in food production and agricultural field and concludes that Deep Learning (DL) based approaches produce better results, specifically for image processing applications. Additionally, an effort has been made to provide a list of publicly available datasets for the related study.},
journal = {Multimedia Tools Appl.},
month = jul,
pages = {27973–27999},
numpages = {27},
keywords = {Food Ssecurity, Deep learning, Convolutional neural network, Smart farming}
}

@article{10.1007/s11277-021-08136-5,
author = {Jain, Praphula Kumar and Pamula, Rajendra and Ansari, Sarfraj},
title = {A Supervised Machine Learning Approach for the Credibility Assessment of User-Generated Content},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {118},
number = {4},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08136-5},
doi = {10.1007/s11277-021-08136-5},
abstract = {Consumers increasingly rely on online reviews to assist them in their buying decisions. The rising popularity of e-commerce websites, hotel reviews, and social media has become a relevant research field in recent years. Online reviews affect people’s decisions in their day-to-day life; the fake review impacts both consumers and business organizations. They need to know how different types of consumers prefer consumer feedback, which influences their opinion. Automatic detection of such reviews is a difficult job, provided that the author writes in such a way that it seems like a real review. Previous work has tackled the identification of fake reviews in many fields, including food reviews or company reviews in a restaurant and hotels. In this study, we proposed a fully supervised approach to distinguish opinion spammers in online reviews. In this work, we have used labeled data that can be useful to classify real and fake reviews. We have also implemented various machine learning algorithms for classification on two different datasets (Yelp hotel review dataset, Yelp restaurant review dataset). We have performed the classification task on the features engineered dataset. Our experiment’s measured results show that Logistic regression performs better than other algorithms on most occasions. We may conclude that the presented study contributes to the existing literature with better accuracy from the obtained results.},
journal = {Wirel. Pers. Commun.},
month = jun,
pages = {2469–2485},
numpages = {17},
keywords = {Online review, Fake review, Opinion spam, Natural language processing, Machine learning}
}

@article{10.4018/IJWP.2017070102,
author = {Sirqueira, Tassio Ferenzini Martins and Braga, Regina and Ara\'{u}jo, Marco Ant\^{o}nio P. and David, Jos\'{e} Maria N. and Campos, Fernanda and Str\"{o}ele, Victor},
title = {An Approach to Configuration Management of Scientific Workflows},
year = {2017},
issue_date = {July 2017},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {2},
issn = {1938-0194},
url = {https://doi.org/10.4018/IJWP.2017070102},
doi = {10.4018/IJWP.2017070102},
abstract = {A scientific software ecosystem aims to integrate all stages of an experiment and its related workflows, in order to solve complex problems. In this vein, in order to assure the experiment proper execution, any modification that occurs must be propagated to the associated workflows, which must be maintained and evolved for the successful conduction of the research. One way to ensure this control is through configuration management using data provenance. In this work, the authors use data provenance concepts and models, together with ontologies to provide an architecture for the storage and query of scientific experiment information. Considering the architecture, a proof of concept was conducted using workflows extracted from the myExperiment repository. The results are presented along the paper.},
journal = {Int. J. Web Portals},
month = jul,
pages = {20–46},
numpages = {27},
keywords = {Data Provenance, Ontology, Scientific Experiment Management, Workflow Maintenance and Evolution}
}

@inproceedings{10.1109/ICSE43902.2021.00100,
author = {Velez, Miguel and Jamshidi, Pooyan and Siegmund, Norbert and Apel, Sven and K\"{a}stner, Christian},
title = {White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00100},
doi = {10.1109/ICSE43902.2021.00100},
abstract = {Performance-influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system. With this understanding, stakeholders can debug performance behavior and make deliberate configuration decisions. Current black-box techniques to build such models combine various sampling and learning strategies, resulting in tradeoffs between measurement effort, accuracy, and interpretability. We present Comprex, a white-box approach to build performance-influence models for configurable systems, combining insights of local measurements, dynamic taint analysis to track options in the implementation, compositionality, and compression of the configuration space, without relying on machine learning to extrapolate incomplete samples. Our evaluation on 4 widely-used, open-source projects demonstrates that Comprex builds similarly accurate performance-influence models to the most accurate and expensive black-box approach, but at a reduced cost and with additional benefits from interpretable and local models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1072–1084},
numpages = {13},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1145/3388792,
author = {Prenkaj, Bardh and Velardi, Paola and Stilo, Giovanni and Distante, Damiano and Faralli, Stefano},
title = {A Survey of Machine Learning Approaches for Student Dropout Prediction in Online Courses},
year = {2020},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3388792},
doi = {10.1145/3388792},
abstract = {The recent diffusion of online education (both MOOCs and e-courses) has led to an increased economic and scientific interest in e-learning environments. As widely documented, online students have a much higher chance of dropping out than those attending conventional classrooms. It is of paramount interest for institutions, students, and faculty members to find more efficient methodologies to mitigate withdrawals. Following the rise of attention on the Student Dropout Prediction (SDP) problem, the literature has witnessed a significant increase in contributions to this subject. In this survey, we present an in-depth analysis of the state-of-the-art literature in the field of SDP, under the central perspective, but not exclusive, of machine learning predictive algorithms. Our main contributions are the following: (i) we propose a comprehensive hierarchical classification of existing literature that follows the workflow of design choices in the SDP; (ii) to facilitate the comparative analysis, we introduce a formal notation to describe in a uniform way the alternative dropout models investigated by the researchers in the field; (iii) we analyse some other relevant aspects to which the literature has given less attention, such as evaluation metrics, gathered data, and privacy concerns; (iv) we pay specific attention to deep sequential machine learning methods—recently proposed by some contributors—which represent one of the most effective solutions in this area. Overall, our survey provides novice readers who address these topics with practical guidance on design choices, as well as directs researchers to the most promising approaches, highlighting current limitations and open challenges in the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {57},
numpages = {34},
keywords = {Student dropout prediction, educational data mining, learning analytics}
}

@article{10.1007/s00521-018-3655-2,
author = {Veredas, Francisco J. and Urda, Daniel and Subirats, Jos\'{e} L. and Cant\'{o}n, Francisco R. and Aledo, Juan C.},
title = {Combining feature engineering and feature selection to improve the prediction of methionine oxidation sites in proteins},
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {2},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3655-2},
doi = {10.1007/s00521-018-3655-2},
abstract = {Methionine is a proteinogenic amino acid that can be post-translationally modified. It is now well established that reactive oxygen species can oxidise methionine residues within living cells. For a long time, it has been thought that such a modification represents merely an inevitable damage derived from aerobic metabolism. However, several authors have begun to contemplate a possible role for this methionine modification in cell signalling. During the last years, a number of proteomic studies have been carried out with the purpose of detecting proteins containing oxidised methionines. Although these proteomic works allow to pinpoint those methionines being oxidised, they are also arduous, expensive and time-consuming. For these reasons, computational approaches aimed at predicting methionine oxidation sites in proteins become an appealing alternative. In the current work, we address methionine oxidation prediction by combining computational intelligence methods with feature engineering and feature selection techniques to improve the efficacy of several machine learning models, while reducing the number of input characteristics needed to get high accuracy rates. We compare random forests, support vector machines, neural networks and flexible discriminant analysis models. Random forests give the best AUC (0.8124±0.0334) and accuracy rates (0.7590±0.0551) by using only a reduced set of 16 characteristics. These results surpass the outcomes of previous works. In addition, we present an end-user script that has been developed to take a protein ID as an input and return a list with the oxidation state of all the methionine residues found in the analysed protein. Finally, to illustrate the applicability of this tool, we have selected the human α1-antitrypsin protein as a case study. This protein was selected because it was not present among the set of proteins used to build up the predictive models but the protein has been well characterised experimentally in terms of methionine oxidation. The prediction returned by our script fully matches the empirical evidence. Out of the nine methionine residues found in this protein, our model predicts the oxidation of only two of them, M351 and M358, which have been reported, on the base of mass spectrometry analyses, to be particularly susceptible to oxidation.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {323–334},
numpages = {12},
keywords = {Protein prediction, Post-translational modification, Methionine oxidation, Predictive computational model}
}

@phdthesis{10.5555/AAI28716555,
author = {Eluri, Vijaya Kumar and Amir, Etemadi, and Thomas, Holzer, and P, Blackford, Joseph},
advisor = {Shahram, Sarkani, and Thomas, Mazzuchi,},
title = {Predicting Long-Time Contributors for GitHub Projects Using Machine Learning},
year = {2021},
isbn = {9798535595184},
publisher = {The George Washington University},
abstract = {Organizations typically develop software systems using non-developmental items and commercial off-the-shelf software. Many organizations are changing the way they create, capture, consume, and commercialize software by increasingly Open-Source Software projects. However, many OSS projects do not survive, as the survival of OSS projects depends mainly on retaining new contributors. While organizations driven by their business needs support some OSS projects, most OSS contributors are volunteers who contribute their work for free. While many join OSS projects, only a few contribute to an OSS project for a considerably long time. A Long-time contributor is defined as a contributor who joins a project and continues to contribute for more than T years; T is generally set to 1, 2, and 3 years. LTCs often contribute more code than non-LTCs.Most new contributors abandon a project without becoming LTCs. The data in this research shows that 98% of new contributors leave a project before three years. Various factors affect whether a new contributor becomes an LTC, including the new contributor's experience, expertise, the project's maturity, working environment, documentation, and task difficulty. Identifying factors that predict potential LTCs can enable project owners to gain insight into what matters to contributors and take action to retain new contributors for a long time. These actions could include mentoring, quickly responding to questions, providing timely code reviews, and merging contributions.This research investigates effective predictability of new contributors to OSS repositories becoming LTC based on repository and contributor meta-data collected from OSS repositories.  Compared to state-of-the-art models, the models built in this research use less than 50% features and produce better results. In 10-fold cross-validation, the precision, recall, F1-score, MCC, and AUC of the best state-of-the-art model are 0.546, 0.041, 0.075, 0.1446, and 0.908, respectively.},
note = {AAI28716555}
}

@inproceedings{10.1007/978-3-030-64583-0_59,
author = {Rantonen, Mika and Korpihalkola, Joni},
title = {Prediction of Spot Prices in Nord Pool’s Day-Ahead Market Using Machine Learning and Deep Learning},
year = {2020},
isbn = {978-3-030-64582-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64583-0_59},
doi = {10.1007/978-3-030-64583-0_59},
abstract = {Aim of this paper is to describe and compare the machine learning and deep learning based forecasting models that predict Spot prices in Nord Pool’s Day-ahead market in Finland with open-source software. The liberalization of electricity markets has launched an interest in forecasting future prices and developing models on how the prices will develop. Due to the improvements in computing capabilities, more and more complex machine learning models and neural networks can be trained faster as well as the growing amount of open data enables to collect of the large and relevant dataset. The dataset consist of multiple different features ranging from weather data to production plans was constructed. Different statistical models generated forecasts from Spot price history and machine learning models were trained on the constructed dataset. The forecasts were compared to a baseline model using three different error metrics. The result was an ensemble of statistical and machine learning models, where the models’ forecasts were combined and given weights by a neural network acting as a metalearner. The results also prove that the model is able to forecast the trend and seasonality of Spot prices but unable to predict sudden price spikes.},
booktitle = {Machine Learning, Optimization, and Data Science: 6th International Conference, LOD 2020, Siena, Italy, July 19–23, 2020, Revised Selected Papers, Part I},
pages = {676–687},
numpages = {12},
keywords = {Machine learning, Deep learning, SPOT price prediction},
location = {Siena, Italy}
}

@article{10.1016/j.jbi.2021.103922,
author = {Zhang, Hengwei and Li, Yan and McConnell, William},
title = {Predicting potential palliative care beneficiaries for health plans: A generalized machine learning pipeline},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {123},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2021.103922},
doi = {10.1016/j.jbi.2021.103922},
journal = {J. of Biomedical Informatics},
month = nov,
numpages = {8},
keywords = {Machine Learning Pipeline, Palliative Care, Administrative Claims, Mortality Risk Prediction, Risk-stratified care management, Population Health}
}

@inproceedings{10.1007/978-3-030-87626-5_22,
author = {Kiefer, Sebastian and Pesch, G\"{u}nter},
title = {Unsupervised Anomaly Detection for&nbsp;Financial Auditing with Model-Agnostic Explanations},
year = {2021},
isbn = {978-3-030-87625-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87626-5_22},
doi = {10.1007/978-3-030-87626-5_22},
abstract = {Explainable Artificial Intelligence (AI) has emerged to be a key component for Black-Box Machine Learning (ML) approaches in domains with a high demand for transparency. Besides medical expert systems, which inherently need to be interpretable, transparent, and comprehensible as they deal with life-changing decision tasks, other application domains like financial auditing require trust in ML as well. The European General Data Protection Regulation (GDPR) also applies to such highly regulated areas where an auditor evaluates financial transactions and statements of a business. In this paper we propose an ML architecture that shall help financial auditors by transparently detecting anomalous datapoints in the absence of ground truth. While most of the time Anomaly Detection (AD) is performed in a supervised manner, where model-agnostic explainers can be easily applied, unsupervised AD is hardly comprehensible especially across different algorithms. In this work we investigate how to dissolve this: We describe an integrated architecture for unsupervised AD that identifies outliers at different levels of granularity using an ensemble of independent algorithms. Furthermore, we show how model-agnostic explanations can be generated for such an ensemble using supervised approximation and Local Interpretable Model-Agnostic Explanations (LIME). Additionally, we propose techniques for explanation-post-processing that allow explanations to be selective, receiver-dependent, and easily understandable. In a nutshell, our architecture paves the way for model-agnostic explainability for the task of unsupervised AD. It can further be transferred smoothly to other unsupervised ML problems like clustering problems.},
booktitle = {KI 2021: Advances in Artificial Intelligence: 44th German Conference on AI, Virtual Event, September 27 – October 1, 2021, Proceedings},
pages = {291–308},
numpages = {18},
keywords = {Anomaly Detection, Outlier Detection, Unsupervised Learning, Explainable Artificial Intelligence, Human-like explanations}
}

@article{10.1007/s10614-019-09960-5,
author = {Chen, Yi-Ting and Sun, Edward W. and Lin, Yi-Bing},
title = {Machine learning with parallel neural networks for analyzing and forecasting electricity demand},
year = {2020},
issue_date = {Aug 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {2},
issn = {0927-7099},
url = {https://doi.org/10.1007/s10614-019-09960-5},
doi = {10.1007/s10614-019-09960-5},
abstract = {Traditional methods applied in electricity demand forecasting have been challenged by the course of dimensionality arisen with a growing number of distributed or decentralized energy systems are employing. Without manually operated data preprocessing, classic models are not well-calibrated for their robustness when dealing with the disruptive elements (e.g., demand changes in holidays and extreme weather). Based on the application of big data driven analytics, we propose a novel machine learning method originating from the parallel neural networks for robust monitoring and forecasting power demand to enhance supervisory control and data acquisition for new industrial tendency such as Industry 4.0 and Energy IoT. Through our approach, we generalize the implementation of machine learning by using classic feed-forward neural networks, for parallelization in order to let the proposed method achieve superior performance when dealing with high dimensionality and disruptiveness. With the high-frequency data of consumption in Australia from January 2009 to December 2015, the overall empirical results confirm that our proposed method performs significantly better for dynamic monitoring and forecasting of power demand comparing with the classic methods.},
journal = {Comput. Econ.},
month = aug,
pages = {569–597},
numpages = {29},
keywords = {Big data, Energy, Forecasting, Machine learning, Neural networks (PNNs), C02, C10, C63}
}

@inproceedings{10.1145/2791060.2791069,
author = {Valov, Pavel and Guo, Jianmei and Czarnecki, Krzysztof},
title = {Empirical comparison of regression methods for variability-aware performance prediction},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791069},
doi = {10.1145/2791060.2791069},
abstract = {Product line engineering derives product variants by selecting features. Understanding the correlation between feature selection and performance is important for stakeholders to acquire a desirable product variant. We infer such a correlation using four regression methods based on small samples of measured configurations, without additional effort to detect feature interactions. We conduct experiments on six real-world case studies to evaluate the prediction accuracy of the regression methods. A key finding in our empirical study is that one regression method, called Bagging, is identified as the best to make accurate and robust predictions for the studied systems.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {186–190},
numpages = {5},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@article{10.1016/j.cie.2021.107580,
author = {Ma, Qiuping and Li, Hongyan and Thorstenson, Anders},
title = {A big data-driven root cause analysis system: Application of Machine Learning in quality problem solving},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {160},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107580},
doi = {10.1016/j.cie.2021.107580},
journal = {Comput. Ind. Eng.},
month = oct,
numpages = {16},
keywords = {Quality management, Data mining, Machine Learning, Multi-class classification, Neural Network}
}

@inproceedings{10.1007/978-3-030-03493-1_57,
author = {Silva, P. and Rivolli, A. and Rocha, P. and Correia, F. and Soares, C.},
title = {Machine Learning for Drugs Prescription},
year = {2018},
isbn = {978-3-030-03492-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-03493-1_57},
doi = {10.1007/978-3-030-03493-1_57},
abstract = {In a medical appointment, patient information, including past exams, is analyzed in order to define a diagnosis. This process is prone to errors, since there may be many possible diagnoses. This analysis is very dependent on the experience of the doctor. Even with the correct diagnosis, prescribing medicines can be a problem, because there are multiple drugs for each disease and some may not be used due to allergies or high cost. Therefore, it would be helpful, if the doctors were able to use a system that, for each diagnosis, provided a list of the most suitable medicines. Our approach is to support the physician in this process. Rather than trying to predict the medicine, we aim to, given the available information, predict the set of the most likely drugs. The prescription problem may be solved as a Multi-Label classification problem since, for each diagnosis, multiple drugs may be prescribed at the same time. Due to its complexity, some simplifications were performed for the problem to be treatable. So, multiple approaches were done with different assumptions. The data supplied was also complex, with important problems in its quality, that led to a strong investment in data preparation, in particular, feature engineering. Overall, the results in each scenario are good with performances almost twice the baseline, especially using Binary Relevance as transformation approach.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2018: 19th International Conference,  Madrid, Spain, November 21–23, 2018, Proceedings, Part I},
pages = {548–555},
numpages = {8},
keywords = {Machine learning, Classification problems, Multi-label classification, Health systems, Medicines prescriptions},
location = {Madrid, Spain}
}

@inproceedings{10.1109/WAIN52551.2021.00016,
author = {Staron, Miroslaw and Herg\`{e}s, Helena Odenstedt and Naredi, Silvana and Block, Linda and El-Merhi, Ali and Vithal, Richard and Elam, Mikael},
title = {Robust Machine Learning in Critical Care — Software Engineering and Medical Perspectives},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/WAIN52551.2021.00016},
doi = {10.1109/WAIN52551.2021.00016},
abstract = {Using machine learning in clinical practice poses hard requirements on explainability, reliability, replicability and robustness of these systems. Therefore, developing reliable software for monitoring critically ill patients requires close collaboration between physicians and software engineers. However, these two different disciplines need to find own research perspectives in order to contribute to both the medical and the software engineering domain. In this paper, we address the problem of how to establish a collaboration where software engineering and medicine meets to design robust machine learning systems to be used in patient care. We describe how we designed software systems for monitoring patients under carotid endarterectomy, in particular focusing on the process of knowledge building in the research team. Our results show what to consider when setting up such a collaboration, how it develops over time and what kind of systems can be constructed based on it. We conclude that the main challenge is to find a good research team, where different competences are committed to a common goal.},
booktitle = {2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)},
pages = {62–69},
numpages = {8},
location = {Madrid, Spain}
}

@article{10.1145/3398020,
author = {Qian, Bin and Su, Jie and Wen, Zhenyu and Jha, Devki Nandan and Li, Yinhao and Guan, Yu and Puthal, Deepak and James, Philip and Yang, Renyu and Zomaya, Albert Y. and Rana, Omer and Wang, Lizhe and Koutny, Maciej and Ranjan, Rajiv},
title = {Orchestrating the Development Lifecycle of Machine Learning-based IoT Applications: A Taxonomy and Survey},
year = {2020},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3398020},
doi = {10.1145/3398020},
abstract = {Machine Learning (ML) and Internet of Things (IoT) are complementary advances: ML techniques unlock the potential of IoT with intelligence, and IoT applications increasingly feed data collected by sensors into ML models, thereby employing results to improve their business processes and services. Hence, orchestrating ML pipelines that encompass model training and implication involved in the holistic development lifecycle of an IoT application often leads to complex system integration. This article provides a comprehensive and systematic survey of the development lifecycle of ML-based IoT applications. We outline the core roadmap and taxonomy and subsequently assess and compare existing standard techniques used at individual stages.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {82},
numpages = {47},
keywords = {IoT, deep learning, machine learning, orchestration}
}

@inproceedings{10.1007/978-3-030-52683-2_1,
author = {W\r{a}reus, Emil and Hell, Martin},
title = {Automated CPE Labeling of CVE Summaries with Machine Learning},
year = {2020},
isbn = {978-3-030-52682-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-52683-2_1},
doi = {10.1007/978-3-030-52683-2_1},
abstract = {Open Source Security and Dependency Vulnerability Management (DVM) has become a more vital part of the software security stack in recent years as modern software tend to be more dependent on open source libraries. The largest open source of vulnerabilities is the National Vulnerability Database (NVD), which supplies developers with machine-readable vulnerabilities. However, sometimes Common Vulnerabilities and Exposures (CVE) have not been labeled with a Common Platform Enumeration (CPE) -version, -product and -vendor. This makes it very hard to automatically discover these vulnerabilities from import statements in dependency files. We, therefore, propose an automatic process of matching CVE summaries with CPEs through the machine learning task called Named Entity Recognition (NER). Our proposed model achieves an F-measure of 0.86 with a precision of 0.857 and a recall of 0.865, outperforming previous research for automated CPE-labeling of CVEs.},
booktitle = {Detection of Intrusions and Malware, and Vulnerability Assessment: 17th International Conference, DIMVA 2020, Lisbon, Portugal, June 24–26, 2020, Proceedings},
pages = {3–22},
numpages = {20},
keywords = {Machine learning, Open source, Vulnerabilities, CVE, CPE},
location = {Lisbon, Portugal}
}

@article{10.1016/j.eswa.2021.114756,
author = {Chen, Shui-xia and Wang, Xiao-kang and Zhang, Hong-yu and Wang, Jian-qiang},
title = {Customer purchase prediction from the perspective of imbalanced data: A machine learning framework based on factorization machine},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {173},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114756},
doi = {10.1016/j.eswa.2021.114756},
journal = {Expert Syst. Appl.},
month = jul,
numpages = {12},
keywords = {Customer purchase prediction, Factorization machine, Imbalanced data, Machine learning}
}

@inproceedings{10.1145/3448016.3452788,
author = {Phani, Arnab and Rath, Benjamin and Boehm, Matthias},
title = {LIMA: Fine-grained Lineage Tracing and Reuse in Machine Learning Systems},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3452788},
doi = {10.1145/3448016.3452788},
abstract = {Machine learning (ML) and data science workflows are inherently exploratory. Data scientists pose hypotheses, integrate the necessary data, and run ML pipelines of data cleaning, feature engineering, model selection and hyper-parameter tuning. The repetitive nature of these workflows, and their hierarchical composition from building blocks exhibits high computational redundancy. Existing work addresses this redundancy with coarse-grained lineage tracing and reuse for ML pipelines. This approach allows using existing ML systems, but views entire algorithms as black boxes, and thus, fails to eliminate fine-grained redundancy and to handle internal non-determinism. In this paper, we introduce LIMA, a practical framework for efficient, fine-grained lineage tracing and reuse inside ML systems. Lineage tracing of individual operations creates new challenges and opportunities. We address the large size of lineage traces with multi-level lineage tracing and reuse, as well as lineage deduplication for loops and functions; exploit full and partial reuse opportunities across the program hierarchy; and integrate this framework with task parallelism and operator fusion. The resulting framework performs fine-grained lineage tracing with low overhead, provides versioning and reproducibility, and is able to eliminate fine-grained redundancy. Our experiments on a variety of ML pipelines show performance improvements up to 12.4x.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {1426–1439},
numpages = {14},
keywords = {lineage tracing, lineage-based reuse, ml systems, reuse of intermediates},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@article{10.1007/s10515-020-00277-4,
author = {Esteves, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Understanding machine learning software defect predictions},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00277-4},
doi = {10.1007/s10515-020-00277-4},
abstract = {Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.},
journal = {Automated Software Engg.},
month = dec,
pages = {369–392},
numpages = {24},
keywords = {Software defects, Explainable models, Jureczko datasets, SHAP values}
}

@book{10.5555/2600138,
author = {Nettleton, David},
title = {Commercial Data Mining: Processing, Analysis and Modeling for Predictive Analytics Projects},
year = {2014},
isbn = {0124166024},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Whether you are brand new to data mining or working on your tenth predictive analytics project, Commercial Data Mining will be there for you as an accessible reference outlining the entire process and related themes. In this book, you'll learn that your organization does not need a huge volume of data or a Fortune 500 budget to generate business using existing information assets. Expert author David Nettleton guides you through the process from beginning to end and covers everything from business objectives to data sources, and selection to analysis and predictive modeling. Commercial Data Mining includes case studies and practical examples from Nettleton's more than 20 years of commercial experience. Real-world cases covering customer loyalty, cross-selling, and audience prediction in industries including insurance, banking, and media illustrate the concepts and techniques explained throughout the book. Illustrates cost-benefit evaluation of potential projects Includes vendor-agnostic advice on what to look for in off-the-shelf solutions as well as tips on building your own data mining tools Approachable reference can be read from cover to cover by readers of all experience levels Includes practical examples and case studies as well as actionable business insights from author's own experience}
}

@article{10.1016/j.infsof.2019.01.008,
author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
title = {Mining software repositories for adaptive change commits using machine learning techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.008},
doi = {10.1016/j.infsof.2019.01.008},
journal = {Inf. Softw. Technol.},
month = may,
pages = {80–91},
numpages = {12},
keywords = {Code change metrics, Adaptive maintenance, Commit types, Maintenance classification, Machine learning}
}

@inproceedings{10.1145/2993412.3003392,
author = {Boss, Birgit and Tischer, Christian and Krishnan, Sreejith and Nutakki, Arun and Gopinath, Vinod},
title = {Setting up architectural SW health builds in a new product line generation},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3003392},
doi = {10.1145/2993412.3003392},
abstract = {Setting up a new product line generation in a mature domain, typically does not start from scratch but takes into consideration the architecture and assets of the former product line generation. Being able to accommodate legacy and 3rd party code is one of the major product line qualities to be met. On the other side, product line qualities like reusability, maintainability and alterability, i.e. being able to cope up with a large amount of variability, with configurability and fast integratability are major drivers.While setting up a new product line generation and thus a new corresponding architecture, we this time focused on architectural software (SW) health and tracking of architectural metrics from the very beginning. Taking the definition of "architecture being a set of design decisions" [18] literally, we attempt to implement an architectural check for every design decision taken. Architectural design decisions in our understanding do not only - and even not mainly - deal with the definition of components and their interaction but with patterns and rules or anti-patterns. The rules and anti-patterns, "what not to do" or more often also "what not to do &lt;u&gt;any more&lt;/u&gt;", is even more important in setting up a new product line generation because developers are not only used to the old style of developing and the old architecture, but also still have to develop assets for both generations.In this article we describe selected architectural checks that we have implemented, the layered architecture check and the check for usage of obsolete services. Additionally we discuss selected architectural metrics: the coupling coefficient metrics and the instability metrics. In the summary and outlook we describe our experiences and still open topics in setting up architectural SW health checks for a large-scale product line.The real-world examples are taken from the domain of Engine Control Unit development at Robert Bosch GmbH.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {16},
numpages = {7},
keywords = {architectural checks, architectural technical debt, embedded software, product line development, software architecture, software erosion, technical debt},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@inproceedings{10.1007/978-3-030-95470-3_5,
author = {Carta, Salvatore and Podda, Alessandro Sebastian and Reforgiato&nbsp;Recupero, Diego and Stanciu, Maria Madalina},
title = {Explainable AI for&nbsp;Financial Forecasting},
year = {2021},
isbn = {978-3-030-95469-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-95470-3_5},
doi = {10.1007/978-3-030-95470-3_5},
abstract = {One of the most important steps when employing machine learning approaches is the feature engineering process. It plays a key role in the identification of features that can effectively help modeling the given classification or regression task. This process is usually not trivial and it might lead to the development of handcrafted features. Within the financial domain, this step is even more complex given the general low correlation between features extracted from financial data and their associated labels. This represents indeed a challenging task that it is possible to explore today through the explainable artificial intelligence approaches that have recently appeared in the literature. This paper examines the potential of machine learning automatic feature selection process to support decisions in financial forecasting. Using explainable artificial intelligence methods, we develop different feature selection strategies in an applied financial setting where we want to predict the next-day returns for a set of input stocks. We propose to identify the relevant features for each stock individually; in this way, we take into account the heterogeneous stocks’ behavior. We demonstrate that our approach can separate important features from unimportant ones and bring prediction performance improvements as shown by our performed comparisons between our proposed strategies and several state-of-the-art baselines on real-world financial time series.},
booktitle = {Machine Learning, Optimization, and Data Science: 7th International Conference, LOD 2021, Grasmere, UK, October 4–8, 2021, Revised Selected Papers, Part II},
pages = {51–69},
numpages = {19},
keywords = {XAI, Machine learning, Financial forecasting, Time-series},
location = {Grasmere, United Kingdom}
}

@inproceedings{10.1145/3480001.3480008,
author = {Ye, Ziyuan},
title = {A Data Slicing Method to Improve Machine Learning Model Accuracy in Bankruptcy Prediction},
year = {2021},
isbn = {9781450390163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3480001.3480008},
doi = {10.1145/3480001.3480008},
abstract = {High-accuracy bankruptcy prediction has been important to investors and corporate finance officers for decades. With bankruptcy data in China and Poland given, this paper is an exploratory study attempting to aid feature engineering in bankruptcy predictions through a new exploratory method we call “Data Slicing.” Our data slicing analysis relies on making predictions on carefully selected and sliced financial datasets and measuring each sliced dataset's prediction accuracy. According to the findings in this research, the most related metric and the best variable to slice on to get a predictable sliced dataset turn out to be “Solvency Ratio” both in Chinese and Polish data. Simultaneously, using two different sliced datasets, the accuracy of machine learning and deep learning methods is improved. Support Vector Machine, Neural Networks and Random Forest methods are suggested to use in bankruptcy detection for higher accuracy. In summary, investors and other risk management officers are highly recommended to pay attention to firm's ability to pay debts, especially in their valuation attempts and forecasts.},
booktitle = {Proceedings of the 2021 5th International Conference on Deep Learning Technologies},
pages = {32–39},
numpages = {8},
keywords = {Bankruptcy Prediction, Machine, Neural Networks, Random Forest, Solvency Ratio, Support Vector},
location = {Qingdao, China},
series = {ICDLT '21}
}

@inproceedings{10.1007/978-3-030-58475-7_52,
author = {Nejati, Saeed and Le Frioux, Ludovic and Ganesh, Vijay},
title = {A Machine Learning Based Splitting Heuristic for Divide-and-Conquer Solvers},
year = {2020},
isbn = {978-3-030-58474-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58475-7_52},
doi = {10.1007/978-3-030-58475-7_52},
abstract = {In this paper, we present a machine learning based splitting heuristic for divide-and-conquer parallel Boolean SAT solvers. Splitting heuristics, whether they are look-ahead or look-back, are designed using proxy metrics, which when optimized, approximate the true metric of minimizing solver runtime on sub-formulas resulting from a split. The rationale for such metrics is that they have been empirically shown to be excellent proxies for runtime of solvers, in addition to being cheap to compute in an online fashion. However, the design of traditional splitting methods are often ad-hoc and do not leverage the copious amounts of data that solvers generate.To address the above-mentioned issues, we propose a machine learning based splitting heuristic that leverages the features of input formulas and data generated during the run of a divide-and-conquer (DC) parallel solver. More precisely, we reformulate the splitting problem as a ranking problem and develop two machine learning models for pairwise ranking and computing the minimum ranked variable. Our model can compare variables according to their splitting quality, which is based on a set of features extracted from structural properties of the input formula, as well as dynamic probing statistics, collected during the solver’s run. We derive the true labels through offline collection of runtimes of a parallel DC solver on sample formulas and variables within them. At each splitting point, we generate a predicted ranking (pairwise or minimum rank) of candidate variables and split the formula on the top variable. We implemented our heuristic in the Painless parallel SAT framework and evaluated our solver on a set of cryptographic instances encoding the SHA-1 preimage as well as SAT competition 2018 and 2019 benchmarks. We solve significantly more instances compared to the baseline Painless solver and outperform top divide-and-conquer solvers from recent SAT competitions, such as Treengeling. Furthermore, we are much faster than these top solvers on cryptographic benchmarks.},
booktitle = {Principles and Practice of Constraint Programming: 26th International Conference, CP 2020, Louvain-La-Neuve, Belgium, September 7–11, 2020, Proceedings},
pages = {899–916},
numpages = {18},
location = {Louvain-la-Neuve, Belgium}
}

@article{10.1007/s00521-021-06288-w,
author = {Chatterjee, Tanmoy and Essien, Aniekan and Ganguli, Ranjan and Friswell, Michael I.},
title = {The stochastic aeroelastic response analysis of helicopter rotors using deep and shallow machine learning},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {23},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06288-w},
doi = {10.1007/s00521-021-06288-w},
abstract = {This paper addresses the influence of manufacturing variability of a helicopter rotor blade on its aeroelastic responses. An aeroelastic analysis using finite elements in spatial and temporal domains is used to compute the helicopter rotor frequencies, vibratory hub loads, power required and stability in forward flight. The novelty of the work lies in the application of advanced data-driven machine learning (ML) techniques, such as convolution neural networks (CNN), multi-layer perceptron (MLP), random forests, support vector machines and adaptive Gaussian process (GP) for capturing the nonlinear responses of these complex spatio-temporal models to develop an efficient physics-informed ML framework for stochastic rotor analysis. Thus, the work is of practical significance as (i) it accounts for manufacturing uncertainties, (ii) accurately quantifies their effects on nonlinear response of rotor blade and (iii) makes the computationally expensive simulations viable by the use of ML. A rigorous performance assessment of the aforementioned approaches is presented by demonstrating validation on the training dataset and prediction on the test dataset. The contribution of the study lies in the following findings: (i) The uncertainty in composite material and geometric properties can lead to significant variations in the rotor aeroelastic responses and thereby highlighting that the consideration of manufacturing variability in analyzing helicopter rotors is crucial for assessing their behaviour in real-life scenarios. (ii) Precisely, the substantial effect of uncertainty has been observed on the six vibratory hub loads and the damping with the highest impact on the yawing hub moment. Therefore, sufficient factor of safety should be considered in the design to alleviate the effects of perturbation in the simulation results. (iii) Although advanced ML techniques are harder to train, the optimal model configuration is capable of approximating the nonlinear response trends accurately. GP and CNN followed by MLP achieved satisfactory performance. Excellent accuracy achieved by the above ML techniques demonstrates their potential for application in the optimization of rotors under uncertainty.},
journal = {Neural Comput. Appl.},
month = dec,
pages = {16809–16828},
numpages = {20},
keywords = {Helicopter rotor, Aeroelastic, Stochastic, Machine learning}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00042,
author = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
title = {Software engineering for machine learning: a case study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00042},
doi = {10.1109/ICSE-SEIP.2019.00042},
abstract = {Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be "entangled" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {291–300},
numpages = {10},
keywords = {AI, data, process, software engineering},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1145/3233027.3233039,
author = {Pereira, Juliana Alves and Schulze, Sandro and Figueiredo, Eduardo and Saake, Gunter},
title = {N-dimensional tensor factorization for self-configuration of software product lines at runtime},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233039},
doi = {10.1145/3233027.3233039},
abstract = {Dynamic software product lines demand self-adaptation of their behavior to deal with runtime contextual changes in their environment and offer a personalized product to the user. However, taking user preferences and context into account impedes the manual configuration process, and thus, an efficient and automated procedure is required. To automate the configuration process, context-aware recommendation techniques have been acknowledged as an effective mean to provide suggestions to a user based on their recognized context. In this work, we propose a collaborative filtering method based on tensor factorization that allows an integration of contextual data by modeling an N-dimensional tensor User-Feature-Context instead of the traditional two-dimensional User-Feature matrix. In the proposed approach, different types of non-functional properties are considered as additional contextual dimensions. Moreover, we show how to self-configure software product lines by applying our N-dimensional tensor factorization recommendation approach. We evaluate our approach by means of an empirical study using two datasets of configurations derived for medium-sized product lines. Our results reveal significant improvements in the predictive accuracy of the configuration over a state-of-the-art non-contextual matrix factorization approach. Moreover, it can scale up to a 7-dimensional tensor containing hundred of configurations in a couple of milliseconds.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {87–97},
numpages = {11},
keywords = {recommender systems, runtime decision-making, self-configuration, software product lines},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@inproceedings{10.1145/2647648.2647649,
author = {Raschke, Wolfgang and Zilli, Massimiliano and Loinig, Johannes and Weiss, Reinhold and Steger, Christian and Kreiner, Christian},
title = {Embedding research in the industrial field: a case of a transition to a software product line},
year = {2014},
isbn = {9781450330459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647648.2647649},
doi = {10.1145/2647648.2647649},
abstract = {Java Cards [4, 5] are small resource-constrained embedded systems that have to fulfill rigorous security requirements. Multiple application scenarios demand diverse product performance profiles which are targeted towards markets such as banking applications and mobile applications. In order to tailor the products to the customer's needs we implemented a Software Product Line (SPL). This paper reports on the industrial case of an adoption to a SPL during the development of a highly-secure software system. In order to provide a scientific method which allows the description of research in the field, we apply Action Research (AR). The rationale of AR is to foster the transition of knowledge from a mature research field to practical problems encountered in the daily routine. Thus, AR is capable of providing insights which might be overlooked in a traditional research approach. In this paper we follow the iterative AR process, and report on the successful transfer of knowledge from a research project to a real industrial application.},
booktitle = {Proceedings of the 2014 International Workshop on Long-Term Industrial Collaboration on Software Engineering},
pages = {3–8},
numpages = {6},
keywords = {action research, knowledge transfer, software reuse},
location = {Vasteras, Sweden},
series = {WISE '14}
}

@article{10.1155/2018/6157249,
author = {Ji, Shaoxiong and Yu, Celina Ping and Fung, Sai-fu and Pan, Shirui and Long, Guodong and Cong, Gao},
title = {Supervised Learning for Suicidal Ideation Detection in Online User Content},
year = {2018},
issue_date = {2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2018},
issn = {1076-2787},
url = {https://doi.org/10.1155/2018/6157249},
doi = {10.1155/2018/6157249},
abstract = {Early detection and treatment are regarded as the most effective ways to prevent suicidal ideation and potential suicide attempts—two critical risk factors resulting in successful suicides. Online communication channels are becoming a new way for people to express their suicidal tendencies. This paper presents an approach to understand suicidal ideation through online user-generated content with the goal of early detection via supervised learning. Analysing users’ language preferences and topic descriptions reveals rich knowledge that can be used as an early warning system for detecting suicidal tendencies. Suicidal individuals express strong negative feelings, anxiety, and hopelessness. Suicidal thoughts may involve family and friends. And topics they discuss cover both personal and social issues. To detect suicidal ideation, we extract several informative sets of features, including statistical, syntactic, linguistic, word embedding, and topic features, and we compare six classifiers, including four traditional supervised classifiers and two neural network models. An experimental study demonstrates the feasibility and practicability of the approach and provides benchmarks for the suicidal ideation detection on the active online platforms: Reddit SuicideWatch and Twitter.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@article{10.1007/s42979-021-00751-0,
author = {Nath, Rajdeep Kumar and Thapliyal, Himanshu and Humble, Travis S.},
title = {A Review of Machine Learning Classification Using Quantum Annealing for Real-World Applications},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {5},
url = {https://doi.org/10.1007/s42979-021-00751-0},
doi = {10.1007/s42979-021-00751-0},
abstract = {Optimizing the training of a machine learning pipeline helps in reducing training costs and improving model performance. One such optimizing strategy is quantum annealing, which is an emerging computing paradigm that has shown potential in optimizing the training of a machine learning model. The implementation of a physical quantum annealer has been realized by D-wave systems and is available to the research community for experiments. Recent experimental results on a variety of machine learning applications using quantum annealing have shown interesting results where the performance of classical machine learning techniques is limited by limited training data and high dimensional features. This article explores the application of D-wave’s quantum annealer for optimizing machine learning pipelines for real-world classification problems. We review the application domains on which a physical quantum annealer has been used to train machine learning classifiers. We discuss and analyze the experiments performed on the D-Wave quantum annealer for applications such as image recognition, remote sensing imagery, computational biology, and particle physics. We discuss the possible advantages and the problems for which quantum annealing is likely to be advantageous over classical computation.},
journal = {SN Comput. Sci.},
month = jul,
numpages = {11},
keywords = {Classification, Machine learning, Optimization, Quantum annealing, Quantum computing}
}

@inproceedings{10.1145/3447568.3448513,
author = {Nahili, Wedjdane and Rezeg, Khaled and Kazar, Okba},
title = {Sentiment analysis on product reviews data using supervised learning: A comprehensive review of recent techniques},
year = {2021},
isbn = {9781450376556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447568.3448513},
doi = {10.1145/3447568.3448513},
abstract = {With the availability of text data in various forms on social media platforms, text mining and sentiment analysis have received huge attention. The task of deriving information from this volume of data in order to extract knowledge is very complex and expensive because it is usually unstructured and contains noise. Recently, there is a growing need for implementing various approaches and models for efficiently processing this type of data and extracting useful information. This process is known as sentiment analysis, which includes: data gathering, data pre-processing, feature engineering and labelling, finally the application of various natural language processing and machine learning algorithms. This paper provides an overview of the most recent methods used in text mining and sentiment analysis along with their detailed description and a discussion of obtained results.CCS Concepts},
booktitle = {Proceedings of the 10th International Conference on Information Systems and Technologies},
articleno = {5},
numpages = {6},
keywords = {big data analytics, business intelligence, natural language processing, sentiment analysis, text analytics, text mining},
location = {Lecce, Italy},
series = {ICIST '20}
}

@article{10.1007/s12650-018-0531-1,
author = {Jiang, Liu and Liu, Shixia and Chen, Changjian},
title = {Recent research advances on interactive machine learning},
year = {2019},
issue_date = {April     2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {2},
issn = {1343-8875},
url = {https://doi.org/10.1007/s12650-018-0531-1},
doi = {10.1007/s12650-018-0531-1},
abstract = {Interactive machine learning (IML) is an iterative learning process that tightly couples a human with a machine learner, which is widely used by researchers and practitioners to effectively solve a wide variety of real-world application problems. Although recent years have witnessed the proliferation of IML in the field of visual analytics, most recent surveys either focus on a specific area of IML or aim to summarize a visualization field that is too generic for IML. In this paper, we systematically review the recent literature on IML and classify them into a task-oriented taxonomy built by us. We conclude the survey with a discussion of open challenges and research opportunities that we believe are inspiring for future work in IML.},
journal = {J. Vis.},
month = apr,
pages = {401–417},
numpages = {17},
keywords = {Interactive machine learning, Interactive visualization, Machine learning}
}

@phdthesis{10.5555/AAI28491465,
author = {Darveau, Katherine E. and Rife, Jason and Stearns, Mary and Foster, Chad and Crall, Sharon},
advisor = {Daniel, Hannon,},
title = {Automated Classification of Human Factors Aviation Operational and Safety Events: A Human-Machine Teaming Approach to Text Mining and Machine Learning},
year = {2021},
isbn = {9798515227012},
publisher = {Tufts University},
address = {USA},
abstract = {The identification and interpretation of adverse event root cause is a critical function supporting the development of appropriate corrective actions in high-risk industries.  Aviation Human Factors (HF) professionals are interested in identifying events caused by human error in aircraft and engine assembly and maintenance to develop solutions to systemic issues.  Current event classification methods are heavily dependent on manual review of report narratives, which presents an opportunity to explore automated techniques using data science (DS), rule-based classification, and machine learning (ML).  In this study, automated classification models were developed, combined, and compared, using multiple event report fields as model inputs.  Based on the determination that event narratives are the most valuable source of root cause information, natural language processing (NLP) and feature engineering methods were explored to identify patterns in human language associated with error causal factors.  Human Factors principles guided the development of classifier models, interpretation of model output, and considerations for system implementation, resulting in a thorough, systemic process for effective integration of HF into the development of automated decision tools.  This process includes considerations for evaluating the data collection system to understand data quality limitations, selecting and manipulating model inputs, and developing feature extraction methods that target critical language and filter out noise.  A significant finding from this unique HF approach was the demonstrated benefit of subject matter expertise in model development and in the comparison of model performance to human capability.  The most effective models utilized human-machine teaming, which balances the strengths of automation and human interpretation.  Varying the level of human intervention resulted in performance tradeoffs, exposing the importance of evaluating performance goals and available resources when designing a human-machine teaming system.  Certain classification performance issues could not be overcome by enhanced modeling or subject matter expert (SME) input, yielding recommendations for the design and/or modification of operational and safety event reporting systems to improve data quality. The success of demonstrated classification models contributes significantly to the body of knowledge about text-based ML and aviation event classification.  Several validation studies suggest that findings are applicable to other aviation reporting systems and, possibly, event and/or injury narratives in other safety-critical industries.},
note = {AAI28491465}
}

@article{10.1007/s00500-021-05893-0,
author = {Kocher, Geeta and Kumar, Gulshan},
title = {Machine learning and deep learning methods for intrusion detection systems: recent developments and challenges},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {15},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-05893-0},
doi = {10.1007/s00500-021-05893-0},
abstract = {Deep learning (DL) is gaining significant prevalence in every field of study due to its domination in training large data sets. However, several applications are utilizing machine learning (ML) methods from the past several years and reported good performance. However, their limitations in terms of data complexity give rise to DL methods. Intrusion detection is one of the prominent areas in which researchers are extending DL methods. Even though several excellent surveys cover the growing body of research on this subject, the literature lacks a detailed comparison of ML methods such as ANN, SVM, fuzzy approach, swarm intelligence and evolutionary computation methods in intrusion detection, particularly on recent research. In this context, the present paper deals with the systematic review of ML methods and DL methods in intrusion detection. In addition to reviewing ML and DL methods, this paper also focuses on benchmark datasets, performance evaluation measures and various applications of DL methods for intrusion detection. The present paper summarizes the recent work, compares their experimental results for detecting network intrusions. Furthermore, current research challenges are identified for helping fellow researchers in the era of DL-based intrusion detection.},
journal = {Soft Comput.},
month = aug,
pages = {9731–9763},
numpages = {33},
keywords = {Intrusion detection system, Deep learning, Deep belief network, Recurrent neural network, Network intrusion detection system}
}

@article{10.1155/2020/8049504,
author = {Castelli, Mauro and Clemente, Fabiana Martins and Popovi\v{c}, Ale\v{s} and Silva, Sara and Vanneschi, Leonardo and Chan, Felix},
title = {A Machine Learning Approach to Predict Air Quality in California},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/8049504},
doi = {10.1155/2020/8049504},
abstract = {Predicting air quality is a complex task due to the dynamic nature, volatility, and high variability in time and space of pollutants and particulates. At the same time, being able to model, predict, and monitor air quality is becoming more and more relevant, especially in urban areas, due to the observed critical impact of air pollution on citizens’ health and the environment. In this paper, we employ a popular machine learning method, support vector regression (SVR), to forecast pollutant and particulate levels and to predict the air quality index (AQI). Among the various tested alternatives, radial basis function (RBF) was the type of kernel that allowed SVR to obtain the most accurate predictions. Using the whole set of available variables revealed a more successful strategy than selecting features using principal component analysis. The presented results demonstrate that SVR with RBF kernel allows us to accurately predict hourly pollutant concentrations, like carbon monoxide, sulfur dioxide, nitrogen dioxide, ground-level ozone, and particulate matter 2.5, as well as the hourly AQI for the state of California. Classification into six AQI categories defined by the US Environmental Protection Agency was performed with an accuracy of 94.1% on unseen validation data.},
journal = {Complex.},
month = jan,
numpages = {23}
}

@inproceedings{10.1145/3382494.3410681,
author = {Serban, Alex and van der Blom, Koen and Hoos, Holger and Visser, Joost},
title = {Adoption and Effects of Software Engineering Best Practices in Machine Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410681},
doi = {10.1145/3382494.3410681},
abstract = {Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner.Aim. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components.Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models.Results. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied.Conclusion. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {3},
numpages = {12},
keywords = {best practices, machine learning engineering, survey},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1007/978-3-030-85447-8_54,
author = {Langley, David and Reidy, Caoimhe and Towey, Mark and Manisha and Dennehy, Denis},
title = {Developing Machine Learning Model for Predicting Social Media Induced Fake News},
year = {2021},
isbn = {978-3-030-85446-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85447-8_54},
doi = {10.1007/978-3-030-85447-8_54},
abstract = {Fake news has been associated with major global events such as Covid-19 and the political polarisation of the US presidential election in 2016. This paper investigates how fake news has affected society and advance understanding of the nature of its impact in the future of democratic societies. Taken from large datasets consisting of over 23,000 fake news story words and over 21,000 true news story words we use descriptive and predictive analytics, partly analysing more than 350 words during the selected period of October 2016 to April 2017. The findings show that Trump was the most popular word for both true and fake news. In this study, we compare and contrast the words used and the volume of true versus fake news stories related to the election and the inauguration. This study makes an important contribution as it develops a predictive model that highlights the severity of political polarization and its consequences in democratic societies, which inevitably have implications for inclusive societies in the 21st century.},
booktitle = {Responsible AI and Analytics for an Ethical and Inclusive Digitized Society: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021, Galway, Ireland, September 1–3, 2021, Proceedings},
pages = {656–669},
numpages = {14},
keywords = {Fake news, Social media, Echo chambers, Filter bubbles, Machine learning, Polarization},
location = {Galway, Ireland}
}

@article{10.3233/JIFS-200682,
author = {Abulaish, Muhammad and Fazil, Mohd},
title = {A machine learning approach for socialbot targets detection on Twitter},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-200682},
doi = {10.3233/JIFS-200682},
abstract = {In online social networks (OSNs), socialbots are responsible for various malicious activities, and they are mainly programmed to imitate human-behavior to bypass the existing detection systems. The socialbots are generally successful in their malicious intent due to the existence of OSN users who follow them and thereby increase their reputation in the network. Analysis of the socialbot networks and their users is vital to comprehend the socialbot problem from target users’ perspective. In this paper, we present a machine learning-based approach for characterizing and detecting socialbot targets, i.e., users who are susceptible to be trapped by the socialbots. We model OSN users based on their identity and behavior information, representing the static and dynamic components of their personality. The proposed approach classifies socialbot targets into three categories viz. active, reactive, and inactive users. We evaluate the proposed approach using three classifiers over a dataset collected from a live socialbot injection experiment conducted on Twitter. We also present a comparative evaluation of the proposed approach with a state-of-the-art method and show that it performs significantly better. On feature ablation analysis, we found that network structure and user intention and personality related dynamic features are most discriminative, whereas static features show the least impact on the classification. Additionally, following rate, multimedia ratio, and follower rate are most relevant to segregate different categories of the socialbot targets. We also perform a detailed topical and behavioral analysis of socialbot targets and found active users to be suspicious. Further, joy and agreeableness are the most dominating personality traits among the three categories of the users.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {4115–4133},
numpages = {19},
keywords = {Machine learning, social network analysis, social network security, user profiling, socialbots}
}

@article{10.1007/s10614-017-9711-7,
author = {Chen, Yi-Ting and Sun, Edward W. and Yu, Min-Teh},
title = {Risk Assessment with Wavelet Feature Engineering for High-Frequency Portfolio Trading},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {2},
issn = {0927-7099},
url = {https://doi.org/10.1007/s10614-017-9711-7},
doi = {10.1007/s10614-017-9711-7},
abstract = {Dynamic risk management requires the risk measures to adapt to information at different times, such that this dynamic framework takes into account the time consistency of risk measures interrelated at different times. Therefore, dynamic risk measures for processes can be identified as risk measures for random variables on an appropriate product space. This paper proposes a wavelet feature decomposing algorithm based on the discrete wavelet transform that optimally decomposes the time-consistent features from the product space. This approach allows us to generalize the multiple-stage risk measures of value at risk and conditional value at risk for the feature-decomposed processes, and implement them into portfolio selection using high-frequency data of U.S. DJIA stocks. The overall empirical results confirm that our proposed method significantly improves the performance of dynamic risk assessment and portfolio selection.},
journal = {Comput. Econ.},
month = aug,
pages = {653–684},
numpages = {32},
keywords = {Big financial data, C02, C10, C63, Dynamic risk measures, Feature engineering, Portfolio optimization, Time consistency, Wavelet}
}

@article{10.1177/0165551516677911,
author = {Onan, Aytu\u{g}},
title = {An ensemble scheme based on language function analysis and feature engineering for text genre classification},
year = {2018},
issue_date = {2 2018},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {44},
number = {1},
issn = {0165-5515},
url = {https://doi.org/10.1177/0165551516677911},
doi = {10.1177/0165551516677911},
abstract = {Text genre classification is the process of identifying functional characteristics of text documents. The immense quantity of text documents available on the web can be properly filtered, organised and retrieved with the use of text genre classification, which may have potential use on several other tasks of natural language processing and information retrieval. Genre may refer to several aspects of text documents, such as function and purpose. The language function analysis LFA concentrates on single aspect of genres and it aims to classify text documents into three abstract classes, such as expressive, appellative and informative. Text genre classification is typically performed by supervised machine learning algorithms. The extraction of an efficient feature set to represent text documents is an essential task for building a robust classification scheme with high predictive performance. In addition, ensemble learning, which combines the outputs of individual classifiers to obtain a robust classification scheme, is a promising research field in machine learning research. In this regard, this article presents an extensive comparative analysis of different feature engineering schemes such as features used in authorship attribution, linguistic features, character  n -grams, part of speech  n -grams and the frequency of the most discriminative words and five different base learners Na ve Bayes, support vector machines, logistic regression,  k -nearest neighbour and Random Forest in conjunction with ensemble learning methods such as Boosting, Bagging and Random Subspace. Based on the empirical analysis, an ensemble classification scheme is presented, which integrates Random Subspace ensemble of Random Forest with four types of features features used in authorship attribution, character  n -grams, part of speech  n -grams and the frequency of the most discriminative words. For LFA corpus, the highest average predictive performance obtained by the proposed scheme is 94.43%.},
journal = {J. Inf. Sci.},
month = feb,
pages = {28–47},
numpages = {20},
keywords = {Text genre, ensemble learning, language function analysis}
}

@article{10.1016/j.neucom.2017.01.026,
author = {Zhou, Lina and Pan, Shimei and Wang, Jianwu and Vasilakos, Athanasios V.},
title = {Machine learning on big data},
year = {2017},
issue_date = {May 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {237},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2017.01.026},
doi = {10.1016/j.neucom.2017.01.026},
abstract = {Machine learning (ML) is continuously unleashing its power in a wide range of applications. It has been pushed to the forefront in recent years partly owing to the advent of big data. ML algorithms have never been better promised while challenged by big data. Big data enables ML algorithms to uncover more fine-grained patterns and make more timely and accurate predictions than ever before; on the other hand, it presents major challenges to ML such as model scalability and distributed computing. In this paper, we introduce a framework of ML on big data (MLBiD) to guide the discussion of its opportunities and challenges. The framework is centered on ML which follows the phases of preprocessing, learning, and evaluation. In addition, the framework is also comprised of four other components, namely big data, user, domain, and system. The phases of ML and the components of MLBiD provide directions for identification of associated opportunities and challenges and open up future work in many unexplored or under explored research areas.},
journal = {Neurocomput.},
month = may,
pages = {350–361},
numpages = {12},
keywords = {Big data, Data preprocessing, Evaluation, Machine learning, Parallelization}
}

@inbook{10.1145/3447404.3447407,
author = {McMenemy, David},
title = {Ethical Issues in Digital Signal Processing and Machine Learning},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447407},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {15–19},
numpages = {5}
}

@article{10.1155/2021/9988651,
author = {Lu, Fei and Shi, Zhenjiang and Su, Rijian and Wang, Wei},
title = {Communication Signal Modulation Mechanism Based on Artificial Feature Engineering Deep Neural Network Modulation Identifier},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/9988651},
doi = {10.1155/2021/9988651},
abstract = {Based on the characteristics of time domain and frequency domain recognition theory, a recognition scheme is designed to complete the modulation identification of communication signals including 16 analog and digital modulations, involving 10 different eigenvalues in total. In the in-class recognition of FSK signal, feature extraction in frequency domain is carried out, and a statistical algorithm of spectral peak number is proposed. This paper presents a method to calculate the rotation degree of constellation image. By calculating the rotation degree and modifying the clustering radius, the recognition rate of QAM signal is improved significantly. Another commonly used method for calculating the rotation of constellations is based on Radon transform. Compared with the proposed algorithm, the proposed algorithm has lower computational complexity and higher accuracy under certain SNR conditions. In the modulation discriminator of the deep neural network, the spectral features and cumulative features are extracted as inputs, the modified linear elements are used as neuron activation functions, and the cross-entropy is used as loss functions. In the modulation recognitor of deep neural network, deep neural network and cyclic neural network are constructed for modulation recognition of communication signals. The neural network automatic modulation recognizer is implemented on CPU and GPU, which verifies the recognition accuracy of communication signal modulation recognizer based on neural network. The experimental results show that the communication signal modulation recognizer based on artificial neural network has good classification accuracy in both the training set and the test set.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {11}
}

@inproceedings{10.1145/3379177.3388905,
author = {Liu, Hanyan and Eksmo, Samuel and Risberg, Johan and Hebig, Regina},
title = {Emerging and Changing Tasks in the Development Process for Machine Learning Systems},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388905},
doi = {10.1145/3379177.3388905},
abstract = {Integrating machine learning components in software systems is a task more and more companies are confronted with. However, there is not much knowledge today on how the software development process needs to change, when such components are integrated into a software system. We performed an interview study with 16 participants, focusing on emerging and changing task. The results uncover a set of 25 tasks associated to different software development phases, such as requirements engineering or deployment. We are just starting to understand the implications of using machine-learning components on the software development process. This study allows some first insights into how widespread the required process changes are.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {125–134},
numpages = {10},
keywords = {Challenges, Machine learning, Roles, Software process},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@inproceedings{10.1145/3377929.3397770,
author = {Le, Trang T. and Fu, Weixuan and Moore, Jason H.},
title = {Large scale biomedical data analysis with tree-based automated machine learning},
year = {2020},
isbn = {9781450371278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377929.3397770},
doi = {10.1145/3377929.3397770},
abstract = {Tree-based Pipeline Optimization Tool (TPOT) is an automated machine learning (AutoML) system that recommends optimal pipeline for supervised learning problems by scanning data for novel features, selecting appropriate models and optimizing their parameters. However, like other AutoML systems, TPOT may reach computational resource limits when working on big data such as whole-genome expression data. We develop two novel features for TPOT, Feature Set Selector and Template, which leverage domain knowledge, greatly reduce the computational expense and flexibly extend TPOT's application to biomedical big data analysis.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
pages = {21–22},
numpages = {2},
keywords = {autoML, genetic programming},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@article{10.1016/j.cose.2019.04.018,
author = {Carlin, Domhnall and O’Kane, Philip and Sezer, Sakir},
title = {A cost analysis of machine learning using dynamic runtime opcodes for malware detection},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {85},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2019.04.018},
doi = {10.1016/j.cose.2019.04.018},
journal = {Comput. Secur.},
month = aug,
pages = {138–155},
numpages = {18},
keywords = {Malicious code, Network security, Machine learning, Computer security, Malware}
}

@article{10.3233/THC-199005,
author = {Gao, Yongsheng and Luo, Yang and Zhao, Jie and Li, Qiang and G\'{o}mez, Carlos and Schwarzacher, Severin P.},
title = {sEMG-angle estimation using feature engineering techniques for least square support vector machine},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {S1},
issn = {0928-7329},
url = {https://doi.org/10.3233/THC-199005},
doi = {10.3233/THC-199005},
abstract = {In the practical implementation of control of electromyography (sEMG) driven devices, algorithms should recognize the human’s motion from sEMG with fast speed and high accuracy. This study proposes two feature engineering (FE) techniques, namely, feature-vector resampling and time-lag techniques, to improve the accuracy and speed of least square support vector machine (LSSVM) for wrist palmar angle estimation from sEMG feature. The root mean square error and correlation coefficients of LSSVM with FE are 9.50 ± 2.32 degree and 0.971 ± 0.018 respectively. The average training time and average execution time of LSSVM with FE in processing 12600 sEMG points are 0.016&nbsp;s and 0.053&nbsp;s respectively. To evaluate the proposed algorithm, its estimation results are compared with those of three other methods, namely, LSSVM, radial basis function (RBF) neural network, and RBF with FE. Experimental results verify that introduction of time-lag into feature vector can greatly improve the estimation accuracy of both RBF and LSSVM; meanwhile the application of feature-vector resampling technique can significantly increase the training and execution speed of RBF neural network and LSSVM. Among different algorithms applied in this study, LSSVM with FE techniques performed best in terms of training and execution speed, as well as estimation accuracy.},
journal = {Technol. Health Care},
month = jan,
pages = {31–46},
numpages = {16},
keywords = {Least square support vector machine, feature engineering, angle estimation, electromyograph}
}

@inproceedings{10.1145/2430502.2430531,
author = {Wulf-Hadash, Ora and Reinhartz-Berger, Iris},
title = {Cross product line analysis},
year = {2013},
isbn = {9781450315418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430502.2430531},
doi = {10.1145/2430502.2430531},
abstract = {Due to increase in market competition and merger and acquisition of companies, different software product lines (SPLs) may exist under the same roof. These SPLs may be developed applying different domain analysis processes, but are likely not disjoint. Cross product line analysis aims to examine the common and variable aspects of different SPLs for improving maintenance and future development of related SPLs. Currently different SPL artifacts, or more accurately feature models, are compared, matched, and merged for supporting scalability, increasing modularity and reuse, synchronizing feature model versions, and modeling multiple SPLs for software supply chains. However, in all these cases the focus is on creating valid merged models from the input feature models. Furthermore, the terminology used in all the input feature models is assumed to be the same, namely similar features are named the same. As a result these methods cannot be simply applied to feature models that represent different SPLs. In this work we offer adapting similarity metrics and text clustering techniques in order to enable cross product line analysis. This way analysis of feature models that use different terminologies in the same domain can be done in order to improve the management of the involved SPLs. Preliminary results reveal that the suggested method helps systematically analyze the commonality and variability between related SPLs, potentially suggesting improvements to existing SPLs and to the maintenance of sets of SPLs.},
booktitle = {Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {21},
numpages = {8},
keywords = {empirical evaluation, feature clustering, feature diagram matching, feature diagram merging, feature similarity},
location = {Pisa, Italy},
series = {VaMoS '13}
}

@inproceedings{10.1145/3205651.3208204,
author = {Fehst, Valerie and La, Huu Chuong and Nghiem, Tri-Duc and Mayer, Ben E. and Englert, Paul and Fiebig, Karl-Heinz},
title = {Automatic vs. manual feature engineering for anomaly detection of drinking-water quality},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208204},
doi = {10.1145/3205651.3208204},
abstract = {This paper evaluates anomaly detection approaches for drinking-water quality. Two major machine learning techniques are compared. One is manual feature engineering with feature subset selection for dimensionality reduction. The other is automatic feature learning through a recurrent neural network. Both methods incorporate the time domain for change detection. Preliminary results show a superior performance of automatic feature learning with an F1 score of 80%. While the feature set proposed in this work out-performs naive classification with original features, it needs further analysis to reach comparable performance to the automatic approach.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {5–6},
numpages = {2},
keywords = {anomaly detection, deep learning, fresh water, internet of things, machine learning},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@article{10.1007/s00779-019-01273-6,
author = {Zhang, Lan},
title = {Design of a sports culture data fusion system based on a data mining algorithm},
year = {2019},
issue_date = {Feb 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {1},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-019-01273-6},
doi = {10.1007/s00779-019-01273-6},
abstract = {The sports industry is an important component of social life and the national economy. With the advent of the era of big data, promoting the decision-making and scientific construction of the sports and cultural goods industry is conducive to the transformation and upgrading of the sports industry. In view of the shortcomings of the current sports stationery industry consumption data system, this paper combines K-means spatial clustering, fusion decision tree, naive Bayes, and other data mining algorithms and data warehouse technologies to the sports stationery industry. The consumption data system is the research object, and the analysis of geospatial feature clustering, customer segmentation, and consumption preference prediction of sports stationery industry consumption is carried out. The data mining–based sports cultural product industry data fusion system model is constructed, and the architecture, technology path, and function realization of the model are clarified. The actual case analysis and performance test results show that the realized sports cultural goods consumption data fusion system can provide a scientific reference model and basis for the modern sports stationery industry to use data mining and other new technologies to establish a decision-making information system.},
journal = {Personal Ubiquitous Comput.},
month = aug,
pages = {75–86},
numpages = {12},
keywords = {Sports stationery, Data mining, Decision tree, Naive Bayes, K-means}
}

@article{10.1145/3460822,
author = {Chakraborty, Saurav and Onuchowska, Agnieszka and Samtani, Sagar and Jank, Wolfgang and Wolfram, Brandon},
title = {Machine Learning for Automated Industrial IoT Attack Detection: An Efficiency-Complexity Trade-off},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/3460822},
doi = {10.1145/3460822},
abstract = {Critical city infrastructures that depend on smart Industrial Internet of Things (IoT) devices have been increasingly becoming a target of cyberterrorist or hacker attacks. Although this has led to multiple studies in the recent past, there exists a paucity of literature concerning real-time Industrial IoT attack detection. The goal of this article is to build a machine-learning approach using Industrial IoT sensor readings for accurately tracking down Industrial IoT attacks in real time. We analyze IoT system behavior under a lab-controlled series of attacks on a Secure Water Treatment (SWaT) system. The system is analytically challenging in that it results in sensor readings that resemble waveforms. To that end, we develop a novel early detection method using functional shape analysis (FSA) to extract features from the data that can capture the profile of the waveform. Our results show an efficiency-complexity trade-off between functional and non-functional methods in predicting IoT attacks.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = oct,
articleno = {37},
numpages = {28},
keywords = {Industrial IoT, cybersecurity, machine learning, functional shape analysis (FSA)}
}

@inproceedings{10.5555/3466184.3466252,
author = {Liu, Yang and Yan, Liang and Liu, Sheng and Jiang, Ting and Zhang, Feng and Wang, Yu and Wu, Shengnan},
title = {Enhancing input parameter estimation by machine learning for the simulation of large-scale logistics networks},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {The quality of large-scale logistics network simulation highly depends on the estimation of its key input parameters, which are usually influenced by various factors that are difficult to obtain. To tackle this challenge, this paper proposes a framework to estimate these parameters with high precision through machine learning, in which the impacting factors are divided into static and dynamic groups and used as features to train a learning model for estimation. To overcome the obstacle that dynamic factors are hard to obtain in some scenarios, the proposed framework employs unsupervised learning to analyze their patterns and extract time-invariant features for modeling. A validation study is conducted on the estimation of distribution center sorting times. The results proved our approach can generate more accurate estimation of input parameters, even with the shift of operational plans and absence of relevant data.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {608–619},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@article{10.1145/3185515,
author = {Chen, Nan-Chen and Drouhard, Margaret and Kocielnik, Rafal and Suh, Jina and Aragon, Cecilia R.},
title = {Using Machine Learning to Support Qualitative Coding in Social Science: Shifting the Focus to Ambiguity},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3185515},
doi = {10.1145/3185515},
abstract = {Machine learning (ML) has become increasingly influential to human society, yet the primary advancements and applications of ML are driven by research in only a few computational disciplines. Even applications that affect or analyze human behaviors and social structures are often developed with limited input from experts outside of computational fields. Social scientists—experts trained to examine and explain the complexity of human behavior and interactions in the world—have considerable expertise to contribute to the development of ML applications for human-generated data, and their analytic practices could benefit from more human-centered ML methods. Although a few researchers have highlighted some gaps between ML and social sciences [51, 57, 70], most discussions only focus on quantitative methods. Yet many social science disciplines rely heavily on qualitative methods to distill patterns that are challenging to discover through quantitative data. One common analysis method for qualitative data is qualitative coding. In this article, we highlight three challenges of applying ML to qualitative coding. Additionally, we utilize our experience of designing a visual analytics tool for collaborative qualitative coding to demonstrate the potential in using ML to support qualitative coding by shifting the focus to identifying ambiguity. We illustrate dimensions of ambiguity and discuss the relationship between disagreement and ambiguity. Finally, we propose three research directions to ground ML applications for social science as part of the progression toward human-centered machine learning.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jun,
articleno = {9},
numpages = {20},
keywords = {Social scientists, ambiguity, computational social science, human-centered machine learning, machine learning, qualitative coding}
}

@inproceedings{10.1007/978-3-030-37429-7_58,
author = {Zeng, Fuwei and Bao, Tie and Xiang, Wenhao},
title = {Machine Learning in Short Video APP User Activity Prediction},
year = {2019},
isbn = {978-3-030-37428-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37429-7_58},
doi = {10.1007/978-3-030-37429-7_58},
abstract = {In order to improve the accuracy and reduce the cost of forecasting, this paper uses machine learning related technology to solve this problem in the user activity prediction model of short video industry. Continuous use of short video APP by active users is a sufficient and necessary condition for its success. The prediction of user activity has a direct guiding effect on the subsequent user loss warning. Based on the analysis of the impact on user activity, this paper extracts the characteristics according to registration log, startup log, shooting log and behavior log, and proposes a prediction algorithm based on model fusion for user activity. Based on the experimental data, the results show that the predicted AUC value reached 0.9514.},
booktitle = {Human Centered Computing: 5th International Conference, HCC 2019, \v{C}a\v{c}ak, Serbia, August 5–7, 2019, Revised Selected Papers},
pages = {568–575},
numpages = {8},
keywords = {Short video APP, Activity, Machine learning, LightGBM, AUC},
location = {\v{C}a\v{c}ak, Serbia}
}

@article{10.1007/s11277-021-08284-8,
author = {Hongsong, Chen and Yongpeng, Zhang and Yongrui, Cao and Bhargava, Bharat},
title = {Security Threats and Defensive Approaches in Machine Learning System Under Big Data Environment},
year = {2021},
issue_date = {Apr 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {117},
number = {4},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08284-8},
doi = {10.1007/s11277-021-08284-8},
abstract = {Under big data environment, machine learning has been rapidly developed and widely used. It has been successfully applied in computer vision, natural language processing, computer security and other application fields. However, there are many security problems in machine learning under big data environment. For example, attackers can add “poisoned” sample to the data source, and big data process system will process these “poisoned” sample and use machine learning methods to train model, which will directly lead to wrong prediction results. In this paper, machine learning system and machine learning pipeline are proposed. The security problems that maybe occur in each stage of machine learning system under big data processing pipeline are analyzed comprehensively. We use four different attack methods to compare the attack experimental results.The security problems are classified comprehensively, and the defense approaches to each security problem are analyzed. Drone-deploy MapEngine is selected as a case study, we analyze the security threats and defense approaches in the Drone-Cloud machine learning application envirolment. At last,the future development drections of security issues and challenages in the machine learning system are proposed.},
journal = {Wirel. Pers. Commun.},
month = apr,
pages = {3505–3525},
numpages = {21},
keywords = {Machine learning system, Big data pipeline, Security threats, Defensive approaches, Case study}
}

@article{10.1007/s00521-019-04643-6,
author = {Gao, Huanbing and Yuan, Liyan},
title = {Research on key technology of pavement object recognition based on machine learning},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {10},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04643-6},
doi = {10.1007/s00521-019-04643-6},
abstract = {According to statistics, the incidence of traffic accidents in China is far greater than that of developed countries such as the USA and Germany. Nearly 100,000 people die in traffic accidents every year in China. The use of the assisted driving system effectively reduces the incidence of traffic accidents, while road surface object recognition is the key research object in the assisted driving system. At present, in the research on the recognition of pavement objects, there are problems such as low recognition rate and long recognition time, which cannot play the role of assisting driving. In response to these problems, this paper proposes a research on pavement object recognition based on machine learning, including analysis of key technologies of machine learning and optimization of related algorithms. In order to verify the feasibility of the proposed method in the assisted driving system, the research results are applied to the road surface object recognition device and the experiment is carried out under the actual traffic environment. The results show that in the selected experimental scenes, the recognition accuracy of the road surface object recognition device applying the research results of this paper is 100%, and the recognition time is far lower than the traditional road object recognition method. The results show that the proposed method can quickly and effectively identify the pavement object, and then assist the driver to control the vehicle, which has good applicability in the assisted driving system.},
journal = {Neural Comput. Appl.},
month = may,
pages = {5483–5493},
numpages = {11},
keywords = {Machine learning, Object recognition, Assisted driving, Support vector machine, Classifier}
}

@inproceedings{10.1007/978-3-642-33666-9_46,
author = {Ali, Shaukat and Yue, Tao and Briand, Lionel and Walawege, Suneth},
title = {A product line modeling and configuration methodology to support model-based testing: an industrial case study},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_46},
doi = {10.1007/978-3-642-33666-9_46},
abstract = {Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behavioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {726–742},
numpages = {17},
keywords = {UML state machine, aspect-oriented modeling, behavioral variability, model-based testing, product line engineering},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@article{10.1016/j.procs.2019.08.183,
author = {Balabaeva, Ksenia and Kovalchuk, Sergey},
title = {Comparison of Temporal and Non-Temporal Features Effect on Machine Learning Models Quality and Interpretability for Chronic Heart Failure Patients},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {156},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.08.183},
doi = {10.1016/j.procs.2019.08.183},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {87–96},
numpages = {10},
keywords = {chronic heart failure, predictive modelling, complex systems modelling, machine learning, interpretable machine learning}
}

@article{10.1016/j.compag.2019.105124,
author = {Gorczyca, Michael T. and Gebremedhin, Kifle G.},
title = {Ranking of environmental heat stressors for dairy cows using machine learning algorithms},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {168},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2019.105124},
doi = {10.1016/j.compag.2019.105124},
journal = {Comput. Electron. Agric.},
month = jan,
numpages = {8},
keywords = {Heat stress, Dairy cows, Machine learning, Random forest, Neural network}
}

@article{10.1007/s10664-020-09864-1,
author = {Abualhaija, Sallam and Arora, Chetan and Sabetzadeh, Mehrdad and Briand, Lionel C. and Traynor, Michael},
title = {Automated demarcation of requirements in textual specifications: a machine learning-based approach},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09864-1},
doi = {10.1007/s10664-020-09864-1},
abstract = {A simple but important task during the analysis of a textual requirements specification is to determine which statements in the specification represent requirements. In principle, by following suitable writing and markup conventions, one can provide an immediate and unequivocal demarcation of requirements at the time a specification is being developed. However, neither the presence nor a fully accurate enforcement of such conventions is guaranteed. The result is that, in many practical situations, analysts end up resorting to after-the-fact reviews for sifting requirements from other material in a requirements specification. This is both tedious and time-consuming. We propose an automated approach for demarcating requirements in free-form requirements specifications. The approach, which is based on machine learning, can be applied to a wide variety of specifications in different domains and with different writing styles. We train and evaluate our approach over an independently labeled dataset comprised of 33 industrial requirements specifications. Over this dataset, our approach yields an average precision of 81.2% and an average recall of 95.7%. Compared to simple baselines that demarcate requirements based on the presence of modal verbs and identifiers, our approach leads to an average gain of 16.4% in precision and 25.5% in recall. We collect and analyze expert feedback on the demarcations produced by our approach for industrial requirements specifications. The results indicate that experts find our approach useful and efficient in practice. We developed a prototype tool, named DemaRQ, in support of our approach. To facilitate replication, we make available to the research community this prototype tool alongside the non-proprietary portion of our training data.},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5454–5497},
numpages = {44},
keywords = {Textual requirements, Requirements identification and classification, Machine learning, Natural language processing}
}

@article{10.1007/s10270-020-00856-9,
author = {Pilarski, Sebastian and Staniszewski, Martin and Bryan, Matthew and Villeneuve, Frederic and Varr\'{o}, D\'{a}niel},
title = {Predictions-on-chip: model-based training and automated deployment of machine learning models at runtime: For multi-disciplinary design and operation of gas turbines},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00856-9},
doi = {10.1007/s10270-020-00856-9},
abstract = {The design of gas turbines is a challenging area of cyber-physical systems where complex model-based simulations across multiple disciplines (e.g., performance, aerothermal) drive the design process. As a result, a continuously increasing amount of data is derived during system design. Finding new insights in such data by exploiting various machine learning (ML) techniques is a promising industrial trend since better predictions based on real data result in substantial product quality improvements and cost reduction. This paper presents a method that generates data from multi-paradigm simulation tools, develops and trains ML models for prediction, and deploys such prediction models into an active control system operating at runtime with limited computational power. We explore the replacement of existing traditional prediction modules with ML counterparts with different architectures. We validate the effectiveness of various ML models in the context of three (real) gas turbine bearings using over 150,000 data points for training, validation, and testing. We introduce code generation techniques for automated deployment of neural network models to industrial off-the-shelf programmable logic controllers.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {685–709},
numpages = {25},
keywords = {Prediction-at-runtime, Machine learning, Neural networks, Automated deployment, Code generation, Gas turbine engines}
}

@article{10.1109/TCBB.2018.2858808,
author = {Wassan, Jyotsna Talreja and Wang, Haiying and Browne, Fiona and Zheng, Huiru},
title = {A Comprehensive Study on Predicting Functional Role of Metagenomes Using Machine Learning Methods},
year = {2019},
issue_date = {May 2019},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2018.2858808},
doi = {10.1109/TCBB.2018.2858808},
abstract = {"Metagenomics" is the study of genomic sequences obtained directly from environmental microbial communities with the aim to linking their structures with functional roles. The field has been aided in the unprecedented advancement through high-throughput omics data sequencing. The outcome of sequencing are biologically rich data sets. Metagenomic data consisting of microbial species which outnumber microbial samples, lead to the "curse of dimensionality" in datasets. Hence, the focus in metagenomics studies has moved towards developing efficient computational models using Machine Learning ML, reducing the computational cost. In this paper, we comprehensively assessed various ML approaches to classifying high-dimensional human microbiota effectively into their functional phenotypes. We propose the application of embedded feature selection methods, namely, Extreme Gradient Boosting and Penalized Logistic Regression to determine important microbial species. The resultant feature set enhanced the performance of one of the most popular state-of-the-art methods, Random Forest RF over metagenomic studies. Experimental results indicate that the proposed method achieved best results in terms of accuracy, area under the Receiver Operating Characteristic curve ROC-AUC, and major improvement in processing time. It outperformed other feature selection methods of filters or wrappers over RF and classifiers such as Support Vector Machine SVM, Extreme Learning Machine ELM, and k- Nearest Neighbors k-NN.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = may,
pages = {751–763},
numpages = {13}
}

@inproceedings{10.5555/3045118.3045209,
author = {Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
title = {Unsupervised learning of video representations using LSTMs},
year = {2015},
publisher = {JMLR.org},
abstract = {We use Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {843–852},
numpages = {10},
location = {Lille, France},
series = {ICML'15}
}

@inproceedings{10.1145/3177540.3177555,
author = {Wang, Li-C.},
title = {Machine Learning for Feature-Based Analytics},
year = {2018},
isbn = {9781450356268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177540.3177555},
doi = {10.1145/3177540.3177555},
abstract = {Applying machine learning in Electronic Design Automation (EDA) has received growing interests in recent years. One approach to analyze data in EDA applications can be called feature-based analytics. In this context, the paper explains the inadequacy of adopting a traditional machine learning problem formulation view. Then, an alternative machine learning view is suggested where learning from data is treated as an iterative search process. The theoretical and practical considerations for implementing such a search process are discussed in the context of various applications.},
booktitle = {Proceedings of the 2018 International Symposium on Physical Design},
pages = {74–81},
numpages = {8},
keywords = {Occam's razor, design automation, feature-based analytics, learnable, machine learning, version space},
location = {Monterey, California, USA},
series = {ISPD '18}
}

@article{10.1155/2021/4767388,
author = {Soleymani, Ali and Arabgol, Fatemeh and Shojae Chaeikar, Saman},
title = {A Novel Approach for Detecting DGA-Based Botnets in DNS Queries Using Machine Learning Techniques},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {2090-7141},
url = {https://doi.org/10.1155/2021/4767388},
doi = {10.1155/2021/4767388},
abstract = {In today’s security landscape, advanced threats are becoming increasingly difficult to detect as the pattern of attacks expands. Classical approaches that rely heavily on static matching, such as blacklisting or regular expression patterns, may be limited in flexibility or uncertainty in detecting malicious data in system data. This is where machine learning techniques can show their value and provide new insights and higher detection rates. The behavior of botnets that use domain-flux techniques to hide command and control channels was investigated in this research. The machine learning algorithm and text mining used to analyze the network DNS protocol and identify botnets were also described. For this purpose, extracted and labeled domain name datasets containing healthy and infected DGA botnet data were used. Data preprocessing techniques based on a text-mining approach were applied to explore domain name strings with n-gram analysis and PCA. Its performance is improved by extracting statistical features by principal component analysis. The performance of the proposed model has been evaluated using different classifiers of machine learning algorithms such as decision tree, support vector machine, random forest, and logistic regression. Experimental results show that the random forest algorithm can be used effectively in botnet detection and has the best botnet detection accuracy.},
journal = {J. Comput. Netw. Commun.},
month = jan,
numpages = {13}
}

@article{10.1016/j.inffus.2018.09.012,
author = {Zitnik, Marinka and Nguyen, Francis and Wang, Bo and Leskovec, Jure and Goldenberg, Anna and Hoffman, Michael M.},
title = {Machine learning for integrating data in biology and medicine: Principles, practice, and opportunities},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.09.012},
doi = {10.1016/j.inffus.2018.09.012},
journal = {Inf. Fusion},
month = oct,
pages = {71–91},
numpages = {21},
keywords = {Computational biology, Personalized medicine, Systems biology, Heterogeneous data, Machine learning}
}

@inproceedings{10.1007/978-3-030-58817-5_66,
author = {Kumari, Madhu and Singh, Ujjawal Kumar and Sharma, Meera},
title = {Entropy Based Machine Learning Models for Software Bug Severity Assessment in Cross Project Context},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_66},
doi = {10.1007/978-3-030-58817-5_66},
abstract = {There can be noise and uncertainty in the bug reports data as the bugs are reported by a heterogeneous group of users working across different countries. Bug description is an essential attribute that helps to predict other bug attributes, such as severity, priority, and time fixes. We need to consider the noise and confusion present in the text of the bug report, as it can impact the output of different machine learning techniques. Shannon entropy has been used in this paper to calculate summary uncertainty about the bug. Bug severity attribute tells about the type of impact the bug has on the functionality of the software. Correct bug severity estimation allows scheduling and repair bugs and hence help in resource and effort utilization. To predict the severity of the bug we need software project historical data to train the classifier. These training data are not always available in particular for new software projects. The solution which is called cross project prediction is to use the training data from other projects. Using bug priority, summary weight and summary entropy, we have proposed cross project bug severity assessment models. Results for proposed summary entropy based approach for bug severity prediction in cross project context show improved performance of the Accuracy and F-measure up to 70.23% and 93.72% respectively across all the machine learning techniques over existing work.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {939–953},
numpages = {15},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3368089.3417063,
author = {Peng, Zi and Yang, Jinqiu and Chen, Tse-Hsun (Peter) and Ma, Lei},
title = {A first look at the integration of machine learning models in complex autonomous driving systems: a case study on Apollo},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417063},
doi = {10.1145/3368089.3417063},
abstract = {Autonomous Driving System (ADS) is one of the most promising and valuable large-scale machine learning (ML) powered systems. Hence, ADS has attracted much attention from academia and practitioners in recent years. Despite extensive study on ML models, it still lacks a comprehensive empirical study towards understanding the ML model roles, peculiar architecture, and complexity of ADS (i.e., various ML models and their relationship with non-trivial code logic). In this paper, we conduct an in-depth case study on Apollo, which is one of the state-of-the-art ADS, widely adopted by major automakers worldwide. We took the first step to reveal the integration of the underlying ML models and code logic in Apollo. In particular, we study the Apollo source code and present the underlying ML model system architecture. We present our findings on how the ML models interact with each other, and how the ML models are integrated with code logic to form a complex system. Finally, we inspect Apollo in a dynamic view and notice the heavy use of model-relevant components and the lack of adequate tests in general. Our study reveals potential maintenance challenges of complex ML-powered systems and identifies future directions to improve the quality assurance of ADS and general ML systems.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1240–1250},
numpages = {11},
keywords = {Autonomous driving systems, Empirical study, Machine learning, Model testing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3377325.3377538,
author = {Weidele, Daniel Karl I. and Weisz, Justin D. and Oduor, Erick and Muller, Michael and Andres, Josh and Gray, Alexander and Wang, Dakuo},
title = {AutoAIViz: opening the blackbox of automated artificial intelligence with conditional parallel coordinates},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377538},
doi = {10.1145/3377325.3377538},
abstract = {Artificial Intelligence (AI) can now automate the algorithm selection, feature engineering, and hyperparameter tuning steps in a machine learning workflow. Commonly known as AutoML or AutoAI, these technologies aim to relieve data scientists from the tedious manual work. However, today's AutoAI systems often present only limited to no information about the process of how they select and generate model results. Thus, users often do not understand the process, neither do they trust the outputs. In this short paper, we provide a first user evaluation by 10 data scientists of an experimental system, AutoAIViz, that aims to visualize AutoAI's model generation process. We find that the proposed system helps users to complete the data science tasks, and increases their understanding, toward the goal of increasing trust in the AutoAI system.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {308–312},
numpages = {5},
keywords = {AutoAI, AutoML, democratizing AI, human-AI collaboration, parallel coordinates, visualization},
location = {Cagliari, Italy},
series = {IUI '20}
}

@inproceedings{10.1145/2623330.2623377,
author = {Srikant, Shashank and Aggarwal, Varun},
title = {A system to grade computer programming skills using machine learning},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623377},
doi = {10.1145/2623330.2623377},
abstract = {The automatic evaluation of computer programs is a nascent area of research with a potential for large-scale impact. Extant program assessment systems score mostly based on the number of test-cases passed, providing no insight into the competency of the programmer. In this paper, we present a system to grade computer programs automatically. In addition to grading a program on its programming practices and complexity, the key kernel of the system is a machine-learning based algorithm which determines closeness of the logic of the given program to a correct program. This algorithm uses a set of highly-informative features, derived from the abstract representations of a given program, that capture the program's functionality. These features are then used to learn a model to grade the programs, which are built against evaluations done by experts. We show that the regression models provide much better grading than the ubiquitous test-case-pass based grading and rivals the grading accuracy of other open-response problems such as essay grading . We also show that our novel features add significant value over and above basic keyword/expression count features. In addition to this, we propose a novel way of posing computer-program grading as a one-class modeling problem and report encouraging preliminary results. We show the value of the system through a case study in a real-world industrial deployment. To the best of the authors' knowledge, this is the first time a system using machine learning has been developed and used for grading programs. The work is timely with regard to the recent boom in Massively Online Open Courseware (MOOCs), which promises to produce a significant amount of hand-graded digitized data.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1887–1896},
numpages = {10},
keywords = {automatic grading, feature engineering, mooc, one-class learning, recruitment, supervised learning},
location = {New York, New York, USA},
series = {KDD '14}
}

@inproceedings{10.1145/2934466.2934485,
author = {Lape\~{n}a, Ra\'{u}l and Ballarin, Manuel and Cetina, Carlos},
title = {Towards clone-and-own support: locating relevant methods in legacy products},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934485},
doi = {10.1145/2934466.2934485},
abstract = {Clone-and-Own (CAO) is a common practice in families of software products consisting of reusing code from methods in legacy products in new developments. In industrial scenarios, CAO consumes high amounts of time and effort without guaranteeing good results. We propose a novel approach, Computer Assisted CAO (CACAO), that given the natural language requirements of a new product, and the legacy products from that family, ranks the legacy methods in the family for each of the new product requirements according to their relevancy to the new development. We evaluated our approach in the industrial domain of train control software. Without CACAO, software engineers tasked with the development of a new product had to manually review a total of 2200 methods in the family. Results show that CACAO can reduce the number of methods to be reviewed, and guide software engineers towards the identification of relevant legacy methods to be reused in the new product.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {194–203},
numpages = {10},
keywords = {clone and own, families of software products, software reuse},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1007/s11063-020-10381-x,
author = {Sentuna, Ayan and Alsadoon, Abeer and Prasad, P. W. C. and Saadeh, Maha and Alsadoon, Omar Hisham},
title = {A Novel Enhanced Na\"{\i}ve Bayes Posterior Probability (ENBPP) Using Machine Learning: Cyber Threat Analysis},
year = {2021},
issue_date = {Feb 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {1},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10381-x},
doi = {10.1007/s11063-020-10381-x},
abstract = {Machine learning techniques, that are based on semantic analysis of behavioural attack patterns, have not been successfully implemented in cyber threat intelligence. This is because of the error prone and time-consuming manual process of deep learning solutions, which is commonly used for searching correlated cyber-attack tactics, techniques and procedures in cyber-attacks prediction techniques. The aim of this paper is to improve the prediction accuracy and the processing time of cyber-attacks prediction mechanisms by proposing enhanced Na\"{\i}ve Bayes posterior probability (ENBPP) algorithm. The proposed algorithm combines two functions; a modified version of Na\"{\i}ve Bayes posterior probability function and a modified risk assessment function. Combining these two functions will enhance the threat prediction accuracy and decrease the processing time. Five different datasets were used to obtain the results. Five different datasets containing 328,814 threat samples were used to obtain the processing time and the prediction accuracy results for the proposed solution. Results show that the proposed solution gives better prediction accuracy and processing time when different examination types and different scenarios are taken into consideration. The proposed solution provides a significant prediction accuracy improvement in threat analysis from 92–96% and decreases the average processing time from 0.043 to 0.028 s compared with the other method. The proposed solution successfully enhances the overall prediction accuracy and improves the processing time by solving the TTPs dependency and the prediction sets threshold problems. Thus, the proposed algorithm reaches a more reliable threat prediction solution.},
journal = {Neural Process. Lett.},
month = feb,
pages = {177–209},
numpages = {33},
keywords = {Cyber threat intelligence, Deep belief network, Machine learning, Latent semantic indexing, Tactics, Techniques and procedures, Intrusion detection systems, Na\"{\i}ve Bayes}
}

@inproceedings{10.1145/2791060.2791093,
author = {Souto, Sabrina and Gopinath, Divya and d'Amorim, Marcelo and Marinov, Darko and Khurshid, Sarfraz and Batory, Don},
title = {Faster bug detection for software product lines with incomplete feature models},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791093},
doi = {10.1145/2791060.2791093},
abstract = {A software product line (SPL) is a family of programs that are differentiated by features --- increments in functionality. Systematically testing an SPL is challenging because it requires running each test of a test suite against a combinatorial number of programs. Feature models capture dependencies among features and can (1) reduce the space of programs to test and (2) enable accurate categorization of failing tests as failures of programs or the tests themselves, not as failures due to illegal combinations of features. In practice, sadly, feature models are not always available.We introduce SPLif, the first approach for testing SPLs that does not require the a priori availability of feature models. Our insight is to use a profile of passing and failing test runs to quickly identify failures that are indicative of real problems in test or code rather than specious failures due to illegal feature combinations.Experimental results on five SPLs and one large configurable system (GCC) demonstrate the effectiveness of our approach. SPLif enabled the discovery of five news bugs in GCC, three of which have already been fixed.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {151–160},
numpages = {10},
keywords = {GCC, feature models, software testing},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3341162.3346276,
author = {Maritsch, Martin and B\'{e}rub\'{e}, Caterina and Kraus, Mathias and Lehmann, Vera and Z\"{u}ger, Thomas and Feuerriegel, Stefan and Kowatsch, Tobias and Wortmann, Felix},
title = {Improving heart rate variability measurements from consumer smartwatches with machine learning},
year = {2019},
isbn = {9781450368698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341162.3346276},
doi = {10.1145/3341162.3346276},
abstract = {The reactions of the human body to physical exercise, psychophysiological stress and heart diseases are reflected in heart rate variability (HRV). Thus, continuous monitoring of HRV can contribute to determining and predicting issues in well-being and mental health. HRV can be measured in everyday life by consumer wearable devices such as smartwatches which are easily accessible and affordable. However, they are arguably accurate due to the stability of the sensor. We hypothesize a systematic error which is related to the wearer movement. Our evidence builds upon explanatory and predictive modeling: we find a statistically significant correlation between error in HRV measurements and the wearer movement. We show that this error can be minimized by bringing into context additional available sensor information, such as accelerometer data. This work demonstrates our research-in-progress on how neural learning can minimize the error of such smartwatch HRV measurements.},
booktitle = {Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers},
pages = {934–938},
numpages = {5},
keywords = {heart rate variability, neural networks, smartwatch},
location = {London, United Kingdom},
series = {UbiComp/ISWC '19 Adjunct}
}

@article{10.1016/j.procs.2021.06.022,
author = {Domashova, Jenny and Kripak, Elena},
title = {Application of machine learning methods for risk analysis of unfavorable outcome of government procurement procedure in building and grounds maintenance domain},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {190},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.06.022},
doi = {10.1016/j.procs.2021.06.022},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {171–177},
numpages = {7},
keywords = {public procurement, government procurement, associative rules, cluster analysis methods, machine learning.}
}

@inproceedings{10.1145/3209889.3209897,
author = {Xin, Doris and Ma, Litian and Liu, Jialin and Macke, Stephen and Song, Shuchen and Parameswaran, Aditya},
title = {Accelerating Human-in-the-loop Machine Learning: Challenges and Opportunities},
year = {2018},
isbn = {9781450358286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209889.3209897},
doi = {10.1145/3209889.3209897},
abstract = {Development of machine learning (ML) workflows is a tedious process of iterative experimentation: developers repeatedly make changes to workflows until the desired accuracy is attained. We describe our vision for a "human-in-the-loop" ML system that accelerates this process: by intelligently tracking changes and intermediate results over time, such a system can enable rapid iteration, quick responsive feedback, introspection and debugging, and background execution and automation. We finally describe Helix, our preliminary attempt at such a system that has already led to speedups of upto 10x on typical iterative workflows against competing systems.},
booktitle = {Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning},
articleno = {9},
numpages = {4},
location = {Houston, TX, USA},
series = {DEEM'18}
}

@inproceedings{10.1145/3318299.3318317,
author = {Li, Haifeng and Li, Yan and Li, Xutao and Ye, Yunming and Li, Xian and Xie, Pengfei},
title = {A Comparative Study on Machine Learning Approaches to Thunderstorm Gale Identification},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318317},
doi = {10.1145/3318299.3318317},
abstract = {In this paper, we make a comparative study to examine the performance of different machine learning approaches for the thunderstorm gale identification. To this end, a thunderstorm gale benchmark dataset is constructed, which comprises radar images in Guangdong from 2015 to 2017. The corresponding wind velocities recorded by the automatic meteorological observation stations are utilized to offer the ground-truth. Based on the dataset, we evaluate the performance of Decision Tree Regressor (DT), Linear Regression (LR), Ridge regression, Lasso regression, Random Forest Regressor (RFR), K-nearest Neighbor Regressor (KNNR), Bayesian Ridge Regressor (BR), Adaboost Regressor (AR), Support Vector Regressor (SVR), Gradient Boosting Regressor (GBR), and Convolutional Neural Network (CNN). Ten important features are extracted to apply these approaches, except CNN, which include radar echo intensity, radar reflectivity factor, radar combined reflectivity, vertical integrated liquid, echo tops and their changes with respect to (w.r.t.) time. Experimental results demonstrate the machine learning approaches can effectively identify the thunderstorm gale, and the CNN model performs the best. Finally, a thunderstorm system is developed based on CNN model, which help meteorologists to identify thunderstorm gales in terms of radar images.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {12–16},
numpages = {5},
keywords = {Radar echo images, convolutional neural network, regression, thunderstorm gale identification},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1016/j.cie.2014.01.011,
author = {Deng, S. and Aydin, R. and Kwong, C. K. and Huang, Yun},
title = {Integrated product line design and supplier selection: A multi-objective optimization paradigm},
year = {2014},
issue_date = {April, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {70},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2014.01.011},
doi = {10.1016/j.cie.2014.01.011},
abstract = {Product line design is commonly used to provide higher product variety for satisfying diversified customer needs. To reduce the cost and development time and improve quality of products, companies quite often consider sourcing. Conventionally, product line design and supplier selection are dealt with separately. Some previous studies have been attempted to consider product line design and supplier selection simultaneously but two shortcomings were noted. First, the previous studies considered several objectives as a single objective function in the formulation of optimization models for the integrated problem. Second, positions of product variants to be offered in a product line in competitive markets are not clearly defined that would affect the formulation of marketing strategies for the product line. In this paper, a methodology for integrated product line design and supplier selection is proposed to address the shortcomings in which a multi-objective optimization model is formulated to determine their specifications and select suppliers for maximizing the profit, quality and performance as well as minimizing the cost of the product line. In addition, joint-spacing mapping is introduced to help estimate market share of products and indicate positions of product variants. The proposed methodology can provide decision makers with a better tradeoff among various objectives of product line design, and define market positions of product variants explicitly. The results generated based on the methodology could help companies develop product lines with higher profits, better product quality and larger market share to be obtained. A case study of a product line design of notebook computers was performed to illustrate the effectiveness of the proposed methodology. The results have shown that Pareto optimal product line designs and the specifications of product variants can be determined. Suppliers of components and modules can be selected with considerations of minimum sourcing cost, and maximum performance and quality of product variants. Prices and positions of the product variants can also be determined.},
journal = {Comput. Ind. Eng.},
month = apr,
pages = {150–158},
numpages = {9},
keywords = {Multi-objective optimization, NSGA II, Product line design, Supplier selection}
}

@article{10.1007/s00500-019-04347-y,
author = {Khan, Wasiat and Malik, Usman and Ghazanfar, Mustansar Ali and Azam, Muhammad Awais and Alyoubi, Khaled H. and Alfakeeh, Ahmed S.},
title = {Predicting stock market trends using machine learning algorithms via public sentiment and political situation analysis},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {15},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-04347-y},
doi = {10.1007/s00500-019-04347-y},
abstract = {Stock market trends can be affected by external factors such as public sentiment and political events. The goal of this research is to find whether or not public sentiment and political situation on a given day can affect stock market trends of individual companies or the overall market. For this purpose, the sentiment and situation features are used in a machine learning model to find the effect of public sentiment and political situation on the prediction accuracy of algorithms for 7&nbsp;days in future. Besides, interdependencies among companies and stock markets are also studied. For the sake of experimentation, stock market historical data are downloaded from Yahoo! Finance and public sentiments are obtained from Twitter. Important political events data of Pakistan are crawled from Wikipedia. The raw text data are then pre-processed, and the sentiment and situation features are generated to create the final data sets. Ten machine learning algorithms are applied to the final data sets to predict the stock market future trend. The experimental results show that the sentiment feature improves the prediction accuracy of machine learning algorithms by 0–3%, and political situation feature improves the prediction accuracy of algorithms by about 20%. Furthermore, the sentiment attribute is most effective on day 7, while the political situation attribute is most effective on day 5. SMO algorithm is found to show the best performance, while ASC and Bagging show poor performance. The interdependency results indicate that stock markets in the same industry show a medium positive correlation with each other.},
journal = {Soft Comput.},
month = aug,
pages = {11019–11043},
numpages = {25},
keywords = {Natural language processing, Predictive models, Stock markets, Sentiment analysis}
}

@article{10.3233/JHS-200641,
author = {Alothman, Zainab and Alkasassbeh, Mouhammd and Al-Haj Baddar, Sherenaz},
title = {An efficient approach to detect IoT botnet attacks using machine learning},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {26},
number = {3},
issn = {0926-6801},
url = {https://doi.org/10.3233/JHS-200641},
doi = {10.3233/JHS-200641},
abstract = {The numerous security loopholes in the design and implementation of many IoT devices have rendered them an easy target for botnet attacks. Several approaches to implement behavioral IoT botnet attacks detection have been explored, including machine learning. The main goal of previous studies was to achieve the highest possible accuracy in distinguishing normal from malicious IoT traffic, with minimal regard to the identification of the particular type of attack that is being launched. In this study, we present a machine learning based approach for detecting IoT botnet attacks that not only helps distinguish normal from malicious traffic, but also detects the type of the IoT botnet attack. To achieve this goal, the Bot-IoT dataset, in which instances have main attack and sub-attack categories, was utilized after performing the Synthetic Minority Over-sampling Technique (SMOTE), among other preprocessing techniques. Moreover, multiple classifiers were tested and the results from the best three, namely: J48, Random Forest (RF), and Multilayer Perceptron (MLP) networks were reported. The results showed the superiority of the RF and J48 classifiers compared to the MLP networks and other state-of-the-art solutions. The accuracy of the best binary classifier reported in this study reached 0.999, whereas the best accuracies of main attack and subcategories classifications reached 0.96 and 0.93, respectively. Only few studies address the classification errors in this domain, yet, it was assessed in this study in terms of False Negative (FN) rates. J48 and RF classifiers, here also, outperformed the MLP network classifier, and achieved a maximum micro FN rate for subcategories classification of 0.076.},
journal = {J. High Speed Netw.},
month = jan,
pages = {241–254},
numpages = {14},
keywords = {IoT botnets, Intrusion Detection, Bot-IoT dataset, SMOTE, machine learning, malicious IoT traffic}
}

@article{10.1007/s10664-019-09769-8,
author = {Ochodek, Miroslaw and Hebig, Regina and Meding, Wilhelm and Frost, Gert and Staron, Miroslaw},
title = {Recognizing lines of code violating company-specific coding guidelines using machine learning: A Method and Its Evaluation},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09769-8},
doi = {10.1007/s10664-019-09769-8},
abstract = {Software developers in big and medium-size companies are working with millions of lines of code in their codebases. Assuring the quality of this code has shifted from simple defect management to proactive assurance of internal code quality. Although static code analysis and code reviews have been at the forefront of research and practice in this area, code reviews are still an effort-intensive and interpretation-prone activity. The aim of this research is to support code reviews by automatically recognizing company-specific code guidelines violations in large-scale, industrial source code. In our action research project, we constructed a machine-learning-based tool for code analysis where software developers and architects in big and medium-sized companies can use a few examples of source code lines violating code/design guidelines (up to 700 lines of code) to train decision-tree classifiers to find similar violations in their codebases (up to 3 million lines of code). Our action research project consisted of (i) understanding the challenges of two large software development companies, (ii) applying the machine-learning-based tool to detect violations of Sun’s and Google’s coding conventions in the code of three large open source projects implemented in Java, (iii) evaluating the tool on evolving industrial codebase, and (iv) finding the best learning strategies to reduce the cost of training the classifiers. We were able to achieve the average accuracy of over 99% and the average F-score of 0.80 for open source projects when using ca. 40K lines for training the tool. We obtained a similar average F-score of 0.78 for the industrial code but this time using only up to 700 lines of code as a training dataset. Finally, we observed the tool performed visibly better for the rules requiring to understand a single line of code or the context of a few lines (often allowing to reach the F-score of 0.90 or higher). Based on these results, we could observe that this approach can provide modern software development companies with the ability to use examples to teach an algorithm to recognize violations of code/design guidelines and thus increase the number of reviews conducted before the product release. This, in turn, leads to the increased quality of the final software.},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {220–265},
numpages = {46},
keywords = {Measurement, Machine learning, Action research, Code reviews}
}

@inproceedings{10.1145/3428363.3428365,
author = {Barut, Onur and Grohotolski, Matthew and DiLeo, Connor and Luo, Yan and Li, Peilong and Zhang, Tong},
title = {Machine Learning Based Malware Detection on Encrypted Traffic: A Comprehensive Performance Study},
year = {2020},
isbn = {9781450389051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428363.3428365},
doi = {10.1145/3428363.3428365},
abstract = {The increasing volume of encrypted network traffic yields a clutter for hackers to use encryption to spread their malicious software on the network. We study the problem of detecting TLS-encrypted malware on the client side using metadata and TLS protocol related flow features. We conduct a comprehensive study on a set of widely used machine learning and deep learning algorithms to detect encrypted malware on two malware flows datasets. In addition to reporting the classification accuracy of the approaches under study, we conduct comprehensive experiments to quantify their run-time performance in terms of throughput and system resource utilization such as the CPU and RAM utilization. Moreover, we further boost the speed of the detection systems using acceleration libraries such as DAAL and OpenVINO. Through the quantitative analysis, we provide a comparison on the effectiveness and run-time performance of the machine learning models, and evaluate techniques to accelerate real-world deployment.},
booktitle = {Proceedings of the 7th International Conference on Networking, Systems and Security},
pages = {45–55},
numpages = {11},
keywords = {deep learning, encrypted traffic analysis, machine learning, malware detection},
location = {Dhaka, Bangladesh},
series = {NSysS '20}
}

@inproceedings{10.1145/3411764.3445306,
author = {Xin, Doris and Wu, Eva Yiwei and Lee, Doris Jung-Lin and Salehi, Niloufar and Parameswaran, Aditya},
title = {Whither AutoML? Understanding the Role of Automation in Machine Learning Workflows},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445306},
doi = {10.1145/3411764.3445306},
abstract = {Efforts to make machine learning more widely accessible have led to a rapid increase in Auto-ML tools that aim to automate the process of training and deploying machine learning. To understand how Auto-ML tools are used in practice today, we performed a qualitative study with participants ranging from novice hobbyists to industry researchers who use Auto-ML tools. We present insights into the benefits and deficiencies of existing tools, as well as the respective roles of the human and automation in ML workflows. Finally, we discuss design implications for the future of Auto-ML tool development. We argue that instead of full automation being the ultimate goal of Auto-ML, designers of these tools should focus on supporting a partnership between the user and the Auto-ML tool. This means that a range of Auto-ML tools will need to be developed to support varying user goals such as simplicity, reproducibility, and reliability.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {83},
numpages = {16},
location = {Yokohama, Japan},
series = {CHI '21}
}

@book{10.5555/3006371,
author = {Hearty, John},
title = {Advanced Machine Learning with Python},
year = {2016},
isbn = {1784398632},
publisher = {Packt Publishing},
abstract = {Solve challenging data science problems by mastering cutting-edge machine learning techniques in PythonAbout This BookResolve complex machine learning problems and explore deep learningLearn to use Python code for implementing a range of machine learning algorithms and techniquesA practical tutorial that tackles real-world computing problems through a rigorous and effective approachWho This Book Is ForThis title is for Python developers and analysts or data scientists who are looking to add to their existing skills by accessing some of the most powerful recent trends in data science. If youve ever considered building your own image or text-tagging solution, or of entering a Kaggle contest for instance, this book is for you!Prior experience of Python and grounding in some of the core concepts of machine learning would be helpful. What You Will LearnCompete with top data scientists by gaining a practical and theoretical understanding of cutting-edge deep learning algorithmsApply your new found skills to solve real problems, through clearly-explained code for every technique and testAutomate large sets of complex data and overcome time-consuming practical challengesImprove the accuracy of models and your existing input data using powerful feature engineering techniquesUse multiple learning techniques together to improve the consistency of resultsUnderstand the hidden structure of datasets using a range of unsupervised techniques Gain insight into how the experts solve challenging data problems with an effective, iterative, and validation-focused approach Improve the effectiveness of your deep learning models further by using powerful ensembling techniques to strap multiple models together In Detail Designed to take you on a guided tour of the most relevant and powerful machine learning techniques in use today by top data scientists, this book is just what you need to push your Python algorithms to maximum potential. Clear examples and detailed code samples demonstrate deep learning techniques, semi-supervised learning, and more - all whilst working with real-world applications that include image, music, text, and financial data. The machine learning techniques covered in this book are at the forefront of commercial practice. They are applicable now for the first time in contexts such as image recognition, NLP and web search, computational creativity, and commercial/financial data modeling. Deep Learning algorithms and ensembles of models are in use by data scientists at top tech and digital companies, but the skills needed to apply them successfully, while in high demand, are still scarce. This book is designed to take the reader on a guided tour of the most relevant and powerful machine learning techniques. Clear descriptions of how techniques work and detailed code examples demonstrate deep learning techniques, semi-supervised learning and more, in real world applications. We will also learn about NumPy and Theano. By this end of this book, you will learn a set of advanced Machine Learning techniques and acquire a broad set of powerful skills in the area of feature selection &amp; feature engineering. Style and approach This book focuses on clarifying the theory and code behind complex algorithms to make them practical, useable, and well-understood. Each topic is described with real-world applications, providing both broad contextual coverage and detailed guidance.}
}

@article{10.1007/s42979-021-00617-5,
author = {Assegie, Tsehay Admassu and Sushma, S. J. and Bhavya, B. G. and Padmashree, S.},
title = {Correlation Analysis for Determining Effective Data in Machine Learning: Detection of Heart Failure},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00617-5},
doi = {10.1007/s42979-021-00617-5},
abstract = {Heart disease is one of the causes for death throughout the world. Heart disease cannot be easily identified by the medical experts and practitioners as the detection of heart disease requires expertise and experience. Hence, developing better performing models for heart disease detection using machine-learning algorithms is crucial for detecting heart disease in an early stage. However, employing machine learning algorithm involves determining the relationship between the heart failure dataset features. In this study, correlation analysis is employed to identify the relationship among the heart failure dataset features and a predictive model for heart failure detection is developed with K-nearest neighbor (KNN). Pearson correlation is employed to identify the relationship between the features in the heart failure dataset and the effect of strong correlation to the target feature on the performance of K-nearest neighbor (KNN) model is analyzed. The experimental result shows that highly correlated feature significantly affected the performance of K-nearest neighbor (KNN) for heart failure detection. Finally, the performance of KNN is evaluated and result reveals that the model has acceptable level of performance with highest accuracy of 97.07% on heart failure prediction.},
journal = {SN Comput. Sci.},
month = apr,
numpages = {5},
keywords = {Correlation analysis, KNN, Heart failure, Heart failure detection, Machine learning}
}

@article{10.1145/3319616,
author = {Wu, Tongshuang and Weld, Daniel S. and Heer, Jeffrey},
title = {Local Decision Pitfalls in Interactive Machine Learning: An Investigation into Feature Selection in Sentiment Analysis},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {1073-0516},
url = {https://doi.org/10.1145/3319616},
doi = {10.1145/3319616},
abstract = {Tools for Interactive Machine Learning (IML) enable end users to update models in a “rapid, focused, and incremental”—yet local—manner. In this work, we study the question of local decision making in an IML context around feature selection for a sentiment classification task. Specifically, we characterize the utility of interactive feature selection through a combination of human-subjects experiments and computational simulations. We find that, in expectation, interactive modification fails to improve model performance and may hamper generalization due to overfitting. We examine how these trends are affected by the dataset, learning algorithm, and the training set size. Across these factors we observe consistent generalization issues. Our results suggest that rapid iterations with IML systems can be dangerous if they encourage local actions divorced from global context, degrading overall model performance. We conclude by discussing the implications of our feature selection results to the broader area of IML systems and research.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = jun,
articleno = {24},
numpages = {27},
keywords = {Machine learning, performance analysis, text classification}
}

@inproceedings{10.1145/3461702.3462572,
author = {Lee, Michelle Seng Ah and Singh, Jatinder},
title = {Risk Identification Questionnaire for Detecting Unintended Bias in the Machine Learning Development Lifecycle},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462572},
doi = {10.1145/3461702.3462572},
abstract = {Unintended biases in machine learning (ML) models have the potential to introduce undue discrimination and exacerbate social inequalities. The research community has proposed various technical and qualitative methods intended to assist practitioners in assessing these biases. While frameworks for identifying the risks of harm due to unintended biases have been proposed, they have not yet been operationalised into practical tools to assist industry practitioners.In this paper, we link prior work on bias assessment methods to phases of a standard organisational risk management process (RMP), noting a gap in measures for helping practitioners identify bias- related risks. Targeting this gap, we introduce a bias identification methodology and questionnaire, illustrating its application through a real-world, practitioner-led use case. We validate the need and usefulness of the questionnaire through a survey of industry practitioners, which provides insights into their practical requirements and preferences. Our results indicate that such a questionnaire is helpful for proactively uncovering unexpected bias concerns, particularly where it is easy to integrate into existing processes, and facilitates communication with non-technical stakeholders. Ultimately, the effective end-to-end management of ML risks requires a more targeted identification of potential harm and its sources, so that appropriate mitigation strategies can be formulated. Towards this, our questionnaire provides a practical means to assist practitioners in identifying bias-related risks.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {704–714},
numpages = {11},
keywords = {algorithmic bias, algorithmic fairness, fair ML, questionnaire, risk identification, risk management},
location = {Virtual Event, USA},
series = {AIES '21}
}

@inproceedings{10.1145/3026724.3026730,
author = {Kumar, Sumit},
title = {Analyzing efficiency of Pseudo-Random Number Generators using Machine Learning},
year = {2016},
isbn = {9781450347969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3026724.3026730},
doi = {10.1145/3026724.3026730},
abstract = {Random numbers are very important components in cyber security. A main application of random numbers is in the field of cryptography. PKI and TLS based encryption uses random numbers extensively. Other areas include session IDs of web applications, passwords and game of chance. A number of cyber security attacks have happened in the past because of using weak random number generators.Machine learning has been extensively used in pattern identification in a number of areas, including credit card frauds, genomics and face identification. It utilizes a set of algorithms to detect patterns from in a data to perform tasks like classification, clustering and prediction.In this paper, a fast method to test the randomness of a sequence generated by pseudo-random number generator is proposed which tries to take advantages of the pattern identification of machine learning.},
booktitle = {Proceedings of the 4th International Conference on Information and Network Security},
pages = {66–72},
numpages = {7},
keywords = {Feature Engineering, K Nearest Neighbor and Information Security, Machine Learning, Pseudo-Random Number Generator, Random Forest Classifier, Supervised Learning},
location = {Kuala Lumpur, Malaysia},
series = {ICINS '16}
}

@inproceedings{10.1145/2019136.2019150,
author = {Serajzadeh, Hadi and Shams, Fereidoon},
title = {The application of swarm intelligence in service-oriented product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019150},
doi = {10.1145/2019136.2019150},
abstract = {Changing markets and environments has made the ability to rapidly adapt to these changes a necessity in software systems. However the costs of changing and adapting systems to new requirements still remains an unsolved issue. In this context service-oriented software product lines were introduced with the aim to combine the reusability of software product line with the flexibility of service-oriented architecture. Although this approach helps build flexible software systems with high levels of reuse, certain issues are raised. The main issue is the complexity that a service-oriented product line will face. Developing systems from internal and external assets, taking into consideration the variety and number of these assets, can cause problems in deciding which asset is best suited for the system. To help solve these issues we propose the use of approaches based on artificial intelligence. In this paper we show how swarm intelligence can be used in service-oriented product lines to reduce complexity and find optimal solutions for the development of software systems. We also present an example of the application of swarm intelligence in finding the optimal product for a service-oriented product line.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {12},
numpages = {7},
keywords = {optimization, service-oriented product line, swarm intelligence},
location = {Munich, Germany},
series = {SPLC '11}
}

@article{10.1155/2020/6689134,
author = {Derhab, Abdelouahid and Aldweesh, Arwa and Emam, Ahmed Z. and Khan, Farrukh Aslam and Wang, Xiaojie},
title = {Intrusion Detection System for Internet of Things Based on Temporal Convolution Neural Network and Efficient Feature Engineering},
year = {2020},
issue_date = {2020},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2020},
issn = {1530-8669},
url = {https://doi.org/10.1155/2020/6689134},
doi = {10.1155/2020/6689134},
abstract = {In the era of the Internet of Things (IoT), connected objects produce an enormous amount of data traffic that feed big data analytics, which could be used in discovering unseen patterns and identifying anomalous traffic. In this paper, we identify five key design principles that should be considered when developing a deep learning-based intrusion detection system (IDS) for the IoT. Based on these principles, we design and implement Temporal Convolution Neural Network (TCNN), a deep learning framework for intrusion detection systems in IoT, which combines Convolution Neural Network (CNN) with causal convolution. TCNN is combined with Synthetic Minority Oversampling Technique-Nominal Continuous (SMOTE-NC) to handle unbalanced dataset. It is also combined with efficient feature engineering techniques, which consist of feature space reduction and feature transformation. TCNN is evaluated on Bot-IoT dataset and compared with two common machine learning algorithms, i.e., Logistic Regression (LR) and Random Forest (RF), and two deep learning techniques, i.e., LSTM and CNN. Experimental results show that TCNN achieves a good trade-off between effectiveness and efficiency. It outperforms the state-of-the-art deep learning IDSs that are tested on Bot-IoT dataset and records an accuracy of 99.9986% for multiclass traffic detection, and shows a very close performance to CNN with respect to the training time.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {16}
}

@phdthesis{10.5555/AAI28022522,
author = {Islam, Md Johirul and Ciardo, Gianfranco and Prabhu, Gurpur and Tian, Jin and Sharma, Anuj},
advisor = {Hridesh, Rajan,},
title = {Towards Understanding the Challenges Faced by Machine Learning Software Developers and Enabling Automated Solutions},
year = {2020},
isbn = {9798672106496},
publisher = {Iowa State University},
address = {USA},
abstract = {Modern software systems are increasingly including machine learning (ML) as an integral component. However, we do not yet understand the difficulties faced by software developers when learning about ML libraries and using them within their systems. To fill that gap this thesis reports on a detailed (manual) examination of 3,243 highly-rated Q&amp;A posts related to ten ML libraries, namely Tensorflow, Keras, scikitlearn, Weka, Caffe, Theano, MLlib, Torch, Mahout, and H2O, on Stack Overflow, a popular online technical Q&amp;A forum. Our findings reveal the urgent need for software engineering (SE) research in this area.The second part of the thesis particularly focuses on understanding the Deep Neural Network (DNN) bug characteristics. We study 2,716 high-quality posts from Stack Overflow and 500 bug fix commits from Github about five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand the types of bugs, their root causes and impacts, bug-prone stage of deep learning pipeline as well as whether there are some common antipatterns found in this buggy software.While exploring the bug characteristics, our findings imply that repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs. So, the third part of this thesis presents a comprehensive study of bug fix patterns to address these questions. We have studied 415 repairs from Stack Overflow and 555 repairs from Github for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns. Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns and the most common bug fix patterns are fixing data dimension and neural network connectivity.Finally, we propose an automatic technique to detect ML Application Programming Interface (API) misuses. We started with an empirical study to understand ML API misuses. Our study shows that ML API misuse is prevalent and distinct compared to non-ML API misuses. Inspired by these findings, we contributed Amimla (Api Misuse In Machine Learning Apis) an approach and a tool for ML API misuse detection. Amimla relies on several technical innovations. First, we proposed an abstract representation of ML pipelines to use in misuse detection. Second, we proposed an abstract representation of neural networks for deep learning related APIs. Third, we have developed a representation strategy for constraints on ML APIs. Finally, we have developed a misuse detection strategy for both single and multi-APIs. Our experimental evaluation shows that Amimla achieves a high average accuracy of ∼80% on two benchmarks of misuses from Stack Overflow and Github.},
note = {AAI28022522}
}

@inproceedings{10.1145/3267809.3267812,
author = {Wang, Hao and Niu, Di and Li, Baochun},
title = {Dynamic and Decentralized Global Analytics via Machine Learning},
year = {2018},
isbn = {9781450360111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267809.3267812},
doi = {10.1145/3267809.3267812},
abstract = {Operating at a large scale, data analytics has become an essential tool for gaining insights from operational data, such as user online activities. With the volume of data growing exponentially, data analytic jobs have expanded from a single datacenter to multiple geographically distributed datacenters. Unfortunately, designed originally for a single datacenter, the software stack that supports data analytics is oblivious to on-the-fly resource variations on inter-datacenter networks, which negatively affects the performance of analytic queries. Existing solutions that optimize query execution plans before their execution are not able to quickly adapt to resource variations at query runtime.In this paper, we present Turbo, a lightweight and non-intrusive data-driven system that dynamically adjusts query execution plans for geo-distributed analytics in response to runtime resource variations across datacenters. A highlight of Turbo is its ability to use machine learning at runtime to accurately estimate the time cost of query execution plans, so that adjustments can be made when necessary. Turbo is non-intrusive in the sense that it does not require modifications to the existing software stack for data analytics. We have implemented a real-world prototype of Turbo, and evaluated it on a cluster of 33 instances across 8 regions in the Google Cloud platform. Our experimental results have shown that Turbo can achieve a cost estimation accuracy of over 95% and reduce query completion times by 41%.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {14–25},
numpages = {12},
keywords = {Data Analytics, Distributed Systems, Machine Learning},
location = {Carlsbad, CA, USA},
series = {SoCC '18}
}

@inproceedings{10.1145/3377929.3389886,
author = {Picek, Stjepan and Jakobovic, Domagoj},
title = {Evolutionary computation and machine learning in cryptology},
year = {2020},
isbn = {9781450371278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377929.3389886},
doi = {10.1145/3377929.3389886},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
pages = {1147–1173},
numpages = {27},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inbook{10.5555/1985668.1985675,
author = {Metzger, Andreas and Benbernou, Salima and Carro, Manuel and Driss, Maha and Kecskemeti, Gabor and Kazhamiakin, Raman and Krytikos, Kyriakos and Mocci, Andrea and Di Nitto, Elisabetta and Wetzstein, Branimir and Silvestri, Fabrizio},
title = {Analytical quality assurance},
year = {2010},
isbn = {3642175988},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Service Research Challenges and Solutions for the Future Internet: S-Cube - towards Engineering, Managing and Adapting Service-Based Systems},
pages = {209–270},
numpages = {62}
}

@inproceedings{10.1145/2019136.2019177,
author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
title = {Knowledge evolution in autonomic software product lines},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019177},
doi = {10.1145/2019136.2019177},
abstract = {We describe ongoing work in knowledge evolution management for autonomic software product lines. We explore how an autonomic product line may benefit from new knowledge originating from different source activities and artifacts at run time. The motivation for sharing run-time knowledge is that products may self-optimize at run time and thus improve quality faster compared to traditional software product line evolution. We propose two mechanisms that support knowledge evolution in product lines: online learning and knowledge sharing. We describe two basic scenarios for runtime knowledge evolution that involves these mechanisms. We evaluate online learning and knowledge sharing in a small product line setting that shows promising results.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {36},
numpages = {8},
keywords = {knowledge sharing, online learning, product-line management, self-adaptation, software design, software product-lines},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3109729.3109734,
author = {Marc\'{e}n, Ana C. and Font, Jaime and Pastor, \'{O}scar and Cetina, Carlos},
title = {Towards Feature Location in Models through a Learning to Rank Approach},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109734},
doi = {10.1145/3109729.3109734},
abstract = {In this work, we propose a feature location approach to discover software artifacts that implement the feature functionality in a model. Given a model and a feature description, model fragments extracted from the model and the feature description are encoded based on a domain ontology. Then, a Learning to Rank algorithm is used to train a classifier that is based on the model fragments and feature description encoded. Finally, the classifier assesses the similarity between a population of model fragments and the target feature being located to find the set of most suitable feature realizations. We have evaluated the approach with an industrial case study, locating features with mean precision and recall values of around 73.75% and 73.31%, respectively (the sanity check obtains less than 35%).},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {57–64},
numpages = {8},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3035918.3054775,
author = {Kumar, Arun and Boehm, Matthias and Yang, Jun},
title = {Data Management in Machine Learning: Challenges, Techniques, and Systems},
year = {2017},
isbn = {9781450341974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3035918.3054775},
doi = {10.1145/3035918.3054775},
abstract = {Large-scale data analytics using statistical machine learning (ML), popularly called advanced analytics, underpins many modern data-driven applications. The data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics. This tutorial provides a comprehensive review of such systems and analyzes key data management challenges and techniques. We focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks. Finally, we identify key open data management challenges for future research in this important area.},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
pages = {1717–1722},
numpages = {6},
keywords = {data management, machine learning},
location = {Chicago, Illinois, USA},
series = {SIGMOD '17}
}

@article{10.1007/s10586-021-03472-4,
author = {Mansour, Romany F. and Abdel-Khalek, S. and Hilali-Jaghdam, In\`{e}s and Nebhen, Jamel and Cho, Woong and Joshi, Gyanendra Prasad},
title = {An intelligent outlier detection with machine learning empowered big data analytics for mobile edge computing},
year = {2021},
issue_date = {Feb 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03472-4},
doi = {10.1007/s10586-021-03472-4},
abstract = {In recent times, the Internet of Things and big data analytics have become a hot research topic in mobile edge computing (MEC) desires wide-ranging research works for intelligent decision making. In this view, this paper designs an intelligent outlier detection with machine learning empowered big data analytics (IODML-BDA) for MEC. The proposed model involves an adaptive synthetic sampling-based outlier detection technique to eradicate the existence of outliers. Besides, the oppositional swallow swarm optimization (OSSO) based feature selection technique is used to choose an effective set of features. Finally, long short-term memory based classification model is employed to identify different class labels. The design of OSSO algorithm for feature selection with ADASYN technique for big data analytics show the novelty of the work. A comprehensive experimental analysis is carried out on GPS trajectories, movement prediction, water treatment plant, hepatitis, and Twitter datasets to confirm the experimental results. The experimentation outcomes pointed out that the proposed IODML-BDA model achieves the higher accuracy of 0.9735, 0.9816, 0.9798, 0.9896, and 0.9912 on the applied datasets.},
journal = {Cluster Computing},
month = nov,
pages = {71–83},
numpages = {13},
keywords = {Mobile edge computing, Big data analytics, Outlier detection, Machine learning, Outlier detection, Internet of Things}
}

@inproceedings{10.1145/2019136.2019162,
author = {Quinton, Cl\'{e}ment and Mosser, S\'{e}bastien and Parra, Carlos and Duchien, Laurence},
title = {Using multiple feature models to design applications for mobile phones},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019162},
doi = {10.1145/2019136.2019162},
abstract = {The design of a mobile phone application is a tedious task according to its intrinsic variability. Software designers must take into account in their development process the versatility of available platforms (e.g., Android, iPhone). In addition to this, the variety of existing devices and their divergences (e.g., frontal camera, GPS) introduce another layer of complexity in the development process. These two dimensions can be formalized as Software Product Lines (SPL), independently defined. In this paper, we use a dedicated metamodel to bridge the gap between an application SPL and a mobile device one. This meta-model is also the support for the product derivation process. The approach is implemented in a framework named Applide, and is used to successfully derive customer relationship management software on different devices.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {23},
numpages = {8},
keywords = {application for mobile phones, feature model, meta-model, smartphones, software product line},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1145/3128572.3140445,
author = {Kumar, Ram Shankar Siva and Wicker, Andrew and Swann, Matt},
title = {Practical Machine Learning for Cloud Intrusion Detection: Challenges and the Way Forward},
year = {2017},
isbn = {9781450352024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3128572.3140445},
doi = {10.1145/3128572.3140445},
abstract = {Operationalizing machine learning based security detections is extremely challenging, especially in a continuously evolving cloud environment. Conventional anomaly detection does not produce satisfactory results for analysts that are investigating security incidents in the cloud. Model evaluation alone presents its own set of problems due to a lack of benchmark datasets. When deploying these detections, we must deal with model compliance, localization, and data silo issues, among many others. We pose the problem of "attack disruption" as a way forward in the security data science space. In this paper, we describe the framework, challenges, and open questions surrounding the successful operationalization of machine learning based security detections in a cloud environment and provide some insights on how we have addressed them.},
booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
pages = {81–90},
numpages = {10},
keywords = {cloud, intrusion detection system, machine learning, security},
location = {Dallas, Texas, USA},
series = {AISec '17}
}

@phdthesis{10.5555/AAI28088573,
author = {Zhang, Yang and Kruggel, Frithjof and Digman, Michelle and Chow, Daniel},
advisor = {Min-Ying, Su, and Gultekin, Gulsen,},
title = {Machine Learning in Clinical Application of Medical Imaging for Lesion Detection, Segmentation, Diagnosis, Therapy, and Prognosis Prediction},
year = {2020},
isbn = {9798557020725},
publisher = {University of California, Irvine},
abstract = {Medical imaging, including computed tomography (CT), magnetic resonance imaging (MRI), mammography, ultrasound, X-ray, and nuclear medicine, is the non-invasive process utilized to create visual representations of interior organs and tissues. Medical imaging's clinical purpose is to observe health, aid in diagnosis, monitor treatment response, and perform follow-up for disease surveillance. Clinically, interpreting medical images has mostly been performed by human experts such as radiologists or physicians. However, given the wide variety in pathological conditions and the potential fatigue that can result from visual assessment of numerous images, computer-aided diagnosis or detection (CAD) algorithms have been developed and proven to be very helpful. These CAD systems can also provide various functions, such as giving quantitative measurements, extracting radiomics features, and displaying the most important information to assist radiologists' interpretation. Furthermore, it can even detect suspicious findings and present the malignancy probability using various methods, such as different markers and colors.The maturity of radiomics analysis with machine learning has provided a very efficient method to build classification models for clinical tasks, including diagnosis, staging, and prognosis prediction. In recent years, neural network methods, a machine learning technique inspired by the human neuronal synapse system, have been widely applied in medical imaging for disease management. The increased volume and quality of digital imaging datasets has created the potential for more accurate and efficient image evaluation using fully automated computer algorithms. However, compared with other machine learning methods such as radiomics, neural networks suffer from several major limitations, including the need for a large dataset to train the deep architecture, the high demand for computing power, and the poor generalization to other datasets not considered in training.However, during the last 5 years, neural networks have become increasingly popular and have even proven feasible for implementation in clinical practice with the growing availability of big data, enhanced computing power, and novel algorithms. There are many Artificial Intelligence (AI) companies working in this field, and new software being rapidly approved by FDA for clinical use. Deep Learning (DL) algorithms, particularly the convolutional neural networks (CNN), have become the methodology of choice for analyzing medical images. Unlike conventional CAD algorithms, such as radiomics analysis in which task-related features are designed mostly by human experts based on their knowledge about the target domains, deep learning incorporates the feature engineering steps into its learning process. That is, instead of extracting pre-defined features, deep learning only requires pre-processed input data and outcome, discovering its own characteristic information in a self-taught manner. Therefore, the burden of feature engineering has shifted from humans to computers to generate more consistent and reliable outputs.This thesis will feature radiomics and deep learning-based techniques developed and implemented to extract information from medical images for performing commonly needed clinical tasks, including: lesion detection, organ/tissue segmentation, tumor classification, therapy planning, therapy response prediction, and prognosis prediction.},
note = {AAI28088573}
}

@inproceedings{10.1145/3106195.3106206,
author = {Arcaini, Paolo and Gargantini, Angelo and Vavassori, Paolo},
title = {Automated Repairing of Variability Models},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106206},
doi = {10.1145/3106195.3106206},
abstract = {Variability models are a common means for describing the commonalities and differences in Software Product Lines (SPL); configurations of the SPL that respect the constraints imposed by the variability model define the problem space. The same variability is usually also captured in the final implementation through implementation constraints, defined in terms of preprocessor directives, build files, build-time errors, etc. Configurations satisfying the implementation constraints and producing correct (compilable) programs define the solution space. Since sometimes the variability model is defined after the implementation exists, it could wrongly assess the validity of some system configurations, i.e., it could consider acceptable some configurations (not belonging to the solution space) that do not permit to obtain a correct program. We here propose an approach that automatically repairs variability models such that the configurations they consider valid are also part of the solution space. Experiments show that some existing variability models are indeed faulty and can be repaired by our approach.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {9–18},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1561/0300000099,
author = {Ferrati, Francesco and Muffatto, Moreno},
title = {Entrepreneurial Finance: Emerging Approaches Using Machine Learning and Big Data},
year = {2021},
issue_date = {Apr 2021},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {17},
number = {3},
issn = {1551-3114},
url = {https://doi.org/10.1561/0300000099},
doi = {10.1561/0300000099},
abstract = {For equity investors the identification of ventures that most likely will achieve the expected return on investment is an extremely complex task. To select early-stage companies, venture capitalists and business angels traditionally rely on a mix of assessment criteria and their own experience. However, given the high level of risk with new, innovative companies, the number of financially successful startups within an investment portfolio is generally very low. In this context of uncertainty, a data-driven approach to investment decision-making can provide more effective results. Specifically, the application of machine learning techniques can provide equity investors and scholars in entrepreneurial finance with new insights on patterns common to successful startups.This study presents a comprehensive overview of the applications of machine learning algorithms to the Crunchbase database. We highlight the main research goals that can be addressed and then we review all the variables and algorithms used for each goal. For each machine learning algorithm, we analyze the respective performance metrics to identify a baseline model. This study aims to be a reference for researchers and practitioners on the use of machine learning as an effective tool to support decision-making processes in equity investments.},
journal = {Found. Trends Entrepreneurship},
month = apr,
pages = {232–329},
numpages = {97}
}

@inproceedings{10.1145/3473714.3473794,
author = {Chen, Ziqi and Tao, Zhuoang and Chang, Aiwei},
title = {A data-driven approach to optimize building energy performance and thermal comfort using machine learning models},
year = {2021},
isbn = {9781450390231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3473714.3473794},
doi = {10.1145/3473714.3473794},
abstract = {Buildings account for 30% of the world's total energy consumption, and heating, ventilation and air conditioning systems account for more than 70% of the world's total energy consumption. People pay more and more attention to the energy efficiency improvement of building energy saving system, especially HVAC system. Open-plan office is one of the most popular office types in recent decades, which can not only improve communication efficiency, but also save considerable construction costs. But it can't satisfy everyone's comfort requirements, especially indoor air temperature and relative humidity. In this paper, a data-driven thermal comfort model is established based on ASHRAE Global Thermal Comfort Database II. Two machine learning algorithms for building thermal comfort models are studied: support vector machine (SVM) and random forest. The model optimizes energy consumption while ensuring thermal comfort of commercial buildings. Under the thermal comfort condition, the purpose of energy saving is achieved by controlling the indoor temperature setting value. We also set up a co-simulation model of building energy consumption, compared the benchmark control strategy with the optimal control strategy by using the data-driven thermal comfort model, and analyzed the economic benefits of the enterprise by using the whole-life cycle cost analysis method. The results have shown the optimized control strategy outperforms the baseline owing to better thermal comfort prediction performances with machine learning. Therefore, this paper contributes to intelligent human building interaction areas with artificial intelligence.},
booktitle = {Proceedings of the 2021 1st International Conference on Control and Intelligent Robotics},
pages = {464–469},
numpages = {6},
keywords = {data-driven, energy saving system, thermal comfort model},
location = {Guangzhou, China},
series = {ICCIR '21}
}

@inproceedings{10.1007/978-3-030-37494-5_10,
author = {van de Ven, Arno and Zhang, Yingqian and Lee, Wan-Jui},
title = {Boosting Local Search Using Machine Learning: A Study on Improving Local Search by Graph Classification in Determining Capacity of Shunting Yards},
year = {2019},
isbn = {978-3-030-37493-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37494-5_10},
doi = {10.1007/978-3-030-37494-5_10},
abstract = {Determining the maximum capacities of shunting yards is an important problem at Dutch Railways (NS). Solving this capacity determination problem is computational expensive as it requires to solve an NP-hard shunting planning problem. Currently, NS uses a shunt plan simulator where a local search heuristic is implemented to determine such capacities.In this paper, we study how to combine machine learning with local search in order to speed up finding shunting plans in the capacity determination problem. We investigate this in the following two ways. In the first approach, we propose to use the Deep Graph Convolutional Neural Network (DGCNN) to predict whether local search will find a feasible shunt plan given an initial solution. Using instances generated from the simulator, we build a classification model and show our approach can significantly reduce the simulation time in determining the capacity of a given shunting yard.In the second approach, we investigate whether we can use machine learning to help local search decide which promising areas to explore during search. Therefore, DGCNN is applied to predict the order of search operators in which the local search heuristic should evaluate. We show that accurately predicting the evaluation order could find improved solutions faster, and may lead to more consistent plans.},
booktitle = {Agents and Artificial Intelligence: 11th International Conference, ICAART 2019, Prague, Czech Republic, February 19–21, 2019, Revised Selected Papers},
pages = {183–203},
numpages = {21},
keywords = {Planning and scheduling, Machine learning - Convolutional neural networks, Classification, Local search},
location = {Prague, Czech Republic}
}

@article{10.1155/2021/4116497,
author = {Ran, JingFei and Ali, Sikandar},
title = {Intelligent Method of Supply Chain Circulation Industry Structure Based on Machine Learning},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/4116497},
doi = {10.1155/2021/4116497},
abstract = {In the deepening of supply chain competition, whether the structure of supply chain industry is reasonable and scientific has been severely tested. For warehousing, purchase and distribution channels, and customers, it largely determines whether the structure of supply chain is stable and efficient. The rationality of structure can determine the value of supply chain. By analyzing these four levels, this paper judges whether the supply chain structure is reasonable; the judgment standard is based on the three popular machine learning models, Stochastic Forest, XGBoost, and Support Vector Machine. The three models are based on a large number of real data environments. Through data simulation and parameter optimization, four supply chain characteristics are put into the model for simulation training for many times, and the three error numbers of MAE, RMSE, and MAPE of the model are analyzed to judge the reliability of the model. On this basis, through the combination of models, it is determined that the average percentage error of the combination of the three models is higher than that of the other pairwise combinations, reaching 0.937, which completes the expectation of intelligent prediction of supply chain structure.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {10}
}

@inproceedings{10.1145/3336294.3336297,
author = {Munoz, Daniel-Jesus and Oh, Jeho and Pinto, M\'{o}nica and Fuentes, Lidia and Batory, Don},
title = {Uniform Random Sampling Product Configurations of Feature Models That Have Numerical Features},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336297},
doi = {10.1145/3336294.3336297},
abstract = {Analyses of Software Product Lines (SPLs) rely on automated solvers to navigate complex dependencies among features and find legal configurations. Often these analyses do not support numerical features with constraints because propositional formulas use only Boolean variables. Some automated solvers can represent numerical features natively, but are limited in their ability to count and Uniform Random Sample (URS) configurations, which are key operations to derive unbiased statistics on configuration spaces.Bit-blasting is a technique to encode numerical constraints as propositional formulas. We use bit-blasting to encode Boolean and numerical constraints so that we can exploit existing #SAT solvers to count and URS configurations. Compared to state-of-art Satisfiability Modulo Theory and Constraint Programming solvers, our approach has two advantages: 1) faster and more scalable configuration counting and 2) reliable URS of SPL configurations. We also show that our work can be used to extend prior SAT-based SPL analyses to support numerical features and constraints.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {289–301},
numpages = {13},
keywords = {bit-blasting, feature model, model counting, numerical features, propositional formula, software product lines},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.5555/3524938.3525578,
author = {Milacski, Zolt\'{a}n \'{A}. and P\'{o}czos, Barnab\'{a}s and L\H{o}rincz, Andr\'{a}s},
title = {VideoOneNet: bidirectional convolutional recurrent onenet with trainable data steps for video processing},
year = {2020},
publisher = {JMLR.org},
abstract = {Deep Neural Networks (DNNs) achieve the state-of-the-art results on a wide range of image processing tasks, however, the majority of such solutions are problem-specific, like most AI algorithms. The One Network to Solve Them All ('OneNet') procedure has been suggested to resolve this issue by exploiting a DNN as the proximal operator in Alternating Direction Method of Multipliers (ADMM) solvers for various imaging problems. In this work, we make two contributions, both facilitating end-to-end learning using backpropagation. First, we generalize OneNet to videos by augmenting its convolutional prior network with bidirectional recurrent connections; second, we extend the fixed fully connected linear ADMM data step with another trainable bidirectional convolutional recurrent network. In our computational experiments on the Rotated MNIST, Scanned CIFAR-10 and UCF-101 data sets, the proposed modifications improve performance by a large margin compared to end-to-end convolutional OneNet and 3D Wavelet sparsity on several video processing problems: pixelwise inpainting-denoising, blockwise inpainting, scattered inpainting, super resolution, compressive sensing, deblurring, frame interpolation, frame prediction and colorization. Our two contributions are complementary, and using them together yields the best results.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {640},
numpages = {12},
series = {ICML'20}
}

@article{10.1109/TCBB.2021.3139048,
author = {Wu, Tzu-Hsuan and Lin, Peng-Chan and Chou, Hsin-Hung and Shen, Meng-Ru and Hsieh, Sun-Yuan},
title = {Pathogenicity Prediction of Single Amino Acid Variants With Machine Learning Model Based on Protein Structural Energies},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3139048},
doi = {10.1109/TCBB.2021.3139048},
abstract = {The most popular tools for predicting pathogenicity of single amino acid variants (SAVs) were developed based on sequence-based techniques. SAVs may change protein structure and function. In the context of van der Waals force and disulfide bridge calculations, no method directly predicts the impact of mutations on the energies of the protein structure. Here, we combined machine learning methods and energy scores of protein structures calculated by Rosetta Energy Function 2015 to predict SAV pathogenicity. The accuracy level of our model (0.76) is higher than that of six prediction tools. Further analyses revealed that the differential reference energies, attractive energies, and solvation of polar atoms between wildtype and mutant side-chains played essential roles in distinguishing benign from pathogenic variants. These features indicated the physicochemical properties of amino acids, which were observed in 3D structures instead of sequences. We added 16 features to Rhapsody (the prediction tool we used for our data set) and consequently improved its performance. The results indicated that these energy scores were more appropriate and more detailed representations of the pathogenicity of SAVs.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = dec,
pages = {606–615},
numpages = {10}
}

@article{10.14778/3229863.3229876,
author = {Dong, Xin Luna and Rekatsinas, Theodoros},
title = {Data integration and machine learning: a natural synergy},
year = {2018},
issue_date = {August 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3229863.3229876},
doi = {10.14778/3229863.3229876},
abstract = {As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {2094–2097},
numpages = {4}
}

@inproceedings{10.1145/3411508.3421378,
author = {Solano, Jes\'{u}s and Lopez, Christian and Rivera, Esteban and Castelblanco, Alejandra and Tengana, Lizzy and Ochoa, Martin},
title = {SCRAP: Synthetically Composed Replay Attacks vs. Adversarial Machine Learning Attacks against Mouse-based Biometric Authentication},
year = {2020},
isbn = {9781450380942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411508.3421378},
doi = {10.1145/3411508.3421378},
abstract = {Adversarial attacks have gained popularity recently due to their simplicity and impact. Their applicability to diverse security scenarios is however less understood. In particular, in some scenarios, attackers may come up naturally with ad-hoc black-box attack techniques inspired directly on characteristics of the problem space rather than using generic adversarial techniques. In this paper we explore an intuitive attack technique for Mouse-based Behavioral Biometrics and compare its effectiveness against adversarial machine learning attacks. We show that attacks leveraging on domain knowledge have higher transferability when applied to various machine-learning techniques and are also more difficult to defend against. We also propose countermeasures against such attacks and discuss their effectiveness.},
booktitle = {Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security},
pages = {37–47},
numpages = {11},
keywords = {adversarial machine learning, behavioral biometrics, machine learning, mouse-based authentication, static authentication},
location = {Virtual Event, USA},
series = {AISec'20}
}

@article{10.1007/s00138-018-0971-6,
author = {Xu, Yuanping and Lu, Li and Xu, Zhijie and He, Jia and Zhou, Jiliu and Zhang, Chaolong},
title = {Dual-channel CNN for efficient abnormal behavior identification through crowd feature engineering},
year = {2019},
issue_date = {July      2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {5},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-018-0971-6},
doi = {10.1007/s00138-018-0971-6},
abstract = {This research has been investigating an automatic and online crowd anomaly detection model by exploring a novel compound image descriptor generated from live video streams. A dual-channel convolutional neural network (DCCNN) has been set up for efficiently processing scene-related and motion-related crowd information inherited from raw frames and the compound descriptor instances. The novelty of the work stemmed from the creation of the spatio-temporal cuboids in online (or near real-time) manner through dynamically extracting local feature tracklets within the temporal space while handling the foreground region-of-interests (i.e., moving targets) through the exploration of Gaussian Mixture Model in the spatial space. Hence, the extracted foreground blocks can effectively eliminate irrelevant backgrounds and noises from the live streams for reducing the computational costs in the subsequent detecting phases. The devised compound feature descriptor, named as spatio-temporal feature descriptor (STFD), is capable of characterizing the crowd attributes through the measures such as collectiveness, stability, conflict and density in each online generated spatio-temporal cuboid. A STFD instance registers not only the dynamic variation of the targeted crowd over time based on local feature tracklets, but also the interaction information of neighborhoods within a crowd, e.g., the interaction force through the K-nearest neighbor (K-NN) analysis. The DCCNN developed in this research enables online identification of suspicious crowd behaviors based on analyzing the live-feed images and their STFD instances. The proposed model has been developed and evaluated against benchmarking techniques and databases. Experimental results have shown substantial improvements in terms of detection accuracy and efficiency for online crowd abnormal behavior identification.},
journal = {Mach. Vision Appl.},
month = jul,
pages = {945–958},
numpages = {14},
keywords = {Crowd abnormal behaviors, Crowd feature engineering, Dual-channel convolutional neural network, Gaussian Mixture Model, Spatio-temporal feature descriptor}
}

@article{10.1016/j.ijinfomgt.2019.05.020,
author = {Min, Qingfei and Lu, Yangguang and Liu, Zhiyong and Su, Chao and Wang, Bo},
title = {Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {0268-4012},
url = {https://doi.org/10.1016/j.ijinfomgt.2019.05.020},
doi = {10.1016/j.ijinfomgt.2019.05.020},
journal = {Int. J. Inf. Manag.},
month = dec,
pages = {502–519},
numpages = {18},
keywords = {digital twin, machine learning, internet of things, petrochemical industry, production control optimization}
}

@inproceedings{10.1145/3209889.3209894,
author = {Alkowaileet, Wail and Alsubaiee, Sattam and Carey, Michael J. and Li, Chen and Ramampiaro, Heri and Sinthong, Phanwadee and Wang, Xikui},
title = {End-to-End Machine Learning with Apache AsterixDB},
year = {2018},
isbn = {9781450358286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209889.3209894},
doi = {10.1145/3209889.3209894},
abstract = {Recent developments in machine learning and data science provide a foundation for extracting underlying information from Big Data. Unfortunately, current platforms and tools often require data scientists to glue together and maintain custom-built platforms consisting of multiple Big Data component technologies. In this paper, we explain how Apache AsterixDB, an open source Big Data Management System, can help to reduce the burden involved in using machine learning algorithms in Big Data analytics. In particular, we describe how AsterixDB's built-in support for user-defined functions (UDFs), the availability of UDFs in data ingestion pipelines and queries, and the provision of machine learning platform and notebook inter-operation capabilities can together enable data analysts to more easily create and manage end-to-end analytical dataflows.},
booktitle = {Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning},
articleno = {6},
numpages = {10},
location = {Houston, TX, USA},
series = {DEEM'18}
}

@inproceedings{10.1145/2934466.2934488,
author = {Plakidas, Konstantinos and Stevanetic, Srdjan and Schall, Daniel and Ionescu, Tudor B. and Zdun, Uwe},
title = {How do software ecosystems evolve? a quantitative assessment of the r ecosystem.},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934488},
doi = {10.1145/2934466.2934488},
abstract = {In this work we advance the understanding of software eco-systems research by examining the structure and evolution of the R statistical computing open-source ecosystem. Our research attempts to shed light on the following intriguing question: what makes software ecosystems successful? The approach we follow is to perform a quantitative analysis of the R ecosystem. R is a well-established and popular ecosystem, whose community and marketplace are steadily growing. We assess and quantify the ecosystem throughout its history, and derive metrics on its core software components, the marketplace as well as its community. We use our insights to make observations that are applicable to ecosystems in general, validate existing theories from the literature, and propose a predictive model for the evolution of software packages. Our results show that the success of the ecosystem relies on a strong commitment by a small core of users who support a large and growing community.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {89–98},
numpages = {10},
keywords = {R, empirical study, predictive model, software ecosystems},
location = {Beijing, China},
series = {SPLC '16}
}

@article{10.1016/j.cosrev.2021.100376,
author = {Amutha, J. and Sharma, Sandeep and Sharma, Sanjay Kumar},
title = {Strategies based on various aspects of clustering in wireless sensor networks using classical, optimization and machine learning techniques: Review, taxonomy, research findings, challenges and future directions},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100376},
doi = {10.1016/j.cosrev.2021.100376},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {43},
keywords = {Wireless Sensor Networks, Optimization, Machine learning, Routing, Security, Reliability}
}

@inproceedings{10.1145/3479876.3481589,
author = {Sudusinghe, Chamika and Charles, Subodha and Mishra, Prabhat},
title = {Denial-of-service attack detection using machine learning in network-on-chip architectures},
year = {2021},
isbn = {9781450390835},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479876.3481589},
doi = {10.1145/3479876.3481589},
abstract = {State-of-the-art System-on-Chip (SoC) designs consist of many Intellectual Property (IP) cores that interact using a Network-on-Chip (NoC) architecture. SoC designers increasingly rely on global supply chains for obtaining third-party IPs. In addition to inherent vulnerabilities associated with utilizing third-party IPs, NoC based SoCs enable attackers to exploit the distributed nature of NoC and its connectivity with various IPs to launch a plethora of attacks. Specifically, Denial-of-Service (DoS) attacks pose a serious threat in degrading the SoC performance by flooding the NoC with unnecessary packets. In this paper, we present a machine learning-based runtime monitoring mechanism to detect DoS attacks. The models are statically trained and used for runtime attack detection leading to minimum runtime performance overhead. Our approach is capable of detecting DoS attacks with high accuracy, even in the presence of unpredictable NoC traffic patterns caused by various application mappings. We extensively explore machine learning models and features to provide a comprehensive study on how to use machine learning for DoS attack detection in NoC-based SoCs.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Networks-on-Chip},
pages = {35–40},
numpages = {6},
location = {Virtual Event},
series = {NOCS '21}
}

@inproceedings{10.1145/3139367.3139400,
author = {Kosmidis, Konstantinos and Kalloniatis, Christos},
title = {Machine Learning and Images for Malware Detection and Classification},
year = {2017},
isbn = {9781450353557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139367.3139400},
doi = {10.1145/3139367.3139400},
abstract = {Detecting malicious code with exact match on collected datasets is becoming a large-scale identification problem due to the existence of new malware variants. Being able to promptly and accurately identify new attacks enables security experts to respond effectively.My proposal is to develop an automated framework for identification of unknown vulnerabilities by leveraging current neural network techniques. This has a significant and immediate value for the security field, as current anti-virus software is typically able to recognize the malware type only after its infection, and preventive measures are limited.Artificial Intelligence plays a major role in automatic malware classification: numerous machine-learning methods, both supervised and unsupervised, have been researched to try classifying malware into families based on features acquired by static and dynamic analysis.The value of automated identification is clear, as feature engineering is both a time-consuming and time-sensitive task, with new malware studied while being observed in the wild.},
booktitle = {Proceedings of the 21st Pan-Hellenic Conference on Informatics},
articleno = {5},
numpages = {6},
keywords = {Malware analysis, classification, clustering, computer vision, image processing, machine learning, malware detection},
location = {Larissa, Greece},
series = {PCI '17}
}

@inproceedings{10.1145/3373419.3373437,
author = {Yu, Jie},
title = {Hard disk Drive Failure Prediction Challenges in Machine Learning for Multi-variate Time Series},
year = {2020},
isbn = {9781450376754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373419.3373437},
doi = {10.1145/3373419.3373437},
abstract = {Hard disk drive failure prediction (HDDFP) is an active area of machine learning applications. While recent work shows very promising results with high failure recall (95%) and precision based on SMART attributes, challenges remain that call for improvement in the machine learning pipeline. This paper starts with an introduction of the topic and a summary of recent work. Some challenges applicable to the existing solutions are then illustrated with an example using Backblaze dataset and its HDDFP rule. A main result of the paper is a rigorous formulation of the HDDFP problem as a MIMO dynamic system problem to tackle the challenges. It is also shown that the general formulation can help the existing classification method by enhancing the prediction lead time requirement. Though presented in the context of the HDDFP problem, the findings and thought process are applicable to other dynamic system failure prediction, and in some degree to the IoT and time series based analytics in general.},
booktitle = {Proceedings of the 2019 3rd International Conference on Advances in Image Processing},
pages = {144–148},
numpages = {5},
keywords = {Failure prediction, IoT, SMART, big data, dynamic system, hard disk, machine learning, multi-variate, time series},
location = {Chengdu, China},
series = {ICAIP '19}
}

@inproceedings{10.1145/3439961.3439991,
author = {Rivero, Luis and Diniz, Jo\~{a}o and Silva, Giovanni and Borralho, Gabriel and Braz Junior, Geraldo and Paiva, Anselmo and Alves, Erika and Oliveira, Milton},
title = {Deployment of a Machine Learning System for Predicting Lawsuits Against Power Companies: Lessons Learned from an Agile Testing Experience for Improving Software Quality},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439991},
doi = {10.1145/3439961.3439991},
abstract = {The advances in Machine Learning (ML) require software organizations to evolve their development processes in order to improve the quality of ML systems. Within the software development process, the testing stage of an ML system is more critical, considering that it is necessary to add data validation, trained model quality evaluation, and model validation to traditional unit, integration tests and system tests. In this paper, we focus on reporting the lessons learned of using model testing and exploratory testing within the context of the agile development process of an ML system that predicts lawsuits proneness in energy supply companies. Through the development of the project, the SCRUM agile methodology was applied and activities related to the development of the ML model and the development of the end-user application were defined. After the testing process of the ML model, we managed to achieve 93.89 accuracy; 95.58 specificity; 88.84 sensitivity; and 87.09 precision. Furthermore, we focused on the quality of use of the application embedding the ML model, by carrying out exploratory testing. As a result, through several iterations, different types of defects were identified and corrected. Our lessons learned support software engineers willing to develop ML systems that consider both the ML model and the end-user application.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {30},
numpages = {10},
keywords = {Methods, Software Processes, Validation, Verification, and Testing, and Tools},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@inproceedings{10.1145/3312614.3312644,
author = {Farahani, Bahar and Barzegari, Mojtaba and Aliee, Fereidoon Shams},
title = {Towards Collaborative Machine Learning Driven Healthcare Internet of Things},
year = {2019},
isbn = {9781450366403},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3312614.3312644},
doi = {10.1145/3312614.3312644},
abstract = {The relationship between technology and healthcare due to the rise of Intelligent Internet of Things (IoT) and the rapid public embracement of medical-grade wearables has been dramatically transformed in the past few years. Powered by IoT, technology brought disruptive changes and unique opportunities to the healthcare industry including personalized services, tailored content, improved availability and accessibility, and cost-effective delivery. Despite these exciting advancements in transition from clinic-centric to patient-centric healthcare, many challenges still need to be tackled. The key to successfully unlock and enable this digital shift is adopting a holistic architecture to provide high-level of quality in attributes such as latency, availability, and real-time analytics processing. In this paper, we discuss applicability of Intelligent IoT based on Collaborative Machine Learning in healthcare and medicine by presenting a holistic multi-layer architecture. This solution enables real-time actionable insights which ultimately improves decision-making powers of patients and healthcare providers. The feasibility of such architecture is investigated by a case study, ECG-based arrhythmia detection, based on deep learning and Convolutional Neural Network (CNN) methods distributed across endpoint IoT Devices, Edge (Fog) nodes, and Cloud servers.},
booktitle = {Proceedings of the International Conference on Omni-Layer Intelligent Systems},
pages = {134–140},
numpages = {7},
keywords = {Health, Internet of Things, Machine Learning},
location = {Crete, Greece},
series = {COINS '19}
}

@inproceedings{10.1145/2783258.2788628,
author = {Schleier-Smith, Johann},
title = {An Architecture for Agile Machine Learning in Real-Time Applications},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2788628},
doi = {10.1145/2783258.2788628},
abstract = {Machine learning techniques have proved effective in recommender systems and other applications, yet teams working to deploy them lack many of the advantages that those in more established software disciplines today take for granted. The well-known Agile methodology advances projects in a chain of rapid development cycles, with subsequent steps often informed by production experiments. Support for such workflow in machine learning applications remains primitive.The platform developed at if(we) embodies a specific machine learning approach and a rigorous data architecture constraint, so allowing teams to work in rapid iterative cycles. We require models to consume data from a time-ordered event history, and we focus on facilitating creative feature engineering. We make it practical for data scientists to use the same model code in development and in production deployment, and make it practical for them to collaborate on complex models.We deliver real-time recommendations at scale, returning top results from among 10,000,000 candidates with sub-second response times and incorporating new updates in just a few seconds. Using the approach and architecture described here, our team can routinely go from ideas for new models to production-validated results within two weeks.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2059–2068},
numpages = {10},
keywords = {agile, machine learning, recommender systems},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inbook{10.1145/3310205.3310213,
title = {Machine learning and probabilistic data cleaning},
year = {2019},
isbn = {9781450371520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3310205.3310213},
abstract = {Data quality is one of the most important problems in data management, since dirty data often leads to inaccurate data analytics results and incorrect business decisions. Poor data across businesses and the U.S. government are reported to cost trillions of dollars a year. Multiple surveys show that dirty data is the most common barrier faced by data scientists. Not surprisingly, developing effective and efficient data cleaning solutions is challenging and is rife with deep theoretical and engineering problems.This book is about data cleaning, which is used to refer to all kinds of tasks and activities to detect and repair errors in the data. Rather than focus on a particular data cleaning task, we give an overview of the endto- end data cleaning process, describing various error detection and repair methods, and attempt to anchor these proposals with multiple taxonomies and views. Specifically, we cover four of the most common and important data cleaning tasks, namely, outlier detection, data transformation, error repair (including imputing missing values), and data deduplication. Furthermore, due to the increasing popularity and applicability of machine learning techniques, we include a chapter that specifically explores how machine learning techniques are used for data cleaning, and how data cleaning is used to improve machine learning models.This book is intended to serve as a useful reference for researchers and practitioners who are interested in the area of data quality and data cleaning. It can also be used as a textbook for a graduate course. Although we aim at covering state-of-the-art algorithms and techniques, we recognize that data cleaning is still an active field of research and therefore provide future directions of research whenever appropriate.},
booktitle = {Data Cleaning}
}

@inproceedings{10.1007/978-3-030-63836-8_1,
author = {Panta, Adhish and Khushi, Matloob and Naseem, Usman and Kennedy, Paul and Catchpoole, Daniel},
title = {Classification of Neuroblastoma Histopathological Images Using Machine Learning},
year = {2020},
isbn = {978-3-030-63835-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63836-8_1},
doi = {10.1007/978-3-030-63836-8_1},
abstract = {Neuroblastoma is the most common cancer in young children accounting for over 15% of deaths in children due to cancer. Identification of the class of neuroblastoma is dependent on histopathological classification performed by pathologists which are considered the gold standard. However, due to the heterogeneous nature of neuroblast tumours, the human eye can miss critical visual features in histopathology. Hence, the use of computer-based models can assist pathologists in classification through mathematical analysis. There is no publicly available dataset containing neuroblastoma histopathological images. So, this study uses dataset gathered from The Tumour Bank at Kids Research at The Children’s Hospital at Westmead, which has been used in previous research. Previous work on this dataset has shown maximum accuracy of 84%. One main issue that previous research fails to address is the class imbalance problem that exists in the dataset as one class represents over 50% of the samples. This study explores a range of feature extraction and data undersampling and over-sampling techniques to improve classification accuracy. Using these methods, this study was able to achieve accuracy of over 90% in the dataset. Moreover, significant improvements observed in this study were in the minority classes where previous work failed to achieve high level of classification accuracy. In doing so, this study shows importance of effective management of available data for any application of machine learning.},
booktitle = {Neural Information Processing: 27th International Conference, ICONIP 2020, Bangkok, Thailand, November 23–27, 2020, Proceedings, Part III},
pages = {3–14},
numpages = {12},
location = {Bangkok, Thailand}
}

@inproceedings{10.1145/3320326.3320371,
author = {Adnane, Marouane and El, Mohammed and El Fkihi, Sanaa and Thami, Rachid Oulad Haj},
title = {Prediction Demand for Classified Ads Using Machine Learning: an Experiment Study},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320371},
doi = {10.1145/3320326.3320371},
abstract = {Classified ads prediction is a very interesting activity for organizations in order to increase the purchase quantity of a product and thereafter the possibility of sale. Used goods predicting can be done by calculating the probability of sale for each selected product. In this paper, we conduct an empirical analysis on classified ads prediction of Avito dataset in order to develop prediction models using three individual machine-learning techniques and five ensemble learners. We compare and evaluate the performance of the proposed models using Root Mean Square Error (RMSE) measure. The stacked generalization method was also used to combine the best-performed models to select the best one. The results show that the Extreme Gradient Boosting Machine algorithm (XGBoost) is the most accurate model with an RMSE value of 0.2253.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {39},
numpages = {6},
keywords = {Classified ads, Ensemble techniques, Machine Learning, Prediction, Stacked generalization},
location = {Rabat, Morocco},
series = {NISS '19}
}

@article{10.1145/2724721,
author = {Alonso, Omar},
title = {Challenges with Label Quality for Supervised Learning},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/2724721},
doi = {10.1145/2724721},
abstract = {Organizations that develop and use technologies around information retrieval, machine learning, recommender systems, and natural language processing depend on labels for engineering and experimentation. These labels, usually gathered via human computation, are used in machine-learned models for prediction and evaluation purposes. In such scenarios, collecting high-quality labels is a very important part of the overall process. We elaborate on these challenges and discuss research directions.},
journal = {J. Data and Information Quality},
month = mar,
articleno = {2},
numpages = {3},
keywords = {Label quality, crowdsourcing, human computation, machine learning}
}

@article{10.1016/j.jisa.2019.02.008,
author = {Wang, Defu and Wang, Xiaojuan and Zhang, Yong and Jin, Lei},
title = {Detection of power grid disturbances and cyber-attacks based on machine learning},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {46},
number = {C},
issn = {2214-2126},
url = {https://doi.org/10.1016/j.jisa.2019.02.008},
doi = {10.1016/j.jisa.2019.02.008},
journal = {J. Inf. Secur. Appl.},
month = jun,
pages = {42–52},
numpages = {11},
keywords = {Machine learning algorithm, Network attack, Feature construction engineering, Data processing}
}

@article{10.1145/3373464.3373470,
author = {Gomes, Heitor Murilo and Read, Jesse and Bifet, Albert and Barddal, Jean Paul and Gama, Jo\~{a}o},
title = {Machine learning for streaming data: state of the art, challenges, and opportunities},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/3373464.3373470},
doi = {10.1145/3373464.3373470},
abstract = {Incremental learning, online learning, and data stream learning are terms commonly associated with learning algorithms that update their models given a continuous influx of data without performing multiple passes over data. Several works have been devoted to this area, either directly or indirectly as characteristics of big data processing, i.e., Velocity and Volume. Given the current industry needs, there are many challenges to be addressed before existing methods can be efficiently applied to real-world problems. In this work, we focus on elucidating the connections among the current stateof- the-art on related fields; and clarifying open challenges in both academia and industry. We treat with special care topics that were not thoroughly investigated in past position and survey papers. This work aims to evoke discussion and elucidate the current research opportunities, highlighting the relationship of different subareas and suggesting courses of action when possible.},
journal = {SIGKDD Explor. Newsl.},
month = nov,
pages = {6–22},
numpages = {17}
}

@article{10.1155/2021/4213791,
author = {Zhu, Jianbin and Shi, Xiaojun and Zhang, Shuanghua and Ali, Rahman},
title = {Machine Learning-Based Grammar Error Detection Method in English Composition},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/4213791},
doi = {10.1155/2021/4213791},
abstract = {The detection of grammatical errors in English composition is an important task in the field of NLP. The main purpose of this task is to check out grammatical errors in English sentences and correct them. Grammatical error detection and correction are important applications in the automatic proofreading of English texts and in the field of English learning aids. With the increasing influence of English on a global scale, a huge breakthrough has been made in the task of detecting English grammatical errors. Based on machine learning, this paper designs a new method for detecting grammatical errors in English composition. First, this paper implements a grammatical error detection model based on Seq2Seq. Second, this paper implements a grammatical error detection and correction scheme based on the Transformer model. The Transformer model performs better than most grammar models. Third, this paper realizes the application of the BERT model in grammar error detection and error correction tasks, and the generalization ability of the model has been significantly enhanced. This solves the problem that the forward and backward cannot be merged when the Transformer trains the language model. Fourth, this paper proposes a method of grammatical error detection and correction in English composition based on a hybrid model. According to specific application scenarios, the corresponding neural network model is used for grammatical error correction. Combine the Seq2Seq structure to encode the input sequence and automate feature engineering. Through the combination of traditional model and deep model, the advantages are complemented to realize grammatical error detection and automatic correction.},
journal = {Sci. Program.},
month = jan,
numpages = {10}
}

@article{10.14778/3342263.3342633,
author = {Kunft, Andreas and Katsifodimos, Asterios and Schelter, Sebastian and Bre\ss{}, Sebastian and Rabl, Tilmann and Markl, Volker},
title = {An intermediate representation for optimizing machine learning pipelines},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342633},
doi = {10.14778/3342263.3342633},
abstract = {Machine learning (ML) pipelines for model training and validation typically include preprocessing, such as data cleaning and feature engineering, prior to training an ML model. Preprocessing combines relational algebra and user-defined functions (UDFs), while model training uses iterations and linear algebra. Current systems are tailored to either of the two. As a consequence, preprocessing and ML steps are optimized in isolation. To enable holistic optimization of ML training pipelines, we present Lara, a declarative domain-specific language for collections and matrices. Lara's inter-mediate representation (IR) reflects on the complete program, i.e., UDFs, control flow, and both data types. Two views on the IR enable diverse optimizations. Monads enable operator pushdown and fusion across type and loop boundaries. Combinators provide the semantics of domain-specific operators and optimize data access and cross-validation of ML algorithms. Our experiments on preprocessing pipelines and selected ML algorithms show the effects of our proposed optimizations on dense and sparse data, which achieve speedups of up to an order of magnitude.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1553–1567},
numpages = {15}
}

@inproceedings{10.1145/3359789.3359835,
author = {Jindal, Chani and Salls, Christopher and Aghakhani, Hojjat and Long, Keith and Kruegel, Christopher and Vigna, Giovanni},
title = {Neurlux: dynamic malware analysis without feature engineering},
year = {2019},
isbn = {9781450376280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359789.3359835},
doi = {10.1145/3359789.3359835},
abstract = {Malware detection plays a vital role in computer security. Modern machine learning approaches have been centered around domain knowledge for extracting malicious features. However, many potential features can be used, and it is time consuming and difficult to manually identify the best features, especially given the diverse nature of malware.In this paper, we propose Neurlux, a neural network for malware detection. Neurlux does not rely on any feature engineering, rather it learns automatically from dynamic analysis reports that detail behavioral information. Our model borrows ideas from the field of document classification, using word sequences present in the reports to predict if a report is from a malicious binary or not. We investigate the learned features of our model and show which components of the reports it tends to give the highest importance. Then, we evaluate our approach on two different datasets and report formats, showing that Neurlux improves on the state of the art and can effectively learn from the dynamic analysis reports. Furthermore, we show that our approach is portable to other malware analysis environments and generalizes to different datasets.},
booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
pages = {444–455},
numpages = {12},
keywords = {deep learning, dynamic malware analysis, machine learning},
location = {San Juan, Puerto Rico, USA},
series = {ACSAC '19}
}

@inproceedings{10.1007/978-3-030-86517-7_28,
author = {Palacios Salinas, Nelly Rosaura and Baratchi, Mitra and van Rijn, Jan N. and Vollrath, Andreas},
title = {Automated Machine Learning for Satellite Data: Integrating Remote Sensing Pre-trained Models into AutoML Systems},
year = {2021},
isbn = {978-3-030-86516-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86517-7_28},
doi = {10.1007/978-3-030-86517-7_28},
abstract = {Current AutoML systems have been benchmarked with traditional natural image datasets. Differences between satellite images and natural images (e.g., bit-wise resolution, the number, and type of spectral bands) and lack of labeled satellite images for training models, pose open questions about the applicability of current AutoML systems on satellite data. In this paper, we demonstrate how AutoML can be leveraged for classification tasks on satellite data. Specifically, we deploy the Auto-Keras system for image classification tasks and create two new variants, IMG-AK and RS-AK, for satellite image classification that respectively incorporate transfer learning using models pre-trained with (i) natural images (using ImageNet) and (ii) remote sensing datasets. For evaluation, we compared the performance of these variants against manually designed architectures on a benchmark set of 7 satellite datasets. Our results show that in 71% of the cases the AutoML systems outperformed the best previously proposed model, highlighting the usefulness of a customized satellite data search space in AutoML systems. Our RS-AK variant performed better than IMG-AK for small datasets with a limited amount of training data. Furthermore, it found the best automated model for the datasets composed of near-infrared, green, and red bands.},
booktitle = {Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part V},
pages = {447–462},
numpages = {16},
keywords = {Remote sensing, AutoML, Transfer learning, Classification},
location = {Bilbao, Spain}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00032,
author = {Parthy, Abhaya and Silberstein, Leo and Kowalczyk, Emily and High, John-Paul and Nagarajan, Adithya and Memon, Atif},
title = {Using machine learning to recommend correctness checks for geographic map data},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00032},
doi = {10.1109/ICSE-SEIP.2019.00032},
abstract = {Developing an industry application that serves geographic map data to users across the world presents the significant challenge of checking the data using "data correctness checks." The size of data that needs to be checked---the entire world---and data churn rate---thousands per day---makes executing the full set of candidate checks cost prohibitive. Current techniques rely on hand-curated static subsets of checks to be run at different stages of the data production pipeline, These hard-coded subsets are uninformed of data changes, and cause bug detection to be delayed to downstream quality assurance activities. To address these problems, we have developed new representations of map data changes and checks, formally defined "check safety," and built a recommender system that dynamically and automatically selects and ranks a relevant subset of checks using signals from latest data changes. Empirical evaluation shows that it improves (1) efficiency by eliminating 65% of checks unrelated to changes, (2) coverage by recommending and ranking change-related checks from the full set of candidate checks, previously excluded by the manual process, and (3) overall visibility into the data editing process by quickly and automatically identifying latest fault prone parts of the data.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {223–232},
numpages = {10},
keywords = {automated data validation, data check recommender, safe test/check selection},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@article{10.1016/j.asoc.2018.12.012,
author = {Arevalillo, Jorge M.},
title = {A machine learning approach to assess price sensitivity with application to automobile loan segmentation},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {76},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2018.12.012},
doi = {10.1016/j.asoc.2018.12.012},
journal = {Appl. Soft Comput.},
month = mar,
pages = {390–399},
numpages = {10},
keywords = {Machine learning, Conditional inference trees, Random forests, Model based recursive partitioning, Price sensitivity}
}

@inproceedings{10.1145/3430895.3460135,
author = {Bernius, Jan Philip and Krusche, Stephan and Bruegge, Bernd},
title = {A Machine Learning Approach for Suggesting Feedback in Textual Exercises in Large Courses},
year = {2021},
isbn = {9781450382151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430895.3460135},
doi = {10.1145/3430895.3460135},
abstract = {Open-ended textual exercises facilitate the comprehension of problem-solving skills. Students can learn from their mistakes when teachers provide individual feedback. However, courses with hundreds of students cause a heavy workload for teachers: providing individual feedback is mostly a manual, repetitive, and time-consuming activity.This paper presents CoFee, a machine learning approach designed to suggest computer-aided feedback in open-ended textual exercises. The approach uses topic modeling to split student answers into text segments and language embeddings to transform these segments. It then applies clustering to group the text segments by similarity so that the same feedback can be applied to all segments within the same cluster.We implemented this approach in a reference implementation called Athene and integrated it into Artemis. We used Athene to review 17 textual exercises in two large courses at the Technical University of Munich with 2,300 registered students and 53 teachers. On average, Athene suggested feedback for 26% of the submissions. Accordingly, 85% of these suggestions were accepted by the teachers, 5% were extended with a comment and then accepted, and 10% were changed.},
booktitle = {Proceedings of the Eighth ACM Conference on Learning @ Scale},
pages = {173–182},
numpages = {10},
keywords = {assessment support system, automatic assessment, education, feedback, grading, interactive learning, learning, software engineering},
location = {Virtual Event, Germany},
series = {L@S '21}
}

@inproceedings{10.1007/978-3-030-00338-8_5,
author = {Paulheim, Heiko},
title = {Machine Learning with and for Semantic Web Knowledge Graphs},
year = {2018},
isbn = {978-3-030-00337-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-00338-8_5},
doi = {10.1007/978-3-030-00338-8_5},
abstract = {Large-scale cross-domain knowledge graphs, such as DBpedia or Wikidata, are some of the most popular and widely used datasets of the Semantic Web. In this paper, we introduce some of the most popular knowledge graphs on the Semantic Web. We discuss how machine learning is used to improve those knowledge graphs, and how they can be exploited as background knowledge in popular machine learning tasks, such as recommender systems.},
booktitle = {Reasoning Web. Learning, Uncertainty, Streaming, and Scalability: 14th International Summer School 2018, Esch-Sur-Alzette, Luxembourg, September 22–26, 2018, Tutorial Lectures},
pages = {110–141},
numpages = {32},
keywords = {Knowledge graphs, Semantic web, Machine learning, Background knowledge},
location = {Esch-sur-Alzette , Luxembourg}
}

@article{10.1016/j.procs.2017.08.193,
author = {Mercaldo, Francesco and Nardone, Vittoria and Santone, Antonella},
title = {Diabetes Mellitus Affected Patients Classification and Diagnosis through Machine Learning Techniques},
year = {2017},
issue_date = {September 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {112},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.08.193},
doi = {10.1016/j.procs.2017.08.193},
abstract = {Medical studies demonstrated that diabetes pathology is increasing in last decades and the trend do not tends to stop. In order to help and to accelerate the diagnosis of diabetes in this paper we propose a method able to classify patients affected by diabetes using a set of characteristic selected in according to World Health Organization criteria. Evaluating real-world data using state of the art machine learning algorithms, we obtain a precision value equal to 0.770 and a recall equal to 0.775 using the HoeffdingTree algorithm.},
journal = {Procedia Comput. Sci.},
month = sep,
pages = {2519–2528},
numpages = {10},
keywords = {classification, deep learning, health, machine learning}
}

@article{10.1155/2019/4368036,
author = {Deli\'{c}, Vlado and Peri\'{c}, Zoran and Se\v{c}ujski, Milan and Jakovljevi\'{c}, Nik\v{s}a and Nikoli\'{c}, Jelena and Mi\v{s}kovi\'{c}, Dragi\v{s}a and Simi\'{c}, Nikola and Suzi\'{c}, Sini\v{s}a and Deli\'{c}, Tijana and Gastaldo, Paolo},
title = {Speech Technology Progress Based on New Machine Learning Paradigm},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1687-5265},
url = {https://doi.org/10.1155/2019/4368036},
doi = {10.1155/2019/4368036},
abstract = {Speech technologies have been developed for decades as a typical signal processing area, while the last decade has brought a huge progress based on new machine learning paradigms. Owing not only to their intrinsic complexity but also to their relation with cognitive sciences, speech technologies are now viewed as a prime example of interdisciplinary knowledge area. This review article on speech signal analysis and processing, corresponding machine learning algorithms, and applied computational intelligence aims to give an insight into several fields, covering speech production and auditory perception, cognitive aspects of speech communication and language understanding, both speech recognition and text-to-speech synthesis in more details, and consequently the main directions in development of spoken dialogue systems. Additionally, the article discusses the concepts and recent advances in speech signal compression, coding, and transmission, including cognitive speech coding. To conclude, the main intention of this article is to highlight recent achievements and challenges based on new machine learning paradigms that, over the last decade, had an immense impact in the field of speech signal processing.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@inproceedings{10.5555/3504035.3505132,
author = {Nargesian, Fatemeh and Khurana, Udayan and Pedapati, Tejaswini and Samulowitz, Horst and Turaga, Deepak},
title = {Dataset evolver: an interactive feature engineering notebook},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {We present DATASET EVOLVER, an interactive Jupyter notebook-based tool to support data scientists perform feature engineering for classification tasks. It provides users with suggestions on new features to construct, based on automated feature engineering algorithms. Users can navigate the given choices in different ways, validate the impact, and selectively accept the suggestions. DATASET EVOLVER is a pluggable feature engineering framework where several exploration strategies could be added. It currently includes meta-learning based exploration and reinforcement learning based exploration. The suggested features are constructed using well-defined mathematical functions and are easily interpretable. Our system provides a mixed-initiative system of a user being assisted by an automated agent to efficiently and effectively solve the complex problem of feature engineering. It reduces the effort of a data scientist from hours to minutes.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1097},
numpages = {2},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1145/3206098.3206113,
author = {Joshi, Santosh and Upadhyay, Himanshu and Lagos, Leonel and Akkipeddi, Naga Suryamitra and Guerra, Valerie},
title = {Machine Learning Approach for Malware Detection Using Random Forest Classifier on Process List Data Structure},
year = {2018},
isbn = {9781450363549},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3206098.3206113},
doi = {10.1145/3206098.3206113},
abstract = {As computer systems have become an integral part of every organization, it is a big challenge to safeguard the computer systems from malicious activities which compromise not only the systems but also the data stored within. Traditional malware and rootkit detection using antivirus systems are not dynamic enough to capture the complex behavior of malware and its isolated activities. There are many signature-based malware detection techniques have been introduced, but enterprises as well as general users are still facing problems to get protection for their cyber systems against malware. Thus, it emphasizes the necessity of developing an efficient malware detection technique. In this research paper, we design a machine learning approach for malware detection using Random Forest classifier for the process list data extracted from Linux based virtual machine environment.},
booktitle = {Proceedings of the 2nd International Conference on Information System and Data Mining},
pages = {98–102},
numpages = {5},
keywords = {Classifier, Ensemble, Linux, Machine Learning, Malware Detection, Model, Prediction, Process List Data Structure, Random Forest, Virtual Memory Introspection},
location = {Lakeland, FL, USA},
series = {ICISDM '18}
}

@inproceedings{10.1145/3384941.3409588,
author = {Ahmed, Chuadhry Mujeeb and M R, Gauthama Raman and Mathur, Aditya P.},
title = {Challenges in Machine Learning based approaches for Real-Time Anomaly Detection in Industrial Control Systems},
year = {2020},
isbn = {9781450376082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384941.3409588},
doi = {10.1145/3384941.3409588},
abstract = {Data-centric approaches are becoming increasingly common in the creation of defense mechanisms for critical infrastructure such as the electric power grid and water treatment plants. Such approaches often use well-known methods from machine learning and system identification, i.e., the Multi-Layer Perceptron, Convolutional Neural Network, and Deep Auto Encoders to create process anomaly detectors. Such detectors are then evaluated using data generated from an operational plant or a simulator; rarely is the assessment conducted in real time on a live plant. Regardless of the method to create an anomaly detector, and the data used for performance evaluation, there remain significant challenges that ought to be overcome before such detectors can be deployed with confidence in city-scale plants or large electric power grids. This position paper enumerates such challenges that the authors have faced when creating data-centric anomaly detectors and using them in a live plant.},
booktitle = {Proceedings of the 6th ACM on Cyber-Physical System Security Workshop},
pages = {23–29},
numpages = {7},
keywords = {CPS security, ICS security, anomaly detection, attack detection, challenges in ids, intrusion detection system, machine learning, neural networks},
location = {Taipei, Taiwan},
series = {CPSS '20}
}

@inproceedings{10.1145/3447548.3470823,
author = {Ahmad, Muhammad Aurangzeb and Overman, Steve and Allen, Christine and Kumar, Vikas and Teredesai, Ankur and Eckert, Carly},
title = {Software as a Medical Device: Regulating AI in Healthcare via Responsible AI},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470823},
doi = {10.1145/3447548.3470823},
abstract = {With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4023–4024},
numpages = {2},
keywords = {ai in healthcare, explainable ai, fairness in machine learning, interpretable machine learning, responsible ai, xai},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1016/j.knosys.2018.04.006,
author = {Lee, Gichang and Jeong, Jaeyun and Seo, Seungwan and Kim, CzangYeob and Kang, Pilsung},
title = {Sentiment classification with word localization based on weakly supervised learning with a convolutional neural network},
year = {2018},
issue_date = {July 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {152},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2018.04.006},
doi = {10.1016/j.knosys.2018.04.006},
abstract = {In order to maximize the applicability of sentiment analysis results, it is necessary to not only classify the overall sentiment (positive/negative) of a given document but also to identify the main words that contribute to the classification. However, most datasets for sentiment analysis only have the sentiment label for each document or sentence. In other words, there is a lack of information about which words play an important role in sentiment classification. In this paper, we propose a method for identifying key words discriminating positive and negative sentences by using a weakly supervised learning method based on a convolutional neural network (CNN). In our model, each word is represented as a continuous-valued vector and each sentence is represented as a matrix whose rows correspond to the word vector used in the sentence. Then, the CNN model is trained using these sentence matrices as inputs and the sentiment labels as the output. Once the CNN model is trained, we implement the word attention mechanism that identifies high-contributing words to classification results with a class activation map, using the weights from the fully connected layer at the end of the learned CNN model. To verify the proposed methodology, we evaluated the classification accuracy and the rate of polarity words among high scoring words using two movie review datasets. Experimental results show that the proposed model can not only correctly classify the sentence polarity but also successfully identify the corresponding words with high polarity scores.},
journal = {Know.-Based Syst.},
month = jul,
pages = {70–82},
numpages = {13},
keywords = {Class activation mapping, Convolutional neural network, Sentiment analysis, Weakly supervised learning, Word localization}
}

@inproceedings{10.5555/2996850.2996852,
author = {Adam-Bourdarios, Claire and Cowan, Glen and Germain, C\'{e}cile and Guyon, Isabelle and K\'{e}gl, Bal\'{a}zs and Rousseau, David},
title = {The Higgs boson machine learning challenge},
year = {2014},
publisher = {JMLR.org},
abstract = {The Higgs Boson Machine Learning Challenge (HiggsML or the Challenge for short) was organized to promote collaboration between high energy physicists and data scientists. The ATLAS experiment at CERN provided simulated data that has been used by physicists in a search for the Higgs boson. The Challenge was organized by a small group of ATLAS physicists and data scientists. It was hosted by Kaggle at https://www.kaggle. com/c/higgs-boson; the challenge data is now available on http://opendata.cern.ch/ collection/ATLAS-Higgs-Challenge-2014. This paper provides the physics background and explains the challenge setting, the challenge design, and analyzes its results.},
booktitle = {Proceedings of the 2014 International Conference on High-Energy Physics and Machine Learning - Volume 42},
pages = {19–55},
numpages = {37},
keywords = {higgs boson, high energy physics, machine learning, statistical tests},
series = {HEPML'14}
}

@inproceedings{10.1145/3388440.3412427,
author = {Das, William and Khanna, Shubh},
title = {A Novel Pupillometric-Based Application for the Automated Detection of ADHD Using Machine Learning},
year = {2020},
isbn = {9781450379649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388440.3412427},
doi = {10.1145/3388440.3412427},
abstract = {Attention-deficit/hyperactivity disorder is the most pervasive neurodevelopmental disorder among children and adolescents. Current clinical diagnosis, however, is inaccurate and inefficient, hindering the administration of proper treatment regimens. Clinical assessments are based on qualitative observations of perceived behavior. They are time-consuming and costly, preventing individuals from gaining the support they need to succeed academically, socially, and occupationally. A more accurate and efficient method of detection is necessary to ensure that all children are able to be diagnosed and given proper treatment regimens. This research proposes a novel machine learning-based method to analyze pupil-dynamics data as an objective biomarker to characterize ADHD. After visualizing and engineering pupillometric features, an evaluation of state-of-the-art machine learning algorithms showed that an Ensemble Voting Classifier yielded the optimal binary classification metrics using leave-one-out-cross-validation (LOOCV). The model classified ADHD with 82.1% sensitivity, 72.7% specificity, and 85.6% AUROC. Moreover, novel insights into associations between pupillometric features and the presence of ADHD were garnered and statistically validated. The optimal machine learning model was implemented in a web application that administers a memory task and captures pupil biometrics in real-time to output a probabilistic risk score of a patient having ADHD. This application is the first to use pupil-size dynamics as a biomarker, and offers a time-efficient and accurate approach to detect ADHD in children.},
booktitle = {Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {68},
numpages = {6},
keywords = {ADHD, Behavioral analysis, Machine learning, Medical prognostics, Pupillometry},
location = {Virtual Event, USA},
series = {BCB '20}
}

@inproceedings{10.1145/1858996.1859064,
author = {Boucher, Quentin and Classen, Andreas and Heymans, Patrick and Bourdoux, Arnaud and Demonceau, Laurent},
title = {Tag and prune: a pragmatic approach to software product line implementation},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859064},
doi = {10.1145/1858996.1859064},
abstract = {To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for the developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations.These concerns were the motivation for the industry-university collaboration described in this paper where we develop a minimally intrusive coding technique based on tags. It is supported by a toolchain and is now in use in the partner company for the development of flight grade satellite communication software libraries.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {333–336},
numpages = {4},
keywords = {code tagging, feature diagram},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1145/2934466.2934469,
author = {Zhang, Yi and Guo, Jianmei and Blais, Eric and Czarnecki, Krzysztof and Yu, Huiqun},
title = {A mathematical model of performance-relevant feature interactions},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934469},
doi = {10.1145/2934466.2934469},
abstract = {Modern software systems have grown significantly in their size and complexity, therefore understanding how software systems behave when there are many configuration options, also called features, is no longer a trivial task. This is primarily due to the potentially complex interactions among the features. In this paper, we propose a novel mathematical model for performance-relevant, or quantitative in general, feature interactions, based on the theory of Boolean functions. Moreover, we provide two algorithms for detecting all such interactions with little measurement effort and potentially guaranteed accuracy and confidence level. Empirical results on real-world configurable systems demonstrated the feasibility and effectiveness of our approach.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {25–34},
numpages = {10},
keywords = {boolean functions, feature interactions, fourier transform, performance},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/3433174.3433592,
author = {Vundavalli, Vara and Barsha, Farhat and Masum, Mohammad and Shahriar, Hossain and Haddad, Hisham},
title = {Malicious URL Detection Using Supervised Machine Learning Techniques},
year = {2021},
isbn = {9781450387514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433174.3433592},
doi = {10.1145/3433174.3433592},
booktitle = {13th International Conference on Security of Information and Networks},
articleno = {21},
numpages = {6},
keywords = {Blacklist, Logistic Regression, Malicious URL detection, Neural Networks, na\"{\i}ve Bayes},
location = {Merkez, Turkey},
series = {SIN 2020}
}

@inproceedings{10.1145/2364412.2364439,
author = {Vale, Tassio and Figueiredo, Gustavo Bittencourt and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero},
title = {A study on service identification methods for software product lines},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364439},
doi = {10.1145/2364412.2364439},
abstract = {The combination of service-orientation and software product line engineering, called Service-Oriented Product Line Engineering (SOPLE) have received attention by researchers and practitioners in the last years, and these areas can address issues of each other. One service-orientation issue is service identification. It consists of determining candidate services to a service-oriented environment based on pre-existing software artifacts, e.g., business process, source code, and so on. In order to provide a systematic identification of services, there are many available service identification methods in the literature, regarding different understanding of services, goals, and techniques. Due to this heterogeneity, this paper presents an in-depth comparison of service identification methods as well as a recommendation of the most suitable ones in the SOPLE context. This work can help the decision making of the most suitable method according to stakeholders' needs.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {156–163},
numpages = {8},
keywords = {service identification, service-oriented computing, service-oriented product lines, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3472771.3472773,
author = {Zhohov, Roman and Palaios, Alexandros and Geuer, Philipp},
title = {Learning from large-scale commercial networks: challenges and knowledge extraction towards machine learning use cases},
year = {2021},
isbn = {9781450386364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472771.3472773},
doi = {10.1145/3472771.3472773},
abstract = {Machine Learning (ML) algorithms are proposed to replace conventional algorithms in the area of wireless networking. Many of the suggested algorithms are often based on simulators or smallscale test-beds. We provide a study based on a dataset collected over a large commercial network, and highlight some of the real network dynamics that learning agents need to cope with. Our dataset includes not only measurements from the User Equipment (UE) but also integrates information from the network. Based on the collected data, we highlight some of the aspects that are important for the design of learning agents and discuss potential dataset characteristics that might hinder the learning process. Then we discuss what dataset characteristics can facilitate the deployment of ML algorithms in the real networks. Finally, we showcase how throughput prediction can be implemented by using ML techniques and provide some examples and insights on feature engineering and the training process.},
booktitle = {Proceedings of the 1st Workshop on 5G Measurements, Modeling, and Use Cases},
pages = {14–19},
numpages = {6},
keywords = {4G, LTE, QoE, QoS, artificial intelligence, cellular networks, dataset characteristics, machine learning, network dynamics, performance evaluation, wireless networking},
location = {Virtual Event},
series = {5G-MeMU '21}
}

@inproceedings{10.1145/3308557.3308683,
author = {Narita, Minori and Igarashi, Takeo},
title = {Programming-by-example for data transformation to improve machine learning performance},
year = {2019},
isbn = {9781450366731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308557.3308683},
doi = {10.1145/3308557.3308683},
abstract = {In this study, we propose a programming-by-example (PBE)-based data transformation method for feature engineering in machine learning. Data transformation by PBE is not new. However, we utilized the one proposed herein to improve the performance of machine learning in synthesizing a transformation rule from examples. Herein, the system first generates candidate rules, and then chooses the rule that achieves the highest performance in a target machine learning task. We tested this system with the Titanic dataset, and the result shows that the proposed method can avoid worst-case performance compared to the original PBE method.},
booktitle = {Companion Proceedings of the 24th International Conference on Intelligent User Interfaces},
pages = {113–114},
numpages = {2},
keywords = {data transformation, feature generation, program synthesis, programming-by-example},
location = {Marina del Ray, California},
series = {IUI '19 Companion}
}

@inproceedings{10.1109/ASE.2013.6693104,
author = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
title = {Scalable product line configuration: a straw to break the camel's back},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693104},
doi = {10.1109/ASE.2013.6693104},
abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a "seed" in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {465–474},
numpages = {10},
keywords = {SMT solvers, automated configuration, evolutionary algorithms, multiobjective optimization, variability models},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1145/2593069.2596675,
author = {Wang, Li-C. and Abadir, Magdy S.},
title = {Data Mining In EDA - Basic Principles, Promises, and Constraints},
year = {2014},
isbn = {9781450327305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593069.2596675},
doi = {10.1145/2593069.2596675},
abstract = {This paper discusses the basic principles of applying data mining in Electronic Design Automation. It begins by introducing several important concepts in statistical learning and summarizes different types of learning algorithms. Then, the experience of developing a practical data mining application is described, including promises that are demonstrated through positive results based on industrial settings and constraints explained in their respective application contexts.},
booktitle = {Proceedings of the 51st Annual Design Automation Conference},
pages = {1–6},
numpages = {6},
keywords = {Computer-Aided Design, Data Mining, Test, Verification},
location = {San Francisco, CA, USA},
series = {DAC '14}
}

@article{10.1155/2021/4454648,
author = {Wei, Wentao and Hu, Xuhui and Liu, Hua and Zhou, Ming and Song, Yan and Liu, Heng},
title = {Towards Integration of Domain Knowledge-Guided Feature Engineering and Deep Feature Learning in Surface Electromyography-Based Hand Movement Recognition},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4454648},
doi = {10.1155/2021/4454648},
abstract = {As a machine-learning-driven decision-making problem, the surface electromyography (sEMG)-based hand movement recognition is one of the key issues in robust control of noninvasive neural interfaces such as myoelectric prosthesis and rehabilitation robot. Despite the recent success in sEMG-based hand movement recognition using end-to-end deep feature learning technologies based on deep learning models, the performance of today’s sEMG-based hand movement recognition system is still limited by the noisy, random, and nonstationary nature of sEMG signals and researchers have come up with a number of methods that improve sEMG-based hand movement via feature engineering. Aiming at achieving higher sEMG-based hand movement recognition accuracies while enabling a trade-off between performance and computational complexity, this study proposed a progressive fusion network (PFNet) framework, which improves sEMG-based hand movement recognition via integration of domain knowledge-guided feature engineering and deep feature learning. In particular, it learns high-level feature representations from raw sEMG signals and engineered time-frequency domain features via a feature learning network and a domain knowledge network, respectively, and then employs a 3-stage progressive fusion strategy to progressively fuse the two networks together and obtain the final decisions. Extensive experiments were conducted on five sEMG datasets to evaluate our proposed PFNet, and the experimental results showed that the proposed PFNet could achieve the average hand movement recognition accuracies of 87.8%, 85.4%, 68.3%, 71.7%, and 90.3% on the five datasets, respectively, which outperformed those achieved by the state of the arts.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@book{10.5555/3122169,
author = {Karim, Md. Rezaul and Kaysar, Md. Mahedi},
title = {Large Scale Machine Learning with Spark},
year = {2016},
isbn = {1785888749},
publisher = {Packt Publishing},
abstract = {Discover everything you need to build robust machine learning applications with Spark 2.0About This BookGet the most up-to-date book on the market that focuses on design, engineering, and scalable solutions in machine learning with Spark 2.0.0Use Sparks machine learning library in a big data environmentYou will learn how to develop high-value applications at scale with ease and a develop a personalized design Who This Book Is ForThis book is for data science engineers and scientists who work with large and complex data sets. You should be familiar with the basics of machine learning concepts, statistics, and computational mathematics. Knowledge of Scala and Java is advisable. What You Will LearnGet solid theoretical understandings of ML algorithmsConfigure Spark on cluster and cloud infrastructure to develop applications using Scala, Java, Python, and RScale up ML applications on large cluster or cloud infrastructuresUse Spark ML and MLlib to develop ML pipelines with recommendation system, classification, regression, clustering, sentiment analysis, and dimensionality reduction Handle large texts for developing ML applications with strong focus on feature engineering Use Spark Streaming to develop ML applications for real-time streaming Tune ML models with cross-validation, hyperparameters tuning and train split Enhance ML models to make them adaptable for new data in dynamic and incremental environments In Detail Data processing, implementing related algorithms, tuning, scaling up and finally deploying are some crucial steps in the process of optimising any application. Spark is capable of handling large-scale batch and streaming data to figure out when to cache data in memory and processing them up to 100 times faster than Hadoop-based MapReduce. This means predictive analytics can be applied to streaming and batch to develop complete machine learning (ML) applications a lot quicker, making Spark an ideal candidate for large data-intensive applications. This book focuses on design engineering and scalable solutions using ML with Spark. First, you will learn how to install Spark with all new features from the latest Spark 2.0 release. Moving on, youll explore important concepts such as advanced feature engineering with RDD and Datasets. After studying developing and deploying applications, you will see how to use external libraries with Spark. In summary, you will be able to develop complete and personalised ML applications from data collections, model building, tuning, and scaling up to deploying on a cluster or the cloud. Style and approach This book takes a practical approach where all the topics explained are demonstrated with the help of real-world use cases.}
}

@inproceedings{10.1145/3465481.3470029,
author = {Rupa, Ch and Srivastava, Gautam and Bhattacharya, Sweta and Reddy, Praveen and Gadekallu, Thippa Reddy},
title = {A Machine Learning Driven Threat Intelligence System for Malicious URL Detection},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3470029},
doi = {10.1145/3465481.3470029},
abstract = {Malicious websites predominantly promote the growth of criminal activities over the Internet restraining the development of web services. Furthermore, we see different types of devices being equipped with WiFi capabilities, that allow web traffic to pass through the device’s data systems with ease. The proposed framework in the present study analyzes the Uniform Resource Locator (URL) through which malicious users can gain access to the content of the websites. It thus eliminates issues of run-time latency and possibilities of users being subjected to browser oriented vulnerabilities. The primary objective of this paper is to detect malicious links on the web using a machine learning classification technique that would help users defend against cyber-crime attacks and related threats of the real world. This may be helpful in the newly expanding Intelligent Infrastructures, where we see more data availability almost daily. The embedding of malicious URLs is a predominant web threat faced by the Internet community in the present day and age. Attackers falsely claim of being a trustworthy entity and lure users to click on compromised links to extract confidential information, victimizing them towards identity theft. The present work explores the various ways of detecting malicious links from the host-based and lexical features of the URL in order to protect users from being subjected to identity theft attacks.},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {154},
numpages = {7},
keywords = {Phishing Attacks, Runtime Latency, URL detection, Web-Based Attacks},
location = {Vienna, Austria},
series = {ARES '21}
}

@inproceedings{10.1007/978-3-030-59277-6_15,
author = {Mu\~{n}oz, Marlen Sof\'{\i}a and Torres, Camilo Ernesto Sarmiento and L\'{o}pez, Diego M. and Salazar-Cabrera, Ricardo and Vargas-Ca\~{n}as, Rubiel},
title = {Automatic Detection of Epileptic Waves in Electroencephalograms Using Bag of Visual Words and Machine Learning},
year = {2020},
isbn = {978-3-030-59276-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59277-6_15},
doi = {10.1007/978-3-030-59277-6_15},
abstract = {Epilepsy is one of the most recurrent brain disorders worldwide and mainly affects children. As a diagnostic support, the electroencephalogram is used, which is relatively easy to apply but requires a long time to analyze. Automatic EEG analysis presents difficulties both in the construction of the database and in the extracted characteristics used to build models. This article a machine learning-based methodology that uses a visual word bag of raw EEG images as input to identify images with abnormal signals. The performance introduces of the algorithms was tested using a proprietary pediatric EEG database. Accuracy greater than 95% was achieved, with calculation times less than 0.01&nbsp;s per image. Therefore, the paper demonstrates the feasibility of using machine learning algorithms to directly analyze EEG images.},
booktitle = {Brain Informatics: 13th International Conference, BI 2020, Padua, Italy, September 19, 2020, Proceedings},
pages = {163–172},
numpages = {10},
keywords = {Childhood epilepsy, Feature extraction and selection, Supervised classification, Visual categorization, Semantic categorization},
location = {Padua, Italy}
}

@article{10.1016/j.eswa.2020.114176,
author = {AlOmar, Eman Abdullah and Peruma, Anthony and Mkaouer, Mohamed Wiem and Newman, Christian and Ouni, Ali and Kessentini, Marouane},
title = {How we refactor and how we document it? On the use of supervised machine learning algorithms to classify refactoring documentation},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114176},
doi = {10.1016/j.eswa.2020.114176},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {26},
keywords = {Refactoring, Software quality, Software engineering, Machine learning}
}

@inproceedings{10.1145/3411764.3445088,
author = {Suresh, Harini and Gomez, Steven R. and Nam, Kevin K. and Satyanarayan, Arvind},
title = {Beyond Expertise and Roles: A Framework to Characterize the Stakeholders of Interpretable Machine Learning and their Needs},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445088},
doi = {10.1145/3411764.3445088},
abstract = {To ensure accountability and mitigate harm, it is critical that diverse stakeholders can interrogate black-box automated systems and find information that is understandable, relevant, and useful to them. In this paper, we eschew prior expertise- and role-based categorizations of interpretability stakeholders in favor of a more granular framework that decouples stakeholders’ knowledge from their interpretability needs. We characterize stakeholders by their formal, instrumental, and personal knowledge and how it manifests in the contexts of machine learning, the data domain, and the general milieu. We additionally distill a hierarchical typology of stakeholder needs that distinguishes higher-level domain goals from lower-level interpretability tasks. In assessing the descriptive, evaluative, and generative powers of our framework, we find our more nuanced treatment of stakeholders reveals gaps and opportunities in the interpretability literature, adds precision to the design and comparison of user studies, and facilitates a more reflexive approach to conducting this research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {74},
numpages = {16},
keywords = {expertise, explainability, framework, goals, interpretability, knowledge, machine learning, needs},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3313831.3376504,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus},
title = {Affective State Prediction Based on Semi-Supervised Learning from Smartphone Touch Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376504},
doi = {10.1145/3313831.3376504},
abstract = {Gaining awareness of the user's affective states enables smartphones to support enriched interactions that are sensitive to the user's context. To accomplish this on smartphones, we propose a system that analyzes the user's text typing behavior using a semi-supervised deep learning pipeline for predicting affective states measured by valence, arousal, and dominance. Using a data collection study with 70 participants on text conversations designed to trigger different affective responses, we developed a variational auto-encoder to learn efficient feature embeddings of two-dimensional heat maps generated from touch data while participants engaged in these conversations. Using the learned embedding in a cross-validated analysis, our system predicted three levels (low, medium, high) of valence (AUC up to 0.84), arousal (AUC up to 0.82), and dominance (AUC up to 0.82). These results demonstrate the feasibility of our approach to accurately predict affective states based only on touch data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affective computing, classification, deep learning, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1007/978-3-030-75765-6_58,
author = {Liu, Haozhe and Lin, Hongzhan and Chen, Guang},
title = {TANTP: Conversational Emotion Recognition Using Tree-Based Attention Networks with Transformer Pre-training},
year = {2021},
isbn = {978-3-030-75764-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-75765-6_58},
doi = {10.1007/978-3-030-75765-6_58},
abstract = {Conversational emotion recognition has gained significant attention in data mining and text mining recently. Most existing methods only consider the utterance in conversations as a temporal sequence and ignore the fine-grained emotional clues in the compositional structure, where the non-ignorable semantic transitions and tone enhancement are implied. Consequently, such models hardly capture accurate semantic features of the utterance, which results in the accumulation of incorrect emotional features in the memory bank. To address this problem, we propose a novel framework, Tree-based Attention Networks with Transformer Pre-training (TANTP), which incorporates contextual representations and recursive constituency tree structure into the model architecture. Different from merely modeling the utterance in light of the time order, TANTP could effectively capture compositional emotion semantics of utterance features for the memory bank, where complex semantic transitions and emotional progression are difficult to be revealed by previous conventional sequential methods. Experimental results conducted on two public benchmark datasets demonstrate that TANTP could achieve superior performance compared with other state-of-the-art models.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II},
pages = {730–742},
numpages = {13},
keywords = {Conversational emotion recognition, Tree-based attention networks, Transformer, Compositional emotion semantics}
}

@article{10.5555/3322706.3362023,
author = {Chew, Rob and Wenger, Michael and Kery, Caroline and Nance, Jason and Richards, Keith and Hadley, Emily and Baumgartner, Peter},
title = {SMART: an open source data labeling platform for supervised learning},
year = {2019},
issue_date = {January 2019},
publisher = {JMLR.org},
volume = {20},
number = {1},
issn = {1532-4435},
abstract = {SMART is an open source web application designed to help data scientists and research teams efficiently build labeled training data sets for supervised machine learning tasks. SMART provides users with an intuitive interface for creating labeled data sets, supports active learning to help reduce the required amount of labeled data, and incorporates interrater reliability statistics to provide insight into label quality. SMART is designed to be platform agnostic and easily deployable to meet the needs of as many different research teams as possible. The project website contains links to the code repository and extensive user documentation.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2999–3003},
numpages = {5},
keywords = {active learning, data labeling, open source, software, supervised learning}
}

@inproceedings{10.1145/3338906.3338943,
author = {Fucci, Davide and Mollaalizadehbahnemiri, Alireza and Maalej, Walid},
title = {On using machine learning to identify knowledge in API reference documentation},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338943},
doi = {10.1145/3338906.3338943},
abstract = {Using API reference documentation like JavaDoc is an integral part of software development. Previous research introduced a grounded taxonomy that organizes API documentation knowledge in 12 types, including knowledge about the Functionality, Structure, and Quality of an API. We study how well modern text classification approaches can automatically identify documentation containing specific knowledge types. We compared conventional machine learning (k-NN and SVM) with deep learning approaches trained on manually-annotated Java and .NET API documentation (n = 5,574). When classifying the knowledge types individually (i.e., multiple binary classifiers) the best AUPRC was up to 87},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {109–119},
numpages = {11},
keywords = {API documentation, information needs, machine learning},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1007/978-3-319-20370-6_1,
author = {\v{S}vec, Jan},
title = {Semi-supervised Learning Algorithm for Binary Relevance Multi-label Classification},
year = {2014},
isbn = {978-3-319-20369-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-20370-6_1},
doi = {10.1007/978-3-319-20370-6_1},
abstract = {The presented paper describes our model for the WISE 2014 challenge multi-label classification task. The goal of the challenge was to implement a multi-label text classification model which maximizes the mean  score on a private test data. The described method involves a binary relevance scheme with linear classifiers trained using stochastic gradient descent. A novel method for determining the values of classifiers’ meta-parameters was developed. In addition, our solution employs the semi-supervised learning which significantly improves the evaluation score. The presented solution won the third place in the challenge. The results are discussed and the supervised and semi-supervised approaches are compared.},
booktitle = {Web Information Systems Engineering – WISE 2014 Workshops: 15th International Workshops IWCSN 2014, Org2 2014, PCS 2014, and QUAT 2014, Thessaloniki, Greece, October 12-14, 2014, Revised Selected Papers},
pages = {1–13},
numpages = {13},
keywords = {Multi-label classification, Semi-supervised learning, Linear model},
location = {Thessaloniki, Greece}
}

@inproceedings{10.1145/3152465.3152476,
author = {Wang, Yibo and Xu, Wei and Zhang, Yiqun and Qin, Yu and Zhang, Wenping and Wu, Xue},
title = {Machine Learning Methods for Driving Risk Prediction},
year = {2017},
isbn = {9781450354936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152465.3152476},
doi = {10.1145/3152465.3152476},
abstract = {The development of technology makes the personalized analysis of driving behavior possible. A variety of attributes have been added to driving behavior analysis. Through in-depth analysis of driving behavior data, this paper uses machine learning methods to analyze and predict driving risk, thus laying a foundation for improving driver's driving behavior. Moreover, the experiment results shows that it is necessary to take detailed analysis into consideration.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management},
articleno = {10},
numpages = {6},
keywords = {Driving behavior, machine learning, neural networks},
location = {Redondo Beach, CA, USA},
series = {EM-GIS '17}
}

@article{10.1145/3386295,
author = {Thambawita, Vajira and Jha, Debesh and Hammer, Hugo Lewi and Johansen, H\r{a}vard D. and Johansen, Dag and Halvorsen, P\r{a}l and Riegler, Michael A.},
title = {An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
url = {https://doi.org/10.1145/3386295},
doi = {10.1145/3386295},
abstract = {Precise and efficient automated identification of gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Toward this goal, we present comprehensive evaluations of five distinct machine learning models using global features and deep neural networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics, such as recall, precision, specificity, accuracy, F1-score, and the Matthews correlation coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset—that is, the performance metrics should always be interpreted together rather than relying on a single metric.},
journal = {ACM Trans. Comput. Healthcare},
month = jun,
articleno = {17},
numpages = {29},
keywords = {CVC-12K, CVC-356, CVC-612, Kvasir, Medical, Nerthus, computer-aided diagnosis, cross-dataset evaluations, deep learning, gastrointestinal tract diseases, global features, multi-class classification, polyp classification}
}

@inproceedings{10.1145/2791060.2791068,
author = {B\'{e}can, Guillaume and Behjati, Razieh and Gotlieb, Arnaud and Acher, Mathieu},
title = {Synthesis of attributed feature models from product descriptions},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791068},
doi = {10.1145/2791060.2791068},
abstract = {Many real-world product lines are only represented as nonhierarchical collections of distinct products, described by their configuration values. As the manual preparation of feature models is a tedious and labour-intensive activity, some techniques have been proposed to automatically generate boolean feature models from product descriptions. However, none of these techniques is capable of synthesizing feature attributes and relations among attributes, despite the huge relevance of attributes for documenting software product lines. In this paper, we introduce for the first time an algorithmic and parametrizable approach for computing a legal and appropriate hierarchy of features, including feature groups, typed feature attributes, domain values and relations among these attributes. We have performed an empirical evaluation by using both randomized configuration matrices and real-world examples. The initial results of our evaluation show that our approach can scale up to matrices containing 2,000 attributed features, and 200,000 distinct configurations in a couple of minutes.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {1–10},
numpages = {10},
keywords = {attributed feature models, product descriptions},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.1145/3205651.3208202,
author = {Ribeiro, Victor Henrique Alves and Reynoso-Meza, Gilberto},
title = {Online anomaly detection for drinking water quality using a multi-objective machine learning approach},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208202},
doi = {10.1145/3205651.3208202},
abstract = {This document proposes the use of multi-objective machine learning in order to solve the problem of online anomaly detection for drinking water quality. Such problem consists of an imbalanced data set where events, the minority class, must be correctly detected based on a time series denoting water quality data and operative data. In order to develop two different robust systems, signal processing and feature engineering are used to prepare the data, while evolutionary multi-objective optimization is used for feature selection and ensemble generation. The proposed systems are tested with hold-out validation during optimization, and are expected to generalize well the predictions for future testing data.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1–2},
numpages = {2},
keywords = {anomaly detection, evolutionary computation, machine learning, time series},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@article{10.1007/s10994-018-5763-8,
author = {Berrar, Daniel and Lopes, Philippe and Davis, Jesse and Dubitzky, Werner},
title = {Guest editorial: special issue on machine learning for soccer},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {108},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-018-5763-8},
doi = {10.1007/s10994-018-5763-8},
journal = {Mach. Learn.},
month = jan,
pages = {1–7},
numpages = {7}
}

@article{10.1007/s00778-017-0478-1,
author = {Elgohary, Ahmed and Boehm, Matthias and Haas, Peter J. and Reiss, Frederick R. and Reinwald, Berthold},
title = {Compressed linear algebra for large-scale machine learning},
year = {2018},
issue_date = {October   2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {5},
issn = {1066-8888},
url = {https://doi.org/10.1007/s00778-017-0478-1},
doi = {10.1007/s00778-017-0478-1},
abstract = {Large-scale machine learning algorithms are often iterative, using repeated read-only data access and I/O-bound matrix-vector multiplications to converge to an optimal model. It is crucial for performance to fit the data into single-node or distributed main memory and enable fast matrix-vector operations on in-memory data. General-purpose, heavy- and lightweight compression techniques struggle to achieve both good compression ratios and fast decompression speed to enable block-wise uncompressed operations. Therefore, we initiate work--inspired by database compression and sparse matrix formats--on value-based compressed linear algebra (CLA), in which heterogeneous, lightweight database compression techniques are applied to matrices, and then linear algebra operations such as matrix-vector multiplication are executed directly on the compressed representation. We contribute effective column compression schemes, cache-conscious operations, and an efficient sampling-based compression algorithm. Our experiments show that CLA achieves in-memory operations performance close to the uncompressed case and good compression ratios, which enables fitting substantially larger datasets into available memory. We thereby obtain significant end-to-end performance improvements up to 9.2x.},
journal = {The VLDB Journal},
month = oct,
pages = {719–744},
numpages = {26},
keywords = {Declarative, Large-scale, Linear algebra, Lossless compression, Machine learning}
}

@inproceedings{10.1145/3077981.3078037,
author = {Tits, Micka\"{e}l and Tilmanne, Jo\"{e}lle and Dutoit, Thierry},
title = {Morphology Independent Feature Engineering in Motion Capture Database for Gesture Evaluation},
year = {2017},
isbn = {9781450352093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077981.3078037},
doi = {10.1145/3077981.3078037},
abstract = {In the recent domain of motion capture and analysis, a new challenge has been the automatic evaluation of skill in gestures. Many methods have been proposed for gesture evaluation based on feature extraction, skill modeling and gesture comparison. However, movements can be influenced by many factors other than skill, including morphology. All these influences make comparison between gestures of different people difficult. In this paper, we propose a new method based on constrained linear regression to remove the influence of morphology on motion features. To validate our method, we compare it to a baseline method, consisting in a scaling of the skeleton data [14]. Results show that our method outperforms previous work both in removing morphology influence on feature, and in improving feature relation with skill. For a set of 326 features extracted from two datasets of Taijiquan gestures, we show that morphology influence is completely removed for 100% of the features using our method, whereas the baseline method only allows limited reduction of morphology influence for 74% of the features. Our method improves correlation with skill as assessed by an expert by 0.04 (p &lt; 0.0001) in average for 98% of the features, against 0.001 (p = 0.68) for 58% of the features with the baseline method. Our method is also more general than previous work, as it could potentially be applied with any interindividual factor on any feature.},
booktitle = {Proceedings of the 4th International Conference on Movement Computing},
articleno = {26},
numpages = {8},
keywords = {Factor Independence, Feature Extraction, Gesture Evaluation, Linear Regression, Morphology, Motion Capture, Residue},
location = {London, United Kingdom},
series = {MOCO '17}
}

@article{10.1109/TASLP.2017.2732162,
author = {Qian, Yanmin and Chen, Nanxin and Dinkel, Heinrich and Wu, Zhizheng and Yanmin Qian and Nanxin Chen and Dinkel, Heinrich and Zhizheng Wu},
title = {Deep Feature Engineering for Noise Robust Spoofing Detection},
year = {2017},
issue_date = {October 2017},
publisher = {IEEE Press},
volume = {25},
number = {10},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2017.2732162},
doi = {10.1109/TASLP.2017.2732162},
abstract = {Spoofing detection for automatic speaker verification ASV aims to discriminate between genuine and spoofed speech. This topic has received increased attentions recently due to safety concerns with deploying an ASV system. While the performance of spoofing detection has improved significantly in clean condition in recent studies, the performance degrades dramatically in noisy conditions. To address this issue, in this paper, we propose to extract robust and discriminative deep features by using deep learning techniques for spoofing detection. In particular, we employ deep feedforward, recurrent, and convolutional neural networks to extract discriminative features. We also introduce multicondition training, noise-aware training, and annealed dropout training to make neural networks more robust against noise and to avoid overfitting to specific spoofing attacks and noise types. The proposed neural networks and training techniques are combined into a single framework for spoofing detection. Experimental evaluation is carried out on a noisy version of the standard ASVspoof 2015 corpus, including both additive noisy and reverberant scenarios. Experimental results confirm that the proposed system dramatically decreases averaged equal error rates from 19.1% and 22.6% to 3.2% and 5.1% for seen and unseen noisy conditions, respectively.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {1942–1955},
numpages = {14}
}

@inproceedings{10.1145/3383455.3422529,
author = {Chen, Qian and Liu, Xiao-Yang},
title = {Quantifying ESG alpha using scholar big data: an automated machine learning approach},
year = {2021},
isbn = {9781450375849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383455.3422529},
doi = {10.1145/3383455.3422529},
abstract = {ESG (Environmental, social and governance) alpha strategy that makes sustainable investment has gained popularity among investors. The ESG fields of study in scholar big data is a valuable alternative data that reflects a company's long-term ESG commitment. However, it is considered a difficulty to quantitatively measure a company's ESG premium and its impact to the company's stock price using scholar big data. In this paper, we utilize ESG scholar data as alternative data to develop an automatic trading strategy and propose a practical machine learning approach to quantify the ESG premium of a company and capture the ESG alpha. First, we construct our ESG investment universe and apply feature engineering on the companies' ESG scholar data from the Microsoft Academic Graph database. Then, we train six complementary machine learning models using a combination of financial indicators and ESG scholar data features and employ an ensemble method to predict stock prices and automatically set up portfolio allocation. Finally, we manage our portfolio, trade and rebalance the portfolio allocation monthly using predicted stock prices. We backtest our ESG alpha strategy and compare its performance with benchmarks. The proposed ESG alpha strategy achieves a cumulative return of 2,154.4% during the backtesting period of ten years, which significantly outperforms the NASDAQ-100 index's 397.4% and S&amp;P 500's 226.9%. The traditional financial indicators results in only 1,443.7%, thus our scholar data-based ESG alpha strategy is better at capturing ESG premium than traditional financial indicators.},
booktitle = {Proceedings of the First ACM International Conference on AI in Finance},
articleno = {41},
numpages = {8},
keywords = {AI in finance, ESG alpha, alternative data, quantitative investment, scholar data},
location = {New York, New York},
series = {ICAIF '20}
}

@article{10.14778/2078324.2078325,
author = {Pavlo, Andrew and Jones, Evan P. C. and Zdonik, Stanley},
title = {On predictive modeling for optimizing transaction execution in parallel OLTP systems},
year = {2011},
issue_date = {October 2011},
publisher = {VLDB Endowment},
volume = {5},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/2078324.2078325},
doi = {10.14778/2078324.2078325},
abstract = {A new emerging class of parallel database management systems (DBMS) is designed to take advantage of the partitionable workloads of on-line transaction processing (OLTP) applications [23, 20]. Transactions in these systems are optimized to execute to completion on a single node in a shared-nothing cluster without needing to coordinate with other nodes or use expensive concurrency control measures [18]. But some OLTP applications cannot be partitioned such that all of their transactions execute within a single-partition in this manner. These distributed transactions access data not stored within their local partitions and subsequently require more heavy-weight concurrency control protocols. Further difficulties arise when the transaction's execution properties, such as the number of partitions it may need to access or whether it will abort, are not known beforehand. The DBMS could mitigate these performance issues if it is provided with additional information about transactions. Thus, in this paper we present a Markov model-based approach for automatically selecting which optimizations a DBMS could use, namely (1) more efficient concurrency control schemes, (2) intelligent scheduling, (3) reduced undo logging, and (4) speculative execution. To evaluate our techniques, we implemented our models and integrated them into a parallel, main-memory OLTP DBMS to show that we can improve the performance of applications with diverse workloads.},
journal = {Proc. VLDB Endow.},
month = oct,
pages = {85–96},
numpages = {12}
}

@inproceedings{10.1145/3486183.3491066,
author = {Schneider, Nicole R. and Samet, Hanan},
title = {Which portland is it? a machine learning approach},
year = {2021},
isbn = {9781450391009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486183.3491066},
doi = {10.1145/3486183.3491066},
abstract = {This paper reviews several approaches to the problem of toponym resolution for news articles referring to 'Portland.' We train several models to differentiate between Portland, Maine and Portland, Oregon, generating features using only the text of the articles. The data used is in the form of articles pulled from NewsStand. The labels, which are provided by NewsStand's interpretation of the articles, allow for a supervised learning approach. We apply Natural Language Processing (NLP) and data cleaning techniques to process the article data, perform feature reduction, and then feed the data to the models. We show that the logistic regression model performs the best of the four models that we test. We also demonstrate that this model learns a more robust representation of the two classes than the other three models do.},
booktitle = {Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-Based Recommendations, Geosocial Networks and Geoadvertising},
articleno = {8},
numpages = {10},
keywords = {experimental, geotagging, machine learning, spatio-textual, toponym resolution},
location = {Beijing, China},
series = {LocalRec '21}
}

@article{10.1007/s10115-017-1121-6,
author = {Pecli, Antonio and Cavalcanti, Maria Claudia and Goldschmidt, Ronaldo},
title = {Automatic feature selection for supervised learning in link prediction applications: a comparative study},
year = {2018},
issue_date = {July      2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {56},
number = {1},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-017-1121-6},
doi = {10.1007/s10115-017-1121-6},
abstract = {For the last years, a considerable amount of attention has been devoted to the research about the link prediction (LP) problem in complex networks. This problem tries to predict the likelihood of an association between two not interconnected nodes in a network to appear in the future. One of the most important approaches to the LP problem is based on supervised machine learning (ML) techniques for classification. Although many works have presented promising results with this approach, choosing the set of features (variables) to train the classifiers is still a major challenge. In this article, we report on the effects of three different automatic variable selection strategies (Forward, Backward and Evolutionary) applied to the feature-based supervised learning approach in LP applications. The results of the experiments show that the use of these strategies does lead to better classification models than classifiers built with the complete set of variables. Such experiments were performed over three datasets (Microsoft Academic Network, Amazon and Flickr) that contained more than twenty different features each, including topological and domain-specific ones. We also describe the specification and implementation of the process used to support the experiments. It combines the use of the feature selection strategies, six different classification algorithms (SVM, K-NN, na\"{\i}ve Bayes, CART, random forest and multilayer perceptron) and three evaluation metrics (Precision, F-Measure and Area Under the Curve). Moreover, this process includes a novel ML voting committee inspired approach that suggests sets of features to represent data in LP applications. It mines the log of the experiments in order to identify sets of features frequently selected to produce classification models with high performance. The experiments showed interesting correlations between frequently selected features and datasets.},
journal = {Knowl. Inf. Syst.},
month = jul,
pages = {85–121},
numpages = {37},
keywords = {Binary classification, Complex network analysis, Feature selection, Link prediction}
}

@inproceedings{10.1145/3394171.3416285,
author = {Feng, Ming and Xu, Kele and Wang, Yin},
title = {A Quantitative Comparison of Different Machine Learning Approaches for Human Spermatozoa Quality Prediction Using Multimodal Datasets},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3416285},
doi = {10.1145/3394171.3416285},
abstract = {Despite remarkable advances in medical data analysis fields, they are severely restrained from the limited property of the employed single modality, usually medical imaging data. However, other modalities (such as patient-related information) should also be taken into account in the process of clinical decision. How to fully employ the multi-modal dataset is still under-explored. In this paper, we make a quantitative comparison of different machine learning approaches for the human spermatozoa quality prediction task, leveraging multiple modalities dataset. To empirically investigate the advantages and disadvantages of different machine learning approaches, we perform extensive experiments. Leveraging different features, we achieve state-of-the-art performance on most of the tasks. The obtained results show that simple models can provide better performance, which emphasizes the importance of avoiding overfitting. For the sake of reproducibility, we have released our code to facilitate the research community.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {4659–4663},
numpages = {5},
keywords = {machine learning, multimodal, quantitative comparison},
location = {Seattle, WA, USA},
series = {MM '20}
}

@inproceedings{10.1007/978-3-030-32391-2_9,
author = {Shojaee, Ali and Li, Kendrick and Atluri, Gowtham},
title = {A Machine Learning Framework for Accurate Functional Connectome Fingerprinting and an Application of a Siamese Network},
year = {2019},
isbn = {978-3-030-32390-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32391-2_9},
doi = {10.1007/978-3-030-32391-2_9},
abstract = {The goal of functional connectome (FC) fingerprinting is to uniquely identify subjects based on their functional connectome. In recent years, interest in this problem has increased substantially with efforts made to understand the factors that affect the accuracy of fingerprinting and to develop more effective approaches. In this work, we developed a novel machine learning framework for FC fingerprinting. Specifically, while existing approaches match a query FC with a reference FC based on a correlation score between the two FCs, our framework employed a machine learning model to determine if two FCs are similar. This allowed us to capture more complex features from FCs and also to capture non-linear similarities that may exist among FCs. We explored multiple machine learning algorithms that include a Siamese neural network and several classification algorithms. From our experiments, we observed that the Siamese network outperformed other classification models, with an FC fingerprinting accuracy of .},
booktitle = {Connectomics in NeuroImaging: Third International Workshop, CNI 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings},
pages = {83–94},
numpages = {12},
keywords = {Functional connectivity, Fingerprinting, Parcellation, Precision neuroscience},
location = {Shenzhen, China}
}

@article{10.1016/j.compag.2020.105286,
author = {Taneja, Mohit and Byabazaire, John and Jalodia, Nikita and Davy, Alan and Olariu, Cristian and Malone, Paul},
title = {Machine learning based fog computing assisted data-driven approach for early lameness detection in dairy cattle},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {171},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2020.105286},
doi = {10.1016/j.compag.2020.105286},
journal = {Comput. Electron. Agric.},
month = apr,
numpages = {15},
keywords = {Smart dairy farming, Fog computing, Internet of Things (IoT), Cloud computing, Smart farm, Data analytics, Microservices, Machine learning, Clustering, Classification, Data-driven}
}

@article{10.1007/s11036-021-01834-1,
author = {Pang, Zhen and Wang, Xiang and Wang, Xulong and Qi, Jun and Zhao, Zhong and Gao, Yuan and Yang, Yun and Yang, Po},
title = {A Multi-modal Data Platform for Diagnosis and Prediction of Alzheimer’s Disease Using Machine Learning Methods},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {6},
issn = {1383-469X},
url = {https://doi.org/10.1007/s11036-021-01834-1},
doi = {10.1007/s11036-021-01834-1},
abstract = {Alzheimer’s an irreversible neurodegenerative disease with the most far-reaching impact, the most extensive, and the most difficult to cure in the world. It is also the most common disease of Alzheimer’s disease. With the rapid rise of data mining, machine learning and other fields, they have penetrated various disciplines. In particular, research in the field of AD is developing rapidly and has demonstrated strong vitality. In terms of data, Alzheimer’s Disease Neuroimaging Initiative (ADNI) researchers collect, verify and use a variety of data modalities as predictors of disease, including MRI and PET images, genetics, cognitive testing, cerebrospinal fluid and blood biomarkers, etc. Therefore, this paper uses a multi-task learning algorithm based on the ADNI data set to implement regression tasks and predict the cognitive scores of subjects in the next 3&nbsp;years. This method can effectively assess the cognitive trends of patients in the future and aims to predict the progression of the disease. In addition, we used four different machine learning classification algorithms to conduct fusion research on AD multi-modal data, including MRI, PET, and cognitive scoring data. This method can determine the current patient’s cognitive stage, to achieve the effect of assisting doctors in diagnosis. Finally, we designed a multi-modal data platform technical architecture to standardize management and sharing of ADNI data and data obtained by offline medical institutions to improve the utilization and value of data. The design of the technical architecture proposed in this article is more easily scalable and compatible with other neurological diseases. Nowadays, the large amount of data being generated by AD can provide valuable solutions for the research of disease progression prediction and auxiliary diagnosis.},
journal = {Mob. Netw. Appl.},
month = dec,
pages = {2341–2352},
numpages = {12},
keywords = {Multi-modal data, Multi-task learning, Classification, Technical architecture, Disease progression prediction, Auxiliary diagnosis}
}

@article{10.1016/j.eswa.2015.12.030,
author = {Correa Bahnsen, Alejandro and Aouada, Djamila and Stojanovic, Aleksandar and Ottersten, Bj\"{o}rn},
title = {Feature engineering strategies for credit card fraud detection},
year = {2016},
issue_date = {June 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {51},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.12.030},
doi = {10.1016/j.eswa.2015.12.030},
abstract = {Credit card fraud detection evaluation measure.Each example is assumed to have different financial cost.Transaction aggregation strategy for predicting fraud.Periodic features using the von Mises distribution.Code is open source and available at albahnsen.com/CostSensitiveClassification. Every year billions of Euros are lost worldwide due to credit card fraud. Thus, forcing financial institutions to continuously improve their fraud detection systems. In recent years, several studies have proposed the use of machine learning and data mining techniques to address this problem. However, most studies used some sort of misclassification measure to evaluate the different solutions, and do not take into account the actual financial costs associated with the fraud detection process. Moreover, when constructing a credit card fraud detection model, it is very important how to extract the right features from the transactional data. This is usually done by aggregating the transactions in order to observe the spending behavioral patterns of the customers. In this paper we expand the transaction aggregation strategy, and propose to create a new set of features based on analyzing the periodic behavior of the time of a transaction using the von Mises distribution. Then, using a real credit card fraud dataset provided by a large European card processing company, we compare state-of-the-art credit card fraud detection models, and evaluate how the different sets of features have an impact on the results. By including the proposed periodic features into the methods, the results show an average increase in savings of 13%.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {134–142},
numpages = {9},
keywords = {Cost-sensitive learning, Fraud detection, Preprocessing, Von Mises distribution}
}

@article{10.1155/2021/8387680,
author = {Bharti, Rohit and Khamparia, Aditya and Shabaz, Mohammad and Dhiman, Gaurav and Pande, Sagar and Singh, Parneet and Abd El-Latif, Ahmed A.},
title = {Prediction of Heart Disease Using a Combination of Machine Learning and Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/8387680},
doi = {10.1155/2021/8387680},
abstract = {The correct prediction of heart disease can prevent life threats, and incorrect prediction can prove to be fatal at the same time. In this paper different machine learning algorithms and deep learning are applied to compare the results and analysis of the UCI Machine Learning Heart Disease dataset. The dataset consists of 14 main attributes used for performing the analysis. Various promising results are achieved and are validated using accuracy and confusion matrix. The dataset consists of some irrelevant features which are handled using Isolation Forest, and data are also normalized for getting better results. And how this study can be combined with some multimedia technology like mobile devices is also discussed. Using deep learning approach, 94.2% accuracy was obtained.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {11}
}

@inproceedings{10.1145/3340531.3412757,
author = {Rozemberczki, Benedek and Kiss, Oliver and Sarkar, Rik},
title = {Karate Club: An API Oriented Open-Source Python Framework for Unsupervised Learning on Graphs},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412757},
doi = {10.1145/3340531.3412757},
abstract = {Graphs encode important structural properties of complex systems. Machine learning on graphs has therefore emerged as an important technique in research and applications. We present Karate Club - a Python framework combining more than 30 state-of-the-art graph mining algorithms. These unsupervised techniques make it easy to identify and represent common graph features. The primary goal of the package is to make community detection, node and whole graph embedding available to a wide audience of machine learning researchers and practitioners. Karate Club is designed with an emphasis on a consistent application interface, scalability, ease of use, sensible out of the box model behaviour, standardized dataset ingestion, and output generation. This paper discusses the design principles behind the framework with practical examples. We show Karate Club's efficiency in learning performance on a wide range of real world clustering problems and classification tasks along with supporting evidence of its competitive speed.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {3125–3132},
numpages = {8},
keywords = {community detection, graph classification, graph embedding, graph mining, machine learning, network embedding, node embedding},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@article{10.1145/3299887.3299891,
author = {Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
title = {Data Lifecycle Challenges in Production Machine Learning: A Survey},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/3299887.3299891},
doi = {10.1145/3299887.3299891},
abstract = {Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.},
journal = {SIGMOD Rec.},
month = dec,
pages = {17–28},
numpages = {12}
}

@inproceedings{10.1145/2517288.2517293,
author = {Zhong, Erheng and Li, Lianghao and Wang, Naiyan and Tan, Ben and Zhu, Yin and Zhao, Lili and Yang, Qiang},
title = {Contextual rule-based feature engineering for author-paper identification},
year = {2013},
isbn = {9781450324953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517288.2517293},
doi = {10.1145/2517288.2517293},
abstract = {We present the ideas and methodologies that we used to address the KDD Cup 2013 challenge on author-paper identification. We firstly formulate the problem as a personalized ranking task and then propose to solve the task through a supervised learning framework. The key point is to eliminate those incorrectly assigned papers of a given author based on existing records. We choose Gradient Boosted Tree as our main classifier. Through our exploration we conclude that the most critical factor to achieve our results is the effective feature engineering. In this paper, we formulate this process as a unified framework that constructs features based on contextual information and combines machine learning techniques with human intelligence. Besides this, we suggest several strategies to parse authors' names, which improve the prediction results significantly. Divide-conquer based model building as well as the model averaging techniques also benefit the prediction precision.},
booktitle = {Proceedings of the 2013 KDD Cup 2013 Workshop},
articleno = {6},
numpages = {6},
location = {Chicago, Illinois},
series = {KDD Cup '13}
}

@article{10.1155/2021/5520366,
author = {Amin, Samina and Uddin, Muhammad Irfan and alSaeed, Duaa H. and Khan, Atif and Adnan, Muhammad and Aziz, Furqan},
title = {Early Detection of Seasonal Outbreaks from Twitter Data Using Machine Learning Approaches},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/5520366},
doi = {10.1155/2021/5520366},
abstract = {Seasonal outbreaks have several different periods that occur primarily during winter in temperate regions, while influenza may occur throughout the year in tropical regions, triggering outbreaks more irregularly. Similarly, dengue occurs in the star of the rainy season in early May and reaches its peak in late June. Dengue and flu brought an impact on various countries in the years 2017–2019 and streaming Twitter data reveals the status of dengue and flu outbreaks in the most affected regions. This research work presents that Social Media Analysis (SMA) can be used as a detector of the epidemic outbreak and to understand the sentiment of social media users regarding various diseases. Providing awareness about seasonal outbreaks through SMA is an effective approach for researchers and healthcare responders to detect the early outbreaks. The proposed model aims to find the sentiment about the disease in tweets, and the seasonal outbreaks-related tweets are classified into two classes as disease positive and disease negative. This work proposes a machine-learning-based approach to detect dengue and flu outbreaks in social media platform Twitter, using four machine learning algorithms: Random Forest (RF), K-Nearest Neighbor (KNN), Support Vector Machine (SVM), and Decision Tree (DT), with the help of Term Frequency and Inverse Document Frequency (TF-IDF). For experimental analysis, two datasets (dengue and flu) are analyzed individually. The experimental results show that the RF classifier has outperformed the comparison models in terms of improved accuracy, precision, recall, F1-measure, and Receiver Operating Characteristic (ROC) curve. The proposed work offers favorable performance with total precision, accuracy, recall, and F1-measure ranging from 84% to 88% for conventional machine learning techniques.},
journal = {Complex.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/3052973.3053009,
author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
title = {Practical Black-Box Attacks against Machine Learning},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3052973.3053009},
doi = {10.1145/3052973.3053009},
abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {506–519},
numpages = {14},
keywords = {adversarial machine learning, black-box attack, machine learning},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}

@inproceedings{10.5555/3045390.3045466,
author = {Patrini, Giorgio and Nielsen, Frank and Nock, Richard and Carioni, Marcello},
title = {Loss factorization, weakly supervised learning and label noise robustness},
year = {2016},
publisher = {JMLR.org},
abstract = {We prove that the empirical risk of most well-known loss functions factors into a linear term aggregating all labels with a term that is label free, and can further be expressed by sums of the same loss. This holds true even for non-smooth, non-convex losses and in any RKHS. The first term is a (kernel) mean operator -- the focal quantity of this work -- which we characterize as the sufficient statistic for the labels. The result tightens known generalization bounds and sheds new light on their interpretation.Factorization has a direct application on weakly supervised learning. In particular, we demonstrate that algorithms like SGD and proximal methods can be adapted with minimal effort to handle weak supervision, once the mean operator has been estimated. We apply this idea to learning with asymmetric noisy labels, connecting and extending prior work. Furthermore, we show that most losses enjoy a data-dependent (by the mean operator) form of noise robustness, in contrast with known negative results.},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
pages = {708–717},
numpages = {10},
location = {New York, NY, USA},
series = {ICML'16}
}

@inproceedings{10.1145/3374135.3385282,
author = {Phillips, Brandon and Gamess, Eric and Krishnaprasad, Sri},
title = {An Evaluation of Machine Learning-based Anomaly Detection in a SCADA System Using the Modbus Protocol},
year = {2020},
isbn = {9781450371056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374135.3385282},
doi = {10.1145/3374135.3385282},
abstract = {Supervisory Control and Data Acquisition (SCADA) systems have been designed with the assumption that the system would run within a closed environment. They have only generated concerns for security issues that may appear during system deployment, and there are no clear methods to assess security threats when considered. Recent technological and economic trends have driven SCADA systems from serial communication networks to networks based on TCP/IP. This exposes legacy SCADA systems to new security threats they were not designed to defend against. This work examines the viability of machine learning techniques in detecting new security threats specific to SCADA systems and the Modbus protocol. Machine learning-based anomaly detection algorithms were used to detect malicious traffic in a generated dataset of Remote Terminal Unit (RTU) communications using the Modbus protocol. The implemented algorithms are Support Vector Machines, decision trees, k-nearest neighbors, and k-means clustering. While the algorithms performed well overall, Support Vector Machine, Decision Trees, and K-nearest Neighbors algorithms had the best performance with individual attack types. K-means clustering did not perform satisfactorily with specific attack types.},
booktitle = {Proceedings of the 2020 ACM Southeast Conference},
pages = {188–196},
numpages = {9},
keywords = {Anomaly Detection, Industrial Control Systems, Machine Learning, Modbus, SCADA},
location = {Tampa, FL, USA},
series = {ACMSE '20}
}

@article{10.1007/s10270-020-00791-9,
author = {Westfechtel, Bernhard and Greiner, Sandra},
title = {Extending single- to multi-variant model transformations by trace-based propagation of variability annotations},
year = {2020},
issue_date = {Jul 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00791-9},
doi = {10.1007/s10270-020-00791-9},
abstract = {Model-driven engineering involves the construction of models on different levels of abstraction. Software engineers are supported by model transformations, which automate the transition from high- to low-level models. Product line engineering denotes a systematic process that aims at developing different product variants from a set of reusable assets. When model-driven engineering is combined with product line engineering, engineers have to deal with multi-variant models. In annotative approaches to product line engineering, model elements are decorated with annotations, i.e., Boolean expressions that define the product variants in which model elements are to be included. In model-driven product line engineering, domain engineers require multi-variant transformations, which create multi-variant target models from multi-variant source models. We propose a reuse-based gray-box approach to realizing multi-variant model transformations. We assume that single-variant transformations already exist, which have been developed for model-driven engineering, without considering product lines. Furthermore, we assume that single-variant transformations create traces, which comprise the steps executed in order to derive target models from source models. Single-variant transformations are extended into multi-variant transformations by trace-based propagation: after executing a single-variant transformation, the resulting single-variant target model is enriched with annotations that are calculated with the help of the transformation’s trace. This approach may be applied to single-variant transformations written in different languages and requires only access to the trace, not to the respective transformation definition. We also provide a correctness criterion for trace-based propagation, and a proof that this criterion is satisfied under the prerequisites of a formal computational model.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {853–888},
numpages = {36},
keywords = {Model transformation, Software product line, Annotative variability}
}

@inproceedings{10.1007/978-3-030-03596-9_53,
author = {Fu, Min and Wong, Chi Man and Zhu, Hai and Huang, Yanjun and Li, Yuanping and Zheng, Xi and Wu, Jia and Yang, Jian and Vong, Chi Man},
title = {DAliM: Machine Learning Based Intelligent Lucky Money Determination for Large-Scale E-Commerce Businesses},
year = {2018},
isbn = {978-3-030-03595-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-03596-9_53},
doi = {10.1007/978-3-030-03596-9_53},
abstract = {E-commerce businesses compete in the market by conducting marketing strategies consisting of four aspects: customers, products, marketplaces and intermediaries. One of the widely-used marketing strategies, called Lucky Money, is capable of encouraging customers to buy products from marketplaces. However, the amount of luck money for each customer is usually randomly determined or even manually determined and cannot fully achieve the business objectives. This paper proposes a machine-learning based lucky money determination approach, called DAliM, for e-commerce businesses to achieve their desired goals. We implement DAliM for the “Double 11 Global Shopping Festival 2017” initiated by Alibaba Group and evaluate it using a few hundred million real customers from all over the world. The experimental results demonstrate that our method manages to decrease the lucky money spent by 41.71% and increase the final purchase rate by 24.94% compared to the state-of-the-art baseline.},
booktitle = {Service-Oriented Computing: 16th International Conference, ICSOC 2018, Hangzhou, China, November 12-15, 2018, Proceedings},
pages = {740–755},
numpages = {16},
keywords = {Machine learning, Lucky money, E-commerce, Data mining, Price prediction, Price optimization},
location = {Hangzhou, China}
}

@article{10.1145/3415219,
author = {Halfaker, Aaron and Geiger, R. Stuart},
title = {ORES: Lowering Barriers with Participatory Machine Learning in Wikipedia},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW2},
url = {https://doi.org/10.1145/3415219},
doi = {10.1145/3415219},
abstract = {Algorithmic systems---from rule-based bots to machine learning classifiers---have a long history of supporting the essential work of content moderation and other curation work in peer production projects. From counter-vandalism to task routing, basic machine prediction has allowed open knowledge projects like Wikipedia to scale to the largest encyclopedia in the world, while maintaining quality and consistency. However, conversations about how quality control should work and what role algorithms should play have generally been led by the expert engineers who have the skills and resources to develop and modify these complex algorithmic systems. In this paper, we describe ORES: an algorithmic scoring service that supports real-time scoring of wiki edits using multiple independent classifiers trained on different datasets. ORES decouples several activities that have typically all been performed by engineers: choosing or curating training data, building models to serve predictions, auditing predictions, and developing interfaces or automated agents that act on those predictions. This meta-algorithmic system was designed to open up socio-technical conversations about algorithms in Wikipedia to a broader set of participants. In this paper, we discuss the theoretical mechanisms of social change ORES enables and detail case studies in participatory machine learning around ORES from the 5 years since its deployment.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {148},
numpages = {37},
keywords = {algorithms, fairness, governance, machine learning, reflection, transparency, wikipedia}
}

@article{10.1016/j.eswa.2018.02.022,
author = {Srinivas, Sharan and Ravindran, A. Ravi},
title = {Optimizing outpatient appointment system using machine learning algorithms and scheduling rules},
year = {2018},
issue_date = {July 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {102},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.02.022},
doi = {10.1016/j.eswa.2018.02.022},
abstract = {Developed prescriptive analytics framework to schedule patients in real-time.Used machine learning to classify patients based on their no-show risk.Proposed scheduling rules by simultaneously considering multiple design decisions.Results provide insights on patient sequencing and overbooking decisions.Helps clinicians to move towards customized, patient-centered care. In the US, the demand for outpatient services is expected to increase, while the supply of physicians to provide the care is projected to decrease. Besides, inefficiencies in the appointment system (AS) and patient no-shows (patients who do not arrive for scheduled appointments) reduce provider productivity, timely access to care, and cost the U.S. healthcare system more than $150 billion a year. To handle increasing demand and compensate for patient no-shows, outpatient clinics tend to overbook appointments. The current scheduling practice at most clinics and majority of the scheduling rules proposed in the literature assume all patients are equally likely to miss an appointment. Further, most scheduling rules in the literature do not make use of the available data, such as electronic health records, when scheduling patients. This paper proposes a prescriptive analytics framework to improve the performance of an AS with respect to patient satisfaction (measured using average patient waiting time and number of patients unable to get an appointment for the day under consideration) and resource utilization (measured using average resource idle time, overflow time and overtime). In the proposed framework, patient-related data from various sources are used to develop predictive models that identify the risk of a patient no-show. Different scheduling rules, that leverage the patient-specific no-show risk is then proposed. A case study, with real data from a Family Medicine Clinic in Pennsylvania, is used to show the feasibility of the proposed framework. The effectiveness of the proposed scheduling rules is evaluated by benchmarking it with three rules adapted from the literature. The results indicate that the proposed scheduling rules consistently outperform the benchmark rules for all the clinic settings tested. Further, the proposed framework is generic and can be adopted by any outpatient clinic characterized by occurrences of no-shows and appointment-based customer arrivals.},
journal = {Expert Syst. Appl.},
month = jul,
pages = {245–261},
numpages = {17},
keywords = {Machine learning, Patient scheduling, Patient-specific no-shows, Prescriptive analytics, Sequential scheduling rules}
}

@article{10.1007/s10115-012-0528-3,
author = {Anchuri, Pranay and Zaki, Mohammed J. and Barkol, Omer and Bergman, Ruth and Felder, Yifat and Golan, Shahar and Sityon, Arik},
title = {Graph mining for discovering infrastructure patterns in configuration management databases},
year = {2012},
issue_date = {Dec 2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-012-0528-3},
doi = {10.1007/s10115-012-0528-3},
abstract = {A configuration management database (CMDB) can be considered to be a large graph representing the IT infrastructure entities and their interrelationships. Mining such graphs is challenging because they are large, complex, and multi-attributed and have many repeated labels. These characteristics pose challenges for graph mining algorithms, due to the increased cost of subgraph isomorphism (for support counting) and graph isomorphism (for eliminating duplicate patterns). The notion of pattern frequency or support is also more challenging in a single graph, since it has to be defined in terms of the number of its (potentially, exponentially many) embeddings. We present CMDB-Miner, a novel two-step method for mining infrastructure patterns from CMDB graphs. It first samples the set of maximal frequent patterns and then clusters them to extract the representative infrastructure patterns. We demonstrate the effectiveness of CMDB-Miner on real-world CMDB graphs, as well as synthetic graphs.},
journal = {Knowl. Inf. Syst.},
month = dec,
pages = {491–522},
numpages = {32},
keywords = {Configuration management databases, Frequent subgraphs, Single graph mining, Sparse graph mining}
}

@article{10.1016/j.procs.2019.12.133,
author = {Rahouma, Kamel H. and Ali, Ayman},
title = {Applying Machine Learning Technology to Optimize the Operational Cost of the Egyptian Optical Network},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {163},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.12.133},
doi = {10.1016/j.procs.2019.12.133},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {502–517},
numpages = {16},
keywords = {Machine Learning Technology, Optical Network, Operational Cost, Intelligent Universal Platform}
}

@inproceedings{10.1109/ASE.2009.90,
author = {Nguyen, Tung Thanh and Nguyen, Hoan Anh and Pham, Nam H. and Al-Kofahi, Jafar M. and Nguyen, Tien N.},
title = {Clone-Aware Configuration Management},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.90},
doi = {10.1109/ASE.2009.90},
abstract = {Recent research results show several benefits of the management of code clones. In this paper, we introduce Clever, a novel clone-aware software configuration management (SCM) system. In addition to traditional SCM functionality, Clever provides clone management support, including clone detection and update, clone change management, clone consistency validating, clone synchronizing, and clone merging. Clever represents source code and clones as (sub)trees in Abstract Syntax Trees (ASTs), measures code similarity based on structural characteristic vectors, and describes code changes as tree editing scripts. The key techniques of Clever include the algorithms to compute tree editing scripts; to detect and update code clones and their groups; and to analyze the changes of cloned code to validate their consistency and recommend the relevant synchronization. Our empirical study on many real-world programs shows that Clever is highly efficient and accurate in clone detection and updating, and provides useful analysis of clone changes.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {123–134},
numpages = {12},
keywords = {clone editing consistency, clone management, clone synchronization, clone-aware, tree edit},
series = {ASE '09}
}

@article{10.1007/s00530-020-00743-9,
author = {Pundir, Sumit and Obaidat, Mohammad S. and Wazid, Mohammad and Das, Ashok Kumar and Singh, Devesh Pratap and Rodrigues, Joel J. P. C.},
title = {MADP-IIME: malware attack detection protocol in IoT-enabled industrial multimedia environment using machine learning approach},
year = {2021},
issue_date = {Jun 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {29},
number = {3},
issn = {0942-4962},
url = {https://doi.org/10.1007/s00530-020-00743-9},
doi = {10.1007/s00530-020-00743-9},
abstract = {Internet of Things (IoT) is one of the fastest-growing technologies. With the deployment of massive and faster mobile networks, almost every daily-use item is connected to the Internet. IoT-enabled industrial multimedia environment is used for the collection and analysis of different types of multimedia data (i.e., images, videos, audios, etc.). This multimedia data is generated by various types of smart devices like drones, robots, smart controller, smart surveillance system which are deployed for the industrial monitoring and control. The multimedia data is generated in the enormous amount which can be considered as the big data. This data is further utilized in various types of business needs for example, chances of fire accidents in the industrial plant, overall machine health, etc., which can be predicted through the application of big data analytics. Therefore, IoT-enabled industrial multimedia environment is very helpful to the concerned authorities as they come to know the important information in advance. However, all the smart devices are connected and controlled through the Internet. It further causes severe threats to the communication happens in an IoT-enabled industrial multimedia environment. It is vulnerable to various types of attacks such as replay, man-in-the-middle, impersonation, secret information leakage, sensitive information modification, and malware injection (i.e., mirai). Therefore, it is important to prevent the communication of such an environment against the different types of possible attacks. These days, the attacks performed by botnets (i.e., malware attacks such as mirai and reaper) have drawn attention to the researchers. Under the influence of such attacks, the communication of IoT-enabled industrial multimedia environment is disrupted. Moreover, the attackers may also control the smart devices remotely and can change their functionalities. Hence, we need some robust mechanism to detect the presence of the malware attacks in such an environment. In this paper, we propose a malware detection mechanism in IoT-enabled industrial multimedia environment with the help of machine-learning approach, which is named as MADP-IIME. MADP-IIME uses four different types of machine learning methods (i.e., naive bayes, logistic regression, artificial neural networks (ANN) and random forest) to detect the presence of malware attacks successfully. Furthermore, MADP-IIME performs better than other related existing schemes and achieves 99.5% detection and 0.5% false positive rate. In addition, the conducted security analysis proves the resilience of the proposed MADP-IIME against different types of malware attacks.},
journal = {Multimedia Syst.},
month = jan,
pages = {1785–1797},
numpages = {13},
keywords = {Internet of Things (IoT), Industrial multimedia environment, Security, Malware detection, Machine learning, Simulation}
}

@article{10.1016/j.procs.2021.10.050,
author = {Barabanova, Irina V. and Vychuzhanin, Pavel and Nikitin, Nikolay O.},
title = {Sensitivity Analysis of the Composite Data-Driven Pipelines in the Automated Machine Learning},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {193},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.10.050},
doi = {10.1016/j.procs.2021.10.050},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {484–493},
numpages = {10},
keywords = {sensitivity analysis, AutoML, composite models}
}

@inproceedings{10.1145/3460418.3479386,
author = {Kojima, Ryoichi and Legaspi, Roberto and Mishima, Yutaro and Wada, Shinya},
title = {Classical machine learning and deep neural network ensemble model for GPS-based activity recognition},
year = {2021},
isbn = {9781450384612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460418.3479386},
doi = {10.1145/3460418.3479386},
abstract = {Our KDDI Research team proposes an ensemble model for the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge using GPS data. During preprocessing, we corrected the GPS dataset that contains errors and missing values using a Kalman smoother. Since this smoother can be processed offline, it can be used to correct backforward using the recorded future locations in the dataset. Further, by using features that have similar distributions in the train subject’s data and the other subjects’ datasets, we could achieve robust feature selection across multiple subjects. The first stage of our ensemble model employs classical machine learning and deep neural network approaches independently, specifically, LightGBM and LSTM, respectively. The second stage calculates the weighted average of the outputs of both approaches. Our results show the improved accuracy contributed by our ensemble, suggesting that it effectively makes use of both statistical and non-statistical features given the suitable base models. We confirmed that the use of Kalman-smoother, selection of features with similar distributions across subjects and ensemble modeling contributed to improving the accuracy of both train and validation datasets.},
booktitle = {Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
pages = {369–373},
numpages = {5},
keywords = {Kalman-smoother, Locomotion activity recognition, deep neural networks, lightgbm},
location = {Virtual, USA},
series = {UbiComp/ISWC '21 Adjunct}
}

@inproceedings{10.1007/978-3-030-45371-8_3,
author = {Shirazi, Hossein and Ray, Indrakshi and Anderson, Charles},
title = {Using Machine Learning to Detect Anomalies in Embedded Networks in&nbsp;Heavy Vehicles},
year = {2019},
isbn = {978-3-030-45370-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-45371-8_3},
doi = {10.1007/978-3-030-45371-8_3},
abstract = {Modern automobiles have more than 70 electronic control units (ECUs) and 100 million lines of code to improve safety, fuel economy, performance, durability, user experience, and to reduce emissions. Automobiles are becoming increasingly interconnected with the outside world. Consequently, modern day automobiles are becoming more prone to cyber security attacks. Towards this end, we present an approach that uses machine learning to detect abnormal behavior, including malicious ones, on embedded networks in heavy vehicles. Our modular algorithm uses machine learning approaches on the internal network traffic in heavy vehicles to generate warning alarms in real-time. We tested our hypothesis on five separate data logs that characterize the operations of heavy vehicles having different specifications under varying driving conditions. We report a malicious detection rate of 98–99% and a mean accuracy rate of 96–99% across all experiments using five-fold cross-validation. Our analysis also shows that with a small subset of hand-crafted features, the complex dynamic behavior of heavy vehicle ECUs can be predicted and classified as normal or abnormal.},
booktitle = {Foundations and Practice of Security: 12th International Symposium, FPS 2019, Toulouse, France, November 5–7, 2019, Revised Selected Papers},
pages = {39–55},
numpages = {17},
keywords = {Anomaly detection, SAE-J1939, Heavy vehicle security},
location = {Toulouse, France}
}

@inproceedings{10.1145/3400302.3415614,
author = {Huang, Xuan-Xue and Chen, Hsien-Chia and Wang, Sheng-Wei and Jiang, Iris Hui-Ru and Chou, Yih-Chih and Tsai, Cheng-Hong},
title = {Dynamic IR-drop ECO optimization by cell movement with current waveform staggering and machine learning guidance},
year = {2020},
isbn = {9781450380263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3400302.3415614},
doi = {10.1145/3400302.3415614},
abstract = {Excessive dynamic IR-drop degrades the circuit performance and may lead to functional failure. Existing IR-drop fixing techniques at the placement stage do not consider the time-variant property and thus cannot handle dynamic IR-drop hotspots well. In current practice, designers perform Engineer Change Order (ECO) to move out these hotspot cells based on their experience. In this paper, we present a novel dynamic IR-drop ECO optimization and prediction framework by wise cell movement. We first spread high demand current cells in a global view to stagger their current waveforms. Then, we further move IR hotspot cells close to power/ground (PG) vias for minimizing the resistance from PG pads to their PG pins. Moreover, we propose an accurate machine learning-based dynamic IR-drop prediction model to guide the final cell movement. The features of our model capture power ground network characteristics, timing information, and cumulative current drawn by cells, thus leading to a general model applicable to ECO. Experimental results show that our proposed model precisely predicts dynamic IR-drop after cell movement, and our optimization scheme can substantially alleviate dynamic IR-drop without timing degradation.},
booktitle = {Proceedings of the 39th International Conference on Computer-Aided Design},
articleno = {156},
numpages = {9},
keywords = {ECO, IR-drop, detailed placement, machine learning},
location = {Virtual Event, USA},
series = {ICCAD '20}
}

@article{10.1016/j.eswa.2021.114846,
author = {Caglar Gencosman, Burcu and undefinednkaya, T\"{u}lin},
title = {Characterization of Syrian refugees with work permit applications in Turkey: A data mining based methodology},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114846},
doi = {10.1016/j.eswa.2021.114846},
journal = {Expert Syst. Appl.},
month = oct,
numpages = {25},
keywords = {Data mining, Self-organizing maps, Decision tree, Association rule mining, Syrian refugees}
}

@article{10.1109/TCBB.2021.3099068,
author = {Manduchi, Elisabetta and Le, Trang T. and Fu, Weixuan and Moore, Jason H.},
title = {Genetic Analysis of Coronary Artery Disease Using Tree-Based Automated Machine Learning Informed By Biology-Based Feature Selection},
year = {2021},
issue_date = {May-June 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3099068},
doi = {10.1109/TCBB.2021.3099068},
abstract = {Machine Learning (ML) approaches are increasingly being used in biomedical applications. Important challenges of ML include choosing the right algorithm and tuning the parameters for optimal performance. Automated ML (AutoML) methods, such as Tree-based Pipeline Optimization Tool (TPOT), have been developed to take some of the guesswork out of ML thus making this technology available to users from more diverse backgrounds. The goals of this study were to assess applicability of TPOT to genomics and to identify combinations of single nucleotide polymorphisms (SNPs) associated with coronary artery disease (CAD), with a focus on genes with high likelihood of being good CAD drug targets. We leveraged public functional genomic resources to group SNPs into biologically meaningful sets to be selected by TPOT. We applied this strategy to data from the U.K. Biobank, detecting a strikingly recurrent signal stemming from a group of 28 SNPs. Importance analysis of these SNPs uncovered functional relevance of the top SNPs to genes whose association with CAD is supported in the literature and other resources. Furthermore, we employed game-theory based metrics to study SNP contributions to individual-level TPOT predictions and discover distinct clusters of well-predicted CAD cases. The latter indicates a promising approach towards precision medicine.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jul,
pages = {1379–1386},
numpages = {8}
}

@inproceedings{10.1145/2517288.2517294,
author = {Li, Jiefei and Liang, Xiaocong and Ding, Weijie and Yang, Weidong and Pan, Rong},
title = {Feature engineering and tree modeling for author-paper identification challenge},
year = {2013},
isbn = {9781450324953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517288.2517294},
doi = {10.1145/2517288.2517294},
abstract = {The ability to search literature and collect/aggregate metrics around publications is a central tool for modern research. Both academic and industry researchers across hundreds of scientific disciplines, from astronomy to zoology, increasingly rely on search to understand what has been published and by whom. Microsoft Academic Search is an open platform, which provides a variety of metrics and experiences for the research community, in addition to literature search. As the covering data came from many sources, the profile of an author with an ambiguous name tends to contain noise, resulting in papers that are incorrectly assigned to others. KDD Cup 2013 Track 1 challenges participants to determine which papers in an author profile were truly written by the given author.In this work, we present how to use tree-base models to accurately predict the paper author. We incorporate feature engineering into the models with the advantages of them. This paper introduces two kinds of tree-base models (GB-DT [4], RGF [5]) and presents in detail the learning algorithm and how features can be generated for the task. The experimental results show the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 2013 KDD Cup 2013 Workshop},
articleno = {5},
numpages = {8},
keywords = {ensemble tree model, feature engineering},
location = {Chicago, Illinois},
series = {KDD Cup '13}
}

@inproceedings{10.1007/978-3-030-58309-5_21,
author = {Wr\'{o}bel, Anna and Gygax, Gregory and Schmid, Andi and Ott, Thomas},
title = {Going for 2D or 3D? Investigating Various Machine Learning Approaches for Peach Variety Identification},
year = {2020},
isbn = {978-3-030-58308-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58309-5_21},
doi = {10.1007/978-3-030-58309-5_21},
abstract = {Machine learning-based pattern recognition methods are about to revolutionize the farming sector. For breeding and cultivation purposes, the identification of plant varieties is a particularly important problem that involves specific challenges for the different crop species. In this contribution, we consider the problem of peach variety identification for which alternatives to DNA-based analysis are being sought. While a traditional procedure would suggest using manually designed shape descriptors as the basis for classification, the technical developments of the last decade have opened up possibilities for fully automated approaches, either based on 3D scanning technology or by employing deep learning methods for 2D image classification. In our feasibility study, we investigate the potential of various machine learning approaches with a focus on the comparison of methods based on 2D images and 3D scans. We provide and discuss first results, paving the way for future use of the methods in the field.},
booktitle = {Artificial Neural Networks in Pattern Recognition: 9th IAPR TC3 Workshop, ANNPR 2020, Winterthur, Switzerland, September 2–4, 2020, Proceedings},
pages = {257–265},
numpages = {9},
keywords = {Peach variety identification, ML classification, 3D scans},
location = {Winterthur, Switzerland}
}

@inproceedings{10.1007/978-3-030-29387-1_34,
author = {Wall, Emily and Ghorashi, Soroush and Ramos, Gonzalo},
title = {Using Expert Patterns in Assisted Interactive Machine Learning: A Study in Machine Teaching},
year = {2019},
isbn = {978-3-030-29386-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29387-1_34},
doi = {10.1007/978-3-030-29387-1_34},
abstract = {Machine Teaching (MT) is an emerging practice where people, without Machine Learning (ML) expertise, provide rich information beyond labels in order to create ML models. MT promises to lower the barrier of entry to creating ML models by requiring a softer set of skills from users than having ML expertise. In this paper, we explore and show how end-users without MT experience successfully build ML models using the MT process, and achieve results not far behind those of MT experts. We do this by conducting two studies. We first investigated how MT experts build models, from which we extracted expert teaching patterns. In our second study, we observed end-users without MT experience create ML models with and without guidance from expert patterns. We found that all users built models comparable to those built by MT experts. Further, we observed that users who received guidance perceived the task to require less effort and felt less mental demand than those who did not receive guidance.},
booktitle = {Human-Computer Interaction – INTERACT 2019: 17th IFIP TC 13 International Conference, Paphos, Cyprus, September 2–6, 2019, Proceedings, Part III},
pages = {578–599},
numpages = {22},
keywords = {Interactive machine learning, Machine Teaching, User studies},
location = {Paphos, Cyprus}
}

@article{10.5555/2010978.2010987,
author = {Halkidi, M. and Spinellis, D. and Tsatsaronis, G. and Vazirgiannis, M.},
title = {Data mining in software engineering},
year = {2011},
issue_date = {August 2011},
publisher = {IOS Press},
address = {NLD},
volume = {15},
number = {3},
issn = {1088-467X},
abstract = {The increased availability of data created as part of the software development process allows us to apply novel analysis techniques on the data and use the results to guide the process's optimization. In this paper we describe various data sources and discuss the principles and techniques of data mining as applied on software engineering data. Data that can be mined is generated by most parts of the development process: requirements elicitation, development analysis, testing, debugging, and maintenance. Based on this classification we survey the mining approaches that have been used and categorize them according to the corresponding parts of the development process and the task they assist. Thus the survey provides researchers with a concise overview of data mining techniques applied to software engineering data, and aids practitioners on the selection of appropriate data mining techniques for their work.},
journal = {Intell. Data Anal.},
month = aug,
pages = {413–441},
numpages = {29},
keywords = {Data mining techniques, KDD methods, mining software engineering data}
}

@article{10.1145/3337930,
author = {Al-Hyari, Abeer and Abuowaimer, Ziad and Martin, Timothy and Gr\'{e}wal, Gary and Areibi, Shawki and Vannelli, Anthony},
title = {Novel Congestion-estimation and Routability-prediction Methods based on Machine Learning for Modern FPGAs},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1936-7406},
url = {https://doi.org/10.1145/3337930},
doi = {10.1145/3337930},
abstract = {Effectively estimating and managing congestion during placement can save substantial placement and routing runtime. In this article, we present a machine-learning model for accurately and efficiently estimating congestion during FPGA placement. Compared with the state-of-the-art machine-learning congestion-estimation model, our results show a 25% improvement in prediction accuracy. This makes our model competitive with congestion estimates produced using a global router. However, our model runs, on average, 291\texttimes{} faster than the global router. Overall, we are able to reduce placement runtimes by 17% and router runtimes by 19%. An additional machine-learning model is also presented that uses the output of the first congestion-estimation model to determine whether or not a placement is routable. This second model has an accuracy in the range of 93% to 98%, depending on the classification algorithm used to implement the learning model, and runtimes of a few milliseconds, thus making it suitable for inclusion in any placer with no worry of additional computational overhead.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = aug,
articleno = {16},
numpages = {25},
keywords = {Congestion estimation, Xilinx UltraScale FPGA, machine learning, routability prediction}
}

@inproceedings{10.1145/3377325.3377501,
author = {Drozdal, Jaimie and Weisz, Justin and Wang, Dakuo and Dass, Gaurav and Yao, Bingsheng and Zhao, Changruo and Muller, Michael and Ju, Lin and Su, Hui},
title = {Trust in AutoML: exploring information needs for establishing trust in automated machine learning systems},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377501},
doi = {10.1145/3377325.3377501},
abstract = {We explore trust in a relatively new area of data science: Automated Machine Learning (AutoML). In AutoML, AI methods are used to generate and optimize machine learning models by automatically engineering features, selecting models, and optimizing hyperparameters. In this paper, we seek to understand what kinds of information influence data scientists' trust in the models produced by AutoML? We operationalize trust as a willingness to deploy a model produced using automated methods. We report results from three studies - qualitative interviews, a controlled experiment, and a card-sorting task - to understand the information needs of data scientists for establishing trust in AutoML systems. We find that including transparency features in an AutoML tool increased user trust and understandability in the tool; and out of all proposed features, model performance metrics and visualizations are the most important information to data scientists when establishing their trust with an AutoML tool.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {297–307},
numpages = {11},
keywords = {AutoAI, AutoDS, AutoML, automated artificial intelligence, automated data science, automated machine learning, trust},
location = {Cagliari, Italy},
series = {IUI '20}
}

@article{10.1016/j.neucom.2012.01.030,
author = {Ortigosa-Hern\'{a}ndez, Jonathan and Rodr\'{\i}guez, Juan Diego and Alzate, Leandro and Lucania, Manuel and Inza, I\~{n}aki and Lozano, Jose A.},
title = {Approaching Sentiment Analysis by using semi-supervised learning of multi-dimensional classifiers},
year = {2012},
issue_date = {September, 2012},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2012.01.030},
doi = {10.1016/j.neucom.2012.01.030},
abstract = {Sentiment Analysis is defined as the computational study of opinions, sentiments and emotions expressed in text. Within this broad field, most of the work has been focused on either Sentiment Polarity classification, where a text is classified as having positive or negative sentiment, or Subjectivity classification, in which a text is classified as being subjective or objective. However, in this paper, we consider instead a real-world problem in which the attitude of the author is characterised by three different (but related) target variables: Subjectivity, Sentiment Polarity, Will to Influence, unlike the two previously stated problems, where there is only a single variable to be predicted. For that reason, the (uni-dimensional) common approaches used in this area yield to suboptimal solutions to this problem. Somewhat similar happens with multi-label learning techniques which cannot directly tackle this problem. In order to bridge this gap, we propose, for the first time, the use of the novel multi-dimensional classification paradigm in the Sentiment Analysis domain. This methodology is able to join the different target variables in the same classification task so as to take advantage of the potential statistical relations between them. In addition, and in order to take advantage of the huge amount of unlabelled information available nowadays in this context, we propose the extension of the multi-dimensional classification framework to the semi-supervised domain. Experimental results for this problem show that our semi-supervised multi-dimensional approach outperforms the most common Sentiment Analysis approaches, concluding that our approach is beneficial to improve the recognition rates for this problem, and in extension, could be considered to solve future Sentiment Analysis problems.},
journal = {Neurocomput.},
month = sep,
pages = {98–115},
numpages = {18},
keywords = {EM algorithm, Multi-dimensional class Bayesian network classifiers, Multi-dimensional classification, Semi-supervised learning, Sentiment Analysis}
}

@inproceedings{10.5555/1753235.1753241,
author = {John, Isabel and Eisenbarth, Michael},
title = {A decade of scoping: a survey},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Scoping can be defined as the process of deciding in which parts of an organization's products, features and domains systematic reuse is economically useful. It generally is the first phase in product line engineering. For a decade now scoping has been recognized as a discipline of it's own in product line engineering. So it's time to look at what has been done in scoping in the last years and what is still to be done. In this survey, we identify and characterize existing scoping approaches with the main goal to derive open areas and research questions for further research in scoping. We analyze and compare existing approaches and derive open and partially addressed research questions that can be tackled by researchers in product line engineering in the next years.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {31–40},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.5555/1753235.1753266,
author = {Hubaux, Arnaud and Classen, Andreas and Heymans, Patrick},
title = {Formal modelling of feature configuration workflows},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {In software product line engineering, the configuration process can be a long and complex undertaking that involves many participants. When configuration is supported by feature diagrams, two challenges are to modularise the feature diagram into related chunks, and to schedule them as part of the configuration process. Existing work has only focused on the first of these challenges and, for the rest, assumes that feature diagram modules are configured sequentially. This paper addresses the second challenge. It suggests using YAWL, a state-of-the-art workflow language, to represent the configuration workflow while feature diagrams model the available configuration options. The principal contribution of the paper is a new combined formalism: feature configuration workflows. A formal semantics is provided so as to pave the way for unambiguous tool specification and safer reasoning about of the configuration process. The work is motivated and illustrated through a configuration scenario taken from the space industry.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {221–230},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.1145/3332186.3332209,
author = {Vento, Davide Del and Fanfarillo, Alessandro},
title = {Traps, Pitfalls and Misconceptions of Machine Learning applied to Scientific Disciplines},
year = {2019},
isbn = {9781450372275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3332186.3332209},
doi = {10.1145/3332186.3332209},
abstract = {In the last decade, Machine Learning has experienced a dramatic increase in performance on a wide variety of tasks, including computer vision, speech recognition, text parsing, and language translation, just to name a few. This has corresponded to an understandable hype especially for the remarkable results achieved in some cases. Therefore, practitioners of Scientific Disciplines have become interested in utilizing new Machine Learning techniques, and have sometimes started doing so with mixed success.The purpose of this paper is to describe some of the common Traps, Pitfalls and Misconceptions of Machine Learning as relevant to the Scientific Discipline, and how to avoid them. In fact, Machine Learning and Deep Learning are fast evolving fields, and some of the astonishing results achieved recently sit on small but important details which have become the state of the art. Some of these details are not broadly known by the scientific community. No new scientific result is presented in this paper, which is a survey and a summary of the best of the field, for the benefit of researchers with limited experience.It is not the intention of the authors to provide any criticism to the work of experienced practitioners, particularly not to the ones working on the cutting edge of what is currently possible: in these cases expert researchers may well be doing exactly what we recommend here to avoid, and for a good reason. However we believe that the advice provided here will be useful, and perhaps even a reference, for the newcomers of the field.},
booktitle = {Practice and Experience in Advanced Research Computing 2019: Rise of the Machines (Learning)},
articleno = {75},
numpages = {8},
location = {Chicago, IL, USA},
series = {PEARC '19}
}

@article{10.1007/s11042-019-07814-8,
author = {Maiti, Ananjan and Chatterjee, Biswajoy},
title = {Improving detection of Melanoma and Naevus with deep neural networks},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {21–22},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-019-07814-8},
doi = {10.1007/s11042-019-07814-8},
abstract = {Machines can acknowledge the images of skin lesion as well as the disease compared to an experienced dermatologist. These might be executed by giving a proper label for the provided images of skin lesion. Within the proposed study researchers have examined various frameworks for detection of skin cancer as well as classification of melanoma. The current research includes a unique image pre-processing technique and modification of the image followed by image segmentation. The 23 texture and ten shape features of the dataset are further refined with feature engineering techniques. The improved dataset has been processed inside a Deep Neural Network models by binary cross-entropy. The dataset passes through several mixes of multiple activation layers with varying features and optimization techniques. As an outcome of the study, researchers have selected a useful, timesaving model to find an image as melanoma or even naevus. The model was evaluated with 170 images of MED NODE and 2000 images of ISIC dataset. This improved framework achieves a favorable accuracy of 96.8% with few noticeable epochs which concern other 12 machine learning models and five deep learning models. In the future, certainly there can be an investigation with several classes of skin cancer with an improved dataset.},
journal = {Multimedia Tools Appl.},
month = jun,
pages = {15635–15654},
numpages = {20},
keywords = {Melanoma classification, Supervised machine learning, Image preprocessing, Feature engineering, Segmentation, Artificial intelligence, Deep neural network}
}

@inproceedings{10.1145/2635868.2635919,
author = {Cordy, Maxime and Heymans, Patrick and Legay, Axel and Schobbens, Pierre-Yves and Dawagne, Bruno and Leucker, Martin},
title = {Counterexample guided abstraction refinement of product-line behavioural models},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635919},
doi = {10.1145/2635868.2635919},
abstract = {The model-checking problem for Software Products Lines (SPLs) is harder than for single systems: variability constitutes a new source of complexity that exacerbates the state-explosion problem. Abstraction techniques have successfully alleviated state explosion in single-system models. However, they need to be adapted to SPLs, to take into account the set of variants that produce a counterexample. In this paper, we apply CEGAR (Counterexample-Guided Abstraction Refinement) and we design new forms of abstraction specifically for SPLs. We carry out experiments to evaluate the efficiency of our new abstractions. The results show that our abstractions, combined with an appropriate refinement strategy, hold the potential to achieve large reductions in verification time, although they sometimes perform worse. We discuss in which cases a given abstraction should be used.},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {190–201},
numpages = {12},
keywords = {Abstraction, CEGAR, Model Checking, Software Product Lines},
location = {Hong Kong, China},
series = {FSE 2014}
}

@article{10.1007/s42979-021-00815-1,
author = {Sarker, Iqbal H.},
title = {Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
url = {https://doi.org/10.1007/s42979-021-00815-1},
doi = {10.1007/s42979-021-00815-1},
abstract = {Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of today’s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics,&nbsp;cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals.},
journal = {SN Comput. Sci.},
month = aug,
numpages = {20},
keywords = {Deep learning, Artificial neural network, Artificial intelligence, Discriminative learning, Generative learning, Hybrid learning, Intelligent systems}
}

@inproceedings{10.1007/978-3-030-86271-8_46,
author = {Baldo, Alessandro and Cuzzocrea, Alfredo and Fadda, Edoardo and Bringas, Pablo G.},
title = {Financial Forecasting via Deep-Learning and Machine-Learning Tools over Two-Dimensional Objects Transformed from Time Series},
year = {2021},
isbn = {978-3-030-86270-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86271-8_46},
doi = {10.1007/978-3-030-86271-8_46},
abstract = {In this study, we propose a deeper analysis on the algorithmic treatment of financial time series, with a focus on Forex markets’ applications. The relevant aspects of the paper refers to a more beneficial data arrangement, proposed into a two-dimensional objects and to the application of a Temporal Convolutional Neural Network model, representing a more than valid alternative to Recurrent Neural Networks. The results are supported by expanding the comparison to other more consolidated deep learning models, as well as with some of the most performing Machine Learning methods. Finally, a financial framework is proposed to test the real effectiveness of the algorithms.},
booktitle = {Hybrid Artificial Intelligent Systems: 16th International Conference, HAIS 2021, Bilbao, Spain, September 22–24, 2021, Proceedings},
pages = {550–563},
numpages = {14},
location = {Bilbao, Spain}
}

@inproceedings{10.1145/3342195.3387530,
author = {Gong, Liangyi and Li, Zhenhua and Qian, Feng and Zhang, Zifan and Chen, Qi Alfred and Qian, Zhiyun and Lin, Hao and Liu, Yunhao},
title = {Experiences of landing machine learning onto market-scale mobile malware detection},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387530},
doi = {10.1145/3342195.3387530},
abstract = {App markets, being crucial and critical for today's mobile ecosystem, have also become a natural malware delivery channel since they actually "lend credibility" to malicious apps. In the past decade, machine learning (ML) techniques have been explored for automated, robust malware detection. Unfortunately, to date, we have yet to see an ML-based malware detection solution deployed at market scales. To better understand the real-world challenges, we conduct a collaborative study with a major Android app market (T-Market) offering us large-scale ground-truth data. Our study shows that the key to successfully developing such systems is manifold, including feature selection/engineering, app analysis speed, developer engagement, and model evolution. Failure in any of the above aspects would lead to the "wooden barrel effect" of the entire system. We discuss our careful design choices as well as our first-hand deployment experiences in building such an ML-powered malware detection system. We implement our design and examine its effectiveness in the T-Market for over one year, using a single commodity server to vet ~ 10K apps every day. The evaluation results show that this design achieves an overall precision of 98% and recall of 96% with an average per-app scan time of 1.3 minutes.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {2},
numpages = {14},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{10.1145/3331453.3361679,
author = {Liang, Tong and Feng, Qisheng and Ge, Jing and Xie, Hongjie and Liang, Tiangang},
title = {Assessment of Machine Learning Methods for Modeling Alpine Grassland Biomass in Southern Qinghai Province, China},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331453.3361679},
doi = {10.1145/3331453.3361679},
abstract = {Accurate and effective modeling of grassland aboveground biomass (AGB) is an important basic task in monitoring and management of grassland and livestock interaction in pastoral areas. In this study, three machine learning methods, multi-layer perceptron network (MLP), support vector regression, and random forest regression (RF) are assessed for modeling the grassland AGB in the southern region, Qinghai Province, China. The results show that: 1) among the three methods, the MLP model performs the worst, with R2 and RMSE of 0.38 and 768.74 kg DW/ha, respectively for the test data, and of 0.34 and 745.06 kg DW/ha for the training dataset; 2) the RF model performs the best, with R2 and RMSE of 0.76 and 473.20 kg DW/ha, respectively for the test data, and of 0.95 and 208.88 kg DW/ha for the training dataset. This performance is similar to the best back propagation ANN model previously reported (0.66 and 556.57 kg DW/ha for test data, 0.85 and 355.04 kg DW/ha for training data, and 0.68 and 537.09 kg DW/ha for validation). The RF model is easy to apply in practice and is a robust tool for modeling grassland biomass based on DEM and remote sensing data.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {77},
numpages = {5},
keywords = {Aboveground biomass, Multi-layer perceptron, Random forest regression, Remote sensing, Support vector regression},
location = {Sanya, China},
series = {CSAE '19}
}

@article{10.1145/3439189,
author = {Alam, Manaar and Bhattacharya, Sarani and Mukhopadhyay, Debdeep},
title = {Victims Can Be Saviors: A Machine Learning--based Detection for Micro-Architectural Side-Channel Attacks},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3439189},
doi = {10.1145/3439189},
abstract = {Micro-architectural side-channel attacks are major threats to the most mathematically sophisticated encryption algorithms. In spite of the fact that there exist several defense techniques, the overhead of implementing the countermeasures remains a matter of concern. A promising strategy is to develop online detection and prevention methods for these attacks. Though some recent studies have devised online prevention mechanisms for some categories of these attacks, still other classes remain undetected. Moreover, to detect these side-channel attacks with minimal False Positives is a challenging effort because of the similarity of their behavior with computationally intensive applications. This article presents a generalized machine learning--based multi-layer detection technique that targets these micro-architectural side-channel attacks, while not restricting its attention only on a single category of attacks. The proposed mechanism gathers low-level system information by profiling performance counter events using Linux perf tool and then applies machine learning techniques to analyze the data. A novel approach using time-series analysis of the data is implemented to find out the correlation of the execution trace of the attack process with the secret key of encryption, which helps in dealing with False-Positives and unknown attacks. This article also provides a detailed theoretical analysis of the detection mechanism of the proposed model along with its security analysis. The experimental results show that the proposed method is superior to the state-of-the-art reported techniques with high detection accuracy, low False Positives, and low implementation overhead while being able to detect before the completion of the attack.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {14},
numpages = {31},
keywords = {Micro-architectural side-channel attacks, hardware performance counters, machine learning, time-series}
}

@inproceedings{10.1145/3017680.3022468,
author = {Jamison, Joseph},
title = {Applying Machine Learning to Predict Davidson College's Admissions Yield},
year = {2017},
isbn = {9781450346986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3017680.3022468},
doi = {10.1145/3017680.3022468},
abstract = {This project attempted to find a solution to the problem of declining yield rates at colleges and universities around the nation. Yield rate, the rate at which accepted students decide to enroll at a given school, is important to a school for academic, economic and logistical reasons. As such, this project aimed to raise the yield rate at Davidson College by applying machine learning techniques to applicant data in order to predict the yield decisions of the applicants. Using these techniques, a model was created that predicted applicants' yield decisions with 86% accuracy. With these predictions, Davidson College can have a better understanding of their yield and can consequently make more informed, tactical admissions decisions, thus raising their yield rate.},
booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
pages = {765–766},
numpages = {2},
keywords = {davidson college, predicting yield, yield rate},
location = {Seattle, Washington, USA},
series = {SIGCSE '17}
}

@inproceedings{10.1007/978-3-030-61527-7_26,
author = {Cherrier, No\"{e}lie and Mayo, Michael and Poli, Jean-Philippe and Defurne, Maxime and Sabati\'{e}, Franck},
title = {Interpretable Machine Learning with Bitonic Generalized Additive Models and Automatic Feature Construction},
year = {2020},
isbn = {978-3-030-61526-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61527-7_26},
doi = {10.1007/978-3-030-61527-7_26},
abstract = {In many machine learning applications, interpretable models are necessary for the sake of trust or for further understanding the patterns in the data. In particular, scientists often want models that elucidate knowledge and therefore may lead to new discoveries. Currently, Generalized Additive Models (GAM) are gaining interest in other application domains because of their ability to fit the data well while at the same time being intelligible. Moreover, prior domain-specific knowledge is often valuable to guide the learning. In this work, extensions and generalizations of GAM are proposed to incorporate prior knowledge during the learning phase. Specifically, the fitting method for GAM is modified so that it can fit the data with bitonic functions. In physics for instance, the most discriminative variables often present specific distributions with respect to the target variable, especially peaking (i.e. bitonic) distributions. An algorithm is also described to build automatically bitonic high-level features to be used in the GAM terms. Experiments on three physics datasets are used to validate these ideas in conjunction with physics scientists.},
booktitle = {Discovery Science: 23rd International Conference, DS 2020, Thessaloniki, Greece, October 19–21, 2020, Proceedings},
pages = {386–402},
numpages = {17},
keywords = {Bitonicity, Generalized additive models, Experimental physics},
location = {Thessaloniki, Greece}
}

@inproceedings{10.1145/2362536.2362554,
author = {Martini, Antonio and Pareto, Lars and Bosch, Jan},
title = {Enablers and inhibitors for speed with reuse},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362554},
doi = {10.1145/2362536.2362554},
abstract = {An open issue in industry is software reuse in the context of large scale Agile product development. The speed offered by agile practices is needed to hit the market, while reuse is needed for long-term productivity, efficiency, and profit. The paper presents an empirical investigation of factors influencing speed and reuse in three large product developing organizations seeking to implement Agile practices. The paper identifies, through a multiple case study with 3 organizations, 114 business-, process-, organizational-, architecture-, knowledge- and communication factors with positive or negative influences on reuse, speed or both. Contributions are a categorized inventory of influencing factors, a display for organizing factors for the purpose of process improvement work, and a list of key improvement areas to address when implementing reuse in organizations striving to become more Agile. Categories identified include good factors with positive influences on reuse or speed, harmful factors with negative influences, and complex factors involving inverse or ambiguous relationships. Key improvement areas in the studied organizations are intra-organizational communication practices, reuse awareness and practices, architectural integration and variability management. Results are intended to support process improvement work in the direction of Agile product development. Feedback on results from the studied organizations has been that the inventory captures current situations, and is useful for software process improvement work.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {116–125},
numpages = {10},
keywords = {agile software development, embedded systems, enablers, inhibitors, software process improvement (SPI), software reuse, speed},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3442442.3451887,
author = {Reelfs, Jens Helge and Bergmann, Max and Hohlfeld, Oliver and Henckell, Niklas},
title = {Understanding &amp; Predicting User Lifetime with Machine Learning in an Anonymous Location-Based Social Network},
year = {2021},
isbn = {9781450383134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442442.3451887},
doi = {10.1145/3442442.3451887},
abstract = {In this work, we predict the user lifetime within the anonymous and location-based social network Jodel in the Kingdom of Saudi Arabia. Jodel’s location-based nature yields to the establishment of disjoint communities country-wide and enables for the first time the study of user lifetime in the case of a large set of disjoint communities. A user’s lifetime is an important measurement for evaluating and steering customer bases as it can be leveraged to predict churn and possibly apply suitable methods to circumvent potential user losses. We train and test off the shelf machine learning techniques with 5-fold crossvalidation to predict user lifetime as a regression and classification problem; identifying the Random Forest to provide very strong results. Discussing model complexity and quality trade-offs, we also dive deep into a time-dependent feature subset analysis, which does not work very well; Easing up the classification problem into a binary decision (lifetime longer than timespan x) enables a practical lifetime predictor with very good performance. We identify implicit similarities across community models according to strong correlations in feature importance. A single countrywide model generalizes the problem and works equally well for any tested community; the overall model internally works similar to others also indicated by its feature importances.},
booktitle = {Companion Proceedings of the Web Conference 2021},
pages = {324–331},
numpages = {8},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1007/978-3-319-70087-8_42,
author = {Arif, Muhammad Hassan and Jin, Xin and Li, Jianxin and Iqbal, Muhammad},
title = {Text Classification Using Lifelong Machine Learning},
year = {2017},
isbn = {978-3-319-70086-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-70087-8_42},
doi = {10.1007/978-3-319-70087-8_42},
abstract = {This paper proposes a novel lifelong machine learning model for text classification. The proposed model tries to solve problems as humans do i.e. it learns small and simple problems, retains the knowledge learnt from those problems, mines the useful information from the stored knowledge and reuses the extracted knowledge to learn future problems. The proposed approach adopts rule based learning classifier systems and a new encoding scheme is proposed to identify building units of knowledge which can be reused for future learning. The fitter building units from the learning system trained against small problems of text classification domain are extracted and utilized in high dimensional social media text classification problems to achieve scalable learning. The experimental results show that proposed continuous learning approach successfully solves complex high dimensional problems by reusing the previously learned fitter building blocks of knowledge.},
booktitle = {Neural Information Processing: 24th International Conference, ICONIP 2017, Guangzhou, China, November 14-18, 2017, Proceedings, Part I},
pages = {394–404},
numpages = {11},
keywords = {Lifelong learning, Code fragments, Text classification},
location = {Guangzhou, China}
}

@article{10.1155/2020/5874935,
author = {Aljably, Randa and Tian, Yuan and Al-Rodhaan, Mznah and Pan, Zhaoqing},
title = {Preserving Privacy in Multimedia Social Networks Using Machine Learning Anomaly Detection},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1939-0114},
url = {https://doi.org/10.1155/2020/5874935},
doi = {10.1155/2020/5874935},
abstract = {Nowadays, user’s privacy is a critical matter in multimedia social networks. However, traditional machine learning anomaly detection techniques that rely on user’s log files and behavioral patterns are not sufficient to preserve it. Hence, the social network security should have multiple security measures to take into account additional information to protect user’s data. More precisely, access control models could complement machine learning algorithms in the process of privacy preservation. The models could use further information derived from the user’s profiles to detect anomalous users. In this paper, we implement a privacy preservation algorithm that incorporates supervised and unsupervised machine learning anomaly detection techniques with access control models. Due to the rich and fine-grained policies, our control model continuously updates the list of attributes used to classify users. It has been successfully tested on real datasets, with over 95% accuracy using Bayesian classifier, and 95.53% on receiver operating characteristic curve using deep neural networks and long short-term memory recurrent neural network classifiers. Experimental results show that this approach outperforms other detection techniques such as support vector machine, isolation forest, principal component analysis, and Kolmogorov–Smirnov test.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {14}
}

@inproceedings{10.1145/3439706.3447043,
author = {Nath, Siddhartha and Khandelwal, Vishal},
title = {Machine Learning-Enabled High-Frequency Low-Power Digital Design Implementation At Advanced Process Nodes},
year = {2021},
isbn = {9781450383004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439706.3447043},
doi = {10.1145/3439706.3447043},
abstract = {Relentless pursuit of high-frequency low-power designs at advanced nodes necessitate achieving signoff-quality timing and power during digital implementation to minimize any over-design. With growing design sizes (1--10M instances), full flow runtime is an equally important metric and commercial implementation tools use graph-based timing analysis (GBA) to gain runtime over path-based timing analysis (PBA), at the cost of pessimism in timing. Last mile timing and power closure is then achieved through expensive PBA-driven engineering change order (ECO) loops in signoff stage. In this work, we explore "on-the-fly'' machine learning (ML) models to predict PBA timing based on GBA features, to drive digital implementation flow. Our ML model reduces the GBA vs. PBA pessimism with minimal runtime overhead, resulting in improved area/power without compromising on signoff timing closure. Experimental results obtained by integrating our technique in a commercial digital implementation tool show improvement of up to 0.92% in area, 11.7% and 1.16% in power in leakage- and total power-centric designs, respectively. Our method has a runtime overhead of $sim$3% across a suite of 5--16nm industrial designs.},
booktitle = {Proceedings of the 2021 International Symposium on Physical Design},
pages = {83–90},
numpages = {8},
keywords = {gradient-boosted forests, optimization, timing analysis},
location = {Virtual Event, USA},
series = {ISPD '21}
}

@inproceedings{10.1145/1871437.1871709,
author = {Kobdani, Hamidreza and Sch\"{u}tze, Hinrich and Burkovski, Andre and Kessler, Wiltrud and Heidemann, Gunther},
title = {Relational feature engineering of natural language processing},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871709},
doi = {10.1145/1871437.1871709},
abstract = {We present a new framework for feature engineering of natural language processing that is based on a relational data model of text. It includes fast and flexible methods for implementing and extracting new features and thereby reduces the effort of creating an NLP system for a particular task.In an instantiation and evaluation of the framework for the problem of coreference resolution in multiple languages, we were able to obtain competitive results in a short implementation period. This demonstrates the potential power of our framework for feature engineering.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {1705–1708},
numpages = {4},
keywords = {coreference resolution, feature engineering, natural language processing, relational data model},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@article{10.1016/j.comnet.2019.106980,
author = {Subramanya, Tejas and Harutyunyan, Davit and Riggio, Roberto},
title = {Machine learning-driven service function chain placement and scaling in MEC-enabled 5G networks},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {166},
number = {C},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2019.106980},
doi = {10.1016/j.comnet.2019.106980},
journal = {Comput. Netw.},
month = jan,
numpages = {16},
keywords = {Auto-scaling, Service function chain placement, Machine learning, Neural-networks, Multi-access edge computing}
}

@article{10.1145/3293607,
author = {Jeon, Minseok and Jeong, Sehun and Cha, Sungdeok and Oh, Hakjoo},
title = {A Machine-Learning Algorithm with Disjunctive Model for Data-Driven Program Analysis},
year = {2019},
issue_date = {June 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/3293607},
doi = {10.1145/3293607},
abstract = {We present a new machine-learning algorithm with disjunctive model for data-driven program analysis. One major challenge in static program analysis is a substantial amount of manual effort required for tuning the analysis performance. Recently, data-driven program analysis has emerged to address this challenge by automatically adjusting the analysis based on data through a learning algorithm. Although this new approach has proven promising for various program analysis tasks, its effectiveness has been limited due to simple-minded learning models and algorithms that are unable to capture sophisticated, in particular disjunctive, program properties. To overcome this shortcoming, this article presents a new disjunctive model for data-driven program analysis as well as a learning algorithm to find the model parameters. Our model uses Boolean formulas over atomic features and therefore is able to express nonlinear combinations of program properties. A key technical challenge is to efficiently determine a set of good Boolean formulas, as brute-force search would simply be impractical. We present a stepwise and greedy algorithm that efficiently learns Boolean formulas. We show the effectiveness and generality of our algorithm with two static analyzers: context-sensitive points-to analysis for Java and flow-sensitive interval analysis for C. Experimental results show that our automated technique significantly improves the performance of the state-of-the-art techniques including ones hand-crafted by human experts.},
journal = {ACM Trans. Program. Lang. Syst.},
month = jun,
articleno = {13},
numpages = {41},
keywords = {Data-driven program analysis, context-sensitivity, flow-sensitivity, static analysis}
}

@inproceedings{10.1007/978-3-030-61401-0_9,
author = {Gadri, Said and Neuhold, Erich},
title = {Building Best Predictive Models Using ML and DL Approaches to Categorize Fashion Clothes},
year = {2020},
isbn = {978-3-030-61400-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61401-0_9},
doi = {10.1007/978-3-030-61401-0_9},
abstract = {Today Deep learning approach DL becomes the new tendency of machine learning approach ML which is used since it gives much more sophisticated pattern recognition and image classification than classic machine learning approach. Among the most used methods in DL, CNNs are for a special interest. In this work, we have developed an automatic classifier that permits to classify a large number of fashion clothing articles based on ML and DL approaches. Initially, we proceeded to the classification task using many ML algorithms, then we proposed a new CNN model composed of many convolutional layers, one maxpooling layer, and one full connected layer. Finally, we established a comparison between different algorithms. As programming tools, we have used Python, Tensoflow, and Keras which are the most used in the field.},
booktitle = {Artificial Intelligence and Soft Computing: 19th International Conference, ICAISC 2020, Zakopane, Poland, October 12-14, 2020, Proceedings, Part I},
pages = {90–102},
numpages = {13},
keywords = {Machine learning, Deep learning, Pattern recognition, Neural networks, Convolutional Neural Networks},
location = {Zakopane, Poland}
}

@inproceedings{10.1145/3361525.3361543,
author = {Grohmann, Johannes and Nicholson, Patrick K. and Iglesias, Jesus Omana and Kounev, Samuel and Lugones, Diego},
title = {Monitorless: Predicting Performance Degradation in Cloud Applications with Machine Learning},
year = {2019},
isbn = {9781450370097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361525.3361543},
doi = {10.1145/3361525.3361543},
abstract = {Today, software operation engineers rely on application key performance indicators (KPIs) for sizing and orchestrating cloud resources dynamically. KPIs are monitored to assess the achievable performance and to configure various cloud-specific parameters such as flavors of instances and autoscaling rules, among others. Usually, keeping KPIs within acceptable levels requires application expertise which is expensive and can slow down the continuous delivery of software. Expertise is required because KPIs are normally based on application-specific quality-of-service metrics, like service response time and processing rate, instead of generic platform metrics, like those typical across various environments (e.g., CPU and memory utilization, I/O rate, etc.)In this paper, we investigate the feasibility of outsourcing the management of application performance from developers to cloud operators. In the same way that the serverless paradigm allows the execution environment to be fully managed by a third party, we discuss a monitorless model to streamline application deployment by delegating performance management. We show that training a machine learning model with platform-level data, collected from the execution of representative containerized services, allows inferring application KPI degradation. This is an opportunity to simplify operations as engineers can rely solely on platform metrics -- while still fulfilling application KPIs -- to configure portable and application agnostic rules and other cloud-specific parameters to automatically trigger actions such as autoscaling, instance migration, network slicing, etc.Results show that monitorless infers KPI degradation with an accuracy of 97% and, notably, it performs similarly to typical autoscaling solutions, even when autoscaling rules are optimally tuned with knowledge of the expected workload.},
booktitle = {Proceedings of the 20th International Middleware Conference},
pages = {149–162},
numpages = {14},
keywords = {Cloud computing, DevOps, Machine learning, Monitoring},
location = {Davis, CA, USA},
series = {Middleware '19}
}

@inproceedings{10.1145/3375627.3375858,
author = {Zucker, Julian and d'Leeuwen, Myraeka},
title = {Arbiter: A Domain-Specific Language for Ethical Machine Learning},
year = {2020},
isbn = {9781450371100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375627.3375858},
doi = {10.1145/3375627.3375858},
abstract = {The widespread deployment of machine learning models in high- stakes decision making scenarios requires a code of ethics for machine learning practitioners. We identify four of the primary components required for the ethical practice of machine learn- ing: transparency, fairness, accountability, and reproducibility. We introduce Arbiter, a domain-specific programming language for machine learning practitioners that is designed for ethical machine learning. Arbiter provides a notation for recording how machine learning models will be trained, and we show how this notation can encourage the four described components of ethical machine learning.},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
pages = {421–425},
numpages = {5},
keywords = {domain-specific languages, ethical machine learning},
location = {New York, NY, USA},
series = {AIES '20}
}

@inproceedings{10.1145/2623330.2623347,
author = {Zheng, Li and Zeng, Chunqiu and Li, Lei and Jiang, Yexi and Xue, Wei and Li, Jingxuan and Shen, Chao and Zhou, Wubai and Li, Hongtai and Tang, Liang and Li, Tao and Duan, Bing and Lei, Ming and Wang, Pengnian},
title = {Applying data mining techniques to address critical process optimization needs in advanced manufacturing},
year = {2014},
isbn = {9781450329569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2623330.2623347},
doi = {10.1145/2623330.2623347},
abstract = {Advanced manufacturing such as aerospace, semi-conductor, and flat display device often involves complex production processes, and generates large volume of production data. In general, the production data comes from products with different levels of quality, assembly line with complex flows and equipments, and processing craft with massive controlling parameters. The scale and complexity of data is beyond the analytic power of traditional IT infrastructures. To achieve better manufacturing performance, it is imperative to explore the underlying dependencies of the production data and exploit analytic insights to improve the production process. However, few research and industrial efforts have been reported on providing manufacturers with integrated data analytical solutions to reveal potentials and optimize the production process from data-driven perspectives.In this paper, we design, implement and deploy an integrated solution, named PDP-Miner, which is a data analytics platform customized for process optimization in Plasma Display Panel (PDP) manufacturing. The system utilizes the latest advances in data mining technologies and Big Data infrastructures to create a complete analytical solution. Besides, our proposed system is capable of supporting automatically configuring and scheduling analysis tasks, and balancing heterogeneous computing resources. The system and the analytic strategies can be applied to other advanced manufacturing fields to enable complex data analysis tasks. Since 2013, PDP-Miner has been deployed as the data analysis platform of ChangHong COC. By taking the advantages of our system, the overall PDP yield rate has increased from 91% to 94%. The monthly production is boosted by 10,000 panels, which brings more than 117 million RMB of revenue improvement per year.},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1739–1748},
numpages = {10},
keywords = {advanced manufacturing, big data, data mining platform, process optimization},
location = {New York, New York, USA},
series = {KDD '14}
}

@article{10.1007/s10586-017-1108-9,
author = {Ilavarasi, A. K. and Sathiyabhama, B.},
title = {An evolutionary feature set decomposition based anonymization for classification workloads: Privacy Preserving Data Mining},
year = {2017},
issue_date = {Dec 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-017-1108-9},
doi = {10.1007/s10586-017-1108-9},
abstract = {Privacy has become an important concern while publishing micro data about a population. The emerging area called privacy preserving data mining (PPDM) focus on individual privacy without compromising data mining results. An adversarial exploitation of published data poses a risk of information disclosure about individuals. On the other hand, imposing privacy constraints on the data results in substantial information loss and compromises the legitimate data analysis. Motivated by the increasing growth of PPDM algorithms, we first investigate the privacy implications and the crosscutting issues between privacy versus utility of data. We present a privacy model that embeds the anonymization procedure in to a learning algorithm and this has mitigated the additional overheads imposed on data mining tasks. Our primary concern about PPDM is that the utility of data should not be compromised by the transformation applied. Different data mining classification workloads are analyzed with the proposed anonymization procedure for any side effects incurred. It is shown empirically that classification accuracy obtained for most of the datasets outperforms the results obtained with original dataset.},
journal = {Cluster Computing},
month = dec,
pages = {3515–3525},
numpages = {11},
keywords = {Anonymization, Classification, Data mining, Decomposition, Evolutionary partitioning, Privacy}
}

@article{10.1504/ijkesdp.2020.112630,
author = {Moses, Beulah and Singhal, Shyam},
title = {Effort estimation in software development using story point: a machine learning approach},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {7},
number = {1},
issn = {1755-3210},
url = {https://doi.org/10.1504/ijkesdp.2020.112630},
doi = {10.1504/ijkesdp.2020.112630},
abstract = {Agile methodologies are besieged with problems and potential solutions around predictive insights on a project. These problems range from estimation, quality, to effort and duration requirements. Despite of having innumerable predictive models not a single reliable solution is available to estimate the duration and effort required to complete an agile project on an ongoing basis. This is due subjective nature of 'story point', and progressive elaboration of 'user story'. This paper analyses the relationship between story points and effort, across a sample of software development projects, in an organisation. A novel machine learning predictive model has been developed and is implemented across agile projects that infer relationship between 'effort' and 'story points', directly in contrast with agile literature. This predictive model was tested and worked accurately, reliably and effectively across various agile projects. This research can be extended to agile projects having sprints of less than fifty story points.},
journal = {Int. J. Knowl. Eng. Soft Data Paradigm.},
month = jan,
pages = {25–44},
numpages = {19},
keywords = {forecasting, estimation model, machine learning, regression, agile, scrum, story points, effort estimation}
}

@inproceedings{10.1145/3493287.3493291,
author = {Si, Wenting and Yang, Xiao},
title = {Medicine Retail Terminal Layout and Site Selection Problems Based on Machine Learning Research: Take S Enterprise as an Example},
year = {2021},
isbn = {9781450389877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493287.3493291},
doi = {10.1145/3493287.3493291},
abstract = {In view of the existing in the traditional medicine retail terminal location selection of cycle is long, large artificial subjective factors, location index idealized, empiricism is the highest, using ArcGIS software for data processing, build characteristic data set, the use of random forests, support vector machine (SVM) and logistic regression modeling and XGBoost algorithm, comprehensive comparing the advantages and disadvantages of these algorithms, formulate scientific and reasonable location model, improve the accuracy of the location . This paper takes Licheng District of Jinan City as the research object, on the grid scale of 700m * 700m, based on the data of urban interest points, combined with the distribution of existing retail terminals of S enterprise, constructs the location model. The example shows that the results of random forest algorithm are excellent, which can reduce the subjectivity in the process of location, shorten the time of location, and improve the correctness of location.},
booktitle = {Proceedings of the 2021 6th International Conference on Cloud Computing and Internet of Things},
pages = {22–28},
numpages = {7},
keywords = {ArcGIS, Random forests, Retail terminal location, Web crawler},
location = {Okinawa, Japan},
series = {CCIOT '21}
}

@inproceedings{10.1145/3462462.3468882,
author = {Zhang, Hantian and Shahbazi, Nima and Chu, Xu and Asudeh, Abolfazl},
title = {FairRover: explorative model building for fair and responsible machine learning},
year = {2021},
isbn = {9781450384865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462462.3468882},
doi = {10.1145/3462462.3468882},
abstract = {The potential harms and drawbacks of automated decision making has become a challenge as data science blends into our lives. In particular, fairness issues with deployed machine learning models have drawn significant attention from the research community. Despite the myriad of algorithmic fairness work in various research communities, in practice data scientists still face many roadblocks in ensuring the fairness of their machine learning models. This is primarily because there does not exist an end-to-end system that guides the users in building a fair machine learning model in a responsible way from model auditing, to model explanation, to bias mitigation.We propose a explorative model building system FairRover for responsible fair model building. FairRover guides users in (1) discovering the potential biases in the model; (2) providing explanation to the discovered biases so as to help users in understanding potential causes of the biases; and (3) mitigating the most important biases selected by the users. Because of the impossibility theorem of fairness, and the well-known trade-off between fairness and accuracy, it is generally impossible to achieve a completely fair and accurate machine learning model. Therefore, this responsible model building process is naturally performed iteratively until a satisfying trade-off is reached. Human users are involved in the loop to make various decisions guided by FairRover.We demonstrate a case study on the Adult Census dataset, which shows how FairRover guides users in iteratively building a fair income prediction model in a responsible way. We discuss the current limitations of FairRover and future work.},
booktitle = {Proceedings of the Fifth Workshop on Data Management for End-To-End Machine Learning},
articleno = {5},
numpages = {10},
location = {Virtual Event, China},
series = {DEEM '21}
}

@article{10.1007/s00521-020-05321-8,
author = {Asim, Muhammad Nabeel and Ghani, Muhammad Usman and Ibrahim, Muhammad Ali and Mahmood, Waqar and Dengel, Andreas and Ahmed, Sheraz},
title = {Benchmarking performance of machine and deep learning-based methodologies for Urdu text document classification},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {11},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05321-8},
doi = {10.1007/s00521-020-05321-8},
abstract = {In order to provide benchmark performance for Urdu text document classification, the contribution of this paper is manifold. First, it provides a publicly available benchmark dataset manually tagged against 6 classes. Second, it investigates the performance impact of traditional machine learning-based Urdu text document classification methodologies by embedding 10 filter-based feature selection algorithms which have been widely used for other languages. Third, for the very first time, it assesses the performance of various deep learning-based methodologies for Urdu text document classification. In this regard, for experimentation, we adapt 10 deep learning classification methodologies which have produced best performance figures for English text classification. Fourth, it also investigates the performance impact of transfer learning by utilizing Bidirectional Encoder Representations from Transformers approach for Urdu language. Fifth, it evaluates the integrity of a hybrid approach which combines traditional machine learning-based feature engineering and deep learning-based automated feature engineering. Experimental results show that feature selection approach named as normalized difference measure along with support vector machine outshines state-of-the-art performance on two closed source benchmark datasets CLE Urdu Digest 1000k, and CLE Urdu Digest 1Million with a significant margin of 32% and 13%, respectively. Across all three datasets, normalized difference measure outperforms other filter-based feature selection algorithms as it significantly uplifts the performance of all adopted machine learning, deep learning, and hybrid approaches. The source code and presented dataset are available at Github repository .},
journal = {Neural Comput. Appl.},
month = jun,
pages = {5437–5469},
numpages = {33},
keywords = {Urdu text document classification, Urdu news classification, Urdu news genre categorization, Multi-class Urdu text categorization computational methodologies, Deep neural networks, BERT}
}

@inproceedings{10.1007/978-3-030-78292-4_31,
author = {Sha, Lele and Rakovic, Mladen and Whitelock-Wainwright, Alexander and Carroll, David and Yew, Victoria M. and Gasevic, Dragan and Chen, Guanliang},
title = {Assessing Algorithmic Fairness in&nbsp;Automatic Classifiers of Educational Forum Posts},
year = {2021},
isbn = {978-3-030-78291-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78292-4_31},
doi = {10.1007/978-3-030-78292-4_31},
abstract = {Automatic classifiers of educational forum posts are essential in helping instructors effectively implement their teaching practices and thus have been widely investigated. However, existing studies mostly stressed the accuracy of a classifier, while the fairness of the classifier remains largely unexplored, i.e., whether the posts generated by a group of students are more likely to be correctly labeled than those generated by other groups of students. Undoubtedly, any unfairness based on student performance, sex, or other subjective views can have a detrimental effect on a student’s learning experience and performance. Therefore, this study aimed to assess the algorithmic fairness of six popular models used in building automatic classifiers of educational forum posts. Here, we measured the algorithmic fairness displayed (i) between students of different sex (female vs. male) and (ii) between students of different first languages (English-as-first-language speakers vs. English-as-second-language speakers). Besides, we investigated whether a classifier’s fairness could be enhanced by applying data sampling techniques. Our results demonstrated that: 1) traditional Machine Learning models slightly outperformed up-to-date Deep Learning models in delivering fair predictions; 2) students of different first languages faced more unfair predictions than students of different sex, and most of the classifiers tended to favor English-as-first-language students; and 3) with equal numbers of posts generated by different groups of students in the training data, the fairness of a classifier could be greatly enhanced.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part I},
pages = {381–394},
numpages = {14},
keywords = {Educational forum post, Text classification, Algorithmic fairness},
location = {Utrecht, The Netherlands}
}

@inproceedings{10.1007/978-3-030-38085-4_19,
author = {Christodoulopoulos, Konstantinos and Sartzetakis, Ippokratis and Soumplis, Polizois and Varvarigos, Emmanouel (Manos)},
title = {Machine Learning Assisted Quality of Transmission Estimation and Planning with Reduced Margins},
year = {2019},
isbn = {978-3-030-38084-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38085-4_19},
doi = {10.1007/978-3-030-38085-4_19},
abstract = {In optical transport networks, the Quality of Transmission (QoT) using a physical layer model (PLM) is estimated before establishing new or reconfiguring established optical connections. Traditionally, high margins are added to account for the model’s inaccuracy and the uncertainty in the current and evolving physical layer conditions, targeting uninterrupted operation for several years, until the end-of-life (EOL). Reducing the margins increases network efficiency but requires accurate QoT estimation. We present two machine learning (ML) assisted QoT estimators that leverage monitoring data of existing connections to understand the actual physical layer conditions and achieve high estimation accuracy. We then quantify the benefits of planning/upgrading a network over multiple periods with accurate QoT estimation as opposed to planning with EOL margins.},
booktitle = {Optical Network Design and Modeling: 23rd IFIP WG 6.10 International Conference, ONDM 2019, Athens, Greece, May 13–16, 2019, Proceedings},
pages = {211–222},
numpages = {12},
keywords = {Overprovisioning, Static network planning, End-of-life margins, Physical layer impairments, Monitoring, Cross-layer optimization, Incremental multi-period planning, Marginless},
location = {Athens, Greece}
}

@article{10.1007/s11192-021-04055-1,
author = {Iqbal, Sehrish and Hassan, Saeed-Ul and Aljohani, Naif Radi and Alelyani, Salem and Nawaz, Raheel and Bornmann, Lutz},
title = {A decade of in-text citation analysis based on natural language processing and machine learning techniques: an overview of empirical studies},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {126},
number = {8},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-021-04055-1},
doi = {10.1007/s11192-021-04055-1},
abstract = {In-text citation analysis is one of the most frequently used methods in research evaluation. We are seeing significant growth in citation analysis through bibliometric metadata, primarily due to the availability of citation databases such as the Web of Science, Scopus, Google Scholar, Microsoft Academic, and Dimensions. Due to better access to full-text publication corpora in recent years, information scientists have gone far beyond traditional bibliometrics by tapping into advancements in full-text data processing techniques to measure the impact of scientific publications in contextual terms. This has led to technical developments in citation classifications, citation sentiment analysis, citation summarisation, and citation-based recommendation. This article aims to narratively review the studies on these developments. Its primary focus is on publications that have used natural language processing and machine learning techniques to analyse citations.},
journal = {Scientometrics},
month = aug,
pages = {6551–6599},
numpages = {49},
keywords = {In-text citation analysis, Citation context analysis, Citation content analysis, Citation classification, Citation sentiment analysis, Summarisation, Recommendation, Bibliometrics}
}

@inproceedings{10.1145/3336499.3338003,
author = {Attanasio, Giuseppe and Cagliero, Luca and Garza, Paolo and Baralis, Elena},
title = {Quantitative cryptocurrency trading: exploring the use of machine learning techniques},
year = {2019},
isbn = {9781450368230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336499.3338003},
doi = {10.1145/3336499.3338003},
abstract = {Machine learning techniques have found application in the study and development of quantitative trading systems. These systems usually exploit supervised models trained on historical data in order to automatically generate buy/sell signals on the financial markets. Although in this context a deep exploration of the Stock, Forex, and Future exchange markets has already been made, a more limited effort has been devoted to the application of machine learning techniques to the emerging cryptocurrency exchange market. This paper explores the potential of the most established classification and time series forecasting models in cryptocurrency trading by backtesting model performance over a eight year period. The results show that, due to the heterogeneity and volatility of the underlying financial instruments, prediction models based on series forecasting perform better than classification techniques. Furthermore, trading multiple cryptocurrencies at the same time significantly increases the overall returns compared to baseline strategies exclusively based on Bitcoin trading.},
booktitle = {Proceedings of the 5th Workshop on Data Science for Macro-Modeling with Financial and Economic Datasets},
articleno = {1},
numpages = {6},
keywords = {Classification, Cryptocurrencies, Machine learning, Quantitative trading},
location = {Amsterdam, Netherlands},
series = {DSMM'19}
}

@article{10.1145/3470918,
author = {Karmaker (“Santu”), Shubhra Kanti and Hassan, Md. Mahadi and Smith, Micah J. and Xu, Lei and Zhai, Chengxiang and Veeramachaneni, Kalyan},
title = {AutoML to Date and Beyond: Challenges and Opportunities},
year = {2021},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3470918},
doi = {10.1145/3470918},
abstract = {As big data becomes ubiquitous across domains, and more and more stakeholders aspire to make the most of their data, demand for machine learning tools has spurred researchers to explore the possibilities of automated machine learning (AutoML). AutoML tools aim to make machine learning accessible for non-machine learning experts (domain experts), to improve the efficiency of machine learning, and to accelerate machine learning research. But although automation and efficiency are among AutoML’s main selling points, the process still requires human involvement at a number of vital steps, including understanding the attributes of domain-specific data, defining prediction problems, creating a suitable training dataset, and selecting a promising machine learning technique. These steps often require a prolonged back-and-forth that makes this process inefficient for domain experts and data scientists alike and keeps so-called AutoML systems from being truly automatic. In this review article, we introduce a new classification system for AutoML systems, using a seven-tiered schematic to distinguish these systems based on their level of autonomy. We begin by describing what an end-to-end machine learning pipeline actually looks like, and which subtasks of the machine learning pipeline have been automated so far. We highlight those subtasks that are still done manually—generally by a data scientist—and explain how this limits domain experts’ access to machine learning. Next, we introduce our novel level-based taxonomy for AutoML systems and define each level according to the scope of automation support provided. Finally, we lay out a roadmap for the future, pinpointing the research required to further automate the end-to-end machine learning pipeline and discussing important challenges that stand in the way of this ambitious goal.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {175},
numpages = {36},
keywords = {Automated machine learning, interactive data science, democratization of artificial intelligence, predictive analytics}
}

@article{10.1155/2021/2658090,
author = {Shi, Xiaorui and Cui, Wei and Zhu, Ping and Yang, Yanhua and Souri, Alireza},
title = {Research on Automobile Assembly Line Optimization Based on Industrial Engineering Technology and Machine Learning Algorithm},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/2658090},
doi = {10.1155/2021/2658090},
abstract = {Aiming at the lack of search depth of traditional genetic algorithm in automobile assembly line balance optimization, an improved genetic algorithm based on bagging integrated clustering is proposed for balance optimization. Through the integrated learning of several K-means algorithm based learners through bagging, a population clustering analysis method based on bagging integrated clustering algorithm is established, and then, a dual objective automobile assembly line balance optimization model is established. The population clustering analysis method is used to improve the intersection link of genetic algorithm to improve the search depth. The effectiveness and search performance of the improved genetic algorithm in solving the double objective assembly line balance problem are verified in an example.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {9}
}

@inproceedings{10.1007/978-3-030-59987-4_31,
author = {Ajisafe, Toyin},
title = {Leveraging Muscular Fitness Surrogates to Classify Cardiorespiratory Fitness Status in Youth: A Supervised Machine Learning Approach},
year = {2020},
isbn = {978-3-030-59986-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59987-4_31},
doi = {10.1007/978-3-030-59987-4_31},
abstract = {Cardiorespiratory fitness (CRF) is linked with anxiety, depression, and cardiovascular disease risk. Assessing CRF is time consuming, space-prohibitive, and may require specialized equipment. Therefore, it is not routinely assessed in schools or clinical settings. This study aimed to leverage muscular fitness surrogates, anthropometrics and demographics to build optimal CRF classifiers that can be easily deployed across multiple settings. VO2PEAK was estimated using a prediction equation that integrated the 20-m Progressive Aerobic Cardiovascular Endurance Run dataset from 210 youth (116 males) (9.7 ± 1.08 years; 138.6 ± 9.4&nbsp;cm; 42.3 ± 14.4&nbsp;kg). Muscular fitness (i.e., 90° push-up, curl-up, etc.) was assessed. Several models (e.g., Support Vector Machine (SVM), Na\"{\i}ve Bayes, and Logistic Regression) were trained using both the originally imbalanced dataset and a balanced dataset resulting from synthetically oversampling the minority class. Metrics, including Area Under Curve (AUC) and True and False Positive Rates (TPR and FPR) were used to compare performance between models. The most salient model was a Logistic Regression model with nine features (i.e., sex, age, sit-and-reach, body mass, trunk lift, BMI, curl-up, 90° push-up, and height) (accuracy = 89.5%; AUC = 0.96; TPR = 0.86, FPRs = 0.08). This model correctly classified 100% and 100% of positive and negative class observations, respectively. A Logistic Regression model (accuracy = 85.7%; AUC = 0.92; TPR = 0.84, FPRs = 0.14) with four features (i.e., sex, age, sit-and-reach, and body mass) correctly predicted 100% and 91% of positive and negative class observations, respectively. Results demonstrate the feasibility of leveraging muscular fitness, anthropometrics, and basic demographics to develop accurate, streamlined models that can be easily deployed across multiple settings in order to facilitate routine CRF assessment in youth.},
booktitle = {HCI International 2020 – Late Breaking Papers: Digital Human Modeling and Ergonomics, Mobility and Intelligent Environments: 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {443–454},
numpages = {12},
keywords = {Machine learning, Cardiorespiratory fitness classification, Weight status, Hispanic/latino youth, School fitness surveillance},
location = {Copenhagen, Denmark}
}

@article{10.1145/3453478,
author = {Dilhara, Malinda and Ketkar, Ameya and Dig, Danny},
title = {Understanding Software-2.0: A Study of Machine Learning Library Usage and Evolution},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3453478},
doi = {10.1145/3453478},
abstract = {Enabled by a rich ecosystem of Machine Learning (ML) libraries, programming using learned models, i.e., Software-2.0, has gained substantial adoption. However, we do not know what challenges developers encounter when they use ML libraries. With this knowledge gap, researchers miss opportunities to contribute to new research directions, tool builders do not invest resources where automation is most needed, library designers cannot make informed decisions when releasing ML library versions, and developers fail to use common practices when using ML libraries.We present the first large-scale quantitative and qualitative empirical study to shed light on how developers in Software-2.0 use ML libraries, and how this evolution affects their code. Particularly, using static analysis we perform a longitudinal study of 3,340 top-rated open-source projects with 46,110 contributors. To further understand the challenges of ML library evolution, we survey 109 developers who introduce and evolve ML libraries. Using this rich dataset we reveal several novel findings.Among others, we found an increasing trend of using ML libraries: The ratio of new Python projects that use ML libraries increased from 2% in 2013 to 50% in 2018. We identify several usage patterns including the following: (i) 36% of the projects use multiple ML libraries to implement various stages of the ML workflows, (ii) developers update ML libraries more often than the traditional libraries, (iii) strict upgrades are the most popular for ML libraries among other update kinds, (iv) ML library updates often result in cascading library updates, and (v) ML libraries are often downgraded (22.04% of cases). We also observed unique challenges when evolving and maintaining Software-2.0 such as (i) binary incompatibility of trained ML models and (ii) benchmarking ML models. Finally, we present actionable implications of our findings for researchers, tool builders, developers, educators, library vendors, and hardware vendors.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {55},
numpages = {42},
keywords = {Machine learning libraries, Software-2.0, empirical studies}
}

@article{10.1016/j.infsof.2019.04.011,
author = {Rodrigues, Arthur and Rodrigues, Gena\'{\i}na Nunes and Knauss, Alessia and Ali, Raian and Andrade, Hugo},
title = {Enhancing context specifications for dependable adaptive systems: A data mining approach},
year = {2019},
issue_date = {Aug 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {112},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.04.011},
doi = {10.1016/j.infsof.2019.04.011},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {115–131},
numpages = {17},
keywords = {Self-adaptive system, Context uncertainty, Data mining, Design time, Goal modelling, Dependability}
}

@article{10.5555/2444851.2444855,
author = {Mirroshandel, Seyed Abolghasem and Ghassem-Sani, Gholamreza},
title = {Towards unsupervised learning of temporal relations between events},
year = {2012},
issue_date = {September 2012},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {45},
number = {1},
issn = {1076-9757},
abstract = {Automatic extraction of temporal relations between event pairs is an important task for several natural language processing applications such as Question Answering, Information Extraction, and Summarization. Since most existing methods are supervised and require large corpora, which for many languages do not exist, we have concentrated our efforts to reduce the need for annotated data as much as possible. This paper presents two different algorithms towards this goal. The first algorithm is a weakly supervised machine learning approach for classification of temporal relations between events. In the first stage, the algorithm learns a general classifier from an annotated corpus. Then, inspired by the hypothesis of "one type of temporal relation per discourse", it extracts useful information from a cluster of topically related documents. We show that by combining the global information of such a cluster with local decisions of a general classifier, a bootstrapping cross-document classifier can be built to extract temporal relations between events. Our experiments show that without any additional annotated data, the accuracy of the proposed algorithm is higher than that of several previous successful systems. The second proposed method for temporal relation extraction is based on the expectation maximization (EM) algorithm. Within EM, we used different techniques such as a greedy best-first search and integer linear programming for temporal inconsistency removal. We think that the experimental results of our EM based algorithm, as a first step toward a fully unsupervised temporal relation extraction method, is encouraging.},
journal = {J. Artif. Int. Res.},
month = sep,
pages = {125–163},
numpages = {39}
}

@article{10.1016/j.envsoft.2018.11.013,
author = {Barker, J.L.P. and Macleod, C.J.A.},
title = {Development of a national-scale real-time Twitter data mining pipeline for social geodata on the potential impacts of flooding on communities},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {115},
number = {C},
issn = {1364-8152},
url = {https://doi.org/10.1016/j.envsoft.2018.11.013},
doi = {10.1016/j.envsoft.2018.11.013},
journal = {Environ. Model. Softw.},
month = may,
pages = {213–227},
numpages = {15},
keywords = {Flood management, Twitter, Volunteered geographic information, Natural language processing, Word embeddings, Social geodata}
}

@article{10.1016/j.compag.2021.106183,
author = {Rojo, Diego and Htun, Nyi Nyi and Parra, Denis and De Croon, Robin and Verbert, Katrien},
title = {AHMoSe: A knowledge-based visual support system for selecting regression machine learning models},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {187},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106183},
doi = {10.1016/j.compag.2021.106183},
journal = {Comput. Electron. Agric.},
month = aug,
numpages = {11},
keywords = {Decision Support System, Visual Analytics, Explainable AI, Automated Machine Learning}
}

@article{10.1016/j.compbiomed.2018.02.008,
author = {McAllister, Patrick and Zheng, Huiru and Bond, Raymond and Moorhead, Anne},
title = {Combining deep residual neural network features with supervised machine learning algorithms to classify diverse food image datasets},
year = {2018},
issue_date = {Apr 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {95},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2018.02.008},
doi = {10.1016/j.compbiomed.2018.02.008},
journal = {Comput. Biol. Med.},
month = apr,
pages = {217–233},
numpages = {17},
keywords = {Obesity, Food logging, Deep learning, Convolutional neural networks, Feature extraction}
}

@inproceedings{10.1007/978-3-030-37494-5_6,
author = {Rashed, Ahmed and Grabocka, Josif and Schmidt-Thieme, Lars},
title = {Weighted Personalized Factorizations for Network Classification with Approximated Relation Weights},
year = {2019},
isbn = {978-3-030-37493-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37494-5_6},
doi = {10.1007/978-3-030-37494-5_6},
abstract = {Classifying Multi-Label nodes in networks is a well-known and widely used task in different domains. Current classification models rely on mining the network structure either by random walks or through approximating the laplacian of the network graph which gives insight about the nodes’ neighborhood. In implicit feedback relations, these models assume all relation edges to be equally strong and important. However, in real life, this is not necessarily the case as some edges might have different semantic weights such as friendship relation. To tackle this limitation we propose in this paper a weighted two-stage multi-relational matrix factorization model with Bayesian personalized ranking loss for network classification that utilizes different weighting functions for approximating the implicit feedback relation weights. Experiments on four real-world datasets show that the proposed model significantly outperforms the state-of-art models. Results also show that selecting the right weighting functions for approximating relation weights significantly improves classification accuracy.},
booktitle = {Agents and Artificial Intelligence: 11th International Conference, ICAART 2019, Prague, Czech Republic, February 19–21, 2019, Revised Selected Papers},
pages = {100–117},
numpages = {18},
keywords = {Multi-relational learning, Network representations Multi-label classification, Recommender systems, Document classification},
location = {Prague, Czech Republic}
}

@inproceedings{10.1145/3383455.3422539,
author = {Koshiyama, Adriano and Firoozye, Nick and Treleaven, Philip},
title = {Algorithms in future capital markets: a survey on AI, ML and associated algorithms in capital markets},
year = {2021},
isbn = {9781450375849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383455.3422539},
doi = {10.1145/3383455.3422539},
abstract = {This paper reviews Artificial Intelligence (AI), Machine Learning (ML) and associated algorithms in future Capital Markets. New AI algorithms are constantly emerging, with each 'strain' mimicking a new form of human learning, reasoning, knowledge, and decisionmaking. The current main disrupting forms of learning include Deep Learning, Adversarial Learning, Transfer and Meta Learning. Albeit these modes of learning have been in the AI/ML field more than a decade, they now are more applicable due to the availability of data, computing power and infrastructure. These forms of learning have produced new models (e.g., Long Short-Term Memory, Generative Adversarial Networks) and leverage important applications (e.g., Natural Language Processing, Adversarial Examples, Deep Fakes, etc.). These new models and applications will drive changes in future Capital Markets, so it is important to understand their computational strengths and weaknesses. Since ML algorithms effectively self-program and evolve dynamically, financial institutions and regulators are becoming increasingly concerned with ensuring there remains a modicum of human control, focusing on Algorithmic Interpretability/Explainability, Robustness and Legality. For example, the concern is that, in the future, an ecology of trading algorithms across different institutions may 'conspire' and become unintentionally fraudulent (cf. LIBOR) or subject to subversion through compromised datasets (e.g. Microsoft Tay). New and unique forms of systemic risks can emerge, potentially coming from excessive algorithmic complexity. The contribution of this paper is to review AI, ML and associated algorithms, their computational strengths and weaknesses, and discuss their future impact on the Capital Markets.},
booktitle = {Proceedings of the First ACM International Conference on AI in Finance},
articleno = {14},
numpages = {8},
keywords = {artificial intelligence, deep learning, finance, generative adversarial networks, machine learning, transfer learning},
location = {New York, New York},
series = {ICAIF '20}
}

@article{10.1016/j.mcm.2005.02.006,
author = {Nichols, K. B. and Venkataramanan, M. A. and Ernstberger, K. W.},
title = {Product line selection and pricing analysis: Impact of genetic relaxations},
year = {2005},
issue_date = {December, 2005},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {42},
number = {13},
issn = {0895-7177},
url = {https://doi.org/10.1016/j.mcm.2005.02.006},
doi = {10.1016/j.mcm.2005.02.006},
abstract = {A model for the product line selection and pricing problem (PLSP) is presented andthree solution procedures based on a genetic algorithm are developed to analyze the results based on consumer preference patterns. Since the PLSP model is nonlinear and integer, two of the solution procedures use genetic encoding to ''relax'' the NP hard model. The relaxations result in linear integer and shortest path models for the fitness evaluation which are solved using branch and bound and labeling algorithms, respectively. Performance of the quality of solutions generated by the procedures is evaluated for various problem sizes and customer preference structures. The results show that the genetic relaxations provide efficient and effective solution methodologies for the problem, when compared to the pure artificial intelligence technique of genetic search. The impact of the preference structure on the product line and the managerial implications of the solution characteristics generated by the genetic relaxations are also discussed. The models can be used to explicitly consider tradeoffs between marketing and operations concerns in designing a product line.},
journal = {Math. Comput. Model.},
month = dec,
pages = {1397–1410},
numpages = {14},
keywords = {Genetic algorithms, Heuristics, Pricing, Product line}
}

@inproceedings{10.1145/3136825.3136874,
author = {Bansal, Ankit and Mahapatra, Sudipta},
title = {A comparative analysis of machine learning techniques for botnet detection},
year = {2017},
isbn = {9781450353038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136825.3136874},
doi = {10.1145/3136825.3136874},
abstract = {Day by day more and more devices are getting connected to the Internet and with the advent of the Internet of Things, this rate has had an exponential growth. The lack of security in devices connected to the IoT is making them hot targets for cyber-criminals and strength of botnet attacks have increased drastically. Botnets are the technological backbones of multitudinous attacks including Distributed Denial of Service (DDoS), SPAM, identity theft and organizational spying. The 2016 Dyn cyber attack involved multiple DDoS attacks with an estimated throughput of 1.2 terabits per second; the attack is the largest DDoS attack on record. In this paper, we compare three different techniques for botnet detection with each having its unique use cases. The results of the detection methods were verified using ISCX Intrusion Detection Dataset and the CTU-13 Dataset.},
booktitle = {Proceedings of the 10th International Conference on Security of Information and Networks},
pages = {91–98},
numpages = {8},
keywords = {botnet detection, clustering, machine learning},
location = {Jaipur, India},
series = {SIN '17}
}

@article{10.1016/j.knosys.2021.107522,
author = {Rahim, Md Shamsur and Nguyen, Khoi Anh and Stewart, Rodney Anthony and Ahmed, Tanvir and Giurco, Damien and Blumenstein, Michael},
title = {A clustering solution for analyzing residential water consumption patterns},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {233},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107522},
doi = {10.1016/j.knosys.2021.107522},
journal = {Know.-Based Syst.},
month = dec,
numpages = {17},
keywords = {Digital water meters, Residential water consumption, Clustering, Customer segmentation, k-means clustering, Hierarchical agglomerative clustering, Consumption patterns, Data analytics, Machine learning}
}

@article{10.1007/s10957-006-9135-3,
author = {Fruchter, G. E. and Fligler, A. and Winer, R. S.},
title = {Optimal Product Line Design: Genetic Algorithm Approach to Mitigate Cannibalization},
year = {2006},
issue_date = {November  2006},
publisher = {Plenum Press},
address = {USA},
volume = {131},
number = {2},
issn = {0022-3239},
url = {https://doi.org/10.1007/s10957-006-9135-3},
doi = {10.1007/s10957-006-9135-3},
abstract = {In this marketing-oriented era where manufacturers maximize profits through customer satisfaction, there is an increasing need to design a product line rather than a single product. By offering a product line, the manufacturer can customize his or her products to the needs of a variety of segments in order to maximize profits by satisfying more customers than a single product would. When the amount of data on customer preferences or possible product configurations is large and no analytical relations can be established, the problem of an optimal product line design becomes very difficult and there are no traditional methods to solve it. In this paper, we show that the usage of genetic algorithms, a mathematical heuristics mimicking the process of biological evolution, can solve efficiently the problem. Special domain operators were developed to help the genetic algorithm mitigate cannibalization and enhance the algorithm's local search abilities. Using manufacturer's profits as the criteria for fitness in evaluating chromosomes, the usage of domain specific operators was found to be highly beneficial with better final results. Also, we have hybridized the genetic algorithm with a linear programming postprocessing step to fine tune the prices of products in the product line. Attacking the core difficulty of cannibalization in the algorithm, the operators introduced in this work are unique.},
journal = {J. Optim. Theory Appl.},
month = nov,
pages = {227–244},
numpages = {18},
keywords = {Genetic algorithms, cannibalization, heuristics, marketing, pricing, product line design}
}

@article{10.1007/s10586-020-03210-2,
author = {Chiang, Ron C.},
title = {Contention-aware container placement strategy for docker swarm with machine learning based clustering algorithms},
year = {2020},
issue_date = {Feb 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-020-03210-2},
doi = {10.1007/s10586-020-03210-2},
abstract = {Containerization technology utilizes operating system level virtualization to package applications to run with required libraries and are isolated from other processes on the same host. Lightweight and quick deployment make containers popular in many data centers. Running distributed applications in data centers usually involves multiple clusters of machines. Docker Swarm is a container orchestration tool for managing a cluster of Docker containers and their hosts. However, Docker Swarm’s scheduler does not consider resource utilization when placing containers in a cluster. This paper first investigated performance interference in container clusters. Our experimental study showed that distributed applications’ performance can be degraded when co-located with other containers which aggressively consume resources. A new scheduler is proposed to improve performance while keeping high resource utilization. The experimental results demonstrated that the proposed prototype with machine learning based clustering algorithms could effectively improve distributed applications’ performance by up to 14.5% with an average at around 12%. This work also provides theoretical bounds for the container placement problem.},
journal = {Cluster Computing},
month = nov,
pages = {13–23},
numpages = {11},
keywords = {Cloud computing, Container, Virtualization, Serverless Computing, Microservices}
}

@article{10.1016/j.is.2008.04.003,
author = {Marb\'{a}n, Oscar and Segovia, Javier and Menasalvas, Ernestina and Fern\'{a}ndez-Baiz\'{a}n, Covadonga},
title = {Toward data mining engineering: A software engineering approach},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {34},
number = {1},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2008.04.003},
doi = {10.1016/j.is.2008.04.003},
abstract = {The number, variety and complexity of projects involving data mining or knowledge discovery in databases activities have increased just lately at such a pace that aspects related to their development process need to be standardized for results to be integrated, reused and interchanged in the future. Data mining projects are quickly becoming engineering projects, and current standard processes, like CRISP-DM, need to be revisited to incorporate this engineering viewpoint. This is the central motivation of this paper that makes the point that experience gained about the software development process over almost 40 years could be reused and integrated to improve data mining processes. Consequently, this paper proposes to reuse ideas and concepts underlying the IEEE Std 1074 and ISO 12207 software engineering model processes to redefine and add to the CRISP-DM process and make it a data mining engineering standard.},
journal = {Inf. Syst.},
month = mar,
pages = {87–107},
numpages = {21},
keywords = {Data mining, Knowledge engineering, Software engineering}
}

@inproceedings{10.1145/3220162.3220188,
author = {Ma, Xiaofeng and Yang, Yan and Zhou, Zhurong},
title = {Using Machine Learning Algorithm to Predict Student Pass Rates In Online Education},
year = {2018},
isbn = {9781450364577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220162.3220188},
doi = {10.1145/3220162.3220188},
abstract = {In online education, the quality evaluation of education is crucial importance to schools and even to the entire range of educational institutions. There are many ways to evaluate online education. Taking the prediction of student pass rates as an example, many researchers have used machine Learning algorithms to predict student pass rates and find out important student features affecting learning. However, they did not establish feature model for online education that predicts the student pass rates and introduce deep neural network (DNN) algorithms - a new method in machine learning into online education. Therefore, this study first explores how to establish a feature model that predicts the student pass rates for online education, and then uses the grid search (GS) algorithm to optimize the decision tree algorithm (DT) and support vector machine (SVM) algorithm to improve the prediction accuracy. Finally, compared the improved algorithm with the DNN algorithm, we find a suitable algorithm for student pass rate prediction. The purpose of this study is to improve the quality of online teaching by predicting the student pass rates, increasing students' academic performance and strengthening online educational management.},
booktitle = {Proceedings of the 3rd International Conference on Multimedia Systems and Signal Processing},
pages = {156–161},
numpages = {6},
keywords = {Decision Tree Algorithm, Deep Neural Network, Feature Model, Grid Search Algorithm, Support Vector Machine Algorithm},
location = {Shenzhen, China},
series = {ICMSSP '18}
}

@inproceedings{10.1145/3064663.3064735,
author = {Mellis, David A. and Zhang, Ben and Leung, Audrey and Hartmann, Bj\"{o}rn},
title = {Machine Learning for Makers: Interactive Sensor Data Classification Based on Augmented Code Examples},
year = {2017},
isbn = {9781450349222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064663.3064735},
doi = {10.1145/3064663.3064735},
abstract = {Although many software libraries and hardware modules support reading data from sensors, makers of interactive systems often struggle to extract higher-level information from raw sensor data. Available general-purpose machine learning (ML) libraries remain difficult to use for non-experts. Prior research has sought to bridge this gap through domain-specific user interfaces for particular types of sensors or algorithms. Our ESP (Example-based Sensor Prediction) system introduces a more general approach in which interactive visualizations and control interfaces are dynamically generated from augmented code examples written by experts. ESP's augmented examples allow experts to write logic that guides makers through important steps such as sensor calibration, parameter tuning, and assessing signal quality and classification performance. Writing augmented examples requires additional effort. ESP leverages a fundamental dynamic of online communities: experts are often willing to invest such effort to teach and train novices. Thus support for particular sensing domains does not have to be hard-wired a priori by system authors, but can be provided later by its community of users. We illustrate ESP's flexibility by detailing pipelines for four distinct sensors and classification algorithms. We validated the usability and flexibility of our example-based approach through a one-day workshop with 11 participants.},
booktitle = {Proceedings of the 2017 Conference on Designing Interactive Systems},
pages = {1213–1225},
numpages = {13},
location = {Edinburgh, United Kingdom},
series = {DIS '17}
}

@inproceedings{10.1145/2019136.2019169,
author = {Duran-Limon, Hector A. and Castillo-Barrera, Francisco E. and Lopez-Herrejon, Roberto E.},
title = {Towards an ontology-based approach for deriving product architectures},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019169},
doi = {10.1145/2019136.2019169},
abstract = {Software product line (SPL) engineering has proven to improve software quality and shorten costs and development time. An important aspect in the product line development process involves variability, which is the ability of a system for being customised, changed, or extended. Approaches are required for modelling and resolving variability as well as for verifying the selections. In this paper, we outline our ongoing research towards an approach that automates the derivation of product architectures from an SPL architecture. The proposed approach relies on ontology-based reasoning and model-driven techniques, the former supports the validation of the generated architectures and the generation of the transformation rules while the latter realises the actual target product architectures. We sketch our approach with a voice over IP case example.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {29},
numpages = {5},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1109/ICSE43902.2021.00109,
author = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
title = {InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00109},
doi = {10.1109/ICSE43902.2021.00109},
abstract = {Learning code representations has found many uses in software engineering, such as code classification, code search, comment generation, and bug prediction, etc. Although representations of code in tokens, syntax trees, dependency graphs, paths in trees, or the combinations of their variants have been proposed, existing learning techniques have a major limitation that these models are often trained on datasets labeled for specific downstream tasks, and as such the code representations may not be suitable for other tasks. Even though some techniques generate representations from unlabeled code, they are far from being satisfactory when applied to the downstream tasks. To overcome the limitation, this paper proposes InferCode, which adapts the self-supervised learning idea from natural language processing to the abstract syntax trees (ASTs) of code. The novelty lies in the training of code representations by predicting subtrees automatically identified from the contexts of ASTs. With InferCode, subtrees in ASTs are treated as the labels for training the code representations without any human labelling effort or the overhead of expensive graph construction, and the trained representations are no longer tied to any specific downstream tasks or code units.We have trained an instance of InferCode model using Tree-Based Convolutional Neural Network (TBCNN) as the encoder of a large set of Java code. This pre-trained model can then be applied to downstream unsupervised tasks such as code clustering, code clone detection, cross-language code search, or be reused under a transfer learning scheme to continue training the model weights for supervised tasks such as code classification and method name prediction. Compared to prior techniques applied to the same downstream tasks, such as code2vec, code2seq, ASTNN, using our pre-trained InferCode model higher performance is achieved with a significant margin for most of the tasks, including those involving different programming languages. The implementation of InferCode and the trained embeddings are available at the link: https://github.com/bdqnghi/infercode.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1186–1197},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1145/2719920,
author = {Karimi, Sarvnaz and Wang, Chen and Metke-Jimenez, Alejandro and Gaire, Raj and Paris, Cecile},
title = {Text and Data Mining Techniques in Adverse Drug Reaction Detection},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2719920},
doi = {10.1145/2719920},
abstract = {We review data mining and related computer science techniques that have been studied in the area of drug safety to identify signals of adverse drug reactions from different data sources, such as spontaneous reporting databases, electronic health records, and medical literature. Development of such techniques has become more crucial for public heath, especially with the growth of data repositories that include either reports of adverse drug reactions, which require fast processing for discovering signals of adverse reactions, or data sources that may contain such signals but require data or text mining techniques to discover them. In order to highlight the importance of contributions made by computer scientists in this area so far, we categorize and review the existing approaches, and most importantly, we identify areas where more research should be undertaken.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {56},
numpages = {39},
keywords = {Drug side effect, adverse drug reaction, data mining, drug safety, signal detection, statistical analysis, text mining}
}

@inproceedings{10.1145/3452296.3472926,
author = {Zhang, Qizhen and Ng, Kelvin K. W. and Kazer, Charles and Yan, Shen and Sedoc, Jo\~{a}o and Liu, Vincent},
title = {MimicNet: fast performance estimates for data center networks with machine learning},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472926},
doi = {10.1145/3452296.3472926},
abstract = {At-scale evaluation of new data center network innovations is becoming increasingly intractable. This is true for testbeds, where few, if any, can afford a dedicated, full-scale replica of a data center. It is also true for simulations, which while originally designed for precisely this purpose, have struggled to cope with the size of today's networks. This paper presents an approach for quickly obtaining accurate performance estimates for large data center networks. Our system,MimicNet, provides users with the familiar abstraction of a packet-level simulation for a portion of the network while leveraging redundancy and recent advances in machine learning to quickly and accurately approximate portions of the network that are not directly visible. MimicNet can provide over two orders of magnitude speedup compared to regular simulation for a data center with thousands of servers. Even at this scale, MimicNet estimates of the tail FCT, throughput, and RTT are within 5% of the true results.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {287–304},
numpages = {18},
keywords = {approximation, data center networks, machine learning, network modeling, network simulation},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@article{10.5555/2789272.2912094,
author = {Li, Chun-Liang and Su, Yu-Chuan and Lin, Ting-Wei and Tsai, Cheng-Hao and Chang, Wei-Cheng and Huang, Kuan-Hao and Kuo, Tzu-Ming and Lin, Shan-Wei and Lin, Young-San and Lu, Yu-Chen and Yang, Chun-Pai and Chang, Cheng-Xia and Chin, Wei-Sheng and Juan, Yu-Chin and Tung, Hsiao-Yu and Wang, Jui-Pin and Wei, Cheng-Kuang and Wu, Felix and Yin, Tu-Chun and Yu, Tong and Zhuang, Yong and Lin, Shou-De and Lin, Hsuan-Tien and Lin, Chih-Jen},
title = {Combination of feature engineering and ranking models for paper-author identification in KDD cup 2013},
year = {2015},
issue_date = {January 2015},
publisher = {JMLR.org},
volume = {16},
number = {1},
issn = {1532-4435},
abstract = {This paper describes the winning solution of team National Taiwan University for track 1 of KDD Cup 2013. The track 1 in KDD Cup 2013 considers the paper-author identification problem, which is to identify whether a paper is truly written by an author. First, we conduct feature engineering to transform the various types of provided text information into 97 features. Second, we train classification and ranking models using these features. Last, we combine our individual models to boost the performance by using results on the internal validation set and the official Valid set. Some effective post-processing techniques have also been proposed. Our solution achieves 0.98259 MAP score and ranks the first place on the private leaderboard of the Test set.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2921–2947},
numpages = {27},
keywords = {feature generation, paper-author identification}
}

@article{10.1016/j.eswa.2021.115589,
author = {Parmezan, Antonio Rafael Sabino and Lee, Huei Diana and Spola\^{o}r, Newton and Wu, Feng Chung},
title = {Automatic recommendation of feature selection algorithms based on dataset characteristics},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {185},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115589},
doi = {10.1016/j.eswa.2021.115589},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {30},
keywords = {Feature engineering, Characterization measures, Algorithm selection, Recommendation system, Filter, Wrapper}
}

@inproceedings{10.1145/3097983.3098186,
author = {Sharma, Ashlesh and Srinivasan, Vidyuth and Kanchan, Vishal and Subramanian, Lakshminarayanan},
title = {The Fake vs Real Goods Problem: Microscopy and Machine Learning to the Rescue},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098186},
doi = {10.1145/3097983.3098186},
abstract = {Counterfeiting of physical goods is a global problem amounting to nearly 7% of world trade. While there have been a variety of overt technologies like holograms and specialized barcodes and covert technologies like taggants and PUFs, these solutions have had a limited impact on the counterfeit market due to a variety of factors - clonability, cost or adoption barriers. In this paper, we introduce a new mechanism that uses machine learning algorithms on microscopic images of physical objects to distinguish between genuine and counterfeit versions of the same product. The underlying principle of our system stems from the idea that microscopic characteristics in a genuine product or a class of products (corresponding to the same larger product line), exhibit inherent similarities that can be used to distinguish these products from their corresponding counterfeit versions. A key building block for our system is a wide-angle microscopy device compatible with a mobile device that enables a user to easily capture the microscopic image of a large area of a physical object. Based on the captured microscopic images, we show that using machine learning algorithms (ConvNets and bag of words), one can generate a highly accurate classification engine for separating the genuine versions of a product from the counterfeit ones; this property also holds for "super-fake" counterfeits observed in the marketplace that are not easily discernible from the human eye. We describe the design of an end-to-end physical authentication system leveraging mobile devices, portable hardware and a cloud-based object verification ecosystem. We evaluate our system using a large dataset of 3 million images across various objects and materials such as fabrics, leather, pills, electronics, toys and shoes. The classification accuracy is more than 98% and we show how our system works with a cellphone to verify the authenticity of everyday objects.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2011–2019},
numpages = {9},
keywords = {computer vision, conventional neural networks, microscopy, physical authentication},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1007/978-3-030-21290-2_42,
author = {Reinhartz-Berger, Iris and Shimshoni, Ilan and Abdal, Aviva},
title = {Behavior-Derived Variability Analysis: Mining Views for Comparison and Evaluation},
year = {2019},
isbn = {978-3-030-21289-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-21290-2_42},
doi = {10.1007/978-3-030-21290-2_42},
abstract = {The large variety of computerized solutions (software and information systems) calls for a systematic approach to their comparison and evaluation. Different methods have been proposed over the years for analyzing the similarity and variability of systems. These methods get artifacts, such as requirements, design models, or code, of different systems (commonly in the same domain), identify and calculate their similarities, and represent the variability in models, such as feature diagrams. Most methods rely on implementation considerations of the input systems and generate outcomes based on predefined, fixed strategies of comparison (referred to as variability views). In this paper, we introduce an approach for mining relevant views for comparison and evaluation, based on the input artifacts. Particularly, we equip SOVA – a Semantic and Ontological Variability Analysis method – with data mining techniques in order to identify relevant views that highlight variability or similarity of the input artifacts (natural language requirement documents). The comparison is done using entropy and Rand index measures. The method and its outcomes are evaluated on a case of three photo sharing applications.},
booktitle = {Advanced Information Systems Engineering: 31st International Conference, CAiSE 2019, Rome, Italy, June 3–7, 2019, Proceedings},
pages = {675–690},
numpages = {16},
keywords = {Software Product Line Engineering, Variability analysis, Requirements specifications, Feature diagrams},
location = {Rome, Italy}
}

@article{10.5555/2627435.2627438,
author = {Oentaryo, Richard and Lim, Ee-Peng and Finegold, Michael and Lo, David and Zhu, Feida and Phua, Clifton and Cheu, Eng-Yeow and Yap, Ghim-Eng and Sim, Kelvin and Nguyen, Minh Nhut and Perera, Kasun and Neupane, Bijay and Faisal, Mustafa and Aung, Zeyar and Woon, Wei Lee and Chen, Wei and Patel, Dhaval and Berrar, Daniel},
title = {Detecting click fraud in online advertising: a data mining approach},
year = {2014},
issue_date = {January 2014},
publisher = {JMLR.org},
volume = {15},
number = {1},
issn = {1532-4435},
abstract = {Click fraud-the deliberate clicking on advertisements with no real interest on the product or service offered-is one of the most daunting problems in online advertising. Building an effective fraud detection method is thus pivotal for online advertising businesses. We organized a Fraud Detection in Mobile Advertising (FDMA) 2012 Competition, opening the opportunity for participants to work on real-world fraud data from BuzzCity Pte. Ltd., a global mobile advertising company based in Singapore. In particular, the task is to identify fraudulent publishers who generate illegitimate clicks, and distinguish them from normal publishers. The competition was held from September 1 to September 30, 2012, attracting 127 teams from more than 15 countries. The mobile advertising data are unique and complex, involving heterogeneous information, noisy patterns with missing values, and highly imbalanced class distribution. The competition results provide a comprehensive study on the usability of data mining-based fraud detection approaches in practical setting. Our principal findings are that features derived from fine-grained time-series analysis are crucial for accurate fraud detection, and that ensemble methods offer promising solutions to highly-imbalanced nonlinear classification tasks with mixed variable types and noisy/missing patterns. The competition data remain available for further studies at http://palanteer.sis.smu.edu.sg/fdma2012/.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {99–140},
numpages = {42},
keywords = {ensemble learning, feature engineering, fraud detection, imbalanced classification}
}

@inproceedings{10.1145/2364412.2364444,
author = {Filho, Jo\~{a}o Bosco Ferreira and Barais, Olivier and Baudry, Benoit and Viana, Windson and Andrade, Rossana M. C.},
title = {An approach for semantic enrichment of software product lines},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364444},
doi = {10.1145/2364412.2364444},
abstract = {Software Product Lines (SPLs) have evolved and gained attention as one of the most promising approaches for software reuse. Feature models are the main technique to represent domain variability in SPLs. However, there are other domain aspects, besides variability, which cannot be expressed in a feature model. Also, these diagrams were not designed to facilitate information retrieval, interoperability and inference. In contrast, ontologies seem to be the best solution to meet these requirements. Therefore, this work presents an approach for semantic enrichment of SPLs using ontologies. Our proposal provides methods to add domain information besides variability description, and a top-ontology that specifies generic concepts and relations in an SPL, working as a guide model for information addition. The proposed approach reuses the existing SPL feature model, adding semantic descriptions in a less intrusive way than modifying the feature model notation.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {188–195},
numpages = {8},
keywords = {knowledge, ontology, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/2939502.2939503,
author = {Kahng, Minsuk and Fang, Dezhi and Chau, Duen Horng (Polo)},
title = {Visual exploration of machine learning results using data cube analysis},
year = {2016},
isbn = {9781450342070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939502.2939503},
doi = {10.1145/2939502.2939503},
abstract = {As complex machine learning systems become more widely adopted, it becomes increasingly challenging for users to understand models or interpret the results generated from the models. We present our ongoing work on developing interactive and visual approaches for exploring and understanding machine learning results using data cube analysis. We propose MLCube, a data cube inspired framework that enables users to define instance subsets using feature conditions and computes aggregate statistics and evaluation metrics over the subsets. We also design MLCube Explorer, an interactive visualization tool for comparing models' performances over the subsets. Users can interactively specify operations, such as drilling down to specific instance subsets, to perform more in-depth exploration. Through a usage scenario, we demonstrate how MLCube Explorer works with a public advertisement click log data set, to help a user build new advertisement click prediction models that advance over an existing model.},
booktitle = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
articleno = {1},
numpages = {6},
keywords = {data cube, data visualization, interactive data analysis, machine learning},
location = {San Francisco, California},
series = {HILDA '16}
}

@inproceedings{10.1145/3196709.3196729,
author = {Yang, Qian and Suh, Jina and Chen, Nan-Chen and Ramos, Gonzalo},
title = {Grounding Interactive Machine Learning Tool Design in How Non-Experts Actually Build Models},
year = {2018},
isbn = {9781450351980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196709.3196729},
doi = {10.1145/3196709.3196729},
abstract = {Machine learning (ML) promises data-driven insights and solutions for people from all walks of life, but the skill of crafting these solutions is possessed by only a few. Emerging research addresses this issue by creating ML tools that are easy and accessible to people who are not formally trained in ML (non-experts). This work investigated how non-experts build ML solutions for themselves in real life. Our interviews and surveys revealed unique potentials of non-expert ML, as well several pitfalls that non-experts are susceptible to. For example, many perceived percentage accuracy as a sole measure of performance, thus problematic models proceeded to deployment. These observations suggested that, while challenging, making ML easy and robust should both be important goals of designing novice-facing ML tools. To advance on this insight, we discuss design implications and created a sensitizing concept to demonstrate how designers might guide non-experts to easily build robust solutions.},
booktitle = {Proceedings of the 2018 Designing Interactive Systems Conference},
pages = {573–584},
numpages = {12},
keywords = {empirical study, end-user machine learning, interactive machine learning, machine teaching, sensitizing concept, user-centered design},
location = {Hong Kong, China},
series = {DIS '18}
}

@inproceedings{10.1145/3387168.3387212,
author = {Christodoulou, Klitos and Iosif, Elias and Louca, Soulla and Themistocleous, Marinos},
title = {Identity Discovery in Bitcoin Blockchain: Leveraging Transactions Metadata via Supervised Learning},
year = {2020},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387212},
doi = {10.1145/3387168.3387212},
abstract = {Blockchain-based systems such as the one proposed to support the Bitcoin protocol are primarily used to enable the execution of financial transactions in a decentralized manner. The characteristics of blockchains have inspired the development of new types of applications that are shifting from its original purpose. Besides supporting the recording of crypto-currency transactions blockchains are also being exploited as mediums of recording arbitrary chunks of data. One technique for embedding such data on the public Bitcoin blockchain is using the OP_RETURN opcode creating an unspendable transaction.In this paper, we leverage data retrieved from such transactions to reveal the identity of the transacting entity. In more detail, we cast the problem of identity discovery as a classification problem. An empirical evaluation using various supervised classification models (from Naive Bayes to deep learning) yield up to 99.98% classification accuracy. In addition, it is confirmed that our feature engineering methodology on using the leading characters of the OP_RETURN instruction holds a significant discrimination power when compared against the baseline.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {30},
numpages = {6},
keywords = {Blockchain, Classification, Identity Discovery, Metadata},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@article{10.1007/s11192-018-2785-8,
author = {Karimi, Samaneh and Moraes, Luis and Das, Avisha and Shakery, Azadeh and Verma, Rakesh},
title = {Citance-based retrieval and summarization using IR and machine learning},
year = {2018},
issue_date = {August    2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {116},
number = {2},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-018-2785-8},
doi = {10.1007/s11192-018-2785-8},
abstract = {We consider the three interesting problems posed by the CL-SciSumm series of shared tasks. Given a reference document D and a set $$C_D$$CD of citances for D: (1) find the span of reference text that corresponds to each citance $$c in C_D$$c?CD, (2) identify the facet corresponding to each span of reference text from a predefined list of five facets, and (3) construct a summary of at most 250 words for D based on the reference spans. The shared task provided annotated training and test sets for these problems. This paper describes our efforts and the results achieved for each problem, and also a discussion of some interesting parameters of the datasets, which may spur further improvements and innovations.},
journal = {Scientometrics},
month = aug,
pages = {1331–1366},
numpages = {36},
keywords = {Citance-based summarization, Positional language model, Structural correspondence learning, Textual entailment}
}

@inproceedings{10.1145/3491087.3493675,
author = {Karagoz, Gizem Nur},
title = {Multi-objective evolutionary based feature selection supported by distributed multi-label classification and deep learning on image/video data},
year = {2021},
isbn = {9781450391559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491087.3493675},
doi = {10.1145/3491087.3493675},
abstract = {We live in an era in which a myriad of computer systems produce immense amounts of (raw) data every day. This big data must be processed efficiently to gain valuable and hidden knowledge. Complex processing pipelines need to be designed for filtering out irrelevant data, also for efficient data mining and machine learning methods must be used to discover useful correlations in the big data. The purpose of this PhD research is the implementation of multi-objective evolutionary-based dimensionality reduction on a high volume of image/video data with the support of distributed multi-label classification algorithms.},
booktitle = {Proceedings of the 22nd International Middleware Conference: Doctoral Symposium},
pages = {6–7},
numpages = {2},
keywords = {big data processing, dimensionality reduction, distributed machine learning, feature engineering, feature extraction},
location = {Qu\'{e}bec city, Canada},
series = {Middleware '21}
}

@inproceedings{10.1109/ICASSP.2016.7472125,
author = {Li, Ying and Mueller, Kevin and Contreras, Jose D. and Salazar, Luis J.},
title = {Classification of voices that elicit soothing effect by applying a voiced vs. unvoiced feature engineering strategy},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICASSP.2016.7472125},
doi = {10.1109/ICASSP.2016.7472125},
abstract = {This paper introduces a novel approach of classifying voices that elicit a soothing effect on listeners from a domain knowledge inspired application of feature engineering. In particular, we utilize the characteristics of voiced vs, unvoiced speech in order to build a more accurate feature set. Large sets of training data are prepared and disciplined feature selections are conducted. Our final classifier achieved 86.84% classification accuracy of cross validation and evaluations by unknown listener population via crowdsourcing have rates of agreement with the classification model range from 80% to 90%. The technologies are deployed into Jobaline products to help service companies identify hourly-job workers whose voice can elicit soothing effect on customers.},
booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
pages = {2489–2493},
numpages = {5},
location = {Shanghai, China}
}

@inproceedings{10.1145/2019136.2019178,
author = {Brataas, Gunnar and Jiang, Shanshan and Reichle, Roland and Geihs, Kurt},
title = {Performance property prediction supporting variability for adaptive mobile systems},
year = {2011},
isbn = {9781450307895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2019136.2019178},
doi = {10.1145/2019136.2019178},
abstract = {A performance property prediction (PPP) method for component-based self-adaptive applications is presented. Such performance properties are required by an adaptation middleware for reasoning about adaptation activities. Our PPP method is based on the Structure and Performance (SP) framework, a conceptually simple, yet powerful performance modelling framework based on matrices. The main contribution of this paper are the integration of SP-based PPP into a comprehensive model- and variability-based adaptation framework for context-aware mobile applications. A meta model for the SP method is described. The framework is demonstrated using a practical example.},
booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
articleno = {37},
numpages = {8},
keywords = {autonomic computing, mobile systems},
location = {Munich, Germany},
series = {SPLC '11}
}

@inproceedings{10.1109/SEiA.2019.00009,
author = {Omar, Sinayobye Janvier and Fred, Kiwanuka N. and Swaib, Kaawaase Kyanda and Richard, Musabe},
title = {Hybrid model of correlation based filter feature selection and machine learning classifiers applied on smart meter data set},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEiA.2019.00009},
doi = {10.1109/SEiA.2019.00009},
abstract = {Feature selection is referred to the process of obtaining a subset from an original feature set according to certain feature selection criterion, which selects the relevant features of the dataset. It plays a role in compressing the data processing scale, where the redundant and irrelevant features are removed. Feature selection techniques show that more information is not always good in machine learning applications. Apply different algorithms for the data at hand and with baseline classification performance values we can select a final feature selection algorithm. In this paper, we propose a hybrid classification model, which has correlation based filter feature selection algorithm and Machine learning as classifiers. The objective of this study is to select relevant features and analyze the outperform machine learning algorithms in order to train our model, predict and compare their classification performance. In this method, features are ordered according to their Absolute correlation value with respect to the class attribute. Then top K Features are selected from ordered list of features to form a reduced dataset. This proposed classifier model is applied to our smart meter datasets. To measure the performance of these selected features; seven benchmark classifier are used; Random Forest (RF), Logistic Regression (LR), k-Nearest Neighbor (kNN), Na\"{\i}ve Bayes (NB), Decision Tree (DT), Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM). This paper then analyzes the performance of all classifiers with feature selection in term of accuracy, sensitivity, F-Measure, Specificity, Precision, and MCC. From our experiment, we found that Random Forest classifier performed higher than other used classifiers.},
booktitle = {Proceedings of the 2nd Symposium on Software Engineering in Africa},
pages = {1–10},
numpages = {10},
keywords = {feature extraction, feature selection, machine learning, smart meter data sets},
location = {Montreal, Quebec, Canada},
series = {SEiA '19}
}

@inproceedings{10.1145/3097983.3098021,
author = {Baylor, Denis and Breck, Eric and Cheng, Heng-Tze and Fiedel, Noah and Foo, Chuan Yu and Haque, Zakaria and Haykal, Salem and Ispir, Mustafa and Jain, Vihan and Koc, Levent and Koo, Chiu Yuen and Lew, Lukasz and Mewald, Clemens and Modi, Akshay Naresh and Polyzotis, Neoklis and Ramesh, Sukriti and Roy, Sudip and Whang, Steven Euijong and Wicke, Martin and Wilkiewicz, Jarek and Zhang, Xin and Zinkevich, Martin},
title = {TFX: A TensorFlow-Based Production-Scale Machine Learning Platform},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098021},
doi = {10.1145/3097983.3098021},
abstract = {Creating and maintaining a platform for reliably producing and deploying machine learning models requires careful orchestration of many components---a learner for generating models based on training data, modules for analyzing and validating both data as well as models, and finally infrastructure for serving models in production. This becomes particularly challenging when data changes over time and fresh models need to be produced continuously. Unfortunately, such orchestration is often done ad hoc using glue code and custom scripts developed by individual teams for specific use cases, leading to duplicated effort and fragile systems with high technical debt.We present TensorFlow Extended (TFX), a TensorFlow-based general-purpose machine learning platform implemented at Google. By integrating the aforementioned components into one platform, we were able to standardize the components, simplify the platform configuration, and reduce the time to production from the order of months to weeks, while providing platform stability that minimizes disruptions.We present the case study of one deployment of TFX in the Google Play app store, where the machine learning models are refreshed continuously as new data arrive. Deploying TFX led to reduced custom code, faster experiment cycles, and a 2% increase in app installs resulting from improved data and model analysis.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1387–1395},
numpages = {9},
keywords = {continuous training, end-to-end platform, large-scale machine learning},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.5555/3000375.3000387,
author = {Xie, Jianjun and Leishman, Scott and Tian, Liang and Lisuk, David and Koo, Seongjoon and Blume, Matthias},
title = {Feature engineering in user's music preference prediction},
year = {2011},
publisher = {JMLR.org},
abstract = {The second track of this year's KDD Cup asked contestants to separate a user's highly rated songs from unrated songs for a large set of Yahoo! Music listeners. We cast this task as a binary classification problem and addressed it utilizing gradient boosted decision trees. We created a set of highly predictive features, each with a clear explanation. These features were grouped into five categories: hierarchical linkage features, track-based statistical features, user-based statistical features, features derived from the k-nearest neighbors of the users, and features derived from the k-nearest neighbors of the items. No music domain knowledge was needed to create these features. We demonstrate that each group of features improved the prediction accuracy of the classification model. We also discuss the top predictive features of each category in this paper.},
booktitle = {Proceedings of the 2011 International Conference on KDD Cup 2011 - Volume 18},
pages = {183–197},
numpages = {15},
keywords = {kNN, KDD Cup, feature engineering, recommender systems},
series = {KDDCUP'11}
}

@article{10.1007/s10845-012-0684-z,
author = {Jain, Rajeev and Singh, A. R. and Yadav, H. C. and Mishra, P. K.},
title = {Using data mining synergies for evaluating criteria at pre-qualification stage of supplier selection},
year = {2014},
issue_date = {February  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-012-0684-z},
doi = {10.1007/s10845-012-0684-z},
abstract = {A company must purchase a lot of diverse components and raw material from different upstream suppliers to manufacture or assemble its products. Under this situation the supplier selection has become a critical issue for the purchasing department.The selection of suppliers depends on number of criteria and the challenge is to optimize selection process based on critical criteria and select the best supplier(s). During supplier selection process initial screening of potential suppliers from a large set is vital and the determination of prospective supplier is largely dependent on the criteria chosen of such pre-qualification. In the literature, many judgments based methods are proposed and derived criteria selection from the opinion of either the customers or the experts. All these techniques use the knowledge and experience of the decision makers. These methods inherit certain degree of uncertainty due to complex supply chain structure. The extraction of hidden knowledge is one of the most important tools to address such uncertainty and data mining is one such concept to account for such uncertainty and it has been found applicable in many scenarios. The proposed research aims to introduce a data mining approach, to discover the hidden relationships among the supplier's pre-qualification data with the overall supplier rating that have been derived after observation of previously executed work for a period of time. It provides an overview that how supplier's initial strength influence its final work performance.},
journal = {J. Intell. Manuf.},
month = feb,
pages = {165–175},
numpages = {11},
keywords = {Data mining, Supplier selection, Supplier's pre-qualification, Supply chain management (SCM), i-PM algorithm}
}

@inproceedings{10.1007/978-3-030-66981-2_11,
author = {Barbaglia, Luca and Consoli, Sergio and Manzan, Sebastiano},
title = {Exploring the Predictive Power of News and Neural Machine Learning Models for Economic Forecasting},
year = {2020},
isbn = {978-3-030-66980-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-66981-2_11},
doi = {10.1007/978-3-030-66981-2_11},
abstract = {Forecasting economic and financial variables is a challenging task for several reasons, such as the low signal-to-noise ratio, regime changes, and the effect of volatility among others. A recent trend is to extract information from news as an additional source to forecast economic activity and financial variables. The goal is to evaluate if news can improve forecasts from standard methods that usually are not well-specified and have poor out-of-sample performance. In a currently on-going project, our goal is to combine a richer information set that includes news with a state-of-the-art machine learning model. In particular, we leverage on two recent advances in Data Science, specifically on Word Embedding and Deep Learning models, which have recently attracted extensive attention in many scientific fields. We believe that by combining the two methodologies, effective solutions can be built to improve the prediction accuracy for economic and financial time series. In this preliminary contribution, we provide an overview of the methodology under development and some initial empirical findings. The forecasting model is based on DeepAR, an auto-regressive probabilistic Recurrent Neural Network model, that is combined with GloVe Word Embeddings extracted from economic news. The target variable is the spread between the US 10-Year Treasury Constant Maturity and the 3-Month Treasury Constant Maturity (T10Y3M). The DeepAR model is trained on a large number of related GloVe Word Embedding time series, and employed to produce point and density forecasts.},
booktitle = {Mining Data for Financial Applications: 5th ECML PKDD Workshop, MIDAS 2020, Ghent, Belgium, September 18, 2020, Revised Selected Papers},
pages = {135–149},
numpages = {15},
keywords = {Economic and financial forecasting, Neural time series forecasting, Deep learning, Recurrent neural networks, Long short-term memory networks, Word embedding, News analysis},
location = {Ghent, Belgium}
}

@article{10.1145/3479008,
author = {Venkata, Santhilata Kuppili and Young, Paul and Bell, Mark and Green, Alex},
title = {Alexa, Is This a Historical Record?},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1556-4673},
url = {https://doi.org/10.1145/3479008},
doi = {10.1145/3479008},
abstract = {Digital transformation in government has brought an increase in the scale, variety, and complexity of records and greater levels of disorganised data. Current practices for selecting records for transfer to The National Archives (TNA) were developed to deal with paper records and are struggling to deal with this shift. This article examines the background to the problem and outlines a project that TNA undertook to research the feasibility of using commercially available artificial intelligence tools to aid selection. The project AI for Selection evaluated a range of commercial solutions varying from off-the-shelf products to cloud-hosted machine learning platforms, as well as a benchmarking tool developed in-house. Suitability of tools depended on several factors, including requirements and skills of transferring bodies as well as the tools’ usability and configurability. This article also explores questions around trust and explainability of decisions made when using AI for sensitive tasks such as selection.},
journal = {J. Comput. Cult. Herit.},
month = dec,
articleno = {7},
numpages = {20},
keywords = {Document selection, artificial intelligence methodologies, supervised learning methods}
}

@inproceedings{10.1145/3316781.3317884,
author = {Zhou, Yuan and Ren, Haoxing and Zhang, Yanqing and Keller, Ben and Khailany, Brucek and Zhang, Zhiru},
title = {PRIMAL: Power Inference using Machine Learning},
year = {2019},
isbn = {9781450367257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316781.3317884},
doi = {10.1145/3316781.3317884},
abstract = {This paper introduces PRIMAL, a novel learning-based framework that enables fast and accurate power estimation for ASIC designs. PRIMAL trains machine learning (ML) models with design verification testbenches for characterizing the power of reusable circuit building blocks. The trained models can then be used to generate detailed power profiles of the same blocks under different workloads. We evaluate the performance of several established ML models on this task, including ridge regression, gradient tree boosting, multi-layer perceptron, and convolutional neural network (CNN). For average power estimation, ML-based techniques can achieve an average error of less than 1% across a diverse set of realistic benchmarks, outperforming a commercial RTL power estimation tool in both accuracy and speed (15x faster). For cycle-by-cycle power estimation, PRIMAL is on average 50x faster than a commercial gate-level power analysis tool, with an average error less than 5%. In particular, our CNN-based method achieves a 35x speed-up and an error of 5.2% for cycle-by-cycle power estimation of a RISC-V processor core. Furthermore, our case study on a NoC router shows that PRIMAL can achieve a small estimation error of 4.5% using cycle-approximate traces from SystemC simulation.},
booktitle = {Proceedings of the 56th Annual Design Automation Conference 2019},
articleno = {39},
numpages = {6},
keywords = {Power estimation, machine learning},
location = {Las Vegas, NV, USA},
series = {DAC '19}
}

@inproceedings{10.1145/1858996.1859009,
author = {Vierhauser, Michael and Gr\"{u}nbacher, Paul and Egyed, Alexander and Rabiser, Rick and Heider, Wolfgang},
title = {Flexible and scalable consistency checking on product line variability models},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859009},
doi = {10.1145/1858996.1859009},
abstract = {The complexity of product line variability models makes it hard to maintain their consistency over time regardless of the modeling approach used. Engineers thus need support for detecting and resolving inconsistencies. We describe experiences of applying a tool-supported approach for incremental consistency checking on variability models. Our approach significantly improves the overall performance and scalability compared to batch-oriented techniques and allows providing immediate feedback to modelers. It is extensible as new consistency constraints can easily be added. Furthermore, the approach is flexible as it is not limited to variability models and it also checks the consistency of the models with the underlying code base of the product line. We report the results of a thorough evaluation based on real-world product line models and discuss lessons learned.},
booktitle = {Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {incremental consistency checking, lessons learned, memory consumption, model consistency, performance, software product lines, variability models},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@article{10.1007/s11042-020-08906-6,
author = {Sellam, Abdellah and Azzoune, Hamid},
title = {Neighborhood min distance descriptor for kinship verification},
year = {2020},
issue_date = {Aug 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {29–30},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-08906-6},
doi = {10.1007/s11042-020-08906-6},
abstract = {The verification of parental and family relationships based on the facial appearance of subjects is a recent topic that attracted the attention of the computer vision research community. So many feature descriptors for facial images have been proposed, yet they are still unable to describe the similarity level of pairs of facial images in kinship datasets, because most of these images suffer from the illumination and expression variations. In this paper we propose a simple and effective descriptor for pairs of images, this descriptor is designed to be more robust to variations in expression, the idea of the descriptor is to compare each pixel in the first image of the pair with the neighboring pixels in the second image in terms of the euclidean distance on the RGB color space, the minimal distance in this neighborhood is then added to the feature vector of the pair. Experiments on the size of the neighborhood with various classifiers were conducted using the KinFaceW and Cornell-KinFace datasets, results demonstrated that this descriptor outperforms state-of-the-art approaches in five out of eight subsets of the KinFaceW and on the Cornell-KinFace dataset.},
journal = {Multimedia Tools Appl.},
month = aug,
pages = {20861–20880},
numpages = {20},
keywords = {Kinship verification, Feature engineering, Classification}
}

@article{10.1007/s00500-021-05796-0,
author = {Nguyen, Son P.},
title = {Deep customer segmentation with applications to a Vietnamese supermarkets’ data},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {12},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-05796-0},
doi = {10.1007/s00500-021-05796-0},
abstract = {A central problem in customer relation management (CRM) is to cluster customers into meaningful groups.  The problem is often called customer segmentation and is of paramount importance in the twenty-first century due to the rapid development of E-commerce which generates databases containing millions of customers. Recent algorithms in machine learning have been successful in clustering a wide range of datasets such as images, text documents, news and so on. Inspired by those accomplishments, we design a new segmentation model based on a combination of a deep neural network and a self-supervised probabilistic clustering technique. The new model is more flexible and more adaptive to the diversity of customer datasets compared to current heuristic algorithms in CRM. Moreover, feature engineering is the process to clean, prepare and transform raw data into features which are then fed into a model to produce clusters. To perform feature engineering, we combine a novel categorical encoding method in economics and an autoencoder, a recent machine learning data transformation method, to extract useful patterns from the original data. Our experiments with the full model on a set of retail transaction data from a supermarket chain in Ho Chi Minh city, Vietnam, show the capabilities of our algorithm to produce useful, explainable customer clusters.},
journal = {Soft Comput.},
month = jun,
pages = {7785–7793},
numpages = {9},
keywords = {Customer segmentation, Clustering, Machine learning, Autoencoder, Representation learning, Econometrics}
}

@article{10.1016/j.engappai.2012.09.017,
author = {Galitsky, Boris},
title = {Machine learning of syntactic parse trees for search and classification of text},
year = {2013},
issue_date = {March, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {26},
number = {3},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2012.09.017},
doi = {10.1016/j.engappai.2012.09.017},
abstract = {We build an open-source toolkit which implements deterministic learning to support search and text classification tasks. We extend the mechanism of logical generalization towards syntactic parse trees and attempt to detect weak semantic signals from them. Generalization of syntactic parse tree as a syntactic similarity measure is defined as the set of maximum common sub-trees and performed at a level of paragraphs, sentences, phrases and individual words. We analyze semantic features of such similarity measure and compare it with semantics of traditional anti-unification of terms. Nearest-neighbor machine learning is then applied to relate a sentence to a semantic class. Using syntactic parse tree-based similarity measure instead of bag-of-words and keyword frequency approach, we expect to detect a weak semantic signal otherwise unobservable. The proposed approach is evaluated in a four distinct domains where a lack of semantic information makes classification of sentences rather difficult. We describe a toolkit which is a part of Apache Software Foun-dation project OpenNLP, designed to aid search engineers in tasks requiring text relevance assessment.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {1072–1091},
numpages = {20},
keywords = {Machine learning, Parse trees, Text classification, Text search}
}

@inproceedings{10.1145/3365109.3368786,
author = {Jeong, Taehee and Prakash Kankalale, Deeksha and Chau, Raymond and Jeon, Hyeran},
title = {Going Deeper or Wider: Throughput Prediction for Cluster Tools with Machine Learning},
year = {2019},
isbn = {9781450370165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365109.3368786},
doi = {10.1145/3365109.3368786},
abstract = {Cluster tools are automated robotic manufacturing systems andwidely used in semiconductor industry. As the structure of semi-conductor chips becomes more complicated, the complexity of fab-ricating process and the number of fabricating steps are increased.Therefore, the throughput of cluster tool becomes more difficult topredict. The throughput of a cluster tool is defined as the numberof wafers processed in an hour. The throughput of cluster tools hasnonlinear relationship with operating parameters, such as recipetime, cleaning (W ACT M) time, and look-ahead time (JIT1). Existingthroughput models have limitations that only provide the worst andthe best throughput boundaries and have exponentially increasingcomplexity when considering more resources and scheduling steps.Instead, we propose to use machine learning algorithms for clus-ter tool throughput prediction. To understand the nonlinearity ofthroughput of cluster tool and identify the best algorithm that rep-resents the behavior of cluster tool, we evaluated various machinelearning algorithms as well as deep neural networks (DNN). AsDNN performance varies significantly depending on the architec-ture of the network, we explored both depth and width dimensionsof architecture; going deeper (more layers) and going wider (moreneurons per layers). Our evaluation shows that the throughput ofcluster tools with multiple parallel PMs with dual transfer cham-ber arms, buffered AirLocks, and cleaning after recipe can be wellpredicted with deeper DNNs than wider DNNs.},
booktitle = {Proceedings of the 6th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies},
pages = {21–30},
numpages = {10},
keywords = {cluster tool, deep neural network, feature engineering, throughput prediction},
location = {Auckland, New Zealand},
series = {BDCAT '19}
}

@phdthesis{10.5555/1834989,
author = {Feng, Kunwu},
advisor = {Cooper, Kendra M.},
title = {Towards an agile product line requirements engineering framework: knowledge acquisition and process definition},
year = {2009},
isbn = {9781109408010},
publisher = {University of Texas at Dallas},
address = {USA},
abstract = {The strong benefits of applying a well suited RE process on a project have been presented in the literature: it increases the productivity of the development teams, reduces products’ time-to-market and development costs, and improves customer satisfaction. Research on RE processes has been conducted in different, independent research areas, including the agile and product line communities. The former is to provide lighter weight, faster, and nimbler software development processes that allow developers to quickly create high quality software in rapidly changing business environments, while the latter is to efficiently build a set of family projects by assembling pre-developed assets based on planning. Although numerous process models and techniques have been proposed and developed to provide support for requirements development, a huge gap still exists between theory and practices. One of the challenging research problems is how to define or select a requirements engineering (RE) process and a set of RE techniques that is well suited for a project in terms of the degree of agility for product line projects.The objectives of this research are, therefore, to improve the state of the art in this new research area, which focuses on collecting RE knowledge from experts, and identifying the applicability of RE process models and techniques for specific software projects. The outcome of this research is Agile Product Line Requirements Engineering Framework (APLE-RE). The APLE-RE framework recommends a set of RE techniques based on project characteristics and provides a set of process patterns for requirements engineers. It contains two components: Knowledge Acquisition and Process Repository. Knowledge Acquisition is developed to collect expertise of researchers and practitioners who are actively involved in software development using agile, product line RE techniques. A scenario-driven, online-based questionnaire is designed to accomplish this. Based on the knowledge collecting by the questionnaire, the data analysis work uses some machine learning methods to analyze RE techniques in detail and select a set of RE techniques for each project characteristics. The selected RE techniques will be recommended in Process Repository. Process Repository is to provide a collection of process patterns which can help requirements engineers to choose or tailor one pattern for their own purposes, especially for agile product line products. These process patterns are tailored versions of UP and presented in UML, which range from very agile to plan driven approaches for single product and product line RE. In addition, these patterns provides a disciplined approach to assigning tasks and responsibilities within a development organization to ensure that software development process follows a set of pre-defined workflow and produce the high quality software within a predictable schedule and budget. 171 patterns are identified, including 9 single product patterns and 162 product line patterns. Six patterns have been defined and 2 patterns have been validated. The validation approach is based on existing case studies reported in the literature. Case studies are reverse engineered with respect to the RE process used. The closest matching pattern is manually identified in the repository. The difference from the pattern and the actual process used are identified and classified; the difference can be used to indicate the usefulness of the pattern.},
note = {AAI3375943}
}

@article{10.1016/j.eswa.2019.113001,
author = {Bruni, Renato and Bianchi, Gianpiero},
title = {Website categorization: A formal approach and robustness analysis in the case of e-commerce detection},
year = {2020},
issue_date = {Mar 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113001},
doi = {10.1016/j.eswa.2019.113001},
journal = {Expert Syst. Appl.},
month = mar,
numpages = {14},
keywords = {Classification, Machine learning, E-commerce, Feature engineering, Text mining, Surveys}
}

@article{10.1016/j.jbi.2012.04.010,
author = {Garla, Vijay N. and Brandt, Cynthia},
title = {Ontology-guided feature engineering for clinical text classification},
year = {2012},
issue_date = {October, 2012},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {45},
number = {5},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2012.04.010},
doi = {10.1016/j.jbi.2012.04.010},
abstract = {Graphical abstractDisplay Omitted Highlights Leveraged the structure of the UMLS to rank concepts for text classification. Used document class labels to define a context-sensitive semantic similarity measure. Classified clinical text with SVMs using a semantic kernel. Improved the top machine-learning system from I2B2 2008 challenge. In this study we present novel feature engineering techniques that leverage the biomedical domain knowledge encoded in the Unified Medical Language System (UMLS) to improve machine-learning based clinical text classification. Critical steps in clinical text classification include identification of features and passages relevant to the classification task, and representation of clinical text to enable discrimination between documents of different classes. We developed novel information-theoretic techniques that utilize the taxonomical structure of the Unified Medical Language System (UMLS) to improve feature ranking, and we developed a semantic similarity measure that projects clinical text into a feature space that improves classification. We evaluated these methods on the 2008 Integrating Informatics with Biology and the Bedside (I2B2) obesity challenge. The methods we developed improve upon the results of this challenge's top machine-learning based system, and may improve the performance of other machine-learning based clinical text classification systems. We have released all tools developed as part of this study as open source, available at http://code.google.com/p/ytex.},
journal = {J. of Biomedical Informatics},
month = oct,
pages = {992–998},
numpages = {7},
keywords = {Feature selection, Information content, Information gain, Kernel methods, Natural language processing, Semantic similarity}
}

@inproceedings{10.1007/978-3-319-38921-9_12,
author = {Velez, Gorka and Quartulli, Marco and Martin, Angel and Otaegui, Oihana and Assem, Haytham},
title = {Machine Learning for Autonomic Network Management in a Connected Cars Scenario},
year = {2016},
isbn = {9783319389202},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-38921-9_12},
doi = {10.1007/978-3-319-38921-9_12},
abstract = {Current 4G networks are approaching the limits of what is possible with this generation of radio technology. Future 5G networks will be highly based on software, with the ultimate goal of being self-managed. Machine Learning is a key technology to reach the vision of a 5G self-managing network. This new paradigm will significantly impact on connected vehicles, fostering a new wave of possibilities. This paper presents a preliminary approach towards Autonomic Network Management on a connected cars scenario. The focus is on the machine learning part, which will allow forecasting resource demand requirements, detecting errors, attacks and outlier events, and responding and taking corrective actions.},
booktitle = {Proceedings of the 10th International Workshop on Communication Technologies for Vehicles - Volume 9669},
pages = {111–120},
numpages = {10},
keywords = {5G, Connected cars, Machine learning, Network management}
}

@inproceedings{10.1145/3425174.3425211,
author = {Ferreira, Thiago do Nascimento and Vergilio, Silvia Regina and Kessentini, Marouane},
title = {Applying Many-objective Algorithms to the Variability Test of Software Product Lines},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425211},
doi = {10.1145/3425174.3425211},
abstract = {The problem known as Variability Test of Software Product Line (VTSPL) is related to the selection of the most representative products for the SPL testing. This is an optimization problem because a possible exponential number of products can be derived from the SPL variability model, such as the Feature Model (FM). In the literature many works are dedicated to this research subject, each one applying a different search-based algorithm and using distinct criteria. However, there is no study encompassing all these criteria at the same time. To this end, this paper investigates the use of two Many-Objective Evolutionary Algorithms (MaOEAs). We apply the algorithm NSGA-III, widely used for many-objective algorithms, and the algorithm PCA-NSGA-II, a reduction dimensionality algorithm, which uses the Principal-Component Analysis (PCA) in combination with NSGA-II, to evaluate the objectives used in the literature for the VTSPL problem. PCA-NSGA-II reduces the search space dimensionality by eliminating the redundant objectives. The analysis shows the importance of some objectives such as the number of alive mutants, similarity between products, and unselected features. NSGA-III reaches the best results regarding the quality indicators for all instances, but taking a longer time. Besides, PCA-NSGA-II can find different solutions in the search space that are not found by NSGA-III.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {11–20},
numpages = {10},
keywords = {Software product line testing, dimensionality reduction, many-objective problems},
location = {Natal, Brazil},
series = {SAST '20}
}

@inproceedings{10.1007/978-3-030-37599-7_6,
author = {Ghidini, Valentina and Perotti, Alan and Schifanella, Rossano},
title = {Quantitative and Ontology-Based Comparison of Explanations for Image Classification},
year = {2019},
isbn = {978-3-030-37598-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37599-7_6},
doi = {10.1007/978-3-030-37599-7_6},
abstract = {Deep Learning models have recently achieved incredible performances in the Computer Vision field and are being deployed in an ever-growing range of real-life scenarios. Since they do not intrinsically provide insights of their inner decision processes, the field of eXplainable Artificial Intelligence emerged. Different XAI techniques have already been proposed, but the existing literature lacks methods to quantitatively compare different explanations, and in particular the semantic component is systematically overlooked. In this paper we introduce quantitative and ontology-based techniques and metrics in order to enrich and compare different explanations and XAI algorithms.},
booktitle = {Machine Learning, Optimization, and Data Science: 5th International Conference, LOD 2019, Siena, Italy, September 10–13, 2019, Proceedings},
pages = {58–70},
numpages = {13},
keywords = {Explainable artificial intelligence, Neural networks, Deep learning, Computer vision},
location = {Siena, Italy}
}

@article{10.1007/s10916-015-0379-z,
author = {Ramos, M. Isabel and Cubillas, Juan Jos\'{e} and Feito, Francisco R.},
title = {Improvement of the Prediction of Drugs Demand Using Spatial Data Mining Tools},
year = {2016},
issue_date = {January   2016},
publisher = {Plenum Press},
address = {USA},
volume = {40},
number = {1},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-015-0379-z},
doi = {10.1007/s10916-015-0379-z},
abstract = {The continued availability of products at any store is the major issue in order to provide good customer service. If the store is a drugstore this matter reaches a greater importance, as out of stock of a drug when there is high demand causes problems and tensions in the healthcare system. There are numerous studies of the impact this issue has on patients. The lack of any drug in a pharmacy in certain seasons is very common, especially when some external factors proliferate favoring the occurrence of certain diseases. This study focuses on a particular drug consumed in the city of Jaen, southern Andalucia, Spain. Our goal is to determine in advance the Salbutamol demand. Advanced data mining techniques have been used with spatial variables. These last have a key role to generate an effective model. In this research we have used the attributes that are associated with Salbutamol demand and it has been generated a very accurate prediction model of 5.78% of mean absolute error. This is a very encouraging data considering that the consumption of this drug in Jaen varies 500% from one period to another.},
journal = {J. Med. Syst.},
month = jan,
pages = {1–9},
numpages = {9},
keywords = {Data mining, GIS, Pharmacy, Salbutamol, Spatial variables}
}

@inproceedings{10.5555/1753235.1753267,
author = {Mendonca, Marcilio and W\k{a}sowski, Andrzej and Czarnecki, Krzysztof},
title = {SAT-based analysis of feature models is easy},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {Feature models are a popular variability modeling notation used in product line engineering. Automated analyses of feature models, such as consistency checking and interactive or offline product selection, often rely on translating models to propositional logic and using satisfiability (SAT) solvers.Efficiency of individual satisfiability-based analyses has been reported previously. We generalize and quantify these studies with a series of independent experiments. We show that previously reported efficiency is not incidental. Unlike with the general SAT instances, which fall into easy and hard classes, the instances induced by feature modeling are easy throughout the spectrum of realistic models. In particular, the phenomenon of phase transition is not observed for realistic feature models.Our main practical conclusion is a general encouragement for researchers to continued development of SAT-based methods to further exploit this efficiency in future.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {231–240},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@inproceedings{10.5555/2667036.2667042,
author = {Carvalho, Sergio T. and Murta, Leonardo and Loques, Orlando},
title = {Variabilities as first-class elements in product line architectures of homecare systems},
year = {2012},
isbn = {9781467318433},
publisher = {IEEE Press},
abstract = {A homecare system should adapt to changes regarding the patient needs and to variations in the residential environment. This requires a software architecture designed to support customizations before the deployment (static variability) and changes during the system operation (dynamic variability). We present a comprehensive approach in which both kinds of variabilities are seamless described by means of contracts, which are first-class elements associated with a Product Line architecture. To demonstrate the proposed approach, we present a dynamic contract developed to support a context-aware patient reminder application.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering in Health Care},
pages = {33–39},
numpages = {7},
keywords = {SPL architecture, dynamic variability, homecare systems, software architecture, static variability},
location = {Zurich, Switzerland},
series = {SEHC '12}
}

@article{10.1016/j.future.2021.06.011,
author = {Wang, Bin and Ding, Shuai and Liu, Xiao and Li, X. and Li, Gang},
title = {Predictive classification of ICU readmission using weight decay random forest},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {124},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2021.06.011},
doi = {10.1016/j.future.2021.06.011},
journal = {Future Gener. Comput. Syst.},
month = nov,
pages = {351–360},
numpages = {10},
keywords = {Predictive classification, Sparse data, Imbalanced data, Weight decay, Feature engineering}
}

@inproceedings{10.1007/978-3-030-33904-3_7,
author = {Alves, Jairo L. and Weitzel, Leila and Quaresma, Paulo and Cardoso, Carlos E. and Cunha, Luan},
title = {Brazilian Presidential Elections in the Era of Misinformation: A Machine Learning Approach to Analyse Fake News},
year = {2019},
isbn = {978-3-030-33903-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33904-3_7},
doi = {10.1007/978-3-030-33904-3_7},
abstract = {As Brazil faced one of its most important elections in recent times, the fact-checking agencies handled the same kind of misinformation that has attacked voting in the US. However, stopping fake content before it goes viral remains an intense challenge. This paper examines a sample database of the 2018 Brazilian election articles shared by Brazilians over social media platforms. We evaluated three different configuration of Long Short-Term Memory. Experiment results indicate that the 3-layer Deep BiLSTMs with trainable word embeddings configuration was the best structure for fake news detection. We noticed that the developments in deep learning could potentially benefit fake news research.},
booktitle = {Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications: 24th Iberoamerican Congress, CIARP 2019, Havana, Cuba, October 28-31, 2019, Proceedings},
pages = {72–84},
numpages = {13},
keywords = {Fake news, Machine learning, Long Short-Term Memory, Word embeddings, Deep learning, Recurrent neural network},
location = {Havana, Cuba}
}

@article{10.1007/s10618-019-00616-4,
author = {Clark, Jessica and Provost, Foster},
title = {Unsupervised dimensionality reduction versus supervised regularization for classification from sparse data},
year = {2019},
issue_date = {Jul 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {33},
number = {4},
issn = {1384-5810},
url = {https://doi.org/10.1007/s10618-019-00616-4},
doi = {10.1007/s10618-019-00616-4},
abstract = {Unsupervised matrix-factorization-based dimensionality reduction (DR) techniques are popularly used for feature engineering with the goal of improving the generalization performance of predictive models, especially with massive, sparse feature sets. Often DR is employed for the same purpose as supervised regularization and other forms of complexity control: exploiting a bias/variance tradeoff to mitigate overfitting. Contradicting this practice, there is consensus among existing expert guidelines that supervised regularization is a superior way to improve predictive performance. However, these guidelines are not always followed for this sort of data, and it is not unusual to find DR used with no comparison to modeling with the full feature set. Further, the existing literature does not take into account that DR and supervised regularization are often used in conjunction. We experimentally compare binary classification performance using DR features versus the original features under numerous conditions: using a total of 97 binary classification tasks, 6 classifiers, 3 DR techniques, and 4 evaluation metrics. Crucially, we also experiment using varied methodologies to tune and evaluate various key hyperparameters. We find a very clear, but nuanced result. Using state-of-the-art hyperparameter-selection methods, applying DR does not add value beyond supervised regularization, and can often diminish performance. However, if regularization is not done well (e.g., one just uses the default regularization parameter), DR does have relatively better performance--but these approaches result in lower performance overall. These latter results provide an explanation for why practitioners may be continuing to use DR without undertaking the necessary comparison to using the original features. However, this practice seems generally wrongheaded in light of the main results, if the goal is to maximize generalization performance.},
journal = {Data Min. Knowl. Discov.},
month = jul,
pages = {871–916},
numpages = {46},
keywords = {Binary classification, Data mining, Dimensionality reduction, Experimental comparison, Sparse data}
}

@article{10.1016/j.infsof.2005.03.007,
author = {Mahmood, Sajjad and Lai, Richard and Soo Kim, Yong and Hong Kim, Ji and Cheon Park, Seok and Suk Oh, Hae},
title = {A survey of component based system quality assurance and assessment},
year = {2005},
issue_date = {July, 2005},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {47},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2005.03.007},
doi = {10.1016/j.infsof.2005.03.007},
abstract = {Component Based Software Development (CBSD) is focused on assembling existing components to build a software system, with a potential benefit of delivering quality systems by using quality components. It departs from the conventional software development process in that it is integration centric as opposed to development centric. The quality of a component based system using high quality components does not therefore necessarily guarantee a system of high quality, but depends on the quality of its components, and a framework and integration process used. Hence, techniques and methods for quality assurance and assessment of a component based system would be different from those of the traditional software engineering methodology. It is essential to quantify factors that contribute to the overall quality, for instances, the trade off between cost and quality of a component, analytical techniques and formal methods, and quality attribute definitions and measurements. This paper presents a literature survey of component based system quality assurance and assessment; the areas surveyed include formalism, cost estimation, and assessment and measurement techniques for the following quality attributes: performance, reliability, maintainability and testability. The aim of this survey is to help provide a better understanding of CBSD in these aspects in order to facilitate the realisation of its potential benefits of delivering quality systems.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {693–707},
numpages = {15}
}

@inproceedings{10.1145/3416028.3417215,
author = {Dahl, Oskar and Johansson, Fredrik and Khoshkangini, Reza and Pashami, Sepideh and Nowaczyk, S\l{}awomir and Claes, Pihl},
title = {Understanding Association Between Logged Vehicle Data and Vehicle Marketing Parameters: Using Clustering and Rule-Based Machine Learning},
year = {2020},
isbn = {9781450375467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416028.3417215},
doi = {10.1145/3416028.3417215},
abstract = {Trucks are designed, configured and marketed for various working environments. There lies a concern whether trucks are used as intended by the manufacturer, as usage may impact the longevity, efficiency and productivity of the trucks. In this paper we propose a framework that aims to extract costumers' vehicle behaviours from Logged Vehicle Data (LVD) in order to evaluate whether they align with vehicle configurations, so-called Global Transport Application (GTA) parameters. Gaussian mixture model (GMM)s are employed to cluster and classify various vehicle behaviors from the LVD. Rule-based machine learning (RBML) was applied on the clusters to examine whether vehicle behaviors follow the GTA configuration.Particularly, we propose an approach based on studying associations that is able to extract insights on whether the trucks are used as intended. Experimental results shown that while for the vast majority of the trucks' behaviors seemingly follows their GTA configuration, there are also interesting outliers that warrant further analysis.},
booktitle = {Proceedings of the 3rd International Conference on Information Management and Management Science},
pages = {13–22},
numpages = {10},
keywords = {Gaussian Mixture Models, Machine Learning, Usage Behaviors},
location = {London, United Kingdom},
series = {IMMS '20}
}

@inproceedings{10.1007/978-3-030-78292-4_21,
author = {Litman, Diane and Zhang, Haoran and Correnti, Richard and Matsumura, Lindsay Clare and Wang, Elaine},
title = {A Fairness Evaluation of Automated Methods for Scoring Text Evidence Usage in Writing},
year = {2021},
isbn = {978-3-030-78291-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78292-4_21},
doi = {10.1007/978-3-030-78292-4_21},
abstract = {Automated Essay Scoring (AES) can reliably grade essays at scale and reduce human effort in both classroom and commercial settings. There are currently three dominant supervised learning paradigms for building AES models: feature-based, neural, and hybrid. While feature-based models are more explainable, neural network models often outperform feature-based models in terms of prediction accuracy. To create models that are accurate and explainable, hybrid approaches combining neural network and feature-based models are of increasing interest. We compare these three types of AES models with respect to a different evaluation dimension, namely algorithmic fairness. We apply three definitions of AES fairness to an essay corpus scored by different types of AES systems with respect to upper elementary students’ use of text evidence. Our results indicate that different AES models exhibit different types of biases, spanning students’ gender, race, and socioeconomic status. We conclude with a step towards mitigating AES bias once detected.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part I},
pages = {255–267},
numpages = {13},
keywords = {Automated essay scoring, Fairness, Argumentation},
location = {Utrecht, The Netherlands}
}

@article{10.1007/s10270-020-00803-8,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming},
title = {A framework for automated multi-stage and multi-step product configuration of cyber-physical systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00803-8},
doi = {10.1007/s10270-020-00803-8},
abstract = {Product line engineering (PLE) has been employed to large-scale cyber-physical systems (CPSs) to provide customization based on users’ needs. A PLE methodology can be characterized by its support for capturing and managing the abstractions as commonalities and variabilities and the automation of the configuration process for effective selection and customization of reusable artifacts. The automation of a configuration process heavily relies on the captured abstractions and formally specified constraints using a well-defined modeling methodology. Based on the results of our previous work and a thorough literature review, in this paper, we propose a conceptual framework to support multi-stage and multi-step automated product configuration of CPSs, including a comprehensive classification of constraints and a list of automated functionalities of a CPS configuration solution. Such a framework can serve as a guide for researchers and practitioners to evaluate an existing CPS PLE solution or devise a novel CPS PLE solution. To validate the framework, we conducted three real-world case studies. Results show that the framework fulfills all the requirements of the case studies in terms of capturing and managing variabilities and constraints. Results of the literature review indicate that the framework covers all the functionalities concerned by the literature, suggesting that the framework is complete for enabling the maximum automation of configuration in CPS PLE.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {211–265},
numpages = {55},
keywords = {Cyber-physical systems, Product line engineering, Automated configuration, Multi-stage and multi-step configuration process, Constraint classification, Variability modeling, Real-world case studies}
}

@article{10.1016/j.artmed.2021.102167,
author = {Abdollahi, Mahdi and Gao, Xiaoying and Mei, Yi and Ghosh, Shameek and Li, Jinyan and Narag, Michael},
title = {Substituting clinical features using synthetic medical phrases: Medical text data augmentation techniques},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102167},
doi = {10.1016/j.artmed.2021.102167},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {12},
keywords = {Unified Medical Language System, Natural language processing, Machine learning, Data augmentation, Medical document classification}
}

@article{10.1145/3447332.3447336,
author = {Audeh, Bissan and Beigbeder, Michel and Largeron, Christine and Ram\'{\i}rez-Cifuentes, Diana},
title = {Improving exploratory information retrieval for neophytes: machine learning approach with feature analysis},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1559-6915},
url = {https://doi.org/10.1145/3447332.3447336},
doi = {10.1145/3447332.3447336},
abstract = {Digital libraries have become an essential tool for researchers in all scientific domains. With almost unlimited storage capacities, current digital libraries hold a tremendous number of documents. Though some efforts have been made to facilitate access to documents relevant to a specific information need, such a task remains a real challenge for a new researcher. Indeed neophytes do not necessarily use appropriate keywords to express their information need and they might not be qualified enough to evaluate correctly the relevance of documents retrieved by the system. In this study, we suppose that to better meet the needs of neophytes, the information retrieval system in a digital library should take into consideration features other than content-based relevance. To test this hypothesis, we use machine learning methods and build new features from several metadata related to documents. More precisely, we propose to consider as features for machine learning: content-based scores, scores based on the citation graph and scores based on metadata extracted from external resources. As acquiring such features is not a trivial task, we analyze their usefulness and their capacity to detect relevant documents. Our analysis concludes that the use of these additional features improves the performance of the system for a neophyte. In fact, by adding the new features we find more documents suitable for neophytes within the results returned by the system than when using content-based features alone.},
journal = {SIGAPP Appl. Comput. Rev.},
month = jan,
pages = {50–64},
numpages = {15},
keywords = {digital libraries, information retrieval, machine learning, scientific document recommendation}
}

@article{10.1016/j.future.2018.09.053,
author = {Cecchinel, Cyril and Fouquet, Fran\c{c}ois and Mosser, S\'{e}bastien and Collet, Philippe},
title = {Leveraging live machine learning and deep sleep to support a self-adaptive efficient configuration of battery powered sensors},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.09.053},
doi = {10.1016/j.future.2018.09.053},
journal = {Future Gener. Comput. Syst.},
month = mar,
pages = {225–240},
numpages = {16}
}

@inproceedings{10.1145/3474624.3476016,
author = {Bezerra, Carla and Lima, Rafael and Silva, Publio},
title = {DyMMer 2.0: A Tool for Dynamic Modeling and Evaluation of Feature Model},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3476016},
doi = {10.1145/3474624.3476016},
abstract = {Managing dynamic variability has motivated several researchers to combine Dynamic Software Product Lines (DSPLs) practices with runtime variability mechanisms. By combining these approaches, a DSPL acquires important features, ranging from the ability to reconfigure by changing the context, adding or removing features, crash recovery, and re-adaptation based on changes in the model’s features. Feature model (FM) is an important artifact of a DPSL and there is a lack of tools that support the modeling of this artifact. We have extended the DyMMer tool for modeling FM of DSPLs from an adaptation mechanism based on MAPE-K to solve this problem. We migrated the DyMMer tool to a web version and incorporated new features: (i) modeling of FMs from SPLs and DSPLs, (ii) development of an adaptation mechanism for FM of DSPLs, (iii) repository of FMs, (iv) inclusion of thresholds for measures, and (v) user authentication. We believe that this tool is useful for research in the area of DSPLs, and also for dynamic domain modeling and evaluation. Video: https://youtu.be/WVHW6bI8ois},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {121–126},
numpages = {6},
keywords = {Dynamic Software Product Line, Feature Model, Modeling},
location = {Joinville, Brazil},
series = {SBES '21}
}

@article{10.1145/3051482,
author = {Demirbilek, Edip and Gr\'{e}goire, Jean-Charles},
title = {Machine Learning--Based Parametric Audiovisual Quality Prediction Models for Real-Time Communications},
year = {2017},
issue_date = {May 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3051482},
doi = {10.1145/3051482},
abstract = {In order to mechanically predict audiovisual quality in interactive multimedia services, we have developed machine learning--based no-reference parametric models. We have compared Decision Trees--based ensemble methods, Genetic Programming and Deep Learning models that have one and more hidden layers. We have used the Institut national de la recherche scientifique (INRS) audiovisual quality dataset specifically designed to include ranges of parameters and degradations typically seen in real-time communications. Decision Trees--based ensemble methods have outperformed both Deep Learning-- and Genetic Programming--based models in terms of Root-Mean-Square Error (RMSE) and Pearson correlation values. We have also trained and developed models on various publicly available datasets and have compared our results with those of these original models. Our studies show that Random Forests--based prediction models achieve high accuracy for both the INRS audiovisual quality dataset and other publicly available comparable datasets.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
articleno = {16},
numpages = {25},
keywords = {MOS, Perceived quality estimation, audiovisual quality dataset, machine learning, no-reference models}
}

@article{10.1007/s10664-020-09853-4,
author = {Hajri, Ines and Goknil, Arda and Pastore, Fabrizio and Briand, Lionel C.},
title = {Automating system test case classification and prioritization for use case-driven testing in product lines},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09853-4},
doi = {10.1007/s10664-020-09853-4},
abstract = {Product Line Engineering (PLE) is a crucial practice in many software development environments where software systems are complex and developed for multiple customers with varying needs. At the same time, many development processes are use case-driven and this strongly influences their requirements engineering and system testing practices. In this paper, we propose, apply, and assess an automated system test case classification and prioritization approach specifically targeting system testing in the context of use case-driven development of product families. Our approach provides: (i) automated support to classify, for a new product in a product family, relevant and valid system test cases associated with previous products, and (ii) automated prioritization of system test cases using multiple risk factors such as fault-proneness of requirements and requirements volatility in a product family. Our evaluation was performed in the context of an industrial product family in the automotive domain. Results provide empirical evidence that we propose a practical and beneficial way to classify and prioritize system test cases for industrial product lines.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3711–3769},
numpages = {59},
keywords = {Product Line Engineering, Use case driven development, Regression testing, Test case selection and prioritization, Automotive, Requirements engineering}
}

@inproceedings{10.1145/3394486.3403184,
author = {Kang, Tianyu and Chen, Ping and Quackenbush, John and Ding, Wei},
title = {A Novel Deep Learning Model by Stacking Conditional Restricted Boltzmann Machine and Deep Neural Network},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403184},
doi = {10.1145/3394486.3403184},
abstract = {A real-world system often exhibits complex dynamics arising from interaction among its subunits. In machine learning and data mining, these interactions are usually formulated as dependency and correlation among system variables. Similar to Convolution Neural Network dealing with spatially correlated features and Recurrent Neural Network with temporally correlated features, in this paper we present a novel deep learning model to tackle functionally interactive features by stacking a Conditional Restricted Boltzmann Machine and a Deep Neural Network (CRBM-DNN). Variables with their dependency relationships are organized into a bipartite graph, which is further converted into a Restricted Boltzmann Machine conditioned by domain knowledge. We integrate this CRBM and a DNN into one deep learning model constrained by one overall cost function. CRBM-DNN can solve both supervised and unsupervised learning problems. Compared to a regular neural network of the same size, CRBM-DNN has fewer parameters so they require fewer training samples. We perform extensive comparative studies with a large number of supervised learning and unsupervised learning methods using several challenging real-world datasets, and achieve significant superior performance.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1316–1324},
numpages = {9},
keywords = {conditional restricted Boltzmann machine, deep neural network, domain knowledge},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.5555/1857999.1858082,
author = {Berg-Kirkpatrick, Taylor and Bouchard-C\^{o}t\'{e}, Alexandre and DeNero, John and Klein, Dan},
title = {Painless unsupervised learning with features},
year = {2010},
isbn = {1932432655},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We show how features can easily be added to standard generative models for unsupervised learning, without requiring complex new training methods. In particular, each component multinomial of a generative model can be turned into a miniature logistic regression model if feature locality permits. The intuitive EM algorithm still applies, but with a gradient-based M-step familiar from discriminative training of logistic regression models. We apply this technique to part-of-speech induction, grammar induction, word alignment, and word segmentation, incorporating a few linguistically-motivated features into the standard generative model for each task. These feature-enhanced models each outperform their basic counterparts by a substantial margin, and even compete with and surpass more complex state-of-the-art models.},
booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
pages = {582–590},
numpages = {9},
location = {Los Angeles, California},
series = {HLT '10}
}

@article{10.1007/s10506-020-09273-1,
author = {Branting, L. Karl and Pfeifer, Craig and Brown, Bradford and Ferro, Lisa and Aberdeen, John and Weiss, Brandy and Pfaff, Mark and Liao, Bill},
title = {Scalable and explainable legal prediction},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2},
issn = {0924-8463},
url = {https://doi.org/10.1007/s10506-020-09273-1},
doi = {10.1007/s10506-020-09273-1},
abstract = {Legal decision-support systems have the potential to improve access to justice, administrative efficiency, and judicial consistency, but broad adoption of such systems is contingent on development of technologies with low knowledge-engineering, validation, and maintenance costs. This paper describes two approaches to an important form of legal decision support—explainable outcome prediction—that obviate both annotation of an entire decision corpus and manual processing of new cases. The first approach, which uses an attention network for prediction and attention weights to highlight salient case text, was shown to be capable of predicting decisions, but attention-weight-based text highlighting did not demonstrably improve human decision speed or accuracy in an evaluation with 61 human subjects. The second approach, termed semi-supervised case annotation for legal explanations, exploits structural and semantic regularities in case corpora to identify textual patterns that have both predictable relationships to case decisions and explanatory value.},
journal = {Artif. Intell. Law},
month = jun,
pages = {213–238},
numpages = {26},
keywords = {Artificial intelligence and law, Machine learning, Human language technology, Explainable prediction}
}

@inproceedings{10.1145/3219819.3219909,
author = {Sun, Mengying and Tang, Fengyi and Yi, Jinfeng and Wang, Fei and Zhou, Jiayu},
title = {Identify Susceptible Locations in Medical Records via Adversarial Attacks on Deep Predictive Models},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219909},
doi = {10.1145/3219819.3219909},
abstract = {The surging availability of electronic medical records (EHR) leads to increased research interests in medical predictive modeling. Recently many deep learning based predicted models are also developed for EHR data and demonstrated impressive performance. However, a series of recent studies showed that these deep models are not safe: they suffer from certain vulnerabilities. In short, a well-trained deep network can be extremely sensitive to inputs with negligible changes. These inputs are referred to as adversarial examples. In the context of medical informatics, such attacks could alter the result of a high performance deep predictive model by slightly perturbing a patient's medical records. Such instability not only reflects the weakness of deep architectures, more importantly, it offers a guide on detecting susceptible parts on the inputs. In this paper, we propose an efficient and effective framework that learns a time-preferential minimum attack targeting the LSTM model with EHR inputs, and we leverage this attack strategy to screen medical records of patients and identify susceptible events and measurements. The efficient screening procedure can assist decision makers to pay extra attentions to the locations that can cause severe consequence if not measured correctly. We conduct extensive empirical studies on a real-world urgent care cohort and demonstrate the effectiveness of the proposed screening.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {793–801},
numpages = {9},
keywords = {adversarial attack, medical records, predictive modeling},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/2939672.2939710,
author = {Khan, Muhammad R. and Blumenstock, Joshua E.},
title = {Predictors without Borders: Behavioral Modeling of Product Adoption in Three Developing Countries},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939710},
doi = {10.1145/2939672.2939710},
abstract = {Billions of people around the world live without access to banks or other formal financial institutions. In the past several years, many mobile operators have launched "Mobile Money" platforms that deliver basic financial services over the mobile phone network. While many believe that these services can improve the lives of the poor, in many countries adoption of Mobile Money still remains anemic. In this paper, we develop a predictive model of Mobile Money adoption that uses billions of mobile phone communications records to understand the behavioral determinants of adoption. We describe a novel approach to feature engineering that uses a Deterministic Finite Automaton to construct thousands of behavioral metrics of phone use from a concise set of recursive rules. These features provide the foundation for a predictive model that is tested on mobile phone operators logs from Ghana, Pakistan, and Zambia, three very different developing-country contexts. The results highlight the key correlates of Mobile Money use in each country, as well as the potential for such methods to predict and drive adoption. More generally, our analysis provides insight into the extent to which homogenized supervised learning methods can generalize across geographic contexts. We find that without careful tuning, a model that performs very well in one country frequently does not generalize to another.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {145–154},
numpages = {10},
keywords = {feature engineering, gradient boosting, mobilemoney, product adoption, supervised learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{10.1016/j.neucom.2019.02.017,
author = {Zhu, Jiajing and Liu, Yongguo and Zhang, Yun and Chen, Zhi and Li, Qiaoqin and Yang, Shangming and Liu, Xiaofeng and Zhai, Shuangqing and Zhang, Yi and Wen, Chuanbiao},
title = {IHPreten: A novel supervised learning framework with attribute regularization for prediction of incompatible herb pair in traditional Chinese medicine},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {338},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.02.017},
doi = {10.1016/j.neucom.2019.02.017},
journal = {Neurocomput.},
month = apr,
pages = {207–221},
numpages = {15},
keywords = {Incompatible herb pair, Supervised learning, Attribute regularization, Non-negative matrix factorization, Traditional Chinese medicine}
}

@inproceedings{10.1109/RAISE.2019.00014,
author = {Hesenius, Marc and Schwenzfeier, Nils and Meyer, Ole and Koop, Wilhelm and Gruhn, Volker},
title = {Towards a software engineering process for developing data-driven applications},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAISE.2019.00014},
doi = {10.1109/RAISE.2019.00014},
abstract = {Machine Learning and Artificial Intelligence allow the development of a new type of applications that automatically identify hidden patterns, process large amounts of data, and classify data according to aforementioned patterns. While they offer interesting solutions for several problems, they also impose challenges on software engineers in charge of structuring the development effort. The new applications require to incorporate additional specialists and their work into an overall development effort. We thus propose a software engineering process for data-driven applications.},
booktitle = {Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {35–41},
numpages = {7},
keywords = {artificial intelligence, development process, machine learning, software engineering},
location = {Montreal, Quebec, Canada},
series = {RAISE '19}
}

@inproceedings{10.1109/WAIN52551.2021.00008,
author = {Catovic, Armin and Cartwright, Carolyn and Gebreyesus, Yasmin Tesfaldet and Ferlin, Simone},
title = {Linnaeus: A highly reusable and adaptable ML based log classification pipeline},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/WAIN52551.2021.00008},
doi = {10.1109/WAIN52551.2021.00008},
abstract = {Logs are a common way to record detailed run-time information in software. As modern software systems evolve in scale and complexity, logs have become indispensable to understanding the internal states of the system. At the same time however, manually inspecting logs has become impractical. In recent times, there has been more emphasis on statistical and machine learning (ML) based methods for analyzing logs. While the results have shown promise, most of the literature focuses on algorithms and state-of-the-art (SOTA), while largely ignoring the practical aspects. In this paper we demonstrate our end-to-end log classification pipeline, Linnaeus. Besides showing the more traditional ML flow, we also demonstrate our solutions for adaptability and re-use, integration towards large scale software development processes, and how we cope with lack of labelled data. We hope Linnaeus can serve as a blueprint for, and inspire the integration of, various ML based solutions in other large scale industrial settings.},
booktitle = {2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)},
pages = {11–18},
numpages = {8},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3290605.3300358,
author = {Hu, Kevin and Bakker, Michiel A. and Li, Stephen and Kraska, Tim and Hidalgo, C\'{e}sar},
title = {VizML: A Machine Learning Approach to Visualization Recommendation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300358},
doi = {10.1145/3290605.3300358},
abstract = {Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {automated visualization, crowdsourcing, machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3483899.3483905,
author = {Freire, Willian and Tonh\~{a}o, Simone and Bonetti, Tiago and Shigenaga, Marcelo and Cadette, William and Felizardo, Fernando and Amaral, Aline and OliveiraJr, Edson and Colanzi, Thelma},
title = {On the configuration of multi-objective evolutionary algorithms for PLA design optimization},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483905},
doi = {10.1145/3483899.3483905},
abstract = {Search-based algorithms have been successfully applied in the Product Line Architecture (PLA) optimization using the seminal approach called Multi-Objective Approach for Product-Line Architecture Design (MOA4PLA). This approach produces a set of alternative PLA designs intending to improve the different factors being optimized. Currently, the MOA4PLA uses the NSGA-II algorithm, a multi-objective evolutionary algorithm (MOEA) that can optimize several architectural properties simultaneously. Despite the promising results, studying the best values for the algorithm parameters is essential to obtain even better results. This is also crucial to ease the adoption of MOA4PLA by newcomers or non-expert companies willing to start using search-based software engineering to PLA design. Three crossover operators for the PLA design optimization were proposed recently. However, reference values for parameters have not been defined for PLA design optimization using crossover operators. In this context, the objective of this work is conducting an experimental study to discover which are the most effective crossover operators and the best values to configure the MOEA parameters, such as population size, number of generations, and mutation and crossover rates. A quantitative analysis based on quality indicators and statistical tests was performed using four PLA designs to determine the most suitable parameter values to the search-based algorithm. Empirical results pointed out the best combination of crossover operators and the most suitable values to configure MOA4PLA.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {11–20},
numpages = {10},
keywords = {Multi-objective evolutionary algorithm, recombination operators, software architecture, software product line},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@article{10.1016/j.artmed.2021.102130,
author = {Cao, Qing and Du, Nan and Yu, Li and Zuo, Ming and Lin, Jingsheng and Liu, Nathan and Zhong, Erheng and Liu, Zizhu and Chen, Qiaoran and Shen, Ying and Chen, Kang},
title = {Practical fine-grained learning based anomaly classification for ECG image},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {119},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102130},
doi = {10.1016/j.artmed.2021.102130},
journal = {Artif. Intell. Med.},
month = sep,
numpages = {11},
keywords = {Neural networks, ECG anomaly classification, Machine learning, Fine-grained classification}
}

@article{10.1016/j.scico.2006.10.007,
author = {Pe\~{n}a, Joaquin and Hinchey, Michael G. and Resinas, Manuel and Sterritt, Roy and Rash, James L.},
title = {Designing and managing evolving systems using a MAS product line approach},
year = {2007},
issue_date = {April, 2007},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {66},
number = {1},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2006.10.007},
doi = {10.1016/j.scico.2006.10.007},
abstract = {We view an evolutionary system as being a software product line. The core architecture is the unchanging part of the system, and each version of the system may be viewed as a product from the product line. Each ''product'' may be described as the core architecture with some agent-based additions. The result is a multiagent system software product line. We describe an approach to such a software product line-based approach using the MaCMAS agent-oriented methodology. The approach scales to enterprise architectures as a multiagent system is an appropriate means of representing a changing enterprise architecture and the interaction between components in it. In addition, we reduce the gap between the enterprise architecture and the software architecture.},
journal = {Sci. Comput. Program.},
month = apr,
pages = {71–86},
numpages = {16},
keywords = {Enterprise architecture evolution, Multiagent systems product lines, Swarm-based systems}
}

@article{10.1145/3387166,
author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D.},
title = {A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3–4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3387166},
doi = {10.1145/3387166},
abstract = {The need for interpretable and accountable intelligent systems grows along with the prevalence of artificial intelligence (AI) applications used in everyday life. Explainable AI (XAI) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = sep,
articleno = {24},
numpages = {45},
keywords = {Explainable artificial intelligence (XAI), human-computer interaction (HCI), machine learning, explanation, transparency}
}

@inproceedings{10.1007/978-3-031-20837-9_15,
author = {Boutorh, Aicha and Rahim, Hala and Bendoumia, Yassmine},
title = {Explainable AI Models for&nbsp;COVID-19 Diagnosis Using CT-Scan Images and&nbsp;Clinical Data},
year = {2021},
isbn = {978-3-031-20836-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20837-9_15},
doi = {10.1007/978-3-031-20837-9_15},
abstract = {The pandemic of COVID-19 has had a significant impact on global health and is becoming a major international concern. Fortunately, early detection helped decrease its number of deaths. Artificial Intelligence (AI) and Machine Learning (ML) techniques are a new era, where the main objective is no longer to assist experts in decision-making but to improve and increase their capabilities and this is where interpretability comes in. This study aims to address one of the biggest hurdles that AI faces today which is public trust and acceptance due to its black-box strategy. In this paper, we use a deep Convolutional Neural Network (CNN) on chest computed tomography (CT) image data and Support Vector Machine (SVM) and Random Forest (RF) on clinical symptoms data (Bio-data) to diagnose patients positive for COVID-19. Our objective is to present an Explainable AI (XAI) models by using the Local Interpretable Model-agnostic Explanations (LIME) technique to identify positive patients to the virus in an interpreted way. The results are promising and outperformed the state of the art. The CNN model reached an Accuracy and F1-Score of 96% on CT-scan images, and SVM outperformed RF with Accuracy of 90% and Specificity of 91% on Bio-data. The interpretable results of XAI-Img-Model and XAI-Bio-Model, show that LIME explanations help to understand how SVM and CNN black box models behave in making their decision after being trained on different types of COVID-19 dataset. This can significantly increase trust and help experts understand and learn new patterns for the current pandemic.},
booktitle = {Computational Intelligence Methods for Bioinformatics and Biostatistics: 17th International Meeting, CIBB 2021, Virtual Event, November 15–17, 2021, Revised Selected Papers},
pages = {185–199},
numpages = {15},
keywords = {Explainable AI, Deep learning, CNN, Black box classifiers, LIME, COVID-19 diagnosis, Image data, Clinical data}
}

@article{10.1504/IJSN.2012.048493,
author = {Alsubhi, K. and Alhazmi, Y. and Bouabdallah, N. and Boutaba, R.},
title = {Security configuration management in intrusion detection and prevention systems},
year = {2012},
issue_date = {August 2012},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {7},
number = {1},
issn = {1747-8405},
url = {https://doi.org/10.1504/IJSN.2012.048493},
doi = {10.1504/IJSN.2012.048493},
abstract = {This paper aims to study the impact of security enforcement levels on the performance and usability of an enterprise information system. We develop a new analytical model to investigate the relationship between the Intrusion Detection and Prevention System performance and the rules mode selection. In particular, we analyze the IDPS rule-checking process along with its consequent action on the resulting security of the network and on the average service time per event. Simulation was conducted to validate our performance analysis study. The results demonstrate that it is desirable to strike a balance between system security and network performance.},
journal = {Int. J. Secur. Netw.},
month = aug,
pages = {30–39},
numpages = {10}
}

@article{10.5555/3455716.3455773,
author = {Ma, Fan and Meng, Deyu and Dong, Xuanyi and Yang, Yi},
title = {Self-paced multi-view co-training},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Co-training is a well-known semi-supervised learning approach which trains classifiers on two or more different views and exchanges pseudo labels of unlabeled instances in an iterative way. During the co-training process, pseudo labels of unlabeled instances are very likely to be false especially in the initial training, while the standard co-training algorithm adopts a "draw without replacement" strategy and does not remove these wrongly labeled instances from training stages. Besides, most of the traditional co-training approaches are implemented for two-view cases, and their extensions in multi-view scenarios are not intuitive. These issues not only degenerate their performance as well as available application range but also hamper their fundamental theory. Moreover, there is no optimization model to explain the objective a co-training process manages to optimize. To address these issues, in this study we design a unified self-paced multi-view co-training (SPamCo) framework which draws unlabeled instances with replacement. Two specified co-regularization terms are formulated to develop different strategies for selecting pseudo-labeled instances during training. Both forms share the same optimization strategy which is consistent with the iteration process in co-training and can be naturally extended to multi-view scenarios. A distributed optimization strategy is also introduced to train the classifier of each view in parallel to further improve the efficiency of the algorithm. Furthermore, the SPamCo algorithm is proved to be PAC learnable, supporting its theoretical soundness. Experiments conducted on synthetic, text categorization, person re-identification, image recognition and object detection data sets substantiate the superiority of the proposed method.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {57},
numpages = {38},
keywords = {co-training, self-paced learning, multi-view learning, semi-supervised learning, ε-expansion theory, probably approximately correct learnable}
}

@inproceedings{10.1145/3362789.3362923,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco J. and Ther\'{o}n, Roberto},
title = {Automatic generation of software interfaces for supporting decision-making processes. An application of domain engineering and machine learning},
year = {2019},
isbn = {9781450371919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3362789.3362923},
doi = {10.1145/3362789.3362923},
abstract = {Information dashboards are sophisticated tools. Although they enable users to reach useful insights and support their decision-making challenges, a good design process is essential to obtain powerful tools. Users need to be part of these design processes, as they will be the consumers of the information displayed. But users are very diverse and can have different goals, beliefs, preferences, etc., and creating a new dashboard for each potential user is not viable. There exist several tools that allow users to configure their displays without requiring programming skills. However, users might not exactly know what they want to visualize or explore, also becoming the configuration process a tedious task. This research project aims to explore the automatic generation of user interfaces for supporting these decision-making processes. To tackle these challenges, a domain engineering, and machine learning approach is taken. The main goal is to automatize the design process of dashboards by learning from the context, including the end-users and the target data to be displayed.},
booktitle = {Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {1007–1011},
numpages = {5},
keywords = {Automatic generation, Domain engineering, High-level requirements, Information Dashboards, Meta-modeling},
location = {Le\'{o}n, Spain},
series = {TEEM'19}
}

@inproceedings{10.1145/1852786.1852794,
author = {Murgia, Alessandro and Concas, Giulio and Marchesi, Michele and Tonelli, Roberto},
title = {A machine learning approach for text categorization of fixing-issue commits on CVS},
year = {2010},
isbn = {9781450300391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852786.1852794},
doi = {10.1145/1852786.1852794},
abstract = {We studied data mining from CVS repositories of two large OO projects, Eclipse and Netbeans, focusing on "fixing-issue" commits.We highlight common characteristics of issue reporting, and problems related to the identification of these messages, and compare static traditional approaches, like Knowledge Engineering, to dynamic approaches based on Machine Learning techniques. We compare for the first time performances of Machine Learning (ML) techniques to automatic classify "fixing-issues" among message commits. Our study calculates precision and recall of different Machine Learning Classifiers for the correct classification of issue-reporting commits. Our results show that some ML classifiers can correctly classify up to 99.9% of such commits.},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {6},
numpages = {10},
keywords = {classifier, data mining, machine learning},
location = {Bolzano-Bozen, Italy},
series = {ESEM '10}
}

@inproceedings{10.1145/3292500.3330704,
author = {Wang, Bin and Lu, Jie and Yan, Zheng and Luo, Huaishao and Li, Tianrui and Zheng, Yu and Zhang, Guangquan},
title = {Deep Uncertainty Quantification: A Machine Learning Approach for Weather Forecasting},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330704},
doi = {10.1145/3292500.3330704},
abstract = {Weather forecasting is usually solved through numerical weather prediction (NWP), which can sometimes lead to unsatisfactory performance due to inappropriate setting of the initial states. In this paper, we design a data-driven method augmented by an effective information fusion mechanism to learn from historical data that incorporates prior knowledge from NWP. We cast the weather forecasting problem as an end-to-end deep learning problem and solve it by proposing a novel negative log-likelihood error (NLE) loss function. A notable advantage of our proposed method is that it simultaneously implements single-value forecasting and uncertainty quantification, which we refer to as deep uncertainty quantification (DUQ). Efficient deep ensemble strategies are also explored to further improve performance. This new approach was evaluated on a public dataset collected from weather stations in Beijing, China. Experimental results demonstrate that the proposed NLE loss significantly improves generalization compared to mean squared error (MSE) loss and mean absolute error (MAE) loss. Compared with NWP, this approach significantly improves accuracy by 47.76%, which is a state-of-the-art result on this benchmark dataset.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2087–2095},
numpages = {9},
keywords = {deep learning, uncertainty quantification, urban computing, weather forecasting},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1007/s11042-021-11474-y,
author = {Mahajan, Shubham and Pandit, Amit Kant},
title = {Hybrid method to supervise feature selection using signal processing and complex algebra techniques},
year = {2021},
issue_date = {Mar 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {82},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-11474-y},
doi = {10.1007/s11042-021-11474-y},
abstract = {Research in AI has proved to be revolutionarily beneficial to humankind from the past few decades. Many supporting techniques have been developed that indirectly evolved AI and directly enhanced various machine learning models; one of them being the feature engineering. It can also be considered as applied-ML. Another is the so-called feature selection which is method in which most contributing feature to final decision making, out of the entire feature space are selected for processing into an ML model. It is not an easy task to precisely calculate the dependency of the output variable onto the candidate features, particularly when the data is high in dimensions. In this regard, this study proposes a novel method named the cisoidal analysis based feature selection (CAFS) which uses both pre-established algorithms as well as a new approach of relating members of feature space to a complex sinusoid (cisoid) mathematically, then using signal processing techniques to eliminate certain elements in the entire feature space for enhanced feature selection and hence to obtain higher classification accuracy. Derived from experiments with five high dimensional datasets, CAFS displays significantly competitive performance than some of the pre-existing algorithms. CAFS is highly advantageous in reducing dimension of feature space in most of the applications.},
journal = {Multimedia Tools Appl.},
month = oct,
pages = {8213–8234},
numpages = {22},
keywords = {Feature selection, Complex algebra, Feature engineering, Hybrid feature selection, Signal processing, Fourier transform, Image}
}

@inproceedings{10.1007/978-3-030-58942-4_7,
author = {Bengio, Yoshua and Frejinger, Emma and Lodi, Andrea and Patel, Rahul and Sankaranarayanan, Sriram},
title = {A Learning-Based Algorithm to Quickly Compute Good Primal Solutions for Stochastic Integer Programs},
year = {2020},
isbn = {978-3-030-58941-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58942-4_7},
doi = {10.1007/978-3-030-58942-4_7},
abstract = {We propose a novel approach using supervised learning to obtain near-optimal primal solutions for two-stage stochastic integer programming (2SIP) problems with constraints in the first and second stages. The goal of the algorithm is to predict a representative scenario (RS) for the problem such that, deterministically solving the 2SIP with the random realization equal to the RS, gives a near-optimal solution to the original 2SIP. Predicting an RS, instead of directly predicting a solution ensures first-stage feasibility of the solution. If the problem is known to have complete recourse, second-stage feasibility is also guaranteed. For computational testing, we learn to find an RS for a two-stage stochastic facility location problem with integer variables and linear constraints in both stages and consistently provide near-optimal solutions. Our computing times are very competitive with those of general-purpose integer programming solvers to achieve a similar solution quality.},
booktitle = {Integration of Constraint Programming, Artificial Intelligence, and Operations Research: 17th International Conference, CPAIOR 2020, Vienna, Austria, September 21–24, 2020, Proceedings},
pages = {99–111},
numpages = {13},
keywords = {Stochastic integer programming, Machine learning, Heuristics},
location = {Vienna, Austria}
}

@article{10.1145/3491052,
author = {Bronzino, Francesco and Schmitt, Paul and Ayoubi, Sara and Kim, Hyojoon and Teixeira, Renata and Feamster, Nick},
title = {Traffic Refinery: Cost-Aware Data Representation for Machine Learning on Network Traffic},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
url = {https://doi.org/10.1145/3491052},
doi = {10.1145/3491052},
abstract = {Network management often relies on machine learning to make predictions about performance and security from network traffic. Often, the representation of the traffic is as important as the choice of the model. The features that the model relies on, and the representation of those features, ultimately determine model accuracy, as well as where and whether the model can be deployed in practice. Thus, the design and evaluation of these models ultimately requires understanding not only model accuracy but also the systems costs associated with deploying the model in an operational network. Towards this goal, this paper develops a new framework and system that enables a joint evaluation of both the conventional notions of machine learning performance (e.g., model accuracy) and the systems-level costs of different representations of network traffic. We highlight these two dimensions for two practical network management tasks, video streaming quality inference and malware detection, to demonstrate the importance of exploring different representations to find the appropriate operating point. We demonstrate the benefit of exploring a range of representations of network traffic and present Traffic Refinery, a proof-of-concept implementation that both monitors network traffic at 10~Gbps and transforms traffic in real time to produce a variety of feature representations for machine learning. Traffic Refinery both highlights this design space and makes it possible to explore different representations for learning, balancing systems costs related to feature extraction and model training against model accuracy.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = dec,
articleno = {40},
numpages = {24},
keywords = {malware detection, network systems, network traffic, qos inference}
}

@inproceedings{10.1145/3379177.3388892,
author = {John, Meenu Mary and Olsson, Helena Holmstr\"{o}m and Bosch, Jan},
title = {Developing ML/DL Models: A Design Framework},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388892},
doi = {10.1145/3379177.3388892},
abstract = {Artificial Intelligence is becoming increasingly popular with organizations due to the success of Machine Learning and Deep Learning techniques. Using these techniques, data scientists learn from vast amounts of data to enhance behaviour in software-intensive systems. Despite the attractiveness of these techniques, however, there is a lack of systematic and structured design process for developing ML/DL models. The study uses a multiple-case study approach to explore the different activities and challenges data scientists face when developing ML/DL models in software-intensive embedded systems. In addition, we have identified seven different phases in the proposed design process leading to effective model development based on the case study. Iterations identified between phases and events which trigger these iterations optimize the design process for ML/DL models. Lessons learned from this study allow data scientists and engineers to develop high-performance ML/DL models and also bridge the gap between high demand and low supply of data scientists.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {1–10},
numpages = {10},
keywords = {Artificial Intelligence, Deep Learning, Design, Machine Learning, Software Engineering},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@inproceedings{10.1145/2647908.2655969,
author = {ter Beek, Maurice H. and Mazzanti, Franco},
title = {VMC: recent advances and challenges ahead},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655969},
doi = {10.1145/2647908.2655969},
abstract = {The variability model checker VMC accepts a product family specified as a Modal Transition System (MTS) with additional variability constraints. Consequently, it offers behavioral variability analyses over both the family and its valid product behavior. This ranges from product derivation and simulation to efficient on-the-fly model checking of logical properties expressed in a variability-aware version of action-based CTL. In this paper, we first explain the reasons and assumptions underlying the choice for a modeling and analysis framework based on MTSs. Subsequently, we present recent advances on proving inheritance of behavioral analysis properties from a product family to its valid products. Finally, we illustrate challenges remaining for the future.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {70–77},
numpages = {8},
keywords = {behavioral variability, model checking, product families},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.5555/1756006.1756038,
author = {Mann, Gideon S. and McCallum, Andrew},
title = {Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data},
year = {2010},
issue_date = {3/1/2010},
publisher = {JMLR.org},
volume = {11},
issn = {1532-4435},
abstract = {In this paper, we present an overview of generalized expectation criteria (GE), a simple, robust, scalable method for semi-supervised training using weakly-labeled data. GE fits model parameters by favoring models that match certain expectation constraints, such as marginal label distributions, on the unlabeled data. This paper shows how to apply generalized expectation criteria to two classes of parametric models: maximum entropy models and conditional random fields. Experimental results demonstrate accuracy improvements over supervised training and a number of other state-of-the-art semi-supervised learning methods for these models.},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {955–984},
numpages = {30}
}

@article{10.1145/2001269.2001295,
author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
title = {Unsupervised learning of hierarchical representations with convolutional deep belief networks},
year = {2011},
issue_date = {October 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/2001269.2001295},
doi = {10.1145/2001269.2001295},
abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks (DBNs); however, scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model that scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique that shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
journal = {Commun. ACM},
month = oct,
pages = {95–103},
numpages = {9}
}

@inproceedings{10.1145/3486635.3491072,
author = {Iyer, C. V. Krishnakumar and Hou, Feili and Wang, Henry and Wang, Yonghong and Oh, Kay and Ganguli, Swetava and Pandey, Vipul},
title = {Trinity: A No-Code AI platform for complex spatial datasets},
year = {2021},
isbn = {9781450391207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486635.3491072},
doi = {10.1145/3486635.3491072},
abstract = {We present a no-code Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by transforming complex Spatio-temporal datasets to make them consumable by standard deep learning models, in this case, Convolutional Neural Networks (CNNs), and giving the ability to formulate disparate problems in a standard way, eg. semantic segmentation. With an intuitive user interface, a feature store that hosts derivatives of complex feature engineering, a deep learning kernel, and a scalable data processing mechanism, Trinity provides a powerful platform for domain experts to share the stage with scientists and engineers in solving business-critical problems. It enables quick prototyping, rapid experimentation and reduces the time to production by standardizing model building and deployment. In this paper, we present our motivation behind Trinity and its design along with showcasing sample applications to motivate the idea of lowering the bar to using AI.},
booktitle = {Proceedings of the 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {33–42},
numpages = {10},
keywords = {Deep Learning, Geospatial Intelligence, Machine Learning, Machine Learning Platform, No Code platform, Semantic Segmentation},
location = {Beijing, China},
series = {GEOAI '21}
}

@article{10.1016/j.adhoc.2021.102588,
author = {Rahman, Md Arafatur and Zaman, Nafees and Asyhari, A. Taufiq and Sadat, S.M. Nazmus and Pillai, Prashant and Arshah, Ruzaini Abdullah},
title = {SPY-BOT: Machine learning-enabled post filtering for Social Network-Integrated Industrial Internet of Things},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {121},
number = {C},
issn = {1570-8705},
url = {https://doi.org/10.1016/j.adhoc.2021.102588},
doi = {10.1016/j.adhoc.2021.102588},
journal = {Ad Hoc Netw.},
month = oct,
numpages = {11},
keywords = {Behavioral analysis, Computational method, Machine learning, Natural language processing, Social Network, IIoT, Post-filtering}
}

@article{10.1155/2021/6094924,
author = {He, Qi and Hu, Bin and Zhang, Yuanpeng},
title = {Research on the Influencing Factors of Film Consumption and Box Office Forecast in the Digital Era: Based on the Perspective of Machine Learning and Model Integration},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/6094924},
doi = {10.1155/2021/6094924},
abstract = {The film industry is one of the core industries of the digital creative industry, which has great positive externalities to the digital creative economy. Movie box office revenue is an important indicator to measure the realization of the market value of movie consumption, and it is also the basic guarantee for the sustainable development of the movie industry. This paper relies on the professional database of the Maoyan movie market to use Python software to collect a total of 830 domestic movie-related consumption characteristic data from 2017 to 2019. In this study, the stacking method in the machine learning ensemble algorithm combines the fivefold crossfolding training method based on distributed random forest, extremely randomized trees, and generalized linear models. The model is good at handling different data types. It has higher fitting and model accuracy in feature mining and model construction, so as to effectively grasp the relevant feature factors affecting movie consumption and accurately predict the future movie box office. Based on the innovative design method of model fusion, the extracted feature vector is used to build a more accurate movie box office prediction model through stacking with a fivefold crossfolding training method. It is aimed at opening the black box that affects the realization of the value of the film content consumption market in the digital age and putting forward corresponding countermeasures and suggestions.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@inproceedings{10.5555/1893248.1893250,
author = {Soares, Carlos and Ghani, Rayid},
title = {Data Mining for Business Applications: Introduction},
year = {2010},
isbn = {9781607506324},
publisher = {IOS Press},
address = {NLD},
abstract = {This chapter introduces the volume on Data Mining (DM) for Business Applications. The chapters in this book provide an overview of some of the major advances in the field, namely in terms of methodology and applications, both traditional and emerging. In this introductory paper, we provide a context for the rest of the book. The framework for discussing the contents of the book is the DM methodology, which is suitable both to organize and relate the diverse contributions of the chapters selected. The chapter closes with an overview of the chapters in the book to guide the reader.},
booktitle = {Proceedings of the 2010 Conference on Data Mining for Business Applications},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.5555/2820656.2820667,
author = {Buchmann, Thomas and Baumgartl, Johannes and Henrich, Dominik and Westfechtel, Bernhard},
title = {Robots and their variability: a societal challenge and a potential solution},
year = {2015},
publisher = {IEEE Press},
abstract = {A robot is essentially a real-time, distributed embedded system operating in a physical environment. Often, control and communication paths within the system are tightly coupled to the actual hardware configuration of the robot. Furthermore, the domain contains a high amount of variability on different levels, ranging from hardware, over software to the environment in which the robot is operated. Today, special robots are used in households to perform monotonous and recurring tasks like vacuuming or mowing the lawn. In the future there may be robots that can be configured and programmed for more complicated tasks, like washing dishes or cleaning up or to assist elderly people. Nowadays, programming a robot is a highly complex and challenging task, which can be carried out only by programmers with dedicated background in robotics. Societal acceptance of robots can only be achieved, if they are easy to program. In this paper we present our approach to provide customized programming environments enabling programmers without background knowledge in robotics to specify robot programs. Our solution was realized using product line techniques.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {27–30},
numpages = {4},
keywords = {DSL, code generation, model-driven development, robot, software product line},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1145/3292500.3330752,
author = {Yan, Xiao and Yang, Jaewon and Obukhov, Mikhail and Zhu, Lin and Bai, Joey and Wu, Shiqi and He, Qi},
title = {Social Skill Validation at LinkedIn},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330752},
doi = {10.1145/3292500.3330752},
abstract = {The main mission of LinkedIn is to connect 610M+ members to the right opportunities. To find the right opportunities, LinkedIn needs to understand each member's skill set and their expertise levels accurately. However, estimating members' skill expertise is challenging due to lack of ground-truth. So far, the industry relied on either hand-created small scale data, or large scale social gestures containing a lot of social bias (e.g., endorsements).In this paper, we develop the Social Skill Validation, a novel framework of collecting validations for members' skill expertise at the scale of billions of member-skill pairs. Unlike social gestures, we collect signals in an anonymous way to ensure objectiveness. We also develop a machine learning model to make smart suggestions to collect validations more efficiently.With the social skill validation data, we discover the insights on how people evaluate other people in professional social networks. For example, we find that the members with higher seniority do not necessarily get positive evaluations compared to more junior members. We evaluate the value of social skill validation data on predicting who is hired for a job requiring a certain skill, and model using social skill validation outperforms the state-of-the art methods on skill expertise estimation by 10%. Our experiments show that the Social Skill Validation we built provides a novel way to estimate the members' skill expertise accurately at large scale and offers a benchmark to validate social theories on peer evaluation.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2943–2951},
numpages = {9},
keywords = {behavior pattern, skill validation, social signals},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1007/s10270-016-0516-2,
author = {Damiani, Ferruccio and Faitelson, David and Gladisch, Christoph and Tyszberowicz, Shmuel},
title = {A novel model-based testing approach for software product lines},
year = {2017},
issue_date = {October   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {4},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-016-0516-2},
doi = {10.1007/s10270-016-0516-2},
abstract = {Model-based testing relies on a model of the system under test. FineFit is a framework for model-based testing of Java programs. In the FineFit approach, the model is expressed by a set of tables based on Parnas tables. A software product line is a family of programs (the products) with well-defined commonalities and variabilities that are developed by (re)using common artifacts. In this paper, we address the issue of using the FineFit approach to support the development of correct software product lines. We specify a software product line as a specification product line where each product is a FineFit specification of the corresponding software product. The main challenge is to concisely specify the software product line while retaining the readability of the specification of a single system. To address this, we used delta-oriented programming, a recently proposed flexible approach for implementing software product lines, and developed: (1) delta tables as a means to apply the delta-oriented programming idea to the specification of software product lines; and (2) DeltaFineFit as a novel model-based testing approach for software product lines.},
journal = {Softw. Syst. Model.},
month = oct,
pages = {1223–1251},
numpages = {29},
keywords = {Alloy, Delta-oriented programming, Java, Model-based testing, Refinement, Software product line}
}

@inproceedings{10.1145/1321631.1321647,
author = {Sarma, Anita and Bortis, Gerald and van der Hoek, Andre},
title = {Towards supporting awareness of indirect conflicts across software configuration management workspaces},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321647},
doi = {10.1145/1321631.1321647},
abstract = {Workspace awareness techniques have been proposed to enhance the effectiveness of software configuration management systems in coordinating parallel work. These techniques share information regarding ongoing changes, so potential conflicts can be detected during development, instead of when changes are completed and committed to a repository. To date, however, workspace awareness techniques only address direct conflicts, which arise due to concurrent changes to the same artifact, but are unable to support indirect conflicts, which arise due to ongoing changes in one artifact affecting concurrent changes in an-other artifact. In this paper, we present a new, cross-workspace awareness technique that supports one particular kind of indirect conflict, namely those indirect conflicts caused by changes to class signatures. We introduce our approach, discuss its implementation in our workspace awareness tool Palant\'{\i}r, illustrate its potential through two pilot studies, and lay out how to generalize the technique to a broader set of indirect conflicts},
booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {94–103},
numpages = {10},
keywords = {awareness, configuration managment, direct conflicts, indirect conflicts, software configuration management},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{10.1145/2806777.2806945,
author = {Sparks, Evan R. and Talwalkar, Ameet and Haas, Daniel and Franklin, Michael J. and Jordan, Michael I. and Kraska, Tim},
title = {Automating model search for large scale machine learning},
year = {2015},
isbn = {9781450336512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806777.2806945},
doi = {10.1145/2806777.2806945},
abstract = {The proliferation of massive datasets combined with the development of sophisticated analytical techniques has enabled a wide variety of novel applications such as improved product recommendations, automatic image tagging, and improved speech-driven interfaces. A major obstacle to supporting these predictive applications is the challenging and expensive process of identifying and training an appropriate predictive model. Recent efforts aiming to automate this process have focused on single node implementations and have assumed that model training itself is a black box, limiting their usefulness for applications driven by large-scale datasets. In this work, we build upon these recent efforts and propose an architecture for automatic machine learning at scale comprised of a cost-based cluster resource allocation estimator, advanced hyper-parameter tuning techniques, bandit resource allocation via runtime algorithm introspection, and physical optimization via batching and optimal resource allocation. The result is TuPAQ, a component of the MLbase system that automatically finds and trains models for a user's predictive application with comparable quality to those found using exhaustive strategies, but an order of magnitude more efficiently than the standard baseline approach. TuPAQ scales to models trained on Terabytes of data across hundreds of machines.},
booktitle = {Proceedings of the Sixth ACM Symposium on Cloud Computing},
pages = {368–380},
numpages = {13},
location = {Kohala Coast, Hawaii},
series = {SoCC '15}
}

@article{10.1155/2021/1916690,
author = {Xie, Wenxiu and Ji, Meng and Zhao, Mengdan and Lam, Kam-Yiu and Chow, Chi-Yin and Hao, Tianyong and Liu, Heng},
title = {Developing Machine Learning and Statistical Tools to Evaluate the Accessibility of Public Health Advice on Infectious Diseases among Vulnerable People},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/1916690},
doi = {10.1155/2021/1916690},
abstract = {Background. From Ebola, Zika, to the latest COVID-19 pandemic, outbreaks of highly infectious diseases continue to reveal severe consequences of social and health inequalities. People from low socioeconomic and educational backgrounds as well as low health literacy tend to be affected by the uncertainty, complexity, volatility, and progressiveness of public health crises and emergencies. A key lesson that governments have taken from the ongoing coronavirus pandemic is the importance of developing and disseminating highly accessible, actionable, inclusive, coherent public health advice, which represent a critical tool to help people with diverse cultural, educational backgrounds and varying abilities to effectively implement health policies at the grassroots level. Objective. We aimed to translate the best practices of accessible, inclusive public health advice (purposefully designed for people with low socioeconomic and educational background, health literacy levels, limited English proficiency, and cognitive/functional impairments) on COVID-19 from health authorities in English-speaking multicultural countries (USA, Australia, and UK) to adaptive tools for the evaluation of the accessibility of public health advice in other languages. Methods. We developed an optimised Bayesian classifier to produce probabilistic prediction of the accessibility of official health advice among vulnerable people including migrants and foreigners living in China. We developed an adaptive statistical formula for the rapid evaluation of the accessibility of health advice among vulnerable people in China. Results. Our study provides needed research tools to fill in a persistent gap in Chinese public health research on accessible, inclusive communication of infectious diseases’ prevention and management. For the probabilistic prediction, using the optimised Bayesian machine learning classifier (GNB), the largest positive likelihood ratio (LR+) 16.685 (95% confidence interval: 4.35, 64.04) was identified when the probability threshold was set at 0.2 (sensitivity: 0.98; specificity: 0.94). Conclusion. Effective communication of health risks through accessible, inclusive, actionable public advice represents a powerful tool to reduce health inequalities amidst health crises and emergencies. Our study translated the best-practice public health advice developed during the pandemic into intuitive machine learning classifiers for health authorities to develop evidence-based guidelines of accessible health advice. In addition, we developed adaptive statistical tools for frontline health professionals to assess accessibility of public health advice for people from non-English speaking backgrounds.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {14}
}

@article{10.1145/1143489.1143493,
author = {Burgess, Mark},
title = {A control theory perspective on configuration management and Cfengine},
year = {2006},
issue_date = {April 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/1143489.1143493},
doi = {10.1145/1143489.1143493},
abstract = {Cfengine is an autonomous agent for the configuration of Unix-like operating systems. It works by implementing a hybrid feedback loop, with both disrcete and continuous elements.},
journal = {SIGBED Rev.},
month = apr,
pages = {12–16},
numpages = {5},
keywords = {configuration management, control theory}
}

@article{10.1007/s10586-019-03012-1,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e} and Ther\'{o}n, Roberto and Amo Filv\`{a}, Daniel and Fonseca Escudero, David},
title = {Connecting domain-specific features to source code: towards the automatization of dashboard generation},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-03012-1},
doi = {10.1007/s10586-019-03012-1},
abstract = {Dashboards are useful tools for generating knowledge and support decision-making processes, but the extended use of technologies and the increasingly available data asks for user-friendly tools that allow any user profile to exploit their data. Building tailored dashboards for any potential user profile would involve several resources and long development times, taking into account that dashboards can be framed in very different contexts that should be studied during the design processes to provide practical tools. This situation leads to the necessity of searching for methodologies that could accelerate these processes. The software product line paradigm is one recurrent method that can decrease the time-to-market of products by reusing generic core assets that can be tuned or configured to meet specific requirements. However, although this paradigm can solve issues regarding development times, the configuration of the dashboard is still a complex challenge; users’ goals, datasets, and context must be thoroughly studied to obtain a dashboard that fulfills the users’ necessities and that fosters insight delivery. This paper outlines the benefits and a potential approach to automatically configuring information dashboards by leveraging domain commonalities and code templates. The main goal is to test the functionality of a workflow that can connect external algorithms, such as artificial intelligence algorithms, to infer dashboard features and feed a generator based on the software product line paradigm.},
journal = {Cluster Computing},
month = sep,
pages = {1803–1816},
numpages = {14},
keywords = {SPL, Domain engineering, Meta-model, Information dashboards, Feature model, Artificial intelligence, Automatic configuration}
}

@article{10.1016/j.compbiomed.2021.104463,
author = {Reamaroon, Narathip and Sjoding, Michael W. and Gryak, Jonathan and Athey, Brian D. and Najarian, Kayvan and Derksen, Harm},
title = {Automated detection of acute respiratory distress syndrome from chest X-Rays using Directionality Measure and deep learning features},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {134},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104463},
doi = {10.1016/j.compbiomed.2021.104463},
journal = {Comput. Biol. Med.},
month = jul,
numpages = {7},
keywords = {Acute respiratory distress syndrome, Chest X-ray images, Image processing, Machine learning, Deep learning}
}

@article{10.1007/s10462-019-09791-8,
author = {Eke, Christopher Ifeanyi and Norman, Azah Anir and Liyana Shuib and Nweke, Henry Friday},
title = {Sarcasm identification in textual data: systematic review, research challenges and open directions},
year = {2020},
issue_date = {Aug 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {6},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-019-09791-8},
doi = {10.1007/s10462-019-09791-8},
abstract = {Sarcasm is a form of sentiment whereby people express the implicit information, usually the opposite of the message content in order to hurt someone emotionally or criticise something in a humorous way. Sarcasm identification in textual data, being one of the hardest challenges in natural language processing (NLP), has recently become an interesting research area due to its importance in improving the sentiment analysis of social media data. A few studies have carried out a comprehensive literature review on sarcasm identification in the existing primary study within the last 11&nbsp;years. Thus, this study carried out a review on the classification techniques for sarcasm identification under the aspects of datasets, pre-processing, feature engineering, classification algorithms, and performance metrics. The study has considered the published article from the period of 2008 to 2019. Forty (40) academic literature were selected from the 7 standard academic databases in order to carry out the review and realize the objectives. The study revealed that most researchers created their own datasets since there is no standard available datasets in the domain of sarcasm identification. Context and content-based linguistic features were used in most of the studies. This review shows that n-gram and parts of speech tagging techniques were the most commonly used feature extraction techniques. However, binary representation and term frequency were utilized for feature representation whereas Chi squared and information gain were used for the feature selection scheme. Moreover, classification algorithm such as support vector machine, Na\"{\i}ve Bayes, random forest, maximum entropy, and decision tree algorithm were mostly applied using accuracy, precision, recall and F-measure for performance measures. Finally, research challenges and future direction are summarized in this review. This review reveals the impact of sarcasm identification in building effective product reviews and would serve as handle resources for researchers and practitioners in sarcasm identification and text classification in general.},
journal = {Artif. Intell. Rev.},
month = aug,
pages = {4215–4258},
numpages = {44},
keywords = {Sarcasm identification, Social media data, Natural language processing, Pre-processing, Feature engineering, Textual classification, Performance measure}
}

@inproceedings{10.1007/978-3-030-59430-5_10,
author = {Waldis, Andreas and Mazzola, Luca and Denzler, Alexander},
title = {Towards eXplainable AI in Text Features Engineering for Concept Recognition},
year = {2020},
isbn = {978-3-030-59429-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59430-5_10},
doi = {10.1007/978-3-030-59430-5_10},
abstract = {The rapid and pervasive development of methods from Artificial Intelligence (AI) affects our everyday life. Its application improves the users’ experience of many daily tasks. Despite the enhancements provided, such approaches have a substantial limitation in the shortfall of people’s trust connected with their lack of explainability. In natural language understanding (NLU) and processing (NLP), a fundamental objective is to support human interactions using sense-making of the language for communication. Such methods try to comprehend and reproduce the self-evident processes of human communication. This applies either in receiving speech signals or in extracting relevant information from a text. Furthermore, the pervasiveness of AI methods in the workplace and on the free time demands a sustainable and verified support of users’ trust, as a natural condition for their acceptance. The objective of this work is to introduce a framework for the calculation and selection of understandable text features. Such features can increase the confidence placed into adopted NLP solutions. The following work outlines the Text Feature Framework and its text features, based on statistical information coming from a general text corpus. The showcase experiment uses those features to verify them on the concept recognition task. The results shows their capability to explain a model and its predictions. The resulting concept recognition models are competitive with other methods existing in the literature. It has the definitive advantage of being able to externalize the supporting evidence for a choice of concept identification.},
booktitle = {Statistical Language and Speech Processing: 8th International Conference, SLSP 2020, Cardiff, UK, October 14–16, 2020, Proceedings},
pages = {122–133},
numpages = {12},
keywords = {Natural language processing, Information retrieval, Explainable artificial intelligence, Concept recognition, Feature engineering, Feature selection},
location = {Cardiff, United Kingdom}
}

@article{10.1561/2200000090,
author = {Agrawal, Akshay and Ali, Alnur and Boyd, Stephen},
title = {Minimum-Distortion Embedding},
year = {2021},
issue_date = {Sep 2021},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {14},
number = {3},
issn = {1935-8237},
url = {https://doi.org/10.1561/2200000090},
doi = {10.1561/2200000090},
abstract = {We consider the vector embedding problem. We are given a
    finite set of items, with the goal of assigning a representative
    vector to each one, possibly under some constraints (such as
    the collection of vectors being standardized, i.e., having zero
    mean and unit covariance). We are given data indicating
    that some pairs of items are similar, and optionally, some
    other pairs are dissimilar. For pairs of similar items, we want
    the corresponding vectors to be near each other, and for
    dissimilar pairs, we want the vectors to not be near each
    other, measured in Euclidean distance. We formalize this by
    introducing distortion functions, defined for some pairs of
    items. Our goal is to choose an embedding that minimizes
    the total distortion, subject to the constraints. We call this
    the minimum-distortion embedding (MDE) problem.The MDE framework is simple but general. It includes a
    wide variety of specific embedding methods, such as spectral
    embedding, principal component analysis, multidimensional
    scaling, Euclidean distance problems, dimensionality reduction
    methods (like Isomap and UMAP), semi-supervised
    learning, sphere packing, force-directed layout, and others.
    It also includes new embeddings, and provides principled
    ways of validating or sanity-checking historical and new
    embeddings alike.In a few special cases, MDE problems can be solved exactly.
    For others, we develop a projected quasi-Newton method
    that approximately minimizes the distortion and scales to
    very large data sets, while placing few assumptions on the
    distortion functions and constraints. This monograph is accompanied
    by an open-source Python package, PyMDE, for
    approximately solving MDE problems. Users can select from
    a library of distortion functions and constraints or specify
    custom ones, making it easy to rapidly experiment with new
    embeddings. Because our algorithm is scalable, and because
    PyMDE can exploit GPUs, our software scales to problems
    with millions of items and tens of millions of distortion functions.
    Additionally, PyMDE is competitive in runtime with
    specialized implementations of specific embedding methods.
    To demonstrate our method, we compute embeddings for
    several real-world data sets, including images, an academic
    co-author network, US county demographic data, and single-cell
    mRNA transcriptomes.},
journal = {Found. Trends Mach. Learn.},
month = sep,
pages = {211–378},
numpages = {172}
}

@article{10.1016/j.eswa.2021.114708,
author = {Peker, Musa},
title = {Classification of hyperspectral imagery using a fully complex-valued wavelet neural network with deep convolutional features},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {173},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114708},
doi = {10.1016/j.eswa.2021.114708},
journal = {Expert Syst. Appl.},
month = jul,
numpages = {11},
keywords = {Hyperspectral image classification, Complex-valued wavelet neural network (CVWNN), Convolutional neural network (CNN), Deep feature extraction}
}

@inproceedings{10.1007/978-3-642-37247-6_19,
author = {Fares, Murhaf and Oepen, Stephan and Zhang, Yi},
title = {Machine learning for high-quality tokenization replicating variable tokenization schemes},
year = {2013},
isbn = {9783642372469},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-37247-6_19},
doi = {10.1007/978-3-642-37247-6_19},
abstract = {In this work, we investigate the use of sequence labeling techniques for tokenization, arguably the most foundational task in NLP, which has been traditionally approached through heuristic finite-state rules. Observing variation in tokenization conventions across corpora and processing tasks, we train and test multiple CRF binary sequence labelers and obtain substantial reductions in tokenization error rate over off-the-shelf standard tools. From a domain adaptation perspective, we experimentally determine the effects of training on mixed gold-standard data sets and make a tentative recommendation for practical usage. Furthermore, we present a perspective on this work as a feedback mechanism to resource creation, i.e. error detection in annotated corpora. To investigate the limits of our approach, we study an interpretation of the tokenization problem that shows stark contrasts to …classic' schemes, presenting many more token-level ambiguities to the sequence labeler (reflecting use of punctuation and multi-word lexical units). In this setup, we also look at partial disambiguation by presenting a token lattice to downstream processing.},
booktitle = {Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing - Volume Part I},
pages = {231–244},
numpages = {14},
keywords = {domain variation, sequence labeling, tokenization},
location = {Samos, Greece},
series = {CICLing'13}
}

@article{10.1016/j.eswa.2021.115668,
author = {Singh, Apoorva and Saha, Sriparna and Hasanuzzaman, Mohammed and Jangra, Anubhav},
title = {Identifying complaints based on semi-supervised mincuts},
year = {2022},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {186},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115668},
doi = {10.1016/j.eswa.2021.115668},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {14},
keywords = {Complaint mining, Semi-supervised learning, Max-flow mincut theorem}
}

@inproceedings{10.5555/1768029.1768057,
author = {Djebbi, Olfa and Salinesi, Camille},
title = {RED-PL, a method for deriving product requirements from a product line requirements model},
year = {2007},
isbn = {9783540729877},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software product lines (SPL) modeling has proven to be an effective approach to reuse in software development. Several variability approaches were developed to plan requirements reuse, but only little of them actually address the issue of deriving product requirements. Indeed, while the modeling approaches sell on requirements reuse, the associated derivation techniques actually focus on deriving and reusing technical product data.This paper presents a method that intends to support requirements derivation. Its underlying principle is to take advantage of approaches made for reuse PL requirements and to complete them by a requirements development process by reuse for single products. The proposed approach matches users' product requirements with PL requirements models and derives a collection of requirements that is (i) consistent, and (ii) optimal with respect to users' priorities and company's constraints. The proposed methodological process was validated in an industrial setting by considering the requirement engineering phase of a product line of blood analyzers.},
booktitle = {Proceedings of the 19th International Conference on Advanced Information Systems Engineering},
pages = {279–293},
numpages = {15},
keywords = {derivation, product line, requirements},
location = {Trondheim, Norway},
series = {CAiSE'07}
}

@article{10.1109/TASLP.2013.2287055,
author = {Zitouni, Imed and Benajiba, Yassine},
title = {Aligned-Parallel-Corpora Based Semi-Supervised Learning for Arabic Mention Detection},
year = {2014},
issue_date = {February 2014},
publisher = {IEEE Press},
volume = {22},
number = {2},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2013.2287055},
doi = {10.1109/TASLP.2013.2287055},
abstract = {In the last two decades, significant effort has been put into annotating linguistic resources in several languages. Despite this valiant effort, there are still many languages left that have only small amounts of such resources. The goal of this article is to present and investigate a method of propagating information (specifically mentions) from a resource-rich language such as English into a relatively less-resource language such as Arabic. We compare also this approach to its equivalent counterpart using monolingual resources. Part of the investigation is to quantify the contribution of propagating information in different conditions - based on the availability of resources in the target language. Experiments on the language pair Arabic-English show that one can achieve relatively decent performance by propagating information from a language with richer resources such as English into Arabic alone (no resources or models in the source language Arabic). Furthermore, results show that propagated features from English do help improve the Arabic system performance even when used in conjunction with all feature types built from the source language. Experiments also show that using propagated features in conjunction with lexically-derived features only (as can be obtained directly from a mention annotated corpus) brings the system performance at the one obtained in the target language by using feature derived from many linguistic resources, therefore improving the system when such resources are not available.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = feb,
pages = {314–324},
numpages = {11}
}

@inproceedings{10.1007/978-3-030-89370-5_18,
author = {Tian, Yuze and Zhong, Xian and Liu, Wenxuan and Jia, Xuemei and Zhao, Shilei and Ye, Mang},
title = {Random Walk Erasing with Attention Calibration for Action Recognition},
year = {2021},
isbn = {978-3-030-89369-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89370-5_18},
doi = {10.1007/978-3-030-89370-5_18},
abstract = {Action recognition in videos has attracted growing research interests because of the explosive surveillance data in social security applications. In this process, due to the distraction and deviation of the network caused by occlusions, human action features usually suffer different degrees of performance degradation. Considering the occlusion scene in the wild, we find that the occluded objects usually move unpredictably but continuously. Thus, we propose a random walk erasing with attention calibration (RWEAC) for action recognition. Specifically, we introduce the random walk erasing (RWE) module to simulate the unknown occluded real conditions in frame sequence, expanding the diversity of data samples. In the case of erasing (or occlusion), the attention area is sparse. We leverage the attention calibration (AC) module to force the attention to stay stable in other regions of interest. In short, our novel RWEAC network enhances the ability to learn comprehensive features in a complex environment and make the feature representation robust. Experiments are conducted on the challenging video action recognition UCF101 and HMDB51 datasets. The extensive comparison results and ablation studies demonstrate the effectiveness and strength of the proposed method.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part III},
pages = {236–251},
numpages = {16},
keywords = {Action recognition, Random walk erasing, Data augmentation, Attention calibration, Siamese network},
location = {Hanoi, Vietnam}
}

@inproceedings{10.1145/2813448.2813517,
author = {Park, Chanyoung and Kim, Donghyun and Oh, Jinoh and Yu, Hwanjo},
title = {Predicting User Purchase in E-commerce by Comprehensive Feature Engineering and Decision Boundary Focused Under-Sampling},
year = {2015},
isbn = {9781450336659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2813448.2813517},
doi = {10.1145/2813448.2813517},
abstract = {The goal of RecSys Challenge 2015 [2] is: (1) to predict which user will end up with a purchase and if so, (2) to predict items that he/she will buy given click/purchase data provided by YOOCHOOSE. It is hard to achieve the goal of this Challenge because (1) the data does not contain user demographics information and it contains a lot of missing values and (2) the volume of the dataset is massive with about 33 million clicks and 1 million purchase history and the class distribution (the ratio of non-purchased clicks to purchased clicks) is highly imbalanced. In order to efficiently solve these problems, we propose (1) Comprehensive Feature Engineering method (CFE) including imputation of missing values to make up for insufficiency of information and (2) Decision Boundary Focused Under-Sampling method (DBFUS) to cope with class imbalance problem and to reduce learning time and memory usage. Our proposed approach obtained 54403.6 points on the final leaderboard.},
booktitle = {Proceedings of the 2015 International ACM Recommender Systems Challenge},
articleno = {8},
numpages = {4},
keywords = {Class imbalance, Ensemble, Recommender System, Sampling},
location = {Vienna, Austria},
series = {RecSys '15 Challenge}
}

@article{10.1016/S0164-1212(03)00013-X,
author = {Zelkowitz, Marvin V. and Rus, Ioana},
title = {Defect evolution in a product line environment},
year = {2004},
issue_date = {February, 2004},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {70},
number = {1–2},
issn = {0164-1212},
url = {https://doi.org/10.1016/S0164-1212(03)00013-X},
doi = {10.1016/S0164-1212(03)00013-X},
abstract = {One mechanism used for monitoring the development of the Space Shuttle flight control software, in order to minimize any risks to the missions, is the independent verification and validation (IV&amp;V) process. Using data provided by both the Shuttle software developer and the IV&amp;V contractor, in this paper we describe the overall IV&amp;V process as used on the Space Shuttle program and provide an analysis of the use of metrics to document and control this process over multiple releases of this software. Our findings reaffirm the value of IV&amp;V, show the impact of IV&amp;V on multiple releases of a large complex software system, and indicate that some of the traditional measures of defect detection and repair are not applicable in a multiple-release environment such as this one.},
journal = {J. Syst. Softw.},
month = feb,
pages = {143–154},
numpages = {12},
keywords = {Evolutionary software, Life and mission critical software, Metrics, Process characterization, Product line development, Software independent verification and validation, Software safety and reliability, Space Shuttle program}
}

@inproceedings{10.5555/1753235.1753245,
author = {Cetina, Carlos and Haugen, \O{}ystein and Zhang, Xiaorui and Fleurey, Franck and Pelechano, Vicente},
title = {Strategies for variability transformation at run-time},
year = {2009},
publisher = {Carnegie Mellon University},
address = {USA},
abstract = {More and more approaches propose to use Software Product Lines (SPLs) modelling techniques to implement dynamic adaptive systems. The resulting Dynamic Software Product Lines (DSPLs) present new challenges since the variability transformations used to derive alternative configurations have to be intensively used at runtime. This paper proposes to use the Common Variability Language (CVL) for modelling runtime variability and evaluates a set of alternative strategies for implementing the associated variability transformations. All the proposed strategies have been implemented and evaluated on the case-study of a smart-home system. Results show that the proposed strategies provide the same reconfiguration service with significant differences in quality-of-service.},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {61–70},
numpages = {10},
location = {San Francisco, California, USA},
series = {SPLC '09}
}

@article{10.1007/s10579-015-9319-2,
author = {Kashyap, Abhay and Han, Lushan and Yus, Roberto and Sleeman, Jennifer and Satyapanich, Taneeya and Gandhi, Sunil and Finin, Tim},
title = {Robust semantic text similarity using LSA, machine learning, and linguistic resources},
year = {2016},
issue_date = {March     2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {50},
number = {1},
issn = {1574-020X},
url = {https://doi.org/10.1007/s10579-015-9319-2},
doi = {10.1007/s10579-015-9319-2},
abstract = {Semantic textual similarity is a measure of the degree of semantic equivalence between two pieces of text. We describe the SemSim system and its performance in the *SEM 2013 and SemEval-2014 tasks on semantic textual similarity. At the core of our system lies a robust distributional word similarity component that combines latent semantic analysis and machine learning augmented with data from several linguistic resources. We used a simple term alignment algorithm to handle longer pieces of text. Additional wrappers and resources were used to handle task specific challenges that include processing Spanish text, comparing text sequences of different lengths, handling informal words and phrases, and matching words with sense definitions. In the *SEM 2013 task on Semantic Textual Similarity, our best performing system ranked first among the 89 submitted runs. In the SemEval-2014 task on Multilingual Semantic Textual Similarity, we ranked a close second in both the English and Spanish subtasks. In the SemEval-2014 task on Cross-Level Semantic Similarity, we ranked first in Sentence---Phrase, Phrase---Word, and Word---Sense subtasks and second in the Paragraph---Sentence subtask.},
journal = {Lang. Resour. Eval.},
month = mar,
pages = {125–161},
numpages = {37},
keywords = {Latent semantic analysis, Semantic similarity, Term alignment, WordNet}
}

@article{10.1016/j.jss.2014.08.034,
author = {Alsawalqah, Hamad I. and Kang, Sungwon and Lee, Jihyun},
title = {A method to optimize the scope of a software product platform based on end-user features},
year = {2014},
issue_date = {December 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.08.034},
doi = {10.1016/j.jss.2014.08.034},
abstract = {A novel method to optimize the scope of a software product platform is proposed.The method is supported with a mathematical formulation and an optimization solver.Depending on the input parameters and the objectives, competing scopes can exist.The method shows how trade-off analysis can be performed among competing scopes.The results of the method were validated as "satisfiable" to "very satisfiable". ContextDue to increased competition and the advent of mass customization, many software firms are utilizing product families - groups of related products derived from a product platform - to provide product variety in a cost-effective manner. The key to designing a successful software product family is the product platform, so it is important to determine the most appropriate product platform scope related to business objectives, for product line development. AimThis paper proposes a novel method to find the optimized scope of a software product platform based on end-user features. MethodThe proposed method, PPSMS (Product Platform Scoping Method for Software Product Lines), mathematically formulates the product platform scope selection as an optimization problem. The problem formulation targets identification of an optimized product platform scope that will maximize life cycle cost savings and the amount of commonality, while meeting the goals and needs of the envisioned customers' segments. A simulated annealing based algorithm that can solve problems heuristically is then used to help the decision maker in selecting a scope for the product platform, by performing tradeoff analysis of the commonality and cost savings objectives. ResultsIn a case study, PPSMS helped in identifying 5 non-dominated solutions considered to be of highest preference for decision making, taking into account both cost savings and commonality objectives. A quantitative and qualitative analysis indicated that human experts perceived value in adopting the method in practice, and that it was effective in identifying appropriate product platform scope.},
journal = {J. Syst. Softw.},
month = dec,
pages = {79–106},
numpages = {28},
keywords = {Commonality decision, Product platform scope, Software product line engineering}
}

@article{10.1007/s10994-008-5079-1,
author = {Dietterich, Thomas G. and Domingos, Pedro and Getoor, Lise and Muggleton, Stephen and Tadepalli, Prasad},
title = {Structured machine learning: the next ten years},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {73},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-008-5079-1},
doi = {10.1007/s10994-008-5079-1},
abstract = {The field of inductive logic programming (ILP) has made steady progress, since the first ILP workshop in 1991, based on a balance of developments in theory, implementations and applications. More recently there has been an increased emphasis on Probabilistic ILP and the related fields of Statistical Relational Learning (SRL) and Structured Prediction. The goal of the current paper is to consider these emerging trends and chart out the strategic directions and open problems for the broader area of structured machine learning for the next 10 years.},
journal = {Mach. Learn.},
month = oct,
pages = {3–23},
numpages = {21},
keywords = {Inductive logic programming, Relational learning, Statistical relational learning, Structured machine learning}
}

@inproceedings{10.1145/3097983.3098125,
author = {Salehian, Hesam and Howell, Patrick and Lee, Chul},
title = {Matching Restaurant Menus to Crowdsourced Food Data: A Scalable Machine Learning Approach},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098125},
doi = {10.1145/3097983.3098125},
abstract = {We study the problem of how to match a formally structured restaurant menu item to a large database of less structured food items that has been collected via crowd-sourcing. At first glance, this problem scenario looks like a typical text matching problem that might possibly be solved with existing text similarity learning approaches. However, due to the unique nature of our scenario and the need for scalability, our problem imposes certain restrictions on possible machine learning approaches that we can employ. We propose a novel, practical, and scalable machine learning solution architecture, consisting of two major steps. First we use a query generation approach, based on a Markov Decision Process algorithm, to reduce the time complexity of searching for matching candidates. That is then followed by a re-ranking step, using deep learning techniques, to meet our required matching quality goals. It is important to note that our proposed solution architecture has already been deployed in a real application system serving tens of millions of users, and shows great potential for practical cases of user-entered text to structured text matching, especially when scalability is crucial.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {2001–2009},
numpages = {9},
keywords = {convolutional neural networks, markov decision process, nutrition estimation, short text matching},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.5555/2666719.2666730,
author = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
title = {Software feature model recommendations using data mining},
year = {2012},
isbn = {9781467317597},
publisher = {IEEE Press},
abstract = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation.},
booktitle = {Proceedings of the Third International Workshop on Recommendation Systems for Software Engineering},
pages = {47–51},
numpages = {5},
keywords = {design decisions, feature models, range ranking},
location = {Zurich, Switzerland},
series = {RSSE '12}
}

@article{10.1016/j.artmed.2018.11.004,
author = {Banerjee, Imon and Ling, Yuan and Chen, Matthew C. and Hasan, Sadid A. and Langlotz, Curtis P. and Moradzadeh, Nathaniel and Chapman, Brian and Amrhein, Timothy and Mong, David and Rubin, Daniel L. and Farri, Oladimeji and Lungren, Matthew P.},
title = {Comparative effectiveness of convolutional neural network (CNN) and recurrent neural network (RNN) architectures for radiology text report classification},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {97},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2018.11.004},
doi = {10.1016/j.artmed.2018.11.004},
journal = {Artif. Intell. Med.},
month = jun,
pages = {79–88},
numpages = {10},
keywords = {Convolutional neural network (CNN), Recurrent neural network (RNN), Pulmonary embolism, Text report classification, Radiology report analysis}
}

@inproceedings{10.1145/3365871.3365878,
author = {Pastor-L\'{o}pez, Iker and la Puerta, Jos\'{e} Gaviria de and Sanz, Borja and Goti, Aitor and Bringas, Pablo G.},
title = {How IoT and computer vision could improve the casting quality},
year = {2019},
isbn = {9781450372077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365871.3365878},
doi = {10.1145/3365871.3365878},
abstract = {In recent years, Internet of Things has being used in several fields of modern life. The possibility of having an interconnection between all the related objects through data opens up a world of research in different fields. Among these fields, IoT technology is considered to make a significant impact in casting industry and the whole casting process. Moreover, the casting industry is an exceptionally critical field since it directly provides elements to other industries. Therefore, castings are subjected to a series of very rigorous quality controls which must be validated by the entire manufacturing process. Considering that the casting process has to be interconnected in order to foresee the state of the each piece before it is produced, it is vitally important that all sub-processes feed back into the system to learn from errors. In this work, we presented a new methodology for the detection and categorization of the imperfections on the surface of the castings. Among these defects, we particularly focused on inclusions, cold laps and misruns. To this end, we first compared several features extracted from the obtained images in order to highlight the regions of the casting that may be affected. And then, we applied several machine-learning techniques to classify the regions. The final results were carried to the starting point of the process to use them in the models to predict the quality of new castings.},
booktitle = {Proceedings of the 9th International Conference on the Internet of Things},
articleno = {7},
numpages = {8},
keywords = {Computer Vision, Feature Engineering, Image Segmentation, Machine Learning},
location = {Bilbao, Spain},
series = {IoT '19}
}

@article{10.1016/j.future.2021.07.003,
author = {Ruip\'{e}rez-Valiente, Jos\'{e} A. and Jaramillo-Morillo, Daniel and Joksimovi\'{c}, Sre\'{c}ko and Kovanovi\'{c}, Vitomir and Mu\~{n}oz-Merino, Pedro J. and Ga\v{s}evi\'{c}, Dragan},
title = {Data-driven detection and characterization of communities of accounts collaborating in MOOCs},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {125},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2021.07.003},
doi = {10.1016/j.future.2021.07.003},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {590–603},
numpages = {14},
keywords = {Learning analytics, Educational data mining, Collaborative learning, Massive open online courses, Artificial intelligence}
}

@inproceedings{10.5555/1610230.1610233,
author = {Adafre, Sisay Fissaha and de Rijke, Maarten},
title = {Feature engineering and post-processing for temporal expression recognition using conditional random fields},
year = {2005},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We present the results of feature engineering and post-processing experiments conducted on a temporal expression recognition task. The former explores the use of different kinds of tagging schemes and of exploiting a list of core temporal expressions during training. The latter is concerned with the use of this list for post-processing the output of a system based on conditional random fields.We find that the incorporation of knowledge sources both for training and post-processing improves recall, while the use of extended tagging schemes may help to offset the (mildly) negative impact on precision. Each of these approaches addresses a different aspect of the overall recognition performance. Taken separately, the impact on the overall performance is low, but by combining the approaches we achieve both high precision and high recall scores.},
booktitle = {Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing},
pages = {9–16},
numpages = {8},
location = {Ann Arbor, Michigan},
series = {FeatureEng '05}
}

@inproceedings{10.1145/3335484.3335507,
author = {Dong, Doudou and He, Rui and Xiong, Guixi},
title = {Foreign Commodity Sales Forecast Based on Model Fusion},
year = {2019},
isbn = {9781450362788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3335484.3335507},
doi = {10.1145/3335484.3335507},
abstract = {In era of big data, global shopping is very popular. Different from domestic shopping, global shopping requires the merchants to purchase goods from abroad in advance, thus knowing approximate sales of goods in the next period will be very helpful for merchants in determining the procurement amount. To solve this problem, in this paper, we are based on user performance data on commodity, commodity sales data and commodity promotion data to predict the commodity sales after 45 days. We extract two kinds of features, statistical feature and discrete feature and design a fusion model. This fusion model uses three different models, which is LR (Linear regression), XGBoost (Extreme Gradient Boosting) and LightGBM (Light Gradient BoostingMachine). The experimental results show that the prediction results of this model have a less bias compared to real value. It will provide some guidance for the decision of merchants.},
booktitle = {Proceedings of the 4th International Conference on Big Data and Computing},
pages = {185–188},
numpages = {4},
keywords = {Commodity sales forecast, artificial intelligence, data mining, machine learning, model fusion},
location = {Guangzhou, China},
series = {ICBDC '19}
}

@inproceedings{10.1609/aaai.v33i01.33017072,
author = {Takanobu, Ryuichi and Zhang, Tianyang and Liu, Jiexi and Huang, Minlie},
title = {A hierarchical framework for relation extraction with reinforcement learning},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33017072},
doi = {10.1609/aaai.v33i01.33017072},
abstract = {Most existing methods determine relation types only after all the entities have been recognized, thus the interaction between relation types and entity mentions is not fully modeled. This paper presents a novel paradigm to deal with relation extraction by regarding the related entities as the arguments of a relation. We apply a hierarchical reinforcement learning (HRL) framework in this paradigm to enhance the interaction between entity mentions and relation types. The whole extraction process is decomposed into a hierarchy of two-level RL policies for relation detection and entity extraction respectively, so that it is more feasible and natural to deal with overlapping relations. Our model was evaluated on public datasets collected via distant supervision, and results show that it gains better performance than existing methods and is more powerful for extracting overlapping relations.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {868},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1007/978-3-030-94907-5_2,
author = {Galdran, Adrian and Carneiro, Gustavo and Ballester, Miguel A. Gonz\'{a}lez},
title = {Convolutional Nets Versus Vision Transformers for&nbsp;Diabetic Foot Ulcer Classification},
year = {2021},
isbn = {978-3-030-94906-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-94907-5_2},
doi = {10.1007/978-3-030-94907-5_2},
abstract = {This paper compares well-established Convolutional Neural Networks (CNNs) to recently introduced Vision Transformers for the task of Diabetic Foot Ulcer Classification, in the context of the DFUC 2021 Grand-Challenge, in which this work attained the first position. Comprehensive experiments demonstrate that modern CNNs are still capable of outperforming Transformers in a low-data regime, likely owing to their ability for better exploiting spatial correlations. In addition, we empirically demonstrate that the recent Sharpness-Aware Minimization (SAM) optimization algorithm improves considerably the generalization capability of both kinds of models. Our results demonstrate that for this task, the combination of CNNs and the SAM optimization process results in superior performance than any other of the considered approaches.},
booktitle = {Diabetic Foot Ulcers Grand Challenge: Second Challenge, DFUC 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings},
pages = {21–29},
numpages = {9},
keywords = {Diabetic Foot Ulcer Classification, Vision Transformers, Convolutional Neural Networks, Sharpness-Aware Optimization},
location = {Strasbourg, France}
}

@article{10.1016/j.eswa.2010.05.083,
author = {Seng, Jia-Lang and Chen, T. C.},
title = {An analytic approach to select data mining for business decision},
year = {2010},
issue_date = {December, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {12},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.05.083},
doi = {10.1016/j.eswa.2010.05.083},
abstract = {Due to the information technology improvement and the growth of internet, enterprises are able to collect and to store huge amount of data. Using data mining technology to aid the data processing, information retrieval and knowledge generation process has become one of the critical missions to enterprise, so how to use data mining tools properly is user concern. Since not every user completely understand the theory of data mining, choosing the best solution from the functions which data mining tools provides is not easy. If user is not satisfied with the outcome of mining, communication with IT employees to adjust the software costs lots of time. To solve this problem, a selection model of data mining algorithms is proposed. By analyzing the content of business decision and application, user requirements will map to certain data mining category and algorithm. This method makes algorithm selection faster and reasonable to improve the efficiency of applying data mining tools to solve business problems.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {8042–8057},
numpages = {16},
keywords = {Business decision, Data mining, Selection model}
}

@inproceedings{10.5555/1251150.1251155,
author = {Desai, Narayan and Bradshaw, Rick and Matott, Scott and Bittner, Sandra and Coghlan, Susan and Evard, R\'{e}my and Lueninghoener, Cory and Leggett, Ti and Navarro, John-Paul and Rackow, Gene and Stacey, Craig and Stacey, Tisha},
title = {A case study in configuration management tool deployment},
year = {2005},
publisher = {USENIX Association},
address = {USA},
abstract = {While configuration management systems are generally regarded as useful, their deployment process is not well understood or documented. In this paper, we present a case study in configuration management tool deployment. We describe the motivating factors and both the technical considerations and the social issues involved in this process. Our discussion includes an analysis of the overall effect on the system management model and the tasks performed by administrators.},
booktitle = {Proceedings of the 19th Conference on Large Installation System Administration Conference - Volume 19},
pages = {5},
numpages = {1},
location = {San Diego, CA},
series = {LISA '05}
}

@inproceedings{10.1145/3368926.3369711,
author = {Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming},
title = {Unsupervised methods for Software Defect Prediction},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369711},
doi = {10.1145/3368926.3369711},
abstract = {Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {49–55},
numpages = {7},
keywords = {Community Structure Detection, Machine Learning, Software Defect Prediction, Software Engineering, Unsupervised Learning},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@inproceedings{10.1007/978-3-031-17531-2_13,
author = {Sahoo, Bikram and Sims, Seth and Zelikovsky, Alexander},
title = {An SVM Based Approach to&nbsp;Study the&nbsp;Racial Disparity in&nbsp;Triple-Negative Breast Cancer},
year = {2021},
isbn = {978-3-031-17530-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-17531-2_13},
doi = {10.1007/978-3-031-17531-2_13},
abstract = {Triple-negative breast cancer (TNBC) is one of the most heterogeneous molecular subtypes of breast cancer. TNBC is well-known for its poor survival rate, with limited treatment options compared to other breast cancer subtypes. The outcome of the disease is worse, especially in the case of African American women (AA) than European American women (EA), by showing the lowest survival rate in every stage of the disease. The current study considered a Support Vector Machine (SVM) based approach using gene expression data to find possible genes that can aid in understanding the molecular mechanism behind the racial disparity in triple-negative breast cancer. The implementation of linear kernel SVM in gene expression analysis already showed some promising results handling a large number of features/genes. This study found a unique set of genes that can accurately classify the gene expression data into two groups: EA and AA. To validate our results, we considered KLK10, which is highly expressed in AA women, and elevated KLK10 is known for cancer progression and poor survival. Further improvement of the current method and analysis of our results is necessary to understand the racial disparity more accurately in TNBC.},
booktitle = {Computational Advances in Bio and Medical Sciences: 11th International Conference, ICCABS 2021, Virtual Event, December 16–18, 2021, Revised Selected Papers},
pages = {163–175},
numpages = {13},
keywords = {Triple negative breast cancer, Racial disparity, Machine learning, SVM, Feature engineering}
}

@inproceedings{10.1007/978-3-030-47426-3_12,
author = {Xie, Zhifeng and Zhang, Wenling and Ding, Huiming and Ma, Lizhuang},
title = {MsFcNET: Multi-scale Feature-Crossing Attention Network for Multi-field Sparse Data},
year = {2020},
isbn = {978-3-030-47425-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-47426-3_12},
doi = {10.1007/978-3-030-47426-3_12},
abstract = {Feature engineering usually needs to excavate dense-and-implicit cross features from multi-filed sparse data. Recently, many state-of-the-art models have been proposed to achieve low-order and high-order feature interactions. However, most of them ignore the importance of cross features and fail to suppress the negative impact of useless features. In this paper, a novel multi-scale feature-crossing attention network (MsFcNET) is proposed to extract dense-and-implicit cross features and learn their importance in the different scales. The model adopts the DIA-LSTM units to construct a new attention calibration architecture, which can adaptively adjust the weights of features in the process of feature interactions. On the other hand, it also integrates a multi-scale feature-crossing module to strengthen the representation ability of cross features from multi-field sparse data. The extensive experimental results on three real-world prediction datasets demonstrate that our proposed model yields superior performance compared with the other state-of-the-art models.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020, Singapore, May 11–14, 2020, Proceedings, Part I},
pages = {142–154},
numpages = {13},
keywords = {Feature engineering, Feature interactions, Attention network, Factorization machines},
location = {Singapore, Singapore}
}

@article{10.1007/s42979-021-00541-8,
author = {Saber, Takfarinas and Brevet, David and Botterweck, Goetz and Ventresque, Anthony},
title = {Reparation in Evolutionary Algorithms for Multi-objective Feature Selection in Large Software Product Lines},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00541-8},
doi = {10.1007/s42979-021-00541-8},
abstract = {Software Product Lines Engineering is the area of software engineering that aims to systematise the modelling, creation and improvement of groups of interconnected software systems by formally expressing possible alternative products in the form of Feature Models. Deriving a software product/system from a feature model is called Feature Configuration. Engineers select the subset of features (software components) from a feature model that suits their needs, while respecting the underlying relationships/constraints of the system–which is challenging on its own. Since there exist several (and often antagonistic) perspectives on which the quality of software could be assessed, the problem is even more challenging as it becomes a multi-objective optimisation problem. Current multi-objective feature selection in software product line approaches (e.g., SATIBEA) combine the scalability of a genetic algorithm (IBEA) with a solution reparation approach based on a SAT solver or one of its derivatives. In this paper, we propose MILPIBEA, a novel hybrid algorithm which combines IBEA with the accuracy of a mixed-integer linear programming (MILP) reparation. We show that the MILP reparation modifies fewer features from the original infeasible solutions than the SAT reparation and in a shorter time. We also demonstrate that MILPIBEA outperforms SATIBEA on average on various multi-objective performance metrics, especially on the largest feature models. The other major challenge in software engineering in general and in software product lines, in particular, is evolution. While the change in software components is common in the software engineering industry, the particular case of multi-objective optimisation of evolving software product lines is not well-tackled yet. We show that MILPIBEA is not only able to better take advantage of the evolution than SATIBEA, but it is also the one that continues to improve the quality of the solutions when SATIBEA stagnates. Overall, IBEA performs better when combined with MILP instead of SAT reparation when optimising the multi-objective feature selection in large and evolving software product lines.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {14},
keywords = {Software product line, Feature selection, Multi-objective optimisation, Evolutionary algorithm, Reparation, Mixed-integer linear programming}
}

@article{10.1016/j.cose.2021.102274,
author = {Neisari, Ashraf and Rueda, Luis and Saad, Sherif},
title = {Spam review detection using self-organizing maps and convolutional neural networks},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {106},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102274},
doi = {10.1016/j.cose.2021.102274},
journal = {Comput. Secur.},
month = jul,
numpages = {17},
keywords = {Spam review detection, Machine learning, Convolutional neural networks, Self-organizing maps, Word2Vec, GloVe, Fake review detection}
}

@article{10.1016/j.eswa.2021.114740,
author = {Czyzewski, Adam and Krawiec, Faustyna and Brzezinski, Dariusz and Porebski, Przemyslaw Jerzy and Minor, Wladek},
title = {Detecting anomalies in X-ray diffraction images using convolutional neural networks},
year = {2021},
issue_date = {Jul 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {174},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114740},
doi = {10.1016/j.eswa.2021.114740},
journal = {Expert Syst. Appl.},
month = jul,
numpages = {11},
keywords = {X-ray diffraction image, Multi-label classification, Convolutional neural network, Image recognition, Crystallography}
}

@inproceedings{10.1145/3394486.3403322,
author = {Cheng, Dawei and Niu, Zhibin and Zhang, Yiyi},
title = {Contagious Chain Risk Rating for Networked-guarantee Loans},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403322},
doi = {10.1145/3394486.3403322},
abstract = {The small and medium-sized enterprises (SMEs) are allowed to guarantee each other and form complex loan networks to receive loans from banks during the economic expansion stage. However, external shocks may weaken the robustness, and an accidental default may spread across the network and lead to large-scale defaults, even systemic crisis. Thus, predicting and rating the default contagion chains in the guarantee network in order to reduce or prevent potential systemic financial risk, attracts a grave concern from the Regulatory Authority and the banks. Existing credit risk models in the banking industry utilize machine learning methods to generate a credit score for each customer. Such approaches dismiss the contagion risk from guarantee chains and need extensive feature engineering with deep domain expertise. To this end, we propose a novel approach to rate the risk of contagion chains in the bank industry with the deep neural network. We employed the temporal inter-chain attention network on graph-structured loan behavior data to compute risk scores for the contagion chains. We show that our approach is significantly better than the state-of-the-art baselines on the dataset from a major financial institution in Asia. Besides, we conducted empirical studies on the real-world loan dataset for risk assessment. The proposed approach enabled loan managers to monitor risks in a boarder view and avoid significant financial losses for the financial institution.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2715–2723},
numpages = {9},
keywords = {contagion chain, data mining, loan network, risk assessment},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1016/j.compbiomed.2019.02.025,
author = {Gorczyca, Michael T. and Toscano, Nicole C. and Cheng, Julius D.},
title = {The trauma severity model: An ensemble machine learning approach to risk prediction},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {108},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2019.02.025},
doi = {10.1016/j.compbiomed.2019.02.025},
journal = {Comput. Biol. Med.},
month = may,
pages = {9–19},
numpages = {11},
keywords = {Risk prediction, Trauma quality improvement, Machine learning in medicine, National trauma data bank, Nationwide readmission database}
}

@inproceedings{10.1145/3127479.3127490,
author = {Zhang, Haoyu and Stafman, Logan and Or, Andrew and Freedman, Michael J.},
title = {SLAQ: quality-driven scheduling for distributed machine learning},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3127490},
doi = {10.1145/3127479.3127490},
abstract = {Training machine learning (ML) models with large datasets can incur significant resource contention on shared clusters. This training typically involves many iterations that continually improve the quality of the model. Yet in exploratory settings, better models can be obtained faster by directing resources to jobs with the most potential for improvement. We describe SLAQ, a cluster scheduling system for approximate ML training jobs that aims to maximize the overall job quality.When allocating cluster resources, SLAQ explores the quality-runtime trade-offs across multiple jobs to maximize system-wide quality improvement. To do so, SLAQ leverages the iterative nature of ML training algorithms, by collecting quality and resource usage information from concurrent jobs, and then generating highly-tailored quality-improvement predictions for future iterations. Experiments show that SLAQ achieves an average quality improvement of up to 73% and an average delay reduction of up to 44% on a large set of ML training jobs, compared to resource fairness schedulers.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {390–404},
numpages = {15},
keywords = {approximate computing, machine learning, quality, resource management, scheduling},
location = {Santa Clara, California},
series = {SoCC '17}
}

@article{10.1145/2347736.2347755,
author = {Domingos, Pedro},
title = {A few useful things to know about machine learning},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/2347736.2347755},
doi = {10.1145/2347736.2347755},
abstract = {Tapping into the "folk knowledge" needed to advance machine learning applications.},
journal = {Commun. ACM},
month = oct,
pages = {78–87},
numpages = {10}
}

@inproceedings{10.1145/2647908.2655961,
author = {Seidl, Christoph and Domachowska, Irena},
title = {Teaching variability engineering to cognitive psychologists},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655961},
doi = {10.1145/2647908.2655961},
abstract = {In research of cognitive psychology, experiments to measure cognitive processes may be run in many similar yet slightly different configurations. Variability engineering offers techniques to handle variable configurations both conceptually and technically. However, these techniques are largely unknown to cognitive psychologists so that experiment configurations are specified informally or too coarse grain. This is problematic, because it becomes difficult to get an overview of paradigm configurations used in the so far conducted experiments. Variability engineering techniques provide, i.a., concise notations for capturing variability in software and can also be used to express the configurable nature of a wide range of experiments in cognitive psychology. Furthermore, it enables cognitive psychologists to structure configuration knowledge, to identify suitably similar experiment setups and to more efficiently identify individual configuration options as relevant reasons for a particular effect in the outcome of an experiment. In this paper, we present experiences with teaching variability engineering to cognitive psychologists along with a suitable curriculum.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {16–23},
numpages = {8},
keywords = {cognitive psychology, feature model, teaching, variability engineering},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1504/ijbra.2021.117930,
author = {Usharani, R. and Murali, M.},
title = {A review of dimensionality reduction methods applied on clinical data of diabetic neuropathy complaints},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1744-5485},
url = {https://doi.org/10.1504/ijbra.2021.117930},
doi = {10.1504/ijbra.2021.117930},
abstract = {Aim of this paper is to apply Dimensionality Reduction techniques on a large clinical data of Type II diabetes patients in identifying the causes and symptoms that they tend to develop neuropathic complications. Data preprocessing is an essential technique using Machine Learning (ML) and Data Mining are ineffective for big data analytics. An effective approach to dimensionality reduction is reduction of the number of independent/dependent variables which are necessary for our analysis. These processes help in identifying the features to be considered for selection and extraction avoiding the redundant and irrelevant features by choosing subset features which are a linear combination of the original. Both supervised and unsupervised learning are applied for prediction and further analysis. This paper primarily focuses on Supervised Learning, the variables are known beforehand. Combination of feature selection techniques and ML algorithms are used to support practitioners with the best methods for feature reduction and extraction.},
journal = {Int. J. Bioinformatics Res. Appl.},
month = jan,
pages = {324–342},
numpages = {18},
keywords = {Type II diabetes mellitus neuropathic complaints, dimensionality reduction, machine learning algorithms, feature selection, feature extraction}
}

@inproceedings{10.1145/3328833.3328869,
author = {Farag, Nadine and El-Seoud, Samir Abou and McKee, Gerard and Hassan, Ghada},
title = {Bullying Hurts: A Survey on Non-Supervised Techniques for Cyber-bullying Detection},
year = {2019},
isbn = {9781450361057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328833.3328869},
doi = {10.1145/3328833.3328869},
abstract = {The contemporary period is scarred by the predominant place of social media in everyday life. Despite social media being a useful tool for communication and social gathering it also offers opportunities for harmful criminal activities. One of these activities is cyber-bullying enabled through the abuse and mistreatment of the internet as a means of bullying others virtually. As a way of minimising this occurrence, research into computer-based researched is carried out to detect cyber-bullying by the scientific research community. An extensive literature search shows that supervised learning techniques are the most commonly used methods for cyber-bullying detection. However, some non-supervised techniques and other approaches have proven to be effective towards cyber-bullying detection. This paper, therefore, surveys recent research on non-supervised techniques and offers some suggestions for future research in textual-based cyber-bullying detection including detecting roles, detecting emotional state, automated annotation and stylometric methods.},
booktitle = {Proceedings of the 8th International Conference on Software and Information Engineering},
pages = {85–90},
numpages = {6},
keywords = {Deep Learning, Supervised learning, Unsupervised learning},
location = {Cairo, Egypt},
series = {ICSIE '19}
}

@inproceedings{10.5555/3201607.3201710,
author = {Chang, Norman and Baranwal, Ajay and Zhuang, Hao and Shih, Ming-Chih and Rajan, Rahul and Jia, Yaowei and Liao, Hui-Lun and Li, Ying-Shiun and Ku, Ting and Lin, Rex},
title = {Machine learning based generic violation waiver system with application on electromigration sign-off},
year = {2018},
publisher = {IEEE Press},
abstract = {Manually analyzing the results generated by EDA tools to waive or fix any violations is a tedious, error-prone and time-consuming process. By automating these time-consuming rigorous manual procedures by aggregating key insights across different designs using continuing and prior simulation data, a design team can speed up the tape-out process, optimize resources and significantly minimize the risk of overlooking must fix violations that are prone to cause field failures. In this paper, a machine learning based generic waiver system is proposed which continuously learns to improve with new design data using K-means clustering and nearest neighbor algorithms for risk scoring. The system has been used on new designs to demonstrate on-chip Electromigration (EM) waiver (EMWaiver) mechanism that yielded highly confident results.},
booktitle = {Proceedings of the 23rd Asia and South Pacific Design Automation Conference},
pages = {416–421},
numpages = {6},
location = {Jeju, Republic of Korea},
series = {ASPDAC '18}
}

@inproceedings{10.1007/978-3-030-86230-5_55,
author = {Basu, Priyam and Singha Roy, Tiasa and Tiwari, Soham and Mehta, Saksham},
title = {CyberPolice: Classification of Cyber Sexual Harassment},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_55},
doi = {10.1007/978-3-030-86230-5_55},
abstract = {Online sexual harassment is defined as unwanted sexual conduct on any digital platform and it is recognised as a form of sexual violence which can make a person feel threatened, exploited, coerced, humiliated, upset, sexualised or discriminated against. With our work we contend that such content can be leveraged to create models that could automatically detect such malicious online behaviour and thereby, ban such users from posting such content in the future, without having to wait for the other users to report them and thereby, create a safe space on social media. A major attribute of our proposed model is that it focuses on how sexual harassment can be hard to classify on social media. These spaces, unlike a formal environment, have no rigid set of rules or code of conduct to adhere to and therefore it can be very difficult to draw the line between a joke and a more malicious comment. To be able to discern the differences between such analogous statements we must have a model which can read and understand the context clues to better classify. In our paper we have worked with state-of-the-art Machine Learning and Deep Learning models and conducted extensive comparison to find the most effective model to better realise this vision of fair space by achieving the most accurate predictions.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {701–714},
numpages = {14},
keywords = {Machine learning, Deep learning, Sentiment analysis, Natural language processing, Neural networks, Sequential models, Transformers, Classification}
}

@inproceedings{10.1145/2517288.2517290,
author = {Li, Chun-Liang and Su, Yu-Chuan and Lin, Ting-Wei and Tsai, Cheng-Hao and Chang, Wei-Cheng and Huang, Kuan-Hao and Kuo, Tzu-Ming and Lin, Shan-Wei and Lin, Young-San and Lu, Yu-Chen and Yang, Chun-Pai and Chang, Cheng-Xia and Chin, Wei-Sheng and Juan, Yu-Chin and Tung, Hsiao-Yu and Wang, Jui-Pin and Wei, Cheng-Kuang and Wu, Felix and Yin, Tu-Chun and Yu, Tong and Zhuang, Yong and Lin, Shou-de and Lin, Hsuan-Tien and Lin, Chih-Jen},
title = {Combination of feature engineering and ranking models for paper-author identification in KDD Cup 2013},
year = {2013},
isbn = {9781450324953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517288.2517290},
doi = {10.1145/2517288.2517290},
abstract = {The track 1 problem in KDD Cup 2013 is to discriminate between papers confirmed by the given authors from the other deleted papers. This paper describes the winning solution of team National Taiwan University for track 1 of KDD Cup 2013. First, we conduct the feature engineering to transform the various provided text information into 97 features. Second, we train classification and ranking models using these features. Last, we combine our individual models to boost the performance by using results on the internal validation set and the official Valid set. Some effective post-processing techniques have also been proposed. Our solution achieves 0.98259 MAP score and ranks the first place on the private leaderboard of Test set.},
booktitle = {Proceedings of the 2013 KDD Cup 2013 Workshop},
articleno = {2},
numpages = {7},
location = {Chicago, Illinois},
series = {KDD Cup '13}
}

@inproceedings{10.1145/3051457.3054002,
author = {Gardner, Josh and Brooks, Christopher},
title = {A Statistical Framework for Predictive Model Evaluation in MOOCs},
year = {2017},
isbn = {9781450344500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3051457.3054002},
doi = {10.1145/3051457.3054002},
abstract = {Feature extraction and model selection are two essential processes when building predictive models of student success. In this work we describe and demonstrate a statistical approach to both tasks, comparing five modeling techniques (a lasso penalized logistic regression model, na\"{\i}ve Bayes, random forest, SVM, and classification tree) across three sets of features (week-only, summed, and appended). We conduct this comparison on a dataset compiled from 30 total offerings of five different MOOCs run on the Coursera platform. Through the use of the Friedman test with a corresponding post-hoc Nemenyi test, we present comparative performance results for several classifiers across the three different feature extraction methods, demonstrating a rigorous inferential process intended to guide future analyses of student success systems.},
booktitle = {Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale},
pages = {269–272},
numpages = {4},
keywords = {machine learning, model evaluation, mooc, predictive modeling},
location = {Cambridge, Massachusetts, USA},
series = {L@S '17}
}

@inproceedings{10.5555/648033.744208,
author = {Muthig, Dirk and Patzke, Thomas},
title = {Generic Implementation of Product Line Components},
year = {2002},
isbn = {3540007377},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {An argument pro component-based software development is the idea of constructing software systems by assembling preexisting components instead of redeveloping similar or identical functionality always from scratch. Unfortunately, integrating existing components practically means adaptation and use rather than use only, which makes an ideal component-based development hard to realize in practice. Product line engineering, however, tackles this problem by making components as generic as needed for a particular product family and thus allows component reuse. Such a component covers variabilities and thus its implementation must consider variabilities as well.In this paper, we describe a process for implementing generic product line components and give an overview of variability mechanisms at the implementation level, illustrated by a running example, a generic test component.},
booktitle = {Revised Papers from the International Conference NetObjectDays on Objects, Components, Architectures, Services, and Applications for a Networked World},
pages = {313–329},
numpages = {17},
series = {NODe '02}
}

@article{10.5555/1516546.1516580,
author = {Davidson, Jennifer and Zhang, Xi and Amoussou, Guy-Alain},
title = {Generating design knowledge though data mining},
year = {2009},
issue_date = {April 2009},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {24},
number = {4},
issn = {1937-4771},
abstract = {Designing software is an expensive process. Our claim is that designing software can become more efficient if designers have knowledge about their design processes. One avenue of capturing the design process is through documentation. People have not focused on documentation for the purpose of generating design knowledge. A design platform called Lifecycle Manager (LCM) allows designers to document all steps of their design process. However, LCM does not have the means for interpreting the documentation that it collects. Our goal is to add that capability by studying how data mining can be applied to generate design knowledge. We developed a data mining tool and implemented four data mining algorithms on data captured by LCM, to learn that design knowledge cannot be gained from only one pattern. We learned about the evolution of LCM design by analyzing the data mining results. We plan to incorporate our tool into LCM.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {203–210},
numpages = {8}
}

@article{10.1287/mnsc.1090.1058,
author = {Wang, Xinfang (Jocelyn) and Camm, Jeffrey D. and Curry, David J.},
title = {A Branch-and-Price Approach to the Share-of-Choice Product Line Design Problem},
year = {2009},
issue_date = {October 2009},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {55},
number = {10},
issn = {0025-1909},
url = {https://doi.org/10.1287/mnsc.1090.1058},
doi = {10.1287/mnsc.1090.1058},
abstract = {We develop a branch-and-price algorithm for constructing an optimal product line using partworth estimates from choice-based conjoint analysis. The algorithm determines the specific attribute levels for each multiattribute product in a set of products to maximize the resulting product line's share of choice, i.e., the number of respondents for whom at least one new product's utility exceeds the respondent's reservation utility. Computational results using large commercial and simulated data sets demonstrate that the algorithm can identify provably optimal, robust solutions to realistically sized problems.},
journal = {Manage. Sci.},
month = oct,
pages = {1718–1728},
numpages = {11},
keywords = {branch and price, column generation, combinatorial optimization, conjoint analysis, integer programming, marketing, optimization, product line design, share of choice}
}

@article{10.3233/JIFS-200741,
author = {Yang, Dongqi and Zhang, Wenyu and Wu, Xin and Ablanedo-Rosas, Jose H. and Yang, Lingxiao and Yu, Wangzhi},
title = {A novel multi-stage ensemble model with fuzzy clustering and optimized classifier composition for corporate bankruptcy prediction},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-200741},
doi = {10.3233/JIFS-200741},
abstract = {With the rapid development of commercial credit mechanisms, credit funds have become fundamental in promoting the development of manufacturing corporations. However, large-scale, imbalanced credit application information poses a challenge to accurate bankruptcy predictions. A novel multi-stage ensemble model with fuzzy clustering and optimized classifier composition is proposed herein by combining the fuzzy clustering-based classifier selection method, the random subspace (RS)-based classifier composition method, and the genetic algorithm (GA)-based classifier compositional optimization method to achieve accuracy in predicting bankruptcy among corporates. To overcome the inherent inflexibility of traditional hard clustering methods, a new fuzzy clustering-based classifier selection method is proposed based on the mini-batch k-means algorithm to obtain the best performing base classifiers for generating classifier compositions. The RS-based classifier composition method was applied to enhance the robustness of candidate classifier compositions by randomly selecting several subspaces in the original feature space. The GA-based classifier compositional optimization method was applied to optimize the parameters of the promising classifier composition through the iterative mechanism of the GA. Finally, six datasets collected from the real world were tested with four evaluation indicators to assess the performance of the proposed model. The experimental results showed that the proposed model outperformed the benchmark models with higher predictive accuracy and efficiency.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {4169–4185},
numpages = {17},
keywords = {Bankruptcy prediction, ensemble learning, fuzzy mini-batch clustering, heterogeneous model construction, genetic algorithm}
}

@article{10.1145/3473039,
author = {Demetrio, Luca and Coull, Scott E. and Biggio, Battista and Lagorio, Giovanni and Armando, Alessandro and Roli, Fabio},
title = {Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection},
year = {2021},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {2471-2566},
url = {https://doi.org/10.1145/3473039},
doi = {10.1145/3473039},
abstract = {Recent work has shown that adversarial Windows malware samples—referred to as adversarial EXEmples in this article—can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that does not only encompass and generalize previous attacks against machine-learning models, but also includes three novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable file format. These attacks, named Full DOS, Extend, and Shift, inject the adversarial payload by respectively manipulating the DOS header, extending it, and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box scenarios, achieving a better tradeoff in terms of evasion rate and size of the injected payload, while also enabling evasion of models that have been shown to be robust to previous attacks. To facilitate reproducibility of our findings, we open source our framework and all the corresponding attack implementations as part of the secml-malware Python library. We conclude this work by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts directly into the learning process.},
journal = {ACM Trans. Priv. Secur.},
month = sep,
articleno = {27},
numpages = {31},
keywords = {Adversarial examples, evasion, malware detection, semantics-invariant manipulations}
}

@article{10.1145/3268931,
author = {Kimelfeld, Benny and R\'{e}, Christopher},
title = {A Relational Framework for Classifier Engineering},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/3268931},
doi = {10.1145/3268931},
abstract = {In the design of analytical procedures and machine learning solutions, a critical and time-consuming task is that of feature engineering, for which various recipes and tooling approaches have been developed. In this article, we embark on the establishment of database foundations for feature engineering. We propose a formal framework for classification in the context of a relational database. The goal of this framework is to open the way to research and techniques to assist developers with the task of feature engineering by utilizing the database’s modeling and understanding of data and queries and by deploying the well-studied principles of database management. As a first step, we demonstrate the usefulness of this framework by formally defining three key algorithmic challenges. The first challenge is that of separability, which is the problem of determining the existence of feature queries that agree with the training examples. The second is that of evaluating the VC dimension of the model class with respect to a given sequence of feature queries. The third challenge is identifiability, which is the task of testing for a property of independence among features that are represented as database queries. We give preliminary results on these challenges for the case where features are defined by means of conjunctive queries, and, in particular, we study the implication of various traditional syntactic restrictions on the inherent computational complexity.},
journal = {ACM Trans. Database Syst.},
month = oct,
articleno = {11},
numpages = {36},
keywords = {Feature engineering, classifiers, conjunctive queries, machine learning, relational databases}
}

@inproceedings{10.5555/1565639.1565641,
author = {Soares, Carlos and Peng, Yonghong and Meng, Jun and Washio, Takashi and Zhou, Zhi-Hua},
title = {Applications of Data Mining in E-Business Finance: Introduction},
year = {2008},
isbn = {9781586038908},
publisher = {IOS Press},
address = {NLD},
abstract = {This chapter introduces the volume on Applications of Data Mining in E-Business and Finance. It discusses how application-specific issues can affect the development of a data mining project. An overview of the chapters in the book is then given to guide the reader.},
booktitle = {Proceedings of the 2008 Conference on Applications of Data Mining in E-Business and Finance},
pages = {1–9},
numpages = {9},
keywords = {Data Mining Applications, Data Mining Process}
}

@article{10.5555/3322706.3361996,
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
title = {Neural architecture search: a survey},
year = {2019},
issue_date = {January 2019},
publisher = {JMLR.org},
volume = {20},
number = {1},
issn = {1532-4435},
abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1997–2017},
numpages = {21},
keywords = {autoDL, autoML, neural architecture search, performance estimation strategy, search space design, search strategy}
}

@article{10.1007/s11633-021-1291-2,
author = {Zhou, Lu-Jie and Dang, Jian-Wu and Zhang, Zhen-Hai},
title = {Fault Classification for On-board Equipment of High-speed Railway Based on Attention Capsule Network},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {5},
issn = {1476-8186},
url = {https://doi.org/10.1007/s11633-021-1291-2},
doi = {10.1007/s11633-021-1291-2},
abstract = {The conventional troubleshooting methods for high-speed railway on-board equipment, with over-reliance on personnel experience, is characterized by one-sidedness and low efficiency. In the process of high-speed train operation, numerous text-based on-board logs are recorded by on-board computers. Machine learning methods can help technicians make a correct judgment of fault types using the on-board log reasonably. Therefore, a fault classification model of on-board equipment based on attention capsule networks is proposed. This paper presents an empirical exploration of the application of a capsule network with dynamic routing in fault classification. A capsule network can encode the internal spatial part-whole relationship between various entities to identify the fault types. As the importance of each word in the on-board log and the dependencies between them have a significant impact on fault classification, an attention mechanism is incorporated into the capsule network to distill important information. Considering the imbalanced distribution of normal data and fault data in the on-board log, the focal loss function is introduced into the model to adjust the imbalanced data. The experiments are conducted on the on-board log of a railway bureau and compared with other baseline models. The experimental results demonstrate that our model outperforms the compared baseline methods, proving the superiority and competitiveness of our model.},
journal = {Int. J. Autom. Comput.},
month = oct,
pages = {814–825},
numpages = {12},
keywords = {On-board equipment, fault classification, capsule network, attention mechanism, focal loss}
}

@article{10.1016/j.artmed.2021.102162,
author = {Naranjo, Lizbeth and P\'{e}rez, Carlos J. and Campos-Roca, Yolanda and Madruga, Mario},
title = {Replication-based regularization approaches to diagnose Reinke's edema by using voice recordings},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102162},
doi = {10.1016/j.artmed.2021.102162},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {10},
keywords = {Acoustic features, Classification, Reinke's edema, Regularization, Replicated measurements, Variable selection}
}

@article{10.1007/s10618-020-00725-5,
author = {Shaalan, Yassien and Zhang, Xiuzhen and Chan, Jeffrey and Salehi, Mahsa},
title = {Detecting singleton spams in reviews via learning deep anomalous temporal aspect-sentiment patterns},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {35},
number = {2},
issn = {1384-5810},
url = {https://doi.org/10.1007/s10618-020-00725-5},
doi = {10.1007/s10618-020-00725-5},
abstract = {Customer reviews are an essential source of information to consumers. Meanwhile, opinion spams spread widely and the detection of spam reviews becomes critically important for ensuring the integrity of the echo system of online reviews. Singleton spam reviews—one-time reviews—have spread widely of late as spammers can create multiple accounts to purposefully cheat the system. Most available techniques fail to detect this cunning form of malicious reviews, mainly due to the scarcity of behaviour trails left behind by singleton spammers. Available approaches also require extensive feature engineering, expensive manual annotation and are less generalizable. Based on our thorough study of spam reviews, it was found that genuine opinions are usually directed uniformly towards important aspects of entities. In contrast, spammers attempt to counter the consensus towards these aspects while covering their malicious intent by adding more text but on less important aspects. Additionally, spammers usually target specific time periods along products’ lifespan to cause maximum bias to the public opinion. Based on these observations, we present an unsupervised singleton spam review detection model that runs in two steps. Unsupervised deep aspect-level sentiment model employing deep Boltzmann machines first learns fine-grained opinion representations from review texts. Then, an LSTM network is trained on opinion learned representation to track the evolution of opinions through the fluctuation of sentiments in a temporal context, followed by the application of a Robust Variational Autoencoder to identify spam instances. Experiments on three benchmark datasets widely used in the literature showed that our approach outperforms strong state-of-the-art baselines.},
journal = {Data Min. Knowl. Discov.},
month = mar,
pages = {450–504},
numpages = {55},
keywords = {Opinion spam, Aspect sentiment modelling, Anomaly detection, LSTM, Robust variational AutoEncoder, Deep learning}
}

@article{10.1016/j.artmed.2021.102153,
author = {Zaikis, Dimitrios and Vlahavas, Ioannis},
title = {TP-DDI: Transformer-based pipeline for the extraction of Drug-Drug Interactions},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {119},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102153},
doi = {10.1016/j.artmed.2021.102153},
journal = {Artif. Intell. Med.},
month = sep,
numpages = {9},
keywords = {Drug-drug interaction, Relationship extraction, Drug named entity recognition, Relation classification, Pipeline}
}

@article{10.1145/2334801.2334804,
author = {Lee, Jinsik and Lee, Sungjin and Lee, Jonghoon and Kim, Byeongchang and Lee, Gary Geunbae},
title = {Stacking Model-Based Korean Prosodic Phrasing Using Speaker Variability Reduction and Linguistic Feature Engineering},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1530-0226},
url = {https://doi.org/10.1145/2334801.2334804},
doi = {10.1145/2334801.2334804},
abstract = {This article presents a prosodic phrasing model for a general purpose Korean speech synthesis system. To reflect the factors affecting prosodic phrasing in the model, linguistically motivated machine-learning features were investigated. These features were effectively incorporated using a stacking model. The phrasing performance was also improved through feature engineering. The corpus used in the experiment is a 4,392-sentence corpus (55,015 words with an average of 13 words per sentence). Because the corpus contains speaker-dependent variability and such variability is not appropriately reflected in a general purpose speech synthesis system, a method to reduce such variability is proposed. In addition, the entire set of data used in the experiment is provided to the public for future use in comparative research.},
journal = {ACM Transactions on Asian Language Information Processing},
month = sep,
articleno = {10},
numpages = {22},
keywords = {Korean, Prosodic phrasing, linguistic feature, phrase break prediction, prosody, speech synthesis, stacking model}
}

@article{10.14778/3397230.3397235,
author = {Chepurko, Nadiia and Marcus, Ryan and Zgraggen, Emanuel and Fernandez, Raul Castro and Kraska, Tim and Karger, David},
title = {ARDA: automatic relational data augmentation for machine learning},
year = {2020},
issue_date = {May 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3397230.3397235},
doi = {10.14778/3397230.3397235},
abstract = {Automatic machine learning (AML) is a family of techniques to automate the process of training predictive models, aiming to both improve performance and make machine learning more accessible. While many recent works have focused on aspects of the machine learning pipeline like model selection, hyperparameter tuning, and feature selection, relatively few works have focused on automatic data augmentation. Automatic data augmentation involves finding new features relevant to the user's predictive task with minimal "human-in-the-loop" involvement.We present ARDA, an end-to-end system that takes as input a dataset and a data repository, and outputs an augmented data set such that training a predictive model on this augmented dataset results in improved performance. Our system has two distinct components: (1) a framework to search and join data with the input data, based on various attributes of the input, and (2) an efficient feature selection algorithm that prunes out noisy or irrelevant features from the resulting join. We perform an extensive empirical evaluation of different system components and benchmark our feature selection algorithm on real-world datasets.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {1373–1387},
numpages = {15}
}

@article{10.1016/j.eswa.2021.115269,
author = {Cerquitelli, Tania and Ventura, Francesco and Apiletti, Daniele and Baralis, Elena and Macii, Enrico and Poncino, Massimo},
title = {Enhancing manufacturing intelligence through an unsupervised data-driven methodology for cyclic industrial processes},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115269},
doi = {10.1016/j.eswa.2021.115269},
journal = {Expert Syst. Appl.},
month = nov,
numpages = {10},
keywords = {Cluster analysis, Self-tuning machine learning, Industry 4.0, Predictive maintenance, Data analytics}
}

@inproceedings{10.1145/3306618.3314230,
author = {Ibrahim, Mark and Louie, Melissa and Modarres, Ceena and Paisley, John},
title = {Global Explanations of Neural Networks: Mapping the Landscape of Predictions},
year = {2019},
isbn = {9781450363242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3306618.3314230},
doi = {10.1145/3306618.3314230},
abstract = {A barrier to the wider adoption of neural networks is their lack of interpretability. While local explanation methods exist for one prediction, most global attributions still reduce neural network decisions to a single set of features. In response, we present an approach for generating global attributions called GAM, which explains the landscape of neural network predictions across subpopulations. GAM augments global explanations with the proportion of samples that each attribution best explains and specifies which samples are described by each attribution. Global explanations also have tunable granularity to detect more or fewer subpopulations. We demonstrate that GAM's global explanations 1) yield the known feature importances of simulated data, 2) match feature weights of interpretable statistical models on real data, and 3) are intuitive to practitioners through user studies. With more transparent predictions, GAM can help ensure neural network decisions are generated for the right reasons.},
booktitle = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {279–287},
numpages = {9},
keywords = {explainable deep learning, global interpretability, neural networks},
location = {Honolulu, HI, USA},
series = {AIES '19}
}

@article{10.1016/j.eswa.2012.05.074,
author = {Warkentin, Merrill and Sugumaran, Vijayan and Sainsbury, Robert},
title = {The role of intelligent agents and data mining in electronic partnership management},
year = {2012},
issue_date = {December, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {39},
number = {18},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2012.05.074},
doi = {10.1016/j.eswa.2012.05.074},
abstract = {The marketspaces of the ''New Economy'' and the eServices revolution have enabled the formation of new types of partnerships which are electronically mediated. Web-based electronic commerce has also brought a tremendous increase in the volume of data that can be mined for valuable managerial knowledge. The data mining procedures used in this process can be enhanced by employing intelligent agents. This paper describes emerging electronic partnerships between players in developing electronic marketspaces and identifies typical data flows between such players, with an analysis of the potential role of data mining and intelligent agent technology. By identifying the complex nature of information flows between the vast numbers of economic entities, we identify opportunities for applying data mining techniques that can lead to knowledge discovery. In particular, we show how a Generic Agent-based data Mining Architecture (GAMA) can be customized to support managerial decision-making and problem solving in a networked economy. A prototype implementation of GAMA is presented, along with a demonstration of the some of the capabilities of the system. Finally, we explore the role of agents in promoting and maintaining strong automated relationships between various strategic partners.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {13277–13288},
numpages = {12},
keywords = {Data mining, Electronic partnership, Intelligent agents, Supply chain, XML}
}

@article{10.1016/j.eswa.2021.115742,
author = {Rao, Sanjeev and Verma, Anil Kumar and Bhatia, Tarunpreet},
title = {A review on social spam detection: Challenges, open issues, and future directions},
year = {2022},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {186},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115742},
doi = {10.1016/j.eswa.2021.115742},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {31},
keywords = {Deepfake, Machine learning, Online social network, Social spam, Spammer, Spambots}
}

@article{10.1145/3479575,
author = {Smith, Micah J. and Cito, J\"{u}rgen and Lu, Kelvin and Veeramachaneni, Kalyan},
title = {Enabling Collaborative Data Science Development with the Ballet Framework},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479575},
doi = {10.1145/3479575},
abstract = {While the open-source software development model has led to successful large-scale collaborations in building software systems, data science projects are frequently developed by individuals or small teams. We describe challenges to scaling data science collaborations and present a conceptual framework and ML programming model to address them. We instantiate these ideas in Ballet, the first lightweight framework for collaborative, open-source data science through a focus on feature engineering, and an accompanying cloud-based development environment. Using our framework, collaborators incrementally propose feature definitions to a repository which are each subjected to software and ML performance validation and can be automatically merged into an executable feature engineering pipeline. We leverage Ballet to conduct a case study analysis of an income prediction problem with 27 collaborators, and discuss implications for future designers of collaborative projects.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {431},
numpages = {39},
keywords = {collaborative framework, data science, feature definition, feature engineering, feature validation, machine learning, mutual information, streaming feature selection}
}

@article{10.1007/s10664-021-09993-1,
author = {Haakman, Mark and Cruz, Lu\'{\i}s and Huijgens, Hennie and van Deursen, Arie},
title = {AI lifecycle models need to be revised: An exploratory study in Fintech},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09993-1},
doi = {10.1007/s10664-021-09993-1},
abstract = {Tech-leading organizations are embracing the forthcoming artificial intelligence revolution. Intelligent systems are replacing and cooperating with traditional software components. Thus, the same development processes and standards in software engineering ought to be complied in artificial intelligence systems. This study aims to understand the processes by which artificial intelligence-based systems are developed and how state-of-the-art lifecycle models fit the current needs of the industry. We conducted an exploratory case study at ING, a global bank with a strong European base. We interviewed 17 people with different roles and from different departments within the organization. We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment. Our work shows that the real challenges of applying Machine Learning go much beyond sophisticated learning algorithms – more focus is needed on the entire lifecycle. In particular, regardless of the existing development tools for Machine Learning, we observe that they are still not meeting the particularities of this field.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {29},
keywords = {AI engineering, AI lifecycle, SE4AI, Machine learning, Case study}
}

@inproceedings{10.1007/978-3-030-86472-9_9,
author = {Bertl, Markus and Ross, Peeter and Draheim, Dirk},
title = {Predicting Psychiatric Diseases Using AutoAI: A Performance Analysis Based on Health Insurance Billing Data},
year = {2021},
isbn = {978-3-030-86471-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86472-9_9},
doi = {10.1007/978-3-030-86472-9_9},
abstract = {Digital transformation enables a vast growth of health data. Because of that, scholars and professionals considered AI to enhance quality of care significantly. Machine learning (ML) algorithms for improvement have been studied extensively, but automatic artificial intelligence (autoAI/autoML) has been widely neglected. AutoAI aims to automate the complete AI lifecycle to save data scientists from doing low-level coding tasks. Additionally, autoAI has the potential to democratize AI by empowering non-IT users to build AI algorithms. In this paper, we analyze the suitability of autoAI for mental health screening to detect psychiatric diseases. A sooner diagnosis can lead to cost savings for healthcare systems and decrease patients’ suffering. We evaluate AutoAI using the open-source machine learning library auto-sklearn, as well as the commercial Watson Studio’s AutoAI platform to predict depression, post-traumatic stress disorder, and psychiatric disorders in general. We use health insurance billing data from 83,986 patients with a total of 687,697 ICD-10 coded diseases. The results of our research are as follows: (i) on average, an accuracy of 0.6 (F1–score 0.58) with a precision of 0.61 and recall of 0.56 was achieved using auto-sklearn. (ii) The evaluation metrics for Watson Studio’s autoAI were 0.59 accuracy, 0.57 F1–score, a precision of 0.6, and a recall of 0.55. We conclude that the prediction quality of autoAI in psychiatry still lacks behind traditional ML approaches by about 24% and is therefore not ready for production use yet.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part I},
pages = {104–111},
numpages = {8},
keywords = {Artificial intelligence, AI, Machine learning, ML, AutoAI, AutoML, IBM Watson AutoAI, Auto-sklearn, Decision support systems, Psychiatry, Depression, Post-traumatic stress disorder (PTSD)}
}

@article{10.1016/j.eswa.2009.02.087,
author = {Liao, Shu-Hsien and Chen, Jen-Lung and Hsu, Tze-Yuan},
title = {Ontology-based data mining approach implemented for sport marketing},
year = {2009},
issue_date = {October, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {8},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.02.087},
doi = {10.1016/j.eswa.2009.02.087},
abstract = {Since sport marketing is a commercial activity, precise customer and marketing segmentation must be investigated frequently and it would help to know the sport market after a specific customer profile, segmentation, or pattern come with marketing activities has found. Such knowledge would not only help sport firms, but would also contribute to the broader field of sport customer behavior and marketing. This paper proposes using the Apriori algorithm of association rules, and clustering analysis based on an ontology-based data mining approach, for mining customer knowledge from the database. Knowledge extracted from data mining results is illustrated as knowledge patterns, rules, and maps in order to propose suggestions and solutions to the case firm, Taiwan Adidas, for possible product promotion and sport marketing.},
journal = {Expert Syst. Appl.},
month = oct,
pages = {11045–11056},
numpages = {12},
keywords = {Apriori algorithm, Clustering analysis, Data mining, Endorser, Media, Ontology, Sport marketing}
}

@inproceedings{10.1007/978-3-030-91100-3_23,
author = {Verma, Deepika and Bach, Kerstin and Mork, Paul Jarle},
title = {Using Automated Feature Selection for Building Case-Based Reasoning Systems: An Example from Patient-Reported Outcome Measurements},
year = {2021},
isbn = {978-3-030-91099-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91100-3_23},
doi = {10.1007/978-3-030-91100-3_23},
abstract = {Feature selection for case representation is an essential phase of Case-Based Reasoning (CBR) system development. To (semi-)automate the feature selection process can ease the knowledge engineering process. This paper explores the feature importance provided for XGBoost models as basis for creating CBR systems. We use Patient-Reported Outcome Measurements (PROMs) on low back pain from the selfBACK  project in our experiments. PROMs are a valuable source of information that capture physical, emotional as well as social aspects of well-being from the perspective of the patients. Leveraging the analytical capabilities of machine learning methods and data science techniques for exploiting PROMs have the potential of improving decision making. This paper presents a two-fold approach employed on our dataset for feature selection that combines statistical strength with data-driven knowledge modelling in CBR and compares it with permutation feature selection using XGBoost regressor. Furthermore, we compare the performance of the CBR models, built with the selected features, with two machine learning algorithms for predicting different PROMs.},
booktitle = {Artificial Intelligence XXXVIII: 41st SGAI International Conference on Artificial Intelligence, AI 2021, Cambridge, UK, December 14–16, 2021, Proceedings},
pages = {282–295},
numpages = {14},
keywords = {Case-based reasoning, Feature selection, Case representation, Patient-reported outcome measurements},
location = {Cambridge, United Kingdom}
}

@inproceedings{10.1145/1135777.1135842,
author = {Nguyen, Tien N.},
title = {Model-based version and configuration management for a web engineering lifecycle},
year = {2006},
isbn = {1595933239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1135777.1135842},
doi = {10.1145/1135777.1135842},
abstract = {During a lifecycle of a large-scale Web application, Web developers produce a wide variety of inter-related Web objects. Following good Web engineering practice, developers often create them based on a Web application development method, which requires certain logical models for the development and maintenance process. Web development is dynamic, thus, those logical models as well as Web artifacts evolve over time. However, the task of managing their evolution is still very inefficient because design decisions in models are not directly accessible in existing file-based software configuration management repositories. Key limitations of existing Web version control tools include their inadequacy in representing semantics of design models and inability to manage the evolution of model-based objects and their logical connections to Web documents. This paper presents a framework that allows developers to manage versions and configurations of models and to capture changes to model-to-model relations among Web objects. Model-based objects, Web documents, and relations are directly represented and versioned in a structure-oriented manner.},
booktitle = {Proceedings of the 15th International Conference on World Wide Web},
pages = {437–446},
numpages = {10},
keywords = {model-based configuration management, versioned hypermedia, web engineering},
location = {Edinburgh, Scotland},
series = {WWW '06}
}

@inproceedings{10.1145/3239235.3267439,
author = {Zhao, Hui and Liang, Jimin and Yin, Xuezhen and Yang, Lingfeng and Yang, Peili and Wang, Yuhang},
title = {Domain-specific modelware: to make the machine learning model reusable and reproducible},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3267439},
doi = {10.1145/3239235.3267439},
abstract = {Machine learning task is a routine process including data collection, feature engineering, model training, hyper-parameters tuning, model evaluation and model deployment. The process is usually complex, iterated and time-consuming. Commonly, researchers seldom start building the machine model from scratch. They may select some well-known and well-trained models in similar task domains as the reference models. Then they try to tune the hyper-parameters and accelerate the iteration. Thus, some models are often reused and need to be reproduced by using new training dataset. Moreover, understanding the model and the iteration is more necessary. This scenario is very similar to that of software reuse. In this poster, we propose Modelware and argue the need of Modelware to make the machine learning model reusable and reproducible. We define the Modelware which is the reused object and develop a model repository to provide the model lineage management and model visit tool. The big data for building model is managed collaboratively so that the model can be reproduced. The iteration process to obtain the final optimized model is abstracted and implemented using a lightweight workflow. Finally, we take two different classification tasks as the demonstration.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {56},
numpages = {2},
keywords = {modelware, machine learning, model repository, model specification, reproduce, reuse},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.5555/1870568.1870594,
author = {Pighin, Daniele and Moschitti, Alessandro},
title = {On reverse feature engineering of syntactic tree kernels},
year = {2010},
isbn = {9781932432831},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {In this paper, we provide a theoretical framework for feature selection in tree kernel spaces based on gradient-vector components of kernel-based machines. We show that a huge number of features can be discarded without a significant decrease in accuracy. Our selection algorithm is as accurate as and much more efficient than those proposed in previous work. Comparative experiments on three interesting and very diverse classification tasks, i.e. Question Classification, Relation Extraction and Semantic Role Labeling, support our theoretical findings and demonstrate the algorithm performance.},
booktitle = {Proceedings of the Fourteenth Conference on Computational Natural Language Learning},
pages = {223–233},
numpages = {11},
location = {Uppsala, Sweden},
series = {CoNLL '10}
}

@inproceedings{10.5555/1931390.1931457,
author = {Annesi, Paolo and Basili, Roberto and Gitto, Raffaele and Moschitti, Alessandro and Petitti, Riccardo},
title = {Audio feature engineering for automatic music genre classification},
year = {2007},
publisher = {LE CENTRE DE HAUTES ETUDES INTERNATIONALES D'INFORMATIQUE DOCUMENTAIRE},
address = {Paris, FRA},
abstract = {The scenarios opened by the increasing availability, sharing and dissemination of music across the Web is pushing for fast, effective and abstract ways of organizing and retrieving music material. Automatic classification is a central activity to model most of these processes, thus its design plays a relevant role in advanced Music Information Retrieval. In this paper, we adopted a state-of-the-art machine learning algorithm, i.e. Support Vector Machines, to design an automatic classifier of music genres. In order to optimize classification accuracy, we implemented some already proposed features and engineered new ones to capture aspects of songs that have been neglected in previous studies. The classification results on two datasets suggest that our model based on very simple features reaches the state-of-art accuracy (on the ISMIR dataset) and very high performance on a music corpus collected locally.},
booktitle = {Large Scale Semantic Access to Content (Text, Image, Video, and Sound)},
pages = {702–711},
numpages = {10},
location = {Pittsburgh, Pennsylvania},
series = {RIAO '07}
}

@inproceedings{10.5555/646863.707954,
author = {M\'{a}rkus, Andr\'{a}s and V\'{a}ncza, J\'{o}zsef},
title = {Product Line Design with Customer Preferences},
year = {2001},
isbn = {3540422196},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {When customizing their product lines, manufacturers attempt to fulfill the requirements of the customers within the technical and economical constraints of the manufacturing environment. Product line design is a recurrent process that aims at finding the proper balance between the exploration of new product alternatives and the exploitation of the known selling potential of the available variants. This paper offers a framework where, driven by the interaction of customer preferences and the reallocation of manufacturing resources, product families emerge from technically feasible product alternatives.},
booktitle = {Proceedings of the 14th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems: Engineering of Intelligent Systems},
pages = {846–855},
numpages = {10},
series = {IEA/AIE '01}
}

@inproceedings{10.1145/2939672.2939674,
author = {Liu, Guimei and Nguyen, Tam T. and Zhao, Gang and Zha, Wei and Yang, Jianbo and Cao, Jianneng and Wu, Min and Zhao, Peilin and Chen, Wei},
title = {Repeat Buyer Prediction for E-Commerce},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939674},
doi = {10.1145/2939672.2939674},
abstract = {A large number of new buyers are often acquired by merchants during promotions. However, many of the attracted buyers are one-time deal hunters, and the promotions may have little long-lasting impact on sales. It is important for merchants to identify who can be converted to regular loyal buyers and then target them to reduce promotion cost and increase the return on investment (ROI). At International Joint Conferences on Artificial Intelligence (IJCAI) 2015, Alibaba hosted an international competition for repeat buyer prediction based on the sales data of the ``Double 11" shopping event in 2014 at Tmall.com. We won the first place at stage 1 of the competition out of 753 teams. In this paper, we present our winning solution, which consists of comprehensive feature engineering and model training. We created profiles for users, merchants, brands, categories, items and their interactions via extensive feature engineering. These profiles are not only useful for this particular prediction task, but can also be used for other important tasks in e-commerce, such as customer segmentation, product recommendation, and customer base augmentation for brands. Feature engineering is often the most important factor for the success of a prediction task, but not much work can be found in the literature on feature engineering for prediction tasks in e-commerce. Our work provides some useful hints and insights for data science practitioners in e-commerce.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {155–164},
numpages = {10},
keywords = {e-commerce, feature engineering, repeat buyer prediction},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{10.1504/ijdats.2021.120100,
author = {Haddaoui, Bousselham El and Chiheb, Raddouane and Faizi, Rdouan and Afia, Abdellatif El},
title = {Sentiment analysis: a review and framework foundations},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {4},
issn = {1755-8050},
url = {https://doi.org/10.1504/ijdats.2021.120100},
doi = {10.1504/ijdats.2021.120100},
abstract = {The rise of social media as a platform for opinion expression and social interactions motivated the need for an automated data analysis technique for business value extraction with optimal investment considerations. In this respect, sentiment analysis (SA) becomes the de facto approach to investigate generated data and retrieve information such as sentiments and emotions, discussed topics, etc., via traditional machine learning and modern neural network-based algorithms. The current techniques achieve reasonable accuracy scores but their performance evolution is depending on the context of application, also most implementations are complex and non-reusable components. Our literature review shows a lack in research studies to unify existing systems under a common framework for SA tasks. This paper also highlights the rending movement of neural networks approaches and pinpoint recent research studies for SA sub tasks. A SA framework design proposition is presented based on key research projects and enhanced with other promising works.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = jan,
pages = {336–355},
numpages = {19},
keywords = {sentiment analysis, social media, text preprocessing, machine learning, framework, information systems, information retrieval, computing methodologies, machine learning approaches algorithms, artificial intelligence}
}

@inproceedings{10.1145/1185448.1185636,
author = {Gurupur, Varadraj and Tanik, Urcun J},
title = {Software cultivation using the artificial intelligence design framework},
year = {2006},
isbn = {1595933158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1185448.1185636},
doi = {10.1145/1185448.1185636},
abstract = {All along the history of software engineering, traditional software development process has always been a labor intensive process. This is perhaps because we are still in the preliminary evolutionary stage of software production where the software has to be built by a group of software developers either from scratch or by combining and/or reusing the components that have already been developed. In this paper we propose a unique method of building software in a way that is analogous to the growth of any organism to the stage of an adult. In this process of software cultivation, the initial framework of the software system is built by a group of developers and then the system enhances its functionality by gathering domain knowledge from various regions of the Internet by using the Artificial Intelligence Design Framework (AIDF). The internal development of the system is guided by various design theories and methods such as Axiomatic design Theory (ADT) and Design Structure Matrix (DSM). The concept of AIDF was first presented to build a domain expert system in the field of Optical Backplane Engineering, but it was later found that it could be used to solve a wide range of problems including software development. In order to build a system that would design another system various methodologies and theories which have been proved and tested had to be utilized to build the framework for designing a system.Software development has been a process where lot of time and money has to be spent not only on the development process but also on a never-ending process of software maintenance. Sometimes this development process could face obstacles such as the creeping requirements problem where the requirements may change while the software development is still in process. Many software development processes may end in failure owing to the moving target problem due to the rapid change in the domain knowledge. Another way of looking at this problem would be that the domain expert will have to add changes to the domain expert system whenever the domain knowledge undergoes change in some form.The solution to this problem would be a migration from the process of software development to a process of software cultivation. This cultivation would be analogous to the cultivation of a plant in a pot, where we sow the seed and keep adding water and fertilizer to it. In this methodology, we create software and allow the software development framework to handle the process of software maintenance. Here, the process of software maintenance gets transformed into a process of software cultivation where the system consumes networked domain knowledge from the Internet and updates the software to meet the most recent requirements for a given problem domain. For instance, if we have developed a computer based system that helps in the design of optical fiber networks, a recent invention in that field could be used to update the system behavior.As part of the overall artificial intelligence approach, knowledge based engineering (KBE) plays an important role in the AIDF. There are many benefits of using KBE over traditional methods. The time to produce an engineering artifact can be substantially reduced by eliminating tedious engineering duties through automated reasoning. The wisdom of the organization and key people can be retained and accessed by future generations of workers. Concurrent engineering can be accomplished when disparate departments can meld their work together by working in parallel, as opposed to sequentially, enabled by a KBE system intelligently updating files in the background according to its programmed logic. The entire design process will become fully documented, pulling together scattered annotations, designs, suggestions, and established heuristics. Using new technologies, such as the Semantic Web, the KBE engineering system would enable designers to search repositories of parts globally, based on a sophisticated pre-recorded rule-base.One of the key recommendations made by the 2001 report Improving Engineering Design by the National Academy of Sciences was that "decision-making tools and decision theory" should be emphasized. In order to prevent problems occurring during the crucial conceptual stage of the design process, a framework needs to be created that enables the systematic collection, storage, and application of expert knowledge and state-of-the-art practices through machine intelligence. Addressing Suh's future projection of a "Thinking Design Machine" using software to assist engineers at the concept design stage, an Artificial Intelligence Design Framework (AIDF) is introduced. In order to help engineers get their design right the first time, this theory was shown to methodically create a valid design at the concept stage based on a set of axioms, corollaries, and theorems. In order to provide expert advice based on valid design theory, an AIDF is advanced using KBE techniques that capture expert domain knowledge and couple it to the Internet through the use of search agents and ontologies on the Semantic Web. An automated approach intended to get the design right the first time is accomplished by applying machine intelligence to sound axiomatic design theory. This validated approach is structured to prevent costly remedial work done at the end of the design cycle to correct for errors made in the conceptual design phase.The AIDF creates an efficient framework for design and redesign of a system. When a system is built from scratch and the domain knowledge is available on the Internet, sufficient initial design information should be made available to the AIDF. The AIDF will store this knowledge in the form of ontologies and RDF in the knowledge base and the database. The AIDF draws this information from the web agents and domain experts. It is the responsibility of the web agent to extract reliable information from the web, which can be greatly enhanced with Web Services and Semantic Web Technology. Once the information is stored in the AIDF, the AIDF starts rebuilding the software. First it redesigns the software and verifies the correctness of the design according to its rule-base and risk-mitigation algorithms. This verification is carried out in two stages. First the AIDF carries out the required analysis on the design and then if it finds that the design is fault free, it requests the user to verify the design. Once the design has been verified the code generator will generate the required code. If the designer considers that the design was inadequate or faulty, then the designer who also happens to be the user of the system makes recommendations into the system by considering the design as invalid. We need to bear in mind that the AIDF connects itself to the available domain knowledge available on the Internet and supplied directly by the domain expert. Of course, the AIDF does not intend to blindly pull a piece of code available to it and add it to the existing software without filtering through its rule-base and risk-mitigation algorithms. The idea of software cultivation using the AIDF is still in its embryonic stage and therefore, software quality assurance and other aspects associated with the process of software development could be dealt with as our research on software cultivation progresses.The knowledge base in Jena is represented in terms of RDF and ontologies. The ontologies provide a basis for the representation of domain knowledge. The RDF acts as a container for specifications and an excellent way of storing structured metadata. The domain knowledge of a particular system is very much subject to change and any change in the domain knowledge should be recorded and represented in a universally accepted way. Resource Description Framework (RDF) appears to be an excellent way of storing metadata. Jena, the Java technology tool for the Semantic Web, plays an integral role in this process. Jena identifies resources using the Uniform Resource Identifier (URI). The difference between the URI and the URL is that the URI can only identify a resource on the Web and is used predominantly in Web Services, whereas a URL not only identifies a resource on the Web but also locates it. This URI concept is used extensively in Jena. Jena contains library functions to build an RDF model. The complexity analysis for risk-mitigation and internal verification process is carried out using a combination of various analytical methodologies such as Conant theory, Axiomatic Design Theory, and Design Structure Matrix, in addition to risk analysis using methods such as Fault Tree Analysis (FTA) and Failure Mode and Effects Analysis (FMEA).This concept of building an AIDF requires some challenges to be met, most of which emanates from the reliability of the information available on the Internet. An immediate answer to that question would be that the AIDF accepts information that will fit into the system similar to that of a jigsaw puzzle. Sufficient amount of mathematical analysis will be applied on the incoming information content. On top of this, the web agents will derive domain information only from known sources. The AIDF is still in a conceptual phase and we are still looking at the technologies that will be used in building the AIDF.},
booktitle = {Proceedings of the 44th Annual ACM Southeast Conference},
pages = {786–787},
numpages = {2},
location = {Melbourne, Florida},
series = {ACMSE '06}
}

@inproceedings{10.1145/3433996.3434002,
author = {Wan, Min and Guo, Hang and Jian, Wenjuan},
title = {A Geometric Approach for CAD Models Classification based on Shallow Learning},
year = {2020},
isbn = {9781450388641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433996.3434002},
doi = {10.1145/3433996.3434002},
abstract = {Automated classification of three-dimensional geometric models is significant for three-dimensional shape retrieval as well as artificial intelligence application in areas such as civil engineering and mechanical engineering. In this paper, we proposed a geometric approach to classify three-dimensional CAD models. More than 16,000 CAD models were collected from 27 construction projects. Bounding boxes, convex hulls, and alpha shapes were computed on all CAD models and corresponding parameters were extracted as features. Classic supervised learning methods were applied to the extracted features and trained classifiers were evaluated on the collected data to show the efficiency and effectiveness of our method.},
booktitle = {Proceedings of the 2020 Conference on Artificial Intelligence and Healthcare},
pages = {25–29},
numpages = {5},
keywords = {Computer-aided design models, alpha shape, classification, convex hull, neural network, support vector machine},
location = {Taiyuan, China},
series = {CAIH2020}
}

@inproceedings{10.1145/3377812.3381399,
author = {Abbas, Muhammad},
title = {Variability aware requirements reuse analysis},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3381399},
doi = {10.1145/3377812.3381399},
abstract = {Problem: The goal of a software product line is to aid quick and quality delivery of software products, sharing common features. Effectively achieving the above-mentioned goals requires reuse analysis of the product line features. Existing requirements reuse analysis approaches are not focused on recommending product line features, that can be reused to realize new customer requirements. Hypothesis: Given that the customer requirements are linked to product line features' description satisfying them: then the customer requirements can be clustered based on patterns and similarities, preserving the historic reuse information. New customer requirements can be evaluated against existing customer requirements and reuse of product line features can be recommended. Contributions: We treated the problem of feature reuse analysis as a text classification problem at the requirements-level. We use Natural Language Processing and clustering to recommend reuse of features based on similarities and historic reuse information. The recommendations can be used to realize new customer requirements.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {190–193},
numpages = {4},
keywords = {product line, requirements, similarities, software reuse, variability},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1007/s10916-020-01562-1,
author = {Santosh, K. C.},
title = {AI-Driven Tools for Coronavirus Outbreak: Need of Active Learning and Cross-Population Train/Test Models on Multitudinal/Multimodal Data},
year = {2020},
issue_date = {Apr 2020},
publisher = {Plenum Press},
address = {USA},
volume = {44},
number = {5},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-020-01562-1},
doi = {10.1007/s10916-020-01562-1},
abstract = {The novel coronavirus (COVID-19) outbreak, which was identified in late 2019, requires special attention because of its future epidemics and possible global threats. Beside clinical procedures and treatments, since Artificial Intelligence (AI) promises a new paradigm for healthcare, several different AI tools that are built upon Machine Learning (ML) algorithms are employed for analyzing data and decision-making processes. This means that AI-driven tools help identify COVID-19 outbreaks as well as forecast their nature of spread across the globe. However, unlike other healthcare issues, for COVID-19, to detect COVID-19, AI-driven tools are expected to have active learning-based cross-population train/test models that employs multitudinal and multimodal data, which is the primary purpose of the paper.},
journal = {J. Med. Syst.},
month = mar,
numpages = {5},
keywords = {COVID-19, Artificial intelligence, Machine learning, Active learning, Cross-population train/test models, Multitudinal and multimodal data}
}

@article{10.1504/ijdmb.2021.122855,
author = {Rajakumar, Serena and Kavitha, G. and Ali, I. Sathik},
title = {Extraction of drug-drug interaction information using a deep neural network},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {25},
number = {3–4},
issn = {1748-5673},
url = {https://doi.org/10.1504/ijdmb.2021.122855},
doi = {10.1504/ijdmb.2021.122855},
abstract = {The information about Drug-Drug Interaction (DDI) is available in biomedical literature and extraction of this information manually is an extremely challenging and arduous task. DDI information helps medical practitioners to suggest various combination of drugs. The existing DDI extraction systems, based on traditional methods like SVM, require manually defined features, which is a time consuming task. Hence, deep learning algorithms, which eliminate the need for manual feature engineering, are applied for classification of sentences in biomedical journals. In this paper, a 2-Input Layer BiLSTM-based DDI extraction model is developed to assist health care workers to find out the DDI information by themselves. This model takes two features as input, the word embeddings applied to words in a sentence and embeddings for target drug pair. The proposed 2-Input Layer BiLSTM model has outperformed existing models by an F-Score of 4% for binary classification and 10% for multiclass classification.},
journal = {Int. J. Data Min. Bioinformatics},
month = jan,
pages = {181–200},
numpages = {19},
keywords = {recurrent neural network, natural language processing, sentence classification, information extraction, knowledge extraction, binary classification, multiclass classification, bidirectional LSTM, word embedding, GloVe embedding}
}

@inproceedings{10.1007/978-3-030-37599-7_63,
author = {Poveda, Jonatan and Tous, Rub\'{e}n},
title = {Zero-Shot Fashion Products Clustering on Social Image Streams},
year = {2019},
isbn = {978-3-030-37598-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37599-7_63},
doi = {10.1007/978-3-030-37599-7_63},
abstract = {Computer Vision methods have been proposed to solve the problem of matching photographs containing some products from users in social media to products in retail catalogues. This is challenging due to the quality of the photographies, difficulties in dealing with garments and their category taxonomy. A N-Shot Learning approach is required as retail catalogues may contain hundreds of different products for which, in many cases, only one image is provided. This framework can be solved by means of Deep Metric Learning (DML) techniques, in which a metric to discriminate similar than dissimilar samples is learnt. The performance of different authors tackling this problem varies a lot but even if they perform reasonably well, the set of elements they need to return in order to include the exact product is large. As after the query there is a person curating the results, it is important to return the smallest set of elements possible, being ideally just to return only one: the related product. This paper proposes to solve the image-to-product image matching problem through a product retrieval system using DML and Zero-short Learning, focusing on garments, and applying some of the last advances on clustering techniques.},
booktitle = {Machine Learning, Optimization, and Data Science: 5th International Conference, LOD 2019, Siena, Italy, September 10–13, 2019, Proceedings},
pages = {755–758},
numpages = {4},
keywords = {Computer Vision, Deep Metric Learning, Zero-shot Learning, Clustering, Supervised learning},
location = {Siena, Italy}
}

@article{10.1023/B:APIN.0000047383.53680.b6,
author = {Hu, Xiaohua},
title = {A Data Mining Approach for Retailing Bank Customer Attrition Analysis},
year = {2005},
issue_date = {January-February 2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1023/B:APIN.0000047383.53680.b6},
doi = {10.1023/B:APIN.0000047383.53680.b6},
abstract = {Deregulation within the financial service industries and the widespread acceptance of new technologies is increasing competition in the finance marketplace. Central to the business strategy of every financial service company is the ability to retain existing customers and reach new prospective customers. Data mining is adopted to play an important role in these efforts. In this paper, we present a data mining approach for analyzing retailing bank customer attrition. We discuss the challenging issues such as highly skewed data, time series data unrolling, leaker field detection etc, and the procedure of a data mining project for the attrition analysis for retailing bank customers. We use lift as a proper measure for attrition analysis and compare the lift of data mining models of decision tree, boosted na\"{\i}ve Bayesian network, selective Bayesian network, neural network and the ensemble of classifiers of the above methods. Some interesting findings are reported. Our research work demonstrates the effectiveness and efficiency of data mining in attrition analysis for retailing bank.},
journal = {Applied Intelligence},
month = jan,
pages = {47–60},
numpages = {14},
keywords = {attrition analysis, classification method, data mining}
}

@inproceedings{10.1145/3383972.3383980,
author = {Li, Samuel},
title = {Revisiting the Correlation of Basketball Stats and Match Outcome Prediction},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3383980},
doi = {10.1145/3383972.3383980},
abstract = {Professional basketball games, high-stake in nature, have garnered great attention from the research community to model, simulate and predict game outcomes. Despite all the advanced metrics and models developed over the years, predictions remain unreliable and upsets still occur frequently. This paper reinvestigates whether these complex stats perform significantly better over simple statistics, and whether simple statistics benefit from common machine learning generalization and robustification processes.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {63–67},
numpages = {5},
keywords = {Composite Statistic, Feature Selection, Game Prediction, Machine Learning},
location = {Shenzhen, China},
series = {ICMLC '20}
}

@article{10.1017/S0890060405050043,
author = {Yeh, Jinn-Yi and Wu, Tai-Hsi},
title = {Solutions for product configuration management: An empirical study},
year = {2005},
issue_date = {January 2005},
publisher = {Cambridge University Press},
address = {USA},
volume = {19},
number = {1},
issn = {0890-0604},
url = {https://doi.org/10.1017/S0890060405050043},
doi = {10.1017/S0890060405050043},
abstract = {Customers can directly express their preferences on many options when ordering products today. Mass customization manufacturing thus has emerged as a new trend for its aiming to satisfy the needs of individual customers. This process of offering a wide product variety often induces an exponential growth in the volume of information and redundancy for data storage. Thus, a technique for managing product configuration is necessary, on the one hand, to provide customers faster configured and lower priced products, and on the other hand, to translate customers' needs into the product information needed for tendering and manufacturing. This paper presents a decision-making scheme through constructing a product family model (PFM) first, in which the relationship between product, modules, and components are defined. The PFM is then transformed into a product configuration network. A product configuration problem assuming that customers would like to have a minimum-cost and customized product can be easily solved by finding the shortest path in the corresponding product configuration network. Genetic algorithms (GAs), mathematical programming, and tree-searching methods such as uniform-cost search and iterative deepening A* are applied to obtain solutions to this problem. An empirical case is studied in this work as an example. Computational results show that the solution quality of GAs retains 93.89% for a complicated configuration problem. However, the running time of GAs outperforms the running time of other methods with a minimum speed factor of 25. This feature is very useful for a real-time system.},
journal = {Artif. Intell. Eng. Des. Anal. Manuf.},
month = jan,
pages = {39–47},
numpages = {9},
keywords = {Configuration, Genetic Algorithm, Mathematical Programming, Product Family Model, Tree Searching}
}

@article{10.1016/j.compeleceng.2019.04.011,
author = {G., Geetharamani and J., Arun Pandian},
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
doi = {10.1016/j.compeleceng.2019.04.011},
journal = {Comput. Electr. Eng.},
month = jun,
pages = {323–338},
numpages = {16},
keywords = {Artificial intelligence, Deep convolutional neural networks, Deep learning, Dropout, Image augmentation, Leaf diseases identification, Machine learning, Mini batch, Training epoch, Transfer learning}
}

@article{10.1016/j.dss.2021.113492,
author = {Baesens, Bart and H\"{o}ppner, Sebastiaan and Verdonck, Tim},
title = {Data engineering for fraud detection},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {150},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2021.113492},
doi = {10.1016/j.dss.2021.113492},
journal = {Decis. Support Syst.},
month = nov,
numpages = {13},
keywords = {Decision analysis, Payment transactions fraud, Instance engineering, Feature engineering, Cost-based model evaluation}
}

@inproceedings{10.1007/978-3-030-45778-5_17,
author = {Gwetu, Mandlenkosi Victor and Tapamo, Jules-Raymond and Viriri, Serestina},
title = {Random Forests with a Steepend Gini-Index Split Function and Feature Coherence Injection},
year = {2019},
isbn = {978-3-030-45777-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-45778-5_17},
doi = {10.1007/978-3-030-45778-5_17},
abstract = {Although Random Forests (RFs) are an effective and scalable ensemble machine learning approach, they are highly dependent on the discriminative ability of the available individual features. Since most data mining problems occur in the context of pre-existing data, there is little room to choose the original input features. Individual RF decision trees follow a greedy algorithm that iteratively selects the feature with the highest potential for achieving subsample purity. Common heuristics for ranking this potential include the gini-index and information gain metrics. This study seeks to improve the effectiveness of RFs through an adapted gini-index splitting function and a feature engineering technique. Using a structured framework for comparative evaluation of RFs, the study demonstrates that the effectiveness of the proposed methods is comparable with conventional gini-index based RFs. Improvements in the minimum accuracy recorded over some UCI data sets, demonstrate the potential for a hybrid set of splitting functions.},
booktitle = {Machine Learning for Networking: Second IFIP TC 6 International Conference, MLN 2019, Paris, France, December 3–5, 2019, Revised Selected Papers},
pages = {255–272},
numpages = {18},
keywords = {Random Forest, Gini-index, Feature engineering, Feature coherence, Circularity},
location = {Paris, France}
}

@inproceedings{10.1145/1645953.1646087,
author = {Chen, Ye and Pavlov, Dmitry and Berkhin, Pavel and Seetharaman, Aparna and Meltzer, Albert},
title = {Practical lessons of data mining at Yahoo!},
year = {2009},
isbn = {9781605585123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1645953.1646087},
doi = {10.1145/1645953.1646087},
abstract = {The usage of data in many commercial applications has been growing at an unprecedented pace in the last decade. While successful data mining efforts lead to major business advances, there were also numerous, less publicized efforts that for one or another reason failed. In this paper, we discuss practical lessons based on years of our data mining experiences at Yahoo! and offer insights into how to drive the data mining effort to success in a business environment.We use two significant Yahoo's applications as illustrative examples: shopping categorization and behavioral targeting; and reflect on four success factors: methodology, data, infrastructure, and people.},
booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
pages = {1047–1056},
numpages = {10},
keywords = {advertising and optimization, classification and clustering, industrial practice and experience, large-scale statistical modeling},
location = {Hong Kong, China},
series = {CIKM '09}
}

@inproceedings{10.1145/3460881.3460930,
author = {Alimardani, Maryam and Kaba, Mory},
title = {Deep Learning for Neuromarketing; Classification of User Preference using EEG Signals},
year = {2021},
isbn = {9781450390309},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460881.3460930},
doi = {10.1145/3460881.3460930},
abstract = {The present study investigates the applicability of deep learning methods in EEG neuromarketing prediction tasks, compared to traditional machine learning approaches. Neuroscientific methods have expanded research capabilities in marketing and created new insights into consumer behavior and decision making processes. Both machine learning and deep learning approaches can be employed to predict relevant consumer preference from brain activity. The former requires extensive signal processing and feature engineering for classification whereas the later relies on raw brain signals and thus avoids time-consuming preprocessing. In this paper, the performance of a machine learning model comprising an ensemble of algorithms was compared to the performance of a convolutional neural network (CNN) on two independently collected EEG datasets, one concerning product choices and the other movie ratings. While both models showed poor performance for prediction of product choices, the convolutional neural network proved more accurate in the prediction of movie ratings. This provides evidence for the superiority of deep learning algorithms in certain neuromarketing prediction tasks. We discuss the limitations and future application opportunities.},
booktitle = {12th Augmented Human International Conference},
articleno = {2},
numpages = {7},
keywords = {Deep Learning, EEG, Machine Learning, Neuromarketing, User preference},
location = {Geneva, Switzerland},
series = {AH2021}
}

@article{10.1016/j.cie.2020.106536,
author = {Aremu, Oluseun Omotola and Cody, Roya Allison and Hyland-Wood, David and McAree, Peter Ross},
title = {A relative entropy based feature selection framework for asset data in predictive maintenance},
year = {2020},
issue_date = {Jul 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2020.106536},
doi = {10.1016/j.cie.2020.106536},
journal = {Comput. Ind. Eng.},
month = jul,
numpages = {13},
keywords = {Predictive maintenance, Asset management, Machine learning, Feature selection, Feature engineering, Information theory, Relative entropy}
}

@inproceedings{10.5555/646972.713540,
author = {Kandt, Ronald Kirk},
title = {Software Configuration Management Principles and Best Practices},
year = {2002},
isbn = {3540002340},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper identifies fundamental principles and practices essential to the successful performance of a configuration management system. Practices are grouped into four categories that govern the management process, ensure product quality, protect software artifacts, and guide tool use. In addition, the practices are prioritized according to their effect on software products and processes and the coverage of the identified principles. When these practices should be applied in the software development lifecycle is discussed, as is the potential for automating and validating practices.},
booktitle = {Proceedings of the 4th International Conference on Product Focused Software Process Improvement},
pages = {300–313},
numpages = {14},
series = {PROFES '02}
}

@inproceedings{10.1145/3318464.3384707,
author = {Caveness, Emily and G. C., Paul Suganthan and Peng, Zhuo and Polyzotis, Neoklis and Roy, Sudip and Zinkevich, Martin},
title = {TensorFlow Data Validation: Data Analysis and Validation in Continuous ML Pipelines},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3384707},
doi = {10.1145/3318464.3384707},
abstract = {Machine Learning (ML) research has primarily focused on improving the accuracy and efficiency of the training algorithms while paying much less attention to the equally important problem of understanding, validating, and monitoring the data fed to ML. Irrespective of the ML algorithms used, data errors can adversely affect the quality of the generated model. This indicates that we need to adopt a data-centric approach to ML that treats data as a first-class citizen, on par with algorithms and infrastructure which are the typical building blocks of ML pipelines. In this demonstration we showcase TensorFlow Data Validation (TFDV), a scalable data analysis and validation system for ML that we have developed at Google and recently open-sourced. This system is deployed in production as an integral part of TFX - an end-to-end machine learning platform at Google. It is used by hundreds of product teams at Google and has received significant attention from the open-source community as well.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2793–2796},
numpages = {4},
keywords = {data management, machine learning},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@inproceedings{10.1145/2364412.2364442,
author = {Cavalcante, Everton and Almeida, Andr\'{e} and Batista, Thais and Cacho, N\'{e}lio and Lopes, Frederico and Delicato, Flavia C. and Sena, Thiago and Pires, Paulo F.},
title = {Exploiting software product lines to develop cloud computing applications},
year = {2012},
isbn = {9781450310956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364412.2364442},
doi = {10.1145/2364412.2364442},
abstract = {With the advance of the Cloud Computing paradigm, new challenges in terms of models, tools, and techniques to support developers to design, build and deploy complex software systems that make full use of the cloud technology arise. In the heterogeneous scenario of this new paradigm, the development of applications using cloud services becomes hard, and the software product lines (SPL) approach is potentially promising for this context since specificities of the cloud platforms, such as services heterogeneity, pricing model, and other aspects can be catered as variabilities to core features. In this perspective, this paper (i) proposes a seamless adaptation of the SPL-based development to include important features of cloud-based applications, and (ii) reports the experience of developing HW-CSPL, a SPL for the Health Watcher (HW) System, which allows citizens to register complaints and consult information regarding the public health system of a city. Several functionalities of this system were implemented using different Cloud Computing platforms, and run time specificities of this application deployed on the cloud were analyzed, as well as other information such as change impact and pricing.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 2},
pages = {179–187},
numpages = {9},
keywords = {cloud computing, cloud platforms, health watcher system, services, software product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1007/s11042-020-10077-3,
author = {Jahanbakhsh-Nagadeh, Zoleikha and Feizi-Derakhshi, Mohammad-Reza and Sharifi, Arash},
title = {A semi-supervised model for Persian rumor verification based on content information},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {28–29},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-10077-3},
doi = {10.1007/s11042-020-10077-3},
abstract = {Rumor is a collective attempt to interpret a vague but attractive situation by using the power of words. In social networks, false-rumors may have significantly different contextual characteristics from true-rumors at lexical, syntactic, semantic levels. Therefore, this study presents the BERT-SAWS semi-supervised learning model for early verification of Persian rumor by investigating content-based and context features at three views: Contextual Word Embeddings (CWE), speech act, and Writing Style (WS). This model is built by loading pre-trained Bidirectional Encoder Representations from Transformers (BERT) as an unsupervised language representation, fine-tuning it using a small Persian rumor dataset, and combining with a supervised learning model to provide an enriched text representation of the content of the rumor. This text representation enables the model to have a better comprehending of the rumor language to verify rumors better than baseline models for two reasons: (i) early rumor verification by focusing on content-based and context-based features of the source rumor. (ii) overcoming the problem of the shortcoming of the dataset in deep neural networks by loading pre-trained BERT, fine-tuning it using the Persian rumor dataset, and combining with speech act and WS-based features. The empirical results of applying the model on Twitter and Telegram datasets demonstrated that BERT-SAWS can enhance the performance of the classifier from 2% to 18%. It indicates that speech act and WS alongside semantic contextual vectors are helpful features in the rumor verification task.},
journal = {Multimedia Tools Appl.},
month = nov,
pages = {35267–35295},
numpages = {29},
keywords = {Rumor verification, BERT, Speech act, Writing style, Persian rumor classification, Contextual features, Neural language model, Natural language processing}
}

@article{10.1007/s10462-020-09848-z,
author = {Mehndiratta, Akanksha and Asawa, Krishna},
title = {Non-goal oriented dialogue agents: state of the art, dataset, and evaluation},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09848-z},
doi = {10.1007/s10462-020-09848-z},
abstract = {Dialogue agent, a derivative of intelligent agent in the field of computational linguistics, is a computer program that is capable of generating responses and performing conversation in natural language. The field of computational linguistics is flourishing due to the intensive growth of dialogue agents; the most potential one is providing voice controlled smart personal assistant service for handsets and homes. The agents are usable, accessible but perform task-related short conversations. Non-goal-oriented dialogue agents are designed to imitate extended human–human conversations, also called as chit-chat, to provide the consumer with a satisfactory experience on the conversation quality. The design of such agents is primarily defined by a language model, unlike goal-oriented dialogue agents that employees slot based or ontology-based frameworks, hence most of the methods are data-driven. This paper surveys the current state of the art of non-goal-oriented dialogue systems specifically data-driven methods, the most prevalent being deep learning. This paper aims at (a) providing an insight of recent methods and architectures proposed for building context and modeling response along with a comprehensive review of the state of the art (b) examine the type of data set and evaluation methods available (c) present the challenges and limitation that the recent models, dataset and evaluation methods constitute.},
journal = {Artif. Intell. Rev.},
month = jan,
pages = {329–357},
numpages = {29},
keywords = {Natural language processing, Dialogue management systems, Language modeling, Machine learning, Deep learning, Dialogue agent}
}

@article{10.1016/j.asoc.2019.05.002,
author = {Wang, Xizhao and Sangaiah, Arun Kumar and Sheng, Michael and Ahmed, Syed Hassan},
title = {Introduction to the Special Section on Applying Machine Learning Systems for IoT Services in Industrial Informatics},
year = {2019},
issue_date = {Jul 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {80},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.05.002},
doi = {10.1016/j.asoc.2019.05.002},
journal = {Appl. Soft Comput.},
month = jul,
pages = {920–922},
numpages = {3}
}

@inproceedings{10.5555/2891460.2891679,
author = {Natarajan, Sriraam and Kersting, Kristian and Ip, Edward and Jacobs, David R. and Carr, Jeffrey},
title = {Early prediction of coronary artery calcification levels using machine learning},
year = {2013},
publisher = {AAAI Press},
abstract = {Coronary heart disease (CHD) is a major cause of death worldwide. In the U.S. CHD is responsible for approximated 1 in every 6 deaths with a coronary event occurring every 25 seconds and about 1 death every minute based on data current to 2007. Although a multitude of cardiovascular risks factors have been identified, CHD actually reflects complex interactions of these factors over time. Today's datasets from longitudinal studies offer great promise to uncover these interactions but also pose enormous analytical problems due to typically large amount of both discrete and continuous measurements and risk factors with potential long-range interactions over time. Our investigation demonstrates that a statistical relational analysis of longitudinal data can easily uncover complex interactions of risks factors and actually predict future coronary artery calcification (CAC) levels -- an indicator of the risk of CHD present subclinically in an individual -- significantly better than traditional non-relational approaches. The uncovered long-range interactions between risk factors conform to existing clinical knowledge and are successful in identifying risk factors at the early adult stage. This may contribute to monitoring young adults via smartphones and to designing patient-specific treatments in young adults to mitigate their risk later.},
booktitle = {Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence},
pages = {1557–1562},
numpages = {6},
location = {Bellevue, Washington},
series = {AAAI'13}
}

@inproceedings{10.1145/3459637.3482371,
author = {Liu, Qiang and Liu, Zhaocheng and Zhang, Haoli and Chen, Yuntian and Zhu, Jun},
title = {Mining Cross Features for Financial Credit Risk Assessment},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482371},
doi = {10.1145/3459637.3482371},
abstract = {For reliability, machine learning models in some areas, e.g., finance and healthcare, require to be both accurate and globally interpretable. Among them, credit risk assessment is a major application of machine learning for financial institutions to evaluate credit of users and detect default or fraud. Simple white-box models, such as Logistic Regression (LR), are usually used for credit risk assessment, but not powerful enough to model complex nonlinear interactions among features. In contrast, complex black-box models are powerful at modeling, but lack of interpretability, especially global interpretability. Fortunately, automatic feature crossing is a promising way to find cross features to make simple classifiers to be more accurate without heavy handcrafted feature engineering. However, existing automatic feature crossing methods have problems in efficiency on credit risk assessment, for corresponding data usually contains hundreds of feature fields.  In this work, we find local interpretations in Deep Neural Networks (DNNs) of a specific feature are usually inconsistent among different samples. We demonstrate this is caused by nonlinear feature interactions in the hidden layers of DNN. Thus, we can mine feature interactions in DNN, and use them as cross features in LR. This will result in mining cross features more efficiently. Accordingly, we propose a novel automatic feature crossing method called DNN2LR. The final model, which is a LR model empowered with cross features, generated by DNN2LR is a white-box model. We conduct experiments on both public and business datasets from real-world credit risk assessment applications, which show that, DNN2LR outperform both conventional models used for credit assessment and several feature crossing methods. Moreover, comparing with state-of-the-art feature crossing methods, i.e., AutoCross, the proposed DNN2LR method accelerates the speed by about 10 to 40 times on financial credit assessment datasets, which contain hundreds of feature fields.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {1069–1078},
numpages = {10},
keywords = {automated machine learning, credit risk assessment, default prediction, feature crossing, interpretability},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@inproceedings{10.1145/3447548.3467066,
author = {Xie, Yuexiang and Wang, Zhen and Li, Yaliang and Ding, Bolin and G\"{u}rel, Nezihe Merve and Zhang, Ce and Huang, Minlie and Lin, Wei and Zhou, Jingren},
title = {FIVES: Feature Interaction Via Edge Search for Large-Scale Tabular Data},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467066},
doi = {10.1145/3447548.3467066},
abstract = {High-order interactive features capture the correlation between different columns and thus are promising to enhance various learning tasks on ubiquitous tabular data. To automate the generation of interactive features, existing works either explicitly traverse the feature space or implicitly express the interactions via intermediate activations of some designed models. These two kinds of methods show that there is essentially a trade-off between feature interpretability and search efficiency. To possess both of their merits, we propose a novel method named Feature Interaction Via Edge Search (FIVES), which formulates the task of interactive feature generation as searching for edges on the defined feature graph. Specifically, we first present our theoretical evidence that motivates us to search for useful interactive features with increasing order. Then we instantiate this search strategy by optimizing both a dedicated graph neural network (GNN) and the adjacency tensor associated with the defined feature graph. In this way, the proposed FIVES method simplifies the time-consuming traversal as a typical training course of GNN and enables explicit feature generation according to the learned adjacency tensor. Experimental results on both benchmark and real-world datasets show the advantages of FIVES over several state-of-the-art methods. Moreover, the interactive features identified by FIVES are deployed on the recommender system of Taobao, a worldwide leading e-commerce platform. Results of an online A/B testing further verify the effectiveness of the proposed method FIVES, and we further provide FIVES as AI utilities for the customers of Alibaba Cloud.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {3795–3805},
numpages = {11},
keywords = {automated machine learning, feature graph, feature interaction},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3410530.3414354,
author = {Dogan, Gulustan and Cay, Iremnaz and Ertas, Sinem Sena and Keskin, \c{S}eref Recep and Alotaibi, Nouran and Sahin, Elif},
title = {Where are you? human activity recognition with smartphone sensor data},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414354},
doi = {10.1145/3410530.3414354},
abstract = {This paper describes our submission as Team-Petrichor to the competition that was organized by the SHL recognition challenge dataset authors. We compared multiple machine learning approach for classifying eight different activities (Still, Walk, Run, Bike, Car, Bus, Train, Subway). The first step was feature engineering, a wide set of statistical domain features were computed and their quality was evaluated. Finally, the appropriate machine learning model was chosen. The recognition result for the testing dataset will be presented in the summary paper of the SHL recognition challenge.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {301–304},
numpages = {4},
keywords = {activity recognition, locomotion classification, machine learning, transportation mode prediction},
location = {Virtual Event, Mexico},
series = {UbiComp/ISWC '20 Adjunct}
}

@inproceedings{10.5555/1251150.1251165,
author = {Narain, Sanjai},
title = {Network configuration management via model finding},
year = {2005},
publisher = {USENIX Association},
address = {USA},
abstract = {Complex, end-to-end network services are set up via the configuration method: each component has a finite number of configuration parameters each of which is set to a definite value. End-to-end network service requirements can be on connectivity, security, performance and fault-tolerance. However, there is a large conceptual gap between end-to-end requirements and detailed component configurations. To bridge this gap, a number of subsidiary requirements are created that constrain, for example, the protocols to be used, and the logical structures and associated policies to be set up at different protocol layers.By performing different types of reasoning with these requirements, different configuration tasks are accomplished. These include configuration synthesis, configuration error diagnosis, configuration error fixing, reconfiguration as requirements or components are added and deleted, and requirement verification. However, such reasoning is currently ad hoc. Network requirements are not even precisely specified hence automation of reasoning is impossible. This is a major reason for the high cost of network management and total cost of ownership. This paper shows how to formalize and automate such reasoning using a new logical system called Alloy.Alloy is based on the concept of model finding. Given a first-order logic formula and a domain of interpretation, Alloy tries to find whether the formula is satisfiable in that domain, i.e., whether it has a model. Alloy is used to build a Requirement Solver that takes as input a set of network components and requirements upon their configurations and determines component configurations satisfying those requirements.This Solver is used in different ways to accomplish the above reasoning tasks. The Solver is illustrated in depth by carrying out a variety of these tasks in the context of a realistic fault-tolerant virtual private network with remote access. Alloy uses modern satisfiability solvers that solve millions of constraints in millions of variables in seconds. However, poor requirements can easily nullify such speeds. The paper outlines approaches for writing efficient requirements. Finally, it outlines directions for future research.},
booktitle = {Proceedings of the 19th Conference on Large Installation System Administration Conference - Volume 19},
pages = {15},
numpages = {1},
location = {San Diego, CA},
series = {LISA '05}
}

@inproceedings{10.1007/978-3-030-86362-3_12,
author = {Lun, Zhicheng and Gu, Xiaoyan and Fan, Haihui and Li, Bo and Wang, Weiping},
title = {Semi-supervised Graph Edge Convolutional Network for Anomaly Detection},
year = {2021},
isbn = {978-3-030-86361-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86362-3_12},
doi = {10.1007/978-3-030-86362-3_12},
abstract = {In recent years, with deep learning development, graph-based deep anomaly detection has attracted more and more researchers’ attention due to graph data’s strong expression ability. However, at present, graph-based methods mainly focus on node-level anomaly detection, while edge-level anomaly detection is relatively minor. Anomaly detection at the edge level can distinguish the specific edges connected to nodes as detection objects, so its resolution granularity is more detailed than that of the node-based method. Second, the rules of anomalies are challenging to learn. At present, most of the algorithms adopt the unsupervised method to train the model. As a result, the detected result is likely to be noise data. In this paper, we propose a Graph Edge Anomaly Detection model based on a Semi-supervised auto-encoder (GEADS). In this model, we first adjust the traditional mini-batch training strategy to train the model on a large-scale graph. It improves the scalability of the model. Second, we design an edge convolutional neural network layer to realize the fusion of edge neighborhood information. We take the reconstruction error as the evaluation criterion after stacking multiple edge convolutional neural network layers that encode and decode the edges. Third, the few abnormal samples with known labels are utilized to guide the model’s parameter optimization process. While ensuring the generalization ability of the model, it also improves the pertinence to specific anomalies. Finally, we show the effectiveness of the proposed algorithm through experiments on two real-world datasets.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2021: 30th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part I},
pages = {141–152},
numpages = {12},
keywords = {Anomaly detection, Neural networks, Semi-supervised learning, Deep auto-encoder},
location = {Bratislava, Slovakia}
}

@article{10.1007/s10664-021-09944-w,
author = {Riom, Timoth\'{e} and Sawadogo, Arthur and Allix, Kevin and Bissyand\'{e}, Tegawend\'{e} F. and Moha, Naouel and Klein, Jacques},
title = {Revisiting the VCCFinder approach for the identification of vulnerability-contributing commits},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09944-w},
doi = {10.1007/s10664-021-09944-w},
abstract = {Detecting vulnerabilities in software is a constant race between development teams and potential attackers. While many static and dynamic approaches have focused on regularly analyzing the software in its entirety, a recent research direction has focused on the analysis of changes that are applied to the code. VCCFinder is a seminal approach in the literature that builds on machine learning to automatically detect whether an incoming commit will introduce some vulnerabilities. Given the influence of VCCFinder in the literature, we undertake an investigation into its performance as a state-of-the-art system. To that end, we propose to attempt a replication study on the VCCFinder supervised learning approach. The insights of our failure to replicate the results reported in the original publication informed the design of a new approach to identify vulnerability-contributing commits based on a semi-supervised learning technique with an alternate feature set. We provide all artefacts and a clear description of this approach as a new reproducible baseline for advancing research on machine learning-based identification of vulnerability-introducing commits.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {30},
keywords = {Vulnerability detection, Machine learning, Replication, Software engineering}
}

@article{10.1016/j.eswa.2021.114835,
author = {Ashofteh, Afshin and Bravo, Jorge M.},
title = {A conservative approach for online credit scoring},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {176},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114835},
doi = {10.1016/j.eswa.2021.114835},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {16},
keywords = {C01, C41, C53, C58, E51, G21, Risk analysis, Online credit scoring, Big Data, Kruskal_Wallis statistic, Open banking, Machine learning}
}

@article{10.1016/j.jnca.2021.103210,
author = {Jiang, Yuning and Atif, Yacine},
title = {A selective ensemble model for cognitive cybersecurity analysis},
year = {2021},
issue_date = {Nov 2021},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {193},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2021.103210},
doi = {10.1016/j.jnca.2021.103210},
journal = {J. Netw. Comput. Appl.},
month = nov,
numpages = {16},
keywords = {Information security, Vulnerability analysis, Data correlation, Machine learning, Ensemble, Data mining, Database management}
}

@inproceedings{10.1145/3328519.3329134,
author = {Santos, A\'{e}cio and Castelo, Sonia and Felix, Cristian and Ono, Jorge Piazentin and Yu, Bowen and Hong, Sungsoo Ray and Silva, Cl\'{a}udio T. and Bertini, Enrico and Freire, Juliana},
title = {Visus: An Interactive System for Automatic Machine Learning Model Building and Curation},
year = {2019},
isbn = {9781450367912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328519.3329134},
doi = {10.1145/3328519.3329134},
abstract = {While the demand for machine learning (ML) applications is booming, there is a scarcity of data scientists capable of building such models. Automatic machine learning (AutoML) approaches have been proposed that help with this problem by synthesizing end-to-end ML data processing pipelines. However, these follow a best-effort approach and a user in the loop is necessary to curate and refine the derived pipelines. Since domain experts often have little or no expertise in machine learning, easy-to-use interactive interfaces that guide them throughout the model building process are necessary. In this paper, we present Visus, a system designed to support the model building process and curation of ML data processing pipelines generated by AutoML systems. We describe the framework used to ground our design choices and a usage scenario enabled by Visus. Finally, we discuss the feedback received in user testing sessions with domain experts.},
booktitle = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
articleno = {6},
numpages = {7},
keywords = {Automatic machine learning, Data analytics, Data visualization},
location = {Amsterdam, Netherlands},
series = {HILDA '19}
}

@inproceedings{10.1145/3360774.3360787,
author = {Lu, Jianchao and Zheng, Xi and Sheng, Quan Z. and Hussain, Zawar and Wang, Jiaxing and Zhou, Wanlei},
title = {MFE-HAR: multiscale feature engineering for human activity recognition using wearable sensors},
year = {2020},
isbn = {9781450372831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3360774.3360787},
doi = {10.1145/3360774.3360787},
abstract = {Human activity recognition plays a key role in the application areas such as fitness tracking, healthcare and aged care support. However, inaccurate recognition results may cause an adverse effect on users or even an unpredictable accident. In order to improve the accuracy of human activity recognition, multi-device and deep learning based approaches have been proposed. However, they are not practical on a daily basis due to the limitations that devices are difficult to wear, and deep learning requires large training dataset and incurs expensive computational costs. To address this problem, we propose a novel approach, multiscale feature engineering for human activity recognition (MFE-HAR), which exploits the properties of arm movement from global and local scales using the accelerometer and gyroscope sensors on a single wearable device. Our method takes advantage of having important features at multiple scales over previous single-scale methods. We evaluated the performance of the proposed method on two public datasets and achieved the mean classification accuracy of 93% and 98% respectively. Our proposed system performs better than the state of the art multi-device based approaches, and is more practical for real-world applications.},
booktitle = {Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {180–189},
numpages = {10},
keywords = {activity recognition, mobile and wearable computing systems and services, pervasive technologies for healthcare},
location = {Houston, Texas, USA},
series = {MobiQuitous '19}
}

@article{10.1016/j.diin.2019.01.017,
author = {Karbab, ElMouatez Billah and Debbabi, Mourad},
title = {MalDy: Portable, data-driven malware detection using natural language processing and machine learning techniques on behavioral&nbsp;analysis reports},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {28},
number = {S},
issn = {1742-2876},
url = {https://doi.org/10.1016/j.diin.2019.01.017},
doi = {10.1016/j.diin.2019.01.017},
journal = {Digit. Investig.},
month = apr,
pages = {S77–S87},
numpages = {11},
keywords = {Malware, Android, Win32, Behavioral analysis, Machine learning, NLP}
}

@article{10.1007/s10462-021-09970-6,
author = {Pintas, Julliano Trindade and Fernandes, Leandro A. F. and Garcia, Ana Cristina Bicharra},
title = {Feature selection methods for text classification: a systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {8},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-021-09970-6},
doi = {10.1007/s10462-021-09970-6},
abstract = {Feature Selection (FS) methods alleviate key problems in classification procedures as they are used to improve classification accuracy, reduce data dimensionality, and remove irrelevant data. FS methods have received a great deal of attention from the text classification community. However, only a few literature surveys include them focusing on text classification, and the ones available are either a superficial analysis or present a very small set of work in the subject. For this reason, we conducted a Systematic Literature Review (SLR) that asses 1376 unique papers from journals and conferences published in the past eight years (2013–2020). After abstract screening and full-text eligibility analysis, 175 studies were included in our SLR. Our contribution is twofold. We have considered several aspects of each proposed method and mapped them into a new categorization schema. Additionally, we mapped the main characteristics of the experiments, identifying which datasets, languages, machine learning algorithms, and validation methods have been used to evaluate new and existing techniques. By following the SLR protocol, we allow the replication of our revision process and minimize the chances of bias while classifying the included studies. By mapping issues and experiment settings, our SLR helps researchers to develop and position new studies with respect to the existing literature.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {6149–6200},
numpages = {52},
keywords = {Feature selection, Dimensionality reduction, Text classification, Systematic literature review}
}

@article{10.1007/s42979-021-00557-0,
author = {Sarker, Iqbal H. and Furhad, Md Hasan and Nowrozy, Raza},
title = {AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00557-0},
doi = {10.1007/s42979-021-00557-0},
abstract = {Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or&nbsp;Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or&nbsp;AI-based technical point of view.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {18},
keywords = {Cybersecurity, Artificial intelligence, Machine learning, Cyber data analytics, Cyber-attacks, Anomaly, Intrusion detection, Security intelligence}
}

@inproceedings{10.1145/3357223.3362736,
author = {Las-Casas, Pedro and Papakerashvili, Giorgi and Anand, Vaastav and Mace, Jonathan},
title = {Sifter: Scalable Sampling for Distributed Traces, without Feature Engineering},
year = {2019},
isbn = {9781450369732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357223.3362736},
doi = {10.1145/3357223.3362736},
abstract = {Distributed tracing is a core component of cloud and datacenter systems, and provides visibility into their end-to-end runtime behavior. To reduce computational and storage overheads, most tracing frameworks do not keep all traces, but sample them uniformly at random. While effective at reducing overheads, uniform random sampling inevitably captures redundant, common-case execution traces, which are less useful for analysis and troubleshooting tasks. In this work we present Sifter, a general-purpose framework for biased trace sampling. Sifter captures qualitatively more diverse traces, by weighting sampling decisions towards edge-case code paths, infrequent request types, and anomalous events. Sifter does so by using the incoming stream of traces to build an unbiased low-dimensional model that approximates the system's common-case behavior. Sifter then biases sampling decisions towards traces that are poorly captured by this model. We have implemented Sifter, integrated it with several open-source tracing systems, and evaluate with traces from a range of open-source and production distributed systems. Our evaluation shows that Sifter effectively biases towards anomalous and outlier executions, is robust to noisy and heterogeneous traces, is efficient and scalable, and adapts to changes in workloads over time.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {312–324},
numpages = {13},
location = {Santa Cruz, CA, USA},
series = {SoCC '19}
}

@inproceedings{10.1145/2600428.2609601,
author = {Cormack, Gordon V. and Grossman, Maura R.},
title = {Evaluation of machine-learning protocols for technology-assisted review in electronic discovery},
year = {2014},
isbn = {9781450322577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600428.2609601},
doi = {10.1145/2600428.2609601},
abstract = {Abstract Using a novel evaluation toolkit that simulates a human reviewer in the loop, we compare the effectiveness of three machine-learning protocols for technology-assisted review as used in document review for discovery in legal proceedings. Our comparison addresses a central question in the deployment of technology-assisted review: Should training documents be selected at random, or should they be selected using one or more non-random methods, such as keyword search or active learning? On eight review tasks -- four derived from the TREC 2009 Legal Track and four derived from actual legal matters -- recall was measured as a function of human review effort. The results show that entirely non-random training methods, in which the initial training documents are selected using a simple keyword search, and subsequent training documents are selected by active learning, require substantially and significantly less human review effort (P&lt;0.01) to achieve any given level of recall, than passive learning, in which the machine-learning algorithm plays no role in the selection of training documents. Among passive-learning methods, significantly less human review effort (P&lt;0.01) is required when keywords are used instead of random sampling to select the initial training documents. Among active-learning methods, continuous active learning with relevance feedback yields generally superior results to simple active learning with uncertainty sampling, while avoiding the vexing issue of "stabilization" -- determining when training is adequate, and therefore may stop.},
booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
pages = {153–162},
numpages = {10},
keywords = {e-discovery, electronic discovery, predictive coding, technology-assisted review},
location = {Gold Coast, Queensland, Australia},
series = {SIGIR '14}
}

@article{10.1145/3485875,
author = {Yang, Qiang},
title = {Toward Responsible AI: An Overview of Federated Learning for User-centered Privacy-preserving Computing},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3–4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3485875},
doi = {10.1145/3485875},
abstract = {With the rapid advances of Artificial Intelligence (AI) technologies and applications, an increasing concern is on the development and application of responsible AI technologies. Building AI technologies or machine-learning models often requires massive amounts of data, which may include sensitive, user private information to be collected from different sites or countries. Privacy, security, and data governance constraints rule out a brute force process in the acquisition and integration of these data. It is thus a serious challenge to protect user privacy while achieving high-performance models. This article reviews recent progress of federated learning in addressing this challenge in the context of privacy-preserving computing. Federated learning allows global AI models to be trained and used among multiple decentralized data sources with high security and privacy guarantees, as well as sound incentive mechanisms. This article presents the background, motivations, definitions, architectures, and applications of federated learning as a new paradigm for building privacy-preserving, responsible AI ecosystems.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = oct,
articleno = {32},
numpages = {22},
keywords = {Federated learning, responsible AI, decentralized AI, privacy-preserving computing, user privacy, data security, machine learning, blockchain}
}

@article{10.1016/j.asoc.2020.107069,
author = {Zhang, Nan and Tan, Yu-an and Yang, Chen and Li, Yuanzhang},
title = {Deep learning feature exploration for Android malware detection},
year = {2021},
issue_date = {Apr 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.107069},
doi = {10.1016/j.asoc.2020.107069},
journal = {Appl. Soft Comput.},
month = apr,
numpages = {7},
keywords = {Malware detection, Android security, Text classification, Deep learning, Smart city}
}

@inproceedings{10.1145/3219819.3219914,
author = {Samel, Karan and Miao, Xu},
title = {Active Deep Learning to Tune Down the Noise in Labels},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219914},
doi = {10.1145/3219819.3219914},
abstract = {The great success of supervised learning has initiated a paradigm shift from building a deterministic software system to a probabilistic artificial intelligent system throughout the industry. The historical records in enterprise domains can potentially bootstrap the traditional business into the modern data-driven approach almost everywhere. The introduction of the Deep Neural Networks (DNNs) significantly reduces the efforts of feature engineering so that supervised learning becomes even more automated. The last bottleneck is to ensure the data quality, particularly the label quality, because the performance of supervised learning is bounded by the errors present in labels. In this paper, we present a new Active Deep Denoising (ADD) approach that first builds a DNN noise model, and then adopts an active learning algorithm to identify the optimal denoising function. We prove that under the low noise condition, we only need to query the oracle with log n examples where n is the total number in the data. We apply ADD on one enterprise application and show that it can effectively reduce 1/3 of the prediction error with only 0.1% of examples verified by the oracle.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {685–694},
numpages = {10},
keywords = {active learning, classification, deep neural networks, denoising},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.1016/j.eswa.2013.08.042,
author = {Pe\~{n}a-Ayala, Alejandro},
title = {Review: Educational data mining: A survey and a data mining-based analysis of recent works},
year = {2014},
issue_date = {March, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2013.08.042},
doi = {10.1016/j.eswa.2013.08.042},
abstract = {This review pursues a twofold goal, the first is to preserve and enhance the chronicles of recent educational data mining (EDM) advances development; the second is to organize, analyze, and discuss the content of the review based on the outcomes produced by a data mining (DM) approach. Thus, as result of the selection and analysis of 240 EDM works, an EDM work profile was compiled to describe 222 EDM approaches and 18 tools. A profile of the EDM works was organized as a raw data base, which was transformed into an ad-hoc data base suitable to be mined. As result of the execution of statistical and clustering processes, a set of educational functionalities was found, a realistic pattern of EDM approaches was discovered, and two patterns of value-instances to depict EDM approaches based on descriptive and predictive models were identified. One key finding is: most of the EDM approaches are ground on a basic set composed by three kinds of educational systems, disciplines, tasks, methods, and algorithms each. The review concludes with a snapshot of the surveyed EDM works, and provides an analysis of the EDM strengths, weakness, opportunities, and threats, whose factors represent, in a sense, future work to be fulfilled.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1432–1462},
numpages = {31},
keywords = {Data mining, Data mining profile, Educational data mining, Educational data mining approach pattern, Pattern for descriptive and predictive educational data mining approaches}
}

@article{10.1016/j.jss.2018.07.054,
author = {Ochoa, Lina and Gonz\'{a}lez-Rojas, Oscar and Juliana, Alves Pereira and Castro, Harold and Saake, Gunter},
title = {A systematic literature review on the semi-automatic configuration of extended product lines},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.07.054},
doi = {10.1016/j.jss.2018.07.054},
journal = {J. Syst. Softw.},
month = oct,
pages = {511–532},
numpages = {22},
keywords = {Extended product line, Product configuration, Systematic literature review}
}

@article{10.1007/s11042-018-7044-8,
author = {Ishtiaq, Uzair and Abdul Kareem, Sameem and Abdullah, Erma Rahayu Mohd Faizal and Mujtaba, Ghulam and Jahangir, Rashid and Ghafoor, Hafiz Yasir},
title = {Diabetic retinopathy detection through artificial intelligent techniques: a review and open issues},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {21–22},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-7044-8},
doi = {10.1007/s11042-018-7044-8},
abstract = {Diabetic Retinopathy (DR) is the disease caused by uncontrolled diabetes that may lead to blindness among the patients. Due to the advancements in artificial intelligence, early detection of DR through an automated system is more beneficial over the manual detection. At present, there are several published studies on automated DR detection systems through machine learning or deep learning approaches. This study presents a review on DR detection techniques from five different aspects namely, datasets, image preprocessing techniques, machine learning-based approaches, deep learning-based approaches, and performance measures. Moreover, it also presents the authors’ observation and significance of the review findings. Furthermore, we also discuss nine new research challenges in DR detection. After a rigorous selection process, 74 primary publications were selected from eight academic databases for this review. From the selected studies, it was observed that many public datasets are available in the field of DR detection. In image preprocessing techniques, contrast enhancement combined with green channel extraction contributed the most in classification accuracy. In features, shape-based, texture-based and statistical features were reported as the most discriminative in DR detection. The Artificial Neural Network was proven eminent classifier compared to other machine learning classifiers. In deep learning, Convolutional Neural Network outperformed compared to other deep learning networks. Finally, to measure the classification performance, accuracy, sensitivity, and specificity metrics were mostly employed. This review presents a comprehensive summary of DR detection techniques and will be proven useful for the community of scientists working in the field of automated DR detection techniques.},
journal = {Multimedia Tools Appl.},
month = jun,
pages = {15209–15252},
numpages = {44},
keywords = {Diabetic retinopathy, Convolutional neural network, DIARETDB1, Image preprocessing, Artificial neural network, Transfer learning}
}

@article{10.1016/j.eswa.2010.07.119,
author = {Kankar, P. K. and Sharma, Satish C. and Harsha, S. P.},
title = {Fault diagnosis of ball bearings using machine learning methods},
year = {2011},
issue_date = {March, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.07.119},
doi = {10.1016/j.eswa.2010.07.119},
abstract = {Ball bearings faults are one of the main causes of breakdown of rotating machines. Thus, detection and diagnosis of mechanical faults in ball bearings is very crucial for the reliable operation. This study is focused on fault diagnosis of ball bearings using artificial neural network (ANN) and support vector machine (SVM). A test rig of high speed rotor supported on rolling bearings is used. The vibration response are obtained and analyzed for the various defects of ball bearings. The specific defects are considered as crack in outer race, inner race with rough surface and corrosion pitting in balls. Statistical methods are used to extract features and to reduce the dimensionality of original vibration features. A comparative experimental study of the effectiveness of ANN and SVM is carried out. The results show that the machine learning algorithms mentioned above can be used for automated diagnosis of bearing faults. It is also observed that the severe (chaotic) vibrations occur under bearings with rough inner race surface and ball with corrosion pitting.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1876–1886},
numpages = {11},
keywords = {Artificial neural network, Fault diagnosis, Support vector machine}
}

@article{10.1007/s00778-021-00671-8,
author = {Balayn, Agathe and Lofi, Christoph and Houben, Geert-Jan},
title = {Managing bias and unfairness in data for decision support: a survey of machine learning and data engineering approaches to identify and mitigate bias and unfairness within data management and analytics systems},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {5},
issn = {1066-8888},
url = {https://doi.org/10.1007/s00778-021-00671-8},
doi = {10.1007/s00778-021-00671-8},
abstract = {The increasing use of data-driven decision support systems in industry and governments is accompanied by the discovery of a plethora of bias and unfairness issues in the outputs of these systems. Multiple computer science communities, and especially machine learning, have started to tackle this problem, often developing algorithmic solutions to mitigate biases to obtain fairer outputs. However, one of the core underlying causes for unfairness is bias in training data which is not fully covered by such approaches. Especially, bias in data is not yet a central topic in data engineering and management research. We survey research on bias and unfairness in several computer science domains, distinguishing between data management publications and other domains. This covers the creation of fairness metrics, fairness identification, and mitigation methods, software engineering approaches and biases in crowdsourcing activities. We identify relevant research gaps and show which data management activities could be repurposed to handle biases and which ones might reinforce such biases. In the second part, we argue for a novel data-centered approach overcoming the limitations of current algorithmic-centered methods. This approach focuses on eliciting and enforcing fairness requirements and constraints on data that systems are trained, validated, and used on. We argue for the need to extend database management systems to handle such constraints and mitigation methods. We discuss the associated future research directions regarding algorithms, formalization, modelling, users, and systems.},
journal = {The VLDB Journal},
month = may,
pages = {739–768},
numpages = {30},
keywords = {Bias and unfairness, Decision support systems, Data curation, Bias mitigation, Bias constraints for DBMS}
}

@article{10.1504/IJIIDS.2010.035579,
author = {Mateo, Romeo Mark A. and Lee, Jaewan},
title = {Data mining model based on multi-agent for the intelligent distributed framework},
year = {2010},
issue_date = {September 2010},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {4},
number = {4},
issn = {1751-5858},
url = {https://doi.org/10.1504/IJIIDS.2010.035579},
doi = {10.1504/IJIIDS.2010.035579},
abstract = {Most researches in large-scale distributed system only focus on improving a single scheme, and the relationships between the schemes that affect the performance of each scheme are ignored. In this paper, an intelligent distributed framework is introduced to address the use of intelligent models for the adaptive schemes of a distributed system. This paper tackles two aspects; the general model of an agent-based data mining to implement the schemes of distributed object system using data mining algorithms and efficient interactions of the schemes using multi-agent approach. The adaptive schemes use clustering to construct classes for object grouping, classification method to classify the requests using the classes constructed from clustering, and association mining to generate rules for predicting the next object needed to be replicated. These schemes are provided with relationships for the adaptive technique and the interaction is based on the action model of multi-agent system. Simulation result shows significant improvements on serving clients by minimised delay time and efficient load distribution.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = sep,
pages = {322–336},
numpages = {15},
keywords = {MAS, agent-based systems, association mining, classification, clustering, data mining, delay time, distributed systems, intelligent modelling, load distribution, multi-agent systems, object grouping, simulation}
}

@inproceedings{10.1145/3219819.3219851,
author = {Molino, Piero and Zheng, Huaixiu and Wang, Yi-Chia},
title = {COTA: Improving the Speed and Accuracy of Customer Support through Ranking and Deep Networks},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219851},
doi = {10.1145/3219819.3219851},
abstract = {For a company looking to provide delightful user experiences, it is of paramount importance to take care of any customer issues. This paper proposes COTA, a system to improve speed and reliability of customer support for end users through automated ticket classification and answers selection for support representatives. Two machine learning and natural language processing techniques are demonstrated: one relying on feature engineering (COTA v1) and the other exploiting raw signals through deep learning architectures (COTA v2). COTA v1 employs a new approach that converts the multi-classification task into a ranking problem, demonstrating significantly better performance in the case of thousands of classes. For COTA v2, we propose an Encoder-Combiner-Decoder, a novel deep learning architecture that allows for heterogeneous input and output feature types and injection of prior knowledge through network architecture choices. This paper compares these models and their variants on the task of ticket classification and answer selection, showing model COTA v2 outperforms COTA v1, and analyzes their inner workings and shortcomings. Finally, an A/B test is conducted in a production setting validating the real-world impact of COTA in reducing issue resolution time by 10 percent without reducing customer satisfaction.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {586–595},
numpages = {10},
keywords = {customer satisfaction, customer support, deep learning, intent detection, machine learning, natural language processing},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.1007/s10664-021-09940-0,
author = {Cashman, Mikaela and Firestone, Justin and Cohen, Myra B. and Thianniwet, Thammasak and Niu, Wei},
title = {An empirical investigation of organic software product lines},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09940-0},
doi = {10.1007/s10664-021-09940-0},
abstract = {Software product line engineering is a best practice for managing reuse in families of software systems that is increasingly being applied to novel and emerging domains. In this work we investigate the use of software product line engineering in one of these new domains, synthetic biology. In synthetic biology living organisms are programmed to perform new functions or improve existing functions. These programs are designed and constructed using small building blocks made out of DNA. We conjecture that there are families of products that consist of common and variable DNA parts, and we can leverage product line engineering to help synthetic biologists build, evolve, and reuse DNA parts. In this paper we perform an investigation of domain engineering that leverages an open-source repository of more than 45,000 reusable DNA parts. We show the feasibility of these new types of product line models by identifying features and related artifacts in up to 93.5% of products, and that there is indeed both commonality and variability. We then construct feature models for four commonly engineered functions leading to product lines ranging from 10 to 7.5 \texttimes{} 1020 products. In a case study we demonstrate how we can use the feature models to help guide new experimentation in aspects of application engineering. Finally, in an empirical study we demonstrate the effectiveness and efficiency of automated reverse engineering on both complete and incomplete sets of products. In the process of these studies, we highlight key challenges and uncovered limitations of existing SPL techniques and tools which provide a roadmap for making SPL engineering applicable to new and emerging domains.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {43},
keywords = {Software product lines, Synthetic biology, Reverse engineering, BioBricks}
}

@inproceedings{10.1145/3394486.3403205,
author = {Namaki, Mohammad Hossein and Floratou, Avrilia and Psallidas, Fotis and Krishnan, Subru and Agrawal, Ashvin and Wu, Yinghui and Zhu, Yiwen and Weimer, Markus},
title = {Vamsa: Automated Provenance Tracking in Data Science Scripts},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403205},
doi = {10.1145/3394486.3403205},
abstract = {There has recently been a lot of ongoing research in the areas of fairness, bias and explainability of machine learning (ML) models due to the self-evident or regulatory requirements of various ML applications. We make the following observation: All of these approaches require a robust understanding of the relationship between ML models and the data used to train them. In this work, we introduce the ML provenance tracking problem: the fundamental idea is to automatically track which columns in a dataset have been used to derive the features/labels of an ML model. We discuss the challenges in capturing such information in the context of Python, the most common language used by data scientists.We then present Vamsa, a modular system that extracts provenance from Python scripts without requiring any changes to the users' code. Using 26K real data science scripts, we verify the effectiveness of Vamsa in terms of coverage, and performance. We also evaluate Vamsa's accuracy on a smaller subset of manually labeled data. Our analysis shows that Vamsa's precision and recall range from 90.4% to 99.1% and its latency is in the order of milliseconds for average size scripts. Drawing from our experience in deploying ML models in production, we also present an example in which Vamsa helps automatically identify models that are affected by data corruption issues.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1542–1551},
numpages = {10},
keywords = {data science, machine learning, provenance},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1007/s10270-011-0220-1,
author = {Hubaux, Arnaud and Heymans, Patrick and Schobbens, Pierre-Yves and Deridder, Dirk and Abbasi, Ebrahim Khalil},
title = {Supporting multiple perspectives in feature-based configuration},
year = {2013},
issue_date = {July      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-011-0220-1},
doi = {10.1007/s10270-011-0220-1},
abstract = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {641–663},
numpages = {23},
keywords = {Feature diagram, Feature-based configuration, Multi-view, Separation of concerns, Software product line engineering}
}

@article{10.1504/ijkedm.2021.119888,
author = {Elimam, Somaia and Bougeussa, Mohamed},
title = {An evaluation dataset for depression detection in Arabic social media},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {7},
number = {1–2},
issn = {1755-2087},
url = {https://doi.org/10.1504/ijkedm.2021.119888},
doi = {10.1504/ijkedm.2021.119888},
abstract = {Studying depression in Arabic social media has been neglected compared to other languages and the traditional way of dealing with depression (face-to-face medical diagnose) is not enough as the number of people that suffer from depression in Arabic communities increased dramatically. This paper proposes the first dataset to detect depressed users in Arabic social media. We pondered tweets from Twitter, pre-processed and converted it to a structured format. A notable advantage of the elaborated dataset is that it allows effective evaluation of machine learning algorithms for depression detection. We employ several classification algorithms such as deep neural network, logistic regression, multinomial Na\"{\i}ve Bayes, Bernoulli Na\"{\i}ve Bayes, AdaBoost, passive aggressive, nearest centroid, and linear SVC. The F-score, AUC, precision, and accuracy scores were selected as performance measures to compare algorithms, and the result showed that it is very challenging to classify Arabic tweets especially with the sparse nature of Twitter data.},
journal = {Int. J. Knowl. Eng. Data Min.},
month = jan,
pages = {113–126},
numpages = {13},
keywords = {Arabic dataset, depression detection, Arabic social media, machine learning}
}

@inproceedings{10.5555/1599081.1599154,
author = {Mistica, Meladel and Baldwin, Timothy and Cordella, Marisa and Musgrave, Simon},
title = {Applying discourse analysis and data mining methods to spoken OSCE assessments},
year = {2008},
isbn = {9781905593446},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper looks at the transcribed data of patient-doctor consultations in an examination setting. The doctors are internationally qualified and enrolled in a bridging course as preparation for their Australian Medical Council examination. In this study, we attempt to ascertain if there are measurable linguistic features of the consultations, and to investigate whether there is any relevant information about the communicative styles of the qualifying doctors that may predict satisfactory or non-satisfactory examination outcomes. We have taken a discourse analysis approach in this study, where the core unit of analysis is a 'turn'. We approach this problem as a binary classification task and employ data mining methods to see whether the application of which to richly annotated dialogues can produce a system with an adequate predictive capacity.},
booktitle = {Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1},
pages = {577–584},
numpages = {8},
location = {Manchester, United Kingdom},
series = {COLING '08}
}

@inproceedings{10.5555/1596324.1596370,
author = {Wang, Hongling and Wang, Honglin and Zhou, Guodong and Zhu, Qiaoming},
title = {Dependency tree-based SRL with proper pruning and extensive feature engineering},
year = {2008},
isbn = {9781905593484},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper proposes a dependency tree-based SRL system with proper pruning and extensive feature engineering. Official evaluation on the CoNLL 2008 shared task shows that our system achieves 76.19 in labeled macro F1 for the overall task, 84.56 in labeled attachment score for syntactic dependencies, and 67.12 in labeled F1 for semantic dependencies on combined test set, using the standalone MaltParser. Besides, this paper also presents our unofficial system by 1) applying a new effective pruning algorithm; 2) including additional features; and 3) adopting a better dependency parser, MSTParser. Unofficial evaluation on the shared task shows that our system achieves 82.53 in labeled macro F1, 86.39 in labeled attachment score, and 78.64 in labeled F1, using MSTParser on combined test set. This suggests that proper pruning and extensive feature engineering contributes much in dependency tree-based SRL.},
booktitle = {Proceedings of the Twelfth Conference on Computational Natural Language Learning},
pages = {253–257},
numpages = {5},
location = {Manchester, United Kingdom},
series = {CoNLL '08}
}

@inproceedings{10.5555/646089.680078,
author = {Estublier, Jacky},
title = {Objects Control for Software Configuration Management},
year = {2001},
isbn = {3540422153},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A major requirement in Software Engineering is to reduce the time to market. This requirement along with a demand for product sophistication and better quality has led to larger teams which in turn dramatically increases the pressure for more concurrent work in a distributed context.This paper, based on our experience in Software Configuration Management for large software systems, shows why object management in such a context requires specific facilities for the consistent management of objects in multiple copies, different locations and formats, accessed and changed simultaneously by many engineers.We present the solutions we have developed with our partner Dassault Syst mes, for the definition and enforcement of consistent concurrent engineering work, including a number of measures showing that scalability and efficiency are really tough issues.We argue that the scalability and efficiency constraints found in SCMcan only be met by a new architecture of SCM systems and by the development of a middleware layer that should be common to all SCM tools, and also usable by other applications sharing the same concerns.},
booktitle = {Proceedings of the 13th International Conference on Advanced Information Systems Engineering},
pages = {359–373},
numpages = {15},
keywords = {architecture, concurrent engineering, distribution, software configuration management, version control},
series = {CAiSE '01}
}

@article{10.1145/3088440,
author = {Acher, Mathieu and Lopez-Herrejon, Roberto E. and Rabiser, Rick},
title = {Teaching Software Product Lines: A Snapshot of Current Practices and Challenges},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
url = {https://doi.org/10.1145/3088440},
doi = {10.1145/3088440},
abstract = {Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving, as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, and what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. In this article, we report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, that is, an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community.},
journal = {ACM Trans. Comput. Educ.},
month = oct,
articleno = {2},
numpages = {31},
keywords = {Software product lines, software engineering teaching, software product line teaching, variability modeling}
}

@article{10.1613/jair.1.11688,
author = {Mogadala, Aditya and Kalimuthu, Marimuthu and Klakow, Dietrich},
title = {Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods},
year = {2021},
issue_date = {Sep 2021},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {71},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.11688},
doi = {10.1613/jair.1.11688},
abstract = {Interest in Artificial Intelligence (AI) and its applications has seen unprecedented growth in the last few years. This success can be partly attributed to the advancements made in the sub-fields of AI such as machine learning, computer vision, and natural language processing. Much of the growth in these fields has been made possible with deep learning, a sub-area of machine learning that uses artificial neural networks. This has created significant interest in the integration of vision and language. In this survey, we focus on ten prominent tasks that integrate language and vision by discussing their problem formulation, methods, existing datasets, evaluation measures, and compare the results obtained with corresponding state-of-the-art methods. Our efforts go beyond earlier surveys which are either task-specific or concentrate only on one type of visual content, i.e., image or video. Furthermore, we also provide some potential future directions in this field of research with an anticipation that this survey stimulates innovative thoughts and ideas to address the existing challenges and build new applications.},
journal = {J. Artif. Int. Res.},
month = sep,
pages = {1183–1317},
numpages = {135},
keywords = {natural language, machine learning, computer vision, deep learning}
}

@inproceedings{10.1145/3490725.3490753,
author = {He, Miao and Zhan, Xiaoming and Shen, Dayong and Zhu, Yuanyuan and Zhao, Hua and He, Renjie},
title = {What About Your Next Job? Predicting Professional Career Trajectory Using Neural Networks},
year = {2022},
isbn = {9781450384247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490725.3490753},
doi = {10.1145/3490725.3490753},
abstract = {Accurate and effective analysis of professional career trajectories can help job seekers make the right job switch quickly. However, it is a non-trivial task to develop an effective model to predict the next job of users. Previous works either focus on feature engineering that resulted in heavy computations or not supporting complete solutions from the perspective of individuals. To this end, we propose an end-to-end model to predict the next job of users comprehensively. The problem of predicting the next job is broken into three tasks, i.e., position name prediction, salary level prediction, company size prediction. These three tasks share the same framework of the model with different output dimensions. Specifically, we reorder the raw features and regard each resume as a textual sentence consists of several key phrases. Word2Vec is utilized to train the hidden vectors of all phrases in the sentences. Followed by a feature extracting component comprised of a convolutional neural network (CNN) or a long short-term memory (LSTM) network. Experiments on a real-world dataset validate that our proposed model significantly outperforms baselines and reveal interesting insights into job transitions from two perspectives.},
booktitle = {Proceedings of the 2021 4th International Conference on Machine Learning and Machine Intelligence},
pages = {184–189},
numpages = {6},
keywords = {Data Mining, Next Job, Position Prediction, Professional Career Trajectories, Salary Prediction, Size Prediction},
location = {Hangzhou, China},
series = {MLMI '21}
}

@inproceedings{10.1007/978-3-030-87007-2_2,
author = {Vilaseca, Federico and Castro, Alberto and Chreties, Christian and Gorgoglione, Angela},
title = {Daily Rainfall-Runoff Modeling at Watershed Scale: A Comparison Between Physically-Based and Data-Driven Models},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_2},
doi = {10.1007/978-3-030-87007-2_2},
abstract = {In the last decades, data-driven (DD) machine-learning models have been rapidly developed and widely applied to solve hydrologic problems. To explore DD approaches’ capability in rainfall-runoff modeling compared to knowledge-driven models, we conducted a thorough comparison between Soil &amp; Water Assessment Tool (SWAT) and Random Forest (RF) models. They were implemented to simulate the daily surface runoff at Santa Luc\'{\i}a Chico watershed in Uruguay. Aiming at making a fair comparison, the same input time series for RF and SWAT models were considered. Both approaches are able to represent the daily surface runoff adequately. The RF model shows a higher accuracy for calibration/training, while the SWAT model yields better results for validation/testing, indicating that the latter has a better generalization capacity. Furthermore, RF outperforms SWAT in terms of computational time needed for a proper calibration/training. Strategies to improve RF performance and interpretability should include feature selection, feature engineering and a more sophisticated sensitivity analysis technique.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {18–33},
numpages = {16},
keywords = {Hydrology, SWAT, Random Forest, Machine learning},
location = {Cagliari, Italy}
}

@inproceedings{10.1007/978-3-030-89432-0_3,
author = {Choi, Young Ah and Park, Kyung Ho and Park, Eunji and Kim, Huy Kang},
title = {Unsupervised Driver Behavior Profiling Leveraging Recurrent Neural Networks},
year = {2021},
isbn = {978-3-030-89431-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89432-0_3},
doi = {10.1007/978-3-030-89432-0_3},
abstract = {In the era of intelligent transportation, driver behavior profiling has become a beneficial technology as it provides knowledge regarding the driver’s aggressiveness. Previous approaches achieved promising driver behavior profiling performance through establishing statistical heuristics rules or supervised learning-based models. Still, there exist limits that the practitioner should prepare a labeled dataset, and prior approaches could not classify aggressive behaviors which are not known a priori. In pursuit of improving the aforementioned drawbacks, we propose a novel approach to driver behavior profiling leveraging an unsupervised learning paradigm. First, we cast the driver behavior profiling problem as anomaly detection. Second, we established recurrent neural networks that predict the next feature vector given a sequence of feature vectors. We trained the model with normal driver data only. As a result, our model yields high regression error given a sequence of aggressive driver behavior and low error given at a sequence of normal driver behavior. We figured this difference of error between normal and aggressive driver behavior can be an adequate flag for driver behavior profiling and accomplished a precise performance in experiments. Lastly, we further analyzed the optimal level of sequence length for identifying each aggressive driver behavior. We expect the proposed approach to be a useful baseline for unsupervised driver behavior profiling and contribute to the efficient, intelligent transportation ecosystem.},
booktitle = {Information Security Applications: 22nd International Conference, WISA 2021, Jeju Island, South Korea, August 11–13, 2021, Revised Selected Papers},
pages = {28–38},
numpages = {11},
keywords = {Driver behavior profiling, Unsupervised learning, Recurrent neural networks},
location = {Jeju, Korea (Republic of)}
}

@inproceedings{10.1007/978-3-030-77772-2_12,
author = {Dorton, Stephen L. and Hall, Robert A.},
title = {Collaborative Human-AI Sensemaking for Intelligence Analysis},
year = {2021},
isbn = {978-3-030-77771-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77772-2_12},
doi = {10.1007/978-3-030-77772-2_12},
abstract = {AI/ML is often considered the means by which intelligence analysts will overcome challenges of data overload under time pressure; however, AI/ML tools are often data- or algorithm-centric and opaque, and do not support the complexities of analyst sensemaking. An exploratory sensitivity analysis was conducted with a simple Authorship Attribution (AA) task to identify the degree to which an analyst can apply their sensemaking outputs as inputs to affect the performance of AI/ML tools, which can then provide higher quality information for continued sensemaking. These results show that analysts may support the performance of AI/ML primarily by refinement of potential outcomes, refinement of data and features, and refinement of algorithms themselves. A notional model of collaborative sensemaking with AI/ML was developed to show how AI/ML can support analyst sensemaking by processing large amounts of data to assist with different inference-making strategies to build and refine frames of information. Designing tools to fit this framework will increase the performance of the AI/ML, the user’s understanding of the technology and outputs, and the efficiency of the sensemaking process.},
booktitle = {Artificial Intelligence in HCI: Second International Conference, AI-HCI 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings},
pages = {185–201},
numpages = {17},
keywords = {Sensemaking, Decision making, Naturalistic decision making, Reasoning, Intelligence analysis, Artificial intelligence}
}

@inproceedings{10.5555/645882.672254,
author = {Mannion, Mike},
title = {Using First-Order Logic for Product Line Model Validation},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Product line models are used to drive the generation of requirements for single systems in the product line. They are difficult to validate because they are large and complex. By modelling variability and dependency between requirements using propositional connectives, a logical expression can be developed for the model. Validation of the selection of requirements from the model can be achieved by satisfying the logical expression. This approach can be used to validate the model as a whole. A detailed worked example is presented, and the computational aspects of the approach are discussed.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {176–187},
numpages = {12},
series = {SPLC 2}
}

@inproceedings{10.1145/3292500.3330848,
author = {Tu, Ke and Ma, Jianxin and Cui, Peng and Pei, Jian and Zhu, Wenwu},
title = {AutoNE: Hyperparameter Optimization for Massive Network Embedding},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330848},
doi = {10.1145/3292500.3330848},
abstract = {Network embedding (NE) aims to embed the nodes of a network into a vector space, and serves as the bridge between machine learning and network data. Despite their widespread success, NE algorithms typically contain a large number of hyperparameters for preserving the various network properties, which must be carefully tuned in order to achieve satisfactory performance. Though automated machine learning (AutoML) has achieved promising results when applied to many types of data such as images and texts, network data poses great challenges to AutoML and remains largely ignored by the literature of AutoML. The biggest obstacle is the massive scale of real-world networks, along with the coupled node relationships that make any straightforward sampling strategy problematic. In this paper, we propose a novel framework, named AutoNE, to automatically optimize the hyperparameters of a NE algorithm on massive networks. In detail, we employ a multi-start random walk strategy to sample several small sub-networks, perform each trial of configuration selection on the sampled sub-network, and design a meta-leaner to transfer the knowledge about optimal hyperparameters from the sub-networks to the original massive network. The transferred meta-knowledge greatly reduces the number of trials required when predicting the optimal hyperparameters for the original network. Extensive experiments demonstrate that our framework can significantly outperform the existing methods, in that it needs less time and fewer trials to find the optimal hyperparameters.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {216–225},
numpages = {10},
keywords = {automated machine learning, hyperparameter optimization, machine learning on graphs, meta-learning, network embedding, network representation learning},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1145/1189769.1189770,
author = {Calders, Toon and Lakshmanan, Laks V. S. and Ng, Raymond T. and Paredaens, Jan},
title = {Expressive power of an algebra for data mining},
year = {2006},
issue_date = {December 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {4},
issn = {0362-5915},
url = {https://doi.org/10.1145/1189769.1189770},
doi = {10.1145/1189769.1189770},
abstract = {The relational data model has simple and clear foundations on which significant theoretical and systems research has flourished. By contrast, most research on data mining has focused on algorithmic issues. A major open question is: what's an appropriate foundation for data mining, which can accommodate disparate mining tasks? We address this problem by presenting a database model and an algebra for data mining. The database model is based on the 3W-model introduced by Johnson et al. [2000]. This model relied on black box mining operators. A main contribution of this article is to open up these black boxes, by using generic operators in a data mining algebra. Two key operators in this algebra are regionize, which creates regions (or models) from data tuples, and a restricted form of looping called mining loop. Then the resulting data mining algebra MA is studied and properties concerning expressive power and complexity are established. We present results in three directions: (1) expressiveness of the mining algebra; (2) relations with alternative frameworks, and (3) interactions between regionize and mining loop.},
journal = {ACM Trans. Database Syst.},
month = dec,
pages = {1169–1214},
numpages = {46},
keywords = {Algebra, data mining, expressive power}
}

@inproceedings{10.1145/3301275.3302265,
author = {Feng, Shi and Boyd-Graber, Jordan},
title = {What can AI do for me? evaluating machine learning interpretations in cooperative play},
year = {2019},
isbn = {9781450362726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301275.3302265},
doi = {10.1145/3301275.3302265},
abstract = {Machine learning is an important tool for decision making, but its ethical and responsible application requires rigorous vetting of its interpretability and utility: an understudied problem, particularly for natural language processing models. We propose an evaluation of interpretation on a real task with real human users, where the effectiveness of interpretation is measured by how much it improves human performance. We design a grounded, realistic human-computer cooperative setting using a question answering task, Quizbowl. We recruit both trivia experts and novices to play this game with computer as their teammate, who communicates its prediction via three different interpretations. We also provide design guidance for natural language processing human-in-the-loop settings.},
booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
pages = {229–239},
numpages = {11},
keywords = {interpretability, natural language processing, question answering},
location = {Marina del Ray, California},
series = {IUI '19}
}

@inproceedings{10.1007/978-3-642-40131-2_13,
author = {Gomes, Jo\~{a}o B\'{a}rtolo and Phua, Clifton and Krishnaswamy, Shonali},
title = {Where Will You Go? Mobile Data Mining for Next Place Prediction},
year = {2013},
isbn = {9783642401305},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-40131-2_13},
doi = {10.1007/978-3-642-40131-2_13},
abstract = {The technological advances in smartphones and their widespread use has resulted in the big volume and varied types of mobile data which we have today. Location prediction through mobile data mining leverages such big data in applications such as traffic planning, location-based advertising, intelligent resource allocation; as well as in recommender services including the popular Apple Siri or Google Now. This paper, focuses on the challenging problem of predicting the next location of a mobile user given data on his or her current location. In this work, we propose  NextLocation  - a personalised mobile data mining framework - that not only uses spatial and temporal data but also other contextual data such as accelerometer, bluetooth and call/sms log. In addition, the proposed framework represents a new paradigm for privacy-preserving next place prediction as the mobile phone data is not shared without user permission. Experiments have been performed using data from the Nokia Mobile Data Challenge MDC. The results on MDC data show large variability in predictive accuracy of about 17% across users. For example, irregular users are very difficult to predict while for more regular users it is possible to achieve more than 80% accuracy. To the best of our knowledge, our approach achieves the highest predictive accuracy when compared with existing results.},
booktitle = {Proceedings of the 15th International Conference on Data Warehousing and Knowledge Discovery - Volume 8057},
pages = {146–158},
numpages = {13},
location = {Prague, Czech Republic},
series = {DaWaK 2013}
}

@article{10.3233/JIFS-189098,
author = {Yigit, Ahmet Talha and Samak, Baris and Kaya, Tolga and Kahraman, Cengiz},
title = {An XGBoost-lasso ensemble modeling approach to football player value assessment},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-189098},
doi = {10.3233/JIFS-189098},
abstract = {Sports analytics is a field that is growing in popularity and application throughout the world. One of the open problems in this field is the valuation of football players. The aim of this study is to establish a football player value assessment model using machine learning techniques to support the transfer decisions of football clubs. The proposed model is mainly based on the intrinsic features of the individual players which are provided in Football Manager simulation game. To do this, based on the individual statistics of 5316 players who are active in 11 different major leagues from Europe and South America, different value assessment models are conducted using advanced supervised learning techniques which include ridge and lasso regressions, random forests and extreme gradient boosting. All the models have been built in R programming language. The performances of the models are compared based on their mean squared errors and their fit to the real world examples. An ensemble model with inflation is proposed as the output.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6303–6314},
numpages = {12},
keywords = {Football analytics, machine learning, ensemble learning, extreme gradient boosting, lasso regression}
}

@inproceedings{10.1145/3437963.3441707,
author = {Zhang, Yuan and Zhang, Xiaoqing and Hu, Yichuan and Wang, Guanchun and Yan, Rui},
title = {WULAI-QA: Web Understanding and Learning with AI towards Document-based Question Answering against COVID-19},
year = {2021},
isbn = {9781450382977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437963.3441707},
doi = {10.1145/3437963.3441707},
abstract = {With the outbreak of COVID-19, it is urgent and necessary to design a system that can access to information from COVID-19 related documents. Current methods fail to do so since the knowledge about COVID-19, an emerging disease, keeps changing and growing. In this study, we design a dynamic document-based question answering system, namely Web Understanding and Learning with AI (WULAI-QA). WULAI-QA employs feature engineering and online learning to adapt to the non-stationary environment and maintains good and steady performance. We evaluate WULAI-QA's performance on a public question answering (https://www.datafountain.cn/competitions/424) and rank first. We demonstrate that WULAI-QA can learn from user feedback and is easy to use. We believe that WULAI-QA will definitely help people understand COVID-19 and play an important role to fight against the pandemic.},
booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
pages = {898–901},
numpages = {4},
keywords = {COVID-19, document retrieval, leader board competition, machine reading comprehension, question answering},
location = {Virtual Event, Israel},
series = {WSDM '21}
}

@article{10.1016/j.adhoc.2021.102591,
author = {Moti, Zahra and Hashemi, Sattar and Karimipour, Hadis and Dehghantanha, Ali and Jahromi, Amir Namavar and Abdi, Lida and Alavi, Fatemeh},
title = {Generative adversarial network to detect unseen Internet of Things malware},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {122},
number = {C},
issn = {1570-8705},
url = {https://doi.org/10.1016/j.adhoc.2021.102591},
doi = {10.1016/j.adhoc.2021.102591},
journal = {Ad Hoc Netw.},
month = nov,
numpages = {13},
keywords = {Malware, Generative Adversarial Network (GAN), Deeplearning, Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), Edge layer, Internet of Things}
}

@inproceedings{10.1145/2425415.2425420,
author = {Eyal-Salman, Hamzeh and Seriai, Abdelhak-Djamel and Dony, Christophe and Al-msie'deen, Ra'fat},
title = {Recovering traceability links between feature models and source code of product variants},
year = {2012},
isbn = {9781450318099},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2425415.2425420},
doi = {10.1145/2425415.2425420},
abstract = {Usually software product variants, developed by clone-and-own approach, form often a starting point for building Software Product Line (SPL). To migrate software products that deemed similar into a product line, it is essential to trace variability among software artifacts because the distinguishing factor between traditional software engineering and software product line engineering is the variability. Variability tracing is used to support conversion from traditional software development into software product line development and automate products derivation process such that core assets can be automatically configured for a product according to the features selection from the feature model. Tracing and maintaining interrelationships between artifacts within a software system also are needed to facilitate program comprehension, make the process of maintaining the system less dependent on individual experts. This paper presents a method based on information retrieval approach namely, latent semantic indexing, to establish traceability links between object-oriented source code of product variants and their feature model as representative of variability model.},
booktitle = {Proceedings of the VARiability for You Workshop: Variability Modeling Made Useful for Everyone},
pages = {21–25},
numpages = {5},
keywords = {feature models, latent semantic indexing, software product line, source code, traceability links, variability},
location = {Innsbruck, Austria},
series = {VARY '12}
}

@article{10.14778/3297753.3297763,
author = {Xin, Doris and Macke, Stephen and Ma, Litian and Liu, Jialin and Song, Shuchen and Parameswaran, Aditya},
title = {HELIX: holistic optimization for accelerating iterative machine learning},
year = {2018},
issue_date = {December 2018},
publisher = {VLDB Endowment},
volume = {12},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3297753.3297763},
doi = {10.14778/3297753.3297763},
abstract = {Machine learning workflow development is a process of trial-and-error: developers iterate on workflows by testing out small modifications until the desired accuracy is achieved. Unfortunately, existing machine learning systems focus narrowly on model training---a small fraction of the overall development time---and neglect to address iterative development. We propose Helix, a machine learning system that optimizes the execution across iterations---intelligently caching and reusing, or recomputing intermediates as appropriate. Helix captures a wide variety of application needs within its Scala DSL, with succinct syntax defining unified processes for data preprocessing, model specification, and learning. We demonstrate that the reuse problem can be cast as a Max-Flow problem, while the caching problem is NP-Hard. We develop effective lightweight heuristics for the latter. Empirical evaluation shows that Helix is not only able to handle a wide variety of use cases in one unified workflow but also much faster, providing run time reductions of up to 19x over state-of-the-art systems, such as DeepDive or KeystoneML, on four real-world applications in natural language processing, computer vision, social and natural sciences.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {446–460},
numpages = {15}
}

@article{10.1016/j.infsof.2009.11.001,
author = {Rabiser, Rick and Gr\"{u}nbacher, Paul and Dhungana, Deepak},
title = {Requirements for product derivation support: Results from a systematic literature review and an expert survey},
year = {2010},
issue_date = {March, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.11.001},
doi = {10.1016/j.infsof.2009.11.001},
abstract = {Context: An increasing number of publications in product line engineering address product derivation, i.e., the process of building products from reusable assets. Despite its importance, there is still no consensus regarding the requirements for product derivation support. Objective: Our aim is to identify and validate requirements for tool-supported product derivation. Method: We identify the requirements through a systematic literature review and validate them with an expert survey. Results: We discuss the resulting requirements and provide implementation examples from existing product derivation approaches. Conclusions: We conclude that key requirements are emerging in the research literature and are also considered relevant by experts in the field.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {324–346},
numpages = {23},
keywords = {Product derivation, Product line engineering, Software product line, Systematic literature review}
}

@article{10.1016/j.artint.2018.12.008,
author = {Wang, Leye and Geng, Xu and Ma, Xiaojuan and Zhang, Daqing and Yang, Qiang},
title = {Ridesharing car detection by transfer learning},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {273},
number = {C},
issn = {0004-3702},
url = {https://doi.org/10.1016/j.artint.2018.12.008},
doi = {10.1016/j.artint.2018.12.008},
journal = {Artif. Intell.},
month = aug,
pages = {1–18},
numpages = {18},
keywords = {Transfer learning, Co-training, Trajectory mining}
}

@inproceedings{10.1109/SEmotion52567.2021.00011,
author = {Cummaudo, Alex and Graetsch, Ulrike Maria and Curumsing, Maheswaree K and Vasa, Rajesh and Barnett, Scott and Grundy, John},
title = {Emotions in Computer Vision Service Q&amp;A},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEmotion52567.2021.00011},
doi = {10.1109/SEmotion52567.2021.00011},
abstract = {Software developers are increasingly using cloud-based services that provide machine learning capabilities to implement ‘intelligent’ features. Studies show that incorporating machine learning into an application increases technical debt, creates data dependencies, and introduces uncertainty due to their non-deterministic behaviour. We know very little about the emotional state of software developers who have to deal with such issues; and the impacts on productivity. This paper presents a preliminary effort to better understand the emotions of developers when experiencing issues with these services with the wider goal of discovering potential service improvements. We conducted a landscape analysis of emotions found in 1,425 Stack Overflow questions about a specific and mature subset of these cloud-based services, namely those that provide computer vision techniques. To speed up the emotion identification process, we trialled an automatic approach using a pre-trained emotion classifier that was specifically trained on Stack Overflow content, EmoTxt, and manually verified its classification results. We found that the identified emotions vary for different types of questions, and a discrepancy exists between automatic and manual emotion analysis due to subjectivity.},
booktitle = {2021 IEEE/ACM Sixth International Workshop on Emotion Awareness in Software Engineering (SEmotion)},
pages = {13–18},
numpages = {6},
location = {Madrid, Spain}
}

@inproceedings{10.5555/1416222.1416243,
author = {Fleischer, Paul and Kristensen, Lars M.},
title = {Modelling the configuration/management API middleware using coloured petri nets},
year = {2008},
isbn = {9789639799202},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {The Configuration/Management Application Programming Interface (CMAPI) is a vendor-specific API and middlewarelayer for configuration and management of components in embedded systems. CMAPI is used by TietoEnator Denmark in the implementation of a controller for the Generic Access Network (GAN) architecture. This paper presents a hierarchical Coloured Petri Net model of CMAPI that was developed in the process of applying Coloured Petri Nets and CPN Tools for the specification of the GAN controller.},
booktitle = {Proceedings of the 1st International Conference on Simulation Tools and Techniques for Communications, Networks and Systems &amp; Workshops},
articleno = {16},
numpages = {9},
keywords = {CPN tools, coloured petri nets, middleware, modelling, software specification},
location = {Marseille, France},
series = {Simutools '08}
}

@inproceedings{10.1007/978-3-030-89188-6_38,
author = {Bu, Chenyang and Lu, Yi and Liu, Fei},
title = {Automatic Graph Learning with Evolutionary Algorithms: An Experimental Study},
year = {2021},
isbn = {978-3-030-89187-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89188-6_38},
doi = {10.1007/978-3-030-89188-6_38},
abstract = {In recent years, automated machine learning (AutoML) has received widespread attention from academia and industry owing to its ability to significantly reduce the threshold and labor cost of machine learning. It has demonstrated its powerful functions in hyperparameter optimization, model selection, neural network search, and feature engineering. Most AutoML frameworks are not specifically designed to process graph data. That is, in most AutoML tools, only traditional neural networks are integrated without using a graph neural network (GNN). Although traditional neural networks have achieved great success, GNNs have more advantages in processing non-Euclidean data (e.g., graph data) and have gained popularity in recent years. However, to the best of our knowledge, there is currently only one open-source AutoML framework for graph learning, i.e., AutoGL. For the AutoGL framework, traditional AutoML optimization algorithms such as grid search, random search, and Bayesian optimization are used to optimize the hyperparameters. Because each type of traditional optimization algorithm has its own advantages and disadvantages, more options are required. This study analyzes the performance of different evolutionary algorithms (EAs) on AutoGL through experiments. The experimental results show that EAs could be an effective alternative to the hyperparameter optimization of GNN.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part I},
pages = {513–526},
numpages = {14},
keywords = {Automatic graph learning, Evolutionary algorithms, AutoML},
location = {Hanoi, Vietnam}
}

@article{10.1007/s11257-018-9203-z,
author = {Gardner, Josh and Brooks, Christopher},
title = {Student success prediction in MOOCs},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0924-1868},
url = {https://doi.org/10.1007/s11257-018-9203-z},
doi = {10.1007/s11257-018-9203-z},
abstract = {Predictive models of student success in Massive Open Online Courses (MOOCs) are a critical component of effective content personalization and adaptive interventions. In this article we review the state of the art in predictive models of student success in MOOCs and present a categorization of MOOC research according to the predictors (features), prediction (outcomes), and underlying theoretical model. We critically survey work across each category, providing data on the raw data source, feature engineering, statistical model, evaluation method, prediction architecture, and other aspects of these experiments. Such a review is particularly useful given the rapid expansion of predictive modeling research in MOOCs since the emergence of major MOOC platforms in 2012. This survey reveals several key methodological gaps, which include extensive filtering of experimental subpopulations, ineffective student model evaluation, and the use of experimental data which would be unavailable for real-world student success prediction and intervention, which is the ultimate goal of such models. Finally, we highlight opportunities for future research, which include temporal modeling, research bridging predictive and explanatory student models, work which contributes to learning theory, and evaluating long-term learner success in MOOCs.},
journal = {User Modeling and User-Adapted Interaction},
month = jun,
pages = {127–203},
numpages = {77},
keywords = {Learning analytics, MOOC, Model evaluation, Predictive modeling}
}

@inproceedings{10.5555/645882.672259,
author = {Deursen, Arie van and Jonge, Merijn de and Kuipers, Tobias},
title = {Feature-Based Product Line Instantiation Using Source-Level Packages},
year = {2002},
isbn = {3540439854},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we discuss the construction of software products from customer-specific feature selections. We address variability management with the Feature Description Language (FDL) to capture variation points of product line architectures. We describe feature packaging, which covers selecting and packaging implementation components according to feature selections using the autobundle tool. Finally, we discuss a generic approach, based on the abstract factory design pattern, to make instantiated (customer-specific) variability accessible in applications.The solutions and techniques presented in this paper are based on our experience with the product line architecture of the commercial documentation generator DocGen.},
booktitle = {Proceedings of the Second International Conference on Software Product Lines},
pages = {217–234},
numpages = {18},
series = {SPLC 2}
}

@inproceedings{10.1145/3394450.3397466,
author = {Sanchez-Stern, Alex and Alhessi, Yousef and Saul, Lawrence and Lerner, Sorin},
title = {Generating correctness proofs with neural networks},
year = {2020},
isbn = {9781450379960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394450.3397466},
doi = {10.1145/3394450.3397466},
abstract = {Foundational verification allows programmers to build software which has been empirically shown to have high levels of assurance in a variety of important domains. However, the cost of producing foundationally verified software remains prohibitively high for most projects, as it requires significant manual effort by highly trained experts. In this paper we present Proverbot9001, a proof search system using machine learning techniques to produce proofs of software correctness in interactive theorem provers. We demonstrate Proverbot9001 on the proof obligations from a large practical proof project, the CompCert verified C compiler, and show that it can effectively automate what were previously manual proofs, automatically producing proofs for 28% of theorem statements in our test dataset, when combined with solver-based tooling. Without any additional solvers, we exhibit a proof completion rate that is a 4X improvement over prior state-of-the-art machine learning models for generating proofs in Coq.},
booktitle = {Proceedings of the 4th ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
pages = {1–10},
numpages = {10},
keywords = {Machine-learning, theorem proving},
location = {London, UK},
series = {MAPL 2020}
}

@article{10.1155/2021/2553199,
author = {Khan, Muhammad Yaseen and Qayoom, Abdul and Nizami, Muhammad Suffian and Siddiqui, Muhammad Shoaib and Wasi, Shaukat and Raazi, Syed Muhammad Khaliq-ur-Rahman and Sarfraz, Shahzad},
title = {Automated Prediction of Good Dictionary EXamples (GDEX): A Comprehensive Experiment with Distant Supervision, Machine Learning, and Word Embedding-Based Deep Learning Techniques},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/2553199},
doi = {10.1155/2021/2553199},
abstract = {Dictionaries not only are the source of getting meanings of the word but also serve the purpose of comprehending the context in which the words are used. For such purpose, we see a small sentence as an example for the very word in comprehensive book-dictionaries and more recently in online dictionaries. The lexicographers perform a very meticulous activity for the elicitation of Good Dictionary EXamples (GDEX)—a sentence that is best fit in a dictionary for the word’s definition. The rules for the elicitation of GDEX are very strenuous and require a lot of time for committing the manual process. In this regard, this paper focuses on two major tasks, i.e., the development of labelled corpora for top 3K English words through the usage of distant supervision approach and devising a state-of-the-art artificial intelligence-based automated procedure for discriminating Good Dictionary EXamples from the bad ones. The proposed methodology involves a suite of five machine learning (ML) and five word embedding-based deep learning (DL) architectures. A thorough analysis of the results shows that GDEX elicitation can be done by both ML and DL models; however, DL-based models show a trivial improvement of 3.5% over the conventional ML models. We find that the random forests with parts-of-speech information and word2vec-based bidirectional LSTM are the most optimal ML and DL combinations for automated GDEX elicitation; on the test set, these models, respectively, secured a balanced accuracy of 73% and 77%.},
journal = {Complex.},
month = jan,
numpages = {18}
}

@inproceedings{10.1145/3448326.3448353,
author = {Hanussek, Marc and Blohm, Matthias and Kintz, Maximilien},
title = {Can AutoML outperform humans? An evaluation on popular OpenML datasets using AutoML Benchmark},
year = {2021},
isbn = {9781450389266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448326.3448353},
doi = {10.1145/3448326.3448353},
abstract = {Abstract: In the last few years, Automated Machine Learning (AutoML) has gained much attention. With that said, the question arises whether AutoML can outperform results achieved by human data scientists. This paper compares four AutoML frameworks on 12 different popular datasets from OpenML; six of them supervised classification tasks and the other six supervised regression ones. Additionally, we consider a real-life dataset from one of our recent projects. The results show that the automated frameworks perform better or equal than the machine learning community in 7 out of 12 OpenML tasks.},
booktitle = {2020 2nd International Conference on Artificial Intelligence, Robotics and Control},
pages = {29–32},
numpages = {4},
keywords = {Index Terms: automl, automl benchmark, machine learning, openml},
location = {Cairo, MN, Egypt},
series = {AIRC'20}
}

@inproceedings{10.1007/978-3-030-85616-8_8,
author = {Islam, Md. Rabiul and Nawa, Shun and Vargo, Andrew and Iwata, Motoi and Matsubara, Masaki and Morishima, Atsuyuki and Kise, Koichi},
title = {Quality Assessment of Crowdwork via Eye Gaze: Towards Adaptive Personalized Crowdsourcing},
year = {2021},
isbn = {978-3-030-85615-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85616-8_8},
doi = {10.1007/978-3-030-85616-8_8},
abstract = {A significant challenge for creating efficient and fair crowdsourcing platforms is in rapid assessment of the quality of crowdwork. If a crowdworker lacks the skill, motivation, or understanding to provide adequate quality task completion, this reduces the efficacy of a platform. While this would seem like only a problem for task providers, the reality is that the burden of this problem is increasingly leveraged on crowdworkers. For example, task providers may not pay crowdworkers for their work after the evaluation of the task results has been completed. In this paper, we propose methods for quickly evaluating the quality of crowdwork using eye gaze information by estimating the correct answer rate. We find that the method with features generated by self-supervised learning&nbsp;(SSL) provides the most efficient result with a mean absolute error of 0.09. The results exhibit the potential of using eye gaze information to facilitate adaptive personalized crowdsourcing platforms.},
booktitle = {Human-Computer Interaction – INTERACT 2021: 18th IFIP TC 13 International Conference, Bari, Italy, August 30 – September 3, 2021, Proceedings, Part II},
pages = {104–113},
numpages = {10},
keywords = {Crowdsourcing, Eye gaze, Self-supervised learning, Machine learning},
location = {Bari, Italy}
}

@inproceedings{10.5555/3432601.3432628,
author = {Wahba, Yasmen and Madhavji, Nazim H. and Steinbacher, John},
title = {Evaluating the effectiveness of static word embeddings on the classification of IT support tickets},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {Support tickets are service requests, initiated by a system's end-users when they encounter issues with their system. With a wide user-base and system issues, there will be an ongoing influx of generated support tickets. Manual classification and prioritization is effortful and error-prone, that can lead to incorrect routing and delays in the resolution of the issues.Recently, various state-of-the-art machine learning and deep learning methods have been applied to automate the process of text classification. Because the quality of these methods highly depends on the quality of the associated "features", in this paper we focus on the "feature engineering" step in the classification process. In particular, we evaluate the effectiveness of using different static word embeddings on the accuracy of classifying IT support tickets.In collaboration with an industrial partner, we were able to train and evaluate our machine learning model on 1.6 million support tickets and 32 ticket categories.The experimental results show that the traditional Term Frequency Inverse Document Frequency (TFIDF) bag-of-words along with Support Vector Machines (SVM) provides competitive results and sometimes outperforms static word embedding models such as word2vec while maintaining low computational cost.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {198–206},
numpages = {9},
keywords = {customer support tickets, feature engineering, machine learning, natural language processing, word embedding},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.5555/1887176.1887194,
author = {Kolya, Anup Kumar and Ekbal, Asif and Bandyopadhyay, Sivaji},
title = {Event-time relation identification using machine learning and rules},
year = {2010},
isbn = {3642157599},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP). In this paper, we report our works on temporal relation identification within the TimeML framework. We worked on TempEval-2007 Task B that involves identification of relations between events and document creation time. Two different systems, one based on machine learning and the other based on handcrafted rules, are developed. The machine learning system is based on Conditional Random Field (CRF) that makes use of only some of the features available in TimeBank corpus in order to infer temporal relations. The second system is developed using a set of manually constructed handcrafted rules. Evaluation results show that the rule-based system performs better compared to the machine learning based system with the precision, recall and F-score values 75.9%, 75.9% and 75.9%, respectively under the strict evaluation scheme and 77.1%, 77.1% and 77.1%, respectively under the relaxed evaluation scheme. In contrast, CRF based system yields precision, recall and F-score values 74.1%, 73.6% and 73.8%, respectively under the strict evaluation scheme and 75.1%, 74.6% and 74.8%, respectively under the relaxed evaluation scheme.},
booktitle = {Proceedings of the 13th International Conference on Text, Speech and Dialogue},
pages = {117–124},
numpages = {8},
keywords = {TempEval-2007 task B, conditional random field, rule-based approach, temporal relation identification},
location = {Brno, Czech Republic},
series = {TSD'10}
}

@article{10.1007/s10618-021-00774-4,
author = {Wang, Lili and Huang, Chenghan and Ma, Weicheng and Liu, Ruibo and Vosoughi, Soroush},
title = {Hyperbolic node embedding for temporal networks},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {35},
number = {5},
issn = {1384-5810},
url = {https://doi.org/10.1007/s10618-021-00774-4},
doi = {10.1007/s10618-021-00774-4},
abstract = {Generating general-purpose vector representations of networks allows us to analyze them without the need for extensive feature-engineering. Recent works have shown that the hyperbolic space can naturally represent the structure of networks, and that embedding networks into hyperbolic space is extremely efficient, especially in low dimensions. However, the existing hyperbolic embedding methods apply to static networks and cannot capture the dynamic evolution of the nodes and edges of a temporal network. In this paper, we present an unsupervised framework that uses temporal random walks to obtain training samples with both temporal and structural information to learn hyperbolic embeddings from continuous-time dynamic networks. We also show how the framework extends to attributed and heterogeneous information networks. Through experiments on five publicly available real-world temporal datasets, we show the efficacy of our model in embedding temporal networks in low-dimensional hyperbolic space compared to several other unsupervised baselines. We show that our model obtains state-of-the-art performance in low dimensions, outperforming all baselines, and has competitive performance in higher dimensions, outperforming the baselines in three of the five datasets. Our results show that embedding temporal networks in hyperbolic space is extremely effective when necessitating low dimensions.},
journal = {Data Min. Knowl. Discov.},
month = sep,
pages = {1906–1940},
numpages = {35},
keywords = {Hyperbolic embedding, Network embedding, Graph embedding, Representation learning, Temporal networks, Unsupervised learning}
}

@article{10.1007/s10462-021-09967-1,
author = {Zhang, Wengang and Li, Hongrui and Li, Yongqin and Liu, Hanlong and Chen, Yumin and Ding, Xuanming},
title = {Application of deep learning algorithms in geotechnical engineering: a short critical review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {8},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-021-09967-1},
doi = {10.1007/s10462-021-09967-1},
abstract = {With the advent of big data era, deep learning (DL) has become an essential research subject in the field of artificial intelligence (AI). DL algorithms are characterized with powerful feature learning and expression capabilities compared with the traditional machine learning (ML) methods, which attracts worldwide researchers from different fields to its increasingly wide applications. Furthermore, in the field of geochnical engineering, DL has been widely adopted in various research topics, a comprehensive review summarizing its application is desirable. Consequently, this study presented the state of practice of DL in geotechnical engineering, and depicted the statistical trend of the published papers. Four major algorithms, including feedforward neural (FNN), recurrent neural network (RNN), convolutional neural network (CNN) and generative adversarial network (GAN) along with their geotechnical applications were elaborated. In addition, a thorough summary containing pubilished literatures, the corresponding reference cases, the adopted DL algorithms as well as the related geotechnical topics was compiled. Furthermore, the challenges and perspectives of future development of DL in geotechnical engineering were presented and discussed.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {5633–5673},
numpages = {41},
keywords = {Deep learning, Geotechnical engineering, Big data, Neural networks}
}

@inproceedings{10.1007/978-3-030-98682-7_12,
author = {Zare, Nader and Sarvmaili, Mahtab and Sayareh, Aref and Amini, Omid and Matwin, Stan and Soares, Amilcar},
title = {Engineering Features to Improve Pass Prediction in Soccer Simulation 2D Games},
year = {2021},
isbn = {978-3-030-98681-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98682-7_12},
doi = {10.1007/978-3-030-98682-7_12},
abstract = {Soccer Simulation 2D (SS2D) is a simulation of a real soccer game in two dimensions. In soccer, passing behavior is an essential action for keeping the ball in possession of our team and creating goal opportunities. Similarly, for SS2D, predicting the passing behaviors of both opponents and our teammates helps manage resources and score more goals. Therefore, in this research, we have tried to address the modeling of passing behavior of soccer 2D players using Deep Neural Networks (DNN) and Random Forest (RF). We propose an embedded data extraction module that can record the decision-making of agents in an online format. Afterward, we apply four data sorting techniques for training data preparation. After, we evaluate the trained models’ performance playing against 6 top teams of RoboCup 2019 that have distinctive playing strategies. Finally, we examine the importance of different feature groups on the prediction of a passing strategy. All results in each step of this work prove our suggested methodology’s effectiveness and improve the performance of the pass prediction in Soccer Simulation 2D games ranging from 5% (e.g., playing against the same team) to 10% (e.g., playing against Robocup top teams).},
booktitle = {RoboCup 2021: Robot World Cup XXIV},
pages = {140–152},
numpages = {13},
keywords = {Feature engineering, Agent systems, Machine learning, Soccer simulation 2D},
location = {Sydney, NSW, Australia}
}

@inproceedings{10.1007/978-3-030-86514-6_6,
author = {Mathew, Jose and Negi, Meghana and Vijjali, Rutvik and Sathyanarayana, Jairaj},
title = {DeFraudNet: An End-to-End Weak Supervision Framework to Detect Fraud in Online Food Delivery},
year = {2021},
isbn = {978-3-030-86513-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86514-6_6},
doi = {10.1007/978-3-030-86514-6_6},
abstract = {Detecting abusive and fraudulent claims is one of the key challenges in online food delivery. This is further aggravated by the fact that it is not practical to do reverse-logistics on food unlike in e-commerce. This makes the already-hard problem of harvesting labels for fraud even harder because we cannot confirm if the claim was legitimate by inspecting the item(s). Using manual effort to analyze transactions to generate labels is often expensive and time-consuming. On the other hand, typically, there is a wealth of ‘noisy’ information about what constitutes fraud, in the form of customer service interactions, weak and hard rules derived from data analytics, business intuition and domain understanding.In this paper, we present a novel end-to-end framework for detecting fraudulent transactions based on large-scale label generation using weak supervision. We directly use Stanford AI Lab’s (SAIL) Snorkel and tree based methods to do manual and automated discovery of labeling functions, to generate weak labels. We follow this up with an auto-encoder reconstruction-error based method to reduce label noise. The final step is a discriminator model which is an ensemble of an MLP and an LSTM. In addition to cross-sectional and longitudinal features around customer history, transactions, we also harvest customer embeddings from a Graph Convolution Network (GCN) on a customer-customer relationship graph, to capture collusive behavior. The final score is thresholded and used in decision making.This solution is currently deployed for real-time serving and has yielded a 16% points’ improvement in recall at a given precision level. These results are against a baseline MLP model based on manually labeled data and are highly significant at our scale. Our approach can easily scale to additional fraud scenarios or to use-cases where ‘strong’ labels are hard to get but weak labels are prevalent.},
booktitle = {Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part IV},
pages = {85–99},
numpages = {15},
keywords = {Automated labelling functions, Snorkel, Class-specific autoencoders, LSTM, Graph Convolution Network},
location = {Bilbao, Spain}
}

@inproceedings{10.1145/3219819.3220025,
author = {Donnat, Claire and Zitnik, Marinka and Hallac, David and Leskovec, Jure},
title = {Learning Structural Node Embeddings via Diffusion Wavelets},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220025},
doi = {10.1145/3219819.3220025},
abstract = {Nodes residing in different parts of a graph can have similar structural roles within their local network topology. The identification of such roles provides key insight into the organization of networks and can be used for a variety of machine learning tasks. However, learning structural representations of nodes is a challenging problem, and it has typically involved manually specifying and tailoring topological features for each node. In this paper, we develop GraphWave, a method that represents each node's network neighborhood via a low-dimensional embedding by leveraging heat wavelet diffusion patterns. Instead of training on hand-selected features, GraphWave learns these embeddings in an unsupervised way. We mathematically prove that nodes with similar network neighborhoods will have similar GraphWave embeddings even though these nodes may reside in very different parts of the network, and our method scales linearly with the number of edges. Experiments in a variety of different settings demonstrate GraphWave's real-world potential for capturing structural roles in networks, and our approach outperforms existing state-of-the-art baselines in every experiment, by as much as 137%.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1320–1329},
numpages = {10},
keywords = {graph signal processing, graphs, node embeddings, representation learning, structural roles, structural similarity, unsupervised learning},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.1007/s11257-019-09234-7,
author = {Azcona, David and Hsiao, I-Han and Smeaton, Alan F.},
title = {Detecting students-at-risk in computer programming classes with learning analytics from students’ digital footprints},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {4},
issn = {0924-1868},
url = {https://doi.org/10.1007/s11257-019-09234-7},
doi = {10.1007/s11257-019-09234-7},
abstract = {Different sources of data about students, ranging from static demographics to dynamic behavior logs, can be harnessed from a variety sources at Higher Education Institutions. Combining these assembles a rich digital footprint for students, which can enable institutions to better understand student behaviour and to better prepare for guiding students towards reaching their academic potential. This paper presents a new research methodology to automatically detect students “at-risk” of failing an assignment in computer programming modules (courses) and to simultaneously support adaptive feedback. By leveraging historical student data, we built predictive models using students’ offline (static) information including student characteristics and demographics, and online (dynamic) resources using programming and behaviour activity logs. Predictions are generated weekly during semester. Overall, the predictive and personalised feedback helped to reduce the gap between the lower and higher-performing students. Furthermore, students praised the prediction and the personalised feedback, conveying strong recommendations for future students to use the system. We also found that students who followed their personalised guidance and recommendations performed better in examinations.},
journal = {User Modeling and User-Adapted Interaction},
month = sep,
pages = {759–788},
numpages = {30},
keywords = {Computer Science Education, Learning analytics, Predictive modelling, Machine learning, Peer learning, Educational data mining}
}

@article{10.14778/3231751.3231770,
author = {Liu, Yu and Zhang, Hantian and Zeng, Luyuan and Wu, Wentao and Zhang, Ce},
title = {MLbench: benchmarking machine learning services against human experts},
year = {2018},
issue_date = {June 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/3231751.3231770},
doi = {10.14778/3231751.3231770},
abstract = {Modern machine learning services and systems are complicated data systems --- the process of designing such systems is an art of compromising between functionality, performance, and quality. Providing different levels of system supports for different functionalities, such as automatic feature engineering, model selection and ensemble, and hyperparameter tuning, could improve the quality, but also introduce additional cost and system complexity. In this paper, we try to facilitate the process of asking the following type of questions: How much will the users lose if we remove the support of functionality x from a machine learning service?Answering this type of questions using existing datasets, such as the UCI datasets, is challenging. The main contribution of this work is a novel dataset, MLBench, harvested from Kaggle competitions. Unlike existing datasets, MLBench contains not only the raw features for a machine learning task, but also those used by the winning teams of Kaggle competitions. The winning features serve as a baseline of best human effort that enables multiple ways to measure the quality of machine learning services that cannot be supported by existing datasets, such as relative ranking on Kaggle and relative accuracy compared with best-effort systems.We then conduct an empirical study using MLBench to understand example machine learning services from Amazon and Microsoft Azure, and showcase how MLBench enables a comparative study revealing the strength and weakness of these existing machine learning services quantitatively and systematically. The full version of this paper can be found at arxiv.org/abs/1707.09562},
journal = {Proc. VLDB Endow.},
month = jun,
pages = {1220–1232},
numpages = {13}
}

