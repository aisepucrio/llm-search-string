@inproceedings{10.1007/978-3-030-90785-3_16,
author = {Wang, Baoping and Wang, Wennan and Zhu, Linkai and Liu, Wenjian},
title = {Research on Cross-Project Software Defect Prediction Based on Machine Learning},
year = {2021},
isbn = {978-3-030-90784-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90785-3_16},
doi = {10.1007/978-3-030-90785-3_16},
abstract = {In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.},
booktitle = {Advances in Web-Based Learning – ICWL 2021: 20th International Conference, ICWL 2021, Macau, China, November 13–14, 2021, Proceedings},
pages = {160–165},
numpages = {6},
keywords = {Metric, Software defect prediction model, Machine learning},
location = {Macau, China}
}

@inproceedings{10.1145/3387940.3391463,
author = {Omri, Safa and Sinz, Carsten},
title = {Deep Learning for Software Defect Prediction: A Survey},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391463},
doi = {10.1145/3387940.3391463},
abstract = {Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {209–214},
numpages = {6},
keywords = {software testing, software quality assurance, software defect prediction, machine learning, deep learning},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3416508.3417114,
author = {Aljamaan, Hamoud and Alazba, Amal},
title = {Software defect prediction using tree-based ensembles},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417114},
doi = {10.1145/3416508.3417114},
abstract = {Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {Bagging, Boosting, Classification, Ensemble Learning, Machine Learning, Prediction, Software Defect},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@inproceedings{10.1145/3474198.3478215,
author = {Du, Xiaozhi and Yue, Hehe and Dong, Honglei},
title = {Software Defect Prediction Method based on Hybrid Sampling},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478215},
doi = {10.1145/3474198.3478215},
abstract = {Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However, the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue, this paper proposes a software defect prediction method based on hybrid sampling, which combines the strategies of over-sampling with under-sampling. For minority class, over-sampling uses k-means to cluster samples, then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class, under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples, whose instance hardness values are lower than the threshold, are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN, SMOTE-Tomek, SMOTE and DBSMOTE, the accuracy of our method is improved by 17.60%, 6.99%, 8.66% and 26.18% on average respectively.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {93},
numpages = {9},
keywords = {Software defect prediction, Hybrid sampling, Data imbalance},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@article{10.3233/KES-210061,
author = {Shatnawi, Raed},
title = {Software fault prediction using machine learning techniques with metric thresholds},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-210061},
doi = {10.3233/KES-210061},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {machine learning, threshold values, software metrics, Fault prediction}
}

@article{10.1007/s00521-020-04960-1,
author = {Wang, Kechao and Liu, Lin and Yuan, Chengjun and Wang, Zhifei},
title = {Software defect prediction model based on LASSO–SVM},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {14},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04960-1},
doi = {10.1007/s00521-020-04960-1},
abstract = {A software defect report is a bug in the software system that developers and users submit to the software defect library during software development and maintenance. Managing a software defect report that is overwhelming is a challenging task. The traditional method is manual identification, which is time-consuming and laborious and delays the repair of important software defects. Based on the above background, the purpose of this paper is to study the software defect prediction (SDP) model based on LASSO–SVM. In this paper, the problem of poor prediction accuracy of most SDP models is proposed. A SDP model combining minimum absolute value compression and selection method and support vector machine algorithm is proposed. Firstly, the feature selection ability of the minimum absolute value compression and selection method is used to reduce the dimension of the original data set, and the data set not related to SDP is removed. Then, the optimal value of SVM is obtained by using the parameter optimization ability of cross-validation algorithm. Finally, the SDP is completed by the nonlinear computing ability of SVM. The accuracy of simulation results is 93.25% and 66.67%, recall rate is 78.04%, and f-metric is 72.72%. The results show that the proposed defect prediction model has higher prediction accuracy than the traditional defect prediction model, and the prediction speed is faster.},
journal = {Neural Comput. Appl.},
month = jul,
pages = {8249–8259},
numpages = {11},
keywords = {Cross-validation, Support vector machine, Feature selection, Software defect prediction}
}

@inproceedings{10.1145/3368926.3369711,
author = {Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming},
title = {Unsupervised methods for Software Defect Prediction},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369711},
doi = {10.1145/3368926.3369711},
abstract = {Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {49–55},
numpages = {7},
keywords = {Unsupervised Learning, Software Engineering, Software Defect Prediction, Machine Learning, Community Structure Detection},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@article{10.1007/s11063-020-10355-z,
author = {Niu, Liang and Wan, Jianwu and Wang, Hongyuan and Zhou, Kaiwei},
title = {Cost-sensitive Dictionary Learning for Software Defect Prediction},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {3},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10355-z},
doi = {10.1007/s11063-020-10355-z},
abstract = {In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments on twenty-five software projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison with ten state-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.},
journal = {Neural Process. Lett.},
month = dec,
pages = {2415–2449},
numpages = {35},
keywords = {Discrimination, Dictionary learning, Cost-sensitive, Software defect prediction}
}

@article{10.1016/j.infsof.2021.106664,
author = {Yao, Jingxiu and Shepperd, Martin},
title = {The impact of using biased performance metrics on software defect prediction research},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106664},
doi = {10.1016/j.infsof.2021.106664},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Classification metrics, Computational experiment, Software defect prediction, Machine learning, Software engineering}
}

@article{10.1007/s11334-021-00399-2,
author = {Suresh Kumar, P. and Behera, H. S. and Nayak, Janmenjoy and Naik, Bighnaraj},
title = {Bootstrap aggregation ensemble learning-based reliable approach for software defect prediction by using characterized code feature},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-021-00399-2},
doi = {10.1007/s11334-021-00399-2},
abstract = {To ensure software quality, software defect prediction plays a prominent role for the software developers and practitioners. Software defect prediction can assist us with distinguishing software defect modules and enhance the software quality. In present days, many supervised machine learning algorithms have proved their efficacy to identify defective modules. However, those are limited to prove their major significance due to the limitations such as the adaptation of parameters with the environment and complexity. So, it is important to develop a key methodology to improve the efficiency of the prediction module. In this paper, an ensemble learning technique called&nbsp;Bootstrap&nbsp;aggregating has been proposed for software defect prediction object-oriented modules. The proposed method's accuracy, recall, precision, F-measure, and AUC-ROC efficiency were compared to those of many qualified machine learning algorithms. Simulation results and performance comparison are evident that the proposed method outperformed well compared to other approaches.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {355–379},
numpages = {25},
keywords = {Machine learning, Software reliability, Software defect prediction, Ensemble learning}
}

@article{10.4018/IJDSST.2020070105,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P. S.},
title = {Nonlinear Geometric Framework for Software Defect Prediction},
year = {2020},
issue_date = {Jul 2020},
publisher = {IGI Global},
address = {USA},
volume = {12},
number = {3},
issn = {1941-6296},
url = {https://doi.org/10.4018/IJDSST.2020070105},
doi = {10.4018/IJDSST.2020070105},
abstract = {Humans use the software in every walk of life thus it is essential to have the best quality software. Software defect prediction models assist in identifying defect prone modules with the help of historical data, which in turn improves software quality. Historical data consists of data related to modules /files/classes which are labeled as buggy or clean. As the number of buggy artifacts as less as compared to clean artifacts, the nature of historical data becomes imbalance. Due to this uneven distribution of the data, it difficult for classification algorithms to build highly effective SDP models. The objective of this study is to propose a new nonlinear geometric framework based on SMOTE and ensemble learning to improve the performance of SDP models. The study combines the traditional SMOTE algorithm and the novel ensemble Support Vector Machine (SVM) is used to develop the proposed framework called SMEnsemble. SMOTE algorithm handles the class imbalance problem by generating synthetic instances of the minority class. Ensemble learning generates multiple classification models to select the best performing SDP model. For experimentation, datasets from three different software repositories that contain both open source as well as proprietary projects are used in the study. The results show that SMEnsemble performs better than traditional methods for identifying the minority class i.e. buggy artifacts. Also, the proposed model performance is better than the latest state of Art SDP model- SMOTUNED. The proposed model is capable of handling imbalance classes when compared with traditional methods. Also, by carefully selecting the number of ensembles high performance can be achieved in less time.},
journal = {Int. J. Decis Support Syst. Technol.},
month = jul,
pages = {85–100},
numpages = {16},
keywords = {Software Defect Prediction, SMOTE, Preprocessing, Imbalanced Data, Ensemble Learning, Data Analytics For Software Engineering, Classification}
}

@inproceedings{10.1007/978-3-030-58817-5_45,
author = {Balogun, Abdullateef O. and Lafenwa-Balogun, Fatimah B. and Mojeed, Hammed A. and Adeyemo, Victor E. and Akande, Oluwatobi N. and Akintola, Abimbola G. and Bajeh, Amos O. and Usman-Hamza, Fatimah E.},
title = {SMOTE-Based Homogeneous Ensemble Methods for Software Defect Prediction},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_45},
doi = {10.1007/978-3-030-58817-5_45},
abstract = {Class imbalance is a prevalent problem in machine learning which affects the prediction performance of classification algorithms. Software Defect Prediction (SDP) is no exception to this latent problem. Solutions such as data sampling and ensemble methods have been proposed to address the class imbalance problem in SDP. This study proposes a combination of Synthetic Minority Oversampling Technique (SMOTE) and homogeneous ensemble (Bagging and Boosting) methods for predicting software defects. The proposed approach was implemented using Decision Tree (DT) and Bayesian Network (BN) as base classifiers on defects datasets acquired from NASA software corpus. The experimental results showed that the proposed approach outperformed other experimental methods. High accuracy of 86.8% and area under operating receiver characteristics curve value of 0.93% achieved by the proposed technique affirmed its ability to differentiate between the defective and non-defective labels without bias.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {615–631},
numpages = {17},
keywords = {Ensemble methods, Data sampling, Class imbalance, Software Defect Prediction},
location = {Cagliari, Italy}
}

@article{10.1016/j.neucom.2019.11.067,
author = {Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
title = {Deep learning based software defect prediction},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {385},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.11.067},
doi = {10.1016/j.neucom.2019.11.067},
journal = {Neurocomput.},
month = apr,
pages = {100–110},
numpages = {11},
keywords = {Robustness evaluation, Software metrics, Software quality, Deep learning, Software defect prediction}
}

@article{10.1049/iet-sen.2019.0149,
author = {Deng, Jiehan and Lu, Lu and Qiu, Shaojian},
title = {Software defect prediction via LSTM},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2019.0149},
doi = {10.1049/iet-sen.2019.0149},
abstract = {Software quality plays an important role in the software lifecycle. Traditional software defect prediction approaches mainly focused on using hand‐crafted features to detect defects. However, like human languages, programming languages contain rich semantic and structural information, and the cause of defective code is closely related to its context. Failing to catch this significant information, the performance of traditional approaches is far from satisfactory. In this study, the authors leveraged a long short‐term memory (LSTM) network to automatically learn the semantic and contextual features from the source code. Specifically, they first extract the program's Abstract Syntax Trees (ASTs), which is made up of AST nodes, and then evaluate what and how much information they can preserve for several node types. They traverse the AST of each file and fed them into the LSTM network to automatically the semantic and contextual features of the program, which is then used to determine whether the file is defective. Experimental results on several opensource projects showed that the proposed LSTM method is superior to the state‐of‐the‐art methods.},
journal = {IET Software},
month = aug,
pages = {443–450},
numpages = {8},
keywords = {word embedding techniques, numerical vectors, open source projects, long short-term memory network, defective code, structural information, human languages, programming languages, machine learning techniques, software defect prediction approaches, software lifecycle, software quality, LSTM, contextual features, semantic features, AST node sequence, program abstract syntax trees, trees (mathematics), recurrent neural nets, software quality, program debugging, program diagnostics, public domain software, learning (artificial intelligence), feature extraction}
}

@inproceedings{10.1007/978-3-030-37352-8_13,
author = {Cui, Mengtian and Huang, Yameng and Luo, Jing},
title = {Software Defect Prediction Model Based on GA-BP Algorithm},
year = {2019},
isbn = {978-3-030-37351-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37352-8_13},
doi = {10.1007/978-3-030-37352-8_13},
abstract = {The novel software defect prediction model based on GA-BP algorithm was proposed in the paper considering the disadvantage of traditional BP (abbreviated for Back Propagation) neural network, which has the problem of easy to fall into local optimization when constructing software defect prediction model, and finally affects the prediction accuracy. Firstly, the optimization ability of GA (abbreviated for Genetic Algorithms) is introduced to optimize the weights and thresholds of Back Propagation neural network. Then the prediction model was constructed based on the GA-BP. Meanwhile the public dataset MDP from NASA was selected and the tool WEKA was used to clean the data and format conversion and as the result, four datasets is available. In the end, experimental results show that the proposed method in the paper is effective for software defect prediction.},
booktitle = {Cyberspace Safety and Security: 11th International Symposium, CSS 2019, Guangzhou, China, December 1–3, 2019, Proceedings, Part II},
pages = {151–161},
numpages = {11},
keywords = {BP neural network, Genetic Algorithms, Machine learning, Software defect prediction},
location = {Guangzhou, China}
}

@article{10.1016/j.jss.2021.111026,
author = {Zhu, Kun and Ying, Shi and Zhang, Nana and Zhu, Dandan},
title = {Software defect prediction based on enhanced metaheuristic feature selection optimization and a hybrid deep neural network},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111026},
doi = {10.1016/j.jss.2021.111026},
journal = {J. Syst. Softw.},
month = oct,
numpages = {25},
keywords = {Kernel extreme learning machine, Convolutional neural network, Whale optimization algorithm, Metaheuristic feature selection, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-59003-1_26,
author = {Galli, Antonio and Moscato, Vincenzo and Sperl\'{\i}, Giancarlo and Santo, Aniello De},
title = {An Explainable Artificial Intelligence Methodology for Hard Disk Fault Prediction},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_26},
doi = {10.1007/978-3-030-59003-1_26},
abstract = {Failure rates of Hard Disk Drives (HDDs) are high and often due to a variety of different conditions. Thus, there is increasing demand for technologies dedicated to anticipating possible causes of failure, so to allow for preventive maintenance operations. In this paper, we propose a framework to predict HDD health status according to a long short-term memory (LSTM) model. We also employ eXplainable Artificial Intelligence (XAI) tools, to provide effective explanations of the model decisions, thus making the final results more useful to human decision-making processes. We extensively evaluate our approach on standard data-sets, proving its feasibility for real world applications.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {403–413},
numpages = {11},
keywords = {HDD maintenance, LSTMs, Explainable AI},
location = {Bratislava, Slovakia}
}

@article{10.1007/s00500-020-05159-1,
author = {Jin, Cong},
title = {Software defect prediction model based on distance metric learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05159-1},
doi = {10.1007/s00500-020-05159-1},
abstract = {Software defect prediction (SDP) is a very important way for analyzing software quality and reducing development costs. The data during software lifecycle can be used to predict software defect. Currently, many SDP models have been proposed; however, their performance was not always ideal. In many existing prediction models based on machine learning, the distance metric between samples has significant impact on the performance of the SDP model. In addition, most samples are usually class imbalanced. To solve these issues, in this paper, a novel distance metric learning based on cost-sensitive learning (CSL) is proposed for reducing the impact of class imbalance of samples, which is then applied to the large margin distribution machine (LDM) to substitute the traditional kernel function. Further, the improvement and optimization of LDM based on CSL are also studied, and the improved LDM is used as the SDP model, called as CS-ILDM. Subsequently, the proposed CS-ILDM is applied to five publicly available data sets from the NASA Metrics Data Program repository and its performance is compared to other existing SDP models. The experimental results confirm that the proposed CS-ILDM not only has good prediction performance, but also can reduce the misprediction cost and avoid the impact of class imbalance of samples.},
journal = {Soft Comput.},
month = jan,
pages = {447–461},
numpages = {15},
keywords = {Class imbalance of samples, Misprediction cost, Cost-sensitive learning, Distance metric learning, Software attributes, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-79463-7_43,
author = {Lorentz, Joe and Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and Aouada, Djamila},
title = {Explaining Defect Detection with&nbsp;Saliency Maps},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_43},
doi = {10.1007/978-3-030-79463-7_43},
abstract = {The rising quality and throughput demands of the manufacturing domain require flexible, accurate and explainable computer-vision solutions for defect detection. Deep Neural Networks (DNNs) reach state-of-the-art performance on various computer-vision tasks but wide-spread application in the industrial domain is blocked by the lacking explainability of DNN decisions. A promising, human-readable solution is given by saliency maps, heatmaps highlighting the image areas that influence the classifier’s decision. This work evaluates a selection of saliency methods in the area of industrial quality assurance. To this end we propose the distance pointing game, a new metric to quantify the meaningfulness of saliency maps for defect detection. We provide steps to prepare a publicly available dataset on defective steel plates for the proposed metric. Additionally, the computational complexity is investigated to determine which methods could be integrated on industrial edge devices. Our results show that DeepLift, GradCAM and GradCAM++ outperform the alternatives while the computational cost is feasible for real time applications even on edge devices. This indicates that the respective methods could be used as an additional, autonomous post-classification step to explain decisions taken by intelligent quality assurance systems.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {506–518},
numpages = {13},
keywords = {Edge AI, Defect detection, Saliency, XAI},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3352411.3352412,
author = {Li, Ran and Zhou, Lijuan and Zhang, Shudong and Liu, Hui and Huang, Xiangyang and Sun, Zhong},
title = {Software Defect Prediction Based on Ensemble Learning},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352412},
doi = {10.1145/3352411.3352412},
abstract = {Software defect prediction is one of the important ways to guarantee the quality of software systems. Combining various algorithms in machine learning to predict software defects has become a hot topic in the current study. The paper uses the datasets of MDP as the experimental research objects and takes ensemble learning as research focus to construct software defect prediction model. With experimenting five different types of ensemble algorithms and analyzing the features and procedures, this paper discusses the best ensemble algorithm which is Random Forest through experimental comparison. Then we utilize the SMOTE over-sampling and Resample methods to improve the quality of datasets to build a complete new software defect prediction model. Therefore, the results show that the model can improve defect classification performance effectively.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {1–6},
numpages = {6},
keywords = {Under-sampling, Software defect prediction, Over-sampling, Ensemble algorithm},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@article{10.1155/2021/5553470,
author = {Xue, Bin and Wu, Zhisheng and Wu, Wenqing},
title = {Key Technologies of Steel Plate Surface Defect Detection System Based on Artificial Intelligence Machine Vision},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5553470},
doi = {10.1155/2021/5553470},
abstract = {With the rapid development of visual inspection technology, computer technology, and image processing technology, machine vision technology has become more and more mature, and the role of quality inspection and control in the steel industry is becoming more and more obvious and important. Defects on the surface of the strip are a key factor affecting the quality inspection process. Its inspection plays an extremely important role in improving the final quality. For a long time, traditional manual inspection methods cannot meet actual production needs, so in-depth research on steel surface defect inspection systems has become the consensus of today’s steel companies. The accuracy and low performance of traditional detection methods can no longer meet the needs of people and society. The surface defect detection method based on machine vision has the characteristics of high accuracy, fast processing speed, and intelligent processing, which is the main trend of surface defect detection. We select a steel plate; take the invariant moment features of the cracks, holes, scratches, oil stains, and other images on it; extract the data results; and analyze them. Then, we read the texture features of these defect images again, extract the data results, and analyze them. The experimental results prove that after the mean value filter and Gaussian filter process the image, the mean variance value MSE is relatively large (46.276&gt;31.2271), and as the concentration of salt and pepper noise increases, the rate of increase of MSE increases obviously, and as the peak signal-to-noise ratio and the mean variance value MSE increase continuously (32.2271&lt;33.3695), the image distortion is more serious. The method designed in this paper is extremely effective. Improving the surface quality of steel is of great significance to improving market competitiveness.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/3489849.3489948,
author = {Lebiedz, Jacek and Wiszniewski, Bogdan},
title = {CAVE applications: from craft manufacturing to product line engineering},
year = {2021},
isbn = {9781450390927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489849.3489948},
doi = {10.1145/3489849.3489948},
abstract = {Product line engineering model is suitable for engineering related software products in an efficient manner, taking advantage of their similarities while managing their differences. Our feature driven software product line (SPL) solution based on that model allows for instantiation of different CAVE products based on the set of core assets and driven by a set of common VR features with the minimal budget and time to market.},
booktitle = {Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology},
articleno = {57},
numpages = {2},
keywords = {production stations, core assets, VR application features},
location = {Osaka, Japan},
series = {VRST '21}
}

@article{10.1016/j.neucom.2019.05.100,
author = {Huo, Xuan and Li, Ming},
title = {On cost-effective software defect prediction: Classification or ranking?},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {363},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.05.100},
doi = {10.1016/j.neucom.2019.05.100},
journal = {Neurocomput.},
month = oct,
pages = {339–350},
numpages = {12},
keywords = {Classification model, Ranking model, Software defect prediction, Software mining}
}

@inproceedings{10.1109/ASE.2019.00071,
author = {Gong, Lina and Jiang, Shujuan and Wang, Rongcun and Jiang, Li},
title = {Empirical evaluation of the impact of class overlap on software defect prediction},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00071},
doi = {10.1109/ASE.2019.00071},
abstract = {Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {698–709},
numpages = {12},
keywords = {software defect prediction, machine learning, class overlap, K-Means clustering},
location = {San Diego, California},
series = {ASE '19}
}

@article{10.1007/s11219-016-9353-3,
author = {Bowes, David and Hall, Tracy and Petri\'{c}, Jean},
title = {Software defect prediction: do different classifiers find the same defects?},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9353-3},
doi = {10.1007/s11219-016-9353-3},
abstract = {During the last 10 years, hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80% recall. We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers. We perform a sensitivity analysis to compare the performance of Random Forest, Na\"{\i}ve Bayes, RPart and SVM classifiers when predicting defects in NASA, open source and commercial datasets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty of each classifier is compared. Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others. Our results confirm that a unique subset of defects can be detected by specific classifiers. However, while some classifiers are consistent in the predictions they make, other classifiers vary in their predictions. Given our results, we conclude that classifier ensembles with decision-making strategies not based on majority voting are likely to perform best in defect prediction.},
journal = {Software Quality Journal},
month = jun,
pages = {525–552},
numpages = {28},
keywords = {Software defect prediction, Prediction modelling, Machine learning}
}

@article{10.1007/s10515-021-00289-8,
author = {Ali, Aftab and Khan, Naveed and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and McChesney, Ian},
title = {Discriminating features-based cost-sensitive approach for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00289-8},
doi = {10.1007/s10515-021-00289-8},
abstract = {Correlated quality metrics extracted from a source code repository can be utilized to design a model to automatically predict defects in a software system. It is obvious that the extracted metrics will result in a highly unbalanced data, since the number of defects in a good quality software system should be far less than the number of normal instances. It is also a fact that the selection of the best discriminating features significantly improves the robustness and accuracy of a prediction model. Therefore, the contribution of this paper is twofold, first it selects the best discriminating features that help in accurately predicting a defect in a software component. Secondly, a cost-sensitive logistic regression and decision tree ensemble-based prediction models are applied to the best discriminating features for precisely predicting a defect in a software component. The proposed models are compared with the most recent schemes in the literature in terms of accuracy, area under the curve, and recall. The models are evaluated using 11 datasets and it is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
journal = {Automated Software Engg.},
month = nov,
numpages = {18},
keywords = {Recall, AUC, Cost-sensitivity, Discriminating features, Machine learning models, Software bugs/defects}
}

@inproceedings{10.1007/978-3-030-62463-7_33,
author = {Lei, Tianwei and Xue, Jingfeng and Han, Weijie},
title = {Cross-Project Software Defect Prediction Based on Feature Selection and Transfer Learning},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62463-7_33},
doi = {10.1007/978-3-030-62463-7_33},
abstract = {Cross-project software defect prediction solves the problem that traditional defect prediction can’t get enough data, but how to apply the model learned from the data of different mechanisms to the target data set is a new problem. At the same time, there is the problem that information redundancy in the training process leads to low accuracy. Based on the difference of projects, this paper uses MIC to filter features to solve the problem of information redundancy. At the same time, combined with the TrAdaboost algorithm, which is based on the idea of aggravating multiple classification error samples, this paper proposes a cross-project software prediction method based on feature selection and migration learning. Experimental results show that the algorithm proposed in this paper has better experimental results on AUC and F1.},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {363–371},
numpages = {9},
keywords = {Cross-project software defect prediction, MIC, TrAdaboost, Transfer learning},
location = {Guangzhou, China}
}

@article{10.1002/smr.2362,
author = {Guo, Shikai and Dong, Jian and Li, Hui and Wang, Jiahui},
title = {Software defect prediction with imbalanced distribution by radius‐synthetic minority over‐sampling technique},
year = {2021},
issue_date = {July 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2362},
doi = {10.1002/smr.2362},
abstract = {Software defect prediction, which can identify the defect‐prone modules, is an effective technology to ensure the quality of software products. Due to the importance in software maintenance, many learning‐based software defect prediction models are presented in recent years. Actually, the defects usually occupy a very small proportions in software source codes; thus, the imbalanced distributions between defect‐prone modules and non‐defect‐prone modules increase the learning difficulty of the classification task. To address this issue, we present a random over‐sampling mechanism used to generate minority‐class samples from high‐dimensional sampling space to deal with the imbalanced distributions in software defect prediction, in which two constraints are applied to provide a robust way to generate new synthetic samples, that is, scaling the random over‐sampling scope to a reasonable area and distinguishing the majority‐class samples in a critical region. Based on nine open datasets of software projects, we experimentally verify that our presented method is effective on predict the defect‐prone modules, and the effect is superior to the traditional imbalanced processing methods.},
journal = {J. Softw. Evol. Process},
month = jul,
numpages = {21},
keywords = {software quality, software defect prediction, imbalanced learning}
}

@article{10.1016/j.eswa.2021.114637,
author = {Jin, Cong},
title = {Cross-project software defect prediction based on domain adaptation learning and optimization},
year = {2021},
issue_date = {Jun 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114637},
doi = {10.1016/j.eswa.2021.114637},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Improved quantum particle swarm optimization, Cross-project defect prediction, Domain adaptation, Optimization, Software defect prediction}
}

@phdthesis{10.5555/AAI28389525,
author = {Rahman, Ashiqur},
advisor = {R, Cordy, James},
title = {Software Defect Prediction Using Rich Contextualized Language Use Vectors},
year = {2020},
isbn = {9798708779250},
publisher = {Queen's University (Canada)},
abstract = {Context. Software defect prediction aims to find defect prone source code, and thus reduce the effort, time and cost involved with ensuring the quality of software systems. Both code and non-code metrics are commonly used in this process to train machine learning algorithms to predict software defects. Studies have shown that such metrics-based approaches are failing to give satisfactory results, and have reached a performance ceiling. This thesis explores the idea of using code profiles as an alternative to traditional metrics to predict software defects. This code profile-based method proves to be more promising than traditional metrics-based approaches.Aims. This thesis aims to improve software defect prediction using code profiles as feature variables in place of traditional metrics. Software code profiles encode the density of language feature use and the context of such use in Rich Contextualized Language Use Vectors (RCLUVs) by analysing the parse tree of the source code. This thesis explores whether code profiles can be used to train machine learning algorithms, and compares the performance of the derived models to traditional metrics-based approaches.Methods. To achieve these aims the learning curves of several machine learning algorithms are analyzed, and the performance of the derived models are evaluated against traditional metrics-based approaches. Two benchmark bug datasets, the Eclipse bug dataset and the Github bug database, are used to train the models.Results. The learning curves of the models show machine learning algorithms can learn from RCLUV-based code profiles. Performance evaluation against existing metrics-based approaches reveals that the code profile-based approach is more promising than traditional metrics-based approaches. However, the predictive performance of both metrics and code profile-based approaches drops in cross-version predictions.Conclusions. Unlike traditional metrics-based approaches, this thesis uses vectors generated by analyzing language feature use from the parse trees of source code as feature variables to train machine learning algorithms. Experimental results using learning algorithms encourages us to use software code profiles as an alternative to traditional metrics to predict software defects.},
note = {AAI28389525}
}

@inproceedings{10.1007/978-3-030-86472-9_28,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy},
title = {Feature Selection and Software Defect Prediction by Different Ensemble Classifiers},
year = {2021},
isbn = {978-3-030-86471-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86472-9_28},
doi = {10.1007/978-3-030-86472-9_28},
abstract = {Software defect prediction can improve its quality and is actively studied during the last decade. This paper focuses on the improvement of software defect prediction accuracy by proper feature selection techniques and using ensemble classifier. The software code metrics were used to predict the defective modules. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. Boruta, ACE, regsubsets and simple correlation are used for feature selection. The results of selection are formed based on hard voting of all features selectors. A new stacking classifier for software defects prediction is presented in this paper. The stacking classifier for defects prediction algorithm is based on combination of 5 weak classifiers. Random forest algorithm is used to combine the predictions. The obtained prediction accuracy was up to 96.26%.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part I},
pages = {307–313},
numpages = {7},
keywords = {Ensemble of classifiers, Feature selection, Software defect analysis}
}

@article{10.1016/j.infsof.2021.106662,
author = {Feng, Shuo and Keung, Jacky and Yu, Xiao and Xiao, Yan and Zhang, Miao},
title = {Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106662},
doi = {10.1016/j.infsof.2021.106662},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Empirical Software Engineering, SMOTE, Oversampling, Class imbalance, Software defect prediction}
}

@article{10.1007/s10586-018-1730-1,
author = {Jayanthi, R. and Florence, Lilly},
title = {Software defect prediction techniques using metrics based on neural network classifier},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1730-1},
doi = {10.1007/s10586-018-1730-1},
abstract = {Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction.},
journal = {Cluster Computing},
month = jan,
pages = {77–88},
numpages = {12},
keywords = {Software metrics, Software defect prediction, Machine learning techniques, Defect prediction models}
}

@inproceedings{10.1145/3336294.3336321,
author = {Ghofrani, Javad and Kozegar, Ehsan and Fehlhaber, Anna Lena and Soorati, Mohammad Divband},
title = {Applying Product Line Engineering Concepts to Deep Neural Networks},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336321},
doi = {10.1145/3336294.3336321},
abstract = {Deep Neural Networks (DNNs) are increasingly being used as a machine learning solution thanks to the complexity of their architecture and hyperparameters-weights. A drawback is the excessive demand for massive computational power during the training process. Not only as a whole but parts of neural networks can also be in charge of certain functionalities. We present a novel challenge in an intersection between machine learning and variability management communities to reuse modules of DNNs without further training. Let us assume that we are given a DNN for image processing that recognizes cats and dogs. By extracting a part of the network, without additional training a new DNN should be divisible with the functionality of recognizing only cats. Existing research in variability management can offer a foundation for a product line of DNNs composing the reusable functionalities. An ideal solution can be evaluated based on its speed, granularity of determined functionalities, and the support for adding variability to the network. The challenge is decomposed in three subchallenges: feature extraction, feature abstraction, and the implementation of a product line of DNNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {72–77},
numpages = {6},
keywords = {variability, transfer learning, software product lines, machine learning, deep neural networks},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s11277-017-5117-z,
author = {Zhou, Lijuan and Li, Ran and Zhang, Shudong and Wang, Hua},
title = {Imbalanced Data Processing Model for Software Defect Prediction},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5117-z},
doi = {10.1007/s11277-017-5117-z},
abstract = {In the field of software engineering, software defect prediction is the hotspot of the researches which can effectively guarantee the quality during software development. However, the problem of class imbalanced datasets will affect the accuracy of overall classification of software defect prediction, which is the key issue to be solved urgently today. In order to better solve this problem, this paper proposes a model named ASRA which combines attribute selection, sampling technologies and ensemble algorithm. The model adopts the Chi square test of attribute selection and then utilizes the combined sampling technique which includes SMOTE over-sampling and under-sampling to remove the redundant attributes and make the datasets balance. Afterwards, the model ASRA is eventually established by ensemble algorithm named Adaboost with basic classifier J48 decision tree. The data used in the experiments comes from UCI datasets. It can draw the conclusion that the effect of software defect prediction classification which using this model is improved and better than before by comparing the precision P, F-measure and AUC values from the results of the experiments.},
journal = {Wirel. Pers. Commun.},
month = sep,
pages = {937–950},
numpages = {14},
keywords = {Software defect prediction, Sampling, Ensemble algorithm, Class imbalance, Attribute selection}
}

@inproceedings{10.1007/978-3-030-92273-3_53,
author = {Lang, Jiulin and Tang, Chenwei and Gao, Yi and Lv, Jiancheng},
title = {Knowledge Distillation Method for&nbsp;Surface Defect Detection},
year = {2021},
isbn = {978-3-030-92272-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-92273-3_53},
doi = {10.1007/978-3-030-92273-3_53},
abstract = {In this paper, we propose a multi-scale attention mechanism-guided knowledge distillation method for surface defect detection. Enables a lighter student model to mimic the complex teacher model through the use of knowledge distillation techniques, the proposed method improves the defect detection accuracy and maintains high real-time performance, simultaneously. Specifically, we first present a multi-scale fusion-based teacher network. Owing to the fusion of two resolution scales features, the teacher network can keep high compatibility with the low-resolution student network during knowledge distillation, so as to better direct the student model. Then, in the process of knowledge distillation, attentional mechanisms were introduced with the aim of enabling the student network to more effectively mimic the foreground attention map and features of the teacher network. Finally, in order to address the imbalance of foreground and background in defect detection, we introduce a class-weighted cross entropy loss. Experiments conducted on three benchmark datasets proved the validity and efficiency of the proposed method in surface defect detection.},
booktitle = {Neural Information Processing: 28th International Conference, ICONIP 2021, Sanur, Bali, Indonesia, December 8–12, 2021, Proceedings, Part IV},
pages = {644–655},
numpages = {12},
keywords = {Attention mechanism, Multi-scale fusion, Knowledge distillation, Surface defect detection},
location = {Sanur, Bali, Indonesia}
}

@inproceedings{10.1007/978-3-030-87986-0_15,
author = {Nagaraj, Deepak and Vadiraja, Pramod and Nalbach, Oliver and Werth, Dirk},
title = {Convolutional Autoencoder Based Textile Defect Detection Under Unconstrained Setting},
year = {2021},
isbn = {978-3-030-87985-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87986-0_15},
doi = {10.1007/978-3-030-87986-0_15},
abstract = {Automated visual defect detection on textile products under unconstrained setting is a much sought-after, and at the same time a challenging problem. In general, textile products are structurally complex and highly varied in design, which makes the development of a generalized approach using conventional image processing methods impossible. Deep supervised machine learning models have been very successful on similar problems but cannot be applied in this use-case due to lack of annotated data. This paper demonstrates a novel automated approach which still leverages on the ability of deep learning models to capture complex features on the textured and colored fabric, but in an unsupervised manner. Specifically, deep autoencoders are applied to capture the complex features, which are further processed by image processing techniques like thresholding and blob detection, subsequently leading to detection of defects in the images.},
booktitle = {Artificial Intelligence and Soft Computing: 20th International Conference, ICAISC 2021, Virtual Event, June 21–23, 2021, Proceedings, Part I},
pages = {168–181},
numpages = {14},
keywords = {Autoencoder, Dimensionality reduction, Unsupervised learning, Fabric defect detection}
}

@article{10.1155/2021/2323100,
author = {Liu, Wenjian and Wang, Baoping and Wang, Wennan and Ni, Tongguang},
title = {Deep Learning Software Defect Prediction Methods for Cloud Environments Research},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2323100},
doi = {10.1155/2021/2323100},
abstract = {This paper provides an in-depth study and analysis of software defect prediction methods in a cloud environment and uses a deep learning approach to justify software prediction. A cost penalty term is added to the supervised part of the deep ladder network; that is, the misclassification cost of different classes is added to the model. A cost-sensitive deep ladder network-based software defect prediction model is proposed, which effectively mitigates the negative impact of the class imbalance problem on defect prediction. To address the problem of lack or insufficiency of historical data from the same project, a flow learning-based geodesic cross-project software defect prediction method is proposed. Drawing on data information from other projects, a migration learning approach was used to embed the source and target datasets into a Gaussian manifold. The kernel encapsulates the incremental changes between the differences and commonalities between the two domains. To this point, the subspace is the space of two distributional approximations formed by the source and target data transformations, with traditional in-project software defect classifiers used to predict labels. It is found that real-time defect prediction is more practical because it has a smaller amount of code to review; only individual changes need to be reviewed rather than entire files or packages while making it easier for developers to assign fixes to defects. More importantly, this paper combines deep belief network techniques with real-time defect prediction at a fine-grained level and TCA techniques to deal with data imbalance and proposes an improved deep belief network approach for real-time defect prediction, while trying to change the machine learning classifier underlying DBN for different experimental studies, and the results not only validate the effectiveness of using TCA techniques to solve the data imbalance problem but also show that the defect prediction model learned by the improved method in this paper has better prediction performance.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@inproceedings{10.1145/3474124.3474127,
author = {Rajnish, Kumar and Bhattacharjee, Vandana and Chandrabanshi, Vishnu},
title = {Applying Cognitive and Neural Network Approach over Control Flow Graph for Software Defect Prediction},
year = {2021},
isbn = {9781450389204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474124.3474127},
doi = {10.1145/3474124.3474127},
booktitle = {Proceedings of the 2021 Thirteenth International Conference on Contemporary Computing},
pages = {13–17},
numpages = {5},
keywords = {Software Defect Prediction, Neural Network, Graph Convolutional Network, Cognitive Measures, Cognitive Complexity, CFGs},
location = {Noida, India},
series = {IC3-2021}
}

@article{10.1504/ijwmc.2021.120013,
author = {Li, Gongfa and Liu, Xin and Tao, Bo and Jiang, Du and Zeng, Fei and Xu, Shuang},
title = {Research on ceramic tile defect detection based on YOLOv3},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/ijwmc.2021.120013},
doi = {10.1504/ijwmc.2021.120013},
abstract = {Artificial intelligence is a technology that studies, simulates and expands human intelligence theory and related methods, it is the direction of modern and future science and technology development. The teaching methods of artificial intelligence courses are supposed to be different from the traditional teaching methods, but the actual investigation finds that there are still some problems in the artificial intelligence course, such as the single teaching mode, the low enthusiasm of students for studying, and the poor practical ability of students. In order to solve these issues, this paper applies project teaching methods to an artificial intelligence course, through a specific tile defect detection project to analyse. YOLOv3 algorithm is used to detect six kinds of tile defects, and the experimental results are analysed.},
journal = {Int. J. Wire. Mob. Comput.},
month = jan,
pages = {128–133},
numpages = {5},
keywords = {project-based teaching, YOLOv3 algorithm, artificial intelligence, defect detection}
}

@article{10.1016/j.neucom.2021.05.043,
author = {Harzevili, Nima Shiri and Alizadeh, Sasan H.},
title = {Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {460},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.05.043},
doi = {10.1016/j.neucom.2021.05.043},
journal = {Neurocomput.},
month = oct,
pages = {309–330},
numpages = {22},
keywords = {99–00, 00–01, Latent variable, Naive Bayes classifier, Software defect prediction Software metrics}
}

@inproceedings{10.1007/978-3-030-34885-4_27,
author = {Ali, Aftab and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and Lin, Zhiwei and McChesney, Ian},
title = {Contributing Features-Based Schemes for Software Defect Prediction},
year = {2019},
isbn = {978-3-030-34884-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-34885-4_27},
doi = {10.1007/978-3-030-34885-4_27},
abstract = {Automated defect prediction of large and complex software systems is a challenging task. However, by utilising correlated quality metrics, a defect prediction model can be devised to automatically predict the defects in a software system. The robustness and accuracy of a prediction model is highly dependent on the selection of contributing and non-contributing features. Hence, in this regard, the contribution of this paper is twofold, first it separates those features which are contributing towards the development of a defect in a software component from those which are non-contributing features. Secondly, a logistic regression and Ensemble Bagged Trees-based prediction model are applied on the contributing features for accurately predicting a defect in a software component. The proposed models are compared with the most recent scheme in the literature in terms of accuracy and area under the curve (AUC). It is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
booktitle = {Artificial Intelligence XXXVI: 39th SGAI International Conference on Artificial Intelligence, AI 2019, Cambridge, UK, December 17–19, 2019, Proceedings},
pages = {350–361},
numpages = {12},
keywords = {Prediction models, Intelligent information retrieval, Machine learning},
location = {Cambridge, United Kingdom}
}

@inproceedings{10.1007/978-3-030-64243-3_30,
author = {Sun, Yi and Cai, Yuexiao and Li, Yang and Zhao, Yunlong},
title = {Defect Detection of Production Surface Based on CNN},
year = {2020},
isbn = {978-3-030-64242-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64243-3_30},
doi = {10.1007/978-3-030-64243-3_30},
abstract = {With the continuous development of artificial intelligence, great progress has been made in the field of object detection. Defect detection is a branch of the field of object detection, as long as the purpose is to locate and classify defects on the surface of objects to help people further analyze product quality. In large-scale manufacturing, the demand for product surface defect detection has always been strong, and companies hope to reduce costs, while improving detection accuracy. This paper mainly proposes a method that is biased towards the detection of surface defects on smooth products, solving the problems including difficulty on detecting small scratches and imbalance between positive and negative samples. Finally, we achieve good results through the detector.},
booktitle = {Green, Pervasive, and Cloud Computing: 15th International Conference, GPC 2020, Xi'an, China, November 13–15, 2020, Proceedings},
pages = {405–412},
numpages = {8},
keywords = {Deep learning, Defect detection, Object detection},
location = {Xi'an, China}
}

@inproceedings{10.1007/978-3-030-58802-1_25,
author = {Ronchieri, Elisabetta and Canaparo, Marco and Belgiovine, Mauro},
title = {Software Defect Prediction on Unlabelled Datasets: A Comparative Study},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_25},
doi = {10.1007/978-3-030-58802-1_25},
abstract = {Background: Defect prediction on unlabelled datasets is a challenging and widespread problem in software engineering. Machine learning is of great value in this context because it provides techniques - called unsupervised - that are applicable to unlabelled datasets. Objective: This study aims at comparing various approaches employed over the years on unlabelled datasets to predict the defective modules, i.e. the ones which need more attention in the testing phase. Our comparison is based on the measurement of performance metrics and on the real defective information derived from software archives. Our work leverages a new dataset that has been obtained by extracting and preprocessing its metrics from a C++ software. Method: Our empirical study has taken advantage of CLAMI with its improvement CLAMI+ that we have applied on high energy physics software datasets. Furthermore, we have used clustering techniques such as the K-means algorithm to find potentially critical modules. Results: Our experimental analysis have been carried out on 1 open source project with 34 software releases. We have applied 17 ML techniques to the labelled datasets obtained by following the CLAMI and CLAMI+ approaches. The two approaches have been evaluated by using different performance metrics, our results show that CLAMI+ performs better than CLAMI. The predictive average accuracy metric is around 95% for 4 ML techniques (4 out of 17) that show a Kappa statistic greater than 0.80. We applied K-means on the same dataset and obtained 2 clusters labelled according to the output of CLAMI and CLAMI+. Conclusion: Based on the results of the different statistical tests, we conclude that no significant performance differences have been found in the selected classification techniques.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {333–353},
numpages = {21},
keywords = {Machine learning, Unsupervised methods, Defect prediction, Unlabelled dataset},
location = {Cagliari, Italy}
}

@article{10.3103/S1060992X21030024,
author = {Biradar, Maheshwari S. and Shiparamatti, B. G. and Patil, P. M.},
title = {Fabric Defect Detection Using Deep Convolutional Neural Network},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {3},
issn = {1060-992X},
url = {https://doi.org/10.3103/S1060992X21030024},
doi = {10.3103/S1060992X21030024},
journal = {Opt. Mem. Neural Netw.},
month = jul,
pages = {250–256},
numpages = {7},
keywords = {non-patterned fabric, patterned fabric, Deep Convolutional Neural Network, fabric defect detection}
}

@inproceedings{10.1145/3374549.3374553,
author = {Zong, Liang},
title = {Classification Based Software Defect Prediction Model for Finance Software System - An Industry Study},
year = {2020},
isbn = {9781450376495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374549.3374553},
doi = {10.1145/3374549.3374553},
abstract = {Automated software defect prediction is an important and fundamental activity in the domain of software development. Successful software defect prediction can save testing effort thus reduce the time and cost for software development. However, software systems for finance company are inherently large and complex with numerous interfaces with other systems. Thus, identifying and selecting a good model and a set of features is important but challenging problem. In our paper, we first define the problem we want to solve. Then we propose a prediction model based on binary classification and a set of novel features, which is more specific for finance software systems. We collected 15 months real production data and labelled it as our dataset. The experiment shows our model and features can give a better prediction accuracy for finance systems. In addition, we demonstrate how our prediction model helps improve our production quality further. Unlike other research papers, our proposal focuses to solve problem in real finance industry.},
booktitle = {Proceedings of the 2019 3rd International Conference on Software and E-Business},
pages = {60–65},
numpages = {6},
keywords = {Software defect prediction, Machine learning, Finance system, Faulty change},
location = {Tokyo, Japan},
series = {ICSEB '19}
}

@book{10.5555/3175829,
author = {Rashid, Ekbal and Rashid, Ekbal},
title = {Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities},
year = {2017},
isbn = {1522531858},
publisher = {IGI Global},
address = {USA},
edition = {1st},
abstract = {Software development and design is an intricate and complex process that requires a multitude of steps to ultimately create a quality product. One crucial aspect of this process is minimizing potential errors through software fault prediction. Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities is an innovative source of material on the latest advances and strategies for software quality prediction. Including a range of pivotal topics such as case-based reasoning, rate of improvement, and expert systems, this book is an ideal reference source for engineers, researchers, academics, students, professionals, and practitioners interested in novel developments in software design and analysis.}
}

@article{10.1007/s00500-021-06096-3,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {An empirical study toward dealing with noise and class imbalance issues in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06096-3},
doi = {10.1007/s00500-021-06096-3},
abstract = {The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0–80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20–30% after adding 10–40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40–50%. The suggested model leads to avoid noise between 40–60% as compared to other traditional models.},
journal = {Soft Comput.},
month = nov,
pages = {13465–13492},
numpages = {28},
keywords = {Fault proneness, Software metrics, Machine learning, Noisy instance, Class imbalance, Software fault prediction, Software testing}
}

@article{10.1016/j.jss.2018.06.025,
author = {\"{O}zak\i{}nc\i{}, Rana and Tarhan, Ay\c{c}a},
title = {Early software defect prediction: A systematic map and review},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.06.025},
doi = {10.1016/j.jss.2018.06.025},
journal = {J. Syst. Softw.},
month = oct,
pages = {216–239},
numpages = {24},
keywords = {Systematic literature review, Systematic mapping, Prediction model, Software quality, Software defect, Early defect prediction}
}

@article{10.1007/s10664-020-09861-4,
author = {Morasca, Sandro and Lavazza, Luigi},
title = {On the assessment of software defect prediction models via ROC curves},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09861-4},
doi = {10.1007/s10664-020-09861-4},
abstract = {Software defect prediction models are classifiers often built by setting a threshold t on a defect proneness model, i.e., a scoring function. For instance, they classify a software module non-faulty if its defect proneness is below t and positive otherwise. Different values of t may lead to different defect prediction models, possibly with very different performance levels. Receiver Operating Characteristic (ROC) curves provide an overall assessment of a defect proneness model, by taking into account all possible values of t and thus all defect prediction models that can be built based on it. However, using a defect proneness model with a value of t is sensible only if the resulting defect prediction model has a performance that is at least as good as some minimal performance level that depends on practitioners’ and researchers’ goals and needs. We introduce a new approach and a new performance metric (the Ratio of Relevant Areas) for assessing a defect proneness model by taking into account only the parts of a ROC curve corresponding to values of t for which defect proneness models have higher performance than some reference value. We provide the practical motivations and theoretical underpinnings for our approach, by: 1) showing how it addresses the shortcomings of existing performance metrics like the Area Under the Curve and Gini’s coefficient; 2) deriving reference values based on random defect prediction policies, in addition to deterministic ones; 3) showing how the approach works with several performance metrics (e.g., Precision and Recall) and their combinations; 4) studying misclassification costs and providing a general upper bound for the cost related to the use of any defect proneness model; 5) showing the relationships between misclassification costs and performance metrics. We also carried out a comprehensive empirical study on real-life data from the SEACRAFT repository, to show the differences between our metric and the existing ones and how more reliable and less misleading our metric can be.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3977–4019},
numpages = {43},
keywords = {Gini, AUC, Thresholds, ROC, Software defect proneness, Software defect prediction model}
}

@inproceedings{10.1145/3484274.3484285,
author = {Xu, Qinyan and Zhou, Liang},
title = {Straw Defect Detection Algorithm Based on Pruned YOLOv3},
year = {2021},
isbn = {9781450390477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484274.3484285},
doi = {10.1145/3484274.3484285},
abstract = {To solve the problem of defect detection in straw pipeline production, this paper proposes an efficient and fast straw defect detection algorithm (IPOY) based on pruned YOLOv3. Algorithm adopts YOLOv3 model, and then trains the model with channel sparsity regularization, prunes channels with small scaling factors after sparse training, finally fine-tune the pruned network. This process was iterated several times to compress the YOLOv3 model to achieve a lighter model volume, reduce the computational cost of the model, and make the model suitable for industrial production to facilitate application migration to mobile devices. Experimental results show that the proposed algorithm can compress the volume of YOLOv3 model to the maximum extent and maintain the high precision of detection.},
booktitle = {Proceedings of the 4th International Conference on Control and Computer Vision},
pages = {64–69},
numpages = {6},
keywords = {YOLOv3, Straw, Prune, Defect detection},
location = {Macau, China},
series = {ICCCV '21}
}

@inproceedings{10.1145/3424978.3425080,
author = {Zhao, Zhiyong and Gui, Kang and Wang, Peimao},
title = {Fabric Defect Detection Based on Cascade Faster R-CNN},
year = {2020},
isbn = {9781450377720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424978.3425080},
doi = {10.1145/3424978.3425080},
abstract = {With the development of the textile production industry, quality inspection has become an increasingly important means of ensuring the quality of textiles. In order to solve the problem of low efficiency of traditional manual detection methods, automatic textile defect detection technology has become a research focus. Deep learning has several prominent advantages for fabric defect detection. However, the existence of various types of fabric defects and the imbalance of categories have brought great challenges to fabric defect detection. Therefore, this paper proposes a cascaded Faster R-CNN network, which classifies different kinds of defective fabrics by a pre-classifier network, and then sends it to the Faster R-CNN network for defect detection. At the same time, considering the particularity of fabric defects, the optimization of NMS (Non-Maximum Suppression) was carried out. Experimental results show that the method proposed in this paper significantly improves the detection effect of fabric defects.},
booktitle = {Proceedings of the 4th International Conference on Computer Science and Application Engineering},
articleno = {98},
numpages = {6},
keywords = {Objection detection, Fabric defect detection, Cascade Faster R-CNN},
location = {Sanya, China},
series = {CSAE '20}
}

@article{10.1007/s11219-016-9342-6,
author = {Chen, Lin and Fang, Bin and Shang, Zhaowei and Tang, Yuanyan},
title = {Tackling class overlap and imbalance problems in software defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9342-6},
doi = {10.1007/s11219-016-9342-6},
abstract = {Software defect prediction (SDP) is a promising solution to save time and cost in the software testing phase for improving software quality. Numerous machine learning approaches have proven effective in SDP. However, the unbalanced class distribution in SDP datasets could be a problem for some conventional learning methods. In addition, class overlap increases the difficulty for the predictors to learn the defective class accurately. In this study, we propose a new SDP model which combines class overlap reduction and ensemble imbalance learning to improve defect prediction. First, the neighbor cleaning method is applied to remove the overlapping non-defective samples. The whole dataset is then randomly under-sampled several times to generate balanced subsets so that multiple classifiers can be trained on these data. Finally, these individual classifiers are assembled with the AdaBoost mechanism to build the final prediction model. In the experiments, we investigated nine highly unbalanced datasets selected from a public software repository and confirmed that the high rate of overlap between classes existed in SDP data. We assessed the performance of our proposed model by comparing it with other state-of-the-art methods including conventional SDP models, imbalance learning and data cleaning methods. Test results and statistical analysis show that the proposed model provides more reasonable defect prediction results and performs best in terms of G-mean and AUC among all tested models.},
journal = {Software Quality Journal},
month = mar,
pages = {97–125},
numpages = {29},
keywords = {Software defect prediction, Machine learning, Class overlap, Class imbalance}
}

@inproceedings{10.1145/3342999.3343010,
author = {Cui, Mengtian and Sun, Yue and Lu, Yang and Jiang, Yue},
title = {Study on the Influence of the Number of Features on the Performance of Software Defect Prediction Model},
year = {2019},
isbn = {9781450371605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342999.3343010},
doi = {10.1145/3342999.3343010},
abstract = {The software defect prediction model based on machine learning technology is the key to improve the reliability of software. The influence of the number of features on the performance of different software defect prediction models was proposed in this paper. First, a new data sets was built, which is increasing by the number of features based on the NASA public data sets. Then, the eight predictive models are experimented based on these data sets. Next, the influence of the number of features on the performance of different prediction models was analyzed based on the experimental results. Next, the AUC values obtained from the experiment were used to evaluate the performance of different prediction models, and the coefficient of variation C·V values was used to evaluate the performance stability of different prediction models while the number of features changed. In the end, the experiments show that the performance of the predictive model C4.5 is highly susceptible to changes in the number of features, while the performance of the predictive model SMO is relatively stable.},
booktitle = {Proceedings of the 2019 3rd International Conference on Deep Learning Technologies},
pages = {32–37},
numpages = {6},
keywords = {software defect prediction, number of features, machine learning, feature selection},
location = {Xiamen, China},
series = {ICDLT '19}
}

@article{10.1016/j.jss.2021.111038,
author = {Eken, Beyza and Tosun, Ayse},
title = {Investigating the performance of personalized models for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111038},
doi = {10.1016/j.jss.2021.111038},
journal = {J. Syst. Softw.},
month = nov,
numpages = {17},
keywords = {Software recommendation systems, Defect prediction, Change-level, Personalized}
}

@article{10.1049/sfw2.12029,
author = {Zhang, Nana and Ying, Shi and Zhu, Kun and Zhu, Dandan},
title = {Software defect prediction based on stacked sparse denoising autoencoders and enhanced extreme learning machine},
year = {2021},
issue_date = {February 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {1},
url = {https://doi.org/10.1049/sfw2.12029},
doi = {10.1049/sfw2.12029},
abstract = {Software defect prediction is an important software quality assurance technique. Nevertheless, the prediction performance of the constructed model is easily susceptible to irrelevant or redundant features in the software projects and is not predominant enough. To address these two issues, a novel defect prediction model called SSEPG based on Stacked Sparse Denoising AutoEncoders (SSDAE) and Extreme Learning Maching (ELM) optimised by Particle Swarm Optimisation (PSO) and another complementary Gravitational Search Algorithm (GSA) are proposed in this paper, which has two main merits: (1) employ a novel deep neural network – SSDAE to extract new combined features, which can effectively learn the robust deep semantic feature representation. (2) integrate strong exploitation capacity of PSO with strong exploration capability of GSA to optimise the input weights and hidden layer biases of ELM, and utilise the superior discriminability of the enhanced ELM to predict the defective modules. The SSDAE is compared with eleven state‐of‐the‐art feature extraction methods in effect and efficiency, and the SSEPG model is compared with multiple baseline models that contain five classic defect predictors and three variants across 24 software defect projects. The experimental results exhibit the superiority of the SSDAE and the SSEPG on six evaluation metrics.},
journal = {IET Software},
month = may,
pages = {29–47},
numpages = {19},
keywords = {software quality, software maintenance, neural nets, search problems, particle swarm optimisation, learning (artificial intelligence), feature extraction, image denoising, software reliability}
}

@inproceedings{10.1007/978-3-030-89370-5_8,
author = {Cao, Huibin and Lai, Yongxuan and Chen, Quan and Yang, Fan},
title = {A Semi-supervised Defect Detection Method Based on Image Inpainting},
year = {2021},
isbn = {978-3-030-89369-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89370-5_8},
doi = {10.1007/978-3-030-89370-5_8},
abstract = {Defect detection plays an important role in the industrial field. Because the defective images are often insufficient and defects can be various, defective image synthesis is commonly used and models always tend to learn the distribution of defects. However, the complexity of defective image synthesis and difficulty of detecting unseen defects are still the main challenges. To solve these problems, this paper proposes a semi-supervised defect detection method based on image inpainting, denoted as SDDII, which combines the training strategies of CycleGAN and Pix2Pix. First, we train a defect generator unsupervisedly to generate defective images. Second, we train the defect inpaintor supervisedly using the generated images. Finally, the defect inpaintor is used to inpainting the defects, and the defective areas can be segmented by comparing images before and after inpainting. Without ground truth for training, SDDII achieves better results than the naive CycleGAN, and comparable results with UNET which is supervised learning. In addition, SDDII learns the distribution of contents in defect-free images so it has good adaptability for defects unseen before.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part III},
pages = {97–108},
numpages = {12},
keywords = {Generative adversarial networks, Automated optical inspection, Defect detection},
location = {Hanoi, Vietnam}
}

@article{10.1504/ijcsm.2020.112675,
author = {Wang, Junyan},
title = {A hybrid grid-based many-objective optimisation algorithm for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2020.112675},
doi = {10.1504/ijcsm.2020.112675},
abstract = {How to apply limited test resources to detect error module is one of the challenges of software defect prediction problem. To solve the problem, a many-objective software defect prediction model is proposed by considering the probability of detection and false alarm rate, the Balance value and F-measure as defect prediction objectives. At the same time, a hybrid grid-based many-objective optimisation algorithm is designed to solve the model. In the designed algorithm, the adaptive dominant region operator is introduced into the grid-based many-objective optimisation algorithm to improve the performance of algorithm in balancing dynamically the convergence and diversity of population. The simulation results show that the proposed algorithm has better performance in solving many-objective the software defect prediction problem.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {374–384},
numpages = {10},
keywords = {many-objective optimisation, diversity, convergence, adaptive dominant region operator, false alarm rate, the probability of detection, software defect prediction problem}
}

@article{10.1504/ijcat.2020.110428,
author = {Bai, Xue and Zhou, Hua and Yang, Hongji and Wang, Dong},
title = {Connecting historical changes for cross-version software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {63},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2020.110428},
doi = {10.1504/ijcat.2020.110428},
abstract = {In the whole software life cycle, software defects are inevitable and increase the cost of software development and evolution. Cross-Version Software Defect Prediction (CVSDP) aims at learning the defect patterns from the historical data of previous software versions to distinguish buggy software modules from clean ones. In CVSDP, metrics are intrinsic properties associated with the external manifestation of defects. However, traditional software defect measures ignore the sequential information of changes during software evolution process which may play a crucial role in CVSDP. Therefore, researchers tried to connect traditional metrics across versions as a new kind of evolution metrics. This study proposes a new way to connect historical sequence of metrics based on change sequence named HCSM and designs a novel deep learning algorithm GDNN as a classifier to process it. Compared to the traditional metrics approaches and other relevant approaches, the proposed approach fits in projects with stable and orderly defect control trend.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {371–383},
numpages = {12},
keywords = {gate recurrent unit, deep neural networks, DNN, deep learning, historical change sequences, software metrics, cross-version defect prediction, software testing}
}

@article{10.1049/iet-sen.2017.0148,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke},
title = {Progress on approaches to software defect prediction},
year = {2018},
issue_date = {June 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2017.0148},
doi = {10.1049/iet-sen.2017.0148},
abstract = {Software defect prediction is one of the most popular research topics in software engineering. It aims to predict defect‐prone software modules before defects are discovered, therefore it can be used to better prioritise software quality assurance effort. In recent years, especially for recent 3 years, many new defect prediction studies have been proposed. The goal of this study is to comprehensively review, analyse and discuss the state‐of‐the‐art of defect prediction. The authors survey almost 70 representative defect prediction papers in recent years (January 2014–April 2017), most of which are published in the prominent software engineering journals and top conferences. The selected defect prediction papers are summarised to four aspects: machine learning‐based prediction algorithms, manipulating the data, effort‐aware prediction and empirical studies. The research community is still facing a number of challenges for building methods and many research opportunities exist. The identified challenges can give some practical guidelines for both software engineering researchers and practitioners in future software defect prediction.},
journal = {IET Software},
month = jun,
pages = {161–175},
numpages = {15},
keywords = {empirical studies, effort-aware prediction, data manipulation, machine learning-based prediction algorithms, software quality assurance, defect-prone software modules, software engineering journals, software defect prediction, research and development, quality assurance, software reliability, software quality}
}

@inproceedings{10.1007/978-3-030-29551-6_23,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {Software Defect Prediction Using a Hybrid Model Based on Semantic Features Learned from the Source Code},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_23},
doi = {10.1007/978-3-030-29551-6_23},
abstract = {Software defect prediction has extensive applicability thus being a very active research area in Search-Based Software Engineering. A high proportion of the software defects are caused by violated couplings. In this paper, we investigate the relevance of semantic coupling in assessing the software proneness to defects. We propose a hybrid classification model combining Gradual Relational Association Rules with Artificial Neural Networks, which detects the defective software entities based on semantic features automatically learned from the source code. The experiments we have performed led to results that confirm the interplay between conceptual coupling and software defects proneness.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {262–274},
numpages = {13},
keywords = {Conceptual coupling, Machine learning, Software defect prediction},
location = {Athens, Greece}
}

@article{10.1007/s11554-021-01130-x,
author = {Feng, Chuncheng and Zhang, Hua and Li, Yonglong and Wang, Shuang and Wang, Haoran},
title = {Efficient real-time defect detection for spillway tunnel using deep learning},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-021-01130-x},
doi = {10.1007/s11554-021-01130-x},
abstract = {A spillway tunnel eroded by high-speed water for a long time is prone to the rebar-exposed defects. Therefore, regular defect detection is very important for the safety of the hydropower station. The images of spillway tunnel are obtained by erecting scaffolding, and then the defects are manually recognized. This traditional method has some disadvantages such as high risk, inefficiently, time consumption and strong subjectivity. To improve the efficiency of defect detection, a real-time method is proposed for spillway tunnel defect detection (STDD) using deep learning. First, images of a spillway tunnel are collected by an Unmanned Aerial Vehicle (UAV) system and raw images are cropped and labeled to create a dataset of rebar-exposed defects. Then, the lightweight STDD network is developed using separable convolution and asymmetric convolution, and the network is trained and tested on the dataset. To evaluate the performance of STDD network, a comparative experiment is conducted with other networks. The results show that the STDD network has better detection performance. For defect segmentation, the recall, precision, F1 and mean intersection over union (mIoU) are 89.92%, 93.48%, 91.59%, and 91.73%, respectively. The STDD network has 1.7&nbsp;M parameters, and the average inference time is 14.08&nbsp;ms. In summary, the proposed STDD network achieves accurate and real-time defect detection for spillway tunnel, which can provide reliable support for the structure safety evaluation.},
journal = {J. Real-Time Image Process.},
month = dec,
pages = {2377–2387},
numpages = {11},
keywords = {Rebar exposed, UAV, Deep learning, Defect detection, Spillway tunnel, Real-time}
}

@article{10.1016/j.neucom.2019.03.076,
author = {Zhao, Linchang and Shang, Zhaowei and Zhao, Ling and Zhang, Taiping and Tang, Yuan Yan},
title = {Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {352},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.03.076},
doi = {10.1016/j.neucom.2019.03.076},
journal = {Neurocomput.},
month = aug,
pages = {64–74},
numpages = {11},
keywords = {Software defect prediction, Few-shot learning, Deep learning, Cost-sensitive learning, Siamese parallel fully-connected networks}
}

@inproceedings{10.1145/3461001.3475157,
author = {Assun\c{c}\~{a}o, Wesley K. G. and Ayala, Inmaculada and Kr\"{u}ger, Jacob and Mosser, S\'{e}bastien},
title = {International Workshop on Variability Management for Modern Technologies (VM4ModernTech 2021)},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3475157},
doi = {10.1145/3461001.3475157},
abstract = {Variability is an inherent property of software systems that allows developers to deal with the needs of different customers and environments, creating a family of related systems. Variability can be managed in an opportunistic fashion, for example, using clone-and-own, or by employing a systematic approach, for instance, using a software product line (SPL). In the SPL community, variability management has been discussed for systems in various domains, such as defense, avionics, or finance, and for different platforms, such as desktops, web applications, or embedded systems. Unfortunately, other research communities---particularly those working on modern technologies, such as microservice architectures, cyber-physical systems, robotics, cloud computing, autonomous driving, or ML/AI-based systems---are less aware of the state-of-the-art in variability management, which is why they face similar problems and start to redeveloped the same solutions as the SPL community already did. With the International Workshop on Variability Management for Modern Technologies, we aim to foster and strengthen synergies between the communities researching variability management and modern technologies. More precisely, we aim to attract researchers and practitioners to contribute processes, techniques, tools, empirical studies, and problem descriptions or solutions that are related to reuse and variability management for modern technologies. By inviting different communities and establishing collaborations between them, we hope that the workshop can raise the interest of researchers outside the SPL community for variability management, and thus reduce the extent of costly redevelopments in research.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {202},
numpages = {1},
keywords = {variability management, software architecture},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1007/978-3-031-02375-0_41,
author = {Liu, Zhoufeng and Gao, Chengli and Li, Chunlei and Huang, Ning and Guo, Zijing},
title = {Unsupervised Fabric Defect Detection Based on DCGAN with Component-Encoder},
year = {2021},
isbn = {978-3-031-02374-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-02375-0_41},
doi = {10.1007/978-3-031-02375-0_41},
abstract = {Deep learning technology has been proven applicable in fabric defect detection, but the detection performance relies on the large-scale labeled training sets. However, it is a tedious task to construct these annotated datasets in the industrial production line. To alleviate this issue, an unsupervised fabric defect detection model based on generative adversarial network (GAN) with component-encoder is proposed. Firstly, a component encoder is integrated into the deep convolutional generative adversarial network (DCGAN) for easily training the acquired positive sample image instead of random noise, and it is easier for the model to fit the data distribution of the samples. And to ensure the authenticity of the reconstructed image, two loss functions are adopted for the original DCGAN. In the testing stage, the test image patches are input into the trained model to generate the normal image patches. Finally, the residual image obtained by subtracting the original image from the reconstructed image is segmented to localize the defect region. Experimental results on the fabric dataset demonstrate the proposed model can locate the defect region well.},
booktitle = {Pattern Recognition: 6th Asian Conference, ACPR 2021, Jeju Island, South Korea, November 9–12, 2021, Revised Selected Papers, Part I},
pages = {557–568},
numpages = {12},
keywords = {Image processing, Encoder, Unsupervised learning, DCGAN, Fabric defect detection},
location = {Jeju Island, Korea (Republic of)}
}

@article{10.1007/s11227-019-03051-w,
author = {NezhadShokouhi, Mohammad Mahdi and Majidi, Mohammad Ali and Rasoolzadegan, Abbas},
title = {Software defect prediction using over-sampling and feature extraction based on Mahalanobis distance},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {1},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-019-03051-w},
doi = {10.1007/s11227-019-03051-w},
abstract = {As the size of software projects becomes larger, software defect prediction (SDP) will play a key role in allocating testing resources reasonably, reducing testing costs, and speeding up the development process. Most SDP methods have used machine learning techniques based on common software metrics such as Halstead and McCabe’s cyclomatic. Datasets produced by these metrics usually do not follow Gaussian distribution, and also, they have overlaps in defect and non-defect classes. In addition, in many of software defect datasets, the number of defective modules (minority class) is considerably less than non-defective modules (majority class). In this situation, the performance of machine learning methods is reduced dramatically. Therefore, we first need to create a balance between minority and majority classes and then transfer the samples into a new space in which pair samples with same class (must-link set) are near to each other as close as possible and pair samples with different classes (cannot-link) stay as far as possible. To achieve the mentioned objectives, in this paper, Mahalanobis distance in two manners will be used. First, the minority class is oversampled based on the Mahalanobis distance such that generated synthetic data are more diverse from other minority data, and minority class distribution is not changed significantly. Second, a feature extraction method based on Mahalanobis distance metric learning is used which try to minimize distances of sample pairs in must-links and maximize the distance of sample pairs in cannot-links. To demonstrate the effectiveness of the proposed method, we performed some experiments on 12 publicly available datasets which are collected NASA repositories and compared its result by some powerful previous methods. The performance is evaluated in F-measure, G-Mean, and Matthews correlation coefficient. Generally, the proposed method has better performance as compared to the mentioned methods.},
journal = {J. Supercomput.},
month = jan,
pages = {602–635},
numpages = {34},
keywords = {Feature extraction, Over-sampling, Mahalanobis distance, Software metrics, Software defect prediction}
}

@article{10.1155/2021/9948808,
author = {Li, Chao and Li, Jun and Li, Yafei and He, Lingmin and Fu, Xiaokang and Chen, Jingjing and Zhou, Xiaokang},
title = {Fabric Defect Detection in Textile Manufacturing: A Survey of the State of the Art},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/9948808},
doi = {10.1155/2021/9948808},
abstract = {Defects in the textile manufacturing process lead to a great waste of resources and further affect the quality of textile products. Automated quality guarantee of textile fabric materials is one of the most important and demanding computer vision tasks in textile smart manufacturing. This survey presents a thorough overview of algorithms for fabric defect detection. First, this review briefly introduces the importance and inevitability of fabric defect detection towards the era of manufacturing of artificial intelligence. Second, defect detection methods are categorized into traditional algorithms and learning-based algorithms, and traditional algorithms are further categorized into statistical, structural, spectral, and model-based algorithms. The learning-based algorithms are further divided into conventional machine learning algorithms and deep learning algorithms which are very popular recently. A systematic literature review on these methods is present. Thirdly, the deployments of fabric defect detection algorithms are discussed in this study. This paper provides a reference for researchers and engineers on fabric defect detection in textile manufacturing.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {13}
}

@inproceedings{10.1145/3377811.3380389,
author = {Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
title = {Software visualization and deep transfer learning for effective software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380389},
doi = {10.1145/3377811.3380389},
abstract = {Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {578–589},
numpages = {12},
keywords = {cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1504/ijcse.2020.106871,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A benchmarking framework using nonlinear manifold detection techniques for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {4},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2020.106871},
doi = {10.1504/ijcse.2020.106871},
abstract = {Prediction of software defects in time improves quality and helps in locating the defect-prone areas accurately. Although earlier considerable methods were applied, actually none of those measures was found to be fool-proof and accurate. Hence, a newer framework includes nonlinear manifold detection model, and its algorithm originated for defect prediction using different techniques of nonlinear manifold detection (nonlinear MDs) along with 14 different machine learning techniques (MLTs) on eight defective software datasets. A critical analysis cum exhaustive comparative estimation revealed that nonlinear manifold detection model has a more accurate and effective impact on defect prediction as compared to feature selection techniques. The outcome of the experiment was statistically tested by Friedman and post hoc analysis using Nemenyi test, which validates that hidden Markov model (HMM) along with nonlinear manifold detection model outperforms and is significantly different from MLTs.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {593–614},
numpages = {21},
keywords = {post hoc analysis, software defect prediction, nonlinear manifold detection, Nemenyi test, machine learning, Friedman test, feature selection, dimensionality reduction}
}

@article{10.1016/j.infsof.2018.02.003,
author = {Mahmood, Zaheed and Bowes, David and Hall, Tracy and Lane, Peter C.R. and Petri\'{c}, Jean},
title = {Reproducibility and replicability of software defect prediction studies},
year = {2018},
issue_date = {Jul 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {99},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.02.003},
doi = {10.1016/j.infsof.2018.02.003},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {148–163},
numpages = {16},
keywords = {Software defect prediction, Reproducibility, Replication}
}

@inproceedings{10.1007/978-3-030-88013-2_20,
author = {Liu, Zhoufeng and Huang, Ning and Li, Chunlei and Guo, Zijing and Gao, Chengli},
title = {Fabric Defect Detection via Multi-scale Feature Fusion-Based Saliency},
year = {2021},
isbn = {978-3-030-88012-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88013-2_20},
doi = {10.1007/978-3-030-88013-2_20},
abstract = {Automatic fabric defect detection plays a key role in controlling product quality. Salient object detection (SOD) based on convolutional neural network has been proven applicable in fabric defect detection, but how to learn powerful features and feature fusion for saliency are still challenging tasks due to the complex texture of fabric image. In this paper, a novel visual saliency based on multi-scale feature fusion is proposed for fabric defect detection. First, a Multi-scale Feature Learning Module (MFLM) by simulating the parallel processing mechanism of multi-receptive is proposed to efficiently characterize the complex fabric texture. In addition, Feedback Attention Refinement Fusion Module (FARFM) is designed to selectively aggregate multi-level features for enhancing the feature fusion. In the end, fabric defect detection is localized by segmenting the generated saliency map. Experimental results demonstrate that the proposed method can localize the defect region with high accuracy, and outperform the 5 state-of-the-art methods.},
booktitle = {Pattern Recognition and Computer Vision: 4th Chinese Conference, PRCV 2021, Beijing, China, October 29 – November 1, 2021, Proceedings, Part IV},
pages = {240–251},
numpages = {12},
keywords = {Feedback attention refinement fusion, Multi-scale feature learning, Salient object detection, Fabric defect detection},
location = {Beijing, China}
}

@article{10.4018/IJOSSP.2017100102,
author = {Akour, Mohammed and Melhem, Wasen Yahya},
title = {Software Defect Prediction Using Genetic Programming and Neural Networks},
year = {2017},
issue_date = {October 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {4},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017100102},
doi = {10.4018/IJOSSP.2017100102},
abstract = {This article describes how classification methods on software defect prediction is widely researched due to the need to increase the software quality and decrease testing efforts. However, findings of past researches done on this issue has not shown any classifier which proves to be superior to the other. Additionally, there is a lack of research that studies the effects and accuracy of genetic programming on software defect prediction. To find solutions for this problem, a comparative software defect prediction experiment between genetic programming and neural networks are performed on four datasets from the NASA Metrics Data repository. Generally, an interesting degree of accuracy is detected, which shows how the metric-based classification is useful. Nevertheless, this article specifies that the application and usage of genetic programming is highly recommended due to the detailed analysis it provides, as well as an important feature in this classification method which allows the viewing of each attributes impact in the dataset.},
journal = {Int. J. Open Source Softw. Process.},
month = oct,
pages = {32–51},
numpages = {20},
keywords = {Testing, Software Defect Prediction, Neural Networks, Nasa Metrics, Machine learning, Genetic Programming, Genetic Algorithm, Classification}
}

@inproceedings{10.1109/IRI.2018.00047,
author = {Xu, Ling and Wang, Bei and Liu, Ling and Zhou, Mo and Liao, Shengping and Yan, Meng},
title = {Misclassification Cost-Sensitive Software Defect Prediction},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI.2018.00047},
doi = {10.1109/IRI.2018.00047},
abstract = {Software defect prediction helps developers focus on defective modules for efficient software quality assurance. A common goal shared by existing software defect prediction methods is to attain low classification error rates. These proposals suffer from two practical problems: (i) Most of the prediction methods rely on a large number of labeled training data. However, collecting labeled data is a difficult and expensive task. It is hard to obtain classification labels over new software projects or existing projects without historical defect data. (ii) Software defect datasets are highly imbalanced. In many real-world applications, the misclassification cost of defective modules is generally several times higher than that of non-defective ones. In this paper, we present a misclassification Cost-sensitive approach to Software Defect Prediction (CSDP). The CSDP approach is novel in two aspects: First, CSDP addresses the problem of unlabeled software detect datasets by combining an unsupervised sampling method with a domain specific misclassification cost model. This preprocessing step selectively samples a small percentage of modules through estimating their classification labels. Second, CSDP builds a cost-sensitive support vector machine model to predict defect-proneness of the rest of modules with both overall classification error rate and domain specific misclassification cost as quality metrics. CSDP is evaluated on four NASA projects. Experimental results highlight three interesting observations: (1) CSDP achieves higher Normalized Expected Cost of Misclassification (NECM) compared with state-of-art supervised learning models under imbalanced training data with limited labeling. (2) CSDP outperforms state-of-art semi-supervised learning methods, which disregards classification costs, especially in recall rate. (3) CSDP enhanced through unsupervised sampling as a preprocessing step prior to training and prediction outperforms the baseline CSDP without the sampling process.},
booktitle = {2018 IEEE International Conference on Information Reuse and Integration (IRI)},
pages = {256–263},
numpages = {8},
location = {Salt Lake City, UT, USA}
}

@phdthesis{10.5555/AAI28973000,
author = {Chakraborty, Samit},
advisor = {Marguerite, Moore, and Lisa, Parrillo-Chapman, and Maureen, Grasso, and Dan, Harris,},
title = {Automatic Printed Fabric Defect Detection Using a Convolutional Neural Network},
year = {2021},
isbn = {9798780649717},
publisher = {North Carolina State University},
abstract = {Defect detection is a crucial step in textile quality control. An efficient defect detection system can ensure the overall quality of the processes and products that are acceptable to consumers. Research into automatic defect detection systems using image processing and machine learning techniques emerged in recent years along with advances in technological capability. Researchers have established various prototypes for real-time defect detection during weaving and knitting (Hanbay et al., 2019; Kopaczka et al., 2018; Weinmann et al., 2013). There are a number of techniques for real-time defect detection and they tend to vary according to each unique manufacturing process, focal defects, and different computational algorithms. Although the need is high, applications or research related to automatic, real-time defect detection processes for printed fabrics are not prevalent in academic literatures There are a number of academic studies that focus on fabric printing defect detection after the fabric is produced, rather than through a real-time perspective (Alam et al., 2020; Junfeng Jing &amp; Ren, 2020; Kang et al., 2015; Kuo et al., 2012; M. Li et al., 2015; Pan et al., 2010). Also, this stream of research does not include work that employs a convolutional neural network (CNN), which is considered to be particularly efficient for image classification compared to rival algorithmic models (Eldessouki, 2018; Ferguson et al., 2018; Hanbay et al., 2019; Indolia et al., 2018; A. Kumar, 2008; Ngan et al., 2011; Wang et al., 2018).The purpose of this research is to develop an automatic defect detection model employing a CNN to facilitate real-time deployment in the textile printing process. Two general objectives are stated to address this purpose including establishing an empirical dataset (RO1) and developing, training and testing the model using a CNN algorithmic approach. This approach potentially provides a number of potential advantages over current defect detection processes in printing by identifying problems more effectively and efficiently in real-time. This research extends current state of the art machine learning techniques into the print production context and provides potential directions for ADD in textile quality control. This research proposes a novel methodology that demonstrates the application of convolutional neural network (CNN) to classify printing defects based on the fabric images collected from industries. The research also integrated cross validation and k-Nearest Neighbor (KNN) algorithm based classification methods to compare model performance. The results show that the CNN model performs better compared to cross validation and k-Nearest Neighbor (KNN) algorithm based classification methods. Then the research included visual geometric group (VGG), DenseNet-121 (DNS12), InceptionV3 and Xception deep learning networks to compare model performance with proposed CNN model. The results exhibit that the VGG-based models perform better compared to a simple CNN model. However the custom CNN model showed higher accuracy compared to DNS12, InceptionV3 and Xception networks.},
note = {AAI28973000}
}

@article{10.1155/2019/6230953,
author = {Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Yang, Kang and Chen, Liqiong and Vitiello, Autilia},
title = {Software Defect Prediction via Attention-Based Recurrent Neural Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/6230953},
doi = {10.1155/2019/6230953},
abstract = {In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network (DP-ARNN). More specifically, DP-ARNN first parses abstract syntax trees (ASTs) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of DP-ARNN by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it employs the attention mechanism to further generate significant features for accurate defect prediction. To validate our method, we choose seven open-source Java projects in Apache, using F1-measure and area under the curve (AUC) as evaluation criteria. The experimental results show that, in average, DP-ARNN improves the F1-measure by 14% and AUC by 7% compared with the state-of-the-art methods, respectively.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@article{10.1109/TIP.2019.2959741,
author = {Liu, Juhua and Wang, Chaoyue and Su, Hai and Du, Bo and Tao, Dacheng},
title = {Multistage GAN for Fabric Defect Detection},
year = {2020},
issue_date = {2020},
publisher = {IEEE Press},
volume = {29},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2019.2959741},
doi = {10.1109/TIP.2019.2959741},
abstract = {Fabric defect detection is an intriguing but challenging topic. Many methods have been proposed for fabric defect detection, but these methods are still suboptimal due to the complex diversity of both fabric textures and defects. In this paper, we propose a generative adversarial network (GAN)-based framework for fabric defect detection. Considering existing challenges in real-world applications, the proposed fabric defect detection system is capable of learning existing fabric defect samples and automatically adapting to different fabric textures during different application periods. Specifically, we customize a deep semantic segmentation network for fabric defect detection that can detect different defect types. Furthermore, we attempted to train a multistage GAN to synthesize reasonable defects in new defect-free samples. First, a texture-conditioned GAN is trained to explore the conditional distribution of defects given different texture backgrounds. Given a novel fabric, we aim to generate reasonable defective patches. Then, a GAN-based fusion network fuses the generated defects to specific locations. Finally, the well-trained multistage GAN continuously updates the existing fabric defect datasets and contributes to the fine-tuning of the semantic segmentation network to better detect defects under different conditions. Comprehensive experiments on various representative fabric samples are conducted to verify the detection performance of our proposed method.},
journal = {Trans. Img. Proc.},
month = jan,
pages = {3388–3400},
numpages = {13}
}

@inproceedings{10.1145/3377811.3380403,
author = {Tabassum, Sadia and Minku, Leandro L. and Feng, Danyi and Cabral, George G. and Song, Liyan},
title = {An investigation of cross-project learning in online just-in-time software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380403},
doi = {10.1145/3377811.3380403},
abstract = {Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {554–565},
numpages = {12},
keywords = {class imbalance, concept drift, cross-project learning, online learning, software defect prediction, transfer learning, verification latency},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1007/s10462-020-09942-2,
author = {B\'{e}cue, Adrien and Pra\c{c}a, Isabel and Gama, Jo\~{a}o},
title = {Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09942-2},
doi = {10.1007/s10462-020-09942-2},
abstract = {This survey paper discusses opportunities and threats of using artificial intelligence (AI) technology in the manufacturing sector with consideration for offensive and defensive uses of such technology. It starts with an introduction of Industry 4.0 concept and an understanding of AI use in this context. Then provides elements of security principles and detection techniques applied to operational technology (OT) which forms the main attack surface of manufacturing systems. As some intrusion detection systems (IDS) already involve some AI-based techniques, we focus on existing machine-learning and data-mining based techniques in use for intrusion detection. This article presents the major strengths and weaknesses of the main techniques in use. We also discuss an assessment of their relevance for application to OT, from the manufacturer point of view. Another part of the paper introduces the essential drivers and principles of Industry 4.0, providing insights on the advent of AI in manufacturing systems as well as an understanding of the new set of challenges it implies. AI-based techniques for production monitoring, optimisation and control are proposed with insights on several application cases. The related technical, operational and security challenges are discussed and an understanding of the impact of such transition on current security practices is then provided in more details. The final part of the report further develops a vision of security challenges for Industry 4.0. It addresses aspects of orchestration of distributed detection techniques, introduces an approach to adversarial/robust AI development and concludes with human–machine behaviour monitoring requirements.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3849–3886},
numpages = {38},
keywords = {Artificial intelligence, Industry 4.0, Security, Intrusion detection systems}
}

@article{10.1007/s10515-015-0179-1,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Zhang, Liqiang},
title = {Multiple kernel ensemble learning for software defect prediction},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0179-1},
doi = {10.1007/s10515-015-0179-1},
abstract = {Software defect prediction aims to predict the defect proneness of new software modules with the historical defect data so as to improve the quality of a software system. Software historical defect data has a complicated structure and a marked characteristic of class-imbalance; how to fully analyze and utilize the existing historical defect data and build more precise and effective classifiers has attracted considerable researchers' interest from both academia and industry. Multiple kernel learning and ensemble learning are effective techniques in the field of machine learning. Multiple kernel learning can map the historical defect data to a higher-dimensional feature space and make them express better, and ensemble learning can use a series of weak classifiers to reduce the bias generated by the majority class and obtain better predictive performance. In this paper, we propose to use the multiple kernel learning to predict software defect. By using the characteristics of the metrics mined from the open source software, we get a multiple kernel classifier through ensemble learning method, which has the advantages of both multiple kernel learning and ensemble learning. We thus propose a multiple kernel ensemble learning (MKEL) approach for software defect classification and prediction. Considering the cost of risk in software defect prediction, we design a new sample weight vector updating strategy to reduce the cost of risk caused by misclassifying defective modules as non-defective ones. We employ the widely used NASA MDP datasets as test data to evaluate the performance of all compared methods; experimental results show that MKEL outperforms several representative state-of-the-art defect prediction methods.},
journal = {Automated Software Engg.},
month = dec,
pages = {569–590},
numpages = {22},
keywords = {Software defect prediction, Multiple kernel learning, Multiple kernel ensemble learning (MKEL), Ensemble learning}
}

@article{10.1007/s11219-018-9436-4,
author = {Ji, Haijin and Huang, Song and Wu, Yaning and Hui, Zhanwei and Zheng, Changyou},
title = {A new weighted naive Bayes method based on information diffusion for software defect prediction},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9436-4},
doi = {10.1007/s11219-018-9436-4},
abstract = {Software defect prediction (SDP) plays a significant part in identifying the most defect-prone modules before software testing and allocating limited testing resources. One of the most commonly used classifiers in SDP is naive Bayes (NB). Despite the simplicity of the NB classifier, it can often perform better than more complicated classification models. In NB, the features are assumed to be equally important, and the numeric features are assumed to have a normal distribution. However, the features often do not contribute equivalently to the classification, and they usually do not have a normal distribution after performing a Kolmogorov-Smirnov test; this may harm the performance of the NB classifier. Therefore, this paper proposes a new weighted naive Bayes method based on information diffusion (WNB-ID) for SDP. More specifically, for the equal importance assumption, we investigate six weight assignment methods for setting the feature weights and then choose the most suitable one based on the F-measure. For the normal distribution assumption, we apply the information diffusion model (IDM) to compute the probability density of each feature instead of the acquiescent probability density function of the normal distribution. We carry out experiments on 10 software defect data sets of three types of projects in three different programming languages provided by the PROMISE repository. Several well-known classifiers and ensemble methods are included for comparison. The final experimental results demonstrate the effectiveness and practicability of the proposed method.},
journal = {Software Quality Journal},
month = sep,
pages = {923–968},
numpages = {46},
keywords = {Information diffusion, Feature weighting, Naive Bayes, Software defect prediction}
}

@inproceedings{10.1145/3426826.3426832,
author = {Qi, Shengxiang and Yang, Jiarong and Zhong, Zhenyi},
title = {A Review on Industrial Surface Defect Detection Based on Deep Learning Technology},
year = {2020},
isbn = {9781450388344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426826.3426832},
doi = {10.1145/3426826.3426832},
abstract = {In recent years, with the rapid development of deep learning, computer vision technology based on convolutional neural network (CNN) is widely used in industrial fields. At present, surface defect detection by machine vision is one of the most mature applications of CNN in industry. This paper provides a comprehensive overview of deep learning in the field. First of all, we briefly introduce the major tasks of CNN in computer vision researches, including image classification, object detection, edge detection and image segmentation, which are frequently used techniques in surface defect inspection. After that, we describe in detail the applications of computer vision based on CNN models in a variety of industrial scenarios for surface defect detection tasks, which mainly cover the steel surface defect inspection, magnetic tile surface defect inspection, rail surface defect inspection, screen surface detect inspection, solar cell surface defect inspection, and some others. As an emerging representative of artificial intelligence technology, we believe that deep learning will gradually become one of the mainstream technologies for industrial vision in the future. Accordingly, this paper aims to present a reference and guidance for researchers in industry to apply the advanced technology of deep learning.},
booktitle = {Proceedings of the 2020 3rd International Conference on Machine Learning and Machine Intelligence},
pages = {24–30},
numpages = {7},
keywords = {surface defect detection, industrial application, computer vision, Deep learning},
location = {Hangzhou, China},
series = {MLMI '20}
}

@article{10.1016/j.neucom.2021.04.094,
author = {Fuchs, Patrick and Kr\"{o}ger, Thorben and Garbe, Christoph S.},
title = {Defect detection in CT scans of cast aluminum parts: A machine vision perspective},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {453},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.04.094},
doi = {10.1016/j.neucom.2021.04.094},
journal = {Neurocomput.},
month = sep,
pages = {85–96},
numpages = {12},
keywords = {Simulated training data, Self-supervision, Defect detection, Deep learning, Computed tomography, Semantic segmentation}
}

@article{10.1016/j.asoc.2016.06.023,
author = {Mesquita, Diego P.P. and Rocha, Lincoln S. and Gomes, Joo Paulo P. and Rocha Neto, Ajalmar R.},
title = {Classification with reject option for software defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.06.023},
doi = {10.1016/j.asoc.2016.06.023},
abstract = {Graphical abstractDisplay Omitted HighlightsWe propose the use of classification with reject option for software defect prediction (SDP) as a way to incorporate additional knowledge in the SDP process.We propose two variants of the extreme learning machine with reject option.It is proposed an ELM with reject option for imbalanced datasets.The proposed method is tested on five real world software datasets.An example is shown to illustrate how the rejected software modules can be further analyzed to improve the final SDP accuracy. ContextSoftware defect prediction (SDP) is an important task in software engineering. Along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. Several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. This type of yes or no decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. To the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. This knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. ObjectiveWe seek to develop a SDP method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. MethodWe develop a SDP method called rejoELM and its variant, IrejoELM. Both methods were built upon the weighted extreme learning machine (ELM) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. While rejoELM aims to maximize the accuracy for a rejection rate, IrejoELM maximizes the F-measure. Hence, IrejoELM becomes an alternative for classification with reject option for imbalanced datasets. ResultsrejoEM and IrejoELM are tested on five datasets of source code metrics extracted from real world open-source software projects. Results indicate that rejoELM has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. Although IrejoELM shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the F-measure is used as a performance metric. ConclusionIt is concluded that rejoELM is a valid alternative for classification with reject option problems when classes are nearly equally represented. On the other hand, IrejoELM is shown to be the best alternative for classification with reject option on imbalanced datasets. Since SDP problems are usually characterized as imbalanced learning problems, the use of IrejoELM is recommended.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1085–1093},
numpages = {9},
keywords = {Software defect prediction, Extreme learning machines, Classification with reject option}
}

@article{10.1007/s42979-020-0119-4,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Evaluation of Sampling-Based Ensembles of Classifiers on Imbalanced Data for Software Defect Prediction Problems},
year = {2020},
issue_date = {Mar 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
url = {https://doi.org/10.1007/s42979-020-0119-4},
doi = {10.1007/s42979-020-0119-4},
abstract = {Defect prediction in software projects plays a crucial role to reduce quality-based risk and increase the capability of detecting faulty program modules. Hence, classification approaches to anticipate software defect proneness based on static code characteristics have become a hot topic with a great deal of attention in recent years. While several novel studies show that the use of a single classifier causes the performance bottleneck, ensembles of classifiers might effectively enhance classification performance compared to a single classifier. However, the class imbalance property of software defect data severely hinders the classification efficiency of ensemble learning. To cope with this problem, resampling methods are usually combined into ensemble models.
This paper empirically assesses the importance of sampling with regard to ensembles of various classifiers on imbalanced data in software defect prediction problems. Extensive experiments with the combination of seven different kinds of classification algorithms, three sampling methods, and two balanced data learning schemata were conducted over ten datasets. Empirical results indicated the positive effects of combining sampling techniques and the ensemble learning model on the performance of defect prediction regarding datasets with imbalanced class distributions.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {16},
keywords = {Imbalanced data, Ensemble learning, Data balancing, SMOTE, Random oversampling, Random undersampling, Software defect prediction}
}

@article{10.1504/ijista.2019.102667,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {Statistical assessment of nonlinear manifold detection-based software defect prediction techniques},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {6},
issn = {1740-8865},
url = {https://doi.org/10.1504/ijista.2019.102667},
doi = {10.1504/ijista.2019.102667},
abstract = {Prediction of software defects has immense importance for obtaining desired outcome at minimised cost and so attracted researchers working on this topic applying various techniques, which were not found fully effective. Software datasets comprise of redundant features that hinder effective application of techniques resulting inappropriate defect prediction. Hence, it requires newer application of nonlinear manifold detection techniques (nonlinear MDTs) that has been examined for accurate prediction of defects at lesser time and cost using different classification techniques. In this work, we analysed and tested the effect of nonlinear MDTs to find out accurate and best classification technique for all datasets. Comparison has been made between the results of without or with nonlinear MDTs and paired two-tailed T-test has been performed for statistical testing and verifying the performance of classifiers using nonlinear MDTs on all datasets. Outcome revealed that among all nonlinear MDTs, FastMVU makes most accurate prediction of software defects.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {579–605},
numpages = {26},
keywords = {software defect prediction, promise repository, nonlinear, manifold detection, machine learning, FastMVU, fast maximum variance unfolding, dimensionality reduction}
}

@inproceedings{10.1145/3469213.3469219,
author = {Ren, Jing and Huang, Xishi},
title = {Rapid Transformation Estimation Using Deep Learning for Defect Detection},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3469219},
doi = {10.1145/3469213.3469219},
abstract = {Defect detection is a crucial step in the manufacturing of vehicle parts such as the engine. One major method for defect detection is to use image registration and image difference to identify and segment the defects. The key technology of this approach is to extract the accurate transformation information between the template image and the testing images. In this paper, we propose a novel deep neural network (DNN) method to learn the transformations from the training dataset. Wavelet transformation is introduced to denoise the images and reduce the image size for fast image registration. The results show that the trained DNN models are able to effectively predict the transformation between the template image and the actual test image in real time with high accuracy.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {6},
numpages = {5},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1049/iet-sen.2017.0198,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wu, Fei},
title = {Low‐rank representation for semi‐supervised software defect prediction},
year = {2018},
issue_date = {December 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2017.0198},
doi = {10.1049/iet-sen.2017.0198},
abstract = {Software defect prediction based on machine learning is an active research topic in the field of software engineering. The historical defect data in software repositories may contain noises because automatic defect collection is based on modified logs and defect reports. When the previous defect labels of modules are limited, predicting the defect‐prone modules becomes a challenging problem. In this study, the authors propose a graph‐based semi‐supervised defect prediction approach to solve the problems of insufficient labelled data and noisy data. Graph‐based semi‐supervised learning methods used the labelled and unlabelled data simultaneously and consider them as the nodes of the graph at the training phase. Therefore, they solve the problem of insufficient labelled samples. To improve the stability of noisy defect data, a powerful clustering method, low‐rank representation (LRR), and neighbourhood distance are used to construct the relationship graph of samples. Therefore, they propose a new semi‐supervised defect prediction approach, named low‐rank representation‐based semi‐supervised software defect prediction (LRRSSDP). The widely used datasets from NASA projects and noisy datasets are employed as test data to evaluate the performance. Experimental results show that (i) LRRSSDP outperforms several representative state‐of‐the‐art semi‐supervised defect prediction methods; and (ii) LRRSSDP can maintain robustness in noisy environments.},
journal = {IET Software},
month = dec,
pages = {527–535},
numpages = {9},
keywords = {LRRSSDP, low-rank representation, noisy defect data, insufficient labelled samples, unlabelled data, noisy data, insufficient labelled data, semisupervised defect prediction approach, defect-prone modules, defect reports, automatic defect collection, software repositories, historical defect data, software engineering, semisupervised software defect prediction, program diagnostics, graph theory, pattern clustering, learning (artificial intelligence), software engineering}
}

@article{10.1016/j.asoc.2021.107913,
author = {Koulali, Imane and Eskil, M. Taner},
title = {Unsupervised textile defect detection using convolutional neural networks},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107913},
doi = {10.1016/j.asoc.2021.107913},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Manhattan distance, Cross-patch similarity, Neural network, Anomaly detection, Textile defect, Fabric defect}
}

@inproceedings{10.1007/978-3-030-89029-2_16,
author = {Baculo, Maria Jeseca C. and Ruiz, Conrado and Aran, Oya},
title = {Cecid Fly Defect Detection in Mangoes Using Object Detection Frameworks},
year = {2021},
isbn = {978-3-030-89028-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89029-2_16},
doi = {10.1007/978-3-030-89029-2_16},
abstract = {Mango export has experienced rapid growth in global trade over the past few years, however, they are susceptible to surface defects that can affect their market value. This paper investigates the automated detection of a mango defect caused by cecid flies, which can affect a significant portion of the production yield.

 Object detection frameworks using CNN were used to localize and detect multiple defects present in a single mango image. This paper also proposes modified versions of R-CNN and FR-CNN replacing its region search algorithms with segmentation-based region extraction. A dataset consisting of 1329 cecid fly surface blemishes was used to train the object detection models. The results of the experiments show comparable performance between the modified and existing state-of-the-art object detection frameworks. Results show that Faster R-CNN achieved the highest average precision of 0.901 at aP50 while the Modified FR-CNN has the highest average precision of 0.723 at aP75.},
booktitle = {Advances in Computer Graphics: 38th Computer Graphics International Conference, CGI 2021, Virtual Event, September 6–10, 2021, Proceedings},
pages = {205–216},
numpages = {12},
keywords = {Convolutional neural networks, Region-based CNN, Image processing, Defect detection}
}

@article{10.1016/j.asoc.2020.106686,
author = {Haouari, Ahmed Taha and Souici-Meslati, Labiba and Atil, Fadila and Meslati, Djamel},
title = {Empirical comparison and evaluation of Artificial Immune Systems in inter-release software fault prediction},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106686},
doi = {10.1016/j.asoc.2020.106686},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {18},
keywords = {Neural Network, Artificial Immune Recognition System, Inter-projects fault prediction, Software defect prediction, Artificial Immune Systems}
}

@article{10.1007/s10845-021-01864-2,
author = {Huang, Feng and Wang, Ben-wu and Li, Qi-peng and Zou, Jun},
title = {Texture surface defect detection of plastic relays with an enhanced feature pyramid network},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01864-2},
doi = {10.1007/s10845-021-01864-2},
abstract = {Deep learning has seen its promising applications in manufacturing processes. In this study, a deep network named Cascade Tri-DFPN based on the two-stage target detection algorithm is proposed for detecting the defects on the texture surface of plastic relays. The network adopts a derivative Resnet-101d as the backbone to obtain a loss-reduced feature extraction. Meanwhile, an enhanced feature pyramid module is put forward to enhance the feature representation of the network by adding a dense connection of feature layers through the self-attentive block. Moreover, the defect region proposals are optimized by introducing a cascade module to obtain high-quality defective proposal boxes. Experimental results on the augmented data set of relays’ surface defect reveal an average accuracy of 88.57% and an average recall rate of 94.58%, much higher than those of traditional RCNN or FPN detectors, demonstrating the remarkable improvement of the proposed network. Robustness of the method is also verified by performing tests with deteriorative image processing, which indicates an eligible defect detection under relatively&nbsp;complex scenarios such as image blurring. The proposed deep network could be used in surface defect detection of plastic relays and other potentially related industrial defect detection fields.},
journal = {J. Intell. Manuf.},
month = nov,
pages = {1409–1425},
numpages = {17},
keywords = {Manufacturing application, Self-attention, Enhanced FPN, Deep learning, Defect detection}
}

@inproceedings{10.1007/978-3-030-89098-8_54,
author = {Lu, Junxu and Zhang, Xu and Li, Chen},
title = {An Surface Defect Detection Framework for Glass Bottle Body Based on the Stripe Light Source},
year = {2021},
isbn = {978-3-030-89097-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89098-8_54},
doi = {10.1007/978-3-030-89098-8_54},
abstract = {Quality inspection is an essential technology in the glass product industry. Machine vision has shown more significant potential than manual inspection at present. However, the visual inspection of the bottle for defects remains a challenging task in a quality-controlled due to the difficulty in detecting some notable defects. To overcome the problem, we propose a surface defect detection framework based on the stripe light source. First, a novel method, DTST, determines the stripe type in the background with traditional image processing methods. Then, according to the result of DTST, the stripe type is divided into vertical stripes and horizontal stripes. For the former, a defect detection method based on DDVS that uses machine learning technology is proposed to detect cold mold defects precisely. A defect detection method named DDHS that uses deep learning technology is proposed to precisely detect wrinkled skin defects for the latter. The proposed framework is tested for data sets obtained by our designed vision system. The experimental results demonstrate that our framework achieves good performance.},
booktitle = {Intelligent Robotics and Applications: 14th International Conference, ICIRA 2021, Yantai, China, October 22–25, 2021, Proceedings, Part II},
pages = {575–585},
numpages = {11},
keywords = {Deep learning, Machine learning, Stripe light source, Defect detection},
location = {Yantai, China}
}

@article{10.1007/s00521-018-03969-x,
author = {Essa, Ehab and Hossain, M. Shamim and Tolba, A. S. and Raafat, Hazem M. and Elmogy, Samir and Muahmmad, Ghulam},
title = {Toward cognitive support for automated defect detection},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-03969-x},
doi = {10.1007/s00521-018-03969-x},
abstract = {With the development of cognitive computing, machine learning techniques, and big data analytics, cognitive support is crucial for automated industrial production. The real-time automated visual inspection in industrial production is a challenging task. Speed and accuracy are crucial factors for the process of automating the defect detection. Many statistical and spectrum analysis approaches have been introduced; however, they suffer from high computational cost with average performance. This paper proposes a neighborhood-maintaining approach, which is based on the minimum ratio for fast and reliable inspection of industrial products. The minimum ratio between local neighborhood sliding windows is used as a similarity measure for localizing defection. Extreme learning machine is then adapted to classify surfaces to defect or normal. A defect detection accuracy on textile fabrics has achieved 98.07% with 91.29% sensitivity and 99.67% specificity. The minimum ratio shows highly discriminant power to distinguish between normal and abnormal surfaces. A defective region produces a smaller value of minimum ratio than that of a defect-free region. Experimental results show superior speed and accuracy performance over many existing defect detection methods.},
journal = {Neural Comput. Appl.},
month = may,
pages = {4325–4333},
numpages = {9},
keywords = {Cognitive automation, Visual inspection, Defect detection, Minimum ratio}
}

@inproceedings{10.1007/978-3-030-90439-5_28,
author = {Kobayashi, Hiroki and Miyoshi, Ryo and Hashimoto, Manabu},
title = {Normal Image Generation-Based Defect Detection by Generative Adversarial Network with Chaotic Random Images},
year = {2021},
isbn = {978-3-030-90438-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90439-5_28},
doi = {10.1007/978-3-030-90439-5_28},
abstract = {We propose a defect detection method called ChaosGAN (Generative Adversarial Network with Chaotic Random Images) for image generation that can output a normal image with high reconstruction performance regardless of whether the input image is normal or anomaly. A defect detection method based on image generation should be able to (i) convert from a normal image to the same normal image as input and (ii) convert from an anomaly image to normal image with the defective parts removed. ChaosGAN is a combination of Skip-GANomaly, which performs well at identity mapping of a normal image, and AnoGAN, which reconstructs a normal image by regarding a random image as an input latent space. We conducted an experiment to evaluate ChaosGAN using the area under the curve of receiver operating characteristic (AUROC). The AUROC was 0.76 with ChaosGAN (AnoGAN was 0.49, and Skip-GANomaly was 0.67), indicating that it performs better than other defect detection methods.},
booktitle = {Advances in Visual Computing: 16th International Symposium, ISVC 2021, Virtual Event, October 4-6, 2021, Proceedings, Part I},
pages = {353–365},
numpages = {13},
keywords = {Defect detection, Visual inspection, Uniformly distributed random number, Image generation, Random image}
}

@article{10.1016/j.procs.2018.05.115,
author = {Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita},
title = {Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.115},
doi = {10.1016/j.procs.2018.05.115},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {993–1001},
numpages = {9},
keywords = {Software fault prediction, Object Oriented Testing, Object Oriented Coupling, software faults prediction, machine learning}
}

@inproceedings{10.1007/978-3-030-61616-8_2,
author = {Li, Yajie and Chen, Yiqiang and Gu, Yang and Ouyang, Jianquan and Wang, Jiwei and Zeng, Ni},
title = {A Lightweight Fully Convolutional Neural Network of High Accuracy Surface Defect Detection},
year = {2020},
isbn = {978-3-030-61615-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61616-8_2},
doi = {10.1007/978-3-030-61616-8_2},
abstract = {Surface defect detection is an indispensable step in the production process. Recent researches based on deep learning have paid primarily attention to improving accuracy. However, it is difficult to apply in real situation, because of huge number of parameters and the strict hardware requirements. In this paper, a lightweight fully convolutional neural network, named LFCSDD, is proposed. The parameters of our model are 11x fewer than baselines at least, and obtain the accuracy of 99.72% and 98.74% on benchmark defect datasets, DAGM 2007 and KolektorSDD, respectively, outperforming all the baselines. In addition, our model can process the images with different sizes, which is verified on the RSDDs with the accuracy of 97.00%.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part II},
pages = {15–26},
numpages = {12},
keywords = {Lightweight, Convolutional neural network, Surface defect detection},
location = {Bratislava, Slovakia}
}

@article{10.1016/j.procs.2018.05.012,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A Nonlinear Manifold Detection based Model for Software Defect Prediction},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.012},
doi = {10.1016/j.procs.2018.05.012},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {581–594},
numpages = {14},
keywords = {Feature Selection techniques, Friedman test, Nonlinear Manifold Detection techniques, Paired two-tailed T-test, Software Defect Prediction}
}

@article{10.1049/sfw2.12012,
author = {Zou, Quanyi and Lu, Lu and Qiu, Shaojian and Gu, Xiaowei and Cai, Ziyi},
title = {Correlation feature and instance weights transfer learning for cross project software defect prediction},
year = {2021},
issue_date = {February 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {15},
number = {1},
url = {https://doi.org/10.1049/sfw2.12012},
doi = {10.1049/sfw2.12012},
abstract = {Due to the differentiation between training and testing data in the feature space, cross‐project defect prediction (CPDP) remains unaddressed within the field of traditional machine learning. Recently, transfer learning has become a research hot‐spot for building classifiers in the target domain using the data from the related source domains. To implement better CPDP models, recent studies focus on either feature transferring or instance transferring to weaken the impact of irrelevant cross‐project data. Instead, this work proposes a dual weighting mechanism to aid the learning process, considering both feature transferring and instance transferring. In our method, a local data gravitation between source and target domains determines instance weight, while features that are highly correlated with the learning task, uncorrelated with other features and minimizing the difference between the domains are rewarded with a higher feature weight. Experiments on 25 real‐world datasets indicate that the proposed approach outperforms the existing CPDP methods in most cases. By assigning weights based on the different contribution of features and instances to the predictor, the proposed approach is able to build a better CPDP model and demonstrates substantial improvements over the state‐of‐the‐art CPDP models.},
journal = {IET Software},
month = jan,
pages = {55–74},
numpages = {20},
keywords = {software reliability, pattern classification, learning (artificial intelligence)}
}

@article{10.4018/IJOSSP.2018010101,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P.S.},
title = {Combining Data Preprocessing Methods With Imputation Techniques for Software Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2018010101},
doi = {10.4018/IJOSSP.2018010101},
abstract = {Software Defect Prediction SDP models are used to predict, whether software is clean or buggy using the historical data collected from various software repositories. The data collected from such repositories may contain some missing values. In order to estimate missing values, imputation techniques are used, which utilizes the complete observed values in the dataset. The objective of this study is to identify the best-suited imputation technique for handling missing values in SDP dataset. In addition to identifying the imputation technique, the authors have investigated for the most appropriate combination of imputation technique and data preprocessing method for building SDP model. In this study, four combinations of imputation technique and data preprocessing methods are examined using the improved NASA datasets. These combinations are used along with five different machine-learning algorithms to develop models. The performance of these SDP models are then compared using traditional performance indicators. Experiment results show that among different imputation techniques, linear regression gives the most accurate imputed value. The combination of linear regression with correlation based feature selector outperforms all other combinations. To validate the significance of data preprocessing methods with imputation the findings are applied to open source projects. It was concluded that the result is in consistency with the above conclusion.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {1–19},
numpages = {19},
keywords = {Software Defect Prediction, Missing Value Imputation, Instance Selection, Feature Selection}
}

@inproceedings{10.1145/3474198.3478149,
author = {Cheng, Zhen and Luo, Xin and Shi, Youqun and Kita, Kenji},
title = {Fabric defect detection algorithm based on YOLOv3 Transfer learning},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478149},
doi = {10.1145/3474198.3478149},
abstract = {Fabric defect detection is an important part of controlling the quality of fabrics. Aiming at the low accuracy of manual detection methods and the difficulty of manual feature extraction in traditional machine learning methods, a transfer learning method based on YOLOv3 is proposed to achieve fabric defect detection. First, combined with the transfer learning principle, freeze the low layers of the network, and only retrain the parameters of certain layers in the higher layers with the fabric defect dataset. Then use the K-means algorithm to perform dimensional clustering to determine the anchor frame parameters. Finally, a detection layer is added before the third prediction scale in YOLOv3 to fuse the high semantic information of deep network with the high resolution of shallow layer to realize multi-scale fusion detection and improve the accuracy of fabric defect detection task. The experimental results show that the algorithm can effectively detect the surface defects of fabric image, and the accuracy rate is 88.87%. It has practical application value for fabric defect detection.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {69},
numpages = {7},
keywords = {YOLOv3, Transfer learning, K-means, Fabric defect, Deep learning},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@article{10.1049/iet-sen.2020.0119,
author = {Pandey, Sushant Kumar and Rathee, Deevashwer and Tripathi, Anil Kumar},
title = {Software defect prediction using K‐PCA and various kernel‐based extreme learning machine: an empirical study},
year = {2021},
issue_date = {December 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {7},
url = {https://doi.org/10.1049/iet-sen.2020.0119},
doi = {10.1049/iet-sen.2020.0119},
abstract = {Predicting defects during software testing reduces an enormous amount of testing effort and help to deliver a high‐quality software system. Owing to the skewed distribution of public datasets, software defect prediction (SDP) suffers from the class imbalance problem, which leads to unsatisfactory results. Overfitting is also one of the biggest challenges for SDP. In this study, the authors performed an empirical study of these two problems and investigated their probable solution. They have conducted 4840 experiments over five different classifiers using eight NASA projects and 14&nbsp;PROMISE repository datasets. They suggested and investigated the varying kernel function of an extreme learning machine (ELM) along with kernel principal component analysis (K‐PCA) and found better results compared with other classical SDP models. They used the synthetic minority oversampling technique as a sampling method to address class imbalance problems and k‐fold cross‐validation to avoid the overfitting problem. They found ELM‐based SDP has a high receiver operating characteristic curve over 11 out of 22 datasets. The proposed model has higher precision and F‐score values over ten and nine, respectively, compared with other state‐of‐the‐art models. The Mathews correlation coefficient (MCC) of 17 datasets of the proposed model surpasses other classical models' MCC.},
journal = {IET Software},
month = feb,
pages = {768–782},
numpages = {15},
keywords = {public datasets, software defect prediction, class imbalance problem, PROMISE repository datasets, kernel function, kernel principal component analysis, K‐PCA, classical SDP models, overfitting problem, ELM‐based SDP, high receiver operating characteristic curve, kernel‐based extreme learning machine, software testing, high‐quality software system, NASA projects, synthetic minority oversampling technique, sampling method, Mathews correlation coefficient, K, F, software quality, principal component analysis, program testing, learning (artificial intelligence), sampling methods}
}

@article{10.1016/j.ins.2018.02.027,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Czibula, Istvan Gergely},
title = {A novel approach for software defect prediction through hybridizing gradual relational association rules with artificial neural networks},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {441},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.02.027},
doi = {10.1016/j.ins.2018.02.027},
abstract = {The growing complexity of software projects requires increasing consideration of their analysis and testing. Identifying defective software entities is essential for software quality assurance and it also improves activities related to software testing. In this study, we developed a novel supervised classification method called HyGRAR for software defect prediction. HyGRAR is a non-linear hybrid model that combines gradual relational association rule mining and artificial neural networks to discriminate between defective and non-defective software entities. Experiments performed based on 10 open-source data sets demonstrated the excellent performance of the HYGRAR classifier. HyGRAR performed better than most of the previously proposed approaches for software defect prediction in performance evaluations using the same data sets.},
journal = {Inf. Sci.},
month = may,
pages = {152–170},
numpages = {19},
keywords = {Software defect prediction, Machine learning, Gradual relational association rule, Artificial neural network}
}

@article{10.1016/j.patrec.2020.12.006,
author = {Molinara, M. and Bria, A. and De Vito, S. and Marrocco, C.},
title = {Artificial intelligence for distributed smart systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2020.12.006},
doi = {10.1016/j.patrec.2020.12.006},
journal = {Pattern Recogn. Lett.},
month = feb,
pages = {48–50},
numpages = {3}
}

@inproceedings{10.1145/3239576.3239622,
author = {Yang, Zhao and Qian, Hongbing},
title = {Automated Parameter Tuning of Artificial Neural Networks for Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239622},
doi = {10.1145/3239576.3239622},
abstract = {Defect prediction can help predict defect-prone software modules and improve the efficiency and accuracy of defect location and repair, which plays an extremely important role in software quality assurance. Artificial Neural Networks (ANNs), a family of powerful machine learning regression or classification models, have been widely applied for defect prediction. However, the performance of these models will be degraded if they use suboptimal default parameter settings (e.g., the number of units in the hidden layer). This paper utilizes an automated parameter tuning technique-Caret to optimize parameter settings. In our study, 30 datasets are downloaded from the Tera-PROMISE Repository. According to the characteristics of the datasets, we select key features (metrics) as predictors to train defect prediction models. The experiment applies feed-forward, single hidden layer artificial neural network as classifier to build different defect prediction models respectively with optimized parameter settings and with default parameter settings. Confusion matrix and ROC curve are used for evaluating the quality of the models above. The results show that the models trained with optimized parameter settings outperform the models trained with default parameter settings. Hence, we suggest that researchers should pay attention to tuning parameter settings by Caret for ANNs instead of using suboptimal default settings if they select ANNs for training models in the future defect prediction studies.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {203–209},
numpages = {7},
keywords = {Software defect prediction, Metrics, Automated Parameter Tuning, Artificial Neural Networks},
location = {Chengdu, China},
series = {ICAIP '18}
}

@article{10.1155/2021/4997459,
author = {Li, Zhen and Li, Tong and Wu, YuMei and Yang, Liu and Miao, Hong and Wang, DongSheng and Precup, Radu-Emil},
title = {Software Defect Prediction Based on Hybrid Swarm Intelligence and Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4997459},
doi = {10.1155/2021/4997459},
abstract = {In order to improve software quality and testing efficiency, this paper implements the prediction of software defects based on deep learning. According to the respective advantages and disadvantages of the particle swarm algorithm and the wolf swarm algorithm, the two algorithms are mixed to realize the complementary advantages of the algorithms. At the same time, the hybrid algorithm is used in the search of model hyperparameter optimization, the loss function of the model is used as the fitness function, and the collaborative search ability of the swarm intelligence population is used to find the global optimal solution in multiple local solution spaces. Through the analysis of the experimental results of six data sets, compared with the traditional hyperparameter optimization method and a single swarm intelligence algorithm, the model using the hybrid algorithm has higher and better indicators. And, under the processing of the autoencoder, the performance of the model has been further improved.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {17}
}

@inproceedings{10.1145/3411201.3411701,
author = {He, Xinying and Wu, Liming and Song, Feiyang and Jiang, Danfeng and Zheng, Gengzhe},
title = {Research on Fabric Defect Detection Based on Deep Fusion DenseNet-SSD Network},
year = {2020},
isbn = {9781450377638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411201.3411701},
doi = {10.1145/3411201.3411701},
abstract = {Defect detection to control the quality of fabrics is one of the key tasks in the production process of fabrics. Although significant progress has been made in the research of fabric defect detection, while traditional methods are still difficult to cope with complex and variable defect shapes. In order to solve these problems, this paper proposes an adaptive fabric defect detection method based on DenseNet-SSD algorithm to improve the performance of fabric defect detection. This method uses the DenseNet network to replace the backbone network VGG16 in the SSD algorithm, which strengthens the transfer between feature maps, alleviates the problem of gradient disappearance and reduces the number of network parameters. Compared with SSD, it improves network detection accuracy and real-time performance. The accuracy in the test set is 78.6mAP and the detection speed is 61FPS.},
booktitle = {Proceedings of the 2020 International Conference on Wireless Communication and Sensor Networks},
pages = {60–64},
numpages = {5},
keywords = {SSD, DenseNet, Defect Detection, Deep Learning, Artificial Intelligence},
location = {Warsaw, Poland},
series = {icWCSN '20}
}

@article{10.1016/j.asoc.2015.04.045,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Software defect prediction using cost-sensitive neural network},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {33},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.04.045},
doi = {10.1016/j.asoc.2015.04.045},
abstract = {Software defect prediction model was built by Artificial Neural Network (ANN).ANN connection weights were optimized by Artificial Bee Colony (ABC).Parametric cost-sensitivity feature was added to ANN by using a new error function.Model was applied to five publicly available datasets from the NASA repository.Results were compared with other cost-sensitive and non-cost-sensitive studies. The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction.},
journal = {Appl. Soft Comput.},
month = aug,
pages = {263–277},
numpages = {15},
keywords = {Software quality, Software defect prediction, Machine learning, Cost-sensitive classification, Artificial Neural Network, Artificial Bee Colony}
}

@inproceedings{10.1145/3180374.3181331,
author = {Li, Yuting and Su, Jianmin and Yang, Xiaoxing},
title = {Multi-Objective vs. Single-Objective Approaches for Software Defect Prediction},
year = {2018},
isbn = {9781450354318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180374.3181331},
doi = {10.1145/3180374.3181331},
abstract = {Software defect prediction employs attributes of software modules to identify defect-prone modules and thus improves software reliability by allocating testing resources more efficiently. Realizing that single-objective methods might be insufficient for solving defect prediction problems, some researchers have proposed multi-objective learning approaches, and proved better performance of multi-objective than single-objective methods. However, existing compared single-objective methods optimize a completely different goal from goals of multi-objective approaches, which might lead to bias. In this paper, we compare a multi-objective approach that optimizes two objectives and a single-objective approach that directly optimizes a trade-off of the two objectives, in order to further investigate the comparison of multi-objective and single-objective approaches. The conclusion will help to appropriately choose multi-objective or single-objective learning approaches for defect prediction.},
booktitle = {Proceedings of the 2018 2nd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {122–127},
numpages = {6},
keywords = {software defect prediction, single-objective learning, effectiveness, cost, Multi-objective learning},
location = {Wuhan, China},
series = {ICMSS 2018}
}

@article{10.1016/j.artmed.2021.102165,
author = {de Siqueira, Vilson Soares and Borges, Mois\'{e}s Marcos and Furtado, Rog\'{e}rio Gomes and Dourado, Colandy Nunes and da Costa, Ronaldo Martins},
title = {Artificial intelligence applied to support medical decisions for the automatic analysis of echocardiogram images: A systematic review},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102165},
doi = {10.1016/j.artmed.2021.102165},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {19},
keywords = {Deep Learning, Machine Learning, Echocardiography, Echocardiogram}
}

@inproceedings{10.1145/2896387.2900324,
author = {Rahman, Md. Habibur and Sharmin, Sadia and Sarwar, Sheikh Muhammad and Shoyaib, Mohammad},
title = {Software Defect Prediction Using Feature Space Transformation},
year = {2016},
isbn = {9781450340632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896387.2900324},
doi = {10.1145/2896387.2900324},
abstract = {In software quality estimation research, software defect prediction is a key topic. A defect prediction model is generally constructed using a variety of software attributes and each attribute may have positive, negative or neutral effect on a specific model. Selection of an optimal set of attributes for model development remains a vital yet unexplored issue. In this paper, we have introduced a new feature space transformation process with a normalization technique to improve the defect prediction accuracy. We proposed a feature space transformation technique and classify the instances using Support Vector Machine (SVM) with its histogram intersection kernel. The proposed method is evaluated using the data sets from NASA metric data repository and its application demonstrates acceptable accuracy.},
booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
articleno = {72},
numpages = {6},
keywords = {Software defect prediction, Feature space transformation, Attribute selection},
location = {Cambridge, United Kingdom},
series = {ICC '16}
}

@inproceedings{10.1007/978-3-030-68799-1_20,
author = {Huang, Yu-Jen and Huang, Ko-Wei and Lee, Shih-Hsiung},
title = {Defect Detection of Stainless Steel Plates Using Deep Learning Technology},
year = {2021},
isbn = {978-3-030-68798-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68799-1_20},
doi = {10.1007/978-3-030-68799-1_20},
abstract = {In the era of industry 4.0, factories around the world are developing towards automation and artificial intelligence, in which industrial detection plays an important role. After the cutting process, the surface of a stainless steel plate may produce various defects, such as scratches, chisels, and stains. Due to the characteristic of bright reflections on the surface of a stainless steel plate, the traditional manual comparison detection method is time-consuming, laborious, and prone to different detection results due to the interference of high reflection, resulting in the outflow of defective products. This paper used existing mature deep learning models for object detection, YOLOv3 (You Only Look Once) and SSD (Single Shot MultiBox Detector), which are the base network architectures for the defect detection of stainless steel plates, in order to effectively improve the accuracy of stainless steel plate detection. Through image preprocessing, the relative positions of sample defects are marked to improve data processing before training, in order that a large number of image samples can be quickly and effectively processed for training.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part IV},
pages = {289–301},
numpages = {13},
keywords = {Object detection, Deep learning, Defect detection}
}

@inproceedings{10.1145/3028842.3028859,
author = {Gao, Yan and Yang, Chunhui},
title = {Software defect prediction based on manifold learning in subspace selection},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028859},
doi = {10.1145/3028842.3028859},
abstract = {Software defects will lead to software running error and system crashes. In order to detect software defect as early as possible at early stage of software development, a series of machine learning approaches have been studied and applied to predict defects in software modules. Unfortunately, the imbalanceof software defect datasets brings great challenge to software defect prediction model training. In this paper, a new manifold learning based subspace learning algorithm, Discriminative Locality Alignment(DLA), is introduced into software defects prediction. Experimental results demonstrate that DLA is consistently superior to LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) in terms of discriminate information extraction and prediction performance. In addition, DLA reveals some attractive intrinsic properties for numeric calculation, e.g. it can overcome the matrix singular problem and small sample size problem in software defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {17},
numpages = {6},
keywords = {support vector machine, software defect prediction, manifold learning, discriminative locality alignment},
location = {Wuhan, China},
series = {ICIIP '16}
}

@inproceedings{10.1007/978-3-030-87355-4_39,
author = {Xie, Huosheng and Lin, ShuFeng},
title = {A Weakly Supervised Defect Detection Based on Dual Path Networks and GMA-CAM},
year = {2021},
isbn = {978-3-030-87354-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87355-4_39},
doi = {10.1007/978-3-030-87355-4_39},
abstract = {In recent research, the defect detection algorithm based on the fully-supervised object detection model has become one of the research hotspots and has achieved good results. However, fully-supervised object detection models require image-level and localization-level labels. Obtaining these labels requires a great deal of manpower. Therefore, this paper proposes a dual path defect detection network (DPNET) based on weakly supervised object detection model, which aims to identify the classification label and carry on localization for defects merely by using image-level labels. Firstly, the paper employs the deep convolutional residual network ResNet-50 as a feature classification network for defect classification. Secondly, we designed a localization network based on the global average-max pooling class activation map (GAM-CAM) and the Full Convolutional Channel Attention (FCCA) for defect localization, which can improve the defect localization accuracy. Experimental results on the DAGM dataset confirm that the proposed detection model is able to efficiently detect defects.},
booktitle = {Image and Graphics: 11th International Conference, ICIG 2021, Haikou, China, August 6–8, 2021, Proceedings, Part I},
pages = {467–478},
numpages = {12},
keywords = {Full Convolutional Channel Attention, Global average-max pooling class activation map, Dual Path Network, Weakly supervised object detection, Defect detection},
location = {Haikou, China}
}

@inproceedings{10.1109/ICSE.2019.00076,
author = {Cabral, George G. and Minku, Leandro L. and Shihab, Emad and Mujahid, Suhaib},
title = {Class imbalance evolution and verification latency in just-in-time software defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00076},
doi = {10.1109/ICSE.2019.00076},
abstract = {Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that rebuild classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency - the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {666–676},
numpages = {11},
keywords = {verification latency, software defect prediction, online learning, ensembles, concept drift, class imbalance},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1016/j.neucom.2018.04.090,
author = {Malhotra, Ruchika and Kamal, Shine},
title = {An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.090},
doi = {10.1016/j.neucom.2018.04.090},
journal = {Neurocomput.},
month = may,
pages = {120–140},
numpages = {21},
keywords = {Procedural metrics, Machine learning techniques, MetaCost learners, Oversampling methods, Imbalanced data, Defect prediction}
}

@inproceedings{10.1145/3490725.3490739,
author = {Shi, Linlin and Yu, Pengfei and He, Shilie and Zhou, Zhenwei and Meng, Linghui and Liu, Junbin},
title = {Degradation Characteristics Analysis and Fault Prediction of Switching Power Supply Based on Data Mining},
year = {2022},
isbn = {9781450384247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490725.3490739},
doi = {10.1145/3490725.3490739},
abstract = {Fault prediction and health monitoring of DC-DC switching power supply plays an important role in the safe and reliable operation of power electronic equipment. In this paper, a long-term high temperature degradation test was carried out for DC-DC power supply, and the characteristic parameters related to device health, such as input current, input voltage, output current and output voltage, were collected during the test. Through data mining technology, we carry out data preprocessing, feature analysis, health index modeling and fault prediction analysis on the samples collected in the power supply test, so as to study the degradation and fault predictor of the power supply from the real power supply test degradation data. The research results of this paper have important engineering significance for the monitoring and health prediction of power supply.},
booktitle = {Proceedings of the 2021 4th International Conference on Machine Learning and Machine Intelligence},
pages = {89–98},
numpages = {10},
keywords = {feature analysis, Fault Prediction, Data Mining, DC-DC power supply},
location = {Hangzhou, China},
series = {MLMI '21}
}

@inproceedings{10.4108/icst.bict.2014.257871,
author = {Malhotra, Ruchika and Raje, Rajeev},
title = {An empirical comparison of machine learning techniques for software defect prediction},
year = {2014},
isbn = {9781631900532},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bict.2014.257871},
doi = {10.4108/icst.bict.2014.257871},
abstract = {Software systems are exposed to various types of defects. The timely identification of defective classes is essential in early phases of software development to reduce the cost of testing the software. This will guide the software practitioners and researchers for planning of the proper allocation of testing resources. Software metrics can be used in conjunction with defect data to develop models for predicting defective classes. There have been various machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems in less time. However, more studies comparing these techniques are needed to provide evidence so that confidence is established on the performance of one technique over the other. In this paper we address four issues (i) comparison of the machine learning techniques over unpopular used data sets (ii) use of inappropriate performance measures for measuring the performance of defect prediction models (iii) less use of statistical tests and (iv) validation of models from the same data set from which they are trained. To resolve these issues, in this paper, we compare 18 machine learning techniques for investigating the effect of Object-Oriented metrics on defective classes. The results are validated on six releases of the 'MMS' application package of recent widely used mobile operating system -- Android. The overall results of the study indicate the predictive capability of the machine learning techniques and an endorsement of one particular ML technique to predict defects.},
booktitle = {Proceedings of the 8th International Conference on Bioinspired Information and Communications Technologies},
pages = {320–327},
numpages = {8},
keywords = {object-oriented metrics, machine learning, empirical validation, defect prediction},
location = {Boston, Massachusetts},
series = {BICT '14}
}

@inproceedings{10.1145/3483207.3483212,
author = {Yao, Yong and Wei, Siwen and Wang, Jing},
title = {Surface Defect Detection of Aircraft Flared Duct Based on Improved YOLOv4 Algorithm},
year = {2021},
isbn = {9781450390170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483207.3483212},
doi = {10.1145/3483207.3483212},
abstract = {In order to solve the problems of low detection accuracy, slow detection speed and low detection efficiency existing in traditional methods, an improved YOLOv4 algorithm for the surface defect detection of aircraft flared duct is proposed. Firstly, convolutional layers are added to improve the ability of network to extract defect features, and the layers change in the backbone feature extraction network output and the spatial pyramid pooling structure in the YOLOv4 network. Secondly, the aircraft flared ducts with surface defects datasets is made, and the K-means++ clustering algorithm is put forward to cluster the defect samples to obtain the priors anchor's parameters of different sizes. Finally, due to the uneven distribution of defects, we add rotation detection and improved loss function to improve defect detection capabilities. Experiments show that the mAP value of the improved YOLOv4 algorithm on the test set reaches 91.11%, which is 7.50% higher than original YOLOv4 model. The average detection time for each image is 0.1573s, and the detection performance is optimized.},
booktitle = {Proceedings of the 2021 4th International Conference on Signal Processing and Machine Learning},
pages = {26–32},
numpages = {7},
location = {Beijing, China},
series = {SPML '21}
}

@article{10.1016/j.infsof.2017.11.008,
author = {Tong, Haonan and Liu, Bin and Wang, Shihai},
title = {Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning},
year = {2018},
issue_date = {Apr 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {96},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.11.008},
doi = {10.1016/j.infsof.2017.11.008},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {94–111},
numpages = {18},
keywords = {Deep learning, Software metrics, Ensemble learning, Stacked denoising autoencoders, Software defect prediction}
}

@inproceedings{10.1145/3395260.3395296,
author = {Li, Zhang and Weimin, Chen},
title = {Key Technology of Artificial Intelligence in Hull Form Intelligent Optimization},
year = {2020},
isbn = {9781450377072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395260.3395296},
doi = {10.1145/3395260.3395296},
abstract = {Hull form optimization is an important aspect of ship hydrodynamic research, and the primary target of ship design. More and more researchers are focusing on hull form intelligent optimization in recent years. First of all, this paper summarizes the development of ship hull form optimization, as well as the technology used. Then the principle of ship optimization is summarized, and on this basis, the function and framework of ship intelligent optimization are summarized. The key technologies in the process of intelligent optimization are contributed: 1) Non-Uniform Rational B-Splines(NURBS) surface generation technology, including parametric modeling technology and non-parametric modeling technology; 2) surrogate model technology, including artificial neural network(ANN), machine learning(ML) and deep learning(DL); 3) optimization algorithm, including genetic algorithm(GA), ant colony algorithm(ACA) and artificial bee colony algorithm(ABC). Finally, the difficulties and challenges of the key technologies are analyzed. Based on artificial intelligence technology, hull form optimization can effectively improve its efficiency and provide key technical support for ship intelligent optimization.},
booktitle = {Proceedings of the 2020 5th International Conference on Mathematics and Artificial Intelligence},
pages = {167–171},
numpages = {5},
keywords = {hull form optimization, genetic algorithm, deep learning, artificial intelligence, NURBS},
location = {Chengdu, China},
series = {ICMAI '20}
}

@article{10.1504/ijcat.2019.100297,
author = {Jayanthi, R. and Florence, M. Lilly},
title = {Improved Bayesian regularisation using neural networks based on feature selection for software defect prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {60},
number = {3},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2019.100297},
doi = {10.1504/ijcat.2019.100297},
abstract = {Demand for software-based applications has grown drastically in various real-time applications. However, software testing schemes have been developed which include manual and automatic testing. Manual testing requires human effort and chances of error may still affect the quality of software. To overcome this issue, automatic software testing techniques based on machine learning techniques have been developed. In this work, we focus on the machine learning scheme for early prediction of software defects using Levenberg-Marquardt algorithm (LM), Back Propagation (BP) and Bayesian Regularisation (BR) techniques. Bayesian regularisation achieves better performance in terms of bug prediction. However, this performance can be enhanced further. Hence, we developed a novel approach for attribute selection-based feature selection technique to improve the performance of BR classification. An extensive study is carried out with the PROMISE repository where we considered KC1 and JM1 datasets. Experimental study shows that the proposed approach achieves better performance in predicting the defects in software.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {225–241},
numpages = {16},
keywords = {adaptive computation process, cross entropy error function, feature subset selection, gradient-based approach, gradient descent optimisation, software metrics, software defect prediction, machine learning techniques, defect prediction model}
}

@inproceedings{10.1145/3469213.3471336,
author = {Xu, Yichen and Meng, Fanwu and Wang, Lizhong and Zhang, Mingyi and Wu, Changshuo},
title = {Fabric Surface Defect Detection Based on GMRF Model},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3471336},
doi = {10.1145/3469213.3471336},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {307},
numpages = {4},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1016/j.procs.2020.03.272,
author = {Soni, Neha and Sharma, Enakshi Khular and Singh, Narotam and Kapoor, Amita},
title = {Artificial Intelligence in Business: From Research and Innovation to Market Deployment},
year = {2020},
issue_date = {2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {167},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2020.03.272},
doi = {10.1016/j.procs.2020.03.272},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {2200–2210},
numpages = {11},
keywords = {Artificial Intelligence, Fourth Industrial Revolution, Business Analytics, Machine Learning, Deep Learning, Business Intelligence}
}

@article{10.1007/s10515-016-0194-x,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wang, Tie-Jian},
title = {Label propagation based semi-supervised learning for software defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-016-0194-x},
doi = {10.1007/s10515-016-0194-x},
abstract = {Software defect prediction can automatically predict defect-prone software modules for efficient software test in software engineering. When the previous defect labels of modules are limited, predicting the defect-prone modules becomes a challenging problem. In static software defect prediction, there exist the similarity among software modules, a software module can be approximated by a sparse representation of the other part of the software modules, and class-imbalance problem, the number of defect-free modules is much larger than that of defective ones. In this paper, we propose to use graph based semi-supervised learning technique to predict software defect. By using Laplacian score sampling strategy for the labeled defect-free modules, we construct a class-balance labeled training dataset firstly. And then, we use a nonnegative sparse algorithm to compute the nonnegative sparse weights of a relationship graph which serve as clustering indicators. Lastly, on the nonnegative sparse graph, we use a label propagation algorithm to iteratively predict the labels of unlabeled software modules. We thus propose a nonnegative sparse graph based label propagation approach for software defect classification and prediction, which uses not only few labeled data but also abundant unlabeled ones to improve the generalization capability. We vary the size of labeled software modules from 10 to 30 % of all the datasets in the widely used NASA projects. Experimental results show that the NSGLP outperforms several representative state-of-the-art semi-supervised software defect prediction methods, and it can fully exploit the characteristics of static code metrics and improve the generalization capability of the software defect prediction model.},
journal = {Automated Software Engg.},
month = mar,
pages = {47–69},
numpages = {23},
keywords = {Software defect prediction, Semi-supervised learning, Nonnegative sparse graph based label propagation (NSGLP), Nonnegative sparse graph, Label propagation}
}

@inproceedings{10.1145/3238147.3240469,
author = {Qu, Yu and Liu, Ting and Chi, Jianlei and Jin, Yangxu and Cui, Di and He, Ancheng and Zheng, Qinghua},
title = {node2defect: using network embedding to improve software defect prediction},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240469},
doi = {10.1145/3238147.3240469},
abstract = {Network measures have been proved to be useful in predicting software defects. Leveraging the dependency relationships between software modules, network measures can capture various structural features of software systems. However, existing studies have relied on user-defined network measures (e.g., degree statistics or centrality metrics), which are inflexible and require high computation cost, to describe the structural features. In this paper, we propose a new method called node2defect which uses a newly proposed network embedding technique, node2vec, to automatically learn to encode dependency network structure into low-dimensional vector spaces to improve software defect prediction. Specifically, we firstly construct a program's Class Dependency Network. Then node2vec is used to automatically learn structural features of the network. After that, we combine the learned features with traditional software engineering features, for accurate defect prediction. We evaluate our method on 15 open source programs. The experimental results show that in average, node2defect improves the state-of-the-art approach by 9.15% in terms of F-measure.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {844–849},
numpages = {6},
keywords = {software metrics, network embedding, defect prediction, Software defect},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1007/s10462-017-9563-5,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A study on software fault prediction techniques},
year = {2019},
issue_date = {February  2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {2},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9563-5},
doi = {10.1007/s10462-017-9563-5},
abstract = {Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed.},
journal = {Artif. Intell. Rev.},
month = feb,
pages = {255–327},
numpages = {73},
keywords = {Taxonomic classification, Software metrics, Software fault prediction, Software fault datasets, Fault prediction techniques}
}

@inproceedings{10.1007/978-3-030-59003-1_27,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy and Kryvinska, Natalia},
title = {An Improved Software Defect Prediction Algorithm Using Self-organizing Maps Combined with Hierarchical Clustering and Data Preprocessing},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_27},
doi = {10.1007/978-3-030-59003-1_27},
abstract = {An improved software defects prediction algorithm based on combination of Kohonen map and hierarchical clustering is presented in this paper. The need for software reliability assessment and analysis growths rapidly due to increasing dependence of our day-to-day life on software-controlled devices and systems. Software reliability prediction is the only tool available at early stage of software development lifecycle when the debugging cost risk of faulty operation is minimal. Artificial intelligence and machine learning in particular are promising techniques to solve this task. Various classification methods have been used previously to build software defect prediction models, ranging from simple, like logistic regression, to advanced methods, e.g. multivariate adaptive regression splicing. However, the available literature still does not allow to make unambiguous conclusion concerning the choice of the best classifier and trying different dimensions to overcome potential bias is suggested. The purpose of the paper is to analyze the software code metrics to find dependences be-tween software module’s defect-proneness and its metrics. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. To increase the classification accuracy, we combine self-organizing maps with hierarchical clustering and data preprocessing.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {414–424},
numpages = {11},
keywords = {Prediction algorithm, Hierarchical clustering, Software defect analysis},
location = {Bratislava, Slovakia}
}

@article{10.1007/s00607-016-0538-1,
author = {Gupta, Shivani and Gupta, Atul},
title = {A set of measures designed to identify overlapped instances in software defect prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {9},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-016-0538-1},
doi = {10.1007/s00607-016-0538-1},
abstract = {The performance of the learning models will intensely rely on the characteristics of the training data. The previous outcomes recommend that the overlapping between classes and the presence of noise have the most grounded impact on the performance of learning algorithm, and software defect datasets are no exceptions. The class overlap problem is concerned with the performance of machine learning classifiers critical problem is class overlap in which data samples appear as valid examples of more than one class which may be responsible for the presence of noise in datasets. We aim to investigate how the presence of overlapped instances in a dataset influences the classifier's performance, and how to deal with class overlapping problem. To have a close estimate of class overlapping, we have proposed four different measures namely, nearest enemy ratio, subconcept ratio, likelihood ratio and soft margin ratio. We performed our investigations using 327 binary defect classification datasets obtained from 54 software projects, where we first identified overlapped datasets using three data complexity measures proposed in the literature. We also include treatment effort into the prediction process. Subsequently, we used our proposed measures to find overlapped instances in the identified overlapped datasets. Our results indicated that by training a classifier on a training data free from overlapped instances led to an improved classifier performance on the test data containing overlapped instances. The classifiers perform significantly better when the evaluation measure takes the effort into account.},
journal = {Computing},
month = sep,
pages = {889–914},
numpages = {26},
keywords = {Software defect prediction, Machine learning, Data mining, Data complexity measures, Class overlapping}
}

@article{10.1155/2020/8852705,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang and Briola, Daniela},
title = {Software Defect Prediction Based on Fuzzy Weighted Extreme Learning Machine with Relative Density Information},
year = {2020},
issue_date = {2020},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2020},
issn = {1058-9244},
url = {https://doi.org/10.1155/2020/8852705},
doi = {10.1155/2020/8852705},
abstract = {To identify software modules that are more likely to be defective, machine learning has been used to construct software defect prediction (SDP) models. However, several previous works have found that the imbalanced nature of software defective data can decrease the model performance. In this paper, we discussed the issue of how to improve imbalanced data distribution in the context of SDP, which can benefit software defect prediction with the aim of finding better methods. Firstly, a relative density was introduced to reflect the significance of each instance within its class, which is irrelevant to the scale of data distribution in feature space; hence, it can be more robust than the absolute distance information. Secondly, a K-nearest-neighbors-based probability density estimation (KNN-PDE) alike strategy was utilised to calculate the relative density of each training instance. Furthermore, the fuzzy memberships of sample were designed based on relative density in order to eliminate classification error coming from noise and outlier samples. Finally, two algorithms were proposed to train software defect prediction models based on the weighted extreme learning machine. This paper compared the proposed algorithms with traditional SDP methods on the benchmark data sets. It was proved that the proposed methods have much better overall performance in terms of the measures including G-mean, AUC, and Balance. The proposed algorithms are more robust and adaptive for SDP data distribution types and can more accurately estimate the significance of each instance and assign the identical total fuzzy coefficients for two different classes without considering the impact of data scale.},
journal = {Sci. Program.},
month = jan,
numpages = {18}
}

@inproceedings{10.1007/978-3-030-85607-6_20,
author = {Ardito, Carmelo and Deldjoo, Yashar and Di Sciascio, Eugenio and Nazary, Fatemeh and Sapienza, Gianluca},
title = {ISCADA: Towards a Framework for&nbsp;Interpretable Fault Prediction in&nbsp;Smart Electrical Grids},
year = {2021},
isbn = {978-3-030-85606-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85607-6_20},
doi = {10.1007/978-3-030-85607-6_20},
abstract = {This paper reports ongoing research for the definition of a data-driven self-healing system using machine learning (ML) techniques that can perform automatic and timely detection of fault types and locations. Specifically, the proposed method makes use of spectrogram-based CNN modeling of the 3-phase voltage signals. Furthermore, to keep human operators informed about why certain decisions were made, i.e., to facilitate the interpretability of the black-box ML model, we propose a novel explanation approach that highlight regions in the input spectrogram that contributed the most for the prediction task at hand (e.g., fault type or location) - or visual explanation.},
booktitle = {Human-Computer Interaction – INTERACT 2021: 18th IFIP TC 13 International Conference, Bari, Italy, August 30 – September 3, 2021, Proceedings, Part V},
pages = {270–274},
numpages = {5},
keywords = {Fault prediction, Interpretability, Self-healing system},
location = {Bari, Italy}
}

@inproceedings{10.1145/2591062.2591151,
author = {Jing, Xiao-Yuan and Zhang, Zhi-Wu and Ying, Shi and Wang, Feng and Zhu, Yang-Ping},
title = {Software defect prediction based on collaborative representation classification},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591151},
doi = {10.1145/2591062.2591151},
abstract = {In recent years, machine learning techniques have been successfully applied into software defect prediction. Although they can yield reasonably good prediction results, there still exists much room for improvement on the aspect of prediction accuracy. Sparse representation is one of the most advanced machine learning techniques. It performs well with respect to signal compression and classification, but suffers from its time-consuming sparse coding. Compared with sparse representation, collaborative representation classification (CRC) can yield significantly lower computational complexity and competitive classification performance in pattern recognition domains. To achieve better defect prediction results, we introduce the CRC technique in this paper and propose a CRC based software defect prediction (CSDP) approach. We first design a CRC based learner to build a prediction model, whose computational burden is low. Then, we design a CRC based predictor to classify whether the query software modules are defective or defective-free. Experimental results on the widely used NASA datasets demonstrate the effectiveness and efficiency of the proposed approach.},
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {632–633},
numpages = {2},
keywords = {Software defect prediction, Prediction model, Machine learning, Collaborative representation classification},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/2970276.2970288,
author = {Schw\"{a}gerl, Felix and Westfechtel, Bernhard},
title = {SuperMod: tool support for collaborative filtered model-driven software product line engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970288},
doi = {10.1145/2970276.2970288},
abstract = {The increase in productivity implied by model-driven software product line engineering is weakened by the complexity exposed to the user having to manage a multi-variant model. Recently, a new paradigm has emerged: filtered software product line engineering transfers the established check-out/modify/commit workflow from version control to variability management, allowing to iteratively develop the multi-variant model in a single-variant view. This paper demonstrates SuperMod, a tool that supports collaborative filtered model-driven product line engineering, implemented for and with the Eclipse Modeling Framework. Concerning variability management, the tool offers capabilities for editing feature models and specifying feature configurations, both being well-known formalisms in product line engineering. Furthermore, collaborative editing of product lines is provided through distributed version control. The accompanying video shows that SuperMod seamlessly integrates into existing tool landscapes, reduces the complexity of multi-variant editing, automates a large part of variability management, and ensures consistency. A tool demonstration video is available here: http://youtu.be/5XOk3x5kjFc},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {822–827},
numpages = {6},
keywords = {version control, software product line engineering, filtered editing, Model-driven software engineering},
location = {Singapore, Singapore},
series = {ASE '16}
}

@article{10.1016/j.jss.2019.03.012,
author = {Ni, Chao and Chen, Xiang and Wu, Fangfang and Shen, Yuxiang and Gu, Qing},
title = {An empirical study on pareto based multi-objective feature selection for software defect prediction},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.012},
doi = {10.1016/j.jss.2019.03.012},
journal = {J. Syst. Softw.},
month = jun,
pages = {215–238},
numpages = {24},
keywords = {Empirical study, Multi-Objective optimization, Feature selection, Search based software engineering, Software defect prediction, xx-xx, xx-xx}
}

@inproceedings{10.1145/3472163.3472172,
author = {Wiese, Lena and Wiese, Ingmar and Lietz, Kristina},
title = {Software Quality Assessment of a Web Application for Biomedical Data Analysis},
year = {2021},
isbn = {9781450389914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472163.3472172},
doi = {10.1145/3472163.3472172},
abstract = {Data Science as a multidisciplinary discipline has seen a massive transformation in the direction of operationalisation of analysis workflows. Yet it can be observed that such a workflow consists of potentially many diverse components: like modules in different programming languages, database backends, or web frontends. In order to achieve high efficiency and reproducibility of the analysis, a sufficiently high level of software engineering for the different components as well as an overall software architecture that integrates and automates the different components is needed. For the use case of gene expression analysis, from a software quality point of view we analyze a newly developed web application that allows user-friendly access to the underlying workflow.},
booktitle = {Proceedings of the 25th International Database Engineering &amp; Applications Symposium},
pages = {84–93},
numpages = {10},
keywords = {Web service, Software quality, Gene expression analysis, Data Science workflow},
location = {Montreal, QC, Canada},
series = {IDEAS '21}
}

@article{10.1049/iet-sen.2017.0111,
author = {Qiu, Shaojian and Lu, Lu and Jiang, Siyu},
title = {Multiple‐components weights model for cross‐project software defect prediction},
year = {2018},
issue_date = {August 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2017.0111},
doi = {10.1049/iet-sen.2017.0111},
abstract = {Software defect prediction (SDP) technology is receiving widely attention and most of SDP models are trained on data from the same project. However, at an early phase of the software lifecycle, there are little to no within‐project training data to learn an available supervised defect‐prediction model. Thus, cross‐project defect prediction (CPDP), which is learning a defect predictor for a target project by using labelled data from a source project, has shown promising value in SDP. To better perform the CPDP, most current studies focus on filtering instances or selecting features to weaken the impact of irrelevant cross‐project data. Instead, the authors propose a novel multiple‐components weights (MCWs) learning model to analyse the varying auxiliary power of multiple components in a source project to construct a more precise ensemble classifiers for a target project. By combining the MCW model with kernel mean matching algorithm, their proposed approach adjusts the source‐instance weights and source‐component weights to jointly alleviate the negative impacts of irrelevant cross‐project data. They conducted comprehensive experiments by employing 15 real‐world datasets to demonstrate the advantages and effectiveness of their proposed approach.},
journal = {IET Software},
month = aug,
pages = {345–355},
numpages = {11},
keywords = {MCW learning model, Multiple-components weights model, within-project training data, software lifecycle, SDP models, cross-project software defect prediction, source-component weights, source-instance weights, MCW model, CPDP, cross-project defect prediction, software quality, learning (artificial intelligence)}
}

@article{10.1016/j.eswa.2021.114820,
author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
title = {Machine Learning for industrial applications: A comprehensive literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114820},
doi = {10.1016/j.eswa.2021.114820},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {29},
keywords = {Operation management, Machine Learning, Deep Learning, Industrial applications, Literature review}
}

@article{10.1155/2019/2384706,
author = {Yang, Xingguang and Yu, Huiqun and Fan, Guisheng and Shi, Kai and Chen, Liqiong and Tramontana, Emiliano},
title = {Local versus Global Models for Just-In-Time Software Defect Prediction},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/2384706},
doi = {10.1155/2019/2384706},
abstract = {Just-in-time software defect prediction (JIT-SDP) is an active topic in software defect prediction, which aims to identify defect-inducing changes. Recently, some studies have found that the variability of defect data sets can affect the performance of defect predictors. By using local models, it can help improve the performance of prediction models. However, previous studies have focused on module-level defect prediction. Whether local models are still valid in the context of JIT-SDP is an important issue. To this end, we compare the performance of local and global models through a large-scale empirical study based on six open-source projects with 227417 changes. The experiment considers three evaluation scenarios of cross-validation, cross-project-validation, and timewise-cross-validation. To build local models, the experiment uses the k-medoids to divide the training set into several homogeneous regions. In addition, logistic regression and effort-aware linear regression (EALR) are used to build classification models and effort-aware prediction models, respectively. The empirical results show that local models perform worse than global models in the classification performance. However, local models have significantly better effort-aware prediction performance than global models in the cross-validation and cross-project-validation scenarios. Particularly, when the number of clusters k is set to 2, local models can obtain optimal effort-aware prediction performance. Therefore, local models are promising for effort-aware JIT-SDP.},
journal = {Sci. Program.},
month = jan,
numpages = {13}
}

@inproceedings{10.1145/3239576.3239607,
author = {Du, Yuntao and Zhang, Lu and Shi, Jiahao and Tang, Jingjuan and Yin, Ying},
title = {Feature-Grouping-Based Two Steps Feature Selection Algorithm in Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239607},
doi = {10.1145/3239576.3239607},
abstract = {In order to improve the effect of software defect prediction, many algorithms including feature selection, have been proposed. Based on Wrapper and Filter hybrid framework, a feature-grouping-based feature selection algorithm is proposed in this paper. The algorithm is composed of two steps. In the first step, in order to remove the redundant features, we group the features according to the redundancy between the features. The symmetry uncertainty is used as the constant indicator of the correlation and the FCBF-based grouping algorithm is used to group the features. In the second step, a subset of the features are selected from each group to form the final subset of features. Many classical methods select the representative feature from each group. We consider that when the number of intra-group features is large, the representative features are not enough to reflect the information in this group. Therefore, we require that at least one feature be selected within each group, in this step, the PSO algorithm is used for Searching Randomly from each group. We tested on the open source NASA and PROMISE data sets. Using three kinds of classifier. Compared to the other methods tested in this article, our method resulted in 90% improvement in the predictive performance of 30 sets of results on 10 data sets. Compared with the algorithms without feature selection, the AUC values of this method in the Logistic regression, Naive Bayesian, and K-neighbor classifiers are improved by 5.94% and 4.69% And 8.05%. The FCBF algorithm can also be regarded as a kind of first performing feature grouping. Compared with the FCBF algorithm, the AUC values of this method are improved by 4.78%, 6.41% and 4.4% on the basis of Logistic regression, Naive Bayes and K-neighbor. We can also see that for the FCBF-based grouping algorithm, it could be better to choose a characteristic cloud from each group than to choose a representative one.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {173–178},
numpages = {6},
keywords = {Software defect prediction, PSO, Intra-group feature selection, Feature grouping, FCBF-based grouping algorithm},
location = {Chengdu, China},
series = {ICAIP '18}
}

@inproceedings{10.1145/3297156.3297187,
author = {Liu, Kun and Luo, Nana and Ren, Yafei},
title = {A Contrast Pre-adjusted Defect Detection of Strip Steel Surface by Total Variation-based Image Decomposition},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297187},
doi = {10.1145/3297156.3297187},
abstract = {Automatic vision-based defect detection on the strip steel surface is a challenging task due to miscellaneous patterns of defects, low contrast of the image. Traditional methods mainly distinguish the defects from the background by analyzing textural information. In this paper, a novel defect detection method by total variation-based image decomposition is developed to extract abnormal region from repetitive texture. Specially, a contrast-adjusted step is designed for the image decomposition, which can compress the dynamic range of the background brightness and enhance the contrast effectively. Furthermore, the histogram of the enhanced image shows multi-peak characteristics, which greatly contributes to the subsequent image decomposition. Next, the total variation-based image decomposition is developed for the contrast-adjusted image to extract structural map. Finally, the abnormal regions can be located only by an adaptive threshold in the structural map. The proposed method can be extended to detect the defects on other regularly textured surface, even under the low signal-to-noise ratio condition. The experiments show that the performance of the proposed algorithm is better than the state-of-art algorithms.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {327–333},
numpages = {7},
keywords = {Low SNR, Image decomposition, Defect detection, Contrast enhancement},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1145/3404709.3404765,
author = {Shen, Jau-Ji and Lee, Chin-Feng and Chen, Yu-Chuan and Agrawal, Somya},
title = {Unsupervised Defect Detection based on Boundary Equilibrium Generative Adversarial Network},
year = {2020},
isbn = {9781450375337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404709.3404765},
doi = {10.1145/3404709.3404765},
abstract = {In addition to the brand and sales channels that can be found everywhere in the shoe industry, the foundry manufacturing industry is also an important part of the industrial chain. The traditional shoe industry has high manpower requirements but a low ratio of information personnel and high-tech equipment. Many testing procedures can only be performed manually.The complexity of footwear products is high, and the entire inspection process depends on a large amount of manpower. Therefore, problems such as consuming too much manpower, lack of efficiency, difficulty in precise inspection, quality requirements that vary from person to person, and incomplete quality management are extended. Through traditional machine learning methods, most of them are supervised learning methods. Under this method, a large number of negative samples should be always collected. It is very difficult to collect these negative samples in actual industrial production.Therefore, this article proposes a defect detection model based on unsupervised learning. As long as there are enough positive samples to be trained, we use the BEGAN model to modify it and combine another Autoencoder. This model is much easier and faster to be trained than the traditional GAN model, better responding to the footwear industry with more product types.},
booktitle = {Proceedings of the 6th International Conference on Frontiers of Educational Technologies},
pages = {178–182},
numpages = {5},
keywords = {unsupervised learning, image recognition, generative adversarial networks, defect detection, autoencoder},
location = {Tokyo, Japan},
series = {ICFET '20}
}

@inproceedings{10.1007/978-3-030-27538-9_49,
author = {Qin, Shujia and Guo, Di and Chen, Heping and Xi, Ning},
title = {Non-concentric Circular Texture Removal for Workpiece Defect Detection},
year = {2019},
isbn = {978-3-030-27537-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27538-9_49},
doi = {10.1007/978-3-030-27538-9_49},
abstract = {Since workpiece defect detection is a typical problem in computer vision with small datasets, generally its solutions cannot exploit the advantages of high accuracy, generalization ability, and neural network structures from the deep learning paradigm. Thus, traditional image processing techniques are still widely applied in such requirements. Aiming at three types of defects (crack, pitting and scratch) on a workpiece with non-concentric circular textures that severely interfere in the defect recognition stage, this paper proposes a sliding window filter for the texture detection. Experiments compare the proposed method with the polar coordinate mapping method and the T-smooth texture removal algorithm. Results show that the proposed method reveals the three types of defects better than the other two methods.},
booktitle = {Intelligent Robotics and Applications: 12th International Conference, ICIRA 2019, Shenyang, China, August 8–11, 2019, Proceedings, Part IV},
pages = {576–584},
numpages = {9},
keywords = {Small dataset, Non-concentric circle, Defect detection},
location = {Shenyang, China}
}

@article{10.1016/j.asoc.2017.01.050,
author = {Maua, Goran and Galinac Grbac, Tihana},
title = {Co-evolutionary multi-population genetic programming for classification in software defect prediction},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {55},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.01.050},
doi = {10.1016/j.asoc.2017.01.050},
abstract = {Evolving diverse ensembles using genetic programming has recently been proposed for classification problems with unbalanced data. Population diversity is crucial for evolving effective algorithms. Multilevel selection strategies that involve additional colonization and migration operations have shown better performance in some applications. Therefore, in this paper, we are interested in analysing the performance of evolving diverse ensembles using genetic programming for software defect prediction with unbalanced data by using different selection strategies. We use colonization and migration operators along with three ensemble selection strategies for the multi-objective evolutionary algorithm. We compare the performance of the operators for software defect prediction datasets with varying levels of data imbalance. Moreover, to generalize the results, gain a broader view and understand the underlying effects, we replicated the same experiments on UCI datasets, which are often used in the evolutionary computing community. The use of multilevel selection strategies provides reliable results with relatively fast convergence speeds and outperforms the other evolutionary algorithms that are often used in this research area and investigated in this paper. This paper also presented a promising ensemble strategy based on a simple convex hull approach and at the same time it raised the question whether ensemble strategy based on the whole population should also be investigated.},
journal = {Appl. Soft Comput.},
month = jun,
pages = {331–351},
numpages = {21},
keywords = {Software defect prediction, Genetic programming, Coevolution, Classification}
}

@phdthesis{10.5555/AAI29159899,
author = {Arar, \"{O}mer Faruk and undefinedBrahim, \"{O}Z\c{c}elik, and G\"{u}ltekin, \c{C}agil, and Pakize, Erdogmu\c{s}, and Onay, Durdu, Pinar},
advisor = {K\"{u}r\c{s}at, Ayan,},
title = {Makine \"{o}\u{g}renme algoritmalar\i{} kullan\i{}larak yaz\i{}l\i{}m Hata Kestiriminin iyile\c{s}tirilmesi / Using Machine Learning Algorithms to Improve Software Defect Prediction},
year = {2016},
isbn = {9798835589593},
publisher = {Sakarya Universitesi (Turkey)},
abstract = {Yaz\i{}l\i{}m sistemleri g\"{u}nl\"{u}k ya\c{s}ant\i{}m\i{}zda \c{c}ok \"{o}nemli bir role sahiptir ve her ge\c{c}en g\"{u}n kullan\i{}m\i{} daha da yayg\i{}nla\c{s}maktad\i{}r. Makinelerin ve servislerin b\"{u}y\"{u}k \c{c}o\u{g}unlu\u{g}u kendi i\c{c}lerinde farkl\i{} t\"{u}rde yaz\i{}l\i{}m i\c{c}erirler. Yaz\i{}l\i{}m geli\c{s}tiriciler, g\"{u}nl\"{u}k kullan\i{}m\i{}n\i{} yayg\i{}nla\c{s}t\i{}rmak ve rekabette geri kalmamak i\c{c}in m\"{u}mk\"{u}n oldu\u{g}unca h\i{}zl\i{} bir \c{s}ekilde yaz\i{}l\i{}mlar\i{} geli\c{s}tirmektedirler. Yaz\i{}l\i{}m ya\c{s}am d\"{o}ng\"{u}s\"{u}; genellikle analiz, tasar\i{}m, kodlama, test ve kurulum safhalar\i{}ndan olu\c{s}tur. Son kullan\i{}c\i{}ya hatadan ar\i{}nd\i{}r\i{}lm\i{}\c{s} bir yaz\i{}l\i{}m sunabilmek i\c{c}in test safhas\i{} etkili olarak y\"{u}r\"{u}t\"{u}lmelidir. Yaz\i{}l\i{}m metrikleri, kaynak kodun kalitesini yans\i{}tmay\i{} ama\c{c}larlar ve i\c{c}eri\u{g}i ile ilgili niceliksel bilgi verirler. Her bir metrik kodun farkl\i{} bir y\"{o}n\"{u}n\"{u} de\u{g}erlendirir. Kaynak kodun kalitesi seviyesi ile risk seviyesi aras\i{}nda bir ili\c{s}ki vard\i{}r. Son 20 y\i{}ll\i{}k d\"{o}nemde, akademisyenler, yaz\i{}l\i{}m hata kestirimi problemine giderek artan bir ilgi g\"{o}stermi\c{s}ler, daha g\"{u}rb\"{u}z bir kestirim i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi yakla\c{s}\i{}mlar\i{} uygulanm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}mada da bu problem i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi modelleri \"{o}nerilmi\c{s}tir. Yapay Sinir A\u{g}\i{} ve Yapay Ar\i{} Kolonisi kombinasyonu, Lojistik Regresyon-tabanl\i{} Bender Metot ve Naive Bayes bu \c{c}al\i{}\c{s}mada kullan\i{}lan algoritmalard\i{}r. \"{O}nerilen yakla\c{s}\i{}mlar, herkese a\c{c}\i{}k NASA Metrik Veri Program\i{} ve PROMISE havuzunda bulunan veri setlerine uygulanm\i{}\c{s}t\i{}r. undefinedstatistiki olarak g\"{u}venilir sonu\c{c}lar elde etmek ve \"{o}rneklem yanl\i{}l\i{}\u{g}\i{}n\i{} azaltmak i\c{c}in deneyler n-k\"{u}me \c{c}apraz validasyon ile kurgulanm\i{}\c{s}t\i{}r. Performans\i{} artt\i{}rmak i\c{c}in \"{o}nerilen modellere \"{o}zellik se\c{c}imi, normalizasyon ve ayr\i{}kla\c{s}t\i{}rma gibi \c{c}e\c{s}itli veri \"{o}n i\c{s}leme teknikleri uygulanm\i{}\c{s}t\i{}r. Deneylerden elde edilen sonu\c{c}lar di\u{g}er \c{c}al\i{}\c{s}malar ile kar\c{s}\i{}la\c{s}t\i{}r\i{}lm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}ma, \"{o}zellikle, yaz\i{}l\i{}m geli\c{s}tiricileri ve test personelinin kullan\i{}m\i{} y\"{o}n\"{u}yle katk\i{} yapmaktad\i{}r. Yaz\i{}l\i{}m geli\c{s}tiricileri, d\"{u}zenlemeye ihtiya\c{c} duyulan s\i{}n\i{}f veya mod\"{u}lleri g\"{o}r\"{u}rler; dolay\i{}s\i{}yla, bu mod\"{u}llerin kalitesinin artt\i{}r\i{}lmas\i{}na ve risk seviyelerinin azalt\i{}lmas\i{}na katk\i{} yapm\i{}\c{s} olurlar. Test personeli, daha \c{c}ok test yo\u{g}unla\c{s}mas\i{} gerektiren mod\"{u}lleri tespit eder ve bunun neticesinde mod\"{u}llerin \"{o}nceliklendirmesinin risk seviyelerine g\"{o}re yap\i{}lmas\i{} sa\u{g}lanm\i{}\c{s} olunur.},
note = {AAI29159899}
}

@inproceedings{10.1145/2568225.2568320,
author = {Jing, Xiao-Yuan and Ying, Shi and Zhang, Zhi-Wu and Wu, Shan-Shan and Liu, Jin},
title = {Dictionary learning based software defect prediction},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568320},
doi = {10.1145/2568225.2568320},
abstract = {In order to improve the quality of a software system, software defect prediction aims to automatically identify defective software modules for efficient software test. To predict software defect, those classification methods with static code attributes have attracted a great deal of attention. In recent years, machine learning techniques have been applied to defect prediction. Due to the fact that there exists the similarity among different software modules, one software module can be approximately represented by a small proportion of other modules. And the representation coefficients over the pre-defined dictionary, which consists of historical software module data, are generally sparse. In this paper, we propose to use the dictionary learning technique to predict software defect. By using the characteristics of the metrics mined from the open source software, we learn multiple dictionaries (including defective module and defective-free module sub-dictionaries and the total dictionary) and sparse representation coefficients. Moreover, we take the misclassification cost issue into account because the misclassification of defective modules generally incurs much higher risk cost than that of defective-free ones. We thus propose a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that CDDL outperforms several representative state-of-the-art defect prediction methods.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {414–423},
numpages = {10},
keywords = {sparse representation, dictionary learning, cost-sensitive discriminative dictionary learning (CDDL), Software defect prediction},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@article{10.1007/s00500-018-3546-6,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Binary teaching–learning-based optimization algorithm with a new update mechanism for sample subset optimization in software defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3546-6},
doi = {10.1007/s00500-018-3546-6},
abstract = {Software defect prediction has gained considerable attention in recent years. A broad range of computational methods has been developed for accurate prediction of faulty modules based on code and design metrics. One of the challenges in training classifiers is the highly imbalanced class distribution in available datasets, leading to an undesirable bias in the prediction performance for the minority class. Data sampling is a widespread technique to tackle this problem. However, traditional sampling methods, which depend mainly on random resampling from a given dataset, do not take advantage of useful information available in training sets, such as sample quality and representative instances. To cope with this limitation, evolutionary undersampling methods are usually used for identifying an optimal sample subset for the training dataset. This paper proposes a binary teaching–learning- based optimization algorithm employing a distribution-based solution update rule, namely BTLBOd, to generate a balanced subset of highly valuable examples. This subset is then applied to train a classifier for reliable prediction of potentially defective modules in a software system. Each individual in BTLBOd includes two vectors: a real-valued vector generated by the distribution-based update mechanism, and a binary vector produced from the corresponding real vector by a proposed mapping function. Empirical results showed that the optimal sample subset produced by BTLBOd might ameliorate the classification accuracy of the predictor on highly imbalanced software defect data. Obtained results also demonstrated the superior performance of the proposed sampling method compared to other popular sampling techniques.},
journal = {Soft Comput.},
month = oct,
pages = {9919–9935},
numpages = {17},
keywords = {Software defect prediction, Imbalanced learning, Sample subset optimization, Distribution-based update, Binary teaching–learning-based optimization, Teaching–learning-based optimization}
}

@article{10.1007/s10845-021-01871-3,
author = {Melakhsou, Abdallah Amine and Batton-Hubert, Mireille},
title = {Welding monitoring and defect detection using probability density distribution and functional nonparametric kernel classifier},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01871-3},
doi = {10.1007/s10845-021-01871-3},
abstract = {Welding fault detection in the industry of hot water tanks remains typically conducted visually or with the assistance of None Destructive Examination, such as X-ray, ultrasound, and penetrant testing. However, this leads to high consumption of time and resources. We propose in this paper a two-level method for automatic welding defect detection and localization. The method is based on the classification of the probability density distributions of the voltage signals underlying the generated stochastic process from the welding operation. In the main phase, we apply a passband filter to the raw signals and use the Kernel Density Estimation to measure the distribution of the filtered signal. The probability density distributions are processed as functional data and classified employing a functional non-parametric kernel classifier. In the second phase, the signal of nonconforming welding is split into segments and their probability density distributions are classified in order to extract the precise location of the defect in the whole signal. The proposed method allows to detect and localize welding defects with high accuracy.},
journal = {J. Intell. Manuf.},
month = nov,
pages = {1469–1481},
numpages = {13},
keywords = {Probability density distribution, Functional data classification, Welding defect detection}
}

@article{10.1007/s10664-019-09787-6,
author = {Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp and Ziadi, Tewfik and Robin, Jacques and Martinez, Jabier},
title = {The state of adoption and the challenges of systematic variability management in industry},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09787-6},
doi = {10.1007/s10664-019-09787-6},
abstract = {Handling large-scale software variability is still a challenge for many organizations. After decades of research on variability management concepts, many industrial organizations have introduced techniques known from research, but still lament that pure textbook approaches are not applicable or efficient. For instance, software product line engineering—an approach to systematically develop portfolios of products—is difficult to adopt given the high upfront investments; and even when adopted, organizations are challenged by evolving their complex product lines. Consequently, the research community now mainly focuses on re-engineering and evolution techniques for product lines; yet, understanding the current state of adoption and the industrial challenges for organizations is necessary to conceive effective techniques. In this multiple-case study, we analyze the current adoption of variability management techniques in twelve medium- to large-scale industrial cases in domains such as automotive, aerospace or railway systems. We identify the current state of variability management, emphasizing the techniques and concepts they adopted. We elicit the needs and challenges expressed for these cases, triangulated with results from a literature review. We believe our results help to understand the current state of adoption and shed light on gaps to address in industrial practice.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {1755–1797},
numpages = {43},
keywords = {Challenges, Multiple-case study, Software product lines, Variability management}
}

@inproceedings{10.1145/3318299.3318341,
author = {Lin, Zhongkang and Guo, Zhiqiang and Yang, Jie},
title = {Research on Texture Defect Detection Based on Faster-RCNN and Feature Fusion},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318341},
doi = {10.1145/3318299.3318341},
abstract = {Product texture defect detection is one of the important quality inspection procedures in industrial production. For the traditional defect detection methods, the detection processes are cumbersome, the accuracies are not high, and the generalizations are not strong. This paper proposes a method based on Faster-RCNN and feature fusion. This method uses the ResNet network model to extract the shared convolution feature, and combines the high-level features of the ROI pooling layer output with the low-level features obtained by the direction gradient histogram (HOG) as full connection layer input. Then, optimizing the model by adjusting the training parameters and convolutional neural network structure. Experiments on the German Pattern Recognition Association (GAPR) texture defect dataset show that the proposed model has improved in the mAP index. Through the migration learning strategy, experiments are carried out on several sets of actually collected data sets. The experimental results show that the model has good adaptability and can be applied to the surface defect detection of workpieces under different conditions.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {429–433},
numpages = {5},
keywords = {target location, feature fusion, faster-RCNN, defect detection},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1016/j.knosys.2015.09.035,
author = {Li, Weiwei and Huang, Zhiqiu and Li, Qing},
title = {Three-way decisions based software defect prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {91},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.09.035},
doi = {10.1016/j.knosys.2015.09.035},
abstract = {Based on a two-stage classification method and a two-stage ranking method on three-way decisions, this paper introduces a three-way decisions framework for cost-sensitive software defect prediction. For the classification problem in software defect prediction, traditional two-way decisions methods usually generate a higher classification error and more decision cost. Here, a two-stage classification method that integrates three-way decisions and ensemble learning to predict software defect is proposed. Experimental results on NASA data sets show that our method can obtain a higher accuracy and a lower decision cost. For the ranking problem in software defect prediction, a two-stage ranking method is introduced. In the first stage, all software modules are classified into three different regions based on three-way decisions. A dominance relation rough set based ranking algorithm is next applied to rank the modules in each region. Comparison experiments with 6 other ranking methods present that our proposed method can obtain a better result on FPA measure.},
journal = {Know.-Based Syst.},
month = jan,
pages = {263–274},
numpages = {12},
keywords = {Three-way decisions, Software defect ranking, Software defect classification}
}

@inproceedings{10.1145/3028842.3028858,
author = {Gao, Yan and Yang, Chunhui and Liang, Lixin},
title = {Pseudo-samples generation in Gaussian mixture distribution for software defect prediction},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028858},
doi = {10.1145/3028842.3028858},
abstract = {In this paper, we present GCRF method based on pseudo-samples generation and conditional random field (CRF) for software defect prediction in Gaussian Mixture Distribution. In the proposed method, firstly, we leverage Gaussian Mixture Distribution (GMM) to generate pseudo-samples, which can increase the samples of minority class for balancing the train dataset. Secondly, we propose to apply CRF model in the balanced train dataset because the CRF model can handle complex features in nonlinear high dimensional subspace. Moreover, in order to avoid explicit modeling of the observed data, the proposed method can incorporate the classification of software defect data with different statistics characteristics into a unified probabilistic framework. Interestingly, the experiments show that the GCRF method achieves much better prediction performance than the other approach as shown in the software defect data classification task.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {16},
numpages = {6},
keywords = {software defect prediction, imbalance distribution, gaussian mixture distribution, conditional random field},
location = {Wuhan, China},
series = {ICIIP '16}
}

@inproceedings{10.1145/2810146.2810150,
author = {Mahmood, Zaheed and Bowes, David and Lane, Peter C. R. and Hall, Tracy},
title = {What is the Impact of Imbalance on Software Defect Prediction Performance?},
year = {2015},
isbn = {9781450337151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810146.2810150},
doi = {10.1145/2810146.2810150},
abstract = {Software defect prediction performance varies over a large range. Menzies suggested there is a ceiling effect of 80% Recall [8]. Most of the data sets used are highly imbalanced. This paper asks, what is the empirical effect of using different datasets with varying levels of imbalance on predictive performance? We use data synthesised by a previous meta-analysis of 600 fault prediction models and their results. Four model evaluation measures (the Mathews Correlation Coefficient (MCC), F-Measure, Precision and Recall) are compared to the corresponding data imbalance ratio. When the data are imbalanced, the predictive performance of software defect prediction studies is low. As the data become more balanced, the predictive performance of prediction models increases, from an average MCC of 0.15, until the minority class makes up 20% of the instances in the dataset, where the MCC reaches an average value of about 0.34. As the proportion of the minority class increases above 20%, the predictive performance does not significantly increase. Using datasets with more than 20% of the instances being defective has not had a significant impact on the predictive performance when using MCC. We conclude that comparing the results of defect prediction studies should take into account the imbalance of the data.},
booktitle = {Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {4},
numpages = {4},
keywords = {Data Imbalance, Defect Prediction, Machine Learning},
location = {Beijing, China},
series = {PROMISE '15}
}

@inproceedings{10.1007/978-3-030-31654-9_45,
author = {Liu, Zhoufeng and Cui, Jian and Li, Chunlei and Wei, Miaomiao and Yang, Yan},
title = {Fabric Defect Detection Based on Lightweight Neural Network},
year = {2019},
isbn = {978-3-030-31653-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31654-9_45},
doi = {10.1007/978-3-030-31654-9_45},
abstract = {Owing to the variety and complexity of defects in the fabric texture image, automatic fabric defect detection is a challenging task in the fields of machine vision. Deep convolutional neural network (CNN) has achieved remarkable progress in the field of target detection, and the application of deep CNN model to fabric defect detection has achieved better results. However, with the detection accuracy increasing of deep CNNs, comes the drawbacks of significant increase in computational costs and storage services, which seriously hinders the usages of CNN on resource-limited environments such as mobile or embedded devices. In this paper, a fabric defect detection method using lightweight CNN is proposed. We introduce an extremely computation-efficient CNN architecture named YOLO-LFD, which adopts continuous 3  3 and 1  1 convolution layers for dimensionality reduction and feature fusion. We use multi-scale feature extraction method to improve the detection ability of the model for different size targets, and adopt K-means clustering method on the fabric defect image dataset to find the optimal size of anchor boxes. Experimental results demonstrate that the proposed scheme improves the detection accuracy of fabric defects, greatly reduces the model parameters, and improves the detection speed, which can provide real-time fabric defects detection on embedded devices.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part I},
pages = {528–539},
numpages = {12},
keywords = {Optimization model, Fabric defect detection, YOLO-v3, Deep learning},
location = {Xi'an, China}
}

@inproceedings{10.1109/SMC52423.2021.9659140,
author = {Kankam Gyimah, Nana and Girma, Abenezer and Nabil Mahmoud, Mahmoud and Nateghi, Shamila and Homaifar, Abdollah and Opoku, Daniel},
title = {A Robust Completed Local Binary Pattern (RCLBP) for Surface Defect Detection},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9659140},
doi = {10.1109/SMC52423.2021.9659140},
abstract = {In this paper, we present a Robust Completed Local Binary Pattern (RCLBP) framework for a surface defect detection task. Our approach uses a combination of Non-Local (NL) means filter with wavelet thresholding and Completed Local Binary Pattern (CLBP) to extract robust features which are fed into classifiers for surface defects detection. This paper combines three components: A denoising technique based on Non-Local (NL) means filter with wavelet thresholding is established to denoise the noisy image while preserving the textures and edges. Second, discriminative features are extracted using the CLBP technique. Finally, the discriminative features are fed into the classifiers to build the detection model and evaluate the performance of the proposed framework. The performance of the defect detection models are evaluated using a real-world steel surface defect database from Northeastern University (NEU). Experimental results demonstrate that the proposed approach RCLBP is noise robust and can be applied for surface defect detection under varying conditions of intraclass and inter-class changes and with illumination changes.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {1927–1934},
numpages = {8},
location = {Melbourne, Australia}
}

@article{10.1016/j.knosys.2021.107272,
author = {Lin, Dongyun and Li, Yiqun and Prasad, Shitala and Nwe, Tin Lay and Dong, Sheng and Oo, Zaw Min},
title = {CAM-guided Multi-Path Decoding U-Net with Triplet Feature Regularization for Defect Detection and Segmentation},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {228},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107272},
doi = {10.1016/j.knosys.2021.107272},
journal = {Know.-Based Syst.},
month = sep,
numpages = {13},
keywords = {U-Net, Triplet feature regularization, Multi-path decoding, Defect detection and segmentation}
}

@inproceedings{10.1145/3377024.3380451,
author = {Bencomo, Nelly},
title = {Next steps in variability management due to autonomous behaviour and runtime learning},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3380451},
doi = {10.1145/3377024.3380451},
abstract = {One of the basic principles in product lines is to delay design decisions related to offered functionality and quality to later phases of the life cycle [25]. Instead of deciding on what system to develop in advance, a set of assets and a common reference architecture are specified and implemented during the Domain Engineering process. Later on, during Application Engineering, specific systems are developed to satisfy the requirements reusing the assets and architecture [16]. Traditionally, this is during the Application Engineering when delayed design decisions are solved. The realization of this delay relies heavily on the use of variability in the development of product lines and systems. However, as systems become more interconnected and diverse, software architects cannot easily foresee the software variants and the interconnections between components. Consequently, a generic a priori model is conceived to specify the system's dynamic behaviour and architecture. The corresponding design decisions are left to be solved at runtime [13].Surprisingly, few research initiatives have investigated variability models at runtime [9]. Further, they have been applied only at the level of goals and architecture, which contrasts to the needs claimed by the variability community, i.e., Software Product Lines (SPLC) and Dynamic Software Product Lines (DSPL) [2, 10, 14, 22]. Especially, the vision of DSPL with their ability to support runtime updates with virtually zero downtime for products of a software product line, denotes the obvious need of variability models being used at runtime to adapt the corresponding programs. A main challenge for dealing with runtime variability is that it should support a wide range of product customizations under various scenarios that might be unknown until the execution time, as new product variants can be identified only at runtime [10, 11]. Contemporary variability models face the challenge of representing runtime variability to therefore allow the modification of variation points during the system's execution, and underpin the automation of the system's reconfiguration [15]. The runtime representation of feature models (i.e. the runtime model of features) is required to automate the decision making [9].Software automation and adaptation techniques have traditionally required a priori models for the dynamic behaviour of systems [17]. With the uncertainty present in the scenarios involved, the a priori model is difficult to define [20, 23, 26]. Even if foreseen, its maintenance is labour-intensive and, due to architecture decay, it is also prone to get out-of-date. However, the use of models@runtime does not necessarily require defining the system's behaviour model beforehand. Instead, different techniques such as machine learning, or mining software component interactions from system execution traces can be used to build a model which is in turn used to analyze, plan, and execute adaptations [18], and synthesize emergent software on the fly [7].Another well-known problem posed by the uncertainty that characterize autonomous systems is that different stakeholders (e.g. end users, operators and even developers) may not understand them due to the emergent behaviour. In other words, the running system may surprise its customers and/or developers [4]. The lack of support for explanation in these cases may compromise the trust to stakeholders, who may eventually stop using a system [12, 24]. I speculate that variability models can offer great support for (i) explanation to understand the diversity of the causes and triggers of decisions during execution and their corresponding effects using traceability [5], and (ii) better understand the behaviour of the system and its environment.Further, an extension and potentially reframing of the techniques associated with variability management may be needed to help taming uncertainty and support explanation and understanding of the systems. The use of new techniques such as machine learning exacerbates the current situation. However, at the same time machine learning techniques can also help and be used, for example, to explore the variability space [1]. What can the community do to face the challenges associated?We need to meaningfully incorporate techniques from areas such as artificial intelligence, machine learning, optimization, planning, decision theory, and bio-inspired computing into our variability management techniques to provide explanation and management of the diversity of decisions, their causes and the effects associated. My own previous work has progressed [3, 5, 6, 8, 11, 12, 19, 21] to reflect what was discussed above.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {2},
numpages = {2},
keywords = {variability management, uncertainty, machine learning, dynamic variability, dynamic software product lines, autonomous systems},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@inproceedings{10.1145/3467707.3467712,
author = {Wen, Shengping and Tao, Yiwen and Chen, Jingfu},
title = {Defect Detection for Mobile Phone Cases Based on Improved Yolo Model},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3467707.3467712},
doi = {10.1145/3467707.3467712},
abstract = {As an important part of a mobile phone, the mobile phone case is the main factor affecting the appearance of the mobile phone. The mobile phone case has various kinds of defects, which seriously affect its appearance. In order to locate and classify the defects of the mobile phone case, we propose a multiscale defect detection algorithm based on artificial neural networks. The proposed model contains an anchor box generation algorithm to locate the defects using density clustering and an acceleration algorithm to boost the convolution calculation, which is critical in the production lines. We explore the effects of model parameters on the detection performance and conduct detailed experiments. Finally, we compare the proposed algorithm with traditional approaches, and observed an improvement in both detection accuracy and stability on the proposed algorithm.},
booktitle = {Proceedings of the 2021 7th International Conference on Computing and Artificial Intelligence},
pages = {28–38},
numpages = {11},
keywords = {multi-scale prediction, mobile phone case, detection, convolutional neural networks},
location = {Tianjin, China},
series = {ICCAI '21}
}

@article{10.1016/j.asoc.2017.05.043,
author = {Arar, mer Faruk and Ayan, Krat},
title = {A feature dependent Naive Bayes approach and its application to the software defect prediction problem},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {59},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.05.043},
doi = {10.1016/j.asoc.2017.05.043},
abstract = {Display Omitted In Naive Bayes, features are assumed to be independent and have equal weight. But, In practice, features are interrelated.In this study, features are included for calculation as pairs using the proposed Feature Dependent Naive Bayes (FDNB) method.Eight data sets from the NASA PROMISE repository were used for the software defect prediction problem.Results were compared with other modified NBs. Increased classification performance was found after use of the proposed FDNB. Naive Bayes is one of the most widely used algorithms in classification problems because of its simplicity, effectiveness, and robustness. It is suitable for many learning scenarios, such as image classification, fraud detection, web mining, and text classification. Naive Bayes is a probabilistic approach based on assumptions that features are independent of each other and that their weights are equally important. However, in practice, features may be interrelated. In that case, such assumptions may cause a dramatic decrease in performance. In this study, by following preprocessing steps, a Feature Dependent Naive Bayes (FDNB) classification method is proposed. Features are included for calculation as pairs to create dependence between one another. This method was applied to the software defect prediction problem and experiments were carried out using widely recognized NASA PROMISE data sets. The obtained results show that this new method is more successful than the standard Naive Bayes approach and that it has a competitive performance with other feature-weighting techniques. A further aim of this study is to demonstrate that to be reliable, a learning model must be constructed by using only training data, as otherwise misleading results arise from the use of the entire data set.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {197–209},
numpages = {13},
keywords = {Software defect prediction, Naive Bayes, Feature independence, Discretization, Data mining}
}

@inproceedings{10.1007/978-3-030-31726-3_31,
author = {Cheng, Long and Gong, Ping and Qiu, Guanghui and Wang, Jing and Liu, Ziyuan},
title = {Small Defect Detection in Industrial X-Ray Using Convolutional Neural Network},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_31},
doi = {10.1007/978-3-030-31726-3_31},
abstract = {It’s crucial to ensure the complete reliability of each metallic component in vehicle industry. In the past few years, X-ray testing has been widely adopted in defect detection field. Due to huge production in industry, it’s absolutely necessary for manufacturers to employ more intelligent and automated inspection scheme to detect defects efficiently. This study develops an accurate and fast detection method combined with X-ray images using computer vision and deep learning techniques to recognize small defects, mark theirs’ area and divide them into different levels according to their sizes. This program modifies the original RetinaNet to adapt to tiny defects. We present a novel data augmentation method aiming to expand the number of defects. Then a multi-scale transform module is designed to generate scale-specific feature map which helps to grade defects better. Experiments show that the proposed method can achieve significant precision improvement over X-ray machine with similarly high recall rate. Both speed and accuracy of this scheme reach practical industrial-service demand.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {366–377},
numpages = {12},
keywords = {CNN, Dilated convolution, X-ray, Defect detection},
location = {Xi'an, China}
}

@article{10.1155/2021/5069016,
author = {Balogun, Abdullateef O. and Basri, Shuib and Mahamad, Saipunidzam and Capretz, Luiz Fernando and Imam, Abdullahi Abubakar and Almomani, Malek A. and Adeyemo, Victor E. and Kumar, Ganesh and Dourado, Ant\'{o}nio},
title = {A Novel Rank Aggregation-Based Hybrid Multifilter Wrapper Feature Selection Method in Software Defect Prediction},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5069016},
doi = {10.1155/2021/5069016},
abstract = {The high dimensionality of software metric features has long been noted as a data quality problem that affects the performance of software defect prediction (SDP) models. This drawback makes it necessary to apply feature selection (FS) algorithm(s) in SDP processes. FS approaches can be categorized into three types, namely, filter FS (FFS), wrapper FS (WFS), and hybrid FS (HFS). HFS has been established as superior because it combines the strength of both FFS and WFS methods. However, selecting the most appropriate FFS (filter rank selection problem) for HFS is a challenge because the performance of FFS methods depends on the choice of datasets and classifiers. In addition, the local optima stagnation and high computational costs of WFS due to large search spaces are inherited by the HFS method. Therefore, as a solution, this study proposes a novel rank aggregation-based hybrid multifilter wrapper feature selection (RAHMFWFS) method for the selection of relevant and irredundant features from software defect datasets. The proposed RAHMFWFS is divided into two stepwise stages. The first stage involves a rank aggregation-based multifilter feature selection (RMFFS) method that addresses the filter rank selection problem by aggregating individual rank lists from multiple filter methods, using a novel rank aggregation method to generate a single, robust, and non-disjoint rank list. In the second stage, the aggregated ranked features are further preprocessed by an enhanced wrapper feature selection (EWFS) method based on a dynamic reranking strategy that is used to guide the feature subset selection process of the HFS method. This, in turn, reduces the number of evaluation cycles while amplifying or maintaining its prediction performance. The feasibility of the proposed RAHMFWFS was demonstrated on benchmarked software defect datasets with Na\"{\i}ve Bayes and Decision Tree classifiers, based on accuracy, the area under the curve (AUC), and F-measure values. The experimental results showed the effectiveness of RAHMFWFS in addressing filter rank selection and local optima stagnation problems in HFS, as well as the ability to select optimal features from SDP datasets while maintaining or enhancing the performance of SDP models. To conclude, the proposed RAHMFWFS achieved good performance by improving the prediction performances of SDP models across the selected datasets, compared to existing state-of-the-arts HFS methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@article{10.1016/j.procs.2015.02.161,
author = {Arora, Ishani and Tetarwal, Vivek and Saha, Anju},
title = {Open Issues in Software Defect Prediction},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.161},
doi = {10.1016/j.procs.2015.02.161},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {906–912},
numpages = {7},
keywords = {software testing, software quality, machine learning, defect prediction, data mining}
}

@inproceedings{10.1109/ICMA52036.2021.9512731,
author = {Yang, Lei and Song, Shouan and Niu, Yong and Liu, Yanhong},
title = {A Lightweight Defect Detection Algorithm of Insulators for Power Inspection},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA52036.2021.9512731},
doi = {10.1109/ICMA52036.2021.9512731},
abstract = {The rapid development of smart grid causes a large increase of power equipments. Power insulator is one of the most important infrastructures in the power transmission lines which is vital to ensure the safe operation of power system. As a common defect, the missing-cap issues will affect the structural strength of power insulators and the safe operation of power lines. Consequently, the monitoring and assessment of abnormal power insulators are of extreme importance for the safe power transmission lines. Due to the good feature expression ability, machine learning algorithms have got much applications on power line inspection, and they could be divided into two categories: shallow learning and deep learning algorithms. Nevertheless, the defect recognition issues on power insulators are always against complex power inspection environment. It will bring a certain effect to the handcrafted feature design of shallow learning algorithms. Meanwhile, the small-scale defect data set will affect the model training of the deep network model. To address the above issues, aimed at the feature of the limited processing power of airborne processor, a novel lightweight defect detection algorithm is proposed for the defects of power insulators which fuses the advantages of shallow learning and deep learning models. Firstly, an insulator location algorithm based on lightweight deep convolutional neural network (DCNN) model is proposed to remove the disturbance of complex backgrounds and serve the high-precision defect detection. On the basis, the high-level image feature based on the improved transfer learning is acquired to effectively distinguish the normal and abnormal power insulators. Finally, a defect recognition method based on Support Vector Machine (SVM) is proposed to solve the small-scale defect detection issue. Experiments show that the proposed method could well meet the precision and speed demands of power system compared with other inspection methods.},
booktitle = {2021 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {281–286},
numpages = {6},
location = {Takamatsu, Japan}
}

@article{10.1016/j.neucom.2021.06.094,
author = {Posilovi\'{c}, Luka and Medak, Duje and Suba\v{s}i\'{c}, Marko and Budimir, Marko and Lon\v{c}ari\'{c}, Sven},
title = {Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {459},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.06.094},
doi = {10.1016/j.neucom.2021.06.094},
journal = {Neurocomput.},
month = oct,
pages = {361–369},
numpages = {9},
keywords = {Generative adversarial networks, Image generation, Automated defect detection, Ultrasonic B-scan, Non-destructive testing}
}

@article{10.1016/j.engappai.2021.104504,
author = {Vaish, Rachna and Dwivedi, U.D. and Tewari, Saurabh and Tripathi, S.M.},
title = {Machine learning applications in power system fault diagnosis: Research advancements and perspectives},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104504},
doi = {10.1016/j.engappai.2021.104504},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
numpages = {33},
keywords = {Unsupervised learning, Transfer learning, Supervised learning, Reinforcement learning, Machine learning (ML)}
}

@article{10.1007/s11277-018-5390-5,
author = {Hu, Kun and Zhang, Shuyou and Zhao, Xinyue},
title = {An Energy-Minimizing Level Set Method for Defect Detection},
year = {2018},
issue_date = {Oct 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {4},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-018-5390-5},
doi = {10.1007/s11277-018-5390-5},
abstract = {This paper proposes an energy-minimizing level set method for defect detection in product surface, which consists of image segmentation module, image feature extraction module and product defect detection module. This new method, embedding energy function into the classic level set algorithm, segments internal and external areas of product image with minimized energy consumption, ensuring that the gradient of the level set function is in the direction of the minimum point so that the evolution process is closer to the zero level set. 15-dimentional features including zero-crossing rate and image entropy are used in the process of contour detection. Results show that the method is highly accurate and effective.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {3545–3555},
numpages = {11},
keywords = {Level set, Image encryption, Energy minimization, Defect detection}
}

@inproceedings{10.1007/978-3-319-35122-3_5,
author = {Schaefer, Ina and Seidl, Christoph and Cleophas, Loek and Watson, Bruce W.},
title = {Tax-PLEASE--Towards Taxonomy-Based Software Product Line Engineering},
year = {2016},
isbn = {9783319351216},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-35122-3_5},
doi = {10.1007/978-3-319-35122-3_5},
abstract = {Modern software systems, in particular in mobile and cloud-based applications, exist in many different variants in order to adapt to changing user requirements or application contexts. Software product line engineering allows developing these software systems by managed large-scale reuse in order to achieve shorter time to market. Traditional software product line engineering approaches use a domain variability model which only captures the configuration options of the product variants, but does not provide any guideline for designing and implementing reusable artifacts. In contrast, software taxonomies structure software domains from an abstract specification of the functionality to concrete implementable variants by successive correctness-preserving refinements. In this paper, we propose a novel software product line engineering process based on a taxonomy-based domain analysis. The taxonomy's hierarchy provides guidelines for designing and implementing the product line's reusable artifacts while at the same time specifying possible configuration options. By deriving reusable product line artifacts from a software taxonomy, the well-defined structuring of the reusable artifacts yields improved maintainability and evolvability of the product line.},
booktitle = {Proceedings of the 15th International Conference on Software Reuse: Bridging with Social-Awareness - Volume 9679},
pages = {63–70},
numpages = {8},
keywords = {Taxonomy-Based Software Construction TABASCO, Software Product Line SPL},
location = {Limassol, Cyprus},
series = {ICSR 2016}
}

@inproceedings{10.1145/3373509.3373552,
author = {Liu, Zhoufeng and Wang, Jinjin and Li, Chunlei and Li, Bicao and Yang, Ruimin},
title = {Fabric Defect Detection Using Fully Convolutional Network with Attention Mechanism},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373552},
doi = {10.1145/3373509.3373552},
abstract = {Because of the complex and diverse fabric image texture and defects, the traditional fabric defect detection algorithm has poor detection results and low efficiency. Visual saliency model can outstand the defect region from the complex background. However, the previous saliency detection models typically utilize hand-crafted image features to generate the saliency map, and it can only be used for some kinds of fabric type. In this paper, a deep saliency model generated by fully convolutional network with attention mechanism is proposed for fabric defect detection. First, the proposed model extracts multi-level and multi-scale features using Fully Convolutional Networks (FCN), this will improve the characterization ability for fabric texture. Then, the attention mechanism module is incorporated into the backbone network, thus the different feature map is assigned different weight, this further improves the effectiveness of the feature extraction. Finally, multi-level saliency maps are generated after deconvolution, and then fused by a series of short connection structures to better detect the salient region. Experiment results demonstrate that the proposed approach can accurately locate the defect region comparing with the state-of-art methods. Meantime, defect detection ability of the network model can be improved without significantly increasing the amount of calculation and parameters.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {134–140},
numpages = {7},
keywords = {convolutional neural network, attention mechanism, Defect detection},
location = {Beijing, China},
series = {ICCPR '19}
}

@article{10.1016/j.neucom.2020.08.094,
author = {Pastor-L\'{o}pez, Iker and Sanz, Borja and Tellaeche, Alberto and Psaila, Giuseppe and de la Puerta, Jos\'{e} Gaviria and Bringas, Pablo G.},
title = {Quality assessment methodology based on machine learning with small datasets: Industrial castings defects},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {456},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.08.094},
doi = {10.1016/j.neucom.2020.08.094},
journal = {Neurocomput.},
month = oct,
pages = {622–628},
numpages = {7},
keywords = {Defect categorization, Surface defect detection, Machine-learning, Artificial vision}
}

@inproceedings{10.1109/CASE49439.2021.9551659,
author = {Melakhsou, Abdallah Amine and Batton-Hubert, Mireille},
title = {On welding defect detection and causalities between welding signals},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CASE49439.2021.9551659},
doi = {10.1109/CASE49439.2021.9551659},
abstract = {In the manufacturing of hot water tanks, welding quality evaluation and fault detection is a critical operation that is still frequently conducted visually or with the help of none destructive tests, which can generate a high consumption of time and resources. To overcome this problem, many methods have been proposed for defect detection based on the classification of the welding signals. However, most of the proposed methods do not consider the problems of defect localization and the generalization from small sample size. Moreover, studies on the interactions between welding signals seem to be absent in the literature despite its importance in the formulation of the defect detection problem. In this paper, we aim to address these gaps by presenting a study on the causalities between welding signals in the circular welding of hot water tanks. Based on the findings from the causality study, we propose a method that detects and localize welding defect with high accuracy and handles the problem of small sample size. Furthermore, we present a study on the defects root cause and show the possibility of early defect prediction.},
booktitle = {2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)},
pages = {401–408},
numpages = {8},
location = {Lyon, France}
}

@inproceedings{10.1145/3448734.3450927,
author = {Zang, Yangyang and Zhang, Jing and Billah, Mohammad Masum},
title = {Defect detection of flexible circuit board based on convolutional neural network},
year = {2021},
isbn = {9781450389570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448734.3450927},
doi = {10.1145/3448734.3450927},
abstract = {Flexible printed circuit (FPCs) is one of the important links in the manufacture of electronic products. A minor flaw in the FPC can lead to a major flaw in the final product. Therefore, it is critical to detect and locate all defects on a FPC. Although great progress has been made in FPC defect detection, traditional detection methods are still difficult to deal with complex and diverse FPC. Therefore, this paper designs a depth model that can accurately detect FPC defects from non-detection templates and defect detection image input pairs. This method uses the multi-scale pyramid hierarchy structure inherent in deep neural network (DNN) to construct multi-scale characteristics. First of all, k-means clustering is used to design reasonable anchor points. Then, the network strengthens the relationship between the feature mapping at different levels and the advantages of the underlying structure information and is suitable for the detection of minor defects. The experimental results show that the accuracy of defect detection is improved effectively.},
booktitle = {The 2nd International Conference on Computing and Data Science},
articleno = {197},
numpages = {5},
keywords = {convolutional Neural Networks, Multiscale fusion, Deep Learning, DNN},
location = {Stanford, CA, USA},
series = {CONF-CDS 2021}
}

@article{10.3233/KES-200029,
author = {Singh, Pradeep and Verma, Shrish},
title = {ACO based comprehensive model for software fault prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {24},
number = {1},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-200029},
doi = {10.3233/KES-200029},
abstract = {The comprehensive models can be used for software quality modelling which involves prediction of low-quality modules using interpretable rules. Such comprehensive model can guide the design and testing team to focus on the poor quality modules, thereby, limited resources allocated for software quality inspection can be targeted only towards modules that are likely to be defective. Ant Colony Optimization (ACO) based learner is one potential way to obtain rules that can classify the software modules faulty and not faulty. This paper investigates ACO based mining approach with ROC based rule quality updation to constructs a rule-based software fault prediction model with useful metrics. We have also investigated the effect of feature selection on ACO based and other benchmark algorithms. We tested the proposed method on several publicly available software fault data sets. We compared the performance of ACO based learning with the results of three benchmark classifiers on the basis of area under the receiver operating characteristic curve. The evaluation of performance measure proves that the ACO based learner outperforms other benchmark techniques.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {63–71},
numpages = {9},
keywords = {ACO, fault prediction, Software metric}
}

@inproceedings{10.1145/3381271.3381280,
author = {Wei, Liang and Zhang, Ningyu and Xue, Muyao and Huo, Ju},
title = {Research of express box defect detection based on machine vision},
year = {2020},
isbn = {9781450376648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381271.3381280},
doi = {10.1145/3381271.3381280},
abstract = {The traditional box appearance defect detection adopts manual detection which is low accuracy and time consuming. In order to overcome the drawbacks of manual detection and improve transportation automation, an effective and convenient defect detection algorithm of express boxes is proposed. The central idea of the proposed algorithm is to solve defect identification problems during transportation. This technique only needs to observe defects through the binocular camera system, thus the parameters of shape and size can be obtained subsequently. Finally, experiments are carried out. Results show that the algorithm can accurately identify different shaped defects and the highest reconstruction correct rate is up to 95.83%. The results verify the applicability of the proposed approach.},
booktitle = {Proceedings of the 5th International Conference on Multimedia and Image Processing},
pages = {12–17},
numpages = {6},
keywords = {machine vision, defect detection, binocular camera system},
location = {Nanjing, China},
series = {ICMIP '20}
}

@article{10.1155/2021/9374465,
author = {Chen, Yongbin and Fu, Qinshen and Wang, Guitang and Tsai, Sang-Bing},
title = {Surface Defect Detection of Nonburr Cylinder Liner Based on Improved YOLOv4},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/9374465},
doi = {10.1155/2021/9374465},
abstract = {Cylinder liner plays an important role in the internal combustion engine. The surface defects of cylinder liner will directly affect the safety and service life of the internal combustion engine. At present, the surface defect detection of cylinder liner mainly relies on manual visual inspection, which is easily affected by subjective factors of inspectors. Aiming at the bottleneck of traditional visual inspection technology in appearance inspection, this paper proposes a surface defect detection algorithm based on deep learning to realize defect location and classification. Based on the characteristics of the research object in this paper, the surface defect detection algorithm based on the improved YOLOv4 model is proposed, the model framework is constructed, and the data enhancement method and verification method are proposed. Experiments show that the proposed method can improve the detection accuracy and speed and can meet the requirements of the nonburr cylinder surface defect detection. At the same time, the method can be extended to other surface defect detection applications.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {13}
}

@article{10.1007/s00371-020-01820-w,
author = {Liu, Guohua and Zheng, Xiangtong},
title = {Fabric defect detection based on information entropy and frequency domain saliency},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {37},
number = {3},
issn = {0178-2789},
url = {https://doi.org/10.1007/s00371-020-01820-w},
doi = {10.1007/s00371-020-01820-w},
abstract = {The automatic detection of defects is an important part of the fabric production process. However, existing methods of detecting defects in fabrics with periodic patterns lack adaptability and perform poorly in detection. In this paper, we propose an unsupervised fabric defect detection method based on the human visual attention mechanism. The method introduces two-dimensional entropy which can reflect the spatial distribution characteristics of images based on one-dimensional entropy, according to the relationship between information entropy and image texture. The image is reconstructed into a quaternion matrix by combining two-dimensional entropy and three feature maps that characterize the opponent color space representation of the input image. The hypercomplex Fourier transform is then used to transform the quaternion image matrix into the frequency domain. We propose a new method for local tuning of amplitude spectrum, thereby suppressing the background pattern while retaining the defect region. Finally, the inverse transform is performed to obtain a saliency map. Through experimental comparisons and a series of numerical evaluations, we demonstrate that the proposed method has a better detection effect compared to state-of-the-art methods in fabric defect detection.},
journal = {Vis. Comput.},
month = mar,
pages = {515–528},
numpages = {14},
keywords = {Hypercomplex Fourier transform, Visual attention, Information entropy, Fabric defect detection}
}

@inproceedings{10.1007/978-3-031-21517-9_10,
author = {Kunal, Kishore and Upadhyay, Pawan Kumar and Ramasubramaniam, M. and Xavier, M. J.},
title = {Mura Defect Detection in&nbsp;Flat Panel Display Using B-Spline Approximation},
year = {2021},
isbn = {978-3-031-21516-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21517-9_10},
doi = {10.1007/978-3-031-21517-9_10},
abstract = {Flat panel display (FDP) devices continue to grow at rapid rate and quite popular as a promising technology and evolve various investment opportunity. In this paper, a machine vision approach has been proposed for automatic inspection of mura defects in film or glass of flat panel display device. The proposed method is based on a Mura filter using B-spline global approximation method. Experimental result shows that the detection of mura defect has been performed on images data with high speed computational techniques and obtained robust results.},
booktitle = {Mining Intelligence and Knowledge Exploration: 9th International Conference, MIKE 2021, Hammamet, Tunisia, November 1–3, 2021, Proceedings},
pages = {102–108},
numpages = {7},
keywords = {Flat panel display, Machine vision, Machine learning, B-spline},
location = {Hammamet, Tunisia}
}

@inproceedings{10.1145/3373509.3373550,
author = {Liu, Zhoufeng and Cui, Jian and Li, Chunlei and Ding, Shumin and Xu, Qingwei},
title = {Real-time Fabric Defect Detection based on Lightweight Convolutional Neural Network},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373550},
doi = {10.1145/3373509.3373550},
abstract = {Fabric defect detection is an important link for quality control in a textile factory. Deep convolutional neural network (CNN) has made great progress in the field of target detection, and has proven applicable in fabric defect detection. However, the improvement of detection performance of CNN network mainly depends on complex network structure. This comes the drawbacks of significant increase in computational costs and storage services, which seriously hinders the usages of CNN on resource-limited environments, such as smart industrial cameras and other embedded devices. In this paper, a lightweight CNN model is designed for fabric defect detection, and denoted as DefectNet. It is based on a streamlined architecture that uses depthwise separable convolutions instead of standard convolutions to build a lightweight neural network architecture, and significantly reduce the computational complexity of the model. The multi-scale feature extraction method is used to improve the detection ability of the model for fabric defects of various sizes. Experimental results demonstrate that the proposed scheme has higher detection accuracy and faster detection speed on the basis of fewer network parameters, which can provide real-time fabric defects detection on the embedded devices.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {122–127},
numpages = {6},
keywords = {lightweight, fabric defect detection, depthwise separable convolution, Deep learning},
location = {Beijing, China},
series = {ICCPR '19}
}

@phdthesis{10.5555/AAI28498637,
author = {Khalil, Kasem Mohamed Ahmed and Ashok, Kumar, and Mohammad, Madani, and Michael, Totaro,},
advisor = {A, Bayoumi, Magdy},
title = {Fault Prediction and Self-Healing Paradigm for Intelligent Hardware Systems},
year = {2021},
isbn = {9798522907303},
publisher = {University of Louisiana at Lafayette},
abstract = {As the complexity of hardware systems grows, the failure rate, or the rate at which such systems produce faults, accelerates. Ideally, future hardware should heal faults before the faults can occur and impact a system adversely. Fault prediction is needed to identify a fault before it occurs, and this helps to heal the fault early to avoid losing data or missing some operation. Such systems, also referred to as intelligent hardware systems, are expected to revolutionize the way circuits and systems are designed, and it is the focus of this dissertation. An intelligent hardware system is expected to have mechanisms for self-healing and fault prediction. A novel mechanism for self-healing methods for Embryonic Hardware (EmHW), Network-on-Chip (NoC), and neural network is proposed. The proposed self-healing method is implemented in VHDL on Altera Arria 10 GX FPGA device. The area overhead of the proposed self-healing method for EmHW and NoC is 34% and 31%, respectively, with high reliability and the mean-time-to-failure that prove extended network age. The hardware fault prediction requires low-cost machine learning techniques. A hardware neural network optimization and reconfiguration is proposed for artificial neural networks, Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN). An Economic LSTM (ELSTM) is proposed, which saves 34% of the area and 35% of the power consumption compared to LSTM. Next, a novel Absolute Average Deviation (ADD) pooling method with very high accuracy for CNN is also. The AAD pooling achieves an accuracy of more than 98%. and has a modest 4%. It is synthesized using Synopsis in 45 nm technology and found to occupy an area of 244.466 nm2, and consume 0.31 mW of power. Two fault prediction methods are presented, and they are based on the proposed machine learning optimization methods. The proposed fault prediction methods are used for early transistor and architectural fault prediction for NoC and EmHW, using fast Fourier transform, Principal Component Analysis (PCA), Relative PCA (RPCA), ELSTM, and CNN. The proposed approaches are implemented using Tensorflow and FPGA device, and the result shows the proposed approach could predict a fault with the accuracy of more than 98%.},
note = {AAI28498637}
}

@inproceedings{10.1145/3338906.3341462,
author = {Caulo, Maria},
title = {A taxonomy of metrics for software fault prediction},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341462},
doi = {10.1145/3338906.3341462},
abstract = {In the field of Software Fault Prediction (SFP), researchers exploit software metrics to build predictive models using machine learning and/or statistical techniques. SFP has existed for several decades and the number of metrics used has increased dramatically. Thus, the need for a taxonomy of metrics for SFP arises firstly to standardize the lexicon used in this field so that the communication among researchers is simplified and then to organize and systematically classify the used metrics. In this doctoral symposium paper, I present my ongoing work which aims not only to build such a taxonomy as comprehensive as possible, but also to provide a global understanding of the metrics for SFP in terms of detailed information: acronym(s), extended name, univocal description, granularity of the fault prediction (e.g., method and class), category, and research papers in which they were used.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1144–1147},
numpages = {4},
keywords = {taxonomy, software metrics, software fault prediction},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3460426.3463666,
author = {Akhyar, Fityanul and Lin, Chih-Yang and Kathiresan, Gugan S.},
title = {A Beneficial Dual Transformation Approach for Deep Learning Networks Used in Steel Surface Defect Detection},
year = {2021},
isbn = {9781450384636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460426.3463666},
doi = {10.1145/3460426.3463666},
abstract = {Steel surface defect detection represents a challenging task in real-world practical object detection. Based on our observations, there are two critical problems which create this challenge: the tiny size, and vagueness of the defects. To solve these problems, this study a proposes a deep learning-based defect detection system that uses automatic dual transformation in the end-to-end network. First, the original training images in RGB are transformed into the HSV color model to re-arrange the difference in color distribution. Second, the feature maps are upsampled using bilinear interpolation to maintain the smaller resolution. The latest and state-of-the-art object detection model, High-Resolution Network (HRNet) is utilized in this system, with initial transformation performed via data augmentation. Afterward, the output of the backbone stage is applied to the second transformation. According to the experimental results, the proposed approach increases the accuracy of the detection of class 1 Severstal steel surface defects by 3.6% versus the baseline.},
booktitle = {Proceedings of the 2021 International Conference on Multimedia Retrieval},
pages = {619–622},
numpages = {4},
keywords = {high-resolution network, defect detection system, bilinear interpolation, RGB to HSV},
location = {Taipei, Taiwan},
series = {ICMR '21}
}

@inproceedings{10.1145/2961111.2962610,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {Building an Ensemble for Software Defect Prediction Based on Diversity Selection},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962610},
doi = {10.1145/2961111.2962610},
abstract = {Background: Ensemble techniques have gained attention in various scientific fields. Defect prediction researchers have investigated many state-of-the-art ensemble models and concluded that in many cases these outperform standard single classifier techniques. Almost all previous work using ensemble techniques in defect prediction rely on the majority voting scheme for combining prediction outputs, and on the implicit diversity among single classifiers. Aim: Investigate whether defect prediction can be improved using an explicit diversity technique with stacking ensemble, given the fact that different classifiers identify different sets of defects. Method: We used classifiers from four different families and the weighted accuracy diversity (WAD) technique to exploit diversity amongst classifiers. To combine individual predictions, we used the stacking ensemble technique. We used state-of-the-art knowledge in software defect prediction to build our ensemble models, and tested their prediction abilities against 8 publicly available data sets. Conclusion: The results show performance improvement using stacking ensembles compared to other defect prediction models. Diversity amongst classifiers used for building ensembles is essential to achieving these performance improvements.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {46},
numpages = {10},
keywords = {stacking, software faults, ensembles of learning machines, diversity, Software defect prediction},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.1016/j.eswa.2021.115673,
author = {Zhang, Huan and Jiang, Liangxiao and Li, Chaoqun},
title = {CS-ResNet: Cost-sensitive residual convolutional neural network for PCB cosmetic defect detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {185},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115673},
doi = {10.1016/j.eswa.2021.115673},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {10},
keywords = {Cost-sensitive learning, Class imbalance, Residual convolutional neural network, PCB cosmetic defect detection}
}

@article{10.1155/2021/9976209,
author = {Chen, Yuquan and Wang, Hongxing and Shen, Jie and Zhang, Xingwei and Gao, Xiaowei and Nazir, Shah},
title = {Application of Data-Driven Iterative Learning Algorithm in Transmission Line Defect Detection},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/9976209},
doi = {10.1155/2021/9976209},
abstract = {Deep learning technology has received extensive consideration in recent years, and its application value in target detection is also increasing day by day. In order to accelerate the practical process of deep learning technology in electric transmission line defect detection, the current work used the improved Faster R-CNN algorithm to achieve data-driven iterative training and defect detection functions for typical transmission line defect targets. Based on Faster R-CNN, we proposed an improved network that combines deformable convolution and feature pyramid modules and combined it with a data-driven iterative learning algorithm; it achieves extremely automated and intelligent transmission line defect target detection, forming an intelligent closed-loop image processing. The experimental results show that the increase of the recognition of improved Faster R-CNN network combined with data-driven iterative learning algorithm for the pin defect target is 31.7% more than Faster R-CNN. In the future, the proposed method can quickly improve the accuracy of transmission line defect target detection in a small sample and save manpower. It also provides some theoretical guidance for the practical work of transmission line defect target detection.},
journal = {Sci. Program.},
month = jan,
numpages = {9}
}

@inproceedings{10.1109/AIM46487.2021.9517664,
author = {Liu, Ming-Wei and Lin, Yu-Heng and Lo, Yuan-Chieh and Shih, Chih-Hsuan and Lin, Pei-Chun},
title = {Defect Detection of Grinded and Polished Workpieces Using Faster R-CNN},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM46487.2021.9517664},
doi = {10.1109/AIM46487.2021.9517664},
abstract = {Polishing and grinding are crucial in the fabrication processes of industrial and commercial products. While the fabrication process can be automated using robots or specialized machines, experienced workers are still needed for the subsequent quality inspection. Here, we report the development of an automatic defect detection system, which is capable of detecting the defects of grinded and polished faucets due to its Faster Region-based Convolutional Neural Networks (Faster RCNN) architecture. The images of the workpieces were taken using a manipulator with a preset trajectory to cover all the surfaces of the workpieces. After labeling, the data were augmented to the trainable level. Three pretrained CNN-based models were utilized and evaluated. The hyperparameters were analyzed to validate their effect on the performance of the model. The mean average precision, using the tuned hyperparameters, was 80.26%.},
booktitle = {2021 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1290–1296},
numpages = {7},
location = {Delft, Netherlands}
}

@inproceedings{10.1145/2931037.2931039,
author = {Bowes, David and Hall, Tracy and Harman, Mark and Jia, Yue and Sarro, Federica and Wu, Fan},
title = {Mutation-aware fault prediction},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931039},
doi = {10.1145/2931037.2931039},
abstract = {We introduce mutation-aware fault prediction, which leverages additional guidance from metrics constructed in terms of mutants and the test cases that cover and detect them. We report the results of 12 sets of experiments, applying 4 different predictive modelling techniques to 3 large real-world systems (both open and closed source). The results show that our proposal can significantly (p ≤ 0.05) improve fault prediction performance. Moreover, mutation-based metrics lie in the top 5% most frequently relied upon fault predictors in 10 of the 12 sets of experiments, and provide the majority of the top ten fault predictors in 9 of the 12 sets of experiments.},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {330–341},
numpages = {12},
keywords = {Software Metrics, Software Fault Prediction, Software Defect Prediction, Mutation Testing, Empirical Study},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@article{10.1504/IJICA.2017.088162,
title = {Hybrid algorithm for two-objective software defect prediction problem},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {4},
issn = {1751-648X},
url = {https://doi.org/10.1504/IJICA.2017.088162},
doi = {10.1504/IJICA.2017.088162},
abstract = {Static software defect prediction problem is one crucial problem in software test, to measure the performance, several indexes are introduced. In this paper, a two-objective software defect prediction model is employed, while probability of false alarm rate and probability of detection are taken as two objectives. To solve this model, one hybrid algorithm combined with support vector machine SVM and cuckoo search algorithm is designed. SVM is one general tool for this problem, and the performance is significantly influenced by two parameters. To provide a good classification results, one multi-objective cuckoo search algorithm is designed to optimise these two parameters. In this algorithm, the global best position is extended to be one collection including all non-dominated solutions, and the local search manner is changed to increase the local search speed. Simulation results show our hybrid algorithm is effective.},
journal = {Int. J. Innov. Comput. Appl.},
month = jan,
pages = {207–212},
numpages = {6}
}

@article{10.1155/2021/5990020,
author = {Chen, Xieyi and Wang, Dongyun and Shao, Jinjun and Fan, Jun and Pan, Zhaoqing},
title = {Plastic Gasket Defect Detection Based on Transfer Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/5990020},
doi = {10.1155/2021/5990020},
abstract = {To automatically detect plastic gasket defects, a set of plastic gasket defect visual detection devices based on GoogLeNet Inception-V2 transfer learning was designed and established in this study. The GoogLeNet Inception-V2 deep convolutional neural network (DCNN) was adopted to extract and classify the defect features of plastic gaskets to solve the problem of their numerous surface defects and difficulty in extracting and classifying the features. Deep learning applications require a large amount of training data to avoid model overfitting, but there are few datasets of plastic gasket defects. To address this issue, data augmentation was applied to our dataset. Finally, the performance of the three convolutional neural networks was comprehensively compared. The results showed that the GoogLeNet Inception-V2 transfer learning model had a better performance in less time. It means it had higher accuracy, reliability, and efficiency on the dataset used in this paper.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@article{10.1007/s10489-020-01935-6,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of ensemble techniques for software fault prediction},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {6},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01935-6},
doi = {10.1007/s10489-020-01935-6},
abstract = {Previously, many researchers have performed analysis of various techniques for the software fault prediction (SFP). Oddly, the majority of such studies have shown the limited prediction capability and their performance for given software fault datasets was not persistent. In contrast to this, recently, ensemble techniques based SFP models have shown promising and improved results across different software fault datasets. However, many new as well as improved ensemble techniques have been introduced, which are not explored for SFP. Motivated by this, the paper performs an investigation on ensemble techniques for SFP. We empirically assess the performance of seven ensemble techniques namely, Dagging, Decorate, Grading, MultiBoostAB, RealAdaBoost, Rotation Forest, and Ensemble Selection. We believe that most of these ensemble techniques are not used before for SFP. We conduct a series of experiments on the benchmark fault datasets and use three distinct classification algorithms, namely, naive Bayes, logistic regression, and J48 (decision tree) as base learners to the ensemble techniques. Experimental analysis revealed that rotation forest with J48 as the base learner achieved the highest precision, recall, and G-mean 1 values of 0.995, 0.994, and 0.994, respectively and Decorate achieved the highest AUC value of 0.986. Further, results of statistical tests showed used ensemble techniques demonstrated a statistically significant difference in their performance among the used ones for SFP. Additionally, the cost-benefit analysis showed that SFP models based on used ensemble techniques might be helpful in saving software testing cost and effort for twenty out of twenty-eight used fault datasets.},
journal = {Applied Intelligence},
month = jun,
pages = {3615–3644},
numpages = {30},
keywords = {Empirical analysis, PROMISE data repository, Ensemble techniques, Software fault prediction}
}

@article{10.1016/j.jss.2016.09.001,
author = {Andreou, Andreas S. and Chatzis, Sotirios P.},
title = {Software defect prediction using doubly stochastic Poisson processes driven by stochastic belief networks},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.09.001},
doi = {10.1016/j.jss.2016.09.001},
abstract = {This research aims at better addressing the challenges related with software defect prediction.We develop a novel Bayesian inference approach driven from appropriate metrics.Formulation of our method is based on a doubly stochastic homogeneous Poisson process.Our model better learns from data with multiple modes in their distributions.We evaluate generalization across software classes, subsequent releases, and projects. Accurate prediction of software defects is of crucial importance in software engineering. Software defect prediction comprises two major procedures: (i) Design of appropriate software metrics to represent characteristic software system properties; and (ii) development of effective regression models for count data, allowing for accurate prediction of the number of software defects. Although significant research effort has been devoted to software metrics design, research in count data regression has been rather limited. More specifically, most used methods have not been explicitly designed to tackle the problem of metrics-driven software defect counts prediction, thus postulating irrelevant assumptions, such as (log-)linearity of the modeled data. In addition, a lack of simple and efficient algorithms for posterior computation has made more elaborate hierarchical Bayesian approaches appear unattractive in the context of software defect prediction. To address these issues, in this paper we introduce a doubly stochastic Poisson process for count data regression, the failure log-rate of which is driven by a novel latent space stochastic feedforward neural network. Our approach yields simple and efficient updates for its complicated conditional distributions by means of sampling importance resampling and error backpropagation. We exhibit the efficacy of our approach using publicly available and benchmark datasets.},
journal = {J. Syst. Softw.},
month = dec,
pages = {72–82},
numpages = {11},
keywords = {Stochastic belief network, Software defect prediction, Sampling importance resampling, Doubly stochastic Poisson process}
}

@inproceedings{10.1109/COASE.2019.8843204,
author = {Niu, Shuanlong and Lin, Hui and Niu, Tongzhi and Li, Bin and Wang, Xinggang},
title = {DefectGAN: Weakly-Supervised Defect Detection using Generative Adversarial Network},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843204},
doi = {10.1109/COASE.2019.8843204},
abstract = {Traditional methods for defect detection applied in industry are complex, time-consuming, not robust and demanding for professional experience due to hand-crafted features extraction and pipeline design. Besides, current deep learning based methods for general object segmentation demand for a large number of region-level human annotations.Instead, we present DefectGAN for defect detection in a weakly-supervised learning, which requires very a few human annotations. In practical application, images in training dataset are merely labeled with two categories: negative and positive. Despite being trained on image-level rather than region-level labels, DefectGAN has remarkable ability of localizing defect regions.DefectGAN can have comparable and visually even better performance than SegNet, a supervised learning method on dataset CCSD-NL and DAGM 2007. The detected regions are more similar to the original defect regions visually and it has the potential of detecting unseen defects.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {127–132},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@article{10.1007/s11042-020-09245-2,
author = {Xu, Jiabin and Zhang, Jindong and Zhang, Kunpeng and Liu, Tong and Wang, Donghui and Wang, Xue},
title = {An APF-ACO algorithm for automatic defect detection on vehicle paint},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {35–36},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09245-2},
doi = {10.1007/s11042-020-09245-2},
abstract = {As a popular technology in the field of artificial intelligence, computer vision is gradually adapting to the needs of convenience for human beings, improving production efficiency and reducing production costs. Therefore, this study proposes a computer vision algorithm to locate and identify the location of defects. For the traditional edge detection algorithm Sobel, LoG, Canny, the decisive factor for the detection effect of paint defect image is the adjustment of parameters, which can’t achieve an adaptive edge detection algorithm for paint defects, so it is thought that the evolution idea of ant colony algorithm can be used to achieve accurate detection of defects. This paper proposes an automatic detection method for vehicle body paint film defects based on computer vision. An ant colony optimization edge detection algorithm based on automotive paint features (APF-ACO) is proposed. By combining global update and local update, the convergence speed of ant colony algorithm is improved and a new pheromone calculation and update method is proposed to effectively preserve the edge details of the detected image. A reflection area detection algorithm based on HSV color space is designed to detect the reflective area and eliminate interference. Establish defect classification identification rules, identify and mark five types of defects, and determine defect categories. Experiments show that the method can effectively detect the defect area and the recognition accuracy is 97.76%.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {25315–25333},
numpages = {19},
keywords = {Computer vision, Image edge detection, Defect detection, Ant colony algorithm}
}

@inproceedings{10.1007/978-3-030-31726-3_41,
author = {Wang, Junpu and Li, Chunlei and Liu, Zhoufeng and Dong, Yan and Huang, Yun},
title = {Combing Deep and Handcrafted Features for NTV-NRPCA Based Fabric Defect Detection},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_41},
doi = {10.1007/978-3-030-31726-3_41},
abstract = {Fabric defect detection plays an important role in automated inspection and quality control in textile manufacturing. As the textures and defects in fabric images have complexity and diversity, the traditional detection methods show a poor adaptability and low detection accuracy. Low-rank decomposition model that can be used to separate the image into object and background have proven applicable in fabric defect detection. However, how to represent texture feature of the fabric image more effectively is still problematic in this kind of method. Also, in traditional Low-rank decomposition model, we tend to seek the convex surrogate to resolve this model. However, this results in low accuracy and more noises in sparse part. In this paper, a novel fabric defect detection method based on combination of deep global feature and handcrafted local features and NTV-NRPCA is proposed. In this method, image representation ability is well enhanced through fusing the global deep feature extracted by a convolutional neural network and the handcrafted low-level feature masterly. Then, the non-convex total variation regularized non-convex RPCA (NTV-NRPCA) is proposed in which non-convex solution is more approximate to the real solution and non-convex total variation constraint significantly reduces the noises in sparse part. Finally, the defect region is located by segmenting the saliency map generated by the sparse matrix via a threshold segmentation algorithm. The experimental results show that the proposed method improves the adaptability and detection accuracy comparing to the state-of-the-art.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {479–490},
numpages = {12},
keywords = {Non-convex, Total variation, RPCA, Deep-handcrafted feature, Fabric defect detection},
location = {Xi'an, China}
}

@inproceedings{10.1007/978-3-319-97310-4_54,
author = {Zhao, Zhixuan and Li, Bo and Dong, Rong and Zhao, Peng},
title = {A Surface Defect Detection Method Based on Positive Samples},
year = {2018},
isbn = {978-3-319-97309-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-97310-4_54},
doi = {10.1007/978-3-319-97310-4_54},
abstract = {Surface defect detection and classification based on machine vision can greatly improve the efficiency of industrial production. With enough labeled images, defect detection methods based on convolution neural network have achieved the detection effect of state-of-art. However in practical applications, the defect samples or negative samples are usually difficult to be collected beforehand and manual labelling is time-consuming. In this paper, a novel defect detection framework only based on training of positive samples is proposed. The basic detection concept is to establish a reconstruction network which can repair defect areas in the samples if they are existed, and then make a comparison between the input sample and the restored one to indicate the accurate defect areas. We combine GAN and autoencoder for defect image reconstruction and use LBP for image local contrast to detect defects. In the training process of the algorithm, only positive samples is needed, without defect samples and manual label. This paper carries out verification experiments for concentrated fabric images and the dataset of DAGM 2007. Experiments show that the proposed GAN+LBP algorithm and supervised training algorithm with sufficient training samples have fairly high detection accuracy. Because of its unsupervised characteristics, it has higher practical application value.},
booktitle = {PRICAI 2018: Trends in Artificial Intelligence: 15th Pacific Rim International Conference on Artificial Intelligence, Nanjing, China, August 28–31, 2018, Proceedings, Part II},
pages = {473–481},
numpages = {9},
keywords = {Positive samples, Surface defect detection, Autoencoder, GAN},
location = {Nanjing, China}
}

@inproceedings{10.1145/3349341.3349488,
author = {Zhao, Jiuling},
title = {Defect Detection of Solid Rocket Motor Based on Improved Ring Shadow Suppression Algorithm},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349488},
doi = {10.1145/3349341.3349488},
abstract = {An improved annular artifact suppression algorithm is proposed to solve the problem that the third generation CT images are often affected by annular artifacts. An image segmentation algorithm based on mathematical morphology and threshold segmentation algorithm is used to segment CT images after annuls suppression and calculate the feature values of the defects. Finally, a real solid rocket motor CT image is detected by defect detection algorithm, and the detection method proposed in this paper is verified. The results show that the annular artifact is effectively suppressed, and the solid rocket motor defect is extracted accurately.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {673–677},
numpages = {5},
keywords = {Solid rocket motor, Image segmentation, Eigenvalue, Defect detection, Annular artifact},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@phdthesis{10.5555/AAI28962495,
author = {Shen, Mingren and Izabela, Szlufarska, and K., Chan, Maria and Victor, Zavala, and Paul, Evans,},
advisor = {Dane, Morgan,},
title = {Machine Learning Applications in Material Science Problems},
year = {2021},
isbn = {9798762108003},
publisher = {The University of Wisconsin - Madison},
abstract = {Machine learning tools have the potential to provide a new solution for problems in material science community. In this thesis, I will present my works about applying machine learning methods to solve two typical material sciences problems, one is the defect detection problem and another one is the X-ray image pattern problem. Chapter 1 is an introduction of the thesis that states the goal of this thesis and key concepts learned in my Ph.D. study. Chapter 2 talks about the important background knowledge about machine learning, deep learning, and computer vision which are frequently used later. In Chapter 3, three deep learning based defect analysis systems are discussed for TEM/STEM images or videos. Those models prove the ability of deep learning models and show the potential of applying them to solve defect detection problems. In Chapter 4, we introduce a deep learning based classifier that can assist the interpretation of X-ray image patterns which paves the way to better understand the patterns. Chapter 5 summarize other published work I completed at UW-Madison which were not closely related to material science but shared the general theme of this thesis. Finally, in Chapter 6, a summary and future of work is present.},
note = {AAI28962495}
}

@inproceedings{10.1109/ICMLA.2012.226,
author = {Hall, Tracy and Bowes, David},
title = {The State of Machine Learning Methodology in Software Fault Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.226},
doi = {10.1109/ICMLA.2012.226},
abstract = {The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {308–313},
numpages = {6},
keywords = {software engineering, methodology, machine learning, fault prediction, experimental techniques},
series = {ICMLA '12}
}

@article{10.1109/TVLSI.2021.3082476,
author = {Erozan, Ahmet Turan and Bosse, Simon and Tahoori, Mehdi B.},
title = {Defect Detection in Transparent Printed Electronics Using Learning-Based Optical Inspection},
year = {2021},
issue_date = {Aug. 2021},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {29},
number = {8},
issn = {1063-8210},
url = {https://doi.org/10.1109/TVLSI.2021.3082476},
doi = {10.1109/TVLSI.2021.3082476},
abstract = {Printed electronics (PE) is an emerging technology that provides attractive and complementary features compared to traditional wafer-scale silicon fabrication, such as flexible substrate and point-of-use ultralow-cost manufacturing. The low-cost manufacturing and larger feature sizes mandate reduced complexity in circuit size and also limited and transparent printing layers. This enables optical inspection for manufacturing defect detection, eliminating the need for electrical testing for gross defect detection. Therefore, the traditional problem of controllability and observability in logic testing can completely be alleviated. In this article, we present a learning-based method for optical inspection to detect defective transistors in transparent PE. The method leverages domain-specific as well as common inspection features extracted from optical images to detect defective transistors using supervised learning algorithms trained with real fabricated transistor images. The results show that the proposed method detects 95% of the defective transistors, which can significantly reduce the cost of the overall test flow.},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
month = aug,
pages = {1505–1517},
numpages = {13}
}

@article{10.1016/j.asoc.2014.11.023,
author = {Malhotra, Ruchika},
title = {A systematic review of machine learning techniques for software fault prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.11.023},
doi = {10.1016/j.asoc.2014.11.023},
abstract = {Reviews studies from 1991-2013 to assess application of ML techniques for SFP.Identifies seven categories of the ML techniques.Identifies 64 studies to answer the established research questions.Selects primary studies according to the quality assessment of the studies.Systematic literature review performs the following:Summarize ML techniques for SFP models.Assess performance accuracy and capability of ML techniques for constructing SFP models.Provide comparison between the ML and statistical techniques.Provide comparison of performance accuracy of different ML techniques.Summarize the strength and weakness of the ML techniques.Provides future guidelines to software practitioners and researchers. BackgroundSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. MethodIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. ResultsIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. ConclusionBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.},
journal = {Appl. Soft Comput.},
month = feb,
pages = {504–518},
numpages = {15},
keywords = {Systematic literature review, Software fault proneness, Machine learning}
}

@inproceedings{10.1145/3220267.3220286,
author = {El-Shorbagy, Sara Adel and El-Gammal, Wael Mohamed and Abdelmoez, Walid M.},
title = {Using SMOTE and Heterogeneous Stacking in Ensemble learning for Software Defect Prediction},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220286},
doi = {10.1145/3220267.3220286},
abstract = {Nowadays, there are a lot of classifications models used for predictions in the software engineering field such as effort estimation and defect prediction. One of these models is the ensemble learning machine that improves model performance by combining multiple models in different ways to get a more powerful model.One of the problems facing the prediction model is the misclassification of the minority samples. This problem mainly appears in the case of defect prediction. Our aim is the classification of defects which are considered minority samples during the training phase. This can be improved by implementing the Synthetic Minority Over-Sampling Technique (SMOTE) before the implementation of the ensemble model which leads to over-sample the minority class instances.In this paper, our work propose applying a new ensemble model by combining the SMOTE technique with the heterogeneous stacking ensemble to get the most benefit and performance in training a dataset that focus on the minority subset as in the software prediction study. Our proposed model shows better performance that overcomes other techniques results applied on the minority samples of the defect prediction.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {44–47},
numpages = {4},
keywords = {Stacking, Software Engineering, SMOTE, Machine Learning, Heterogeneous, Ensemble, Defect Prediction, Classification},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@article{10.1007/s10489-021-02346-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {12},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-021-02346-x},
doi = {10.1007/s10489-021-02346-x},
abstract = {An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach’s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software’s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost.},
journal = {Applied Intelligence},
month = dec,
pages = {8945–8960},
numpages = {16},
keywords = {Machine learning techniques, Cost-benefit analysis, Dynamic selection, Eclipse project, Software fault prediction}
}

@inproceedings{10.1109/COASE.2019.8842998,
author = {Zhang, Haodong and Chen, Zuzhi and Zhang, Chaoqun and Xi, Juntong and Le, Xinyi},
title = {Weld Defect Detection Based on Deep Learning Method},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8842998},
doi = {10.1109/COASE.2019.8842998},
abstract = {Welding is an important joining technology but the defects in welds wreck the quality of the product evidently. Due to the variety of weld defects’ characteristics, weld defect detection is a complex task in industry. In this paper, we try to explore a possible solution for weld defect detection and a novel image-based approach is proposed using small X-ray image data sets. An image-processing based data augmentation approach and a WGAN based data augmentation approach are applied to deal with imbalanced image sets. Then we train two deep convolutional neural networks (CNNs) on the augmented image sets using feature-extraction based transfer learning techniques. The two trained CNNs are combined to classify defects through a multi-model ensemble framework, aiming at lower false detection rate. Both of the experiments on augmented images and real world defect images achieve satisfying accuracy, which substantiates the possibility that the proposed approach is promising for weld defect detection.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {1574–1579},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.patcog.2019.107057,
author = {Yan, Yaping and Kaneko, Shun’ichi and Asano, Hirokazu},
title = {Accumulated and aggregated shifting of intensity for defect detection on micro 3D textured surfaces},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2019.107057},
doi = {10.1016/j.patcog.2019.107057},
journal = {Pattern Recogn.},
month = feb,
numpages = {11},
keywords = {Illumination invariance, Saliency description, Accumulated and aggregated shifting of intensity (AASI) procedure, Defect detection}
}

@inproceedings{10.1109/ISISE.2012.114,
author = {Wang, Pei and Jin, Cong and Jin, Shu-Wei},
title = {Software Defect Prediction Scheme Based on Feature Selection},
year = {2012},
isbn = {9780769549514},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2012.114},
doi = {10.1109/ISISE.2012.114},
abstract = {Predicting defect-prone software modules accurately and effectively are important ways to control the quality of a software system during software development. Feature selection can highly improve the accuracy and efficiency of the software defect prediction model. The main purpose of this paper is to discuss the best size of feature subset for building a prediction model and prove that feature selection method is useful for establishing software defect prediction model. Mutual information is an outstanding indicator of relevance between variables, and it has been used as a measurement in our feature selection algorithm. We also introduce a nonlinear factor to our evaluation function for feature selection to improve its performance. The results of our feature selection algorithm are validated by different machine learning methods. The experiment results show that all the classifiers achieve higher accuracy by using the feature subset provided by our algorithm.},
booktitle = {Proceedings of the 2012 Fourth International Symposium on Information Science and Engineering},
pages = {477–480},
numpages = {4},
keywords = {software defect prediction, mutual information, feature selection},
series = {ISISE '12}
}

@article{10.1016/j.knosys.2015.10.009,
author = {Rana, Zeeshan Ali and Mian, M. Awais and Shamail, Shafay},
title = {Improving Recall of software defect prediction models using association mining},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {90},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.10.009},
doi = {10.1016/j.knosys.2015.10.009},
abstract = {Use of software product metrics in defect prediction studies highlights the utility of these metrics. Public availability of software defect data based on the product metrics has resulted in the development of defect prediction models. These models experience a limitation in learning Defect-prone (D) modules because the available datasets are imbalanced. Most of the datasets are dominated by Not Defect-prone (ND) modules as compared to D modules. This affects the ability of classification models to learn the D modules more accurately. This paper presents an association mining based approach that allows the defect prediction models to learn D modules in imbalanced datasets. The proposed algorithm preprocesses data by setting specific metric values as missing and improves the prediction of D modules. The proposed algorithm has been evaluated using 5 public datasets. A Naive Bayes (NB) classifier has been developed before and after the proposed preprocessing. It has been shown that Recall of the classifier after the proposed preprocessing has improved. Stability of the approach has been tested by experimenting the algorithm with different number of bins. The results show that the algorithm has resulted in up to 40% performance gain.},
journal = {Know.-Based Syst.},
month = dec,
pages = {1–13},
numpages = {13},
keywords = {Software defect prediction, PROMISE repository, Naive Bayes, Improving Recall, Imbalanced data, Association mining}
}

@inproceedings{10.1145/3383219.3383281,
author = {Khan, Bilal and Iqbal, Danish and Badshah, Sher},
title = {Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383281},
doi = {10.1145/3383219.3383281},
abstract = {Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {434–438},
numpages = {5},
keywords = {data leveraging, Software fault prediction, Software Quality, Machine learning, Instance-based learning, Cross-project},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1007/978-3-030-38961-1_8,
author = {Sun, Yuanyuan and Xu, Lele and Guo, Lili and Li, Ye and Wang, Yongming},
title = {A Comparison Study of VAE and GAN for Software Fault Prediction},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_8},
doi = {10.1007/978-3-030-38961-1_8},
abstract = {Software fault is an unavoidable problem in software project. How to predict software fault to enhance safety and reliability of system is worth studying. In recent years, deep learning has been widely used in the fields of image, text and voice. However it is seldom applied in the field of software fault prediction. Considering the ability of deep learning, we select the deep learning techniques of VAE and GAN for software fault prediction and compare the performance of them. There is one salient feature of software fault data. The proportion of non-fault data is well above the proportion of fault data. Because of the imbalanced data, it is difficult to get high accuracy to predict software fault. As we known, VAE and GAN are able to generate synthetic samples that obey the distribution of real data. We try to take advantage of their power to generate new fault samples in order to improve the accuracy of software fault prediction. The architectures of VAE and GAN are designed to fit for the high dimensional software fault data. New software fault samples are generated to balance the software fault datasets in order to get better performance for software fault prediction. The models of VAE and GAN are trained on GPU TITAN X. SMOTE is also adopted in order to compare the performance with VAE and GAN. The results in the experiment show that VAE and GAN are useful techniques for software fault prediction and VAE has better performance than GAN on this issue.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {82–96},
numpages = {15},
keywords = {Software fault prediction, GAN, VAE, Deep learning},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3358331.3358376,
author = {Easttom, Chuck},
title = {A Methodological Approach to Weaponizing Machine Learning},
year = {2019},
isbn = {9781450372022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358331.3358376},
doi = {10.1145/3358331.3358376},
abstract = {The current literature is replete with studies involving the use of machine learning algorithms for defensive security implementations. For example, machine learning has been utilized to enhance antivirus software and intrusion detection systems. The use of machine learning in defensive cybersecurity operations is well documented. However, there is a substantial gap in the literature on the offensive use of machine learning. Particularly, use of machine learning algorithms to enhance cyber warfare operations. Cyber components to modern conflicts, whether those conflicts are cyber or kinetic warfare, are a fact of the modern international political landscape. It is a natural progression to explore applications of machine learning to cyber warfare, particularly weaponized malware.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Advanced Manufacturing},
articleno = {45},
numpages = {5},
keywords = {weaponized malware, machine learning, cyber warfare, Weaponized malware},
location = {Dublin, Ireland},
series = {AIAM 2019}
}

@article{10.1016/j.asoc.2021.107306,
author = {Shaul Hameed, Syed and Muralidharan, V. and Ane, Bernadetta Kwintiana},
title = {Comparative analysis of fuzzy classifier and ANN with histogram features for defect detection and classification in planetary gearbox},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107306},
doi = {10.1016/j.asoc.2021.107306},
journal = {Appl. Soft Comput.},
month = jul,
numpages = {14},
keywords = {ANN, Fuzzy classifier, Decision tree, Histogram features, Defect detection}
}

@inproceedings{10.1007/978-3-030-59722-1_72,
author = {Ding, Fei and Yang, Gang and Ding, Dayong and Cheng, Gangwei},
title = {Retinal Nerve Fiber Layer Defect Detection with Position Guidance},
year = {2020},
isbn = {978-3-030-59721-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59722-1_72},
doi = {10.1007/978-3-030-59722-1_72},
abstract = {The retinal nerve fiber layer defect (RNFLD) provides early diagnostic evidence for many irreversible disabling or blinding diseases. This paper aims for automated RNFLD detection based on fundus images. Different from previous works that only consider the local contexts, we are the first to propose to detect RNFLD with position guidance, which senses both the physiological position and global dependencies with ease. Our solution consists of a position-consistent data preprocessing, a Position Guided Network, and a weakly supervised learning strategy. In the position-consistent data preprocessing, the optic disc region is evenly divided into several sectors according to the distribution regularity of RNFL. To detect RNFLD in sectors, the proposed Position Guided Network highlights the significant region with a position-aware attention module and captures the global dependencies with a bidirectional GRU module. The dataset about RNFLD suffers from noise labels, which is verified in our created dataset containing 4,335 fundus images. Thus the weakly supervised learning strategy, which jointly optimizes network parameters and label distributions, is proposed to reduce the impact of noise labels. Tested on a clinical dataset of 750 images, our solution achieves outstanding performance, attaining the F1 score of 81.00% that outperforms the baseline by 13.71%.},
booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part V},
pages = {745–754},
numpages = {10},
keywords = {Dependency, Position, Cnn, Fundus image, RNFLD},
location = {Lima, Peru}
}

@inproceedings{10.1109/COASE.2019.8843235,
author = {Xiao, Ling and Huang, Tao and Wu, Bo and Hu, Youmin and Zhou, Jiehan},
title = {Surface Defect Detection using Hierarchical Features},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843235},
doi = {10.1109/COASE.2019.8843235},
abstract = {In this paper, we propose an instance level hierarchical features based convolution neural network model (H-CNN) for detecting surface defects. The H-CNN uses different convolutional layers’ extracted features to generate defect masks. The H-CNN first generates proposal regions. Then, it proposes a fully convolutional neural network to extract different level’s convolutional features and detect instance level defects. We applied the H-CNN model in freight train detection system for detecting oil-leaks, and the results demonstrate that the H-CNN can effectively identify and generate defect masks. It achieves 92% accuracy on the large reflective oil-leak stain, 86% on the large non-reflective oil-leak stain, 89% on the small reflective oil-leak stain and 74% on the small non-reflective oil-leak stain. Its image process speed is 0.467 s per frame.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {1592–1596},
numpages = {5},
location = {Vancouver, BC, Canada}
}

@article{10.1007/s10664-021-09991-3,
author = {Tahir, Amjed and Bennin, Kwabena E. and Xiao, Xun and MacDonell, Stephen G.},
title = {Does class size matter? An in-depth assessment of the effect of class size in software defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09991-3},
doi = {10.1007/s10664-021-09991-3},
abstract = {In the past 20 years, defect prediction studies have generally acknowledged the effect of class size on software prediction performance. To quantify the relationship between object-oriented (OO) metrics and defects, modelling has to take into account the direct, and potentially indirect, effects of class size on defects. However, some studies have shown that size cannot be simply controlled or ignored, when building prediction models. As such, there remains a question whether, and when, to control for class size. This study provides a new in-depth examination of the impact of class size on the relationship between OO metrics and software defects or defect-proneness. We assess the impact of class size on the number of defects and defect-proneness in software systems by employing a regression-based mediation (with bootstrapping) and moderation analysis to investigate the direct and indirect effect of class size in count and binary defect prediction. Our results show that the size effect is not always significant for all metrics. Of the seven OO metrics we investigated, size consistently has significant mediation impact only on the relationship between Coupling Between Objects (CBO) and defects/defect-proneness, and a potential moderation impact on the relationship between Fan-out and defects/defect-proneness. Other metrics show mixed results, in that they are significant for some systems but not for others. Based on our results we make three recommendations. One, we encourage researchers and practitioners to examine the impact of class size for the specific data they have in hand and through the use of the proposed statistical mediation/moderation procedures. Two, we encourage empirical studies to investigate the indirect effect of possible additional variables in their models when relevant. Three, the statistical procedures adopted in this study could be used in other empirical software engineering research to investigate the influence of potential mediators/moderators.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {38},
keywords = {Software quality, Metrics, Class size, Defect prediction}
}

@inproceedings{10.1145/3381271.3381298,
author = {Chen, Xue and Cao, Jian-Wen and Wang, Yu-Peng},
title = {Defect detection in ID cards with accurately reconstructed reference image},
year = {2020},
isbn = {9781450376648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381271.3381298},
doi = {10.1145/3381271.3381298},
abstract = {ID card is made by hot-pressing a standard film with identifiable information onto a fixed baseboard with background of wavy lines. In this paper, we propose a defect detect algorithm by synthesising the film image and baseboard image to accurately reconstruct a reference image for a test card. First, to ensure the content consistency in position and scale, we align the card to a standard film image through perspective transformation(PT) based on AKAZE key-points. Besides, we use contrast limited adaptive histogram equalization(CLAHE) to enhance the background pattern of a baseboard image, and then align it to the rectified card. Second, we apply multiply algorithm to synthesise the aligned film image and baseboard image as a reconstructed reference image. Besides, we align the lightness histogram of the reference image to a test card so as to eliminate the lighting difference. Finally, we apply the difference image method based on canny edge detection to detect difference between a reference image with a card, and further extract the defect information. We experiment on cards with different types of defects and shooting disturbances. Results show high accuracy of our method.},
booktitle = {Proceedings of the 5th International Conference on Multimedia and Image Processing},
pages = {18–22},
numpages = {5},
keywords = {reference image, lightness histogram, difference image, defect detection, AKAZE},
location = {Nanjing, China},
series = {ICMIP '20}
}

@article{10.1504/ijbidm.2021.115475,
author = {Manimozhi, I. and Janakiraman, S.},
title = {An efficient approach for defect detection in pattern texture analysis using an improved support vector machine},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {4},
issn = {1743-8195},
url = {https://doi.org/10.1504/ijbidm.2021.115475},
doi = {10.1504/ijbidm.2021.115475},
abstract = {Texture defect detection can be defined as the process of determining the location and size of the collection pixels in a textured image which deviate in their intensity values or spatial in compression to a background texture. The detection of abnormalities is a very challenging problem in computer vision. In our proposed method we have designed a method for detecting the defect of pattern texture analysis. Initially, features are extracted from the input image using the grey level co-occurrence matrix (GLCM) and grey level run-length matrix (GLRLM). Then the extracted features are fed to the input of classification stage. Here the classification is done by improved support vector machine (ISVM). The proposed pattern analysis showed that the traditional support vector machine is improved by means of kernel methods. In the final stage, the classified features are segmented using the modified fuzzy c means algorithm (MFCM).},
journal = {Int. J. Bus. Intell. Data Min.},
month = jan,
pages = {411–434},
numpages = {23},
keywords = {MFCM, modified fuzzy c means, ISVM, improved support vector machine, GLRLM, grey level run-length matrix, GLCM, grey level co-occurrence matrix, preprocessing, texture defect detection}
}

@inproceedings{10.1145/3480571.3480605,
author = {Yang, Guihua and Dai, Zhicheng},
title = {Research on Copper Foil Winding of Transformer Surface Defect Detection Based on Machine Vision},
year = {2021},
isbn = {9781450390637},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3480571.3480605},
doi = {10.1145/3480571.3480605},
booktitle = {Proceedings of the 6th International Conference on Intelligent Information Processing},
pages = {187–192},
numpages = {6},
keywords = {Machine vision, Image processing, Defect detection, Copper foil windings},
location = {Bucharest, Romania},
series = {ICIIP '21}
}

@inproceedings{10.1145/3379247.3379278,
author = {Ahmed, Md. Razu and Ali, Md. Asraf and Ahmed, Nasim and Zamal, Md. Fahad Bin and Shamrat, F.M. Javed Mehedi},
title = {The Impact of Software Fault Prediction in Real-World Application: An Automated Approach for Software Engineering},
year = {2020},
isbn = {9781450376730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379247.3379278},
doi = {10.1145/3379247.3379278},
abstract = {Software fault prediction and proneness has long been considered as a critical issue for the tech industry and software professionals. In the traditional techniques, it requires previous experience of faults or a faulty module while detecting the software faults inside an application. An automated software fault recovery models enable the software to significantly predict and recover software faults using machine learning techniques. Such ability of the feature makes the software to run more effectively and reduce the faults, time and cost. In this paper, we proposed a software defect predictive development models using machine learning techniques that can enable the software to continue its projected task. Moreover, we used different prominent evaluation benchmark to evaluate the model's performance such as ten-fold cross-validation techniques, precision, recall, specificity, f 1 measure, and accuracy. This study reports a significant classification performance of 98-100% using SVM on three defect datasets in terms of f1 measure. However, software practitioners and researchers can attain independent understanding from this study while selecting automated task for their intended application.},
booktitle = {Proceedings of 2020 6th International Conference on Computing and Data Engineering},
pages = {247–251},
numpages = {5},
keywords = {Software fault, Software engineering, Machine learning, Defect prediction},
location = {Sanya, China},
series = {ICCDE '20}
}

@inproceedings{10.1145/3183399.3183402,
author = {Koch, Patrick and Schekotihin, Konstantin and Jannach, Dietmar and Hofer, Birgit and Wotawa, Franz and Schmitz, Thomas},
title = {Combining spreadsheet smells for improved fault prediction},
year = {2018},
isbn = {9781450356626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183399.3183402},
doi = {10.1145/3183399.3183402},
abstract = {Spreadsheets are commonly used in organizations as a programming tool for business-related calculations and decision making. Since faults in spreadsheets can have severe business impacts, a number of approaches from general software engineering have been applied to spreadsheets in recent years, among them the concept of code smells. Smells can in particular be used for the task of fault prediction. An analysis of existing spreadsheet smells, however, revealed that the predictive power of individual smells can be limited. In this work we therefore propose a machine learning based approach which combines the predictions of individual smells by using an AdaBoost ensemble classifier. Experiments on two public datasets containing real-world spreadsheet faults show significant improvements in terms of fault prediction accuracy.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {25–28},
numpages = {4},
keywords = {spreadsheet smells, spreadsheet QA, fault prediction},
location = {Gothenburg, Sweden},
series = {ICSE-NIER '18}
}

@article{10.1016/j.infsof.2011.09.007,
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
title = {Transfer learning for cross-company software defect prediction},
year = {2012},
issue_date = {March, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.09.007},
doi = {10.1016/j.infsof.2011.09.007},
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {248–256},
numpages = {9},
keywords = {Transfer learning, Software defect prediction, Naive Bayes, Machine learning, Different distribution}
}

@article{10.1155/2021/5592878,
author = {Zhao, Weidong and Chen, Feng and Huang, Hancheng and Li, Dan and Cheng, Wei and Versaci, Mario},
title = {A New Steel Defect Detection Algorithm Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5592878},
doi = {10.1155/2021/5592878},
abstract = {In recent years, more and more scholars devoted themselves to the research of the target detection algorithm due to the continuous development of deep learning. Among them, the detection and recognition of small and complex targets are still a problem to be solved. The authors of this article have understood the shortcomings of the deep learning detection algorithm in detecting small and complex defect targets and would like to share a new improved target detection algorithm in steel surface defect detection. The steel surface defects will affect the quality of steel seriously. We find that most of the current detection algorithms for NEU-DET dataset detection accuracy are low, so we choose to verify a steel surface defect detection algorithm based on machine vision on this dataset for the problem of defect detection in steel production. A series of improvement measures are carried out in the traditional Faster R-CNN algorithm, such as reconstructing the network structure of Faster R-CNN. Based on the small features of the target, we train the network with multiscale fusion. For the complex features of the target, we replace part of the conventional convolution network with a deformable convolution network. The experimental results show that the deep learning network model trained by the proposed method has good detection performance, and the mean average precision is 0.752, which is 0.128 higher than the original algorithm. Among them, the average precision of crazing, inclusion, patches, pitted surface, rolled in scale and scratches is 0.501, 0.791, 0.792, 0.874, 0.649, and 0.905, respectively. The detection method is able to identify small target defects on the steel surface effectively, which can provide a reference for the automatic detection of steel defects.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1016/j.jss.2019.110402,
author = {Xu, Zhou and Li, Shuai and Xu, Jun and Liu, Jin and Luo, Xiapu and Zhang, Yifeng and Zhang, Tao and Keung, Jacky and Tang, Yutian},
title = {LDFR: Learning deep feature representation for software defect prediction},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110402},
doi = {10.1016/j.jss.2019.110402},
journal = {J. Syst. Softw.},
month = dec,
numpages = {20},
keywords = {99-00, 00-01, Deep neural network, Weighted cross-entropy loss, Triplet loss, Deep feature representation, Software defect prediction}
}

@article{10.5555/3324436.3324448,
title = {A statistical comparison for evaluating the effectiveness of linear and nonlinear manifold detection techniques for software defect prediction},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {3–4},
issn = {1755-0386},
abstract = {Most of the software systems are released without predicting defects and therefore, this paper presents a new effective technique-manifold detection technique MDT is essential and different than earlier applied defect prediction methods like regression, feature selection methods, etc. In this paper, performance of classifiers has been compared with or without MDTs to evaluate the effectiveness of different MDTs linear and nonlinear by reducing the dimensions of software datasets. In this process, eight classifiers were applied to four PROMISE datasets to determine the best performing classifier with respect to prediction performance measuring factors accuracy, precision, recall, F-measure, AUC, misclassification error with or without MDTs. The experimental results statistically tested by paired two-tailed t-test proved that FastMVU is the most accurate result producing technique as compared to all other nonlinear MDTs and Bayesian network BN is the most effective technique for software defect prediction using with or without MDTs.},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {370–391},
numpages = {22}
}

@article{10.4018/IJOSSP.2017010102,
author = {Alsukhni, Emad and Saifan, Ahmad A. and Alawneh, Hanadi},
title = {A New Data Mining-Based Framework to Test Case Prioritization Using Software Defect Prediction},
year = {2017},
issue_date = {January 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017010102},
doi = {10.4018/IJOSSP.2017010102},
abstract = {Test cases do not have the same importance when used to detect faults in software; therefore, it is more efficient to test the system with the test cases that have the ability to detect the faults. This research proposes a new framework that combines data mining techniques to prioritize the test cases. It enhances fault prediction and detection using two different techniques: 1 the data mining regression classifier that depends on software metrics to predict defective modules, and 2 the k-means clustering technique that is used to select and prioritize test cases to identify the fault early. Our approach of test case prioritization yields good results in comparison with other studies. The authors used the Average Percentage of Faults Detection APFD metric to evaluate the proposed framework, which results in 19.9% for all system modules and 25.7% for defective ones. Our results give us an indication that it is effective to start the testing process with the most defective modules instead of testing all modules arbitrary arbitrarily.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {21–41},
numpages = {21},
keywords = {Test Case Prioritization, Software Testing, Software Defect Prediction, Data Mining}
}

@article{10.1007/s10462-020-09876-9,
author = {Goh, G. D. and Sing, S. L. and Yeong, W. Y.},
title = {A review on machine learning in 3D printing: applications, potential, and challenges},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09876-9},
doi = {10.1007/s10462-020-09876-9},
abstract = {Additive manufacturing (AM) or 3D printing is growing rapidly in the manufacturing industry and has gained a lot of attention from various fields owing to its ability to fabricate parts with complex features. The reliability of the 3D printed parts has been the focus of the researchers to realize AM as an end-part production tool. Machine learning (ML) has been applied in various aspects of AM to improve the whole design and manufacturing workflow especially in the era of industry 4.0. In this review article, various types of ML techniques are first introduced. It is then followed by the discussion on their use in various aspects of AM such as design for 3D printing, material tuning, process optimization, in situ monitoring, cloud service, and cybersecurity. Potential applications in the biomedical, tissue engineering and building and construction will be highlighted. The challenges faced by ML in AM such as computational cost, standards for qualification and data acquisition techniques will also be discussed. In the authors’ perspective, in situ monitoring of AM processes will significantly benefit from the object detection ability of ML. As a large data set is crucial for ML, data sharing of AM would enable faster adoption of ML in AM. Standards for the shared data are needed to facilitate easy sharing of data. The use of ML in AM will become more mature and widely adopted as better data acquisition techniques and more powerful computer chips for ML are developed.},
journal = {Artif. Intell. Rev.},
month = jan,
pages = {63–94},
numpages = {32},
keywords = {Process optimization, Additive manufacturing, In-situ monitoring, 3D printing, Artificial intelligence, Machine learning}
}

@article{10.1504/IJWMC.2016.076145,
author = {Li, Feixiang and Rong, Xiaotao and Cui, Zhihua},
title = {A hybrid CRBA-SVM model for software defect prediction},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/IJWMC.2016.076145},
doi = {10.1504/IJWMC.2016.076145},
abstract = {Support vector machine SVM model is becoming an increasingly popular method in software defects prediction. This model has strong non-linear classifying ability. However, SVM model lacks effective method to determine the best parameters. In this paper, a modified bat algorithm, named changing range bat algorithm, is employed to optimise the parameters of SVM model. To test the performance of this new model, several public datasets of software defect prediction are employed and then the results are compared with other five approaches. Experimental results show that the classification ability of hybrid CRBA-SVM model surpasses all other approaches.},
journal = {Int. J. Wire. Mob. Comput.},
month = apr,
pages = {191–196},
numpages = {6}
}

@article{10.1007/s10462-019-09760-1,
author = {Hassanien, Aboul Ella and Darwish, Ashraf and Abdelghafar, Sara},
title = {Machine learning in telemetry data mining of space mission: basics, challenging and future directions},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-019-09760-1},
doi = {10.1007/s10462-019-09760-1},
abstract = {The development of an intelligent artificial satellite health monitoring system is a key issue in aerospace engineering that determines satellite health status and failure using telemetry data. The modern design of data mining and machine learning technologies allows the use of satellite telemetry data and the mining of integrated information to produce an advanced health monitoring system. This paper reviews the current status and presents a framework of necessary processes on data mining to solving various problems in telemetry data such as error detection, prediction, summarization, and visualization of large quantities, and help them understand the health status of the satellite and detect the symptoms of anomalies. Machine learning technologies that include neural networks, fuzzy sets, rough sets, support vector machines, Naive Bayesian, swarm optimization, and deep learning are also presented. Also, this paper reviews a wide range of existing satellite health monitoring solutions and discusses them in the framework of remote data mining techniques. In addition, we are discussing the analysis of space debris flow analysis and the prediction of low earth orbit collision based on our orbital Petri nets model. Challenges to be addressed and future directions of research are identified and an extensive bibliography is also included.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3201–3230},
numpages = {30},
keywords = {Aerospace engineering, Debris, Deep learning, Machine learning, Satellite ground control operations, Satellite health monitoring, Satellite telemetry data mining}
}

@article{10.1007/s00500-020-04985-7,
author = {Le, D. Van-Khoa and Chen, Zhiyuan and Wong, Yee Wan and Isa, Dino},
title = {A complete online-SVM pipeline for case-based reasoning system: a study on pipe defect detection system},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-04985-7},
doi = {10.1007/s00500-020-04985-7},
abstract = {Recent developments in case-based reasoning system (CBR) have led to an interest in favoring machine learning (ML) approaches as a replacement for traditional weighted distance methods. However, valuable information obtained through a training process was relinquished as transferring to other phases. This paper proposed a complete pipeline integration of CBR using kernel method designated with support vector machine (SVM) as the main engine. Since the system requires learning SVM model to be invoked in every phase, the online learning mechanism is nominated to effectively update the model when a new case adjoins. The proposed full SVM-CBR integration has been successfully built into a pipe defect detection. The achieved result indicates a substantial improvement by transferring learning information accurately.},
journal = {Soft Comput.},
month = nov,
pages = {16917–16933},
numpages = {17},
keywords = {Expert system, SVM, Online learning, Case-based reasoning, Defect detection}
}

@article{10.1016/j.engappai.2019.01.008,
author = {Wei, Xiukun and Yang, Ziming and Liu, Yuxin and Wei, Dehua and Jia, Limin and Li, Yujie},
title = {Railway track fastener defect detection based on image processing and deep learning techniques: A comparative study},
year = {2019},
issue_date = {Apr 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {80},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.01.008},
doi = {10.1016/j.engappai.2019.01.008},
journal = {Eng. Appl. Artif. Intell.},
month = apr,
pages = {66–81},
numpages = {16},
keywords = {Faster R-CNN, DCNN, Feature extraction, Deep learning, Image processing, Detection, Track fastener}
}

@inproceedings{10.1145/3336294.3336303,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and Ramos-Guti\'{e}rrez, Bel\'{e}n and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Process Mining to Unleash Variability Management: Discovering Configuration Workflows Using Logs},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336303},
doi = {10.1145/3336294.3336303},
abstract = {Variability models are used to build configurators. Configurators are programs that guide users through the configuration process to reach a desired configuration that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the elements that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suites stakeholders according to previous configurations. For example, when configuring a Linux distribution, the configuration process start by choosing the network or the graphic card, and then other packages with respect to a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), an automated technique that given a set of logs of previous configurations and a variability model can automatically assist to determine the configuration workflow that better fits the configuration logs generated by user activities. The technique is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Our proposal is validated using existing data from an ERP configuration environment showing its feasibility. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {265–276},
numpages = {12},
keywords = {variability, process mining, process discovery, configuration workflow, clustering},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s11042-018-6483-6,
author = {Li, Chunlei and Liu, Chaodie and Gao, Guangshuai and Liu, Zhoufeng and Wang, Yuping},
title = {Robust low-rank decomposition of multi-channel feature matrices for fabric defect detection},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-6483-6},
doi = {10.1007/s11042-018-6483-6},
abstract = {Fabric defect detection plays an important role in the quality control of textile products. Most existing defect detection techniques adopted traditional pattern recognition methods, which were lacking adaptability and presented the undesirable detection accuracy. In this paper, a fabric defect detection algorithm based on multi-channel feature matrixes extraction and joint low-rank decomposition was proposed by simulating biological visual perception mechanism. Based on the fact that the second-order gradient information is more suitable for characterizing the fabric texture, we developed a novel second-order multi-channel feature extraction method by modeling the response and distribution properties of the P-type ganglion cells in the primate retina. Upon devising a powerful descriptor, a joint low-rank decomposition method is utilized to model biological visual saliency, and decomposes the fabric images into backgrounds and salient defect objects. Experimental results demonstrate that our proposed algorithm has good self-adaptability and detection performance for plain and twill fabrics or complex patterned fabrics, and is superior to the state-of-the-art methods.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {7321–7339},
numpages = {19},
keywords = {Second-order gradient, Multi-channel feature, Joint low-rank decomposition, Fabric images, Defect detection}
}

@article{10.1007/s10845-020-01563-4,
author = {Stern, Maike Lorena and Schellenberger, Martin},
title = {Fully convolutional networks for chip-wise defect detection employing photoluminescence images: Efficient quality control in LED manufacturing},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01563-4},
doi = {10.1007/s10845-020-01563-4},
abstract = {Efficient quality control is inevitable in the manufacturing of light-emitting diodes (LEDs). Because defective LED chips may be traced back to different causes, a time and cost-intensive electrical and optical contact measurement is employed. Fast photoluminescence measurements, on the other hand, are commonly used to detect wafer separation damages but also hold the potential to enable an efficient detection of all kinds of defective LED chips. On a photoluminescence image, every pixel corresponds to an LED chip’s brightness after photoexcitation, revealing performance information. But due to unevenly distributed brightness values and varying defect patterns, photoluminescence images are not yet employed for a comprehensive defect detection. In this work, we show that fully convolutional networks can be used for chip-wise defect detection, trained on a small data-set of photoluminescence images. Pixel-wise labels allow us to classify each and every chip as defective or not. Being measurement-based, labels are easy to procure and our experiments show that existing discrepancies between training images and labels do not hinder network training. Using weighted loss calculation, we were able to equalize our highly unbalanced class categories. Due to the consistent use of skip connections and residual shortcuts, our network is able to predict a variety of structures, from extensive defect clusters up to single defective LED chips.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {113–126},
numpages = {14},
keywords = {Industrial application, Quality control, LED manufacturing, Defect cluster detection, Chip-wise prediction, Photoluminescence images, Deep learning, Fully convolutional networks}
}

@article{10.1007/s10845-021-01774-3,
author = {Meister, Sebastian and Wermes, Mahdieu A. M. and St\"{u}ve, Jan and Groves, Roger M.},
title = {Review of image segmentation techniques for layup defect detection in the Automated Fiber Placement process: A comprehensive study to improve AFP inspection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {8},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01774-3},
doi = {10.1007/s10845-021-01774-3},
abstract = {The aerospace industry has established the Automated Fiber Placement process as a common technique for manufacturing fibre reinforced components. In this process multiple composite tows are placed simultaneously onto a tool. Currently in such processes manual testing requires often up to 50% of the manufacturing duration. Moreover, the accuracy of quality assurance varies significantly with the inspector in charge. Thus, inspection automation provides an effective way to increase efficiency. However, to achieve a proper inspection performance, the segmentation of layup defects need to be examined. In order to improve such defect detection systems, this paper performs a comprehensive ranking of segmentation techniques. Thus, 29 statistical, spectral and structural algorithms from related work were evaluated based on nine substantial criteria as assessed from literature and process requirements. For reasons of determinism and easy technology transferability without the need of much training data, the development of new Machine Learning algorithms is not part of this paper. Afterwards, seven of the most auspicious algorithms were studied experimentally. Therefore, laser line scan sensor depth maps from fibre placement defects were utilised. Furthermore noisy images were generated and applied for testing algorithm robustness. The test data contained five defect categories with 50 samples per class. It was concluded that Adaptive Thresholding and Cell Wise Standard Deviation Thresholding work best yielding detection accuracies mostly &gt;97%. Noteworthy is that influenced input data can affect the detection results. Feasible algorithms with sensible parameter settings were able to perform reliable defect segmentation for layed material.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {2099–2119},
numpages = {21},
keywords = {Laser line scan sensor, Computer vision, Adaptive thresholding, Inline inspection, Automated fiber placement, Image segmentation}
}

@inproceedings{10.1145/3351917.3351925,
author = {Wang, Jiankun and Hu, Hong and Chen, Long and He, Caiying},
title = {Assembly Defect Detection of Atomizers Based on Machine Vision},
year = {2019},
isbn = {9781450371865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351917.3351925},
doi = {10.1145/3351917.3351925},
abstract = {Atomizers are assembled in an automated assembly line, which inevitably creates assembly defects. In this paper, we use machine vision technology to detect assembly defects in atomizers. We propose two algorithms: an image processing algorithm, and a deep learning algorithm based on convolutional neural network. For design of the image processing algorithm, we set the region of interest for detection according to the position of different assembly defects. For the deep learning algorithm, we adopt the MobileNet model and propose a new training program to improve detection accuracy. The paper also includes an evaluation of the performance of the two algorithms and analyzes their advantages and disadvantages.},
booktitle = {Proceedings of the 2019 4th International Conference on Automation, Control and Robotics Engineering},
articleno = {1},
numpages = {6},
keywords = {Machine vision, Convolutional neural network, Atomizer, Assembly defect detection},
location = {Shenzhen, China},
series = {CACRE2019}
}

@inproceedings{10.1007/978-3-031-08421-8_41,
author = {Giorgio, Lazzarinetti and Nicola, Massarenti and Fabio, Sgr\`{o} and Andrea, Salafia},
title = {Continuous Defect Prediction in CI/CD Pipelines: A Machine Learning-Based Framework},
year = {2021},
isbn = {978-3-031-08420-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08421-8_41},
doi = {10.1007/978-3-031-08421-8_41},
abstract = {Recent advances in information technology has led to an increasing number of applications to be developed and maintained daily by product teams. Ensuring that a software application works as expected and that it is absent of bugs requires a lot of time and resources. Thanks to the recent adoption of DevOps methodologies, it is often the case where code commits and application builds are centralized and standardized. Thanks to this new approach, it is now possible to retrieve log and build data to ease the development and management operations of product teams. However, even if such approaches include code control to detect unit or integration errors, they do not check for the presence of logical bugs that can raise after code builds. For such reasons in this work we propose a framework for continuous defect prediction based on machine learning algorithms trained on a publicly available dataset. The framework is composed of a machine learning model for detecting the presence of logical bugs in code on the basis of the available data generated by DevOps tools and a dashboard to monitor the software projects status. We also describe the serverless architecture we designed for hosting the aforementioned framework.},
booktitle = {AIxIA 2021 – Advances in Artificial Intelligence: 20th International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1–3, 2021, Revised Selected Papers},
pages = {591–606},
numpages = {16},
keywords = {Continuous integration, DevOps, Machine learning, Continuous defect prediction}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00014,
author = {Idowu, Samuel and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Asset management in machine learning: a survey},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00014},
doi = {10.1109/ICSE-SEIP52600.2021.00014},
abstract = {Machine Learning (ML) techniques are becoming essential components of many software systems today, causing an increasing need to adapt traditional software engineering practices and tools to the development of ML-based software systems. This need is especially pronounced due to the challenges associated with the large-scale development and deployment of ML systems. Among the most commonly reported challenges during the development, production, and operation of ML-based systems are experiment management, dependency management, monitoring, and logging of ML assets. In recent years, we have seen several efforts to address these challenges as witnessed by an increasing number of tools for tracking and managing ML experiments and their assets. To facilitate research and practice on engineering intelligent systems, it is essential to understand the nature of the current tool support for managing ML assets. What kind of support is provided? What asset types are tracked? What operations are offered to users for managing those assets? We discuss and position ML asset management as an important discipline that provides methods and tools for ML assets as structures and the ML development activities as their operations. We present a feature-based survey of 17 tools with ML asset management support identified in a systematic search. We overview these tools' features for managing the different types of assets used for engineering ML-based systems and performing experiments. We found that most of the asset management support depends on traditional version control systems, while only a few tools support an asset granularity level that differentiates between important ML assets, such as datasets and models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {51–60},
numpages = {10},
keywords = {machine learning, asset management, SE4AI},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1007/s11277-021-08347-w,
author = {Zhu, Yanlong},
title = {Edge Defect Detection of Network Image by the Application of Modal Symmetry},
year = {2021},
issue_date = {Nov 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {127},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08347-w},
doi = {10.1007/s11277-021-08347-w},
abstract = {In order to improve the accuracy of detection the image defect, a method to detect the edge defect based on modal symmetry algorithm was put forward. The improved PCNN was used to deal with the salt-pepper noise and Gaussian noise in image. On this basis, the semantic learning and annotation of image features were achieved. At first, the corresponding features were extracted from the original image. And then, the semantics were learned by combining the extracted features and the manually labeled library. Combined with the semantic annotation of image, the modal symmetry algorithm was adopted to linearly subtract the data collected by two centrosymmetric sampling points and thus to get the mean value. The asymmetric modal information of the whole image was obtained. Thus, the asymmetric modal could be extracted from the symmetrical modal. Due to the high amplitude of asymmetrical modal signal in defect location. Finally, the defect identification for various locations in image was completed by judging whether the amplitude of asymmetrical modal at the defect location had a sudden change. Following conclusions can be drawn from experimental results. The proposed method has excellent performance in image processing. Meanwhile, this method has high detection accuracy and practicability.},
journal = {Wirel. Pers. Commun.},
month = mar,
pages = {561–576},
numpages = {16},
keywords = {Detection, Edge defect, Image, Modal symmetry algorithm}
}

@article{10.1111/mice.12533,
author = {Tong, Zheng and Yuan, Dongdong and Gao, Jie and Wang, Zhenjun},
title = {Pavement defect detection with fully convolutional network and an uncertainty framework},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {35},
number = {8},
issn = {1093-9687},
url = {https://doi.org/10.1111/mice.12533},
doi = {10.1111/mice.12533},
abstract = {Image segmentation has been implemented for pavement defect detection, from which types, locations, and geometric information can be obtained. In this study, an integration of a fully convolutional network with a Gaussian‐conditional random field (G‐CRF), an uncertainty framework, and probability‐based rejection is proposed for detecting pavement defects. First, a fully convolutional network is designed to generate preliminary segmentation results, and a G‐CRF is used to refine the segmentation. Second, epistemic and aleatory uncertainties in the model and database are considered to overcome the disadvantages of traditional deep‐learning methods. Last, probability‐based rejection is conducted to remove unreasonable segmentations. The proposed method is evaluated on a data set of images that were obtained from 16 highways. The proposed integration segments pavement distresses from digital images with desirable performance. It also provides a satisfactory means to improve the accuracy and generalization performance of pavement defect detection without introducing a delay into the segmentation process.},
journal = {Comput.-Aided Civ. Infrastruct. Eng.},
month = jul,
pages = {832–849},
numpages = {18}
}

@article{10.1016/j.eswa.2019.113156,
author = {Majd, Amirabbas and Vahidi-Asl, Mojtaba and Khalilian, Alireza and Poorsarvi-Tehrani, Pooria and Haghighi, Hassan},
title = {SLDeep: Statement-level software defect prediction using deep-learning model on static code features},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {147},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113156},
doi = {10.1016/j.eswa.2019.113156},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Software metric, Fault prediction model, Machine learning, Software fault proneness, Defect}
}

@article{10.1155/2021/2036466,
author = {Liu, Bangchao and Chen, Youping and Xie, Jingming and Chen, Bing and Praveenkumar, Padmapriya},
title = {Industrial Printing Image Defect Detection Using Multi-Edge Feature Fusion Algorithm},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/2036466},
doi = {10.1155/2021/2036466},
abstract = {Online defect detection system is a necessary technical measure and important means for large-scale industrial printing production. It is effective to reduce artificial detection fatigue and improve the accuracy and stability of industry printing line. However, the existing defect detection algorithms are mainly developed based on high-quality database and it is difficult to detect the defects on low-quality printing images. In this paper, we propose a new multi-edge feature fusion algorithm which is effective in solving this problem. Firstly, according to the characteristics of sheet-fed printing system, a new printing image database is established; compared with the existing databases, it has larger translation, deformation, and uneven illumination variation. These interferences make defect detection become more challenging. Then, SIFT feature is employed to register the database. In order to reduce the number of false detections which are caused by the position, deformation, and brightness deviation between the detected image and reference image, multi-edge feature fusion algorithm is proposed to overcome the effects of these disturbances. Lastly, the experimental results of mAP (92.65%) and recall (96.29%) verify the effectiveness of the proposed method which can effectively detect defects in low-quality printing database. The proposed research results can improve the adaptability of visual inspection system on a variety of different printing platforms. It is better to control the printing process and further reduce the number of operators.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@inproceedings{10.1145/3406601.3406650,
author = {Sousa, Carlos E. B. and Medeiros, Cl\'{a}udio M. S. and Pereira, Renato F. and Neto, Mateus A. V. and Neto, Alcides A.},
title = {Defect Detection and Quality Level Assignment in Wet Blue Goatskin},
year = {2020},
isbn = {9781450377591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406601.3406650},
doi = {10.1145/3406601.3406650},
abstract = {Tanneries acquire hides, in most cases, from rural workers, so, due to the informality of the creation, slaughter and extraction of the animal's skin, they receive them with different types and different defect levels. That said, classifying acquired and processed skins become very complex and tiring activity. The leather discrimination process is completely handmade and subjective, too dependent on the experience of the professional responsible for this step, which, due to tiredness, stress, and other factors, end up generating several errors in this process. Currently, there are several studies in the literature related to the detection of leather flaws, however, few studies go further and qualify the skins based on the detected problems. In view of this factor, a system based on computer vision and artificial intelligence are proposed in which it obtains an accuracy rate of 95.9 % in the detection of defects in wet blue goatskin and 93.3 % in the identification of the quality level of these parts.},
booktitle = {Proceedings of the 11th International Conference on Advances in Information Technology},
articleno = {45},
numpages = {7},
keywords = {Textile industry, Quality Level, Pattern Recognition, Goatskin},
location = {Bangkok, Thailand},
series = {IAIT '20}
}

@inproceedings{10.1145/3378891.3378894,
author = {Liu, Junliang and Zhu, Wei and Yang, Zekun},
title = {Batch-normalized Convolutional Neural Networks for Defect Detection of the Steel Strip},
year = {2020},
isbn = {9781450365130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378891.3378894},
doi = {10.1145/3378891.3378894},
abstract = {Surface defect detection uses advanced machine vision inspection technology to detect defects such as spots, pits, scratches and chromatic aberrations on the surface of the workpiece. The traditional machine vision detection method requires manual selection of defect features as the basis of defect identification, which is time-consuming and laborious and has low accuracy in defect detection. To overcome the aforementioned deficiencies, the convolutional neural network (CNN) is proposed as a deep learning model to extract the defect features autonomously in an elegant way. In this paper, two smaller convolution kernels form a parallel channel in two layers of the convolutional neural network architecture, and then the results of the operation are fused to extract multi-scale information, which increases the adaptability of the network to scale. Besides, the batch normalization (BN) is introduced into convolutional neural network to standardize the data distribution, offering an easy starting condition for training and improving the generalization characteristics of the network. A steel strip defect data sets are adopted to conform the effectiveness of the proposed method. The experimental results show that the proposed method accelerate the training process through reducing the training epoch number, the accuracy and detection consistency on the steel strip defect data sets achieve a superior performance to the existing methods.},
booktitle = {Proceedings of the 2019 2nd International Conference on Robot Systems and Applications},
pages = {1–4},
numpages = {4},
keywords = {surface defect detection, convolutional neural network, batch normalization},
location = {Moscow, Russian Federation},
series = {ICRSA '19}
}

@article{10.1016/j.cosrev.2020.100341,
author = {Kotsiopoulos, Thanasis and Sarigiannidis, Panagiotis and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
title = {Machine Learning and Deep Learning in smart manufacturing: The Smart Grid paradigm},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100341},
doi = {10.1016/j.cosrev.2020.100341},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {25},
keywords = {Smart Grid, Industrial AI, Deep Learning, Machine Learning, Industry 4.0}
}

@article{10.1007/s11042-017-5263-z,
author = {Li, Peng and Liang, Junli and Shen, Xubang and Zhao, Minghua and Sui, Liansheng},
title = {Textile fabric defect detection based on low-rank representation},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {1},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-5263-z},
doi = {10.1007/s11042-017-5263-z},
abstract = {In this paper, we propose a novel and robust fabric defect detection method based on the low-rank representation (LRR) technique. Due to the repeated texture structure we model a defects-free fabric image as a low-rank structure. In addition, because defects, if exist, change only the texture of fabric locally, we model them with a sparse structure. Based on the above idea, we represent a fabric image into the sum of a low-rank matrix which expresses fabric texture and a sparse matrix which expresses defects. Then, the LRR method is applied to obtain the corresponding decomposition. Especially, in order to make better use of low-rank structure characteristics we propose LRREB (low-rank representation based on eigenvalue decomposition and blocked matrix) method to improve LRR. LRREB is implemented by dividing a image into some corresponding blocked matrices to reduce dimensions and applying eigen-value decomposition (EVD) on blocked matrix instead of singular value decomposition (SVD) on original fabric image, which improves the accuracy and efficiency. No training samples are required in our methods. Experimental results show that the proposed fabric defect detection method is feasible, effective, and simple to be employed.},
journal = {Multimedia Tools Appl.},
month = jan,
pages = {99–124},
numpages = {26},
keywords = {low-rank representation based on eigenvalue decomposition and blocked matrix (LRREB), Sparse matrix, Singular value decomposition (SVD), Low-Rank Representation (LRR), Fabric defect detection, Eigen-value decomposition (EVD)}
}

@inproceedings{10.1145/3434581.3434672,
author = {Jiang, Anyao and Liu, Jun},
title = {Pipeline Flange Defect Detection based on Deep Learning},
year = {2020},
isbn = {9781450375764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434581.3434672},
doi = {10.1145/3434581.3434672},
abstract = {Pipe flanges are an indispensable part of industrial piping equipment. Due to the large number of flanges and different installation positions, it will inevitably have a certain negative impact on the quality of manual inspections. Therefore, this paper proposes a pipeline flange visual inspection method based on the improved YOLO v3 algorithm to adjust the network structure: In order to reduce the impact of image shooting scale changes on the detection accuracy, the original network's multi-scale target detection is adjusted to 5 types Scale; At the same time, use the RAdam optimizer to replace the SGD optimizer to improve the training efficiency of the initial stage. Experimental results show that the improved YOLOv3 network can greatly improve the accuracy of flange image recognition and accelerate the convergence speed of the network training phase. It can make full use of the surveillance cameras and intelligent inspection robots in the environment to analyse the flange image, thereby Realize intelligent operation and maintenance.},
booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
pages = {296–300},
numpages = {5},
keywords = {object detection, flange, algorithm, Deep learning},
location = {Weihai City, China},
series = {ICASIT 2020}
}

@article{10.1016/j.ins.2013.12.031,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Software defect prediction using relational association rule mining},
year = {2014},
issue_date = {April, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {264},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.12.031},
doi = {10.1016/j.ins.2013.12.031},
abstract = {This paper focuses on the problem of defect prediction, a problem of major importance during software maintenance and evolution. It is essential for software developers to identify defective software modules in order to continuously improve the quality of a software system. As the conditions for a software module to have defects are hard to identify, machine learning based classification models are still developed to approach the problem of defect prediction. We propose a novel classification model based on relational association rules mining. Relational association rules are an extension of ordinal association rules, which are a particular type of association rules that describe numerical orderings between attributes that commonly occur over a dataset. Our classifier is based on the discovery of relational association rules for predicting whether a software module is or it is not defective. An experimental evaluation of the proposed model on the open source NASA datasets, as well as a comparison to similar existing approaches is provided. The obtained results show that our classifier overperforms, for most of the considered evaluation measures, the existing machine learning based techniques for defect prediction. This confirms the potential of our proposal.},
journal = {Inf. Sci.},
month = apr,
pages = {260–278},
numpages = {19},
keywords = {Software engineering, Defect prediction, Data mining, Association rule}
}

@article{10.1016/j.patcog.2020.107571,
author = {Zhang, Jiabin and Su, Hu and Zou, Wei and Gong, Xinyi and Zhang, Zhengtao and Shen, Fei},
title = {CADN: A weakly supervised learning-based category-aware object detection network for surface defect detection},
year = {2021},
issue_date = {Jan 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {109},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2020.107571},
doi = {10.1016/j.patcog.2020.107571},
journal = {Pattern Recogn.},
month = jan,
numpages = {10},
keywords = {Knowledge distillation, Defect detection, Automated surface inspection, Weakly supervised learning}
}

@article{10.1155/2021/8464612,
author = {Yan, Chenqi and Tan, Mengchao and Venkateswaran, Narasimhan},
title = {The Use of Artificial Intelligence-Based Optical Remote Sensing and Positioning Technology in Microelectronic Processing Technology},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/8464612},
doi = {10.1155/2021/8464612},
abstract = {The purpose is to make defect detection in microelectronic processing technology fast, accurate, reliable, and efficient. A new optical remote sensing-optical beam induced resistance change (ORS-OBIRCH) target recognition and location defect detection method is proposed based on an artificial intelligence algorithm, optical remote sensing (ORS), and optical beam induced resistance change (OBIRCH) location technology using deep convolutional neural network. This method integrates the characteristics of high resolution and rich details of the image obtained by ORS technology and combines the advantages of photosensitive temperature characteristics in OBIRCH positioning technology. It can be adopted to identify, capture, and locate the defects of microdevices in the process of microelectronic processing. Simulation results show that this method can quickly reduce the detection range and locate defects accurately and efficiently. The experimental results reveal that the ORS-OBIRCH target recognition defect location detection method can complete the dynamic synchronization of the IC detection system and obtain high-quality images by changing the laser beam irradiation cycle. Moreover, it can analyze and process the detection results to quickly, accurately, and efficiently locate the defect location. Unlike the traditional detection methods, the success rate of detection has been greatly improved, which is about 95.8%, an increase of nearly 40%; the detection time has been reduced by more than half, from 5.5 days to 1.9 days, and the improvement rate has reached more than 65%. In a word, this method has good practical application value in the field of microelectronic processing.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@inproceedings{10.1145/3390557.3394322,
author = {Qin, Yang and Xing, Yongkang and Du, Jinglong},
title = {LSDDN: A Lightweight End-to-End Network for Surface Defect Detection},
year = {2020},
isbn = {9781450376587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3390557.3394322},
doi = {10.1145/3390557.3394322},
abstract = {Surface defect detection is a key method to control product quality in industry. Deep learning based surface defect detection algorithm plays a crucial role in improving industrial production efficiency. A large number of existing CNN models aim at building deeper and larger structures, thus deep network models are difficult to be applied in the industrial field because of the requirement of speed in industry. This paper proposes a lightweight end-to-end surface defect detection network (LSDDN) to overcome this problem. LSDDN significantly reduces the number of parameters and improves the detection speed while maintaining a high accuracy. We validate our model on the DAGM2007 dataset with an average classification accuracy of 97.23%.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence},
pages = {79–83},
numpages = {5},
keywords = {Lightweight network, Defect detection, Deep learning},
location = {Xiamen, China},
series = {ICIAI '20}
}

@article{10.1007/s00138-021-01177-7,
author = {Xiao, Maohua and Wang, Weichen and Shen, Xiaojie and Zhu, Yue and Bartos, Petr and Yiliyasi, Yilidaer},
title = {Research on defect detection method of powder metallurgy gear based on machine vision},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {2},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01177-7},
doi = {10.1007/s00138-021-01177-7},
abstract = {Powder metallurgy gears are often accompanied by broken teeth, abrasion, scratches and crack defects. In order to eliminate the defective gears in gear production and improve the yield of gears, this paper presents an improved GA–PSO algorithm, called the SHGA–PSO algorithm. Firstly, the gear images were preprocessed by bilateral filtering, and the images were segmented by the Sobel operator. Then, the geometrical shape, texture feature and color features of the sample were extracted. Next, the BP neural network was reconstructed and SHGA–PSO algorithm was used optimize its structure and weights. Finally, four different gear defect samples were brought into the neural network for calculation, and the performance of the SHGA–PSO algorithm was compared with the GA, PSO and GA–PSO algorithms. Compared with GA–BP algorithm, PSO–BP algorithm, and GA–PSO–BP algorithm, the defect diagnosis of SHGA–PSO–BP algorithm not only enhanced generalization ability, but also improved recognition accuracy.},
journal = {Mach. Vision Appl.},
month = mar,
numpages = {13},
keywords = {Detection and recognition, Feature extraction, Image segmentation, Gear defect, Machine vision}
}

@inproceedings{10.1145/3358528.3358594,
author = {Lu, Guo and Zhongqing, Yu and Jianqi, Yu and Chuang, Liu},
title = {Data Driven Induction Motor Condition Identification and Fault Prediction},
year = {2019},
isbn = {9781450371926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358528.3358594},
doi = {10.1145/3358528.3358594},
abstract = {With the development of technologies such as sensing and the scale of industrial production, the equipment data can be gathered massively. For induction motors, the health data can be collected is sufficient, but the fault data is not easy to obtain. Therefore, the focus of this paper was determined to identify motor operating conditions and predict possible faults based on motor health data. In this case, an induction motor condition model consisting of a state recognizer and adaptive thresholds was proposed. The health data was used for the training of the induction motor condition model, and an improved SOM-FCM Two-Layer clustering method was used to solve the problem of obtaining the motor data without label. Finally, the validity of the model and method was verified by normal motor variable load state identification and rotor broken motor fault prediction, and the accuracy of 97.5% and 90.2% was obtained respectively.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Technologies},
pages = {221–229},
numpages = {9},
keywords = {Two-Layer clustering, Induction Motor, Fault Prediction, Data Driven, Condition Identification},
location = {Jinan, China},
series = {ICBDT '19}
}

@inproceedings{10.1109/AIM43001.2020.9159005,
author = {Tran, Xuan Tuyen and Dinh, Tran Hiep and Le, Ha Vu and Zhu, Qiuchen and Ha, Quang},
title = {Defect detection based on singular value decomposition and histogram thresholding},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM43001.2020.9159005},
doi = {10.1109/AIM43001.2020.9159005},
abstract = {This paper presents a novel method for defect detection based on singular value decomposition (SVD) and histogram thresholding. First, the input image is divided into blocks, where SVD is applied to determine if a region contains crack pixels. The detected crack blocks are then merged to construct a histogram to calculate the best binarization threshold by incoporating a recent technique for multiple peaks detection and Otsu algorithm. To validate the effectiveness and advantage of the proposed approach over related thresholding algorithms, experiments on images collected by an unmanned aerial vehicle have been conducted for surface crack detection. The obtained results have confirmed the merits of the proposed approach in terms of accuracy when using some well-known evaluation metrics.},
booktitle = {2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1149–1154},
numpages = {6},
location = {Boston, MA, USA}
}

@inproceedings{10.1109/CIS.2013.61,
author = {Shuai, Bo and Li, Haifeng and Li, Mengjun and Zhang, Quan and Tang, Chaojing},
title = {Software Defect Prediction Using Dynamic Support Vector Machine},
year = {2013},
isbn = {9781479925490},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CIS.2013.61},
doi = {10.1109/CIS.2013.61},
abstract = {In order to solve the problems of traditional SVM classifier for software defect prediction, this paper proposes a novel dynamic SVM method based on improved cost-sensitive SVM (CSSVM) which is optimized by the Genetic Algorithm (GA). Through selecting the geometric classification accuracy as the fitness function, the GA method could improve the performance of CSSVM by enhancing the accuracy of defective modules and reducing the total cost in the whole decision. Experimental results show that the GA-CSSVM method could achieve higher AUC value which denotes better prediction accuracy both for minority and majority samples in the imbalanced software defect data set.},
booktitle = {Proceedings of the 2013 Ninth International Conference on Computational Intelligence and Security},
pages = {260–263},
numpages = {4},
keywords = {software defect, GA, CSSVM, AUC},
series = {CIS '13}
}

@article{10.1007/s10515-011-0092-1,
author = {Li, Ming and Zhang, Hongyu and Wu, Rongxin and Zhou, Zhi-Hua},
title = {Sample-based software defect prediction with active and semi-supervised learning},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0092-1},
doi = {10.1007/s10515-011-0092-1},
abstract = {Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–230},
numpages = {30},
keywords = {Software defect prediction, Sampling, Quality assurance, Machine learning, Active semi-supervised learning}
}

@inproceedings{10.1109/IECON43393.2020.9255229,
author = {Hang, Jingfan and Yang, Xianqiang and Yu, Xinghu},
title = {Sanitary Ceramic Surface Defect Detection Method Based on Neighborhood Pixel Gray Information},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9255229},
doi = {10.1109/IECON43393.2020.9255229},
abstract = {Computer image processing technology has been widely used in ceramic product defect detection. However, there are few studies on automatic defect detection methods for ceramic products with complex surface geometry, such as ceramic wash basins. The main difficulty is that this type of sanitary ceramic product has a complex surface, strong light reflection, and very little texture information. It is hard to find a perfect illumination to make the defects obvious. In view of the above problems, this paper proposes a defect detection method based on the neighborhood pixel gray threshold, and conducts defect detection tests on the imaging results of ceramic wash basins with cracks on the surface under general light conditions, and obtains good results.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {5337–5342},
numpages = {6},
location = {Singapore, Singapore}
}

@article{10.1515/cait-2017-0011,
author = {Yanhua, Guo and Sihua, Zhou and Xiaodong, Zhou and Bojun, Chen and Shaohui, Wang},
title = {Research on Quick Response Code Defect Detection Algorithm},
year = {2017},
issue_date = {Mar 2017},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {17},
number = {1},
issn = {1314-4081},
url = {https://doi.org/10.1515/cait-2017-0011},
doi = {10.1515/cait-2017-0011},
abstract = {Defect Detection is one of the most important parts of Automatic Identification and Data transmission. Quick Response code (QRcode) is one of the most popular types of two-dimensional barcodes. It isachallenge to detect defect of various QRcode images efficiently and accurately. In this paper, we propose the procedure byaserial of carefully designed preprocessing methods. The defect detection procedure consists of QRcode identification, QRcode reconstruction, perspective transformation, image binarization, morphological operation, image matching, and Blob analysis. By these steps, we can detect defect of different types of QRcode images. The experiment results show that our method has stronger robustness and higher efficiency. Moreover, experiment results on QRcode images show that the prediction accuracy of proposed method reaches 99.07%with an average execution time of 6.592 ms. This method can detect defect of these images in real time.},
journal = {Cybern. Inf. Technol.},
month = mar,
pages = {135–145},
numpages = {11},
keywords = {correlation matching, blob analysis, perspective transformation, defect detection, QR Code}
}

@article{10.1155/2021/6630802,
author = {Li, Mengkun and Jia, Junying and Lu, Xin and Zhang, Yue and Tolba, Amr},
title = {A Method of Surface Defect Detection of Irregular Industrial Products Based on Machine Vision},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/6630802},
doi = {10.1155/2021/6630802},
abstract = {In recent years, the surface defect detection technology of irregular industrial products based on machine vision has been widely used in various industrial scenarios. This paper takes Bluetooth headsets as an example, proposes a Bluetooth headset surface defect detection algorithm based on machine vision to quickly and accurately detect defects on the headset surface. After analyzing the surface characteristics and defect types of Bluetooth headsets, we proposed a surface scratch detection algorithm and a surface glue-overflowed detection algorithm. The result of the experiment shows that the detection algorithm can detect the surface defect of Bluetooth headsets fast as well as effectively, and the accuracy of defect recognition reaches 98%. The experiment verifies the correctness of the theory analysis and detection algorithm; therefore, the detection algorithm can be used in the recognition and detection of surface defect of Bluetooth headsets.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@inproceedings{10.1109/MSR.2019.00017,
author = {Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
title = {Lessons learned from using a deep tree-based model for software defect prediction in practice},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00017},
doi = {10.1109/MSR.2019.00017},
abstract = {Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {46–57},
numpages = {12},
keywords = {defect prediction, deep learning},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@article{10.1016/j.aei.2019.101004,
author = {Dai, Wenting and Mujeeb, Abdul and Erdt, Marius and Sourin, Alexei},
title = {Soldering defect detection in automatic optical inspection},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.101004},
doi = {10.1016/j.aei.2019.101004},
journal = {Adv. Eng. Inform.},
month = jan,
numpages = {7},
keywords = {Active learning, Clustering, YOLO, Semi-supervised learning, Localization and classification of solder joint defects, Automatic Optical Inspection (AOI)}
}

@article{10.1007/s10664-012-9218-8,
author = {Okutan, Ahmet and Y\i{}ld\i{}z, Olcay Taner},
title = {Software defect prediction using Bayesian networks},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9218-8},
doi = {10.1007/s10664-012-9218-8},
abstract = {There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {154–181},
numpages = {28},
keywords = {Defect prediction, Bayesian networks}
}

@inproceedings{10.1145/3439961.3439979,
author = {Santos, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Predicting Software Defects with Explainable Machine Learning},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439979},
doi = {10.1145/3439961.3439979},
abstract = {Most software systems must evolve to cope with stakeholders’ requirements and fix existing defects. Hence, software defect prediction represents an area of interest in both academia and the software industry. As a result, predicting software defects can help the development team to maintain substantial levels of software quality. For this reason, machine learning models have increased in popularity for software defect prediction and have demonstrated effectiveness in many scenarios. In this paper, we evaluate a machine learning approach for selecting features to predict software module defects. We use a tree boosting algorithm that receives as input a training set comprising records of software features encoding characteristics of each module and outputs whether the corresponding module is defective prone. For nine projects within the widely known NASA data program, we build prediction models from a set of easy-to-compute module features. We then sample this sizable model space by randomly selecting software features to compose each model. This significant number of models allows us to structure our work along model understandability and predictive accuracy. We argue that explaining model predictions is meaningful to provide information to developers on features related to each module defective-prone. We show that (i) features that contribute most to finding the best models may vary depending on the project, and (ii) effective models are highly understandable based on a survey with 40 developers.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {18},
numpages = {10},
keywords = {software defects, explainable models, SHAP values, NASA datasets},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {clafer configurator, ClaferWiki, ClaferMOO visualizer, ClaferMOO, ClaferIG, Clafer},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3478905.3478914,
author = {Jia, Beini and Luo, Xin and Tao, Ran and Shi, Youqun},
title = {Surface Defect Detection of Aluminum Material Based on HRNet Feature Extraction},
year = {2021},
isbn = {9781450390248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478905.3478914},
doi = {10.1145/3478905.3478914},
booktitle = {2021 4th International Conference on Data Science and Information Technology},
pages = {44–48},
numpages = {5},
keywords = {HRNet Network, Deformable Convolution, Deep learning, Aluminum material defects},
location = {Shanghai, China},
series = {DSIT 2021}
}

@article{10.1007/s10586-021-03282-8,
author = {Mustaqeem, Mohd. and Saqib, Mohd.},
title = {Principal component based support vector machine (PC-SVM): a hybrid technique for software defect detection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03282-8},
doi = {10.1007/s10586-021-03282-8},
abstract = {Defects are the major problems in the current situation and predicting them is also a difficult task. Researchers and scientists have developed many software defects prediction techniques to overcome this very helpful issue. But to some extend there is a need for an algorithm/method to predict defects with more accuracy, reduce time and space complexities. All the previous research conducted on the data without feature reduction lead to the curse of dimensionality. We brought up a machine learning hybrid approach by combining Principal component Analysis (PCA) and Support vector machines (SVM) to overcome the ongoing problem. We have employed PROMISE (CM1: 344 observations, KC1: 2109 observations) data from the directory of NASA to conduct our research. We split the dataset into training (CM1: 240 observations, KC1: 1476 observations) dataset and testing (CM1: 104 observations, KC1: 633 observations) datasets. Using PCA, we find the principal components for feature optimization which reduce the time complexity. Then, we applied SVM for classification due to very native qualities over traditional and conventional methods. We also employed the GridSearchCV method for hyperparameter tuning. In the proposed hybrid model we have found better accuracy (CM1: 95.2%, KC1: 86.6%) than other methods. The proposed model also presents higher evaluation in the terms of other criteria. As a limitation, the only problem with SVM is there is no probabilistic explanation for classification which may very rigid towards classifications. In the future, some other method may also introduce which can overcome this limitation and keep a soft probabilistic based margin for classification on the optimal hyperplane.},
journal = {Cluster Computing},
month = sep,
pages = {2581–2595},
numpages = {15},
keywords = {Software defects detection, PCA, SVM, Feature optimization, Classification, PROMISE dataset}
}

@article{10.1016/j.compeleceng.2018.02.043,
author = {Choudhary, Garvit Rajesh and Kumar, Sandeep and Kumar, Kuldeep and Mishra, Alok and Catal, Cagatay},
title = {Empirical analysis of change metrics for software fault prediction},
year = {2018},
issue_date = {Apr 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2018.02.043},
doi = {10.1016/j.compeleceng.2018.02.043},
journal = {Comput. Electr. Eng.},
month = apr,
pages = {15–24},
numpages = {10},
keywords = {Defect prediction, Software quality, Metrics, Change log, Eclipse, Software fault prediction}
}

@article{10.1155/2021/3965247,
author = {Li, Xiaoguang and Zhu, Juan and Shi, Haoran and Cong, Zijian and Gupta, Punit},
title = {Surface Defect Detection of Seals Based on K-Means Clustering Algorithm and Particle Swarm Optimization},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/3965247},
doi = {10.1155/2021/3965247},
abstract = {As an important part of automobile, the quality and safety of automobile engine high-pressure oil circuit seal parts are an important indicator of the manufacturer’s production process. In order to improve the detection accuracy and efficiency of seal parts in the traditional production process, the defect detection method on the surface of the seal was studied. A K-Means clustering image segmentation algorithm based on particle swarm optimization was proposed. To detect the surface defects of seals, first, preprocess the seal image. Then, use the SURF algorithm to extract the feature points of the seal image. Finally, according to the particle swarm fitness variance function, select the insertion point calculated by combining particle swarm optimization and K-Means algorithm. Through iteration, optimize the initial clustering center of K-Means algorithm. The efficiency of K-Means algorithm clustering iteration is improved. The test verifies the applicability of the algorithm in the actual process, and it can be used to accurately detect seals. Experimental results show that the detection accuracy rate reaches 98%, which is highly applicable to the actual production.},
journal = {Sci. Program.},
month = jan,
numpages = {12}
}

@article{10.1504/IJBIC.2018.092808,
title = {An improved twin support vector machine based on multi-objective cuckoo search for software defect prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1758-0366},
url = {https://doi.org/10.1504/IJBIC.2018.092808},
doi = {10.1504/IJBIC.2018.092808},
abstract = {Recently, software defect prediction SDP has drawn much attention as software size becomes larger and consumers hold higher reliability expectations. The premise of SDP is to guide the detection of software bugs and to conserve computational resources. However, in prior research, data imbalances among software defect modules were largely ignored to focus instead on how to improve defect prediction accuracy. In this paper, a novel SDP model based on twin support vector machines TSVM and a multi-objective cuckoo search MOCS is proposed, called MOCSTSVM. We set the probability of detection and the probability of false alarm as the SDP objectives. We use TSVM to predict defected modules and employ MOCS to optimise TSVM for this dual-objective optimisation problem. To test our approach, we conduct a series of experiments on a public dataset from the PROMISE repository. The experimental results demonstrate that our approach achieves good performance compared with other SDP models.},
journal = {Int. J. Bio-Inspired Comput.},
month = jan,
pages = {282–291},
numpages = {10}
}

@article{10.1504/ijwmc.2020.109275,
author = {Dai, Xiaohong and Zhao, Yingji and Zhu, Chaoping},
title = {A study of an improved RCNN network model for surface defect detection algorithm of precision workpiece and its realisation},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {1},
issn = {1741-1084},
url = {https://doi.org/10.1504/ijwmc.2020.109275},
doi = {10.1504/ijwmc.2020.109275},
abstract = {In this paper, an improved RCNN algorithm for surface defect detection of precision workpiece is proposed. During model training, the original image is processed by data amplification, which overcomes the phenomenon of model overfitting caused by too small data set. The fuzzy image is processed by the conditional generation antagonism network, which guarantees the authenticity of the image and eliminates the fuzziness of the image. On the basis of network selection, through network training and comparative analysis, ResNet101 was selected as the basic network for feature extraction. By combining the network performance, the number of convolutional layers (model depth), system efficiency and other factors, and taking advantage of the spatial characteristics of images, the irregular cross convolution kernel idea and the differentiated convolution kernel design method are adopted to realise the feature fusion of different convolutional layers. Embedded in the target Network Squeeze and Excitation (SE) module channel features fusion module, the Feature Pyramid Network (FPN) module, ROI Network module. The experimental results show that the improved network model is used to realise the location and classification of defects on the workpiece surface. The detection accuracy was 91% and the recall rate was 93%.},
journal = {Int. J. Wire. Mob. Comput.},
month = jan,
pages = {95–105},
numpages = {10},
keywords = {target detection, deep learning, convolution neural network, defect identification, precision workpiece}
}

@article{10.1016/j.eswa.2018.12.033,
author = {Turabieh, Hamza and Mafarja, Majdi and Li, Xiaodong},
title = {Iterated feature selection algorithms with layered recurrent neural network for software fault prediction},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.033},
doi = {10.1016/j.eswa.2018.12.033},
journal = {Expert Syst. Appl.},
month = may,
pages = {27–42},
numpages = {16},
keywords = {Layered recurrent neural network, Feature selection, Software fault prediction}
}

@inproceedings{10.1007/978-3-030-11018-5_35,
author = {Dong, Xinghui and Taylor, Chris J. and Cootes, Tim F.},
title = {Small Defect Detection Using Convolutional Neural Network Features and Random Forests},
year = {2018},
isbn = {978-3-030-11017-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-11018-5_35},
doi = {10.1007/978-3-030-11018-5_35},
abstract = {We address the problem of identifying small abnormalities in an imaged region, important in applications such as industrial inspection. The goal is to label the pixels corresponding to a defect with a minimum of false positives. A common approach is to run a sliding-window classifier over the image. Recent Fully Convolutional Networks (FCNs), such as U-Net, can be trained to identify pixels corresponding to abnormalities given a suitable training set. However in many application domains it is hard to collect large numbers of defect examples (by their nature they are rare). Although U-Net can work in this scenario, we show that better results can be obtained by replacing the final softmax layer of the network with a Random Forest (RF) using features sampled from the earlier network layers. We also demonstrate that rather than just thresholding the resulting probability image to identify defects it is better to compute Maximally Stable Extremal Regions (MSERs). We apply the approach to the challenging problem of identifying defects in radiographs of aerospace&nbsp;welds.},
booktitle = {Computer Vision – ECCV 2018 Workshops: Munich, Germany, September 8-14, 2018, Proceedings, Part IV},
pages = {398–412},
numpages = {15},
keywords = {Random Forests, Local features, CNN, Non-destructive evaluation, Defect detection},
location = {Munich, Germany}
}

@inproceedings{10.1007/978-3-030-03398-9_44,
author = {Chen, Haiyong and Zhao, Huifang and Han, Da and Yan, Haowei and Zhang, Xiaofang and Liu, Kun},
title = {Robust Crack Defect Detection in Inhomogeneously Textured Surface of Near Infrared Images},
year = {2018},
isbn = {978-3-030-03397-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-03398-9_44},
doi = {10.1007/978-3-030-03398-9_44},
abstract = {Robust crack defect detection in solar cells has been challenging because of the inhomogeneously textured surface, low contrast between crack defect and background, the diversity of crack types, and so on. To overcome these challenges, this paper presents a new robust crack defect detection scheme for multicrystalline solar cells. Firstly, a steerable evidence filter is designed to process EL image to obtain the response map, which enhances the contrast between crack and background and provides evidence for the presence of crack defect. Secondly, complete crack extraction from the response map is employed. Finally, the complete crack can be located in the inspection image by the crack skeleton extraction. Experimental results on defective and defect-free EL images show that the proposed scheme is robust, and various cracks can be effectively detected, which outperforms the previous methods.},
booktitle = {Pattern Recognition and Computer Vision: First Chinese Conference, PRCV 2018, Guangzhou, China, November 23-26, 2018, Proceedings, Part I},
pages = {511–523},
numpages = {13},
keywords = {Steerable evidence filter, Inhomogeneous texture, Crack defect},
location = {Guangzhou, China}
}

@article{10.1007/s10044-017-0640-9,
author = {Gaidhane, Vilas H. and Hote, Yogesh V. and Singh, Vijander},
title = {An efficient similarity measure approach for PCB surface defect detection},
year = {2018},
issue_date = {February  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {1},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-017-0640-9},
doi = {10.1007/s10044-017-0640-9},
abstract = {In this paper, an efficient similarity measure method is proposed for printed circuit board (PCB) surface defect detection. The advantage of the presented approach is that the measurement of similarity between the scene image and the reference image of PCB surface is taken without computing image features such as eigenvalues and eigenvectors. In the proposed approach, a symmetric matrix is calculated using the companion matrices of two compared images. Further, the rank of a symmetric matrix is used as similarity measure metric for defect detection. The numerical value of rank is zero for the defectless images and distinctly large for defective images. It is reliable and well tolerated to local variations and misalignment. The various experiments are carried out on the different PCB images. Moreover, the presented approach is tested in the presence of varying illumination and noise effect. Experimental results have shown the effectiveness of the proposed approach for detecting and locating the local defects in a complicated component-mounted PCB images.},
journal = {Pattern Anal. Appl.},
month = feb,
pages = {277–289},
numpages = {13},
keywords = {Similarity measure, Rank, Printed circuit board, Polynomial coefficient, Defect detection, Companion matrix}
}

@article{10.3233/JIFS-179619,
author = {Lyu, Yi and Jiang, YiJie and Zhang, Weiping},
title = {Examination on avionics system fault prediction technology based on ashy neural network and fuzzy recognition},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179619},
doi = {10.3233/JIFS-179619},
abstract = {The purpose of this paper is to accurately locate the fault prediction and diagnosis technology, to have a high degree of automation, and to handle it quickly, for the large aircraft avionics system failure presents the feature of multiple coupling, complex impact and rapid spread. At the same time, the fault prediction diagnosis technology is one of the most important contents of the avionics system equipment prediction, so how to quickly and effectively predict the failure of key system parts of avionics is the core essential to ensure the complete operation of the whole system. This paper through establishing the gray neural network model, combining the advantages of gray model to deal with poor information and the characteristics of artificial neural network processing nonlinear data, to realize the fault prediction of avionics system, At the same time, At the same time, through the fuzzy recognition method based on the deterioration degree, established the bridge between the two, in turn, to achieve the health prediction management of system. The method mainly includes: Firstly, by combining gray theory and artificial neural network algorithm with fuzzy recognition to establish a network model that contains gray neural network models and can reflect the excellent characteristics of fuzzy recognition and conduct experimental analysis; Second, on this basis, improve the weight update strategy of the gray neural network by using additional learning rate method which based on momentum and improve the accuracy of the algorithm. Therefore, it can be concluded that the predictions presented in this paper should not be directly imitated when the system disturbance factor is too large or the system is abnormally caused by a serious disturbance suddenly appearing at a certain point in time, but should properly processed the data firstly according to the actual situation. According to the time series of the actual situation, several models are established, and the data correction is explained from the model prediction effect, and the gray model and description are improved. The improved combination of gray neural network and gray neural network can not only improve the prediction accuracy, but also provide a feasible method for such time series prediction, which provides a practical and effective technical method for avionics system fault prediction.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {3939–3947},
numpages = {9},
keywords = {combined forecast, fault prediction, fuzzy recognition, avionics system, Ashy neural network}
}

@inproceedings{10.1145/3106195.3106223,
author = {Iglesias, Aitziber and Lu, Hong and Arellano, Crist\'{o}bal and Yue, Tao and Ali, Shaukat and Sagardui, Goiuria},
title = {Product Line Engineering of Monitoring Functionality in Industrial Cyber-Physical Systems: A Domain Analysis},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106223},
doi = {10.1145/3106195.3106223},
abstract = {In recent years, manufacturing technology is evolving and progressively becoming more dynamic and complex. This means that manufacturing technology (e.g., based on Industry 4.0) should be able to control the production process at runtime by monitoring physical elements and adapting itself. Such functionality is aimed at increasing production effectiveness and reducing the production cost. We argue that monitoring process can be viewed as a software product line having commonalities and variability. To support our argument, we analyzed and conducted domain analysis of two monitoring systems of Industrial Cyber-Physical Systems (ICPSs) from two industrial domains including automated warehouses and press machines. Based on the domain analysis, we present a common solution for monitoring including a software product line. With such product line, a user can configure, monitor, and visualize data of an ICPS at runtime. However, such solution could not handle the dynamic functionality related to monitoring of ICPS. Thus, we propose the use of dynamic product line and present a set of research questions that must be addressed for such solution.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {195–204},
numpages = {10},
keywords = {Software Product Line, Industrial domains, Dynamic Software Product Line, Cyber Physical System},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1504/ijics.2020.105155,
author = {Pinto, Joey and Jain, Pooja and Kumar, Tapan},
title = {Fault prediction for distributed computing Hadoop clusters using real-time higher order differential inputs to SVM: Zedacross},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {2–3},
issn = {1744-1765},
url = {https://doi.org/10.1504/ijics.2020.105155},
doi = {10.1504/ijics.2020.105155},
abstract = {Hadoop distributed computing clusters are used worldwide for high-performance computations. Often various hardware and software faults occur, leading to both data and computation time losses. This paper proposes the usage of a fault prediction software called 'Zedacross' which uses machine learning principles combined with cluster monitoring tools. Firstly, the paper suggests a model that uses the resource usage statistics of a normally functioning Hadoop cluster to create a machine learning model that can then be used to predict and detect faults in real time. Secondly, the paper explains the novel idea of using higher order differentials as inputs to SVM for highly accurate fault predictions. Predictions of system faults by observing system resource usage statistics in real-time with minimum delay will play a vital role in deciding the need for job rescheduling tasks or even dynamic up-scaling of the cluster. To demonstrate the effectiveness of the design a Java utility was built to perform cluster fault monitoring. The results obtained after running the system on various test cases demonstrate that the proposed method is accurate and effective.},
journal = {Int. J. Inf. Comput. Secur.},
month = jan,
pages = {181–198},
numpages = {17},
keywords = {SVM, higher order differential, Hadoop, Ganglia, fault prediction}
}

@article{10.1155/2021/9870129,
author = {Guo, Kehua and Tan, Zhiyuan and Luo, Entao and Zhou, Xiaokang},
title = {Machine Learning: The Cyber-Security, Privacy, and Public Safety Opportunities and Challenges for Emerging Applications},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/9870129},
doi = {10.1155/2021/9870129},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {2}
}

@article{10.3233/JIFS-179459,
author = {Bashir, Kamal and Li, Tianrui and Yohannese, Chubato Wondaferaw and Yahaya, Mahama and Kahraman, Cengiz},
title = {SMOTEFRIS-INFFC: Handling the challenge of borderline and noisy examples in imbalanced learning for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179459},
doi = {10.3233/JIFS-179459},
abstract = {The object of Software Defect Prediction (SDP) is to identify modules that are prone to defect. This is achieved by training prediction models with datasets obtained by mining software historical depositories. When one acquires data through this approach, it often includes class imbalance which has an unequal class representation among their example. We hypothesize that the imbalance learning is not a problem in itself and decrease in performance is also influenced by other factors related to class distribution in the data. One of these is the existence of noisy and borderline examples. Thus, the objective of our research is to propose a novel preprocessing method using Synthetic Minority Over-Sampling Technique (SMOTE), Fuzzy-rough Instance Selection type II (FRIS-II) and Iterative Noise Filter based on the Fusion of Classifiers (INFFC) which can overcome these problems. The experimental results show that the new proposal significantly outperformed all the methods compared in this study.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {917–933},
numpages = {17},
keywords = {noise filtering, fuzzy rough set, data sampling, Software defect prediction}
}

@article{10.1007/s13319-019-0215-1,
author = {Deotale, Nilesh Tejram and Sarode, Tanuja K.},
title = {Fabric Defect Detection Adopting Combined GLCM, Gabor Wavelet Features and Random Decision Forest},
year = {2019},
issue_date = {March     2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {1},
issn = {2092-6731},
url = {https://doi.org/10.1007/s13319-019-0215-1},
doi = {10.1007/s13319-019-0215-1},
journal = {3D Res.},
month = mar,
articleno = {215},
numpages = {13},
keywords = {Random decision forest, Gabor wavelet, GLCM, Feature extraction, Fabric defect detection}
}

@article{10.1007/s00500-017-2709-1,
author = {Truong, Mai Thanh and Kim, Sanghoon},
title = {Automatic image thresholding using Otsu's method and entropy weighting scheme for surface defect detection},
year = {2018},
issue_date = {July      2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {13},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-017-2709-1},
doi = {10.1007/s00500-017-2709-1},
abstract = {Defect detection is one of the most important tasks and a challenging problem for industrial quality control. Among the available visual inspection techniques, automatic thresholding is a commonly used approach for defect detection because of the simplicity in terms of its implementation and computing. In this paper, we propose an automatic thresholding technique, which is an improvement in Otsu's method, using an entropy weighting scheme. The proposed method enables the detection of extremely small defect regions compared to the product surface area. Experimental results confirm the efficiency of the proposed system over other techniques.},
journal = {Soft Comput.},
month = jul,
pages = {4197–4203},
numpages = {7},
keywords = {Nondestructive testing, Entropy, Defect detection, Automatic thresholding}
}

@article{10.5555/3271870.3271878,
title = {Software fault prediction using firefly algorithm},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {6},
number = {3–4},
issn = {1758-8715},
abstract = {The software fault prediction SFP literature has shown an immense growth of the research studies involving the artificial neural network ANN based fault prediction models. However, the default gradient descent back propagation neural networks BPNNs have a high risk of getting stuck in the local minima of the search space. A class of nature inspired computing methods overcomes this disadvantage of BPNNs and has helped ANNs to evolve into a class of adaptive ANN. In this work, we propose a hybrid SFP model built using firefly algorithm FA and artificial neural network ANN, along with an empirical comparison with GA and PSO based evolutionary methods in optimising the connection weights of ANN. Seven different datasets were involved and MSE and the confusion matrix parameters were used for performance evaluation. The results have shown that FA-ANN model has performed better than the genetic and particle swarm optimised ANN fault prediction models.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {356–377},
numpages = {22}
}

@inproceedings{10.5220/0004862504250431,
author = {\c{C}elik, H. \'{z}brahim and T. Da\'{z}, M. and C. D\"{u}lger, L. and Topalbekiro\'{z}lu, M.},
title = {Artificial Intelligence},
year = {2014},
isbn = {9789897580277},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0004862504250431},
doi = {10.5220/0004862504250431},
abstract = {AI techniques have been successfully used in many fields of engineering. A brief description of possible applications of AI in engineering are dated with future prospects. This study reviews two different experimental systems; bioinformatics and textile engineering. The experimental systems are described. Different databases are used and their implementation results are also presented by using AI.},
booktitle = {Proceedings of the 16th International Conference on Enterprise Information Systems - Volume 1},
pages = {425–431},
numpages = {7},
keywords = {signature verification, fabric defect detection, fabric defect classification, biometric authentication, artificial intelligence, PSO-NN, ANN\'{z}s},
location = {Lisbon, Portugal},
series = {ICEIS 2014}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {machine learning, data leakage, data breach, advanced persistent threat, Data exfiltration}
}

@article{10.5555/2684939.2684969,
author = {Ma, Ying and Pan, Weiwei and Zhu, Shunzhi and Yin, Huayi and Luo, Jian},
title = {An improved semi-supervised learning method for software defect prediction},
year = {2014},
issue_date = {September 2014},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {5},
issn = {1064-1246},
abstract = {This paper presents an improved semi-supervised learning approach for defect prediction involving class imbalanced and limited labeled data problem. This approach employs random under-sampling technique to resample the original training set and updating training set in each round for co-train style algorithm. It makes the defect predictor more practical for real applications, by combating these problems. In comparison with conventional machine learning approaches, our method has significant superior performance. Experimental results also show that with the proposed learning approach, it is possible to design better method to tackle the class imbalanced problem in semi-supervised learning.},
journal = {J. Intell. Fuzzy Syst.},
month = sep,
pages = {2473–2480},
numpages = {8},
keywords = {Semi-Supervised Learning, Random Sampling, Defect Prediction, Co-Train, Class Imbalance}
}

@article{10.1155/2021/6687146,
author = {Lv, Zhaomin and Ma, Anqi and Chen, Xingjie and Zheng, Shubin and Wang, Rui},
title = {Defect Detection of Pandrol Track Fastener Based on Local Depth Feature Fusion Network},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6687146},
doi = {10.1155/2021/6687146},
abstract = {There are three main problems in track fastener defect detection based on image: (1) The number of abnormal fastener pictures is scarce, and supervised learning detection model is difficult to establish. (2) The potential data features obtained by different feature extraction methods are different. Some methods focus on edge features, and some methods focus on texture features. Different features have different detection capabilities, and these features are not effectively fused and utilized. (3) The detection of the track fastener clip will be interfered by the track fastener bolt subimage. Aiming at the above three problems, a method for track fastener defects detection based on Local Deep Feature Fusion Network (LDFFN) is proposed. Firstly, the track fastener image segmentation method is used to obtain the track fastener clip subimage, which can effectively reduce the interference of bolt subimage features on the track fastener clip detection. Secondly, the edge features and texture features of track fastener clip subimages are extracted by Autoencoder (AE) and Restricted Boltzmann Machine (RBM), and the features are fused. Finally, the similarity measurement method Mahalanobis Distance (MD) is used to detect defects in track fasteners. The effectiveness of the proposed method is verified by real Pandrol track fastener images.},
journal = {Complex.},
month = jan,
numpages = {9}
}

@article{10.1007/s11227-018-2326-5,
author = {Kalsoom, Anum and Maqsood, Muazzam and Ghazanfar, Mustansar Ali and Aadil, Farhan and Rho, Seungmin},
title = {A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA)},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {9},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-018-2326-5},
doi = {10.1007/s11227-018-2326-5},
abstract = {Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers--Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques--SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve.},
journal = {J. Supercomput.},
month = sep,
pages = {4568–4602},
numpages = {35},
keywords = {Software fault prediction, Robustness, Reliability, Fisher linear discriminant, Fault-tolerance}
}

@inproceedings{10.1109/ITSC48978.2021.9564437,
author = {Shi, Xiaojie and Dai, Shenghua},
title = {Fault Prediction of Turnout Equipment Based on Double-layer Gated Recurrent Unit Neural Network},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9564437},
doi = {10.1109/ITSC48978.2021.9564437},
abstract = {Turnout is an important railway equipment, and the failure of the turnout equipment will have a great impact on the safe operation of the train. In order to predict the failure of the turnout equipment in advance, this paper combines the double-layer gated recurrent unit (DL-GRU) neural network with the failure prediction of the turnout. This paper extracts the features of the current curves generated during multiple actions before the turnout fails, and uses the method of kernel principal component analysis (KPCA) to reduce the dimensions of the extracted features. Finally, the time series data set of turnout action current fault feature is established, which is used as the input of the DL-GRU neural network to realize the fault prediction of the turnout. The simulation results show that the DL-GRU network has a high prediction accuracy, compared with LSTM network and single-layer GRU neural network, the DL-GRU has better prediction performance.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {2336–2341},
numpages = {6},
location = {Indianapolis, IN, USA}
}

@inproceedings{10.1145/3461001.3471152,
author = {Silva, Publio and Bezerra, Carla I. M. and Machado, Ivan},
title = {A machine learning model to classify the feature model maintainability},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471152},
doi = {10.1145/3461001.3471152},
abstract = {Software Product Lines (SPL) are generally specified using a Feature Model (FM), an artifact designed in the early stages of the SPL development life cycle. This artifact can quickly become too complex, which makes it challenging to maintain an SPL. Therefore, it is essential to evaluate the artifact's maintainability continuously. The literature brings some approaches that evaluate FM maintainability through the aggregation of maintainability measures. Machine Learning (ML) models can be used to create these approaches. They can aggregate the values of independent variables into a single target data, also called a dependent variable. Besides, when using white-box ML models, it is possible to interpret and explain the ML model results. This work proposes white-box ML models intending to classify the FM maintainability based on 15 measures. To build the models, we performed the following steps: (i) we compared two approaches to evaluate the FM maintainability through a human-based oracle of FM maintainability classifications; (ii) we used the best approach to pre-classify the ML training dataset; (iii) we generated three ML models and compared them against classification accuracy, precision, recall, F1 and AUC-ROC; and, (iv) we used the best model to create a mechanism capable of providing improvement indicators to domain engineers. The best model used the decision tree algorithm that obtained accuracy, precision, and recall of 0.81, F1-Score of 0.79, and AUC-ROC of 0.91. Using this model, we could reduce the number of measures needed to evaluate the FM maintainability from 15 to 9 measures.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {35–45},
numpages = {11},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1016/j.aei.2019.100933,
author = {Mujeeb, Abdul and Dai, Wenting and Erdt, Marius and Sourin, Alexei},
title = {One class based feature learning approach for defect detection using deep autoencoders},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {42},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.100933},
doi = {10.1016/j.aei.2019.100933},
journal = {Adv. Eng. Inform.},
month = oct,
numpages = {9},
keywords = {Autoencoders, One Class Classification, Unsupervised learning, Deep learning, Automatic Optical Inspection}
}

@inproceedings{10.1145/3331453.3360958,
author = {He, Ning and Yu, Qingyang and Ye, Weijia},
title = {Application of Artificial Intelligence Technology in the Field of Airport Navigation Lamp Detection},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331453.3360958},
doi = {10.1145/3331453.3360958},
abstract = {With the rapid development of civil aviation industry, maintaining airport operation normally is a big workload every day. The navigation lamp system plays an important role on the operation of the airport. According to each airport's scales, there are considerable lamps install in airport running way and each lamps need to keep working well especially when airplane taking off or landing, however, inspecting each lamp's statues is a heavy works, the present solution is arranging special workers to check all navigation lamps, and airplane keep staying before examine finished. Due to the inspect time is very limited and the number of the navigation lamps is large, causing the intensity and difficulty increased. If staff found the faulty lamps in the process of inspection, only the second time to repair or replace. In order to improve airport operational efficiency. This paper will use the AI technology build an Expert system prototype to predict evaluation of lamps faulty based on lamp electrical characteristics, time of use, structure characteristics, thermal properties and others indicator, which is useful for staff to improve the work efficiency.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {132},
numpages = {6},
keywords = {Fault detection, Expert system, Artificial intelligence, Airport navigation lamp},
location = {Sanya, China},
series = {CSAE '19}
}

@article{10.1155/2021/1093960,
author = {Zhou, Xin and Lei, Xianqing and Tsai, Sang-Bing},
title = {Fault Diagnosis Method of the Construction Machinery Hydraulic System Based on Artificial Intelligence Dynamic Monitoring},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/1093960},
doi = {10.1155/2021/1093960},
abstract = {This paper aims to study the fault diagnosis method of the mechanical hydraulic system based on artificial intelligence dynamic monitoring. According to the characteristics of functional principal component analysis (FPCA) and neural network in the fault diagnosis method in the feature extraction process, the fault diagnosis method combining functional principal component analysis and BP neural network is studied and it is applied to the fault of the coordinator hydraulic system diagnosis. This article mainly completed the following tasks: analyzing the structure and working principle of the mechanical hydraulic system, studying the failure mechanism and failure mode of the mechanical hydraulic system, summarizing the common failures of the hydraulic system and the individual failures of the mechanical hydraulic system, and establishing the mechanical hydraulic system. Description of failure mode and effects analysis (FMEA): then, a joint simulation model of the mechanical hydraulic system was established in ADAMS and AMESim, and the fault detection signal of the hydraulic system was determined and compared with the experimental data. At the same time, the simulation data of the cosimulation model were compared with the simulation data of the hydraulic model in MATLAB to further verify the correctness of the model. The functional principal component analysis is used to perform functional processing on sample data, feature parameters are extracted, and the BP neural network is used to train the mapping relationship between feature parameters and fault parameters. The consistency is verified, and the fault diagnosis method is finally completed. The experimental results show that the diagnostic accuracy rates are 0.9848 and 0.9927, respectively, the reliability is significantly improved, close to 100%, and the uncertainty is basically 0, which significantly improves the accuracy of fault diagnosis.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {10}
}

@article{10.1007/s00521-021-05811-3,
author = {Mehta, Sweta and Patnaik, K. Sridhar},
title = {Improved prediction of software defects using ensemble machine learning techniques},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05811-3},
doi = {10.1007/s00521-021-05811-3},
abstract = {Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {10551–10562},
numpages = {12},
keywords = {Stacking ensemble classifier, XGBoost, Machine learning algorithms, Data imbalance, Dimension reduction, Defect prediction}
}

@inproceedings{10.1109/ICMLA.2012.145,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Hybrid Approach to Coping with High Dimensionality and Class Imbalance for Software Defect Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.145},
doi = {10.1109/ICMLA.2012.145},
abstract = {High dimensionality and class imbalance are the two main problems affecting many software defect prediction. In this paper, we propose a new technique, named SelectRUSBoost, which is a form of ensemble learning that in-corporates data sampling to alleviate class imbalance and feature selection to resolve high dimensionality. To evaluate the effectiveness of the new technique, we apply it to a group of datasets in the context of software defect prediction. We employ two classification learners and six feature selection techniques. We compare the technique to the approach where feature selection and data sampling are used together, as well as the case where feature selection is used alone (no sampling used at all). The experimental results demonstrate that the SelectRUSBoost technique is more effective in improving classification performance compared to the other approaches.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {281–288},
numpages = {8},
keywords = {software defect prediction, high dimensionality, class imbalance},
series = {ICMLA '12}
}

@article{10.1007/s10619-021-07331-4,
author = {Srinivasan, R. and Subalalitha, C. N.},
title = {Sentimental analysis from imbalanced code-mixed data using machine learning approaches},
year = {2021},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {41},
number = {1},
issn = {0926-8782},
url = {https://doi.org/10.1007/s10619-021-07331-4},
doi = {10.1007/s10619-021-07331-4},
abstract = {Knowledge discovery from various perspectives has become a crucial asset in almost all fields. Sentimental analysis is a classification task used to classify the sentence based on the meaning of their context. This paper addresses class imbalance problem which is one of the important issues in sentimental analysis. Not much works focused on sentimental analysis with imbalanced class label distribution. The paper also focusses on another aspect of the problem which involves a concept called “Code Mixing”. Code mixed data consists of text alternating between two or more languages. Class imbalance distribution is a commonly noted phenomenon in a code-mixed data. The existing works have focused more on analyzing the sentiments in a monolingual data but not in a code-mixed data. This paper addresses all these issues and comes up with a solution to analyze sentiments for a class imbalanced code-mixed data using sampling technique combined with levenshtein distance metrics. Furthermore, this paper compares the performances of various machine learning approaches namely, Random Forest Classifier, Logistic Regression, XGBoost classifier, Support Vector Machine and Na\"{\i}ve Bayes Classifier using F1- Score.},
journal = {Distrib. Parallel Databases},
month = mar,
pages = {37–52},
numpages = {16},
keywords = {Code-mixed data, Sentimental analysis, Imbalanced data, Machine learning, Sampling}
}

@article{10.1016/j.compeleceng.2021.107362,
author = {P, Gouthaman and Sankaranarayanan, Suresh},
title = {Prediction of Risk Percentage in Software Projects by Training Machine Learning Classifiers},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107362},
doi = {10.1016/j.compeleceng.2021.107362},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {9},
keywords = {Risk prediction, Machine learning, Incremental, Evolutionary, Waterfall, Agile, Software model}
}

@article{10.1007/s00500-020-05226-7,
author = {Khuat, Thanh Tung and Ruta, Dymitr and Gabrys, Bogdan},
title = {Hyperbox-based machine learning algorithms: a comprehensive survey},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05226-7},
doi = {10.1007/s00500-020-05226-7},
abstract = {With the rapid development of digital information, the data volume generated by humans and machines is growing exponentially. Along with this trend, machine learning algorithms have been formed and evolved continuously to discover new information and knowledge from different data sources. Learning algorithms using hyperboxes as fundamental representational and building blocks are a branch of machine learning methods. These algorithms have enormous potential for high scalability and online adaptation of predictors built using hyperbox data representations to the dynamically changing environments and streaming data. This paper aims to give a comprehensive survey of the literature on hyperbox-based machine learning models. In general, according to the architecture and characteristic features of the resulting models, the existing hyperbox-based learning algorithms may be grouped into three major categories: fuzzy min–max neural networks, hyperbox-based hybrid models and other algorithms based on hyperbox representations. Within each of these groups, this paper shows a brief description of the structure of models, associated learning algorithms and an analysis of their advantages and drawbacks. Main applications of these hyperbox-based models to the real-world problems are also described in this paper. Finally, we discuss some open problems and identify potential future research directions in this field.},
journal = {Soft Comput.},
month = jan,
pages = {1325–1363},
numpages = {39},
keywords = {Online learning, Clustering, Data classification, Hybrid classifiers, Fuzzy min–max neural network, Membership function, Hyperboxes}
}

@inproceedings{10.1109/AIM.2018.8452361,
author = {Jung, S. Y. and Tsai, Y.H. and Chiu, W.Y and Hu, J.S. and Sun, C.T.},
title = {Defect Detection on Randomly Textured Surfaces by Convolutional Neural Networks},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM.2018.8452361},
doi = {10.1109/AIM.2018.8452361},
abstract = {Automatically detecting the defects on the randomly textured surfaces for industrial purpose is a demanding procedure due to the ambiguity between defects and textures, lack of defect-labeled data and the must-have extreme accuracy. In this paper we proposed a procedure as the beginning of automating the defect detection on woods with randomly textured surfaces by employing 3 different architectures of convolutional neural networks. The deep convolutional neural network resulted in 99.80% accuracy, discriminating among normal wood and the other 4 types of defects images. The models were evaluated and understood by visualizing the saliency maps. The results from our work implies that other industrial images with defects on randomly textured surfaces may apply the similar procedures to accelerate the automating of defect detection and progressing of industry 4.0.},
booktitle = {2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1456–1461},
numpages = {6},
location = {Auckland, New Zealand}
}

@inproceedings{10.1145/3360322.3360835,
author = {Li, Xiaoxia and Li, Wei and Yang, Qiang and Yan, Wenjun and Zomaya, Albert Y.},
title = {Building an Online Defect Detection System for Large-scale Photovoltaic Plants},
year = {2019},
isbn = {9781450370059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3360322.3360835},
doi = {10.1145/3360322.3360835},
abstract = {The power efficiency of photovoltaic modules is highly correlated with their health status. Under dynamically changing environments, photovoltaic defects could spontaneously form and develop into fatal faults during the daily operation of photovoltaic plants. To facilitate defect detection with less human intervention, a nondestructive and contactless visual inspection system with the help of unmanned aerial vehicles and edge computing is proposed in this work. Limited by the resources of edge devices and the availability of images of photovoltaic defects for training, we developed an online solution combined with deep learning, data argumentation and transfer learning to properly address the issues of running resource hungry applications on edge devices and lack of training samples faced by the deep learning approaches used in the field. With the reduction of the network depth of the deep convolutional neural network model and the transfer of features from the learned defects, the resource consumption of our proposed approach is significantly reduced, and thus can be used on a wide range of edge devices to complete defect detection in a timely manner with high accuracy. To study the performance of our design, a testbed was built from open source hardware and software, and field trials were carried out in three photovoltaic plants. The experimental results clearly demonstrate the practicality and effectiveness of our design for detecting visible defects on photovoltaic modules.},
booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {253–262},
numpages = {10},
keywords = {transfer learning, edge computing, defects detection, cyber-physical systems, classification},
location = {New York, NY, USA},
series = {BuildSys '19}
}

@article{10.1504/ijica.2021.119339,
author = {Jiang, Xiaoliang and Yang, Xiaojun and Ding, Xiaokang},
title = {An efficient and reliable approach based on adaptive threshold for road defect detection},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {5–6},
issn = {1751-648X},
url = {https://doi.org/10.1504/ijica.2021.119339},
doi = {10.1504/ijica.2021.119339},
abstract = {With the rapid development of economy, automatic detection of road crack becomes a hot research study. However, it still has immense challenges due to the shading, intensity inhomogeneity and divots in the crack image. Traditional detection algorithms use the characteristic of the image such as intensity and texture to segment the crack regions, so they cannot achieve satisfactory performance. In this article, we introduce an automatically image-based method for road crack detection. Firstly, a new mask image is constructed based on the grey-mean of original image. Secondly, calculating the difference between the original image and the mask image and selecting the highest value to extract the targets from the image background. Finally, the redundant interference is removed by morphological operation. Experimental results concentrate on public datasets show that our method is more reliable than previous approaches.},
journal = {Int. J. Innov. Comput. Appl.},
month = jan,
pages = {321–329},
numpages = {8},
keywords = {adaptive threshold, Otsu, image segmentation, road crack detection}
}

@article{10.1002/smr.2330,
author = {Shi, Ke and Lu, Yang and Liu, Guangliang and Wei, Zhenchun and Chang, Jingfei},
title = {MPT‐embedding: An unsupervised representation learning of code for software defect prediction},
year = {2021},
issue_date = {April 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2330},
doi = {10.1002/smr.2330},
abstract = {Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning‐based methods tend to build end‐to‐end models that directly use source code‐based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front‐end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross‐project defect prediction (CPDP) and within‐project defect prediction (WPDP) show that, on average, MPT‐embedding provides improvements over the state‐of‐the‐art method.Source code‐based automatic representations are more objective and accurate than traditional handcrafted metrics. This article proposed a new framework to represent code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on the tasks of defect prediction show the effectiveness of the model.


image
image},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {20},
keywords = {tree embedding, representation learning, defect prediction, deep learning}
}

@inproceedings{10.1007/978-3-030-04780-1_26,
author = {Pal, Amrit and Kumar, Manish},
title = {Applying Big Data Intelligence for Real Time Machine Fault Prediction},
year = {2018},
isbn = {978-3-030-04779-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-04780-1_26},
doi = {10.1007/978-3-030-04780-1_26},
abstract = {Continuous use of mechanical systems requires precise maintenance. Automatic monitoring of such systems generates a large amount of data which require intelligent mining methods for processing and information extraction. The problem is to predict the faults generated with ball bearing which severely degrade operating conditions of machinery. We develop a distributed fault prediction model based on big data intelligence that extracts nine essential features from ball bearing dataset through distributed random forest. We also perform a rigorous simulation analysis of the proposed approach and the results ensure the accuracy/correctness of the method. Different types of fault classes are considered for prediction purpose and classification is done in a supervised distributed environment.},
booktitle = {Big Data Analytics: 6th International Conference, BDA 2018, Warangal, India, December 18–21, 2018, Proceedings},
pages = {376–391},
numpages = {16},
keywords = {Distributed environment, Random forest, Ball bearing, Fault prediction, Spark, Parallel processing, Decision tree},
location = {Warangal, India}
}

@article{10.1007/s11554-020-01023-5,
author = {Wei, Wei and Deng, Dexiang and Zeng, Lin and Zhang, Chen},
title = {Real-time implementation of fabric defect detection based on variational automatic encoder with structure similarity},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {3},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-020-01023-5},
doi = {10.1007/s11554-020-01023-5},
abstract = {Automatic detection of fabric defects based on machine vision is an important topic in the quality control of cotton textile factories. There are many kinds of defects in fabric production, it is very difficult to classify the defects automatically. In recent years, deep learning image processing technology based on a convolutional neural network (CNN) can train and extract features of the target image automatically. Since a large number of defect samples cannot be collected completely, we compared unsupervised learning algorithms based on CNN, including auto encoder (AE), variational automatic encoder (VAE), and generative adversarial networks (GAN). Because of the large amount of calculation and the difficulty of training in GAN, we chose AE and VAE codec networks and then introduced mean structural similarity (MSSIM) as network training loss function to improve the performance that only used Lp-distance loss function for image brightness comparison. After training finished, the authors used the trained model to obtain target defects from SSIM residual maps between input and reconstruct images. According to the evaluation results, we finally implemented a fabric defect detection system based on VAE on Jetson TX2 from Nvidia Corporation, USA. The optimized algorithm can meet the real-time requirements of the project and realize its popularization and application.},
journal = {J. Real-Time Image Process.},
month = jun,
pages = {807–823},
numpages = {17},
keywords = {Deep learning, Real-time, Structural similarity, Variational automatic encoder, Fabric defects}
}

@inproceedings{10.1145/1629716.1629720,
author = {Chae, Wonseok and Blume, Matthias},
title = {Language support for feature-oriented product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629720},
doi = {10.1145/1629716.1629720},
abstract = {Product line engineering is an emerging paradigm of developing a family of products. While product line analysis and design mainly focus on reasoning about commonality and variability of family members, product line implementation gives its attention to mechanisms of managing variability. In many cases, however, product line methods do not impose any specific synthesis mechanisms on product line implementation, so implementation details are left to developers. In our previous work, we adopted feature-oriented product line engineering to build a family of compilers and managed variations using the Standard ML module system. We demonstrated the applicability of this module system to product line implementation. Although we have benefited from the product line engineering paradigm, it mostly served us as a design paradigm to change the way we think about a set of closely related compilers, not to change the way we build them. The problem was that Standard ML did not fully realize this paradigm at the code level, which caused some difficulties when we were developing a set of compilers.In this paper, we address such issues with a language-based solution. MLPolyR is our choice of an implementation language. It supports three different programming styles. First, its first-class cases facilitate composable extensions at the expression levels. Second, its module language provides extensible and parameterized modules, which make large-scale extensible programming possible. Third, its macro system simplifies specification and composition of feature related code. We will show how the combination of these language features work together to facilitate the product line engineering paradigm.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {3–10},
numpages = {8},
keywords = {feature-oriented programming, product line engineering},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@article{10.1016/j.neucom.2015.12.112,
author = {Gai, Shan},
title = {New banknote defect detection algorithm using quaternion wavelet transform},
year = {2016},
issue_date = {July 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {196},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.12.112},
doi = {10.1016/j.neucom.2015.12.112},
abstract = {In order to improve the accuracy of detection of defects in banknote sorting, a new algorithm is proposed to detect cracks and scratches on banknote images. The quaternion wavelet transform and the least squares method are used for the banknote image registration. The features of the defects that are robust to gray intensity changes are constructed using edge information captured by the Kirsch operator. The banknote image is divided into several subzones of fixed size. The level of defect of the banknote image is estimated based on the defective features of each sub-zone. The experimental results show that the proposed algorithm is robust even with low quality banknote images and can obtain a high recognition rate and high stability. The proposed algorithm has already been used in a practical banknote sorting system. The quaternion wavelet transform is applied to banknote image registration.Defect banknote features are extracted by the proposed edge intensity.New banknote defect detection algorithm based on our QWT is proposed.},
journal = {Neurocomput.},
month = jul,
pages = {133–139},
numpages = {7},
keywords = {Quaternion wavelet transform, Feature extraction, Defect detection, Banknote classification}
}

@article{10.1016/j.is.2015.02.006,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {51},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2015.02.006},
doi = {10.1016/j.is.2015.02.006},
abstract = {Software development projects inevitably accumulate defects throughout the development process. Due to the high cost that defects can incur, careful consideration is crucial when predicting which sections of code are likely to contain defects. Classification algorithms used in machine learning can be used to create classifiers which can be used to predict defects. While traditional classification algorithms optimize for accuracy, cost-sensitive classification methods attempt to make predictions which incur the lowest classification cost. In this paper we propose a cost-sensitive classification technique called CSForest which is an ensemble of decision trees. We also propose a cost-sensitive voting technique called CSVoting in order to take advantage of the set of decision trees in minimizing the classification cost. We then investigate a potential solution to class imbalance within our decision forest algorithm. We empirically evaluate the proposed techniques comparing them with six (6) classifier algorithms on six (6) publicly available clean datasets that are commonly used in the research on software defect prediction. Our initial experimental results indicate a clear superiority of the proposed techniques over the existing ones. Author-HighlightsSDP is short for Software Defect Prediction.We show that there is not a clear winner in the studied existing methods for SDP*.A cost-sensitive decision forest and voting technique are proposed.The superiority of the proposed techniques is shown.A proposed framework for the forest algorithm for handling class imbalance.},
journal = {Inf. Syst.},
month = jul,
pages = {62–71},
numpages = {10},
keywords = {Software defect prediction, Forest voting, Decision forest, Cost-sensitive, Class imbalance}
}

@article{10.1145/3408063,
author = {Xama, Nektar and Andraud, Martin and Gomez, Jhon and Esen, Baris and Dobbelaere, Wim and Vanhooren, Ronny and Coyette, Anthony and Gielen, Georges},
title = {Machine Learning-based Defect Coverage Boosting of Analog Circuits under Measurement Variations},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3408063},
doi = {10.1145/3408063},
abstract = {Safety-critical and mission-critical systems, such as airplanes or (semi-)autonomous cars, are relying on an ever-increasing number of embedded integrated circuits. Consequently, there is a need for complete defect coverage during the testing of these circuits to guarantee their functionality in the field. In this context, reducing the escape rate of defects during production testing is crucial, and significant progress has been made to this end. However, production testing using automatic test equipment is subject to various measurement parasitic variations, which may have a negative impact on the testing procedure and therefore limit the final defect coverage. To tackle this issue, this article proposes an improved test flow targeting increased analog defect coverage, both at the system and block levels, by analyzing and improving the coverage of typical functional and structural tests under these measurement variations. To illustrate the flow, the technique of inserting a pseudo-random signal at available circuit nodes and applying machine learning techniques to its response is presented. A DC-DC converter, derived from an industrial product, is used as a case study to validate the flow. In short, results show that system-level tests for the converter suffer strongly from the measurement variations and are limited to just under 80% coverage, even when applying the proposed test flow. Block-level testing, however, can achieve only 70% fault coverage without improvements but is able to consistently achieve 98% of fault coverage at a cost of at most 2% yield loss with the proposed machine learning–based boosting technique.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = aug,
articleno = {47},
numpages = {27},
keywords = {test under measurements variations, Machine learning for test, AMS IC test}
}

@inproceedings{10.1145/3127005.3127013,
author = {Valdivia-Garcia, Harold and Nagappan, Meiyappan},
title = {The Characteristics of False-Negatives in File-level Fault Prediction},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127013},
doi = {10.1145/3127005.3127013},
abstract = {Over the years, a plethora of works has proposed more and more sophisticated machine learning techniques to improve fault prediction models. However, past studies using product metrics from closed-source projects, found a ceiling effect in the performance of fault prediction models. On the other hand, other studies have shown that process metrics are significantly better than product metrics for fault prediction. In our case study therefore we build models that include both product and process metrics taken together. We find that the ceiling effect found in prior studies exists even when we consider process metrics. We then qualitatively investigate the bug reports, source code files, and commit information for the bugs in the files that are false-negative in our fault prediction models trained using product and process metrics. Surprisingly, our qualitative analysis shows that bugs related to false-negative files and true-positive files are similar in terms of root causes, impact and affected components, and consequently such similarities might be exploited to enhance fault prediction models.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {73–82},
numpages = {10},
keywords = {Code Metrics, Post-release Defects, Process Metrics},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.5555/3507788.3507798,
author = {Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Garcon, Sylvain and Tauseef, Qasim},
title = {Failure prediction using machine learning in IBM WebSphere liberty continuous integration environment},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing complexity and dependencies of software have increased the importance of testing to ensure that frequent changes do not adversely affect existing functionality. Moreover, continuous integration comes with unique challenges associated with maintaining a stable build environment. Several studies have shown that the testing environment becomes more efficient with proper test case prioritization techniques. However, an application's dynamic behavior makes it challenging to derive test case prioritization techniques for achieving optimal results. With the advance of machine learning, the context of an application execution can be analyzed to select and prioritize test suites more efficiently.Test suite prioritization techniques aim to reorder test suites' execution to deliver high quality, maintainable software at lower costs to meet specific objectives such as revealing failures earlier. The state-of-the-art techniques on test prioritization in a continuous integration environment focus on relatively small, single-language, unit-tested projects. This paper compares and analyzes Machine learning-based test suite prioritization technique on two large-scale dataset collected from a continuous integration environment Google and IBM respectively. We optimize hyperparameters and report on experiments' findings by using different machine learning algorithms for test suite prioritization. Our optimized algorithms prioritize test suites with 93% accuracy on average and require 20% fewer test suites to detect 80% of the failures than the test suites prioritized randomly.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {test prioritization, machine learning, continuous integration, CI},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1016/j.procs.2017.09.040,
author = {Zhang, Mei and Wu, Jinglan and Lin, Huifeng and Yuan, Peng and Song, Yanan},
title = {The Application of One-Class Classifier Based on CNN in Image Defect Detection},
year = {2017},
issue_date = {November 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {114},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.09.040},
doi = {10.1016/j.procs.2017.09.040},
abstract = {In the field of defect detection, image processing algorithms and feature extraction algorithms have some limitations, owing to their necessity for extracting a large number of different features of diverse products images. Meanwhile, the images of defective products are less and various. Aiming at these problems, we presented a One-Class classifier based on deep convolution neural network to detect the defect images in this paper. We design a loss function with the penalty term based on Euclidean distance to train the deep convolution neural network model. A hypersphere is used as classification decision surface after setting an appropriate hypersphere radius according to the inspection accuracy. It maps the non-defective products into a hypersphere in a high dimensional feature space, while the defect images are mapped somewhere far from the center of hypersphere. Thus, a One-Class classifier based on convolutional neural network(CNN) model is proposed to detect the defects. Experiments show that the proposed method, with less number of iteration, help build the classifier for image defect detection with high generalization ability and high detection precision.},
journal = {Procedia Comput. Sci.},
month = nov,
pages = {341–348},
numpages = {8},
keywords = {One-Class classifier, Image defect detection, Hypersphere, CNN}
}

@article{10.1016/j.asoc.2016.10.030,
author = {Jian, Chuanxia and Gao, Jian and Ao, Yinhui},
title = {Automatic surface defect detection for mobile phone screen glass based on machine vision},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {52},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.10.030},
doi = {10.1016/j.asoc.2016.10.030},
abstract = {Display Omitted A surface defect detection system is proposed for mobile phone screen glass. This system achieves 94% in sensitivity and 97.33% in specificity.The proposed system takes approximate 1.6601s to detect a MPSG. The detection accuracy and speed can meet the needs of online detection for MPSG.Compared with other methods used in the experiment, the proposed improved fuzzy c-means can segment the surface defects in MPSG more accurately. Defect detection using machine vision technology plays an important role in the manufacturing process of mobile phone screen glass (MPSG). This study proposes an improved detection algorithm for MPSG defect recognition and segmentation. Considering the problem of MPSG image misalignment caused by vibrations in the mobile stages, a contour-based registration (CR) method is used to generate the template image used to align the MPSG images. Based on this registration result, the combination of subtraction and projection (CSP) is used to identify defects on the MPSG image, which can eliminate the influence of fluctuation in ambient illumination. To segment the defects with a fuzzy grey boundary from a noisy MPSG image, an improved fuzzy c-means cluster (IFCM) algorithm is developed in this study. A defect detection system is developed, and the proposed algorithms are validated using a number of experimental tests on MPSG images. The testing results demonstrate that the approach proposed in this study can effectively detect various defects on MPSG and that it has better performance than other methods.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {348–358},
numpages = {11},
keywords = {Mobile phone screen glass, Image subtraction, Fuzzy c-means cluster, Defect detection, Contour-based registration}
}

@inproceedings{10.1145/3448734.3450774,
author = {Yang, Jun and He, Ruoyu and Cui, Baojiang},
title = {A GPU memory leakage code defect detection method based on the API calling feature},
year = {2021},
isbn = {9781450389570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448734.3450774},
doi = {10.1145/3448734.3450774},
abstract = {The General-Purpose Graphics Processing Unit (GPGPU) programming has been widely used in artificial intelligence and deep learning, and the GPGPU programming framework, represented by the CUDA framework launched by NIVIDIA Corporation, can apply the powerful parallel computing power of Graphics Processing unit (GPU) to non-graphics tasks. The gradually open computing power of GPU also brings related security risks, but the industry is still mainly concerned with how to dig into the potential security risks of GPU rather than the protection of known problems. In this paper, we propose an API calling feature (ACF) based method for detecting memory leaks in GPU codes and programmatically implement a prototype method to detect the risk of memory data residue in GPU codes written in CUDA framework. The prototype detection method is implemented using the Pass module development capability provided by the LLVM compiler project, and the method is tested to have good accuracy an effectiveness, which can provide a basis for subsequent GPU codes' security research.},
booktitle = {The 2nd International Conference on Computing and Data Science},
articleno = {44},
numpages = {13},
keywords = {features, detection, code defects, General-purpose graphics processing unit programming},
location = {Stanford, CA, USA},
series = {CONF-CDS 2021}
}

@article{10.1007/s11704-020-9441-1,
author = {Sun, Xiaobing and Zhou, Tianchi and Wang, Rongcun and Duan, Yucong and Bo, Lili and Chang, Jianming},
title = {Experience report: investigating bug fixes in machine learning frameworks/libraries},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {6},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-020-9441-1},
doi = {10.1007/s11704-020-9441-1},
abstract = {Machine learning (ML) techniques and algorithms have been successfully and widely used in various areas including software engineering tasks. Like other software projects, bugs are also common in ML projects and libraries. In order to more deeply understand the features related to bug fixing in ML projects, we conduct an empirical study with 939 bugs from five ML projects by manually examining the bug categories, fixing patterns, fixing scale, fixing duration, and types of maintenance. The results show that (1) there are commonly seven types of bugs in ML programs; (2) twelve fixing patterns are typically used to fix the bugs in ML programs; (3) 68.80% of the patches belong to micro-scale-fix and small-scale-fix; (4) 66.77% of the bugs in ML programs can be fixed within one month; (5) 45.90% of the bug fixes belong to corrective activity from the perspective of software maintenance. Moreover, we perform a questionnaire survey and send them to developers or users of ML projects to validate the results in our empirical study. The results of our empirical study are basically consistent with the feedback from developers. The findings from the empirical study provide useful guidance and insights for developers and users to effectively detect and fix bugs in ML projects.},
journal = {Front. Comput. Sci.},
month = dec,
numpages = {16},
keywords = {questionnaire survey, empirical study, machine learning project, bug fixing}
}

@article{10.1504/IJISTA.2016.076102,
author = {Rong, Xiaotao and Li, Feixiang and Cui, Zhihua},
title = {A model for software defect prediction using support vector machine based on CBA},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {15},
number = {1},
issn = {1740-8865},
url = {https://doi.org/10.1504/IJISTA.2016.076102},
doi = {10.1504/IJISTA.2016.076102},
abstract = {Software defection prediction is not only crucial for improving software quality, but also helpful for software test effort estimation. As is well-known, 80% of the fault happens in 20% of the modules. Therefore, we need to find out the most error prone modules accurately and correct them in time to save time, money, and energy. Support vector machine SVM is an advanced classification method that fits the defection classification. However, studies show that, the value of parameters of SVM model has a remarkable influence on its classification accuracy and the selection process lacks theory guidance that makes the SVM model uncertainty and low efficiency. In this paper, a CBA-SVM software defect prediction model is proposed, which take advantage of the non-linear computing ability of SVM model and optimisation capacity of bat algorithm with centroid strategy CBA. Through the experimental comparison with other models, CBA-SVM is proved to have a higher accuracy.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = apr,
pages = {19–34},
numpages = {16}
}

@inproceedings{10.1145/2875913.2875944,
author = {Qing, He and Biwen, Li and Beijun, Shen and Xia, Yong},
title = {Cross-Project Software Defect Prediction Using Feature-Based Transfer Learning},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875944},
doi = {10.1145/2875913.2875944},
abstract = {Cross-project defect prediction is taken as an effective means of predicting software defects when the data shortage exists in the early phase of software development. Unfortunately, the precision of cross-project defect prediction is usually poor, largely because of the differences between the reference and the target projects. Having realized the project differences, this paper proposes CPDP, a feature-based transfer learning approach to cross-project defect prediction. The core insight of CPDP is to (1) filter and transfer highly-correlated data based on data samples in the target projects, and (2) evaluate and choose learning schemas for transferring data sets. Models are then built for predicting defects in the target projects. We have also conducted an evaluation of the proposed approach on PROMISE datasets. The evaluation results show that, the proposed approach adapts to cross-project defect prediction in that f-measure of 81.8% of projects can get improved, and AUC of 54.5% projects improved. It also achieves similar f-measure and AUC as some inner-project defect prediction approaches.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {74–82},
numpages = {9},
keywords = {transfer learning, feature-based transfer, cross-project defect prediction},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1109/COASE.2019.8843313,
author = {Yan, Hao and Yeh, Huai-Ming and Sergin, Nurettin},
title = {Image-based Process Monitoring via Adversarial Autoencoder with Applications to Rolling Defect Detection},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843313},
doi = {10.1109/COASE.2019.8843313},
abstract = {Image-based process monitoring has recently attracted increasing attention due to the advancement of the sensing technologies. However, existing process monitoring methods fail to fully utilize the spatial information of images due to their complex characteristics including the high-dimensionality and complex spatial structures. Recent advancements in unsupervised deep models such as generative adversarial networks (GAN) and adversarial autoencoders (AAE) has enabled to learn the complex spatial structures automatically. Inspired by this advancement, we propose an anomaly detection framework based on the AAE for unsupervised anomaly detection for images. AAE combines the power of GAN with the variational autoencoder, which serves as a nonlinear dimension reduction technique. Based on this, we propose a monitoring statistic efficiently capturing the change of the data. The performance of the proposed AAE-based anomaly detection algorithm is validated through a simulation study and real case study for rolling defect detection.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {311–316},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.eswa.2020.114161,
author = {Houssein, Essam H. and Emam, Marwa M. and Ali, Abdelmgeid A. and Suganthan, Ponnuthurai Nagaratnam},
title = {Deep and machine learning techniques for medical imaging-based breast cancer: A comprehensive review},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114161},
doi = {10.1016/j.eswa.2020.114161},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {20},
keywords = {Thermography images, Ultrasound images, Mammogram images, Medical imaging modalities, Magnetic resonance imaging (MRI), Machine learning, Histological images, Deep learning, Computer-aided diagnosis system (CAD), Convolutional neural network, Breast cancer classification}
}

@article{10.1016/j.neucom.2017.02.021,
author = {Susan, Seba and Sharma, Monika},
title = {Automatic texture defect detection using Gaussian mixture entropy modeling},
year = {2017},
issue_date = {May 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {239},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2017.02.021},
doi = {10.1016/j.neucom.2017.02.021},
abstract = {In this paper we propose a new unsupervised, automated texture defect detection that does not require any user-inputs and yields high accuracies at the same time. To achieve this end we use the non-extensive entropy with Gaussian gain as the regularity index, computed locally from texture patches through a sliding window approach. The optimum window size is determined by modeling the entropy values by a two-mode Gaussian mixture model and checking for the minimum entropy of the mode-probabilities. The outlier entropy values corresponding to defective areas are defined as those that exceed thrice the standard deviation, as is the norm in statistics. The result is automatic defect detection with no manual intervention. Empirical results on defective texture images from the Brodatz database provide accurate localization of the defect as compared to Chetverikov and Hanbury's maximal regularity method, which requires manual setting of threshold parameters for each type of texture despite of being a benchmark for texture defect detection.},
journal = {Neurocomput.},
month = may,
pages = {232–237},
numpages = {6},
keywords = {Texture regularity, Texture defects, Sliding window approach, Non-extensive entropy with Gaussian gain, Gaussian mixture model}
}

@inproceedings{10.1109/ICCUBEA.2015.145,
author = {Karlekar, Vaibhav V. and Biradar, M. S. and Bhangale, K. B.},
title = {Fabric Defect Detection Using Wavelet Filter},
year = {2015},
isbn = {9781479968923},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCUBEA.2015.145},
doi = {10.1109/ICCUBEA.2015.145},
abstract = {Fabric defect detection is now an active area of research for identifying and res olving problems of textile industry, to enhance the performance and also to maintain the quality of fabric. The traditional system of visual inspection by human beings is extremely time consuming, high on costs as well as not reliable since it is highly error prone. Defect detection &amp; cl assification are the major challenges in defect inspection. Hence in order to overcome these drawbacks, faster and cost effective automatic defect detection is very necessary. Considering these necessities, this paper proposes wavelet filter method. It also explains in detail its various techniques of getting final output like preprocessing, decomposition, thresholding, and noise eliminating.},
booktitle = {Proceedings of the 2015 International Conference on Computing Communication Control and Automation},
pages = {712–715},
numpages = {4},
keywords = {wavelet filter, wavelet decomposition, thresholding, morphology filter, Fabric defect detection},
series = {ICCUBEA '15}
}

@inproceedings{10.1109/RAMS.2019.8768923,
author = {Cui, Can and Liu, Bin and Li, Guoqi},
title = {A Novel Feature Selection Method for Software Fault Prediction Model},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAMS.2019.8768923},
doi = {10.1109/RAMS.2019.8768923},
abstract = {Software fault prediction (SFP) is an active issue in software engineering (SE). At present, machine learning (ML) has been successfully applied to SFP classification problems. However, one of the challenges for building software fault prediction models (SFPM) is processing high dimensional datasets, which include many irrelevant and redundant features. To address this issue, feature selection techniques, mainly contain wrapper methods and filter methods, are used. In the paper, we report an empirical study aimed at providing a novel approach to select feature for SFP.},
booktitle = {2019 Annual Reliability and Maintainability Symposium (RAMS)},
pages = {1–6},
numpages = {6},
location = {Orlando, FL, USA}
}

@inproceedings{10.1007/978-3-642-02481-8_80,
author = {Santos, Igor and Nieves, Javier and Penya, Yoseba K. and Bringas, Pablo G.},
title = {Optimising Machine-Learning-Based Fault Prediction in Foundry Production},
year = {2009},
isbn = {9783642024801},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02481-8_80},
doi = {10.1007/978-3-642-02481-8_80},
abstract = {Microshrinkages are known as probably the most difficult defects to avoid in high-precision foundry. The presence of this failure renders the casting invalid, with the subsequent cost increment. Modelling the foundry process as an expert knowledge cloud allows properly-trained machine learning algorithms to foresee the value of a certain variable, in this case the probability that a microshrinkage appears within a casting. Extending previous research that presented outstanding results with a Bayesian-network-based approach, we have adapted and tested an artificial neural network and the K-nearest neighbour algorithm for the same objective. Finally, we compare the obtained results and show that Bayesian networks are more suitable than the rest of the counterparts for the prediction of microshrinkages.},
booktitle = {Proceedings of the 10th International Work-Conference on Artificial Neural Networks: Part II: Distributed Computing, Artificial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living},
pages = {554–561},
numpages = {8},
keywords = {fault prediction, data mining, Machine learning},
location = {Salamanca, Spain},
series = {IWANN '09}
}

@inproceedings{10.1145/3177457.3191709,
author = {Ren, Yidan and Zhu, Zhengzhou and Chen, Xiangzhou and Ding, Huixia and Zhang, Geng},
title = {Research on Defect Detection Technology of Trusted Behavior Decision Tree Based on Intelligent Data Semantic Analysis of Massive Data},
year = {2018},
isbn = {9781450363396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177457.3191709},
doi = {10.1145/3177457.3191709},
abstract = {With the rapid development of information technology, software systems' scales and complexity are showing a trend of expansion. The users' needs for the software security, software security reliability and software stability are growing increasingly. At present, the industry has applied machine learning methods to the fields of defect detection to repair and improve software defects through the massive data intelligent semantic analysis or code scanning. The model in machine learning is faced with big difficulty of model building, understanding, and the poor visualization in the field of traditional software defect detection. In view of the above problems, we present a point of view that intelligent semantic analysis technology based on massive data, and using the trusted behavior decision tree model to analyze the soft behavior by layered detection technology. At the same time, it is equipped related test environment to compare the tested software. The result shows that the defect detection technology based on intelligent semantic analysis of massive data is superior to other techniques at the cost of building time and error reported ratio.},
booktitle = {Proceedings of the 10th International Conference on Computer Modeling and Simulation},
pages = {168–175},
numpages = {8},
keywords = {software defect detection, intelligent semantic analysis, decision tree, Massive data},
location = {Sydney, Australia},
series = {ICCMS '18}
}

@inproceedings{10.1145/2851613.2851788,
author = {das D\^{o}res, Silvia N. and Alves, Luciano and Ruiz, Duncan D. and Barros, Rodrigo C.},
title = {A meta-learning framework for algorithm recommendation in software fault prediction},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851788},
doi = {10.1145/2851613.2851788},
abstract = {Software fault prediction is a significant part of software quality assurance and it is commonly used to detect faulty software modules based on software measurement data. Several machine learning based approaches have been proposed for generating predictive models from collected data, although none has become standard given the specificities of each software project. Hence, we believe that recommending the best algorithm for each project is much more important and useful than developing a single algorithm for being used in any project. For achieving that goal, we propose in this paper a novel framework for recommending machine learning algorithms that is capable of automatically identifying the most suitable algorithm according to the software project that is being considered. Our solution, namely SFP-MLF, makes use of the meta-learning paradigm in order to learn the best learner for a particular project. Results show that the SFP-MLF framework provides both the best single algorithm recommendation and also the best ranking recommendation for the software fault prediction problem.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1486–1491},
numpages = {6},
keywords = {algorithm recommendation, machine learning, meta-learning, software fault prediction, software quality},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/3177404.3177456,
author = {Yan, Kai and Dong, Qian and Sun, Tingting and Zhang, Ming and Zhang, Siyuan},
title = {Weld Defect Detection based on Completed Local Ternary Patterns},
year = {2017},
isbn = {9781450353830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177404.3177456},
doi = {10.1145/3177404.3177456},
abstract = {Contemporarily, the artificial way to review the X-ray film is a common manner to the Quality Examination for Weld. However, this manner has much subjectivity, which may greatly affect the detection efficiency and accuracy, especially after doing a great deal of repetitive mental work. The automatic welding defect inspection system based on X-ray could overcome the shortcomings of artificial marking. Worldwide researchers have made extensive and in-depth research on defect extraction and recognition, and have achieved a great number of effective research results. However, there are still some issues, such as the accurate detection of small defects in uneven background, and effective classification of various defects and automatic identification.For the issues of the weld image based on X-ray, this paper aims to use common texture features to make feature extraction and improved local binary patterns(LBP) as the foundations to propose the completed local ternary patterns (CLTP) to detect weld defects and use SVM classifier based on binary tree to classify and recognize the weld defects to solve the issues on inaccurate detection of small defects and lack of valid classification.},
booktitle = {Proceedings of the International Conference on Video and Image Processing},
pages = {6–14},
numpages = {9},
keywords = {texture features, local binary pattern, completed local ternary patterns, Weld defect detection, SVM},
location = {Singapore, Singapore},
series = {ICVIP '17}
}

@article{10.4018/ijssci.2014040101,
author = {Mishra, Bharavi and Shukla, K.K.},
title = {Software Defect Prediction Based on GUHA Data Mining Procedure and Multi-Objective Pareto Efficient Rule Selection},
year = {2014},
issue_date = {April 2014},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {2},
issn = {1942-9045},
url = {https://doi.org/10.4018/ijssci.2014040101},
doi = {10.4018/ijssci.2014040101},
abstract = {Software defect prediction, if is effective, enables the developers to distribute their testing efforts efficiently and let them focus on defect prone modules. It would be very resource consuming to test all the modules while the defect lies in fraction of modules. Information about fault-proneness of classes and methods can be used to develop new strategies which can help mitigate the overall development cost and increase the customer satisfaction. Several machine learning strategies have been used in recent past to identify defective modules. These models are built using publicly available historical software defect data sets. Most of the proposed techniques are not able to deal with the class imbalance problem efficiently. Therefore, it is necessary to develop a prediction model which consists of small simple and comprehensible rules. Considering these facts, in this paper, the authors propose a novel defect prediction approach named GUHA based Classification Association Rule Mining algorithm G-CARM where "GUHA" stands for General Unary Hypothesis Automaton. G-CARM approach is primarily based on Classification Association Rule Mining, and deploys a two stage process involving attribute discretization, and rule generation using GUHA. GUHA is oldest yet very powerful method of pattern mining. The basic idea of GUHA procedure is to mine the interesting attribute patterns that indicate defect proneness. The new method has been compared against five other models reported in recent literature viz. Naive Bayes, Support Vector Machine, RIPPER, J48 and Nearest Neighbour classifier by using several measures, including AUC and probability of detection. The experimental results indicate that the prediction performance of G-CARM approach is better than other prediction approaches. The authors' approach achieved 76% mean recall and 83% mean precision for defective modules and 93% mean recall and 83% mean precision for non-defective modules on CM1, KC1, KC2 and Eclipse data sets. Further defect rule generation process often generates a large number of rules which require considerable efforts while using these rules as a defect predictor, hence, a rule sub-set selection process is also proposed to select best set of rules according to the requirements. Evolution criteria for defect prediction like sensitivity, specificity, precision often compete against each other. It is therefore, important to use multi-objective optimization algorithms for selecting prediction rules. In this paper the authors report prediction rules that are Pareto efficient in the sense that no further improvements in the rule set is possible without sacrificing some performance criteria. Non-Dominated Sorting Genetic Algorithm has been used to find Pareto front and defect prediction rules.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = apr,
pages = {1–29},
numpages = {29},
keywords = {Pareto Optimality, General Unary Hypothesis Automaton GUHA, Fault Prediction, Defect Patterns, Data Mining}
}

@article{10.1504/ijcsm.2021.117600,
author = {Hammad, Mustafa},
title = {Classifying defective software projects based on machine learning and complexity metrics},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2021.117600},
doi = {10.1504/ijcsm.2021.117600},
abstract = {Software defects can lead to software failures or errors at any time. Therefore, software developers and engineers spend a lot of time and effort in order to find possible defects. This paper proposes an automatic approach to predict software defects based on machine learning algorithms. A set of complexity measures values are used to train the classifier. Three public datasets were used to evaluate the ability of mining complexity measures for different software projects to predict possible defects. Experimental results showed that it is possible to min software complexity to build a defect prediction model with a high accuracy rate.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {401–412},
numpages = {11},
keywords = {support vector machine, SVM, decision trees, na\"{\i}ve Bayes, neural networks, complexity, machine learning, software metrics, defect prediction, software defects}
}

@article{10.1007/s10796-013-9430-0,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Napolitano, Amri and Wald, Randall},
title = {A comparative study of iterative and non-iterative feature selection techniques for software defect prediction},
year = {2014},
issue_date = {November  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-013-9430-0},
doi = {10.1007/s10796-013-9430-0},
abstract = {Two important problems which can affect the performance of classification models are high-dimensionality (an overabundance of independent features in the dataset) and imbalanced data (a skewed class distribution which creates at least one class with many fewer instances than other classes). To resolve these problems concurrently, we propose an iterative feature selection approach, which repeated applies data sampling (in order to address class imbalance) followed by feature selection (in order to address high-dimensionality), and finally we perform an aggregation step which combines the ranked feature lists from the separate iterations of sampling. This approach is designed to find a ranked feature list which is particularly effective on the more balanced dataset resulting from sampling while minimizing the risk of losing data through the sampling step and missing important features. To demonstrate this technique, we employ 18 different feature selection algorithms and Random Undersampling with two post-sampling class distributions. We also investigate the use of sampling and feature selection without the iterative step (e.g., using the ranked list from a single iteration, rather than combining the lists from multiple iterations), and compare these results from the version which uses iteration. Our study is carried out using three groups of datasets with different levels of class balance, all of which were collected from a real-world software system. All of our experiments use four different learners and one feature subset size. We find that our proposed iterative feature selection approach outperforms the non-iterative approach.},
journal = {Information Systems Frontiers},
month = nov,
pages = {801–822},
numpages = {22},
keywords = {Software defect prediction, Iterative feature selection, High dimensionality, Date sampling, Class imbalance}
}

@article{10.1109/TSE.2017.2731766,
author = {Bennin, Kwabena Ebo and Keung, Jacky and Phannachitta, Passakorn and Monden, Akito and Mensah, Solomon},
title = {MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction},
year = {2018},
issue_date = {June 2018},
publisher = {IEEE Press},
volume = {44},
number = {6},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2017.2731766},
doi = {10.1109/TSE.2017.2731766},
abstract = {Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant &lt;italic&gt;pf&lt;/italic&gt; values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.},
journal = {IEEE Trans. Softw. Eng.},
month = jun,
pages = {534–550},
numpages = {17}
}

@article{10.1016/j.cose.2021.102459,
author = {Zhao, Jinxiong and Guo, Sensen and Mu, Dejun},
title = {DouBiGRU-A: Software defect detection algorithm based on attention mechanism and double BiGRU},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {111},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102459},
doi = {10.1016/j.cose.2021.102459},
journal = {Comput. Secur.},
month = dec,
numpages = {10},
keywords = {Flawfinder, RATS, Vulnerability identification, Software defect detection, DouBiGRU-A}
}

@inproceedings{10.1145/3379597.3387461,
author = {Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David},
title = {A Machine Learning Approach for Vulnerability Curation},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387461},
doi = {10.1145/3379597.3387461},
abstract = {Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {32–42},
numpages = {11},
keywords = {self-training, open-source software, machine learning, classifiers ensemble, application security},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@article{10.1145/3437479.3437485,
author = {Yoo, Shin and Aleti, Aldeida and Turhan, Burak and Minku, Leandro L. and Miranskyy, Andriy and Meri\c{c}li, \c{C}etin},
title = {The 8th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3437479.3437485},
doi = {10.1145/3437479.3437485},
abstract = {The International Workshop on Realizing Arti cial Intelligence Synergies in Software Engineering (RAISE) aims to present the state of the art in the crossover between Software Engineering and Arti cial Intelligence. This workshop explored not only the appli- cation of AI techniques to SE problems but also the application of SE techniques to AI problems. Software has become critical for realizing functions central to our society. For example, software is essential for nancial and transport systems, energy generation and distribution systems, and safety-critical medical applications. Software development costs trillions of dollars each year yet, still, many of our software engineering methods remain mostly man- ual. If we can improve software production by smarter AI-based methods, even by small margins, then this would improve a crit- ical component of the international infrastructure, while freeing up tens of billions of dollars for other tasks.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {23–24},
numpages = {2}
}

@article{10.1155/2021/9976306,
author = {Wang, Wei and Wu, Wenqing},
title = {Using Machine Learning Algorithms to Recognize Shuttlecock Movements},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/9976306},
doi = {10.1155/2021/9976306},
abstract = {Shuttlecock is an excellent traditional national sport in China. Because of its simplicity, convenience, and fun, it is loved by the broad masses of people, especially teenagers and children. The development of shuttlecock sports into a confrontational event is not long, and it takes a period of research to master the tactics and strategies of shuttlecock sports. Based on this, this article proposes the use of machine learning algorithms to recognize the movement of shuttlecock movements, aiming to provide more theoretical and technical support for shuttlecock competitions by identifying features through actions with the assistance of technical algorithms. This paper uses literature research methods, model methods, comparative analysis methods, and other methods to deeply study the motion characteristics of shuttlecock motion, the key algorithms of machine learning algorithms, and other theories and construct the shuttlecock motion recognition based on multiview clustering algorithm. The model analyzes the robustness and accuracy of the machine learning algorithm and other algorithms, such as a variety of performance comparisons, and the results of the shuttlecock motion recognition image. For the key movements of shuttlecock movement, disk, stretch, hook, wipe, knock, and abduction, the algorithm proposed in this paper has a good movement recognition rate, which can reach 91.2%. Although several similar actions can be recognized well, the average recognition accuracy rate can exceed 75%, and even through continuous image capture, the number of occurrences of the action can be automatically analyzed, which is beneficial to athletes. And the coach can better analyze tactics and research strategies.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {13}
}

@inproceedings{10.1145/2351676.2351734,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {Software defect prediction using semi-supervised learning with dimension reduction},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351734},
doi = {10.1145/2351676.2351734},
abstract = {Accurate detection of fault prone modules offers the path to high quality software products while minimizing non essential assurance expenditures. This type of quality modeling requires the availability of software modules with known fault content developed in similar environment. Establishing whether a module contains a fault or not can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics. Our results show that the semi-supervised learning algorithm with dimension-reduction preforms significantly better than one of the best performing supervised learning algorithms, random forest, in situations when few modules with known fault content are available for training.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {314–317},
numpages = {4},
keywords = {software metrics, semi-supervised learning, dimension reduction, Software fault prediction},
location = {Essen, Germany},
series = {ASE '12}
}

@article{10.1016/j.scico.2021.102713,
author = {Jain, Shivani and Saha, Anju},
title = {Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {212},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2021.102713},
doi = {10.1016/j.scico.2021.102713},
journal = {Sci. Comput. Program.},
month = dec,
numpages = {34},
keywords = {Stacking, Hybrid feature selection, Ensemble machine learning, Machine learning, Code smell}
}

@article{10.1016/j.future.2019.09.009,
author = {Lopes, F\'{a}bio and Agnelo, Jo\~{a}o and Teixeira, C\'{e}sar A. and Laranjeiro, Nuno and Bernardino, Jorge},
title = {Automating orthogonal defect classification using machine learning algorithms},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.09.009},
doi = {10.1016/j.future.2019.09.009},
journal = {Future Gener. Comput. Syst.},
month = jan,
pages = {932–947},
numpages = {16},
keywords = {Text classification, Machine learning, Orthogonal defect classification, Bug reports, Software defects}
}

@article{10.1016/j.jss.2021.111031,
author = {Giray, G\"{o}rkem},
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111031},
doi = {10.1016/j.jss.2021.111031},
journal = {J. Syst. Softw.},
month = oct,
numpages = {35},
keywords = {Systematic literature review, Deep learning, Machine learning, Software process, Software development, Software engineering}
}

@article{10.3233/KES-170355,
author = {Yang, Yang-Rui and Wang, He-Chuang and Xin, Yan-Hui},
title = {Grey relational analysis model software quality assessment with triangular fuzzy information},
year = {2017},
issue_date = {2017},
publisher = {IOS Press},
address = {NLD},
volume = {21},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-170355},
doi = {10.3233/KES-170355},
abstract = {With the rapid development and the increasingly
widespread application of information technology, the software becomes more
and more important. Also, because of the increasing size and the complexity
of software, the software quality has become difficult to control and
manage. Improving the quality of software has become the focus of software
industry. Software quality assurance becomes an important approach for
improving software quality, which provides developers and managers with the
information reflecting the product quality through monitoring the execution
of software producing task by independent review. In this paper, we
investigate the multiple attribute decision making (MADM) problems
for evaluating the software quality with triangular fuzzy information. Then,
we extend the grey relational analysis (GRA) procedure for triangular fuzzy
multiple attribute decision making for evaluating marine service industry in
triangular fuzzy setting. According to the concept of the GRA, a fuzzy
relative relational degree is defined to determine the ranking order of all
alternatives by calculating the degree of fuzzy grey relational coefficient
to both the triangular fuzzy positive-ideal solution (TFPIS) and triangular
fuzzy negative-ideal solution (TFNIS) simultaneously. Finally, an
illustrative example for evaluating the software quality is given to verify
the developed approach and to demonstrate its practicality and
effectiveness.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {97–102},
numpages = {6},
keywords = {software quality, grey relational analysis (GRA), triangular fuzzy information, Multiple attribute decision-making (MADM)}
}

@inproceedings{10.1109/ICMLA.2014.63,
author = {Coelho, Rodrigo A. and Guimar\~{a}es, Fabr\'{\i}cio dos R. N. and Esmin, Ahmed A. A.},
title = {Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics},
year = {2014},
isbn = {9781479974153},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2014.63},
doi = {10.1109/ICMLA.2014.63},
abstract = {Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the prediction quality. An empirical study shows that the PSO can be a good choice to build defect prediction software models.},
booktitle = {Proceedings of the 2014 13th International Conference on Machine Learning and Applications},
pages = {356–361},
numpages = {6},
keywords = {Software defect prediction, Particle swarm optimization, Ensemble clustering, Cluster data},
series = {ICMLA '14}
}

@inproceedings{10.1145/2961111.2962620,
author = {Shippey, Thomas and Hall, Tracy and Counsell, Steve and Bowes, David},
title = {So You Need More Method Level Datasets for Your Software Defect Prediction? Voil\`{a}!},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962620},
doi = {10.1145/2961111.2962620},
abstract = {Context: Defect prediction research is based on a small number of defect datasets and most are at class not method level. Consequently our knowledge of defects is limited. Identifying defect datasets for prediction is not easy and extracting quality data from identified datasets is even more difficult. Goal: Identify open source Java systems suitable for defect prediction and extract high quality fault data from these datasets. Method: We used the Boa to identify candidate open source systems. We reduce 50,000 potential candidates down to 23 suitable for defect prediction using a selection criteria based on the system's software repository and its defect tracking system. We use an enhanced SZZ algorithm to extract fault information and calculate metrics using JHawk. Result: We have produced 138 fault and metrics datasets for the 23 identified systems. We make these datasets (the ELFF datasets) and our data extraction tools freely available to future researchers. Conclusions: The data we provide enables future studies to proceed with minimal effort. Our datasets significantly increase the pool of systems currently being used in defect analysis studies.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {12},
numpages = {6},
keywords = {Defects, Defect linking, Defect Prediction, Data Mining, Boa},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.4018/IJITSA.2021010104,
author = {Shatnawi, Raed and Mishra, Alok},
title = {An Empirical Study on Software Fault Prediction Using Product and Process Metrics},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {14},
number = {1},
issn = {1935-570X},
url = {https://doi.org/10.4018/IJITSA.2021010104},
doi = {10.4018/IJITSA.2021010104},
abstract = {Product and process metrics are measured from the development and evolution of software. Metrics are indicators of software fault-proneness and advanced models using machine learning can be provided to the development team to select modules for further inspection. Most fault-proneness classifiers were built from product metrics. However, the inclusion of process metrics adds evolution as a factor to software quality. In this work, the authors propose a process metric measured from the evolution of software to predict fault-proneness in software models. The process metrics measures change-proneness of modules (classes and interfaces). Classifiers are trained and tested for five large open-source systems. Classifiers were built using product metrics alone and using a combination of product and the proposed process metric. The classifiers evaluation shows improvements whenever the process metrics were used. Evolution metrics are correlated with quality of software and helps in improving software quality prediction for future releases.},
journal = {Int. J. Inf. Technol. Syst. Appoach},
month = jan,
pages = {62–78},
numpages = {17},
keywords = {Software Fault, Product Metrics, Process Metrics, CK Metrics}
}

@inproceedings{10.1145/3425269.3425276,
author = {Silva, Publio and Bezerra, Carla I. M. and Lima, Rafael and Machado, Ivan},
title = {Classifying Feature Models Maintainability based on Machine Learning Algorithms},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425276},
doi = {10.1145/3425269.3425276},
abstract = {Maintenance in the context of SPLs is a topic of interest, and that still needs further investigation. There are several ways to evaluate the maintainability of a feature model (FM), one of which is a manual or automated analysis of quality measures. However, the use of measures does not allow to evaluate the FM quality as a whole, as each measure considers a specific characteristic of FM. In general, the measures have wide ranges of values and do not have a clear definition of what is appropriate and inappropriate. In this context, the goal of this work is to investigate the use of machine learning techniques to classify the feature model maintainability. The research questions investigated in the study were: (i) how could machine learning techniques aid to classify FMs maintainability; and, (ii) which FM classification model has the best accuracy and precision. In this work, we proposed an approach for FM maintainability classification using machine learning technics. For that, we used a dataset of 15 FM maintainability measures calculated for 326 FMs, and we used machine learning algorithms to clustering. After this, we used thresholds to evaluate the general maintainability of each cluster. With this, we built 5 maintainability classification models that have been evaluated with the accuracy and precision metrics.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {software product line, quality evaluation, machine learning, feature model},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@article{10.1155/2021/1057371,
author = {Yang, Yinghui and cheikhrouhou, omar},
title = {The Potential Energy of Artificial Intelligence Technology in University Education Reform from the Perspective of Communication Science},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/1057371},
doi = {10.1155/2021/1057371},
abstract = {In today’s rapid development of science and technology, science is everywhere in people’s lives, and science communication is everywhere. Science and communication are not only not far away but also very close. Since machine learning algorithms with deep learning as a theme have achieved great success in the fields of vision and speech recognition, as well as the large amount of data resources that cloud computing, big data, and other technologies can provide, the development speed of artificial intelligence has been greatly improved, and it has had a significant impact in various industries in the society, and the country has put forward the concept of intelligent education for this purpose. However, there have been few systematic discussions on the combination of artificial intelligence with education and teaching. Therefore, this article uses artificial intelligence technology to study the potential energy space of artificial intelligence technology in college education reform from the perspective of science communication, designs and implements an online education platform for colleges and universities, and conducts a trial of platform use in a domestic college and universities. Some teachers and students conduct a satisfaction survey after the platform is used, and the conclusions show that whether in the teacher group or the student group, most teachers and students are relatively satisfied with the online education platform designed in this article. The reform of college education includes many aspects. This article is a research study on the form of college education, changing from traditional offline education to online platform education. This research can provide a certain reference for the reform of college education.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {7}
}

@article{10.1016/j.inffus.2018.10.005,
author = {Diez-Olivan, Alberto and Del Ser, Javier and Galar, Diego and Sierra, Basilio},
title = {Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.10.005},
doi = {10.1016/j.inffus.2018.10.005},
journal = {Inf. Fusion},
month = oct,
pages = {92–111},
numpages = {20},
keywords = {VCM, SVMs, SOM-MQE, SBM, SARMA, RNN, RBM, PoF, PCA, LOF, LAD, KDE, kNN, HMM, GRNN, GRBMs, GMM, FPCA, FFT, EWMA, EM, DWT, DBN, BPNN, ANNs, ANFIS, Industry 4.0, Machine learning, Data fusion, Data-driven prognosis}
}

@inproceedings{10.1145/3396743.3396778,
author = {Natsupakpong, Suriya and Nithisopa, Nahpat},
title = {Lens Quality Inspection using Image Processing and Machine Learning},
year = {2020},
isbn = {9781450377065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396743.3396778},
doi = {10.1145/3396743.3396778},
abstract = {This research proposes a system to inspect defective lenses with a polarization technique by using image processing and machine learning. Currently, a skilled operator checks the lens quality with the polarization method by eye and decides whether or not a lens is good (OK) or not good (NG). A 'not good' lens has a circle or a line appearing in the stress pattern of the lens. This research designs and develops a lens quality checking system with machine learning by simulating and prototyping a machine to experiment and collect persistent data, using the camera to capture and analyze images with image processing and machine learning techniques to decide on the lens quality in the computer. The experimental results show that the proposed system with a trained model with data augmentation and image preprocessing can achieve performance testing with 97.75% accuracy.},
booktitle = {Proceedings of the 2020 2nd International Conference on Management Science and Industrial Engineering},
pages = {184–188},
numpages = {5},
keywords = {polarization, machine learning, lens quality inspection, image processing},
location = {Osaka, Japan},
series = {MSIE '20}
}

@article{10.1155/2021/2565500,
author = {Zheng, Danyang and Li, Liming and Zheng, Shubin and Chai, Xiaodong and Zhao, Shuguang and Tong, Qianqian and Wang, Ji and Guo, Lizheng and Zhang, Nian},
title = {A Defect Detection Method for Rail Surface and Fasteners Based on Deep Convolutional Neural Network},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/2565500},
doi = {10.1155/2021/2565500},
abstract = {As a result of long-term pressure from train operations and direct exposure to the natural environment, rails, fasteners, and other components of railway track lines inevitably produce defects, which have a direct impact on the safety of train operations. In this study, a multiobject detection method based on deep convolutional neural network that can achieve nondestructive detection of rail surface and fastener defects is proposed. First, rails and fasteners on the railway track image are localized by the improved YOLOv5 framework. Then, the defect detection model based on Mask R-CNN is utilized to detect the surface defects of the rail and segment the defect area. Finally, the model based on ResNet framework is used to classify the state of the fasteners. To verify the robustness and effectiveness of our proposed method, we conduct experimental tests using the ballast and ballastless railway track images collected from Shijiazhuang-Taiyuan high-speed railway line. Through a variety of evaluation indexes to compare with other methods using deep learning algorithms, experimental results show that our method outperforms others in all stages and enables effective detection of rail surface and fasteners.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {15}
}

@inproceedings{10.1109/ASE.2009.16,
author = {Lauenroth, Kim and Pohl, Klaus and Toehning, Simon},
title = {Model Checking of Domain Artifacts in Product Line Engineering},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.16},
doi = {10.1109/ASE.2009.16},
abstract = {In product line engineering individual products are derived from the domain artifacts of the product line. The reuse of the domain artifacts is constraint by the product line variability. Since domain artifacts are reused in several products, product line engineering benefits from the verification of domain artifacts. For verifying development artifacts, model checking is a well-established technique in single system development. However, existing model checking approaches do not incorporate the product line variability and are hence of limited use for verifying domain artifacts. In this paper we present an extended model checking approach which takes the product line variability into account when verifying domain artifacts. Our approach is thus able to verify that every permissible product (specified with I/O-automata) which can be derived from the product line fulfills the specified properties (specified with CTL). Moreover, we use two examples to validate the applicability of our approach and report on the preliminary validation results.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {269–280},
numpages = {12},
keywords = {Variability, Product Line Engineering, Model Checking, Domain Artifact Verification},
series = {ASE '09}
}

@article{10.1007/s10766-021-00707-0,
author = {\"{O}z, I\c{s}\i{}l and Arslan, Sanem},
title = {Predicting the Soft Error Vulnerability of Parallel Applications Using Machine Learning},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-021-00707-0},
doi = {10.1007/s10766-021-00707-0},
abstract = {With the widespread use of the multicore systems having smaller transistor sizes, soft errors become an important issue for parallel program execution. Fault injection is a prevalent method to quantify the soft error rates of the applications. However, it is very time consuming to perform detailed fault injection experiments. Therefore, prediction-based techniques have been proposed to evaluate the soft error vulnerability in a faster way. In this work, we present a soft error vulnerability prediction approach for parallel applications using machine learning algorithms. We define a set of features including thread communication, data sharing, parallel programming, and performance characteristics; and train our models based on three ML algorithms. This study uses the parallel programming features, as well as the combination of all features for the first time in vulnerability prediction of parallel programs. We propose two models for the soft error vulnerability prediction: (1) A regression model with rigorous feature selection analysis that estimates correct execution rates, (2) A novel classification model that predicts the vulnerability level of the target programs. We get maximum prediction accuracy rate of 73.2% for the regression-based model, and achieve 89% F-score for our classification model.},
journal = {Int. J. Parallel Program.},
month = jun,
pages = {410–439},
numpages = {30},
keywords = {Machine Learning, Parallel programming, Fault injection, Soft error analysis}
}

@inproceedings{10.1007/978-3-030-69449-4_14,
author = {J\"{o}chl, Robert and Uhl, Andreas},
title = {A Machine Learning Approach to Approximate the Age of a Digital Image},
year = {2020},
isbn = {978-3-030-69448-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-69449-4_14},
doi = {10.1007/978-3-030-69449-4_14},
abstract = {In-field image sensor defects develop almost continually over a camera’s lifetime. Since these defects accumulate over time, a forensic analyst can approximate the age of an image under investigation based on the defects present. In this context, the temporal accuracy of the approximation is bounded by the different defect onset times. Thus, the approximation of the image age based on in-field sensor defects can be regarded as a multi-class classification problem. In this paper, we propose to utilize two well-known machine learning techniques (i.e. a Naive Bayes Classifier and a Support Vector Machine) to solve this problem. The accuracy of each technique is empirically evaluated by conducting several experiments, and the results are compared to the current state-of-the art in this field. In addition, the prediction results are assessed individually for each class.},
booktitle = {Digital Forensics and Watermarking: 19th International Workshop, IWDW 2020, Melbourne, VIC, Australia, November 25–27, 2020, Revised Selected Papers},
pages = {181–195},
numpages = {15},
keywords = {Machine learning, Image age approximation, In-field sensor defects, Digital image forensics},
location = {Melbourne, VIC, Australia}
}

@article{10.1007/s00521-021-05892-0,
author = {Rajakumar, M. P. and Ramya, J. and Maheswari, B. Uma},
title = {Health monitoring and fault prediction using a lightweight deep convolutional neural network optimized by Levy flight optimization algorithm},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {19},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05892-0},
doi = {10.1007/s00521-021-05892-0},
abstract = {Agricultural machines (AMs) refer to equipment usually used in agriculture such as tractors, hand tools, and power tools. It reduces the labor work, increases farms produce, enhances goods quality, and reduces farming time and cost-saving. However, the faults in the fuel system, blades, engine of the AM will often result in degraded vehicle performance, compromising the vehicle’s efficiency and strength. To overcome these problems, fault detection algorithms are developed to identify the faults even before they occur with high classification accuracy. The deep convolutional neural network (DCNN) is a popular deep learning model that offers a high classification recognition rate, and it is widely adopted in similar fields for monitoring the health status of machines. Very few state-of-the-art works are available to identify the health state of agricultural machines using deep learning techniques and extracting the acoustic features from an audio recording. The acoustic signal-based agricultural machine health monitoring and fault prediction model using smartphones is a cost-effective option that is deployed in this proposed work. To optimize the network structure of the DCNN, this paper proposes a Levy flight optimization algorithm (LFOA). The DCNN-LFOA model is implemented on the smartphone’s on-board device (OBD) along with the health monitoring application. The LFOA algorithm minimizes the number of neurons in the DCNN hidden layer and the number of input features from the audio recordings and enhances the classification accuracy. The LFOA algorithm provides the optimal solution which is essential in developing a lightweight DCNN model to implement in the edge processor (smartphone). The experimental results prove that the proposed model gives improved accuracy for the six faults to be classified and serves as a new research model to identify the health condition of the vehicles.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {12513–12534},
numpages = {22},
keywords = {Short-term audio signals, Fault detection, Levy flight optimization algorithm, Convolutional neural network, Agricultural vehicles}
}

@article{10.1016/j.mejo.2021.105198,
author = {Abazyan, Suren and Melikyan, Vazgen},
title = {Enhanced pin-access prediction and design optimization with machine learning integration},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {116},
number = {C},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2021.105198},
doi = {10.1016/j.mejo.2021.105198},
journal = {Microelectron. J.},
month = oct,
numpages = {5},
keywords = {Prediction and optimization, Machine learning, Pin access}
}

@inproceedings{10.1145/2491411.2494581,
author = {Zhang, Hongyu and Cheung, S. C.},
title = {A cost-effectiveness criterion for applying software defect prediction models},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2494581},
doi = {10.1145/2491411.2494581},
abstract = {Ideally, software defect prediction models should help organize software quality assurance (SQA) resources and reduce cost of finding defects by allowing the modules most likely to contain defects to be inspected first. In this paper, we study the cost-effectiveness of applying defect prediction models in SQA and propose a basic cost-effectiveness criterion. The criterion implies that defect prediction models should be applied with caution. We also propose a new metric FN/(FN+TN) to measure the cost-effectiveness of a defect prediction model.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {643–646},
numpages = {4},
keywords = {evaluation metrics, cost effectiveness, Defect prediction},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1016/j.asoc.2016.08.025,
author = {Erturk, Ezgi and Akcapinar Sezer, Ebru},
title = {Iterative software fault prediction with a hybrid approach},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.025},
doi = {10.1016/j.asoc.2016.08.025},
abstract = {Display Omitted To make software fault prediction (SFP) more beneficial, it should be into service at the beginning of the project.A novel prediction methodology based on existing methods (i.e. FIS, ANN) are proposed here.Version based development of software projects are considered to design an iterative prediction approach.Proposed methodology is developed as Eclipse plugin.Experiments show that proposed methodology gives promising results to use SFP in daily routine of software development phases. In this study, we consider a software fault prediction task that can assist a developer during the lifetime of a project. We aim to improve the performance of software fault prediction task while keeping it as applicable. Initial predictions are constructed by Fuzzy Inference Systems (FISs), whereas subsequent predictions are performed by data-driven methods. In this paper, an Artificial Neural Network and Adaptive Neuro Fuzzy Inference System are employed. We propose an iterative prediction model that begins with a FIS when no data are available for the software project and continues with a data-driven method when adequate data become available. To prove the usability of this iterative prediction approach, software fault prediction experiments are performed using expert knowledge for the initial version and information about previous versions for subsequent versions. The datasets employed in this paper comprise different versions of Ant, jEdit, Camel, Xalan, Log4j and Lucene projects from the PROMISE repository. The metrics of the models are common object-oriented metrics, such as coupling between objects, weighted methods per class and response for a class. The results of the models are evaluated according to the receiver operating characteristics with the area under the curve approach. The results indicate that the iterative software fault prediction is successful and can be transformed into a tool that can automatically locate fault-prone modules due to its well-organized information flow. We also implement the proposed methodology as a plugin for the Eclipse environment.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1020–1033},
numpages = {14},
keywords = {Software fault prediction, Iterative prediction, Fuzzy inference systems, Artificial neural network, Adaptive neuro fuzzy inference system}
}

@inproceedings{10.1145/3331453.3360965,
author = {Chen, Shouhong and Kang, Huaiqiang and Ma, Jun and Guo, Ling and Hou, Xingna},
title = {Research on TSV Void Defects Based on Machine Learning},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331453.3360965},
doi = {10.1145/3331453.3360965},
abstract = {With the rapid development of 3D TSV (through silicon via) technology, it is particularly important to improve the yield for TSV fault detection. Aiming at TSV void defects, the paper adopts supervised machine learning method to train S parameters in TSV model with void faults, and carries out classification processing, then predicts the size of void faults through stimulus signal and S parameters. The results show that for spherical void defects detection, the classification accuracy of ELM (Extreme Learning Machine) algorithm and KNN (K-Nearest Neighbor) algorithm is above 85%, while for TSV cylindrical void defects detection, the classification accuracy of ELM algorithm is 96%.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {75},
numpages = {4},
keywords = {TSV fault detection, Machine learning, Classification algorithm},
location = {Sanya, China},
series = {CSAE '19}
}

@article{10.5555/3057337.3057441,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A decision tree logic based recommendation system to select software fault prediction techniques},
year = {2017},
issue_date = {March     2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {3},
issn = {0010-485X},
abstract = {Identifying a reliable fault prediction technique is the key requirement for building effective fault prediction model. It has been found that the performance of fault prediction techniques is highly dependent on the characteristics of the fault dataset. To mitigate this issue, researchers have evaluated and compared a plethora of fault prediction techniques by varying the context in terms of domain information, characteristics of input data, complexity, etc. However, the lack of an accepted benchmark makes it difficult to select fault prediction technique for a particular context of prediction. In this paper, we present a recommendation system that facilitates the selection of appropriate technique(s) to build fault prediction model. First, we have reviewed the literature to elicit the various characteristics of the fault dataset and the appropriateness of the machine learning and statistical techniques for the identified characteristics. Subsequently, we have formalized our findings and built a recommendation system that helps in the selection of fault prediction techniques. We performed an initial appraisal of our presented system and found that proposed recommendation system provides useful hints in the selection of the fault prediction techniques.},
journal = {Computing},
month = mar,
pages = {255–285},
numpages = {31},
keywords = {verification, requirements, metrics, etc.), Software fault prediction techniques, Software fault prediction, Recommendation system, Decision tree, 68N30 Mathematical aspects of software engineering (specification}
}

@article{10.1155/2021/2021344,
author = {Luo, Long and Ma, Rukuo and Li, Yuan and Yang, Fangnan and Qiu, Zhanfei and Ding, Bai Yuan},
title = {Image Recognition Technology with Its Application in Defect Detection and Diagnosis Analysis of Substation Equipment},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2021344},
doi = {10.1155/2021/2021344},
abstract = {Detection of substation equipment can promptly and effectively discover equipment overheating defects and prevent equipment failures. Traditional manual diagnosis methods are difficult to deal with the massive infrared images generated by the autonomous inspection of substation robots and drones. At present, most of the infrared image defect recognition is based on traditional machine learning algorithms, with low recognition accuracy and poor generalization capability. Therefore, this paper develops a method for identifying infrared defects of substation equipment based on the improvement of traditional ones. First, based on the Faster RCNN, target detection is performed on 6 types of substation equipment including bushings, insulators, wires, voltage transformers, lightning rods, and circuit breakers to achieve precise positioning of the equipment. Afterwards, different classes are identified based on the sparse representation-based classification (SRC), so the actual label of the input sample can be obtained. Finally, based on the temperature threshold discriminant algorithm, defects are identified in the equipment area. The measured infrared images are used for experiments. The average detection accuracy achieved by the proposed method for the 6 types of equipment reaches 92.34%. The recognition rate of different types of equipment is 98.57%, and the defect recognition accuracy reaches 88.75%. The experimental results show the effectiveness and accuracy of the proposed method.},
journal = {Sci. Program.},
month = jan,
numpages = {6}
}

@article{10.1007/s10515-020-00277-4,
author = {Esteves, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Understanding machine learning software defect predictions},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00277-4},
doi = {10.1007/s10515-020-00277-4},
abstract = {Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.},
journal = {Automated Software Engg.},
month = dec,
pages = {369–392},
numpages = {24},
keywords = {SHAP values, Jureczko datasets, Explainable models, Software defects}
}

@article{10.1016/j.engappai.2017.09.008,
author = {Wang, Hong-Qiao and Cai, Yan-Ning and Fu, Guang-Yuan and Wu, Ming and Wei, Zhen-Hua},
title = {Data-driven fault prediction and anomaly measurement for complex systems using support vector probability density estimation},
year = {2018},
issue_date = {January 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2017.09.008},
doi = {10.1016/j.engappai.2017.09.008},
abstract = {To quantitatively monitor the state of complex system, a data-driven fault prediction and anomaly degree measurement method based on probability density estimation is studied in this paper. First, an anomaly index is introduced and defined to measure the anomaly degree of samples. Then By improving the form of constraint condition, a single slack factor multiple kernel support vector machine probability density estimation model is presented. As a result, the scale of object function and the solution number are all reduced, and the computational efficiency of the presented model is greatly enhanced. On the other hand, as the introduction of multiple kernel functions, a multiple kernel matrix with better data mapping performance is obtained, which can well solve the composite probability density estimation for uncoupled data. The simulation test shows that the presented model has higher estimation precision and speed. The experiments on complex system fault prediction also show that the systems anomaly degree can be quantitatively and accurately measured by the anomaly index gained from the prediction results, which can effectively improve the fault prediction precision and increase the prediction advances.},
journal = {Eng. Appl. Artif. Intell.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {Support vector machine, Probability density estimation, Fault prediction, Data-driven, Anomaly degree measurement}
}

@article{10.1504/ijiids.2020.109457,
author = {Anwar, Khalid and Siddiqui, Jamshed and Sohail, Shahab Saquib},
title = {Machine learning-based book recommender system: a survey and new perspectives},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {2–4},
issn = {1751-5858},
url = {https://doi.org/10.1504/ijiids.2020.109457},
doi = {10.1504/ijiids.2020.109457},
abstract = {The exponential growth of recommender systems research has drawn the attention of the scientific community recently. These systems are very useful in reducing information overload and providing users with the items of their need. The major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. Book recommender systems suggest books of interest to users according to their preferences and requirements. In this article, we have surveyed machine learning techniques which have been used in book recommender systems. Moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. Six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. We have also proposed future perspectives to improve recommender system. We hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jan,
pages = {231–248},
numpages = {17},
keywords = {evaluation metrics, association rule mining, classification, machine learning, BRS, book recommender system}
}

@inproceedings{10.1109/QSIC.2012.19,
author = {Wang, Jun and Shen, Beijun and Chen, Yuting},
title = {Compressed C4.5 Models for Software Defect Prediction},
year = {2012},
isbn = {9780769548333},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2012.19},
doi = {10.1109/QSIC.2012.19},
abstract = {Defects in every software must be handled properly, and the number of defects directly reflects the quality of a software. In recent years, researchers have applied data mining and machine learning methods to predicting software defects. However, in their studies, the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper, aiming at the characteristics of the metrics mined from the open source software, we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models, an experimental scheme is designed. In the experiment, we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.},
booktitle = {Proceedings of the 2012 12th International Conference on Quality Software},
pages = {13–16},
numpages = {4},
keywords = {Software Repository, Defect Prediction, Decision Tree Learner, Data Mining},
series = {QSIC '12}
}

@article{10.3233/JIFS-210229,
author = {Narendiranath Babu, T. and Singh, Prabhu Pal and Somesh, M. and Jha, Harshit Kumar and Rama Prabha, D. and Venkatesan, S. and Ramesh Babu, V.},
title = {Vibration analysis of planetary gearbox using empirical mode decomposition and automatic fault prediction using artificial neural network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-210229},
doi = {10.3233/JIFS-210229},
abstract = {The planetary gearbox works on an epicyclic gear train consisting of sun gear meshed with planets gears and ring gear. It got advantages due to its large torque to weight ratio and reduced vibrations. It is mostly employed in analog clocks, automobile automatic gearbox, Lathe machines, and other heavy industries. Therefore, it was imperative to analyze the various faults occurring in a gearbox. Furthermore, come up with a method so that failures can be avoided at the early stage. It was also a reason why it became the field of intensive research. Moreover, the technology of neural networks emerged recently, where machine learning models are trained to detect uneven vibrations on their own. This attracted many researchers to perform the study to devise their own methods of prediction. The central concept of fault prediction by the neural network without human beings’ interference inspired this study. Most industries always wanted to know if their operation line is working fine or not. In this study, an attempt was made to apply the method of deep learning on one of the most critical gearboxes because of its components and functionality. A significant part of the study also involved filtering the vibration data obtained while testing. Comparative analysis of the variation of the peak of acceleration was performed for healthy and faulty conditions.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6407–6427},
numpages = {21},
keywords = {deep learning, neural networks, Planetary gearbox}
}

@article{10.1145/3450288,
author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
title = {A Systematic Literature Review on Federated Machine Learning: From a Software Engineering Perspective},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450288},
doi = {10.1145/3450288},
abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {95},
numpages = {39},
keywords = {systematic literature review, software engineering, privacy, edge learning, distributed learning, Federated learning}
}

@article{10.1016/j.inffus.2018.09.013,
author = {Praveen Kumar, D. and Amgoth, Tarachand and Annavarapu, Chandra Sekhara Rao},
title = {Machine learning algorithms for wireless sensor networks: A survey},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.09.013},
doi = {10.1016/j.inffus.2018.09.013},
journal = {Inf. Fusion},
month = sep,
pages = {1–25},
numpages = {25},
keywords = {Data aggregation, Network lifetime, Energy efficiency, Machine learning, Wireless sensor networks}
}

@article{10.1007/s11277-017-4361-6,
author = {Yue, Yinggao and Li, Jianqing and Fan, Hehong and Qin, Qin and Gu, Le and Du, Li},
title = {Fault Prediction Based on the Kernel Function for Ribbon Wireless Sensor Networks},
year = {2017},
issue_date = {Dec 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {97},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-4361-6},
doi = {10.1007/s11277-017-4361-6},
abstract = {There exist several applications of wireless sensor networks in which the reliable operation can be crucial. Fault prediction is a critical problem in reliability theory for ribbon wireless sensor networks (RWSNs). Accurate fault prediction can effectively improve the availability of the WSNs system. In this paper, we evaluated the network performance for RWSNs, studied the basic theory of kernel functions, proposed a new failure prediction method based on kernel function, and selected the radial basis function as kernel function failure prediction models from two aspects of node hardware failures and network failures for fault prediction. Theoretical evidence and experimental results have shown that the proposed algorithmic prediction method has higher accuracy of 12 and 15% than that of GRNN and PNN respectively. Finally, we provided extensive numerical results to demonstrate the usage and efficiency of the proposed algorithms and complement our theoretical analysis.},
journal = {Wirel. Pers. Commun.},
month = dec,
pages = {3277–3292},
numpages = {16},
keywords = {Ribbon wireless sensor networks, Reliability, Kernel function, Fault prediction}
}

@inproceedings{10.1109/CEC48606.2020.9185555,
author = {Brester, Christina and Niska, Harri and Ciszek, Robert and Kolehmainen, Mikko},
title = {Weather-based Fault Prediction in Electricity Networks with Artificial Neural Networks},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC48606.2020.9185555},
doi = {10.1109/CEC48606.2020.9185555},
abstract = {Predicting weather-related outages in electricity networks is an important issue for distribution system operators. In this study, we apply a data-driven approach and train artificial neural networks to predict faults in the electricity network. In our experiments, we utilize the meteorological data and fault records collected for the period of1.1.2011-31.12.2013 in central Finland. Assuming that there might be long-term dependencies between weather conditions and faults in the network, we investigate simple recurrent neural networks, long short-term memory networks, and traditional multilayer perceptrons. Taking into account the meteorological observations preceding faults and varying this period from several hours to several days, we found that 6 hours prior to faults included the sufficient information to make accurate predictions. Also, there was no need in more complicated recurrent neural networks as multilayer perceptron was able to predict events with the large number of faults more accurately. Besides, while forecasting all types of faults and wind-related faults only, oversampling allowed the model to predict rare high peaks.},
booktitle = {2020 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@article{10.1007/s11042-020-09727-3,
author = {Jawahar, Malathy and Babu, N. K. Chandra and Vani, K. and Anbarasi, L. Jani and Geetha, S.},
title = {Vision based inspection system for leather surface defect detection using fast convergence particle swarm optimization ensemble classifier approach},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {3},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09727-3},
doi = {10.1007/s11042-020-09727-3},
abstract = {Surface defect inspection plays a vital role in leather manufacturing. Current practice involves an expert to inspect each piece of leather individually and detect defects manually. However, such a manual inspection is highly subjective and varies quite considerably from one assorter to another. Computer vision system for natural material like leather is a challenging research problem. This study describes the application of computer vision system to capture leather surface images and use of a novel Fast Convergence Particle Swarm Optimization (FCPSO) algorithm on a set of handcrafted texture features viz., GLCM and classified using supervised classifiers viz., Multi Layer Perceptron (MLP), Decision Tree (DT), SVM, Na\"{\i}ve Bayes, K-Nearest Neighbors (KNN) and Random Forest (RF). FCPSO using modified fitness function by selective band Shannon entropy is implemented to segment industrial leather images. Segmentation efficiency of the proposed FCPSO algorithm is evaluated and its performance is compared with other optimization algorithms. Efficiency of the segmentation algorithms is evaluated using performance measures such as average difference (AD), Area Error Rate (AER), Edge-based structural similarity index (ESSIM), F-Score, Normalized correlation coefficient (NK), Overlap Error (OE), structural content (SC), Structural similarity index (SSIM) and Zijdenbos similarity index (ZSI). Correlation of the segmented area using FCPSO with the experts’ ground truth is found to be high with R value of 0.84. Feature extraction is carried out using GLCM texture features and the most prominent features were selected using statistical t-test and correlation coefficient. Experimental results showed encouraging results for random forest classifier confirming the potential of the proposed system for automatic leather defect classification.},
journal = {Multimedia Tools Appl.},
month = jan,
pages = {4203–4235},
numpages = {33},
keywords = {Ensemble classifier, Fast convergence particle swarm optimization, Leather surface defect detection, segmentation, Image analysis}
}

@inproceedings{10.1109/IECON.2019.8927370,
author = {Gao, Kai and Lyu, Lijun and Huang, Hua and Fu, ChenZhao and Chen, Fuchun and Jin, Lijun},
title = {Insulation Defect Detection of Electrical Equipment Based on Infrared and Ultraviolet Photoelectric Sensing Technology},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927370},
doi = {10.1109/IECON.2019.8927370},
abstract = {Insulation faults account for a high proportion in the faults of electrical equipment. Insulation defects or faults of electrical equipment may cause excessive temperature rise or partial discharge, which can be used as the criteria of insulation state of electrical equipment. However, the existing detection methods can't meet the requirements of safe and stable operation of modern substations. The exploration of new methods for temperature rise and partial discharge detection has become important for online detection of electrical equipment. Photoelectric sensor is a device that converts optical signal into electrical signal. It can be used to detect the optical signal generated by the running electrical equipment. The infrared photoelectric sensor can detect the temperature of electrical equipment, and the ultraviolet photoelectric sensor can detect the ultraviolet pulse signal generated by partial discharge of electrical equipment. In this paper, the characteristics of infrared photoelectric sensor's temperature changing with the detection distance are studied, and then the optimum detection distance is obtained. The relationship between the output pulse signal of ultraviolet photoelectric sensor and discharge intensity is analyzed, and the attenuation characteristics of pulse signal with the increase of propagation distance are also analyzed. The optimum placement position is selected. An insulation defect detection system for electrical equipment based on infrared and ultraviolet photoelectric sensing technology is constructed. Based on the adaptive fuzzy neural network, the insulation state of electrical equipment is synthetically judged by the signals of the infrared and ultraviolet photoelectric sensors. Experimental results show that through the combined detection of infrared and ultraviolet photoelectric sensors, and then information fusion diagnosis, it can effectively reduce the single sensor's misjudgment caused by one-sided information, and the accuracy of fault diagnosis is significantly improved.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {2184–2189},
numpages = {6},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3409501.3409543,
author = {Yan, Ziyue and Zong, Lu},
title = {Spatial Prediction of Housing Prices in Beijing Using Machine Learning Algorithms},
year = {2020},
isbn = {9781450375603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409501.3409543},
doi = {10.1145/3409501.3409543},
abstract = {The real estate industry places key influence on almost every aspect of social economy given its great financing capacity and prolonged upstream and downstream industry chain. Therefore, predicting housing prices is regarded as an emerging topic in the recent decades. Hedonic Regression and Machine Learning Algorithms are two main methods in this field. This study aims to explore the important explanatory features and determine an accurate mechanism to implement spatial prediction of housing prices in Beijing by incorporating a list of machine learning techniques, including XGBoost, linear regression, Random Forest Regression, Ridge and Lasso Model, bagging and boosting, based on the housing price and features data in Beijing, China. Our result shows that compared to traditional hedonic method, machine learning methods demonstrate significant improvements on the accuracy of estimation despite that they are more time-costly. Moreover, it is found that XGBoost is the most accurate model in explaining and prediciting the spatial dynamics of housing prices in Beijing.},
booktitle = {Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference &amp; 2020 3rd International Conference on Big Data and Artificial Intelligence},
pages = {64–71},
numpages = {8},
keywords = {Spatial Modeling, Prediction, Machine Learning Algorithms, Housing Price},
location = {Qingdao, China},
series = {HPCCT &amp; BDAI '20}
}

@inproceedings{10.1109/ICSE-C.2017.72,
author = {Wu, Fei and Jing, Xiao-Yuan and Dong, Xiwei and Cao, Jicheng and Xu, Mingwei and Zhang, Hongyu and Ying, Shi and Xu, Baowen},
title = {Cross-project and within-project semi-supervised software defect prediction problems study using a unified solution},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.72},
doi = {10.1109/ICSE-C.2017.72},
abstract = {When there exists not enough historical defect data for building accurate prediction model, semi-supervised defect prediction (SSDP) and cross-project defect prediction (CPDP) are two feasible solutions. Existing CPDP methods assume that the available source data is well labeled. However, due to expensive human efforts for labeling a large amount of defect data, usually, we can only make use of the suitable unlabeled source data to help build the prediction model. We call CPDP in this scenario as cross-project semi-supervised defect prediction (CSDP). As to within-project semi-supervised defect prediction (WSDP), although some WSDP methods have been developed in recent years, there still exists much room for improvement. In this paper, we aim to provide an effective solution for both CSDP and WSDP problems. We introduce the semi-supervised dictionary learning technique, an effective machine learning technique, into defect prediction and propose a semi-supervised structured dictionary learning (SSDL) approach for CSDP and WSDP. SSDL can make full use of the useful information in limited labeled defect data and a large amount of unlabeled data. Experiments on two public datasets indicate that SSDL can obtain better prediction performance than related SSDP methods in the CSDP scenario.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {195–197},
numpages = {3},
keywords = {within-project semi-supervised defect prediction, semi-supervised structured dictionary learning, cross-project semi-supervised defect prediction},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1109/ICMA.2018.8484328,
author = {Ge, Qingcai and Fang, Ming and Xu, Jing},
title = {Defect Detection of Industrial Products based on Improved Hough Transform},
year = {2018},
isbn = {978-1-5386-6074-4},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2018.8484328},
doi = {10.1109/ICMA.2018.8484328},
abstract = {In the industrial manufacturing process, defects of industrial products may inevitably occur. In order to detect the defects of industrial products with central symmetry distribution rules, this paper analyzes the limitations of traditional detection methods and proposes an improved detection method based on Hough transform. The method starts from the central area of the industrial product and performs directional clustering towards the direction in which the detection target is located: Firstly, obtain contour of the region of interest and the center point. Secondly, use Hough transform on the points on the contour of the Region Of Interest(ROI). Voting is performed according to the constraint rule that only passes through the direction of central area. The peak corresponding to the detected object is obtained in the voting space, and the defect of the industrial product component is obtained by estimating the peak position. Experimental results show that our algorithm has strong anti-interference ability and can solve the undetectable problems caused by the similarity between the detection target and the background. It can meet the requirements of certain types of industrial production and has significant robustness compared with the traditional Hough method.},
booktitle = {2018 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {832–836},
numpages = {5},
location = {Changchun, Jilin, China}
}

@article{10.1155/2021/6627588,
author = {Xie, Yuan and Zhao, Jisheng and Qiang, Baohua and Mi, Luzhong and Tang, Chenghua and Li, Longge and Xue, Xingsi},
title = {Attention Mechanism-Based CNN-LSTM Model for Wind Turbine Fault Prediction Using SSN Ontology Annotation},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/6627588},
doi = {10.1155/2021/6627588},
abstract = {The traditional model for wind turbine fault prediction is not sensitive to the time sequence data and cannot mine the deep connection between the time series data, resulting in poor generalization ability of the model. To solve this problem, this paper proposes an attention mechanism-based CNN-LSTM model. The semantic sensor data annotated by SSN ontology is used as input data. Firstly, CNN extracts features to get high-level feature representation from input data. Then, the latent time sequence connection of features in different time periods is learned by LSTM. Finally, the output of LSTM is input into the attention mechanism module to obtain more fault-related target information, which improves the efficiency, accuracy, and generalization ability of the model. In addition, in the data preprocessing stage, the random forest algorithm analyzes the feature correlation degree of the data to get the features of high correlation degree with the wind turbine fault, which further improves the efficiency, accuracy, and generalization ability of the model. The model is validated on the icing fault dataset of No. 21 wind turbine and the yaw dataset of No. 4 wind turbine. The experimental results show that the proposed model has better efficiency, accuracy, and generalization ability than RNN, LSTM, and XGBoost.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@article{10.1155/2021/4795396,
author = {Zhang, Bin and Fang, Shuqi and Li, Zhixi and Wang, Long},
title = {Research on Surface Defect Detection of Rare-Earth Magnetic Materials Based on Improved SSD},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/4795396},
doi = {10.1155/2021/4795396},
abstract = {In order to overcome the limitation of manual visual inspection of surface defects of rare-earth magnetic materials and increase production efficiency of traditional rare-earth enterprises, a detection method based on improved SSD (Single Shot Detector) is proposed. The SSD model is improved from two aspects for better performance in the detection of small defects. First of all, the multiscale receptive field module is embedded into the backbone network of the algorithm to improve the feature extraction ability of the model. Secondly, the interlayer feature fusion strategy of bidirectional feature pyramid in PANet (path aggregation network) is integrated into the model. In order to enhance the detection ability of the model, the high-level semantic information is strengthened by an efficient channel attention mechanism. The detection speed of the improved SSD algorithm is 55FPS, and the mAP (mean Average Precision) is up to 83.65%, which is 3.41% higher than of the original SSD algorithm, and the ability to identify small defects is significantly improved.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@article{10.1007/s10922-020-09512-5,
author = {Le, Duc C. and Zincir-Heywood, Nur},
title = {A Frontier: Dependable, Reliable and Secure Machine Learning for Network/System Management},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09512-5},
doi = {10.1007/s10922-020-09512-5},
abstract = {Modern networks and systems pose many challenges to traditional management approaches. Not only the number of devices and the volume of network traffic are increasing exponentially, but also new network protocols and technologies require new techniques and strategies for monitoring controlling and managing up and coming networks and systems. Moreover, machine learning has recently found its successful applications in many fields due to its capability to learn from data to automatically infer patterns for network analytics. Thus, the deployment of machine learning in network and system management has become imminent. This work provides a review of the applications of machine learning in network and system management. Based on this review, we aim to present the current opportunities and challenges in and highlight the need for dependable, reliable and secure machine learning for network and system management.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {827–849},
numpages = {23},
keywords = {Secure machine learning, Reliable and dependable machine learning, Network and system management}
}

@inproceedings{10.1109/WORDS.2005.32,
author = {Challagulla, Venkata U. B. and Bastani, Farokh B. and Yen, I-Ling and Paul, Raymond A.},
title = {Empirical Assessment of Machine Learning based Software Defect Prediction Techniques},
year = {2005},
isbn = {0769523471},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WORDS.2005.32},
doi = {10.1109/WORDS.2005.32},
abstract = {The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems will perform as specified and will not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models, such as Stepwise Multi-linear Regression models and multivariate models, and machine learning approaches, such as Artificial Neural Networks, Instance-based Reasoning, Bayesian-Belief Networks, Decision Trees, and Rule Inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper, we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of 1R and Instance-based Learning along with the Consistencybased Subset Evaluation technique provides relatively better consistency in accuracy prediction compared to other models. The results also show that "size" and "complexity" metrics are not sufficient for accurately predicting real-time software defects.},
booktitle = {Proceedings of the 10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems},
pages = {263–270},
numpages = {8},
series = {WORDS '05}
}

@inproceedings{10.1109/ASE.2019.00122,
author = {Li, Da and Wang, Huiyan and Xu, Chang and Zhang, Ruiqing and Cheung, Shing-Chi and Ma, Xiaoxing},
title = {SGUARD: a feature-based clustering tool for effective spreadsheet defect detection},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00122},
doi = {10.1109/ASE.2019.00122},
abstract = {Spreadsheets are widely used but subject to various defects. In this paper, we present SGUARD to effectively detect spreadsheet defects. SGUARD learns spreadsheet features to cluster cells with similar computational semantics, and then refines these clusters to recognize anomalous cells as defects. SGUARD well balances the trade-off between the precision (87.8%) and recall rate (71.9%) in the defect detection, and achieves an F-measure of 0.79, exceeding existing spreadsheet defect detection techniques. We introduce the SGUARD implementation and its usage by a video presentation (https://youtu.be/gNPmMvQVf5Q), and provide its public download repository (https://github.com/sheetguard/sguard).},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1142–1145},
numpages = {4},
keywords = {defect detection, cell clustering},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3318299.3318345,
author = {Li, ZhanJun and Shao, Yan},
title = {A Survey of Feature Selection for Vulnerability Prediction Using Feature-based Machine Learning},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318345},
doi = {10.1145/3318299.3318345},
abstract = {This paper summarized the basic process of software vulnerability prediction using feature-based machine learning for the first time. In addition to sorting out the related types and basis of vulnerability features definition, the advantages and disadvantages of different methods are compared. Finally, this paper analyzed the difficulties and challenges in this research field, and put forward some suggestions for future work.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {36–42},
numpages = {7},
keywords = {machine learning, feature, Software vulnerability prediction},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1007/s00521-020-05051-x,
author = {Yin, Xiangbao},
title = {Driven by machine learning to intelligent damage recognition of terminal optical components},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {2},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05051-x},
doi = {10.1007/s00521-020-05051-x},
abstract = {In order to realize the terminal optical element online detection system in the Shenguang III system, each optical element in each terminal optical component in the target room is detected. The research on the optical damage of terminal optical components focuses on the search for damage points, the extraction of damage information, and the classification of damage types. In addition, damage classification and identification of terminal optical components are performed through machine learning, and infrared nondestructive testing is used as technical support to improve the identification model and reduce the complexity of the spectral model. After studying the preprocessing and dimensionality reduction methods of near-infrared spectroscopy, this paper compares the effects of different preprocessing methods and screening feature methods and combines different modeling methods to conduct experiments. The research results show that the method proposed in this paper has certain effects.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {789–804},
numpages = {16},
keywords = {Infrared nondestructive testing, Damage identification, Terminal optics, Machine learning}
}

@inproceedings{10.1007/978-3-030-54407-2_17,
author = {Djavadifar, Abtin and Graham-Knight, John Brandon and Gupta, Kashish and K\"{o}rber, Marian and Lasserre, Patricia and Najjaran, Homayoun},
title = {Robot-Assisted Composite Manufacturing Based on Machine Learning Applied to Multi-view Computer Vision},
year = {2019},
isbn = {978-3-030-54406-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-54407-2_17},
doi = {10.1007/978-3-030-54407-2_17},
abstract = {This paper introduces an automated wrinkle detection method on semi-finished fiber products in the aerospace manufacturing industry. Machine learning, computer vision techniques, and evidential reasoning are combined to detect wrinkles during the draping process of fibre-reinforced materials with an industrial robot. A well-performing Deep Convolutional Neural Network (DCNN) was developed based on a preliminary, hand-labelled dataset captured on a functioning robotic system used in a composite manufacturing facility. Generalization of this model to different, unlearned wrinkle features naturally compromises detection accuracy. To alleviate this problem, the proposed method employs computer vision techniques and belief functions to enhance defect detection accuracy. Co-temporal views of the same fabric are extracted, and individual detection results obtained from the DCNN are fused using the Dempster-Shafer Theory (DST). By the application of the DST rule of combination, the overall wrinkle detection accuracy for the generalized case is greatly improved in this composite manufacturing facility.},
booktitle = {Smart Multimedia: Second International Conference, ICSM 2019, San Diego, CA, USA, December 16–18, 2019, Revised Selected Papers},
pages = {199–211},
numpages = {13},
keywords = {Classification, Data fusion, Belief functions, Deep neural network, Machine learning, Process automation, Wrinkle detection, Composite manufacturing, Computer vision},
location = {San Diego, CA, USA}
}

@article{10.1007/s10044-012-0305-7,
author = {Kim, Hye Won and Yoo, Suk I.},
title = {Defect detection using feature point matching for non-repetitive patterned images},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {2},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-012-0305-7},
doi = {10.1007/s10044-012-0305-7},
abstract = {Defect detection is an important technology for the quality control in the production process of wafer, TFT-LCD and PCB. Inspection is performed using the finished product's image. The images are classified into two different groups--images with a repetitive pattern on a regular cycle and images without a repetitive pattern. A standard object for comparison is required, because manual defect detection is not possible for areas without repetitive patterns. In such areas, defect detection occurs through contrasting a reference pattern to the pattern being inspected. Methods of inspection using reference image have been researched but have limitations due to their requirement of precise alignment of the images. This paper proposes a method of defect detection to overcome such limitation using feature point matching. Feature points are extracted using a corner detector and detects defect by finding a correspondence between two feature point sets. Performance of the proposed method is evaluated by using Wafer SEM images and compared with conventional methods. Experiment results demonstrate the proposed method achieves higher detection accuracy than conventional methods and is less sensitive to alignment error and noise.},
journal = {Pattern Anal. Appl.},
month = may,
pages = {415–429},
numpages = {15},
keywords = {Inspection, Feature point matching, Defect detection, Computer vision}
}

@inproceedings{10.1007/978-3-030-33607-3_12,
author = {Shepperd, Martin and Guo, Yuchen and Li, Ning and Arzoky, Mahir and Capiluppi, Andrea and Counsell, Steve and Destefanis, Giuseppe and Swift, Stephen and Tucker, Allan and Yousefi, Leila},
title = {The Prevalence of Errors in Machine Learning Experiments},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_12},
doi = {10.1007/978-3-030-33607-3_12},
abstract = {Context: Conducting experiments is central to research machine learning research to benchmark, evaluate and compare learning algorithms. Consequently it is important we conduct reliable, trustworthy experiments.Objective: We investigate the incidence of errors in a sample of machine learning experiments in the domain of software defect prediction. Our focus is simple arithmetical and statistical errors.Method: We analyse 49 papers describing 2456 individual experimental results from a previously undertaken systematic review comparing supervised and unsupervised defect prediction classifiers. We extract the confusion matrices and test for relevant constraints, e.g., the marginal probabilities must sum to one. We also check for multiple statistical significance testing errors.Results: We find that a total of 22 out of 49 papers contain demonstrable errors. Of these 7 were statistical and 16 related to confusion matrix inconsistency (one paper contained both classes of error).Conclusions: Whilst some errors may be of a relatively trivial nature, e.g., transcription errors their presence does not engender confidence. We strongly urge researchers to follow open science principles so errors can be more easily be detected and corrected, thus as a community reduce this worryingly high error rate with our computational experiments.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {102–109},
numpages = {8},
keywords = {Classifier, Computational experiment, Reliability, Error},
location = {Manchester, United Kingdom}
}

@article{10.1016/j.eswa.2009.12.056,
author = {Zheng, Jun},
title = {Cost-sensitive boosting neural networks for software defect prediction},
year = {2010},
issue_date = {June, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {6},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.12.056},
doi = {10.1016/j.eswa.2009.12.056},
abstract = {Software defect predictors which classify the software modules into defect-prone and not-defect-prone classes are effective tools to maintain the high quality of software products. The early prediction of defect-proneness of the modules can allow software developers to allocate the limited resources on those defect-prone modules such that high quality software can be produced on time and within budget. In the process of software defect prediction, the misclassification of defect-prone modules generally incurs much higher cost than the misclassification of not-defect-prone ones. Most of the previously developed predication models do not consider this cost issue. In this paper, three cost-sensitive boosting algorithms are studied to boost neural networks for software defect prediction. The first algorithm based on threshold-moving tries to move the classification threshold towards the not-fault-prone modules such that more fault-prone modules can be classified correctly. The other two weight-updating based algorithms incorporate the misclassification costs into the weight-update rule of boosting procedure such that the algorithms boost more weights on the samples associated with misclassified defect-prone modules. The performances of the three algorithms are evaluated by using four datasets from NASA projects in terms of a singular measure, the Normalized Expected Cost of Misclassification (NECM). The experimental results suggest that threshold-moving is the best choice to build cost-sensitive software defect prediction models with boosted neural networks among the three algorithms studied, especially for the datasets from projects developed by object-oriented language.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4537–4543},
numpages = {7},
keywords = {Software defect, Neural networks, Cost-sensitive, Adaboost}
}

@article{10.1016/j.sysarc.2021.102298,
author = {Fern\'{a}ndez, Javier and Perez, Jon and Agirre, Irune and Allende, Imanol and Abella, Jaume and Cazorla, Francisco J.},
title = {Towards functional safety compliance of matrix–matrix multiplication for machine learning-based autonomous systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2021.102298},
doi = {10.1016/j.sysarc.2021.102298},
journal = {J. Syst. Archit.},
month = dec,
numpages = {14},
keywords = {Error detection, Functional safety, Machine learning}
}

@inproceedings{10.1145/1321631.1321730,
author = {Dhungana, Deepak and Rabiser, Rick and Gr\"{u}nbacher, Paul and Neumayer, Thomas},
title = {Integrated tool support for software product line engineering},
year = {2007},
isbn = {9781595938824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321631.1321730},
doi = {10.1145/1321631.1321730},
abstract = {Product line engineering comprises many heterogeneous activities such as capturing the variability of reusable assets, supporting the derivation of products from the product line, evolving the product line, or tailoring the approach to the specifics of a domain. The inherent complexity of product lines implicates that tool support is inevitable to facilitate smooth performance and to avoid costly errors. Product line engineering tools have to support heterogeneous stakeholders involved in diverse activities. Tool integration therefore is of particular importance to foster their seamless cooperation. However, the integration is difficult to achieve due to the diversity of models and work products. This paper describes the DOPLER tool suite which has been developed to provide such integrated support. The tool suite is flexible and extensible to support domain-specific needs},
booktitle = {Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {533–534},
numpages = {2},
keywords = {variability modeling, product line tools, product line engineering, product derivation, multi-team modeling, model evolution},
location = {Atlanta, Georgia, USA},
series = {ASE '07}
}

@inproceedings{10.5555/1332044.1332090,
author = {Catal, Cagatay and Diri, Banu},
title = {Software defect prediction using artificial immune recognition system},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {Predicting fault-prone modules for software development projects enables companies to reach high reliable systems and minimizes necessary budget, personnel and resource to be allocated to achieve this goal. Researchers have investigated various statistical techniques and machine learning algorithms until now but most of them applied their models to the different datasets which are not public or used different criteria to decide the best predictor model. Artificial Immune Recognition System is a supervised learning algorithm which has been proposed in 2001 for the classification problems and its performance for UCI datasets (University of California machine learning repository) is remarkable.In this paper, we propose a novel software defect prediction model by applying Artificial Immune Recognition System (AIRS) along with the Correlation-Based Feature Selection (CFS) technique. In order to evaluate the performance of the proposed model, we apply it to the five NASA public defect datasets and compute G-mean 1, G-mean 2 and F-measure values to discuss the effectiveness of the model. Experimental results show that AIRS has a great potential for software defect prediction and AIRS along with CFS technique provides relatively better prediction for large scale projects which consist of many modules.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {285–290},
numpages = {6},
keywords = {artificial immune recognition system (AIRS) and correlation-based feature selection, immune systems, quality prediction, software defect prediction},
location = {Innsbruck, Austria},
series = {SE'07}
}

@article{10.1016/j.infsof.2019.08.005,
author = {Bigonha, Mariza A.S. and Ferreira, Kecia and Souza, Priscila and Sousa, Bruno and Janu\'{a}rio, Marcela and Lima, Daniele},
title = {The usefulness of software metric thresholds for detection of bad smells and fault prediction},
year = {2019},
issue_date = {Nov 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {115},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.08.005},
doi = {10.1016/j.infsof.2019.08.005},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {79–92},
numpages = {14},
keywords = {Fault prediction, Bad smell, Detection strategies, Thresholds, Software quality, Software metrics}
}

@inproceedings{10.1145/3373509.3373575,
author = {Shixing, Han and Pengfei, Li and Guangyao, Zhang},
title = {Yarn-Dyed Fabric Defect Detection based on Multi-resolution Global and Local Saliency},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373575},
doi = {10.1145/3373509.3373575},
abstract = {In order to detect the defection of yarn-dyed fabric, a method of integrating the global and local saliency maps of multi-resolution is proposed. Multi-scale images were obtained by haar wavelet transform, and different resolutions of images were calculated global comprehensive saliency. Then GBVS algorithm was used to calculate local saliency of fabric images. The global and local saliency maps were weighted and fused to obtain comprehensive saliency images. Finally, image segmentation and morphological operations were carried out to detect the defect areas. Experimental analysed that the detection success rate of different types of texture patterns under five different kinds of defects. The experimental results showed that the detection success rate is 93.5%, so the detection rate is fast which has a certain feasibility for industrial production.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {155–159},
numpages = {5},
keywords = {yarn-dyed fabric, multi-resolution global saliency, image fusion, defect defection, comprehensive saliency map},
location = {Beijing, China},
series = {ICCPR '19}
}

@article{10.1080/08839514.2017.1378012,
author = {Fekri-Ershad, Shervan and Tajeripour, Farshad},
title = {Multi-Resolution and Noise-Resistant Surface Defect Detection Approach Using New Version of Local Binary Patterns},
year = {2017},
issue_date = {2017},
publisher = {Taylor &amp; Francis, Inc.},
address = {USA},
volume = {31},
number = {5–6},
issn = {0883-9514},
url = {https://doi.org/10.1080/08839514.2017.1378012},
doi = {10.1080/08839514.2017.1378012},
abstract = {Visual quality inspection systems play an important role in many industrial applications. In this respect, surface defect detection is one of the problems that have received much attention by image processing scientists. Until now, different methods have been proposed based on texture analysis. An operation that provides discriminate features for texture analysis is local binary patterns LBP. LBP was first introduced for gray-level images that makes it useless for colorful samples. Sensitivity to noise is another limitation of LBP. In this article, a new noise-resistant and multi-resolution version of LBP is used that extracts color and texture features jointly. Then, a robust algorithm is proposed for detecting abnormalities in surfaces. It includes two steps. First, new version of LBP is applied on full defect-less surface images, and the basic feature vector is calculated. Then, by image windowing and computing the non-similarity amount between windows and basic vector, a threshold is computed. In test phase, defect parts are detected on test samples using the tuned threshold. High detection rate, low computational complexity, low noise sensitivity, and rotation invariant are some advantages of our proposed approach.},
journal = {Appl. Artif. Intell.},
month = jul,
pages = {395–410},
numpages = {16}
}

@article{10.1016/j.infsof.2013.02.009,
author = {Radjenovi\'{c}, Danijel and Heri\v{c}ko, Marjan and Torkar, Richard and \v{Z}ivkovi\v{c}, Ale\v{s}},
title = {Software fault prediction metrics},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.02.009},
doi = {10.1016/j.infsof.2013.02.009},
abstract = {ContextSoftware metrics may be used in fault prediction models to improve software quality by predicting fault location. ObjectiveThis paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. MethodThis systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. ResultsObject-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. ConclusionMore studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1397–1418},
numpages = {22},
keywords = {Systematic literature review, Software metric, Software fault prediction}
}

@inproceedings{10.1007/978-3-030-30244-3_10,
author = {Khoza, Sibusiso C. and Grobler, Jacomine},
title = {Comparing Machine Learning and Statistical Process Control for Predicting Manufacturing Performance},
year = {2019},
isbn = {978-3-030-30243-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30244-3_10},
doi = {10.1007/978-3-030-30244-3_10},
abstract = {Quality has become one of the most important factors in the success of manufacturing companies. In this paper, the use of machine learning algorithms in quality control is compared to the use of statistical process monitoring, a classical quality management technique. The test dataset has a large number of features, which requires the use of principal component analysis and clustering to isolate the data into potential process groups. A Random Forest, Support Vector Machine and Naive Bayes algorithms were used to predict when the manufacturing process is out of control. The Random Forest algorithm performed significantly better than both the Naive Bayes and SVM algorithms in all 3 clusters of the dataset. The results were benchmarked against Hotelling’s  control charts which were trained using 80% of each cluster dataset and tested on the remaining 20%. In comparison with Hotelling’s  multivariate statistical process monitoring charts, the Random Forest algorithm still emerges as the better quality control method.},
booktitle = {Progress in Artificial Intelligence: 19th EPIA Conference on Artificial Intelligence, EPIA 2019, Vila Real, Portugal, September 3–6, 2019, Proceedings, Part II},
pages = {108–119},
numpages = {12},
location = {Vila Real, Portugal}
}

@article{10.1007/s11263-016-0953-y,
author = {Sindagi, Vishwanath A. and Srivastava, Sumit},
title = {Domain Adaptation for Automatic OLED Panel Defect Detection Using Adaptive Support Vector Data Description},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {122},
number = {2},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-016-0953-y},
doi = {10.1007/s11263-016-0953-y},
abstract = {Detection of surface defects on organic light emitting diode (OLED) panels pose challenges such as irregular shapes and sizes along with varying textures and patterns on the panels. These challenges can be addressed by designing invariant features and training an anomaly detection algorithm such as support vector data description (SVDD). However, these hand designed features may not be capable of handling test datasets that have undergone distributional shift due to changes in lighting configuration or panel specification. This leads to a degradation of the classifier performance. In this paper, we propose a domain adaptation technique for outlier detection called as adaptive support vector data description (A-SVDD) to tackle distributional change in OLED panel datasets. The proposed method aims to learn an incremental classifier based on the existing classifier using an objective function similar to SVDD. We also investigate the application of features called as local inlier---outlier ratios augmented with modified local binary pattern (LBP) for detection of OLED panel defects in the context of SVDD and A-SVDD. In the experiments, the proposed domain adaptation technique is compared with baseline methods and existing approaches to demonstrate its effectiveness. A detailed evaluation of the features was performed in the context of A-SVDD and SVDD on several defects like scratch, spot, stain and pit to demonstrate that the combination of local inlier---outlier ratios and modified LBP significantly increases the detection accuracy.},
journal = {Int. J. Comput. Vision},
month = apr,
pages = {193–211},
numpages = {19},
keywords = {Domain adaptation, Defect detection, Adaptive-SVDD}
}

@inproceedings{10.1109/ICMLA.2009.18,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan},
title = {Feature Selection with Imbalanced Data for Software Defect Prediction},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.18},
doi = {10.1109/ICMLA.2009.18},
abstract = {In this paper, we study the learning impact of data sampling followed by attribute selection on the classification models built with binary class imbalanced data within the scenario of software quality engineering. We use a wrapper-based attribute ranking technique to select a subset of attributes, and the random undersampling technique (RUS) on the majority class to alleviate the negative effects of imbalanced data on the prediction models. The datasets used in the empirical study were collected from numerous software projects. Five data preprocessing scenarios were explored in these experiments, including: (1) training on the original, unaltered fit dataset, (2) training on a sampled version of the fit dataset, (3) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on the unsampled fit dataset, (4) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on a sampled version of the fit dataset, and (5) training on a sampled version of the fit dataset using only the attributes chosen by feature selection based on the sampled version of the fit dataset. We compared the performances of the classification models constructed over these five different scenarios. The results demonstrate that the classification models constructed on the sampled fit data with or without feature selection (case 2 and case 5) significantly outperformed the classification models built with the other cases (unsampled fit data). Moreover, the two scenarios using sampled data (case 2 and case 5) showed very similar performances, but the subset of attributes (case 5) is only around 15% or 30% of the complete set of attributes (case 2).},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {235–240},
numpages = {6},
keywords = {wrapper-based attribute ranking, software defect prediction, imbalanced data, feature selection},
series = {ICMLA '09}
}

@inproceedings{10.1007/978-3-030-26250-1_32,
author = {Robin, Jacques and Mazo, Raul and Madeira, Henrique and Barbosa, Raul and Diaz, Daniel and Abreu, Salvador},
title = {A Self-certifiable Architecture for Critical Systems Powered by Probabilistic Logic Artificial Intelligence},
year = {2019},
isbn = {978-3-030-26249-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26250-1_32},
doi = {10.1007/978-3-030-26250-1_32},
abstract = {We present a versatile architecture for AI-powered self-adaptive self-certifiable critical systems. It aims at supporting semi-automated low-cost re-certification for self-adaptive systems after each adaptation of their behavior to a persistent change in their operational environment throughout their lifecycle.},
booktitle = {Computer Safety, Reliability, and Security: SAFECOMP 2019 Workshops, ASSURE, DECSoS, SASSUR, STRIVE, and WAISE, Turku, Finland, September 10, 2019, Proceedings},
pages = {391–397},
numpages = {7},
keywords = {Probabilistic logic machine learning, Rule-based constraint solving, Argumentation, Autonomic architecture, AI certification},
location = {Turku, Finland}
}

@article{10.1134/S1054661821030068,
author = {Dementev, V. E. and Suetin, M. N. and Gaponova, M. A.},
title = {Using Machine Learning Techniques to Detect Defects in Images of Metal Structures},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {3},
issn = {1054-6618},
url = {https://doi.org/10.1134/S1054661821030068},
doi = {10.1134/S1054661821030068},
journal = {Pattern Recognit. Image Anal.},
month = jul,
pages = {506–512},
numpages = {7},
keywords = {signal processing systems, neural networks, deep learning, unmanned aerial vehicles}
}

@article{10.1016/j.cie.2018.12.043,
author = {He, Di and Xu, Ke and Zhou, Peng},
title = {Defect detection of hot rolled steels with a new object detection framework called classification priority network},
year = {2019},
issue_date = {Feb 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {128},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2018.12.043},
doi = {10.1016/j.cie.2018.12.043},
journal = {Comput. Ind. Eng.},
month = feb,
pages = {290–297},
numpages = {8},
keywords = {Surface inspection, Hot rolled steels, Object detection, Classification priority network}
}

@article{10.1111/mice.12351,
author = {Li, Ruoxing and Yuan, Yachao and Zhang, Wei and Yuan, Yali},
title = {Unified Vision‐Based Methodology for Simultaneous Concrete Defect Detection and Geolocalization},
year = {2018},
issue_date = {July 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {1093-9687},
url = {https://doi.org/10.1111/mice.12351},
doi = {10.1111/mice.12351},
abstract = {Vision‐based autonomous inspection of concrete surface defects is crucial for efficient maintenance and rehabilitation of infrastructures and has become a research hot spot. However, most existing vision‐based inspection methods mainly focus on detecting one kind of defect in nearly uniform testing background where defects are relatively large and easily recognizable. But in the real‐world scenarios, multiple types of defects often occur simultaneously. And most of them occupy only small fractions of inspection images and are swamped in cluttered background, which easily leads to missed and false detections. In addition, the majority of the previous researches only focus on detecting defects but few of them pay attention to the geolocalization problem, which is indispensable for timely performing repair, protection, or reinforcement works. And most of them rely heavily on GPS for tracking the locations of the defects. However, this method is sometimes unreliable within infrastructures where the GPS signals are easily blocked, which causes a dramatic increase in searching costs. To address these limitations, we present a unified and purely vision‐based method denoted as defects detection and localization network, which can detect and classify various typical types of defects under challenging conditions while simultaneously geolocating the defects without requiring external localization sensors. We design a supervised deep convolutional neural network and propose novel training methods to optimize its performance on specific tasks. Extensive experiments show that the proposed method is effective with a detection accuracy of 80.7% and a localization accuracy of 86% at 0.41 s per image (at a scale of 1,200 pixels in the field test experiment), which is ideal for integration within intelligent autonomous inspection systems to provide support for practical applications.},
journal = {Comput.-Aided Civ. Infrastruct. Eng.},
month = jun,
pages = {527–544},
numpages = {18}
}

@inproceedings{10.1145/3297156.3297190,
author = {Qu, Zhenshen and Shen, Jianxiong and Li, Ruikun and Liu, Junyu and Guan, Qiuyu},
title = {PartsNet: A Unified Deep Network for Automotive Engine Precision Parts Defect Detection},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297190},
doi = {10.1145/3297156.3297190},
abstract = {Defect detection is a basic and essential task in automatic parts production, especially for automotive engine precision parts. In this paper, we propose a new idea to construct a deep convolutional network combining related knowledge of feature processing and the representation ability of deep learning. Our algorithm consists of a pixel-wise segmentation Deep Neural Network (DNN) and a feature refining network. The fully convolutional DNN is presented to learn basic features of parts defects. After that, several typical traditional methods which are used to refine the segmentation results are transformed into convolutional manners and integrated. We assemble these methods as a shallow network with fixed weights and empirical thresholds. These thresholds are then released to enhance its adaptation ability and realize end-to-end training. Testing results on different datasets show that the proposed method has good portability and outperforms the state-of-the-art algorithms.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {594–599},
numpages = {6},
keywords = {result refinement, fully convolutional DNN, PartsNet, Defect detection},
location = {Shenzhen, China},
series = {CSAI '18}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using multi-objective search and machine learning to infer rules constraining product configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.},
journal = {Automated Software Engg.},
month = jun,
pages = {1–62},
numpages = {62},
keywords = {Interacting products, Machine learning, Multi-objective search, Rule mining, Configuration, Product line}
}

@inproceedings{10.1145/2362536.2362580,
author = {Hamza, Haitham S. and Martinez, Jabier and Thurimella, Anil Kumar and Deogun, Jitender S.},
title = {Third International Workshop on Knowledge-Oriented Product Line Engineering (KOPLE 2012)},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362580},
doi = {10.1145/2362536.2362580},
abstract = {Software Product Line Engineering (PLE) exploits systematic reuse by identifying and methodically reusing software artifacts to develop different but related software systems. Developing Product Lines requires analysis skills to identify, model, and encode domain and product knowledge into artifacts that can be systematically reused across the development life-cycle. As such, Knowledge plays a paramount role in the success of the various activities of PLE. The objective of the KOPLE workshop series is to bring together SPL researchers and practitioners from academia and industry to investigate the role of Knowledge in PLE. Knowledge is usually encapsulated in PL architectures in a tacit or implicit way, and this may appear to be sufficient for industry to implement successful product lines. Nevertheless, KOPLE also aims to become a discussion forum about techniques and methods to convert from tacit to explicit Knowledge in PLE and to process and use this Knowledge for optimizing and innovating PLE processes.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {292–293},
numpages = {2},
keywords = {tacit knowledge, software reuse, product lines, ontology, knowledge engineering, conceptual graphs},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1109/CSE.2014.61,
author = {Sun, Huixian and Zhang, Yuhua and Li, Zhaorui},
title = {Texture Defect Detection Using Dual-Tree Complex Wavelet Reconstruction},
year = {2014},
isbn = {9781479979813},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSE.2014.61},
doi = {10.1109/CSE.2014.61},
abstract = {This paper introduces a new approach for automated inspection of textured materials using Dual-Tree Complex Wavelet (DT-CWT). The DT-CWT can transform images into a representation with six directionally selective sub bands for each scale. By properly selecting the smooth sub image or the combination of detail sub images in different resolution levels for backward wavelet transform, the reconstructed image will remove regular, repetitive texture patterns and enhance only local anomalies. The difficult defect detection problem in complicated textured images is converted into a simple thresholding problem in nontextured images. The experimental results show that the DT-CWT is more effective than the real discrete wavelet transform.},
booktitle = {Proceedings of the 2014 IEEE 17th International Conference on Computational Science and Engineering},
pages = {161–164},
numpages = {4},
keywords = {Texture analysis, Reconstruction, Dual-tree complex wavelet, Defect detection},
series = {CSE '14}
}

@article{10.1016/j.jss.2016.02.015,
author = {Rana, Rakesh and Staron, Miroslaw and Berger, Christian and Hansson, J\"{o}rgen and Nilsson, Martin and Meding, Wilhelm},
title = {Analyzing defect inflow distribution and applying Bayesian inference method for software defect prediction in large software projects},
year = {2016},
issue_date = {July 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.02.015},
doi = {10.1016/j.jss.2016.02.015},
abstract = {Defect inflow distribution of 14 large projects from industry &amp; OSS is analyzed.6 standard distributions are evaluated for their ability to fit the defect inflow.12 out of 14 projects defect inflow data was described best by beta distribution.Historical projects information is useful for early defect prediction using Bayesian inference method. Tracking and predicting quality and reliability is a major challenge in large and distributed software development projects. A number of standard distributions have been successfully used in reliability engineering theory and practice, common among these for modeling software defect inflow being exponential, Weibull, beta and Non-Homogeneous Poisson Process (NHPP). Although standard distribution models have been recognized in reliability engineering practice, their ability to fit defect data from proprietary and OSS software projects is not well understood. Lack of knowledge about underlying defect inflow distribution also leads to difficulty in applying Bayesian based inference methods for software defect prediction. In this paper we explore the defect inflow distribution of total of fourteen large software projects/release from two industrial domain and open source community. We evaluate six standard distributions for their ability to fit the defect inflow data and also assess which information criterion is practical for selecting the distribution with best fit. Our results show that beta distribution provides the best fit to the defect inflow data for all industrial projects as well as majority of OSS projects studied. In the paper we also evaluate how information about defect inflow distribution from historical projects is applied for modeling the prior beliefs/experience in Bayesian analysis which is useful for making software defect predictions early during the software project lifecycle.},
journal = {J. Syst. Softw.},
month = jul,
pages = {229–244},
numpages = {16},
keywords = {Software, SRGM, Defect Inflow}
}

@article{10.1016/j.ins.2010.11.028,
author = {Khoshgoftaar, Taghi M. and Xiao, Yudong and Gao, Kehan},
title = {Software quality assessment using a multi-strategy classifier},
year = {2014},
issue_date = {February, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {259},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2010.11.028},
doi = {10.1016/j.ins.2010.11.028},
abstract = {Classifying program modules as fault-prone or not fault-prone is a valuable technique for guiding the software development process, so that resources can be allocated to components most likely to have faults. The rule-based classification and the case-based learning techniques are commonly used in software quality classification problems. However, studies show that these two techniques share some complementary strengths and weaknesses. Therefore, in this paper we propose a new multi-strategy classification model, RB2CBL, which integrates a rule-based (RB) model with two case-based learning (CBL) models. RB2CBL possesses the merits of both the RB model and CBL model and restrains their drawbacks. In the RB2CBL model, the parameter optimization of the CBL models is critical and an embedded genetic algorithm optimizer is used. Two case studies were carried out to validate the proposed method. The results show that, by suitably choosing the accuracy of the RB model, the RB2CBL model outperforms the RB model alone without overfitting.},
journal = {Inf. Sci.},
month = feb,
pages = {555–570},
numpages = {16},
keywords = {Software quality classification, Rule-based model, Multi-strategy classifier, Genetic algorithm, Case-based learning}
}

@inproceedings{10.1145/3376067.3376113,
author = {Qian, Kun},
title = {Automated Detection of Steel Defects via Machine Learning based on Real-Time Semantic Segmentation},
year = {2020},
isbn = {9781450376822},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3376067.3376113},
doi = {10.1145/3376067.3376113},
abstract = {To improve automation, increase efficiency, and maintain high quality in the production of steel, applying modern machine learning techniques to help detect steel defects has been the research focus in the steel industry, since an unprecedented revolution in image semantic segmentation has been witnessed in the past few years. In the traditional production process of steel materials, localizing and classifying surface defects manually on a steel sheet is inefficient and error-prone. Therefore, it's a key challenge to achieve automated detection of steel surface defects in image pixel level, leaving an urgent and critical issue to be addressed. In this paper, to accomplish this crucial task, we apply a series of machine learning algorithms of real-time semantic segmentation, utilizing neural networks with encoder-decoder architectures based on Unet and feature pyramid network (FPN). The image dataset of steel defects is provided by Severstal, the largest steel company in Russia, through a featured code competition in the Kaggle community. The results show that the ensemble algorithm of several neural networks with encoder-decoder architectures has a decent performance regarding both time cost and segmentation accuracy. Our machine learning algorithms achieve dice coefficients over 0.915 and 0.905 at a speed of over 1.5 images per second on the public test set and private test set on the Kaggle platform, respectively, which locates at the top 2% among all teams in the competition.},
booktitle = {Proceedings of the 3rd International Conference on Video and Image Processing},
pages = {42–46},
numpages = {5},
keywords = {Steel Defect Detection, Semantic Segmentation, Machine Learning, Encoder-Decoder Neural Network},
location = {Shanghai, China},
series = {ICVIP '19}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00049,
author = {Zhu, Junjie and Long, Teng and Memon, Atif},
title = {Automatically authoring regression tests for machine-learning based systems},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00049},
doi = {10.1109/ICSE-SEIP52600.2021.00049},
abstract = {Two key design characteristics of machine learning (ML) systems---their ever-improving nature, and learning-based emergent functional behavior---create a moving target, posing new challenges for authoring/maintaining functional regression tests. We identify four specific challenges and address them by developing a new general methodology to automatically author and maintain tests. In particular, we use the volume of production data to periodically refresh our large corpus of test inputs and expected outputs; we use perturbation of the data to obtain coverage-adequate tests; and we use clustering to help identify patterns of failures that are indicative of software bugs. We demonstrate our methodology on an ML-based context-aware Speller. Our coverage-adequate, approx. 1 million regression test cases, automatically authored and maintained for Speller (1) are virtually maintenance free, (2) detect a higher number of Speller failures than previous manually-curated tests, (3) have better coverage of previously unknown functional boundaries of the ML component, and (4) lend themselves to automatic failure triaging by clustering and prioritizing subcategories of tests with over-represented failures. We identify several systematic failure patterns which were due to previously undetected bugs in the Speller, e.g., (1) when the user misses the first letter in a short word, and (2) when the user mistakenly inserts a character in the last token of an address; these have since been fixed.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {374–383},
numpages = {10},
keywords = {spelling correction, ML-based testing, ML testing},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1007/s42979-021-00872-6,
author = {Sakhrawi, Zaineb and Sellami, Asma and Bouassida, Nadia},
title = {Software Enhancement Effort Prediction Using Machine-Learning Techniques: A Systematic Mapping Study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
url = {https://doi.org/10.1007/s42979-021-00872-6},
doi = {10.1007/s42979-021-00872-6},
abstract = {Accurate prediction of software enhancement effort is a key success in software project management. To increase the accuracy of estimates, several proposals used machine-learning (ML) techniques for predicting the software project effort. However, there is no clear evidence for determining which techniques to select for predicting more accurate effort within the context of enhancement projects. This paper aims to present a systematic mapping study (SMS) related to the use of ML techniques for predicting software enhancement effort (SEME). A SMS was performed by reviewing relevant papers from 1995 through 2020. We followed well-known guidelines. We selected 30 relevant studies; 19 from journals and 11 conferences proceedings through 4 search engines. Some of the key findings indicate that (1) there is relatively little activity in the area of SEME, (2) most of the successful studies cited focused on regression problems for enhancement maintenance effort prediction, (3) SEME is the dependent variable the most commonly used in software enhancement project planning, and the enhancement size (or the functional change size) is the most used independent variables, (4) several private datasets were used in the selected studies, and there is a growing demand for the use of commonly published datasets, and (5) only single models were employed for SEME prediction. Results indicate that much more work is needed to develop repositories in all prediction models. Based on the findings obtained in this SMS, estimators should be aware that SEME using ML techniques as part of non-algorithmic models demonstrated increased accuracy prediction over the algorithmic models. The use of ML techniques generally provides a reasonable accuracy when using the enhancement functional size as independent variables.},
journal = {SN Comput. Sci.},
month = sep,
numpages = {15},
keywords = {Machine learning (ML), Software enhancement effort (SEME) prediction, Functional change (FC), Systematic mapping study (SMS)}
}

@article{10.1016/j.aei.2015.01.014,
author = {Tsai, Du-Ming and Li, Guan-Nan and Li, Wei-Chen and Chiu, Wei-Yao},
title = {Defect detection in multi-crystal solar cells using clustering with uniformity measures},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {29},
number = {3},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2015.01.014},
doi = {10.1016/j.aei.2015.01.014},
abstract = {Solar cells that convert sunlight into electrical energy are the main component of a solar power system. Quality inspection of solar cells ensures high energy conversion efficiency of the product. The surface of a multi-crystal solar wafer shows multiple crystal grains of random shapes and sizes. It creates an inhomogeneous texture in the surface, and makes the defect inspection task extremely difficult. This paper proposes an automatic defect detection scheme based on Haar-like feature extraction and a new clustering technique. Only defect-free images are used as training samples. In the training process, a binary-tree clustering method is proposed to partition defect-free samples that involve tens of groups. A uniformity measure based on principal component analysis is evaluated for each cluster. In each partition level, the current cluster with the worst uniformity of inter-sample distances is separated into two new clusters using the Fuzzy C-means. In the inspection process, the distance from a test data point to each individual cluster centroid is computed to measure the evidence of a defect. Experimental results have shown that the proposed method is effective and efficient to detect various defects in solar cells. It has shown a very good detection rate, and the computation time is only 0.1s for a 550 550 image.},
journal = {Adv. Eng. Inform.},
month = aug,
pages = {419–430},
numpages = {12},
keywords = {Surface inspection, Solar cells, Fuzzy C-means, Defect detection, Clustering}
}

@inproceedings{10.1145/3377713.3377753,
author = {Lu, Qiwei and Cheng, Jinpei and Guo, Dianlin and Su, Mengmeng and Wu, Xuewei and Ru, Tao},
title = {Binary Classification Model Based on Machine Learning Algorithm for the Short-Circuit Detection in Power System},
year = {2020},
isbn = {9781450372619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377713.3377753},
doi = {10.1145/3377713.3377753},
abstract = {Short circuit faults usually occur in the damaged insulation lines or line connections, which will cause serious accidents such as fires and explosions. As the power supply distance increases, accuracy of short-circuit fault detection is insufficient and the process is tedious with the traditional analysis method. In order to solve the problems above, the short-circuit fault detection is classified into the two classification problems while the machine learning method is used. The data of the normal state and short circuit fault state are obtained by the short-circuit simulation experiment. Extract four features from time domain, including the average current and so on. By training support vector machine (SVM) using the different combinations of extraction features above, the model is obtained. The accuracy of classification of the test data set by the model is high. The results show that the short-circuit fault detection method based on machine learning is more accurate and robust than traditional analysis methods.},
booktitle = {Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {271–275},
numpages = {5},
keywords = {normalization, feature extraction, feature analysis, Short-circuit detection},
location = {Sanya, China},
series = {ACAI '19}
}

@inproceedings{10.1145/3314493.3314508,
author = {Cai, Wang and Wang, Jianzhuang and Zhou, Qi and Yang, Yang and Jiang, Ping},
title = {Equipment and Machine Learning in Welding Monitoring: A Short Review},
year = {2019},
isbn = {9781450360951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314493.3314508},
doi = {10.1145/3314493.3314508},
abstract = {Laser welding has been widely applied to various industries, effective real time monitoring can help to improve the welding efficiency and production quality. This paper makes a short review on the signal detection equipment and machine learning algorithms. It starts with a detailed introduction to some basic monitoring sensors and methods, some special monitoring methods like ICI, MOI and multiple sensor fusion technology are also talked over. The commonly used machine learning algorithms like BPNN and SVM used in welding data mining, weld defects classification and weld seam features forecasting are summarized in the end section. This fundamental work aims to provide a guideline for the selection of monitoring equipment, chose suitable machine learning algorithms for effectively classifying weld defects and realizing welding process intelligent real time monitoring.},
booktitle = {Proceedings of the 5th International Conference on Mechatronics and Robotics Engineering},
pages = {9–15},
numpages = {7},
keywords = {Sensor, Real time monitoring, Machine learning algorithms, Laser welding},
location = {Rome, Italy},
series = {ICMRE'19}
}

@inproceedings{10.1109/ASE.2013.6693126,
author = {Scanniello, Giuseppe and Gravino, Carmine and Marcus, Andrian and Menzies, Tim},
title = {Class level fault prediction using software clustering},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693126},
doi = {10.1109/ASE.2013.6693126},
abstract = {Defect prediction approaches use software metrics and fault data to learn which software properties associate with faults in classes. Existing techniques predict fault-prone classes in the same release (intra) or in a subsequent releases (inter) of a subject software system. We propose an intra-release fault prediction technique, which learns from clusters of related classes, rather than from the entire system. Classes are clustered using structural information and fault prediction models are built using the properties of the classes in each cluster. We present an empirical investigation on data from 29 releases of eight open source software systems from the PROMISE repository, with predictors built using multivariate linear regression. The results indicate that the prediction models built on clusters outperform those built on all the classes of the system.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {640–645},
numpages = {6},
keywords = {software clustering, fault prediction, empirical study},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1109/COASE.2017.8256161,
author = {Luan, Riwei and Wen, Guangrui and Zhang, Ruxin and Chen, Zheng and Zhang, Zhifen},
title = {Porosity defect detection based on FastICA-RBF during pulsed TIG welding process},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2017.8256161},
doi = {10.1109/COASE.2017.8256161},
abstract = {Porosity is a common defect of the aluminum alloy pulsed alternating current (AC) argon tungsten-arc welding (TIG) welding, which can cause huge damage to weld quality. The spectral information which is directly derived from the optical radiation of the arc is intrinsically related to the welding defects. Aiming at the redundancy of arc spectral, this paper proposed a method of porosity defect detection based on fast independent component analysis (fastICA) and radial basis function (RBF) network. The spectral data is collected by spectrometer, and continuous spectra are removed by calculating lower envelope twice. Then fastICA is applied to extract features from selected line spectra. Finally, the porosity defect is detected by RBF network according to the mean value in period of extracted features. Experimental results show that the proposed method can be used to detect the porosity defects during aluminum alloy pulsed TIG welding process.},
booktitle = {2017 13th IEEE Conference on Automation Science and Engineering (CASE)},
pages = {548–553},
numpages = {6},
location = {Xi'an, China}
}

@inproceedings{10.1145/3183440.3194992,
author = {Guo, Yuchen and Shepperd, Martin and Li, Ning},
title = {Bridging effort-aware prediction and strong classification: a just-in-time software defect prediction study},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194992},
doi = {10.1145/3183440.3194992},
abstract = {Context: Most research into software defect prediction ignores the differing amount of effort entailed in searching for defects between software components. The result is sub-optimal solutions in terms of allocating testing resources. Recently effort-aware (EA) defect prediction has sought to redress this deficiency. However, there is a gap between previous classification research and EA prediction.Objective: We seek to transfer strong defect classification capability to efficient effort-aware software defect prediction.Method: We study the relationship between classification performance and the cost-effectiveness curve experimentally (using six open-source software data sets).Results: We observe extremely skewed distributions of change size which contributes to the lack of relationship between classification performance and the ability to find efficient test orderings for defect detection. Trimming allows all effort-aware approaches bridging high classification capability to efficient effort-aware performance.Conclusion: Effort distributions dominate effort-aware models. Trimming is a practical method to handle this problem.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {325–326},
numpages = {2},
keywords = {defect prediction, effort-aware, just-in-time, software},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.engappai.2009.10.001,
author = {Pendharkar, Parag C.},
title = {Exhaustive and heuristic search approaches for learning a software defect prediction model},
year = {2010},
issue_date = {February, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {23},
number = {1},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2009.10.001},
doi = {10.1016/j.engappai.2009.10.001},
abstract = {In this paper, we propose a software defect prediction model learning problem (SDPMLP) where a classification model selects appropriate relevant inputs, from a set of all available inputs, and learns the classification function. We show that the SDPMLP is a combinatorial optimization problem with factorial complexity, and propose two hybrid exhaustive search and probabilistic neural network (PNN), and simulated annealing (SA) and PNN procedures to solve it. For small size SDPMLP, exhaustive search PNN works well and provides an (all) optimal solution(s). However, for large size SDPMLP, the use of exhaustive search PNN approach is not pragmatic and only the SA-PNN allows us to solve the SDPMLP in a practical time limit. We compare the performance of our hybrid approaches with traditional classification algorithms and find that our hybrid approaches perform better than traditional classification algorithms.},
journal = {Eng. Appl. Artif. Intell.},
month = feb,
pages = {34–40},
numpages = {7},
keywords = {Software engineering, Simulated annealing, Probabilistic neural networks, Heuristics, Exhaustive search}
}

@inproceedings{10.1007/978-3-030-78361-7_26,
author = {Fujinuma, Ryota and Asahi, Yumi},
title = {Proposal of Credit Risk Model Using Machine Learning in Motorcycle Sales},
year = {2021},
isbn = {978-3-030-78360-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78361-7_26},
doi = {10.1007/978-3-030-78361-7_26},
abstract = {While the new BIS regulations are reviewing the way of thinking about loans all over the world, many people in Central and South America still have a vague way of thinking about loans. It is due to the global recession. As a result, companies have not been able to recover their manufacturing costs. Therefore, in this study, we create a classification model of customers who default and customers who do not default. Also, explore the characteristics of the default customers. This is because it is thought that it will be easier for companies to improve the loan problem and secure profits.In this study, we compare the accuracy of Random Forest and XG boost. Since the data handled in this study were unbalanced data, data expansion by Synthetic Minority Over-sampling Technique (SMOTE) was effective. Mainly the accuracy of Recall has increased by 30%. Feature selection is performed by correlation, which is one of the filter methods. This can be expected to have the effect of improving accuracy and the effect of improving the interpretability of the model. We were able to reduce it from 46 variables to 22 variables. Furthermore, the accuracy increased by 1% for Binary Accuracy and 1% for Recall. The accuracy decreased when the number of variables was reduced by 23 variables or more. This is probably because important features have been deleted. Shows the accuracy of the model. The accuracy of Random Forest is Binary Accuracy = 61.3%, Recall = 58.2%. The accuracy of XGboost is Binary Accuracy = 60.3%, Recall = 61.6%. Therefore, XG boost became the model that can identify the default of the customer than the random forest.Finally, SHApley Additive exPlanations (SHAP) analyzes what variables contribute to the model. From this analysis result, we will explore the characteristics of what kind of person is the default customer. The variables with the highest contribution were the type of vehicle purchased, the area where the customer lives, and credit information. It turns out that customers who have gone loan bankruptcy in the past tend to be loan bankruptcy again.},
booktitle = {Human Interface and the Management of Information. Information-Rich and Intelligent Environments: Thematic Area, HIMI 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part II},
pages = {353–363},
numpages = {11},
keywords = {Loan, Loan bankruptcy, Credit risk model, Machine learning}
}

@article{10.1016/j.compag.2018.07.025,
author = {Lu, Yuzhen and Lu, Renfu},
title = {Fast Bi-dimensional empirical mode decomposition as an image enhancement technique for fruit defect detection},
year = {2018},
issue_date = {Sep 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {152},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2018.07.025},
doi = {10.1016/j.compag.2018.07.025},
journal = {Comput. Electron. Agric.},
month = sep,
pages = {314–323},
numpages = {10},
keywords = {Fruit, Defect, Structured illumination, Image enhancement, Empirical mode decomposition}
}

@inproceedings{10.1109/COASE.2018.8560341,
author = {Jalalian, A. and Lu, W. F. and Wong, F. S. and Ahmed, S. M. and Chew, C.-M.},
title = {An Automatic Visual Inspection Method based on Statistical Approach for Defect Detection of Ship Hull Surfaces},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2018.8560341},
doi = {10.1109/COASE.2018.8560341},
abstract = {Robotized blasting of ship hull surfaces requires an accurate identification of defective regions of the hull to maximize the blasting efficiency. Accurate surface defect detection may not be achieved by current manual procedures, as its success is highly vulnerable to the human operators' experience and their subjective judgements. Therefore, there is a need for a more accurate and non-subjective method for defect detection. This paper proposes a computer vision based method for detection of ship hull defects. The method utilizes the histogram of hue and entropy data of the hue to identify the defects in two steps. Step 1 is an automatic circular thresholding based on the histogram of hue to distinguish the defects whose hue is different from the defect-free regions. A wrapped Gaussian mixture model is utilized to estimate the circular hue histograms, and maximum likelihood criterion is adopted to set the thresholds. Step 2 uses the probability distribution of the entropy for each segment identified in the first step to decide whether the segments are either defective, defect-free or a mixture of both. For the mixed regions, a Gaussian mixture model is fitted to the probability distribution of the entropy. The maximum likelihood criterion is utilized to segment these regions so as to discriminate their defective and defect-free parts. The high accuracy (F-measure=0.89) and short execution time (&lt;inf&gt;~&lt;/inf&gt;3.5 s) of the proposed method show that it is a good starting point for an automatic defect detection for a fully autonomous ship hull blasting.},
booktitle = {2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)},
pages = {445–450},
numpages = {6},
location = {Munich, Germany}
}

@article{10.1016/j.infsof.2019.106214,
author = {Alsolai, Hadeel and Roper, Marc},
title = {A systematic literature review of machine learning techniques for software maintainability prediction},
year = {2020},
issue_date = {Mar 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {119},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106214},
doi = {10.1016/j.infsof.2019.106214},
journal = {Inf. Softw. Technol.},
month = mar,
numpages = {25},
keywords = {Dataset, Metric, Machine learning, Software maintainability prediction, Systematic literature review}
}

@article{10.1016/j.asoc.2019.02.008,
author = {Juneja, Kapil},
title = {A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {77},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.02.008},
doi = {10.1016/j.asoc.2019.02.008},
journal = {Appl. Soft Comput.},
month = apr,
pages = {696–713},
numpages = {18},
keywords = {Fuzzy, Classification, Intra project, Inter project, Defect Prediction}
}

@article{10.5555/1991856.1991869,
author = {Jiang, Yuan and Li, Ming and Zhou, Zhi-Hua},
title = {Software defect detection with rocus},
year = {2011},
issue_date = {March 2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1000-9000},
abstract = {Software defect detection aims to automatically identify defective software modules for efficient software test in order to improve the quality of a software system. Although many machine learning methods have been successfully applied to the task, most of them fail to consider two practical yet important issues in software defect detection. First, it is rather difficult to collect a large amount of labeled training data for learning a well-performing model; second, in a software system there are usually much fewer defective modules than defect-free modules, so learning would have to be conducted over an imbalanced data set. In this paper, we address these two practical issues simultaneously by prcposing a novel semi-supervised learning approach named ROCUS. This method exploits the abundant unlabeled examples to improve the detection accuracy, as well as employs under-sampling to tackle the class-imbalance problem in the learning process. Experimental results of real-world software defect detection tasks show that ROCUS is effective for software defect cetection. Its performance is better than a semi-supervised learning method that ignores the class-imbalance nature of the task and a class-imbalance learning method that does not make effective use of unlabeled data.},
journal = {J. Comput. Sci. Technol.},
month = mar,
pages = {328–342},
numpages = {15},
keywords = {software defect detection, semi-supervised learning, machine learning, data mining, class-imbalance}
}

@inproceedings{10.1145/2020390.2020405,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {An iterative semi-supervised approach to software fault prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020405},
doi = {10.1145/2020390.2020405},
abstract = {Background: Many statistical and machine learning techniques have been implemented to build predictive fault models. Traditional methods are based on supervised learning. Software metrics for a module and corresponding fault information, available from previous projects, are used to train a fault prediction model. This approach calls for a large size of training data set and enables the development of effective fault prediction models. In practice, data collection costs, the lack of data from earlier projects or product versions may make large fault prediction training data set unattainable. Small size of the training set that may be available from the current project is known to deteriorate the performance of the fault predictive model. In semi-supervised learning approaches, software modules with known or unknown fault content can be used for training.Aims: To implement and evaluate a semi-supervised learning approach in software fault prediction.Methods: We investigate an iterative semi-supervised approach to software quality prediction in which a base supervised learner is used within a semi-supervised application.Results: We varied the size of labeled software modules from 2% to 50% of all the modules in the project. After tracking the performance of each iteration in the semi-supervised algorithm, we observe that semi-supervised learning improves fault prediction if the number of initially labeled software modules exceeds 5%.Conclusion: The semi-supervised approach outperforms the corresponding supervised learning approach when both use random forest as base classification algorithm.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {15},
numpages = {10},
keywords = {fault prediction, semi-supervised learning},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/2601248.2601294,
author = {Rodriguez, Daniel and Herraiz, Israel and Harrison, Rachel and Dolado, Javier and Riquelme, Jos\'{e} C.},
title = {Preliminary comparison of techniques for dealing with imbalance in software defect prediction},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601294},
doi = {10.1145/2601248.2601294},
abstract = {Imbalanced data is a common problem in data mining when dealing with classification problems, where samples of a class vastly outnumber other classes. In this situation, many data mining algorithms generate poor models as they try to optimize the overall accuracy and perform badly in classes with very few samples. Software Engineering data in general and defect prediction datasets are not an exception and in this paper, we compare different approaches, namely sampling, cost-sensitive, ensemble and hybrid approaches to the problem of defect prediction with different datasets preprocessed differently. We have used the well-known NASA datasets curated by Shepperd et al. There are differences in the results depending on the characteristics of the dataset and the evaluation metrics, especially if duplicates and inconsistencies are removed as a preprocessing step.Further Results and replication package: http://www.cc.uah.es/drg/ease14},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {43},
numpages = {10},
keywords = {imbalanced data, defect prediction, data quality},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@article{10.1016/j.eswa.2014.10.025,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {A comparison of some soft computing methods for software fault prediction},
year = {2015},
issue_date = {March 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.10.025},
doi = {10.1016/j.eswa.2014.10.025},
abstract = {Software fault prediction is implemented with ANN, SVM and ANFIS.First ANFIS implementation is applied to solve fault prediction problem.Parameters are discussed in neuro fuzzy approach.Experiments show that the application of ANFIS to the software fault prediction problem is highly reasonable. The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1872–1879},
numpages = {8},
keywords = {Support Vector Machines, Software fault prediction, McCabe metrics, Artificial Neural Networks, Adaptive neuro fuzzy systems}
}

@inproceedings{10.1145/2365324.2365335,
author = {Lu, Huihua and Cukic, Bojan},
title = {An adaptive approach with active learning in software fault prediction},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365335},
doi = {10.1145/2365324.2365335},
abstract = {Background: Software quality prediction plays an important role in improving the quality of software systems. By mining software metrics, predictive models can be induced that provide software managers with insights into quality problems they need to tackle as effectively as possible.Objective: Traditional, supervised learning approaches dominate software quality prediction. Resulting models tend to be project specific. On the other hand, in situations where there are no previous releases, supervised learning approaches are not very useful because large training data sets are needed to develop accurate predictive models.Method: This paper eases the limitations of supervised learning approaches and offers good prediction performance. We propose an adaptive approach in which supervised learning and active learning are coupled together. NaiveBayes classifier is used as the base learner.Results: We track the performance at each iteration of the adaptive learning algorithm and compare it with the performance of supervised learning. Our results show that proposed scheme provides good fault prediction performance over time, i.e., it eventually outperforms the corresponding supervised learning approach. On the other hand, adaptive learning classification approach reduces the variance in prediction performance in comparison with the corresponding supervised learning algorithm.Conclusion: The adaptive approach outperforms the corresponding supervised learning approach when both use Naive-Bayes as base learner. Additional research is needed to investigate whether this observation remains valid with other base classifiers.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {79–88},
numpages = {10},
keywords = {active learning, adaptive learning, software fault prediction},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@inproceedings{10.1109/ICMLA.2012.13,
author = {Zhou, Jian and Semenovich, Dimitri and Sowmya, Arcot and Wang, Jun},
title = {Sparse Dictionary Reconstruction for Textile Defect Detection},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.13},
doi = {10.1109/ICMLA.2012.13},
abstract = {Inspired by the image de-noising techniques using learned dictionaries and sparse representation, we present a fabric defect detection scheme via sparse dictionary reconstruction. Fabric defects can be regarded as local anomalies against the relatively homogeneous texture background. Following from the flexibility of sparse representation, normal fabric samples can be efficiently represented using a linear combination of a few elements of a learned dictionary. When modeling new samples with a learned dictionary, tuned to the input data containing normal fabric structural features, abnormal or defective samples are likely to have larger dissimilarity than normal samples. We evaluate the proposed methods using ten different fabric types. Experimental results show that our method has many advantages in defect detection, especially in adapting variation of fabric textures.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 01},
pages = {21–26},
numpages = {6},
keywords = {Sparse representation, Novelty detection, Image reconstruction, Fabric defect detection, Dictionary learning},
series = {ICMLA '12}
}

@article{10.1007/s00138-014-0600-y,
author = {Schneider, Dorian and Holtermann, Timm and Merhof, Dorit},
title = {A traverse inspection system for high precision visual on-loom fabric defect detection},
year = {2014},
issue_date = {August    2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-014-0600-y},
doi = {10.1007/s00138-014-0600-y},
abstract = {A self-contained inspection system for vision-based on-loom fabric defect detection is presented in this paper. Design and loom integration of a traversing camera sled, a camera vibration damper and a complementary back-light illumination are presented and discussed. Image acquisition strategies and traverse control are described to complete the discussion on hardware and mechanics. The main part of the paper focuses on a novel algorithmic framework for woven fabric defect detection in highly resolved (1,000+ ppi) image data. Within this scope, single yarns are tracked and measured in terms of position, size, and appearance in real time. An inspection prototype has been mounted onto an industrial loom. Extensive on-line and off-line evaluations for various fabric materials gave precise and stable detection results with few false alarms. A brief cost analysis for the prototype system is provided and completes the presentation of the system.},
journal = {Mach. Vision Appl.},
month = aug,
pages = {1585–1599},
numpages = {15},
keywords = {Textile flaws, Real-time, On-loom, Fabric defect detection, Automated visual inspection}
}

@article{10.1007/s11042-010-0472-8,
author = {Shi, Meihong and Fu, Rong and Guo, Yong and Bai, Shixian and Xu, Bugao},
title = {Fabric defect detection using local contrast deviations},
year = {2011},
issue_date = {March     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {1},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-010-0472-8},
doi = {10.1007/s11042-010-0472-8},
abstract = {Defect inspection is a vital step for quality assurance in fabric production. The development of a fully automated fabric defect detection system requires robust and efficient fabric defect detection algorithms. The inspection of real fabric defects is particularly challenging due to delicate features of defects complicated by variations in weave textures and changes in environmental factors (e.g., illumination, noise, etc.). Based on characteristics of fabric structure, an approach of using  local contrast deviation  (LCD) is proposed for fabric defect detection in this paper. LCD is a parameter used to describe features of the contrast difference in four directions between the analyzed image and a defect-free image of the same fabric, and is used with a bilevel threshold function for defect segmentation. The validation tests on the developed algorithms were performed with fabric images from TILDA's Textile Texture Database and captured by a line-scan camera on an inspection machine. The experimental results show that the proposed method has robustness and simplicity as opposed to the approach of using modified local binary patterns (LBP).},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {147–157},
numpages = {11},
keywords = {Local contrast deviation (LCD), Image segmentation, Fabric defect detection}
}

@inproceedings{10.1145/2020390.2020392,
author = {Bell, Robert M. and Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {Does measuring code change improve fault prediction?},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020392},
doi = {10.1145/2020390.2020392},
abstract = {Background: Several studies have examined code churn as a variable for predicting faults in large software systems. High churn is usually associated with more faults appearing in code that has been changed frequently.Aims: We investigate the extent to which faults can be predicted by the degree of churn alone, whether other code characteristics occur together with churn, and which combinations of churn and other characteristics provide the best predictions. We also investigate different types of churn, including both additions to and deletions from code, as well as overall amount of change to code.Method: We have mined the version control database of a large software system to collect churn and other software measures from 18 successive releases of the system. We examine the frequency of faults plotted against various code characteristics, and evaluate a diverse set of prediction models based on many different combinations of independent variables, including both absolute and relative churn.Results: Churn measures based on counts of lines added, deleted, and modified are very effective for fault prediction. Individually, counts of adds and modifications outperform counts of deletes, while the sum of all three counts was most effective. However, these counts did not improve prediction accuracy relative to a model that included a simple count of the number of times that a file had been changed in the prior release.Conclusions: Including a measure of change in the prior release is an essential component of our fault prediction method. Various measures seem to work roughly equivalently.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {2},
numpages = {8},
keywords = {code churn, empirical study, fault prediction, fault-percentile average, software faults},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/3425269.3425278,
author = {Bindewald, Carlos Vinicius and Freire, Willian M. and Amaral, Aline M. M. Miotto and Colanzi, Thelma Elita},
title = {Supporting user preferences in search-based product line architecture design using Machine Learning},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425278},
doi = {10.1145/3425269.3425278},
abstract = {The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line. PLA design requires intensive human effort as it involves several conflicting factors. In order to support this task, an interactive search-based approach, automated by a tool named OPLA-Tool, was proposed in a previous work. Through this tool the software architect evaluates the generated solutions during the optimization process. Considering that evaluating PLA is a complex task and search-based algorithms demand a high number of generations, the evaluation of all solutions in all generations cause human fatigue. In this work, we incorporated in OPLA-Tool a Machine Learning (ML) model to represent the architect in some moments during the optimization process aiming to decrease the architect's effort. Through the execution of a quantiqualitative exploratory study it was possible to demonstrate the reduction of the fatigue problem and that the solutions produced at the end of the process, in most cases, met the architect's needs.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {11–20},
numpages = {10},
keywords = {Product Line Architecture, Machine Learning, Human-computer interaction},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@article{10.1016/j.micpro.2021.103953,
author = {Pandiaraj, K. and Sivakumar, P. and Prakash, K. Jeya},
title = {Machine learning based effective linear regression model for TSV layer assignment in 3DIC},
year = {2021},
issue_date = {Jun 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {83},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2021.103953},
doi = {10.1016/j.micpro.2021.103953},
journal = {Microprocess. Microsyst.},
month = jun,
numpages = {10},
keywords = {Tsv, through silicon via, Ic- integrated circuit, Elrm- efficient linear regression model. ml- machine learning}
}

@article{10.1007/s00607-019-00781-w,
author = {Renga, Daniela and Apiletti, Daniele and Giordano, Danilo and Nisi, Matteo and Huang, Tao and Zhang, Yang and Mellia, Marco and Baralis, Elena},
title = {Data-driven exploratory models of an electric distribution network for fault prediction and diagnosis},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {102},
number = {5},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-019-00781-w},
doi = {10.1007/s00607-019-00781-w},
abstract = {Data-driven models are becoming of fundamental importance in electric distribution networks to enable predictive maintenance, to perform effective diagnosis and to reduce related expenditures, with the final goal of improving the electric service efficiency and reliability to the benefit of both the citizens and the grid operators themselves. This paper considers a dataset collected over 6 years in a real-world medium-voltage distribution network by the Supervisory Control And Data Acquisition (SCADA) system. A transparent, exploratory, and exhaustive data-mining workflow, based on data characterisation, time-windowing, association rule mining, and associative classification is proposed and experimentally evaluated to automatically identify correlations and build a prognostic–diagnostic model from the SCADA events occurring before and after specific service interruptions, i.e., network faults. Our results, evaluated by both data-driven quality metrics and domain expert interpretations, highlight the capability to assess the limited predictive capability of the SCADA events for medium-voltage distribution networks, while their effective exploitation for diagnostic purposes is promising.},
journal = {Computing},
month = may,
pages = {1199–1211},
numpages = {13},
keywords = {68T04, Associative classification, Data mining, Medium Voltage distribution networks, Fault diagnosis, Predictive maintenance, Smart grid}
}

@article{10.1504/IJDATS.2016.075971,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {Software fault prediction using Mamdani type fuzzy inference system},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2016.075971},
doi = {10.1504/IJDATS.2016.075971},
abstract = {High quality software requires the occurrence of minimum number of failures while software runs. Software fault prediction is the determining whether software modules are prone to fault or not. Identification of the modules or code segments which need detailed testing, editing or, reorganising can be possible with the help of software fault prediction systems. In literature, many studies present models for software fault prediction using some soft computing methods which use training/testing phases. As a result, they require historical data to build models. In this study, to eliminate this drawback, Mamdani type fuzzy inference system FIS is applied for the software fault prediction problem. Several FIS models are produced and assessed with ROC-AUC as performance measure. The results achieved are ranging between 0.7138 and 0.7304; they are encouraging us to try FIS with the different software metrics and data to demonstrate general FIS performance on this problem.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = apr,
pages = {14–28},
numpages = {15}
}

@article{10.1016/j.eswa.2011.04.012,
author = {Tolba, A.S.},
title = {Fast defect detection in homogeneous flat surface products},
year = {2011},
issue_date = {Sep 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.04.012},
doi = {10.1016/j.eswa.2011.04.012},
journal = {Expert Syst. Appl.},
month = sep,
pages = {12339–12347},
numpages = {9},
keywords = {Probabilistic neural network (PNN), Homogeneity measures, Log-Gabor filter bank, Feature extraction, Defect detection, Automated visual inspection}
}

@article{10.1007/s10586-019-02917-1,
author = {Mohammed, Bashir and Awan, Irfan and Ugail, Hassan and Younas, Muhammad},
title = {Failure prediction using machine learning in a virtualised HPC system and application},
year = {2019},
issue_date = {Mar 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-02917-1},
doi = {10.1007/s10586-019-02917-1},
abstract = {Failure is an increasingly important issue in high performance computing and cloud systems. As large-scale systems continue to grow in scale and complexity, mitigating the impact of failure and providing accurate predictions with sufficient lead time remains a challenging research problem. Traditional existing fault-tolerance strategies such as regular check-pointing and replication are not adequate because of the emerging complexities of high performance computing systems. This necessitates the importance of having an effective as well as proactive failure management approach in place aimed at minimizing the effect of failure within the system. With the advent of machine learning techniques, the ability to learn from past information to predict future pattern of behaviours makes it possible to predict potential system failure more accurately. Thus, in this paper, we explore the predictive abilities of machine learning by applying a number of algorithms to improve the accuracy of failure prediction. We have developed a failure prediction model using time series and machine learning, and performed comparison based tests on the prediction accuracy. The primary algorithms we considered are the support vector machine (SVM), random forest (RF), k-nearest neighbors (KNN), classification and regression trees (CART) and linear discriminant analysis (LDA). Experimental results indicates that the average prediction accuracy of our model using SVM when predicting failure is 90% accurate and effective compared to other algorithms. This finding implies that our method can effectively predict all possible future system and application failures within the system.},
journal = {Cluster Computing},
month = jun,
pages = {471–485},
numpages = {15},
keywords = {Machine learning, High performance computing, Failure, Cloud computing}
}

@article{10.1109/TSE.2012.20,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
title = {Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers},
year = {2013},
issue_date = {February 2013},
publisher = {IEEE Press},
volume = {39},
number = {2},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2012.20},
doi = {10.1109/TSE.2012.20},
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem\v{s}ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
journal = {IEEE Trans. Softw. Eng.},
month = feb,
pages = {237–257},
numpages = {21},
keywords = {comprehensibility, classification, Software fault prediction, Software, Probability distribution, Predictive models, Measurement, Machine learning, Capability maturity model, Bayesian networks, Bayesian methods}
}

@article{10.1016/j.imavis.2009.03.007,
author = {Mak, K. L. and Peng, P. and Yiu, K. F. C.},
title = {Fabric defect detection using morphological filters},
year = {2009},
issue_date = {September, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {27},
number = {10},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2009.03.007},
doi = {10.1016/j.imavis.2009.03.007},
abstract = {In this paper, a novel defect detection scheme based on morphological filters is proposed to tackle the problem of automated defect detection for woven fabrics. In the proposed scheme, important texture features of the textile fabric are extracted using a pre-trained Gabor wavelet network. These texture features are then used to facilitate the construction of structuring elements in subsequent morphological processing to remove the fabric background and isolate the defects. Since the proposed defect detection scheme requires a few morphological filters only, the amount of computational load involved is not significant. The performance of the proposed scheme is evaluated by using a wide variety of homogeneous textile images with different types of common fabric defects. The test results obtained exhibit accurate defect detection with low false alarms, thus showing the effectiveness and robustness of the proposed detection scheme. In addition, the proposed detection scheme is further evaluated in real time by using a prototyped automated inspection system.},
journal = {Image Vision Comput.},
month = sep,
pages = {1585–1592},
numpages = {8},
keywords = {Textile fabrics, Quality control, Morphological filter, Gabor wavelet network, Defect detection}
}

@inproceedings{10.1007/978-3-319-07626-3_41,
author = {He, Ning and Zhang, Lulu and Lu, Ke},
title = {Aluminum CT Image Defect Detection Based on Segmentation and Feature Extraction},
year = {2014},
isbn = {9783319076256},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-07626-3_41},
doi = {10.1007/978-3-319-07626-3_41},
abstract = {Industrial computed tomography (CT) scanning has been used in many areas of industry for internal inspection of components. Some of the key uses for CT scanning have been flaw detection, failure analysis, metrology, assembly analysis and reverse engineering applications. In this paper we present the approach to detecting defects follows a general image processing scheme based on three steps: segmentation, feature extractions, and classification. In the first step (segmentation), potential defects are segmented using the region method. In the step of feature extraction, two main features of the potential defects are considered: geometric and intensity features. The third step, design a proper classifier. The classifier assigns a feature vector  Z  to one of the two classes: regular structure or defects, that are assigned "0" and "1", respectively. A good metric defining the similarity must be established. Experiments demonstrate that proposed method is fast and accurate to defects detection in CT image, and the method has high robustness for illumination.},
booktitle = {Proceedings of the Third International Conference on Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments - Volume 8518},
pages = {446–454},
numpages = {9},
keywords = {Histograms of gradients, Feature extraction, Defect detection, CT image}
}

@inproceedings{10.1007/978-3-030-30949-7_28,
author = {Farooq, Basit and Bao, Jinsong},
title = {Machine Learning Method for Spinning Cyber-Physical Production System Subject to Condition Monitoring},
year = {2019},
isbn = {978-3-030-30948-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30949-7_28},
doi = {10.1007/978-3-030-30949-7_28},
abstract = {Digitalization encapsulates the importance of machine condition monitoring which is subjected to predictive analytics for realizing significant improvements in the performance and reliability of rotating equipment i.e., spinning. This paper presents a machine learning approach for condition monitoring, based on a regularized deep neural network using automated diagnostics for spinning manufacturing. This article contributes a solution to find disturbances in a running system through real-time data sensing and signal to process via industrial internet of things. Because this controlled sensor network may comprise on different critical components of the same type of machines, therefore back propagation neural network based multi-sensor performance assessment and prediction strategy were developed for our system which worked as intelligent maintenance and diagnostic system. It is completely automatic requiring no manual extraction of handcrafted features.},
booktitle = {Cooperative Design, Visualization, and Engineering: 16th International Conference, CDVE 2019, Mallorca, Spain, October 6–9, 2019, Proceedings},
pages = {244–253},
numpages = {10},
keywords = {Spinning, Prognostics and health management, Machine learning, Condition monitoring, Cyber-physical production system},
location = {Mallorca, Spain}
}

@inproceedings{10.5555/1881763.1881787,
author = {Liu, Guang-Jie and Wang, Wen-Yong},
title = {Research an educational software defect prediction model based on SVM},
year = {2010},
isbn = {3642145329},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We must pay attention and find defects, defects through the prediction to quantify the quality management and quality in order to achieve this goal, requires an estimate of the various defect detection process. Software defects are the departure of software are products' anticipative function. This paper collecting the data of the software defects, then, using the SVM model the predictive values are gained analyzing the predictive results, software are organizations can improve software control measure software process and allocate testing resources effectively.},
booktitle = {Proceedings of the Entertainment for Education, and 5th International Conference on E-Learning and Games},
pages = {215–222},
numpages = {8},
keywords = {software lifecycle, software defect, educational software, SVM},
location = {Changchun, China},
series = {Edutainment'10}
}

@inproceedings{10.1007/978-3-319-30285-0_13,
author = {Williams, Christopher D. and Paul, Manoranjan and Debnath, Tanmoy},
title = {Enhancing Automated Defect Detection in Collagen Based Manufacturing by Employing a Smart Machine Vision Technique},
year = {2015},
isbn = {978-3-319-30284-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-30285-0_13},
doi = {10.1007/978-3-319-30285-0_13},
abstract = {Machine vision is now being extensively used for defect detection in the manufacturing process of collagen-based products such as sausage skins. At present the industry standard is to use a LabView software environment to manage and detect any defects in the collagen skins. Available data corroborates that this method allows for false positives to appear in the results which is responsible for reducing the overall system performance and resulting wastage of resources. Hence novel criteria were added to enhance the current techniques. The proposed improvements aim to achieve a higher accuracy and flexibility in detecting both true and false positives by utilizing a function that probes for the color deviation and fluctuation in the collagen skins. After implementation of the method in a well-known Australian company, investigational results demonstrate an average 26&nbsp;% increase in the ability to detect false positives with a corresponding substantial reduction in operating cost.},
booktitle = {Image and Video Technology – PSIVT 2015 Workshops: RV 2015, GPID 2013, VG 2015, EO4AS 2015, MCBMIIA 2015, and VSWS 2015, Auckland, New Zealand, November 23-27, 2015. Revised Selected Papers},
pages = {155–166},
numpages = {12},
keywords = {Robot vision, Defect detection, Collagen, Machine vision},
location = {Auckland, New Zealand}
}

@article{10.1007/s00521-016-2437-y,
author = {Chatterjee, S. and Nigam, S. and Roy, A.},
title = {Software fault prediction using neuro-fuzzy network and evolutionary learning approach},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2437-y},
doi = {10.1007/s00521-016-2437-y},
abstract = {In the real world, a great deal of information is provided by human experts that normally do not conform to the rules of physics, but describe the complicated systems by a set of incomplete or vague statements. The need of conducting uncertainty analysis in software reliability for the large and complex system is demanding. For large complex systems made up of many components, the uncertainty of each individual parameter amplifies the uncertainty of the total system reliability. In this paper, to overcome with the problem of uncertainty in software development process and environment, a neuro-fuzzy modeling has been proposed for software fault prediction. The training of the proposed neuro-fuzzy model has been done with genetic algorithm and back-propagation learning algorithm. The proposed model has been validated using some real software failure data. The efficiency of the two learning algorithms has been compared with various fuzzy and statistical time series-based forecasting algorithms on the basis of their prediction ability.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {1221–1231},
numpages = {11},
keywords = {Software reliability, Genetic algorithm, Fuzzy neural network, Faults}
}

@article{10.1007/s00521-013-1442-7,
author = {Xie, Liangjun and Huang, Rui and Gu, Nong and Cao, Zhiqiang},
title = {A novel defect detection and identification method in optical inspection},
year = {2014},
issue_date = {June      2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {7–8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-013-1442-7},
doi = {10.1007/s00521-013-1442-7},
abstract = {Optical inspection techniques have been widely used in industry as they are non-destructive. Since defect patterns are rooted from the manufacturing processes in semiconductor industry, efficient and effective defect detection and pattern recognition algorithms are in great demand to find out closely related causes. Modifying the manufacturing processes can eliminate defects, and thus to improve the yield. Defect patterns such as rings, semicircles, scratches, and clusters are the most common defects in the semiconductor industry. Conventional methods cannot identify two scale-variant or shift-variant or rotation-variant defect patterns, which in fact belong to the same failure causes. To address these problems, a new approach is proposed in this paper to detect these defect patterns in noisy images. First, a novel scheme is developed to simulate datasets of these 4 patterns for classifiers' training and testing. Second, for real optical images, a series of image processing operations have been applied in the detection stage of our method. In the identification stage, defects are resized and then identified by the trained support vector machine. Adaptive resonance theory network 1 is also implemented for comparisons. Classification results of both simulated data and real noisy raw data show the effectiveness of our method.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {1953–1962},
numpages = {10},
keywords = {Support vector machine, Optical inspection, Defect detection, Classification, Adaptive resonance theory network}
}

@article{10.1007/s10845-020-01570-5,
author = {Xu, Chengjun and Zhu, Guobin},
title = {Intelligent manufacturing Lie Group Machine Learning: real-time and efficient inspection system based on fog computing},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01570-5},
doi = {10.1007/s10845-020-01570-5},
abstract = {Due to the improvement of network infrastructure and the application of Internet of Things equipment, a large number of sensors are deployed in the industrial pipeline production, and the large size of data is generated. The most typical case in the production line is product inspection, that is, defect inspection. To implement an efficient and robust detection system, in this study, we propose a classification computing model based on Lie Group Machine Learning, which can find the possible defective products in production. Usually, a workshop has a lot of assembly lines. How to process large data on so many production lines in real-time and accurately is a difficult problem. To solve this problem, we use the concept of fog computing to design the system. By offloading the computation burden from the cloud server center to the fog nodes, the system obtains the ability to deal with extremely data. Our system has two obvious advantages. The first one is to apply Lie Group Machine Learning to fog computing environment to improve the computational efficiency and robustness of the system. The other is that without increasing any production costs, it can quickly detect products, reduce network latency, and reduce the load on bandwidth. The simulations prove that, compared with the existing methods, the proposed method has an average running efficiency increase of 52.57%, an average delay reduction of 42.13%, and an average accuracy increase of 27.86%.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {237–249},
numpages = {13},
keywords = {Inspection system, Fog computing, Lie group intrinsic mean, Lie Group Machine Learning}
}

@inproceedings{10.1007/978-3-319-25945-1_9,
author = {Altinger, Harald and Herbold, Steffen and Grabowski, Jens and Wotawa, Franz},
title = {Novel Insights on Cross Project Fault Prediction Applied to Automotive Software},
year = {2015},
isbn = {9783319259444},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-25945-1_9},
doi = {10.1007/978-3-319-25945-1_9},
abstract = {Defect prediction is a powerful tool that greatly helps focusing quality assurance efforts during development. In the case of the availability of fault data from a particular context, there are different ways of using such fault predictions in practice. Companies like Google, Bell Labs and Cisco make use of fault prediction, whereas its use within automotive industry has not yet gained a lot of attraction, although, modern cars require a huge amount of software to operate. In this paper, we want to contribute the adoption of fault prediction techniques for automotive software projects. Hereby we rely on a publicly available data set comprising fault data from three automotive software projects. When learning a fault prediction model from the data of one particular project, we achieve a remarkably high and nearly perfect prediction performance for the same project. However, when applying a cross-project prediction we obtain rather poor results. These results are rather surprising, because of the fact that the underlying projects are as similar as two distinct projects can possibly be within a certain application context. Therefore we investigate the reasons behind this observation through correlation and factor analyses techniques. We further report the obtained findings and discuss the consequences for future applications of Cross-Project Fault Prediction CPFP in the domain of automotive software.},
booktitle = {Proceedings of the 27th IFIP WG 6.1 International Conference on Testing Software and Systems - Volume 9447},
pages = {141–157},
numpages = {17},
keywords = {Project fault prediction, Principal component analysis, Cross project fault prediction, Automotive},
location = {Sharjah and Dubai, United Arab Emirates},
series = {ICTSS 2015}
}

@inproceedings{10.1109/BWCCA.2010.126,
author = {Chang, Chuan-Yu and Li, Shang-Cheng and Chung, Pau-Choo and Kuo, Jui-Yi and Tu, Yung-Chin},
title = {Automatic Facial Skin Defect Detection System},
year = {2010},
isbn = {9780769542362},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/BWCCA.2010.126},
doi = {10.1109/BWCCA.2010.126},
abstract = {Skin analysis is one of the most important procedures before medical cosmetology. Most conventional skin analysis systems are semi-automatic. They often require human intervention. In this study, an automatic facial skin defect detection approach is proposed. The system first detects human face in the facial image. Based on the detected face, facial features are extracted to locate regions of interest. Then, a pattern recognition approach is applied to detect facial skin defects, such as spots and wrinkles, in the regions of interest. For a specific kind of defect, a classifier is designed to provide higher performance for recognition. Using few features extracted from the region of interest, the proposed approach can successfully detect the skin defects. Experimental results demonstrate effectiveness of the proposed approach.},
booktitle = {Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications},
pages = {527–532},
numpages = {6},
keywords = {facial skin defect detection, wrinkle, spot},
series = {BWCCA '10}
}

@inproceedings{10.1109/ASP-DAC47756.2020.9045391,
author = {Yang, Chaofei and Li, Hai and Chen, Yiran and Hu, Jiang},
title = {Enhancing Generalization of Wafer Defect Detection by Data Discrepancy-Aware Preprocessing and Contrast-Varied Augmentation},
year = {2020},
isbn = {9781728141237},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC47756.2020.9045391},
doi = {10.1109/ASP-DAC47756.2020.9045391},
abstract = {Wafer inspection locates defects at early fabrication stages and traditionally focuses on pixel-level defects. However, there are very few solutions that can effectively detect large-scale defects. In this work, we leverage Convolutional Neural Networks (CNNs) to automate the wafer inspection process and propose several techniques to preprocess and augment wafer images for enhancing our model's generalization on unseen wafers (e.g., from other fabs). Cross-fab experimental results of both wafer-level and pixel-level detections show that the F1 score increases from 0.09 to 0.77 and the Precision-Recall area under curve (PR AUC) increases from 0.03 to 0.62 using our proposed method.},
booktitle = {Proceedings of the 25th Asia and South Pacific Design Automation Conference},
pages = {145–150},
numpages = {6},
location = {Beijing, China},
series = {ASPDAC '20}
}

@inproceedings{10.1007/978-3-030-68787-8_33,
author = {Kajatin, Roland and Nalpantidis, Lazaros},
title = {Image Segmentation of Bricks in Masonry Wall Using a Fusion of Machine Learning Algorithms},
year = {2021},
isbn = {978-3-030-68786-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68787-8_33},
doi = {10.1007/978-3-030-68787-8_33},
abstract = {Autonomous mortar raking requires a computer vision system which is able to provide accurate segmentation masks of close-range images of brick walls. The goal is to detect and ultimately remove the mortar, leaving the bricks intact, thus automating this construction-related task. This paper proposes such a vision system based on the combination of machine learning algorithms. The proposed system fuses the individual segmentation outputs of eight classifiers by means of a weighted voting scheme and then performing a threshold operation to generate the final binary segmentation. A novel feature of this approach is the fusion of several segmentations using a low-cost commercial off-the-shelf hardware setup. The close-range brick wall segmentation capabilities of the system are demonstrated on a total of about 9 million data points.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10-15, 2021, Proceedings, Part VII},
pages = {446–461},
numpages = {16},
keywords = {Deep learning, Machine learning, Construction robotics, Image segmentation}
}

@article{10.4018/IJSSCI.2016070102,
author = {Rashid, Ekbal},
title = {R4 Model for Case-Based Reasoning and Its Application for Software Fault Prediction},
year = {2016},
issue_date = {July 2016},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {3},
issn = {1942-9045},
url = {https://doi.org/10.4018/IJSSCI.2016070102},
doi = {10.4018/IJSSCI.2016070102},
abstract = {Making R4 model effective and efficient I have introduced some new features, i.e., renovation of knowledgebase KBS and reducing the maintenance cost by removing the duplicate record from the KBS. Renovation of knowledgebase is the process of removing duplicate record stored in knowledgebase and adding world new problems along with world new solutions. This paper explores case-based reasoning and its applications for software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The system predicts the error level with respect to LOC and with respect to development time, and both affects the quality level. This paper also reviews four existing models of case-based reasoning CBR. The paper presents a work in which I have expanded our previous work Rashid et al., 2012. I have used different similarity measures to find the best method that increases reliability. The present work is also credited through introduction of some new terms like coefficient of efficiency, i.e., developer's ability.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = jul,
pages = {19–38},
numpages = {20},
keywords = {Software Fault Prediction, Similarity Function, Reliability, Machine Learning, LOC, Development Time}
}

@article{10.1155/2020/6688075,
author = {Naseem, Rashid and Khan, Bilal and Ahmad, Arshad and Almogren, Ahmad and Jabeen, Saima and Hayat, Bashir and Shah, Muhammad Arif and Uddin, M. Irfan},
title = {Investigating Tree Family Machine Learning Techniques for a Predictive System to Unveil Software Defects},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/6688075},
doi = {10.1155/2020/6688075},
abstract = {Software defects prediction at the initial period of the software development life cycle remains a critical and important assignment. Defect prediction and correctness leads to the assurance of the quality of software systems and has remained integral to study in the previous years. The quick forecast of imperfect or defective modules in software development can serve the development squad to use the existing assets competently and effectively to provide remarkable software products in a given short timeline. Hitherto, several researchers have industrialized defect prediction models by utilizing statistical and machine learning techniques that are operative and effective approaches to pinpoint the defective modules. Tree family machine learning techniques are well-thought-out to be one of the finest and ordinarily used supervised learning methods. In this study, different tree family machine learning techniques are employed for software defect prediction using ten benchmark datasets. These techniques include Credal Decision Tree (CDT), Cost-Sensitive Decision Forest (CS-Forest), Decision Stump (DS), Forest by Penalizing Attributes (Forest-PA), Hoeffding Tree (HT), Decision Tree (J48), Logistic Model Tree (LMT), Random Forest (RF), Random Tree (RT), and REP-Tree (REP-T). Performance of each technique is evaluated using different measures, i.e., mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), root relative squared error (RRSE), specificity, precision, recall, F-measure (FM), G-measure (GM), Matthew’s correlation coefficient (MCC), and accuracy. The overall outcomes of this paper suggested RF technique by producing best results in terms of reducing error rates as well as increasing accuracy on five datasets, i.e., AR3, PC1, PC2, PC3, and PC4. The average accuracy achieved by RF is 90.2238%. The comprehensive outcomes of this study can be used as a reference point for other researchers. Any assertion concerning the enhancement in prediction through any new model, technique, or framework can be benchmarked and verified.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@article{10.1016/j.jksuci.2014.12.008,
author = {Goyal, Rinkaj and Chandra, Pravin and Singh, Yogesh},
title = {Fuzzy inferencing to identify degree of interaction in the development of fault prediction models},
year = {2017},
issue_date = {January 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {29},
number = {1},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2014.12.008},
doi = {10.1016/j.jksuci.2014.12.008},
abstract = {The software fault prediction models, based on different modeling techniques have been extensively researched to improve software quality for the last three decades. Out of the analytical techniques used by the researchers, fuzzy modeling and its variants are bringing out a major share of the attention of research communities. In this work, we demonstrate the models developed through data driven fuzzy inference system. A comprehensive set of rules induced by such an inference system, followed by a simplification process provides deeper insight into the linguistically identified level of interaction. This work makes use of a publicly available data repository for four software modules, advocating the consideration of compound effects in the model development, especially in the area of software measurement.One related objective is the identification of influential metrics in the development of fault prediction models. A fuzzy rule intrinsically represents a form of interaction between fuzzified inputs. Analysis of these rules establishes that Low and NOT (High) level of inheritance based metrics significantly contributes to the F-measure estimate of the model. Further, the Lack of Cohesion of Methods (LCOM) metric was found insignificant in this empirical study.},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = jan,
pages = {93–102},
numpages = {10},
keywords = {Software fault prediction, Object oriented metrics, Influential metrics, Fuzzy inference system}
}

@inproceedings{10.5555/2045921.2045933,
author = {Sun, Jing and Zhou, Zhiyu},
title = {Fabric defect detection based on computer vision},
year = {2011},
isbn = {9783642238956},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Broken ends, missing picks, oil stain and holes are the most common fabric defects. To deal with the situation that manual fabric detection will affected by the subjective factors of inspectors, an automatic computer vision based fabric defect detection method is introduced in this paper. The system uses threshold segmentation method to identify if there are any defects existed in the fabric, adopts image feature based approach to recognize oil stain and holes, and uses training based technique to detect broken ends and missing picks. Experimental results show that the proposed approach has the advantage of easy implementation, high inspection speed, good noise immunity, greatly meeting the needs for automatic fabric defect inspection.},
booktitle = {Proceedings of the Third International Conference on Artificial Intelligence and Computational Intelligence - Volume Part III},
pages = {86–91},
numpages = {6},
keywords = {fabric detect, computer vision, automatic detection},
location = {Taiyuan, China},
series = {AICI'11}
}

@inproceedings{10.1109/MVHI.2010.210,
author = {Xie, Shipeng},
title = {Hypercomplex Correlation for Defect Detection},
year = {2010},
isbn = {9780769540092},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MVHI.2010.210},
doi = {10.1109/MVHI.2010.210},
abstract = {The normalized cross correlation (NCC) has been used extensively in machine vision for industrial inspection, but the traditional NCC suffers from false alarms for a complicated image that contains partial uniform regions. In this paper, new algorithms of hypercomplex correlation are proposed. We set up a color object model in hypercomplex domain, which provides integrated color characteristics of the object. The proposed hypercomplex correlation in color image can effectively alleviate false alarms in defect detection applications.},
booktitle = {Proceedings of the 2010 International Conference on Machine Vision and Human-Machine Interface},
pages = {3–5},
numpages = {3},
keywords = {Nomalized cross correlation, Hypercomplex Corrlation, Defect detection},
series = {MVHI '10}
}

@article{10.1155/2019/4368036,
author = {Deli\'{c}, Vlado and Peri\'{c}, Zoran and Se\v{c}ujski, Milan and Jakovljevi\'{c}, Nik\v{s}a and Nikoli\'{c}, Jelena and Mi\v{s}kovi\'{c}, Dragi\v{s}a and Simi\'{c}, Nikola and Suzi\'{c}, Sini\v{s}a and Deli\'{c}, Tijana and Gastaldo, Paolo},
title = {Speech Technology Progress Based on New Machine Learning Paradigm},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1687-5265},
url = {https://doi.org/10.1155/2019/4368036},
doi = {10.1155/2019/4368036},
abstract = {Speech technologies have been developed for decades as a typical signal processing area, while the last decade has brought a huge progress based on new machine learning paradigms. Owing not only to their intrinsic complexity but also to their relation with cognitive sciences, speech technologies are now viewed as a prime example of interdisciplinary knowledge area. This review article on speech signal analysis and processing, corresponding machine learning algorithms, and applied computational intelligence aims to give an insight into several fields, covering speech production and auditory perception, cognitive aspects of speech communication and language understanding, both speech recognition and text-to-speech synthesis in more details, and consequently the main directions in development of spoken dialogue systems. Additionally, the article discusses the concepts and recent advances in speech signal compression, coding, and transmission, including cognitive speech coding. To conclude, the main intention of this article is to highlight recent achievements and challenges based on new machine learning paradigms that, over the last decade, had an immense impact in the field of speech signal processing.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@article{10.1007/s11219-011-9156-5,
author = {Roos-Frantz, Fabricia and Benavides, David and Ruiz-Cort\'{e}s, Antonio and Heuer, Andr\'{e} and Lauenroth, Kim},
title = {Quality-aware analysis in product line engineering with the orthogonal variability model},
year = {2012},
issue_date = {September 2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {3–4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9156-5},
doi = {10.1007/s11219-011-9156-5},
abstract = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e.g., CPU and memory consumption) and constraints on these attributes (e.g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e.g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i.e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e.g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions.},
journal = {Software Quality Journal},
month = sep,
pages = {519–565},
numpages = {47},
keywords = {Software product lines, Quality-aware analysis, Quality modelling, Orthogonal variability model, Automated analysis}
}

@inproceedings{10.5555/2404411.2404426,
author = {Gao, Jian and Wang, Zhiliang and Liu, Yanyun and Jian, Chuanxia and Chen, Xin},
title = {Development of OLED panel defect detection system through improved otsu algorithm},
year = {2012},
isbn = {9783642335143},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {OLED (Organic light-emitting) displays have been called the next generation of display devices for their unique properties: colorful images, large viewing angle, light weight and power efficiency. Complex manufacture processing makes the screen have some defects. Detecting the defects will help to improve the quality. In this paper we concentrate on detecting these defects and proposed a corner-points based method, where the corner-points are extracted from the skeleton image and used as the control points for the subtract operation. We proposed an improved Otsu method to determine the image segmentation threshold by recursive process. Based on the algorithm proposed, a system for OLED screen defect detection was developed. The test result shows that the developed system can detect most of the defects on the panel.},
booktitle = {Proceedings of the 5th International Conference on Intelligent Robotics and Applications - Volume Part II},
pages = {127–134},
numpages = {8},
keywords = {subtraction operation, image segmentation, defect detection, Otsu method, OLED panel},
location = {Montreal, QC, Canada},
series = {ICIRA'12}
}

@article{10.1155/2021/6612342,
author = {Li, Yao and Dourado, Ant\'{o}nio},
title = {A Fault Prediction and Cause Identification Approach in Complex Industrial Processes Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/6612342},
doi = {10.1155/2021/6612342},
abstract = {Faults occurring in the production line can cause many losses. Predicting the fault events before they occur or identifying the causes can effectively reduce such losses. A modern production line can provide enough data to solve the problem. However, in the face of complex industrial processes, this problem will become very difficult depending on traditional methods. In this paper, we propose a new approach based on a deep learning (DL) algorithm to solve the problem. First, we regard these process data as a spatial sequence according to the production process, which is different from traditional time series data. Second, we improve the long short-term memory (LSTM) neural network in an encoder-decoder model to adapt to the branch structure, corresponding to the spatial sequence. Meanwhile, an attention mechanism (AM) algorithm is used in fault detection and cause identification. Third, instead of traditional biclassification, the output is defined as a sequence of fault types. The approach proposed in this article has two advantages. On the one hand, treating data as a spatial sequence rather than a time sequence can overcome multidimensional problems and improve prediction accuracy. On the other hand, in the trained neural network, the weight vectors generated by the AM algorithm can represent the correlation between faults and the input data. This correlation can help engineers identify the cause of faults. The proposed approach is compared with some well-developed fault diagnosing methods in the Tennessee Eastman process. Experimental results show that the approach has higher prediction accuracy, and the weight vector can accurately label the factors that cause faults.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {sampling, machine learning, data analysis, Data imbalance}
}

@article{10.1007/s11042-017-4419-1,
author = {Singh, Sandip Kumar and Kumar, Sandeep and Dwivedi, J. P.},
title = {Compound fault prediction of rolling bearing using multimedia data},
year = {2017},
issue_date = {Sep 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {18},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-4419-1},
doi = {10.1007/s11042-017-4419-1},
abstract = {Catastrophic failure of mechanical systems due to faults occurring on rolling bearing is still a great challenge. These faults, which are of multiple type, are compounded in nature. Vibration analysis of multimedia signals is one of the most effective techniques for the health monitoring of these bearings. A compound fault signal usually consists of multiple characteristic signals and strong confusion noise, which makes it a tough task to separate weak fault signals from them. To resolve the compound fault diagnosis problem of rolling bearings byseparation of multimedia signals' (obtained from acoustic or acceleration sensors), ensemble empirical mode decomposition (EEMD) method along with some classifier (like independent component analysis (ICA) technique) has been used to some degree of success. But, they are not found capable of detecting difficult faults existing on small balls of the bearing. In order to solve this problem, we are going to propose a new method based on use of Combined Mode Functions (CMF) for selecting the intrinsic mode functions(IMFs) instead of the maximum cross correlation coefficient based EEMD technique, sandwiched with, Convolution Neural Networks (CNN), which are deep neural nets, used as fault classifiers. This composite CNN-CMF-EEMD methodovercomes the deficiencies of other approaches, such as the inability to learn the complex non-linear relationships in fault diagnosis issues and fine compound faults like those occurring on small balls of the bearing. The difficult compound faults can be separated effectively by executing CNN-CMF-EEMD method, which makes the fault features more easily extracted and more clearly identified. Experimental results reinforce the effectiveness of using CNN-CMF--EEMD technique for fine compound faults. A comparison of CNN-CMF-EEMD with Artificial Neural Networks (ANN) based ANN-CMF-EEMD shows the capability of CNN as a powerful classifier in the domain of compound fault features of rolling bearing.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {18771–18788},
numpages = {18},
keywords = {Multimedia signals, Intrinsic mode functions, Independent component analysis, Ensemble empirical mode distribution, Convolution neural network, Compound faults, Combined mode functions, Artificial neural networks}
}

@inproceedings{10.1145/1868328.1868350,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {On the value of learning from defect dense components for software defect prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868350},
doi = {10.1145/1868328.1868350},
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects.AIMS: To improve those learners by focusing on the defect-rich portions of the training sets.METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment.RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4--5 times more often than any other method, and also lost the least amount of times.CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {14},
numpages = {9},
keywords = {ceiling effect, defect dense components, defect prediction, sampling},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@article{10.1007/s00500-016-2284-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of some software fault prediction techniques for the number of faults prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2284-x},
doi = {10.1007/s00500-016-2284-x},
abstract = {During the software development process, prediction of the number of faults in software modules can be more helpful instead of predicting the modules being faulty or non-faulty. Such an approach may help in more focused software testing process and may enhance the reliability of the software system. Most of the earlier works on software fault prediction have used classification techniques for classifying software modules into faulty or non-faulty categories. The techniques such as Poisson regression, negative binomial regression, genetic programming, decision tree regression, and multilayer perceptron can be used for the prediction of the number of faults. In this paper, we present an experimental study to evaluate and compare the capability of six fault prediction techniques such as genetic programming, multilayer perceptron, linear regression, decision tree regression, zero-inflated Poisson regression, and negative binomial regression for the prediction of number of faults. The experimental investigation is carried out for eighteen software project datasets collected from the PROMISE data repository. The results of the investigation are evaluated using average absolute error, average relative error, measure of completeness, and prediction at level l measures. We also perform Kruskal---Wallis test and Dunn's multiple comparison test to compare the relative performance of the considered fault prediction techniques.},
journal = {Soft Comput.},
month = dec,
pages = {7417–7434},
numpages = {18},
keywords = {Zero-inflated Poisson regression, Software fault prediction, Multilayer perceptron, Kruskal---Wallis test, Genetic programming, Dunn's multiple comparison test}
}

@article{10.1016/j.compag.2020.105332,
author = {Nguyen, Van-Tho and Constant, Thi\'{e}ry and Kerautret, Bertrand and Debled-Rennesson, Isabelle and Colin, Francis},
title = {A machine-learning approach for classifying defects on tree trunks using terrestrial LiDAR},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {171},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2020.105332},
doi = {10.1016/j.compag.2020.105332},
journal = {Comput. Electron. Agric.},
month = apr,
numpages = {12},
keywords = {Standing tree grading, Random forests, Roundwood quality}
}

@article{10.1016/j.infsof.2019.01.008,
author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
title = {Mining software repositories for adaptive change commits using machine learning techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.008},
doi = {10.1016/j.infsof.2019.01.008},
journal = {Inf. Softw. Technol.},
month = may,
pages = {80–91},
numpages = {12},
keywords = {Machine learning, Maintenance classification, Commit types, Adaptive maintenance, Code change metrics}
}

@article{10.1016/j.ins.2010.04.019,
author = {Peng, Yi and Wang, Guoxun and Wang, Honggang},
title = {User preferences based software defect detection algorithms selection using MCDM},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2010.04.019},
doi = {10.1016/j.ins.2010.04.019},
abstract = {A variety of classification algorithms for software defect detection have been developed over the years. How to select an appropriate classifier for a given task is an important issue in Data mining and knowledge discovery (DMKD). Many studies have compared different types of classification algorithms and the performances of these algorithms may vary using different performance measures and under different circumstances. Since the algorithm selection task needs to examine several criteria, such as accuracy, computational time, and misclassification rate, it can be modeled as a multiple criteria decision making (MCDM) problem. The goal of this paper is to use a set of MCDM methods to rank classification algorithms, with empirical results based on the software defect detection datasets. Since the preferences of the decision maker (DM) play an important role in algorithm evaluation and selection, this paper involved the DM during the ranking procedure by assigning user weights to the performance measures. Four MCDM methods are examined using 38 classification algorithms and 13 evaluation criteria over 10 public-domain software defect datasets. The results indicate that the boosting of CART and the boosting of C4.5 decision tree are ranked as the most appropriate algorithms for software defect datasets. Though the MCDM methods provide some conflicting results for the selected software defect datasets, they agree on most top-ranked classification algorithms.},
journal = {Inf. Sci.},
month = may,
pages = {3–13},
numpages = {11},
keywords = {Software defect detection, Multi-criteria decision making (MCDM), Knowledge-driven data mining, Classification algorithm, Algorithm selection}
}

@inproceedings{10.1109/COMPSAC.2014.66,
author = {Liu, Shulong and Chen, Xiang and Liu, Wangshu and Chen, Jiaqiang and Gu, Qing and Chen, Daoxu},
title = {FECAR: A Feature Selection Framework for Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.66},
doi = {10.1109/COMPSAC.2014.66},
abstract = {Software defect prediction can classify new software entities into either buggy or clean. However the effectiveness of existing methods is influenced by irrelevant and redundant features. In this paper, we propose a new feature selection framework FECAR using Feature Clustering And feature Ranking. This framework firstly partitions original features into k clusters based on FF-Correlation measure. Then it selects relevant features from each cluster based on FC-Relevance measure. In empirical study, we choose Symmetric Uncertainty as FF-Correlation measure, and choose Information Gain, Chi-Square, and Relief as three different FC-Relevance measures. Based on some real projects Eclipse and NASA, we implemented our framework and performed empirical studies to investigate the redundancy rate and the performance of the trained defect predictors. Final results verify the effectiveness of our proposed framework and further provide a guideline for achieving cost-effective feature selection when using our framework.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {426–435},
numpages = {10},
keywords = {Software Defect Prediction, Feature Selection, Feature Clustering, Feature Ranking},
series = {COMPSAC '14}
}

@article{10.3233/IDT-170323,
author = {Nguyen, T.H. and Nguyen, T.L. and Sidorov, D.N. and Dreglea, A.I. and Vasant, Pandian and Kose, Utku},
title = {Machine learning algorithms application to road defects classification},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {12},
number = {1},
issn = {1872-4981},
url = {https://doi.org/10.3233/IDT-170323},
doi = {10.3233/IDT-170323},
abstract = {The novel approach for automatic detection and classification of road defects is proposed based on shape and texture features analysis. The system includes three main steps: defects position detection, feature contour extraction followed by classification of defects. The proposed approach is implemented in Matlab for automatic detection and classification of defects based on digital images analysis combined with machine learning algorithms such as the random forest algorithm and boosting. Segmentation is implemented using graph-cuts method and Markov random fields. The efficiency of proposed approach is demonstrated on the real data set.},
journal = {Int. Dec. Tech.},
month = jan,
pages = {59–66},
numpages = {8},
keywords = {boosting algorithm, a random forest algorithm, graph-cuts method, Markov random fields, pavement condition, Road defects}
}

@article{10.1145/3212695,
author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
title = {A Survey of Machine Learning for Big Code and Naturalness},
year = {2018},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3212695},
doi = {10.1145/3212695},
abstract = {Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {81},
numpages = {37},
keywords = {software engineering tools, machine learning, code naturalness, Big code}
}

@article{10.1007/s00500-021-06086-5,
author = {Cao, Minh-Tu and Chang, Kuan-Tsung and Nguyen, Ngoc-Mai and Tran, Van-Duc and Tran, Xuan-Linh and Hoang, Nhat-Duc},
title = {Image processing-based automatic detection of asphalt pavement rutting using a novel metaheuristic optimized machine learning approach},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06086-5},
doi = {10.1007/s00500-021-06086-5},
abstract = {Pavement rutting refers to surface depression in the wheel-path along an asphalt road which causes loss of steering control and consequently leads to serious traffic accidents. Hence, it is necessary to develop powerful methods to accurately recognize pavement rutting during road condition survey. This study presents a novel computer vision-based model to automatically identify rutting on asphalt pavement road. The model is established based on a hybridization of image processing techniques (ITPs), least squares support vector classification (LSSVC), dynamic feature selection (FS) method, and forensic-based investigation (FBI). The ITPs, including Gabor filter and discrete cosine transform were employed to implement texture computation for image data. These techniques are used to generate an initial set of extracted features describing rutting and non-rutting states. The extracted features were then refined by a wrapper-based feature selection (FS) method to determine set of highly relevant features. LSSVC models were used to learn the categorization of rutting and non-rutting based on the refined features and hyper-parameters optimized by the FBI metaheuristic. The final LSSVC prediction model with the most desired prediction accuracy can be obtained once the process of the FBI’s optimization terminates. A dataset of 2000 image samples has been collected during field trip of pavement survey in Da Nang city (Vietnam) to construct and evaluate the newly developed model. The statistical results obtained from a k-fold cross-validation have demonstrated that the hybrid FBI-LSSVC-FS model can achieve the most desired rutting recognition performance with accuracy rate, precision, recall, and F1 score of 98.9%, 0.994, 0.984 and 0.989, respectively. Therefore, this paper contributes to the body of knowledge by proposing a novel AI-based prediction model to assist transportation agencies in the task of periodic asphalt pavement survey.},
journal = {Soft Comput.},
month = oct,
pages = {12839–12855},
numpages = {17},
keywords = {Image processing, Feature selection, Forensic-based investigation, Least squares support vector machine, Rutting detection}
}

@article{10.1016/j.infsof.2008.04.008,
author = {Chang, Ching-Pao and Chu, Chih-Ping and Yeh, Yu-Fang},
title = {Integrating in-process software defect prediction with association mining to discover defect pattern},
year = {2009},
issue_date = {February, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.008},
doi = {10.1016/j.infsof.2008.04.008},
abstract = {Rather than detecting defects at an early stage to reduce their impact, defect prevention means that defects are prevented from occurring in advance. Causal analysis is a common approach to discover the causes of defects and take corrective actions. However, selecting defects to analyze among large amounts of reported defects is time consuming, and requires significant effort. To address this problem, this study proposes a defect prediction approach where the reported defects and performed actions are utilized to discover the patterns of actions which are likely to cause defects. The approach proposed in this study is adapted from the Action-Based Defect Prediction (ABDP), an approach uses the classification with decision tree technique to build a prediction model, and performs association rule mining on the records of actions and defects. An action is defined as a basic operation used to perform a software project, while a defect is defined as software flaws and can arise at any stage of the software process. The association rule mining finds the maximum rule set with specific minimum support and confidence and thus the discovered knowledge can be utilized to interpret the prediction models and software process behaviors. The discovered patterns then can be applied to predict the defects generated by the subsequent actions and take necessary corrective actions to avoid defects. The proposed defect prediction approach applies association rule mining to discover defect patterns, and multi-interval discretization to handle the continuous attributes of actions. The proposed approach is applied to a business project, giving excellent prediction results and revealing the efficiency of the proposed approach. The main benefit of using this approach is that the discovered defect patterns can be used to evaluate subsequent actions for in-process projects, and reduce variance of the reported data resulting from different projects. Additionally, the discovered patterns can be used in causal analysis to identify the causes of defects for software process improvement.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {375–384},
numpages = {10},
keywords = {Software defect prediction, Multi-interval discretization, Association rule}
}

@article{10.1016/j.eswa.2010.09.144,
author = {Si, Xiao-Sheng and Hu, Chang-Hua and Yang, Jian-Bo and Zhang, Qi},
title = {On the dynamic evidential reasoning algorithm for fault prediction},
year = {2011},
issue_date = {May, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {5},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.09.144},
doi = {10.1016/j.eswa.2010.09.144},
abstract = {Research highlights A dynamic evidential reasoning algorithm is presented for dynamic fusion. A fault prognosis model is established based on the dynamic evidential reasoning algorithm. The optimization models are presented for estimating the parameters of the prognosis model. The developed model has been validated by case studies. In this paper, a new fault prediction model is presented to deal with the fault prediction problems in the presence of both quantitative and qualitative data based on the dynamic evidential reasoning (DER) approach. In engineering practice, system performance is constantly changed with time. As such, there is a need to develop a supporting mechanism that can be used to conduct dynamic fusion with time, and establish a prediction model to trace and predict system performance. In this paper, a DER approach is first developed to realize dynamic fusion. The new approach takes account of time effect by introducing belief decaying factor, which reflects the nature that evidence credibility is decreasing over time. Theoretically, it is show that the new DER aggregation schemes also satisfy the synthesis theorems. Then a fault prediction model based on the DER approach is established and several optimization models are developed for locally training the DER prediction model. The main feature of these optimization models is that only partial input and output information is required, which can be either incomplete or vague, either numerical or judgmental, or mixed. The models can be used to fine tune the DER prediction model whose initial parameters are decided by expert's knowledge or common sense. Finally, two numerical examples are provided to illustrate the detailed implementation procedures of the proposed approach and demonstrate its potential applications in fault prediction.},
journal = {Expert Syst. Appl.},
month = may,
pages = {5061–5080},
numpages = {20},
keywords = {Utility, Nonlinear programming, Fault prediction, Dynamic evidential reasoning approach, Artificial intelligence}
}

@article{10.1007/s10845-017-1315-5,
author = {Wu, Mingtao and Song, Zhengyi and Moon, Young B.},
title = {Detecting cyber-physical attacks in CyberManufacturing systems with machine learning methods},
year = {2019},
issue_date = {Mar 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-017-1315-5},
doi = {10.1007/s10845-017-1315-5},
abstract = {CyberManufacturing system (CMS) is a vision for future manufacturing systems. The concept delineates a vision of advanced manufacturing system integrated with technologies such as Internet of Things, Cloud Computing, Sensors Network and Machine Learning. As a result, cyber-attacks such as Stuxnet attack will increase along with growing simultaneous connectivity. Now, cyber-physical attacks are new and unique risks to CMSs and modern cyber security countermeasure is not enough. To learn this new vulnerability, the cyber-physical attacks is defined via a taxonomy under the vision of CMS. Machine learning on physical data is studied for detecting cyber-physical attacks. Two examples were developed with simulation and experiments: 3D printing malicious attack and CNC milling machine malicious attack. By implementing machine learning methods in physical data, the anomaly detection algorithm reached 96.1% accuracy in detecting cyber-physical attacks in 3D printing process; random forest algorithm reached on average 91.1% accuracy in detecting cyber-physical attacks in CNC milling process.},
journal = {J. Intell. Manuf.},
month = mar,
pages = {1111–1123},
numpages = {13},
keywords = {Security, Machine learning, CyberManufacturing systems, Additive manufacturing}
}

@inproceedings{10.1109/ICMLA.2010.27,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Comparative Study of Ensemble Feature Selection Techniques for Software Defect Prediction},
year = {2010},
isbn = {9780769543000},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2010.27},
doi = {10.1109/ICMLA.2010.27},
abstract = {Feature selection has become the essential step in many data mining applications. Using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. We present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly-used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 13,600 classification models. Experimental results indicate that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
booktitle = {Proceedings of the 2010 Ninth International Conference on Machine Learning and Applications},
pages = {135–140},
numpages = {6},
keywords = {feature ranking, ensembles, defect prediction},
series = {ICMLA '10}
}

@article{10.1109/TIP.2012.2194505,
author = {Wang, Xiaosong and Mirmehdi, Majid},
title = {Archive Film Defect Detection and Removal: An Automatic Restoration Framework},
year = {2012},
issue_date = {August 2012},
publisher = {IEEE Press},
volume = {21},
number = {8},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2012.2194505},
doi = {10.1109/TIP.2012.2194505},
abstract = {In this paper, we present an automatic restoration system targeting on dirt and blotches in digitized archive films. The system is composed of mainly two modules: defect detection and defect removal. In defect detection, we locate the defects by combining temporal and spatial information across a number of frames. A hidden Markov model is trained for normal observation sequences and then applied within a framework to detect defective pixels. The resulting defect maps are refined in a two-stage false alarm elimination process and then passed over to the defect removal procedure. A labeled (degraded) pixel is restored in a multiscale framework by first searching the optimal replacement in its dynamically generated random-walk-based region of candidate pixel-exemplars and then updating all its features (intensity, motion, and texture). Finally, the proposed system is compared against the state-of-the-art methods to demonstrate improved accuracy in both detection and restoration using synthetic and real degraded image sequences.},
journal = {Trans. Img. Proc.},
month = aug,
pages = {3757–3769},
numpages = {13}
}

@inproceedings{10.1145/1868328.1868356,
author = {Matsumoto, Shinsuke and Kamei, Yasutaka and Monden, Akito and Matsumoto, Ken-ichi and Nakamura, Masahide},
title = {An analysis of developer metrics for fault prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868356},
doi = {10.1145/1868328.1868356},
abstract = {Background: Software product metrics have been widely used as independent variables for constructing a fault prediction model. However, fault injection depends not only on characteristics of the products themselves, but also on characteristics of developers involved in the project. Aims: The goal of this paper is to study the effects of developer features on software reliability. Method: This paper proposes developer metrics such as the number of code churns made by each developer, the number of commitments made by each developer and the number of developers for each module. By using the eclipse project dataset, we experimentally analyzed the relationship between the number of faults and developer metrics. Second, the effective of developer metrics for performance improvements of fault prediction models were evaluated. Results: The result revealed that the modules touched by more developer contained more faults. Compared with conventional fault prediction models, developer metrics improved the prediction performance. Conclusions: We conclude that developer metrics are good predictor of faults and we must consider the human factors for improving the software reliability.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {18},
numpages = {9},
keywords = {developer metrics, fault prediction, human factor},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@article{10.1016/j.aei.2015.01.008,
author = {Koch, Christian and Georgieva, Kristina and Kasireddy, Varun and Akinci, Burcu and Fieguth, Paul},
title = {A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure},
year = {2015},
issue_date = {April 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {29},
number = {2},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2015.01.008},
doi = {10.1016/j.aei.2015.01.008},
abstract = {Visual inspection of civil infrastructure is essential for condition assessment.We focus on concrete bridges, tunnels, underground pipes, and asphalt pavements.Accordingly, we review the latest computer vision based defect detection methods.Using computer vision most relevant types of defects can be automatically detected.Automatic defect properties retrieval and assessment has not been achieved yet. To ensure the safety and the serviceability of civil infrastructure it is essential to visually inspect and assess its physical and functional condition. This review paper presents the current state of practice of assessing the visual condition of vertical and horizontal civil infrastructure; in particular of reinforced concrete bridges, precast concrete tunnels, underground concrete pipes, and asphalt pavements. Since the rate of creation and deployment of computer vision methods for civil engineering applications has been exponentially increasing, the main part of the paper presents a comprehensive synthesis of the state of the art in computer vision based defect detection and condition assessment related to concrete and asphalt civil infrastructure. Finally, the current achievements and limitations of existing methods as well as open research challenges are outlined to assist both the civil engineering and the computer science research community in setting an agenda for future research.},
journal = {Adv. Eng. Inform.},
month = apr,
pages = {196–210},
numpages = {15},
keywords = {Infrastructure monitoring, Infrastructure, Defect detection, Condition assessment, Computer vision}
}

@article{10.1007/s10664-019-09769-8,
author = {Ochodek, Miroslaw and Hebig, Regina and Meding, Wilhelm and Frost, Gert and Staron, Miroslaw},
title = {Recognizing lines of code violating company-specific coding guidelines using machine learning: A Method and Its Evaluation},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09769-8},
doi = {10.1007/s10664-019-09769-8},
abstract = {Software developers in big and medium-size companies are working with millions of lines of code in their codebases. Assuring the quality of this code has shifted from simple defect management to proactive assurance of internal code quality. Although static code analysis and code reviews have been at the forefront of research and practice in this area, code reviews are still an effort-intensive and interpretation-prone activity. The aim of this research is to support code reviews by automatically recognizing company-specific code guidelines violations in large-scale, industrial source code. In our action research project, we constructed a machine-learning-based tool for code analysis where software developers and architects in big and medium-sized companies can use a few examples of source code lines violating code/design guidelines (up to 700 lines of code) to train decision-tree classifiers to find similar violations in their codebases (up to 3 million lines of code). Our action research project consisted of (i) understanding the challenges of two large software development companies, (ii) applying the machine-learning-based tool to detect violations of Sun’s and Google’s coding conventions in the code of three large open source projects implemented in Java, (iii) evaluating the tool on evolving industrial codebase, and (iv) finding the best learning strategies to reduce the cost of training the classifiers. We were able to achieve the average accuracy of over 99% and the average F-score of 0.80 for open source projects when using ca. 40K lines for training the tool. We obtained a similar average F-score of 0.78 for the industrial code but this time using only up to 700 lines of code as a training dataset. Finally, we observed the tool performed visibly better for the rules requiring to understand a single line of code or the context of a few lines (often allowing to reach the F-score of 0.90 or higher). Based on these results, we could observe that this approach can provide modern software development companies with the ability to use examples to teach an algorithm to recognize violations of code/design guidelines and thus increase the number of reviews conducted before the product release. This, in turn, leads to the increased quality of the final software.},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {220–265},
numpages = {46},
keywords = {Code reviews, Action research, Machine learning, Measurement}
}

@article{10.1016/j.patcog.2011.07.025,
author = {Li, Wei-Chen and Tsai, Du-Ming},
title = {Wavelet-based defect detection in solar wafer images with inhomogeneous texture},
year = {2012},
issue_date = {February, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {45},
number = {2},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2011.07.025},
doi = {10.1016/j.patcog.2011.07.025},
abstract = {Solar power is an attractive alternative source of electricity. Multicrystalline solar cells dominate the market share owing to their lower manufacturing costs. The surface quality of a solar wafer determines the conversion efficiency of the solar cell. A multicrystalline solar wafer surface contains numerous crystal grains of random shapes and sizes in random positions and directions with different illumination reflections, therefore resulting in an inhomogeneous texture in the sensed image. This texture makes the defect detection task extremely difficult. This paper proposes a wavelet-based discriminant measure for defect inspection in multicrystalline solar wafer images. The traditional wavelet transform techniques for texture analysis and surface inspection rely mainly on the discriminant features extracted in individual decomposition levels. However, these techniques cannot be directly applied to solar wafers with inhomogeneous grain patterns. The defects found in a solar wafer surface generally involve scattering and blurred edges with respect to clear and sharp edges of crystal grains in the background. The proposed method uses the wavelet coefficients in individual decomposition levels as features and the difference of the coefficient values between two consecutive resolution levels as the weights to distinguish local defects from the crystal grain background, and generates a better discriminant measure for identifying various defects in the multicrystalline solar wafers. Experimental results have shown the proposed method performs effectively for detecting fingerprint, contaminant, and saw-mark defects in solar wafer surfaces.},
journal = {Pattern Recogn.},
month = feb,
pages = {742–756},
numpages = {15},
keywords = {inhomogeneous texture, Wavelet transform, Surface inspection, Solar wafer, Defect detection}
}

@article{10.1016/j.cosrev.2021.100376,
author = {Amutha, J. and Sharma, Sandeep and Sharma, Sanjay Kumar},
title = {Strategies based on various aspects of clustering in wireless sensor networks using classical, optimization and machine learning techniques: Review, taxonomy, research findings, challenges and future directions},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100376},
doi = {10.1016/j.cosrev.2021.100376},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {43},
keywords = {Reliability, Security, Routing, Machine learning, Optimization, Wireless Sensor Networks}
}

@article{10.1155/2021/4767388,
author = {Soleymani, Ali and Arabgol, Fatemeh and Shojae Chaeikar, Saman},
title = {A Novel Approach for Detecting DGA-Based Botnets in DNS Queries Using Machine Learning Techniques},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {2090-7141},
url = {https://doi.org/10.1155/2021/4767388},
doi = {10.1155/2021/4767388},
abstract = {In today’s security landscape, advanced threats are becoming increasingly difficult to detect as the pattern of attacks expands. Classical approaches that rely heavily on static matching, such as blacklisting or regular expression patterns, may be limited in flexibility or uncertainty in detecting malicious data in system data. This is where machine learning techniques can show their value and provide new insights and higher detection rates. The behavior of botnets that use domain-flux techniques to hide command and control channels was investigated in this research. The machine learning algorithm and text mining used to analyze the network DNS protocol and identify botnets were also described. For this purpose, extracted and labeled domain name datasets containing healthy and infected DGA botnet data were used. Data preprocessing techniques based on a text-mining approach were applied to explore domain name strings with n-gram analysis and PCA. Its performance is improved by extracting statistical features by principal component analysis. The performance of the proposed model has been evaluated using different classifiers of machine learning algorithms such as decision tree, support vector machine, random forest, and logistic regression. Experimental results show that the random forest algorithm can be used effectively in botnet detection and has the best botnet detection accuracy.},
journal = {J. Comput. Netw. Commun.},
month = jan,
numpages = {13}
}

@article{10.1016/j.ins.2019.03.045,
author = {Li, Jin and Palmieri, Francesco and Xiang, Yang},
title = {Special Issue on Security and Privacy in Machine Learning},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {487},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.03.045},
doi = {10.1016/j.ins.2019.03.045},
journal = {Inf. Sci.},
month = jun,
pages = {208–209},
numpages = {2}
}

@article{10.1016/j.patrec.2006.03.009,
author = {Ng, Hui-Fuang},
title = {Automatic thresholding for defect detection},
year = {2006},
issue_date = {15 October 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {27},
number = {14},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2006.03.009},
doi = {10.1016/j.patrec.2006.03.009},
abstract = {Automatic thresholding has been widely used in the machine vision industry for automated visual inspection of defects. A commonly used thresholding technique, the Otsu method, provides satisfactory results for thresholding an image with a histogram of bimodal distribution. This method, however, fails if the histogram is unimodal or close to unimodal. For defect detection applications, defects can range from no defect to small or large defects, which means that the gray-level distributions range from unimodal to bimodal. For this paper, we revised the Otsu method for selecting optimal threshold values for both unimodal and bimodal distributions, and tested the performance of the revised method, the valley-emphasis method, on common defect detection applications.},
journal = {Pattern Recogn. Lett.},
month = oct,
pages = {1644–1649},
numpages = {6},
keywords = {Defect detection, Automatic thresholding}
}

@article{10.1007/s00138-011-0403-3,
author = {Tsai, Du-Ming and Chen, Ming-Chun and Li, Wei-Chen and Chiu, Wei-Yao},
title = {A fast regularity measure for surface defect detection},
year = {2012},
issue_date = {September 2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {5},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-011-0403-3},
doi = {10.1007/s00138-011-0403-3},
abstract = {In this paper, we propose a fast regularity measure for defect detection in non-textured and homogeneously textured surfaces, with specific emphasis on ill-defined subtle defects. A small neighborhood window of proper size is first chosen and they slide over the entire inspection image in a pixel-by-pixel basis. The regularity measure for each image patch enclosed in the window is then derived from the eigenvalues of the covariance matrix formed by the variance–covariance of the x- and y-coordinates with the pixel gray levels as the weights for all pixel points in the window. The two eigenvalues of the weighted covariance matrix will be approximately the same when the image patch contains only a homogeneous region, whereas the two eigenvalues will be relatively different if the image patch in the window contains a defect. The smaller eigenvalue of the covariance matrix is then used as the regularity measure. The integral image technique is introduced to the computation of the regularity measure so that it is invariant to the neighborhood window size. The proposed method uses only one single discrimination feature for defect detection. It avoids the use of complicated classifiers in a high-dimensional feature space, and requires no learning process from a set of defective and defect-free training samples. Experimental results on a variety of material surfaces found in industry, including textured images of plastic surfaces and leather and non-textured images of backside solar wafers and LCD backlight panels, have shown the effectiveness of the proposed regularity measure for surface defect detection. It is computationally very fast, and takes only 0.032 s for a 400 \texttimes{} 400 image on a Pentium 3.00&nbsp;GHz personal computer. In a test set of 73 backside solar wafer images involving 53 defect-free and 20 defective samples, the proposed regularity measure can correctly identify all the test images.},
journal = {Mach. Vision Appl.},
month = sep,
pages = {869–886},
numpages = {18},
keywords = {Texture analysis, Surface inspection, Integral image, Computer vision}
}

@article{10.1007/s40595-014-0028-3,
author = {Pham, Van Huy and Lee, Byung Ryong},
title = {An image segmentation approach for fruit defect detection using k-means clustering and graph-based algorithm},
year = {2015},
issue_date = {February  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {1},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-014-0028-3},
doi = {10.1007/s40595-014-0028-3},
abstract = {Machine vision has been introduced in variety of industrial applications for fruit processing, allowing the automation of tasks performed so far by human operators. Such an important task is the detection of defects present on fruit peel which helps to grade or to classify fruit quality. Image segmentation is usually the first step in detecting flaws in fruits and its result mainly affects the accuracy of the system. A diversity of methods of automatic segmentation for fruit images has been developed. In this paper, a hybrid algorithm, which is based on split and merge approach, is proposed for an image segmentation that can be used in fruit defect detection. The algorithm firstly uses k-means algorithm to split the original image into regions based on Euclidean color distance in $$L^*a^*b^*$$ L a b space to produce an over-segmentation result. Then, based on a graph representation, a merge procedure using minimum spanning tree is then taken into account to iteratively merge similar regions into new homogenous ones. This combination is an efficient approach to employ the local and global characteristic of intensities in the image. The experiment showed good results in the terms of human observation and in processing time.},
journal = {Vietnam J. of Computer Science},
month = feb,
pages = {25–33},
numpages = {9},
keywords = {K-means and graph, Image segmentation, Defect detection}
}

@inproceedings{10.1007/978-3-030-79463-7_36,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Jaskier: A Supporting Software Tool for&nbsp;Continuous Build Outcome Prediction Practice},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_36},
doi = {10.1007/978-3-030-79463-7_36},
abstract = {Continuous Defect Prediction (CDP) is an assisting software development practice that combines Software Defect Prediction (SDP) with machine learning aided modelling and continuous developer feedback. Jaskier is a set of software tools developed under the supervision and with the participation of the authors of the article that implements a lightweight version of CDP called Continuous Build Outcome Prediction (CBOP). CBOP uses classification to label the possible build results based on historical data and metrics derived from the software repository. This paper contains a detailed description of the tool that was already started to be used in the production environment of a real software project where the CBOP practice is being evaluated.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {426–438},
numpages = {13},
keywords = {Continuous integration, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/2811681.2811699,
author = {Hussain, Shahid and Keung, Jacky and Khan, Arif Ali and Bennin, Kwabena Ebo},
title = {Performance Evaluation of Ensemble Methods For Software Fault Prediction: An Experiment},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2811699},
doi = {10.1145/2811681.2811699},
abstract = {In object-oriented software development, a plethora of studies have been carried out to present the application of machine learning algorithms for fault prediction. Furthermore, it has been empirically validated that an ensemble method can improve classification performance as compared to a single classifier. But, due to the inherent differences among machine learning and data mining approaches, the classification performance of ensemble methods will be varied. In this study, we investigated and evaluated the performance of different ensemble methods with itself and base-level classifiers, in predicting the faults proneness classes. Subsequently, we used three ensemble methods AdaboostM1, Vote and StackingC with five base-level classifiers namely Naivebayes, Logistic, J48, VotedPerceptron and SMO in Weka tool. In order to evaluate the performance of ensemble methods, we retrieved twelve datasets of open source projects from PROMISE repository. In this experiment, we used k-fold (k=10) cross-validation and ROC analysis for validation. Besides, we used recall, precision, accuracy, F-value measures to evaluate the performance of ensemble methods and base-level Classifiers. Finally, we observed significant performance improvement of applying ensemble methods as compared to its base-level classifier, and among ensemble methods we observed StackingC outperformed other selected ensemble methods for software fault prediction.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {91–95},
numpages = {5},
keywords = {Weka, Performance, Measures, Ensemble Methods, Classifiers, Chidamber and Kemerer (CK) Metrics},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@inproceedings{10.1145/2365324.2365338,
author = {Bowes, David and Hall, Tracy and Gray, David},
title = {Comparing the performance of fault prediction models which report multiple performance measures: recomputing the confusion matrix},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365338},
doi = {10.1145/2365324.2365338},
abstract = {There are many hundreds of fault prediction models published in the literature. The predictive performance of these models is often reported using a variety of different measures. Most performance measures are not directly comparable. This lack of comparability means that it is often difficult to evaluate the performance of one model against another. Our aim is to present an approach that allows other researchers and practitioners to transform many performance measures of categorical studies back into a confusion matrix. Once performance is expressed in a confusion matrix alternative preferred performance measures can then be derived. Our approach has enabled us to compare the performance of 600 models published in 42 studies. We demonstrate the application of our approach on several case studies, and discuss the advantages and implications of doing this.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {109–118},
numpages = {10},
keywords = {confusion matrix, fault, machine learning},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@inproceedings{10.1109/ICRA.2016.7487573,
author = {Fujii, Hiromitsu and Yamashita, Atsushi and Asama, Hajime},
title = {Defect detection with estimation of material condition using ensemble learning for hammering test},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICRA.2016.7487573},
doi = {10.1109/ICRA.2016.7487573},
abstract = {This paper introduces a new methodology of robotic hammering inspection for the maintenance of social infrastructures. In particular, the estimation of material defect conditions, such as delamination depth of concrete, is focused upon. Development of an automated diagnosis methodology is necessary for the maintenance of superannuated social infrastructures. The hammering test, which is an efficient inspection method, has attracted considerable attention in the context of automated inspection using robots. In this study, to apply the hammering test to robotic inspection, in which material conditions of infrastructures must be diagnosed in detail, an estimation method of the defect conditions is proposed, and an integration technique of plural classifiers for improving the inspection accuracy is introduced. Furthermore, an inspection system that can decrease the influence of the mechanical running-noise is implemented. Our experimental results using concrete test pieces demonstrate the effectiveness of the proposed method; the accuracy of the defect detection and defect condition estimation was validated.},
booktitle = {2016 IEEE International Conference on Robotics and Automation (ICRA)},
pages = {3847–3854},
numpages = {8},
location = {Stockholm, Sweden}
}

@inproceedings{10.1109/ICIP.2017.8296788,
author = {Wang, Jianzhu and Li, Qingyong and Gan, Jinrui and Yu, Haomin},
title = {Fabric defect detection based on improved low-rank and sparse matrix decomposition},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICIP.2017.8296788},
doi = {10.1109/ICIP.2017.8296788},
abstract = {In this paper, we propose an effective approach to detect defects in fabrics. Based on the observation that fabric textures usually form a low-rank structure and the structure can be violated by the presence of defects, we formulate the task as a low-rank and sparse matrix decomposition problem. Moreover, the prior that defects tend to be continuous regions is considered in our model and the estimation of defect levels is properly solved by introducing an integration mechanism. Experimental results demonstrate that our proposed method can not only detect defects accurately but also have greater ability to preserve defect details than traditional approaches.},
booktitle = {2017 IEEE International Conference on Image Processing (ICIP)},
pages = {2776–2780},
numpages = {5},
location = {Beijing, China}
}

@inproceedings{10.1145/1868328.1868357,
author = {Ostrand, Thomas J. and Weyuker, Elaine J. and Bell, Robert M.},
title = {Programmer-based fault prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868357},
doi = {10.1145/1868328.1868357},
abstract = {Background: Previous research has provided evidence that a combination of static code metrics and software history metrics can be used to predict with surprising success which files in the next release of a large system will have the largest numbers of defects. In contrast, very little research exists to indicate whether information about individual developers can profitably be used to improve predictions.Aims: We investigate whether files in a large system that are modified by an individual developer consistently contain either more or fewer faults than the average of all files in the system. The goal of the investigation is to determine whether information about which particular developer modified a file is able to improve defect predictions. We also continue an earlier study to evaluate the use of counts of the number of developers who modified a file as predictors of the file's future faultiness.Method: We analyzed change reports filed by 107 programmers for 16 releases of a system with 1,400,000 LOC and 3100 files. A "bug ratio" was defined for programmers, measuring the proportion of faulty files in release R out of all files modified by the programmer in release R-1. The study compares the bug ratios of individual programmers to the average bug ratio, and also assesses the consistency of the bug ratio across releases for individual programmers.Results: Bug ratios varied widely among all the programmers, as well as for many individual programmers across all the releases that they participated in. We found a statistically significant correlation between the bug ratios for programmers for the first half of changed files versus the ratios for the second half, indicating a measurable degree of persistence in the bug ratio. However, when the computation was repeated with the bug ratio controlled not only by release, but also by file size, the correlation disappeared. In addition to the bug ratios, we confirmed that counts of the cumulative number of different developers changing a file over its lifetime can help to improve predictions, while other developer counts are not helpful.Conclusions: The results from this preliminary study indicate that adding information to a model about which particular developer modified a file is not likely to improve defect predictions. The study is limited to a single large system, and its results may not hold more widely. The bug ratio is only one way of measuring the "fault-proneness" of an individual programmer's coding, and we intend to investigate other ways of evaluating bug introduction by individuals.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {19},
numpages = {10},
keywords = {bug ratio, empirical study, fault-prone, prediction, regression model, software faults},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@article{10.5555/1859570.1859573,
author = {Tolba, A. S. and Atwan, Ahmad and Amanneddine, N. and Mutawa, A. M. and Khan, H. A.},
title = {Defect detection in flat surface products using log-Gabor filters},
year = {2010},
issue_date = {August 2010},
publisher = {IOS Press},
address = {NLD},
volume = {7},
number = {3},
issn = {1448-5869},
abstract = {This paper introduces a novel method for defect detection in homogeneous flat surface products. The coefficient of variation is used as a homogeneity measure for approximate defect localization and features extracted from the Log - Gabor filter bank response are used to accurately localize and detect the defect while reducing the complexity of Gabor based inspection approaches. The scanning window size and threshold parameter are the two major factors that affect the system performance. An adaptive technique is proposed for selecting the size of the scanning window and automating the selection of the threshold level. Compared to the Log-Gabor filters, the proposed combination resulted in speeding up the defect detection process by about ten times. The experimental results show that the proposed system gives promising results and is applicable for defect detection in homogeneous surfaces like paper, steel plates, ceramic tiles and foils.},
journal = {Int. J. Hybrid Intell. Syst.},
month = aug,
pages = {187–201},
numpages = {15},
keywords = {log-gabor filter bank, homogeneity measures, feature extraction, defect detection, Automated visual inspection}
}

@inproceedings{10.1109/GCIS.2013.36,
author = {Li, Min and Deng, Zhong-Min and Wang, Lijing},
title = {Defect Detection of Patterned Fabric by Spectral Estimation Technique and Rough Set Classifier},
year = {2013},
isbn = {9781479928866},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GCIS.2013.36},
doi = {10.1109/GCIS.2013.36},
abstract = {A novel method for patterned fabric defect detection and classification using spectral estimation technique and rough set theory is presented in this paper. Estimating Signal Parameter via Rotational Invariance Technique (ESPRIT) is firstly used to extract the pattern from the image of the patterned fabric. Then, the shape and location of the flawed areas are detected by comparing the pattern image and the source image. A rough set classifier is trained and tested to detect the types of defects in the patterned fabric image. Experimental results show that this method can successfully analyze and recognize oil warp and weft defects in patterned fabrics with nearly 96% success rate.},
booktitle = {Proceedings of the 2013 Fourth Global Congress on Intelligent Systems},
pages = {190–194},
numpages = {5},
keywords = {spectral estimation, rough set theory, patterned fabric, defect detection, Rotational Invariance Technique},
series = {GCIS '13}
}

@article{10.1111/exsy.12078,
author = {Malhotra, Ruchika and Bansal, Ankita Jain},
title = {Fault prediction considering threshold effects of object-oriented metrics},
year = {2015},
issue_date = {April 2015},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {2},
issn = {0266-4720},
url = {https://doi.org/10.1111/exsy.12078},
doi = {10.1111/exsy.12078},
abstract = {Software product quality can be enhanced significantly if we have a good knowledge and understanding of the potential faults therein. This paper describes a study to build predictive models to identify parts of the software that have high probability of occurrence of fault. We have considered the effect of thresholds of object-oriented metrics on fault proneness and built predictive models based on the threshold values of the metrics used. Prediction of fault prone classes in earlier phases of software development life cycle will help software developers in allocating the resources efficiently. In this paper, we have used a statistical model derived from logistic regression to calculate the threshold values of object oriented, Chidamber and Kemerer metrics. Thresholds help developers to alarm the classes that fall outside a specified risk level. In this way, using the threshold values, we can divide the classes into two levels of risk - low risk and high risk. We have shown threshold effects at various risk levels and validated the use of these thresholds on a public domain, proprietary dataset, KC1 obtained from NASA and two open source, Promise datasets, IVY and JEdit using various machine learning methods and data mining classifiers. Interproject validation has also been carried out on three different open source datasets, Ant and Tomcat and Sakura. This will provide practitioners and researchers with well formed theories and generalised results. The results concluded that the proposed threshold methodology works well for the projects of similar nature or having similar characteristics.},
journal = {Expert Sys: J. Knowl. Eng.},
month = apr,
pages = {203–219},
numpages = {17},
keywords = {software quality, receiver operating characteristics, object-oriented metrics, machine learning, logistic regression, empirical validation}
}

@inproceedings{10.1109/DCABES.2011.42,
author = {Zhang, Xingye and Xu, Wenbo and Pan, Ruru and Liu, Jihong and Gao, Weidong},
title = {Fabric Defect Detection Based on Projected Transform for Feature Extraction},
year = {2011},
isbn = {9780769544151},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DCABES.2011.42},
doi = {10.1109/DCABES.2011.42},
abstract = {In order to resolve the key technology problem of automated fabric defect detection, projected transform is proposed to extract features of the fabric image making use of fabric characteristic in this paper. Automated fabric defect detection scheme is divided into two phases, which are the study phase and the detection phase. During the study phase, features of normal fabric image are extracted to get the feature data set of normal fabric. During the detection phase, the method of anomaly detection is developed using features of fabric image to detect defect. Testing on general fabric by this method, experimental results demonstrate that each of feature values is in the normal range for normal fabric image, and one feature value at least is abnormal for defective fabric image. Defects can be located according to the location of abnormal value.},
booktitle = {Proceedings of the 2011 10th International Symposium on Distributed Computing and Applications to Business, Engineering and Science},
pages = {192–196},
numpages = {5},
keywords = {projected transform, feature extraction, fabric, defect detection, anomaly detection},
series = {DCABES '11}
}

@inproceedings{10.1109/ARSO.2016.7736285,
author = {Tao, Yong and Zheng, Jiaqi and Wang, Tianmiao and Hu, Yaoguang},
title = {A state and fault prediction method based on RBF neural networks},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ARSO.2016.7736285},
doi = {10.1109/ARSO.2016.7736285},
abstract = {A state and fault prediction method based on RBF neural networks is proposed. The agricultural machinery is chosen as the experimental object of the method. There are 4 health level, such as failure, hazardous, sub-healthy and healthy. Some data of different provinces have been obtained, the health level can be acquired by RBF neural networks. The mathematical model of agricultural machinery is difficult to be proposed in this paper, so the traditional control algorithm can't be used in agricultural machinery. However, the RBF neural networks can solve this problem. At the same time, some vital factors should be considered, such as mileages, rotational speed, stubble height, water temperature, oil pressure of agricultural machinery. The rotational speed and stubble height have a big effect on fault prediction of agriculture. The experimental results verify the effectiveness of the proposed method.},
booktitle = {2016 IEEE Workshop on Advanced Robotics and Its Social Impacts (ARSO)},
pages = {221–225},
numpages = {5},
location = {Shanghai, China}
}

@article{10.1145/3464959,
author = {Botero, Ulbert J. and Wilson, Ronald and Lu, Hangwei and Rahman, Mir Tanjidur and Mallaiyan, Mukhil A. and Ganji, Fatemeh and Asadizanjani, Navid and Tehranipoor, Mark M. and Woodard, Damon L. and Forte, Domenic},
title = {Hardware Trust and Assurance through Reverse Engineering: A Tutorial and Outlook from Image Analysis and Machine Learning Perspectives},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3464959},
doi = {10.1145/3464959},
abstract = {In the context of hardware trust and assurance, reverse engineering has been often considered as an illegal action. Generally speaking, reverse engineering aims to retrieve information from a product, i.e., integrated circuits (ICs) and printed circuit boards (PCBs) in hardware security-related scenarios, in the hope of understanding the functionality of the device and determining its constituent components. Hence, it can raise serious issues concerning Intellectual Property (IP) infringement, the (in)effectiveness of security-related measures, and even new opportunities for injecting hardware Trojans. Ironically, reverse engineering can enable IP owners to verify and validate the design. Nevertheless, this cannot be achieved without overcoming numerous obstacles that limit successful outcomes of the reverse engineering process. This article surveys these challenges from two complementary perspectives: image processing and machine learning. These two fields of study form a firm basis for the enhancement of efficiency and accuracy of reverse engineering processes for both PCBs and ICs. In summary, therefore, this article presents a roadmap indicating clearly the actions to be taken to fulfill hardware trust and assurance objectives.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jun,
articleno = {62},
numpages = {53},
keywords = {trust and assurances, reverse engineering, printed circuit boards, machine learning, integrated circuits, image processing, imaging, hardware trojan, Hardware counterfeiting}
}

@article{10.1016/j.procs.2015.02.154,
author = {Mahajan, Rohit and Gupta, Sunil Kumar and Bedi, Rajeev Kumar},
title = {Design of Software Fault Prediction Model Using BR Technique},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.154},
doi = {10.1016/j.procs.2015.02.154},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {849–858},
numpages = {10},
keywords = {public dataset ;, Neural network, Levenberg-Marquardt (LM)algorithm, Back Propagation (BPA) algorithm ;Bayesian Regularization(BR)algorithml}
}

@inproceedings{10.1145/2590748.2590755,
author = {Rathore, Santosh Singh and Gupta, Atul},
title = {A comparative study of feature-ranking and feature-subset selection techniques for improved fault prediction},
year = {2014},
isbn = {9781450327763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2590748.2590755},
doi = {10.1145/2590748.2590755},
abstract = {The quality of a fault prediction model depends on the software metrics that are used to build the prediction model. Feature selection represents a process of selecting a subset of relevant features that may lead to build improved prediction models. Feature selection techniques can be broadly categorized into two subcategories: feature-ranking and feature-subset selection. In this paper, we present a comparative investigation of seven feature-ranking techniques and eight feature-subset selection techniques for improved fault prediction. The performance of these feature selection techniques is evaluated using two popular machine-learning classifiers: Naive Bayes and Random Forest, over fourteen software project's fault-datasets obtained from the PROMISE data repository. The performances were measured using F-measure and AUC values. Our results demonstrated that feature-ranking techniques produced better results compared to feature-subset selection techniques. Among, the feature-ranking techniques used in the study, InfoGain and PCA techniques provided the best performance over all the datasets, while for feature-subset selection techniques ClassifierSubsetEval and Logistic Regression produced better results against their peers.},
booktitle = {Proceedings of the 7th India Software Engineering Conference},
articleno = {7},
numpages = {10},
keywords = {wrappers, software metrics, filters, feature-ranking, feature selection, fault prediction},
location = {Chennai, India},
series = {ISEC '14}
}

@inproceedings{10.1109/PACIIA.2008.179,
author = {Guan, Shengqi and Shi, Xiuhua and Cui, Haiying and Song, Yuqin},
title = {Fabric Defect Detection Based on Wavelet Characteristics},
year = {2008},
isbn = {9780769534909},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/PACIIA.2008.179},
doi = {10.1109/PACIIA.2008.179},
abstract = {On the basis of wavelet and singular signal characteristic analysis, a new defect detection method based on wavelet characteristics is presented. Firstly, to select wavelet filters of compact support and high vanishing moment properties are regarded as finite biorthogonal filters. Secondly, the new wavelet with concussive and filters coefficients of centralized distribution is constructed by lifting scheme, which is matching with test fabric texture properties. Lastly, the detail signal feature after wavelet decomposition of fabric image is extracted, and it is compared with the detail signal feature of normal fabric image decomposition to determine whether there exists defect. The experimental result confirms that the proposed method is validity and the detection accuracy is over 92.5%.},
booktitle = {Proceedings of the 2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application - Volume 01},
pages = {366–370},
numpages = {5},
keywords = {Wavelet characteristics, Lifting Sheme, Feature extraction, Defect Detection},
series = {PACIIA '08}
}

@inproceedings{10.1145/3163080.3163120,
author = {Hoshyar, Azadeh Noori and Kharkovsky, Sergey and Taghavipour, Saber and Samali, Bijan and Liyanapathirana, Ranjith},
title = {Structural Damage Detection of a Concrete Based on the Autoregressive All-pole Model Parameters and Artificial Intelligence Techniques},
year = {2017},
isbn = {9781450353847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3163080.3163120},
doi = {10.1145/3163080.3163120},
abstract = {Over the past few decades, damage identification in structural components has been the crucial concern in quality assessment and load capacity rating of infrastructure, as well as in the planning of a maintenance schedule. In this regard, structural health monitoring based on efficient tools to identify the damages in early stages has been focused by researchers to prevent sudden failure in structural components, ensure the public safety and reducing the asset management costs. Therefore, the development and application of sensing technologies and data analysis using machine learning approaches to enable the automatic detection of cracks have become very important. The purpose of this research is to develop a robust method for automatic condition assessment of real-life concrete structures for the detection of relatively small cracks at early stages. A damage identification approach is proposed using the parametric modeling and machine learning approaches to analyze the sensors data. The data obtained from transducers mounted on concrete beams under static loading in laboratory. These data are used as the input parameters. The method relies only on the measured time responses. After filtering and normalization of the data, Autoregressive all-pole model parameters (Yule-Walker method) are considered as features and used as the inputs of a newly developed Self-Advising Support Vector Machine (SA-SVM) for the classification purpose in civil Engineering area. Finally, the results are compared with traditional methods to investigate the feasibility of our proposed method. It is demonstrated that the presented method can reliably detect the crack in the structure and thereby enable the real-time infrastructure health monitoring.},
booktitle = {Proceedings of the 9th International Conference on Signal Processing Systems},
pages = {57–61},
numpages = {5},
keywords = {parametric modeling, classification, Support Vector Machine, Self-Advising Support Vector Machine, Concrete, Autoregressive all-pole model parameters},
location = {Auckland, New Zealand},
series = {ICSPS 2017}
}

@article{10.1504/IJIIDS.2015.070825,
author = {Abaei, Golnoush and Mashinchi, M. Reza and Selamat, Ali},
title = {Software fault prediction using BP-based crisp artificial neural networks},
year = {2015},
issue_date = {July 2015},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1751-5858},
url = {https://doi.org/10.1504/IJIIDS.2015.070825},
doi = {10.1504/IJIIDS.2015.070825},
abstract = {Early fault detection for software reduces the cost of developments. Fault level can be predicted through learning mechanisms. Conventionally, precise metrics measure the fault level and crisp artificial neural networks CANNs perform the learning. However, the performance of CANNs depends on complexities of data and learning algorithm. This paper considers these two complexities to predict the fault level of software. We apply the principle component analysis PCA to reduce the dimensionality of data, and employ the correlation-based feature selection CFS to select the best features. CANNs, then, predict the fault level of software using back propagation BP algorithm as a learning mechanism. To investigate the performance of BP-based CANNs, we analyse varieties of dimensionality reduction. The results reveal the superiority of PCA to CFS in terms of accuracy.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jul,
pages = {15–31},
numpages = {17}
}

@article{10.1016/j.eswa.2008.10.027,
author = {Catal, Cagatay and Diri, Banu},
title = {A systematic review of software fault prediction studies},
year = {2009},
issue_date = {May, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.10.027},
doi = {10.1016/j.eswa.2008.10.027},
abstract = {This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle.},
journal = {Expert Syst. Appl.},
month = may,
pages = {7346–7354},
numpages = {9},
keywords = {Public datasets, Method-level metrics, Machine learning, Expert systems, Automated fault prediction models}
}

@inproceedings{10.1145/1540438.1540466,
author = {Jiang, Yue and Cukic, Bojan},
title = {Misclassification cost-sensitive fault prediction models},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540466},
doi = {10.1145/1540438.1540466},
abstract = {Traditionally, software fault prediction models are built by assuming a uniform misclassification cost. In other words, cost implications of misclassifying a faulty module as fault free are assumed to be the same as the cost implications of misclassifying a fault free module as faulty. In reality, these two types of misclassification costs are rarely equal. They are project-specific, reflecting the characteristics of the domain in which the program operates. In this paper, using project information from a public repository, we analyze the benefits of techniques which incorporate misclassification costs in the development of software fault prediction models. We find that cost-sensitive learning does not provide operational points which outperform cost-insensitive classifiers. However, an advantage of cost-sensitive modeling is the explicit choice of the operational threshold appropriate for the cost differential.},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {20},
numpages = {10},
keywords = {cost-sensitive, fault prediction, machine learning, misclassification cost},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@article{10.1007/s11334-015-0258-2,
author = {Abdi, Yousef and Parsa, Saeed and Seyfari, Yousef},
title = {A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0258-2},
doi = {10.1007/s11334-015-0258-2},
abstract = {Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization (DSMOPSO). Because of discrete search space, we modified this algorithm and named it DSMOPSO-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the PROMISE repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {289–301},
numpages = {13},
keywords = {Multi-objective particle swarm optimization, Kernel k-means, Imbalanced data sets, Fault prediction, DSMOPSO-D, Classification rules}
}

@inproceedings{10.1109/FIT.2012.33,
author = {Hassan, J. and Awan, A. Majid and Jalil, A.},
title = {Welding Defect Detection and Classification Using Geometric Features},
year = {2012},
isbn = {9780769549279},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/FIT.2012.33},
doi = {10.1109/FIT.2012.33},
abstract = {In this paper we present a welding defect detection system using radiographic images. Main goal is to craft a dependable system because a human evaluator is not a stable evaluator besides other humanoid constraints. We present a novel technique for the detection and classification of weld defects by means of geometric features. Firstly noise reduction is done as radiographic images contain noise due to several effects. After this we tend to localize defects with maximum interclass variance and minimum intra class variance. Further we move towards extracting features describing the shape of localized objects in segmented images. Using these shape descriptors (geometric features) we classify the defects by Artificial Neural Network.},
booktitle = {Proceedings of the 2012 10th International Conference on Frontiers of Information Technology},
pages = {139–144},
numpages = {6},
keywords = {welding, radiography, features extraction},
series = {FIT '12}
}

@article{10.1007/s00138-008-0146-y,
author = {Zontak, Maria and Cohen, Israel},
title = {Defect detection in patterned wafers using anisotropic kernels},
year = {2010},
issue_date = {February 2010},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-008-0146-y},
doi = {10.1007/s00138-008-0146-y},
abstract = {Wafer defect detection often relies on accurate image registration of source and reference images obtained from neighboring dies. Unfortunately, perfect registration is generally impossible, due to pattern variations between the source and reference images. In this paper, we propose a defect detection procedure, which avoids image registration and is robust to pattern variations. The proposed method is based on anisotropic kernel reconstruction of the source image using the reference image. The source and reference images are mapped into a feature space, where every feature with origin in the source image is estimated by a weighted sum of neighboring features from the reference image. The set of neighboring features is determined according to the spatial neighborhood in the original image space, and the weights are calculated from exponential distance similarity function. We show that features originating from defect regions are not reconstructible from the reference image, and hence can be identified. The performance of the proposed algorithm is evaluated and its advantage is demonstrated compared to using an anomaly detection algorithm.},
journal = {Mach. Vision Appl.},
month = feb,
pages = {129–141},
numpages = {13},
keywords = {Similarity measure, Semiconductor defect detection, NL-means, Image reconstruction, Anomaly detection, Anisotropic kernels}
}

@article{10.4018/ijsi.2014100105,
author = {Abaei, Golnoush and Selamat, Ali},
title = {Increasing the Accuracy of Software Fault Prediction using Majority Ranking Fuzzy Clustering},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {2},
number = {4},
issn = {2166-7160},
url = {https://doi.org/10.4018/ijsi.2014100105},
doi = {10.4018/ijsi.2014100105},
abstract = {Despite proposing many software fault prediction models, this area has yet to be explored as still there is a room for stable and consistent model with better performance. In this paper, a new method is proposed to increase the accuracy of fault prediction based on the notion of fuzzy clustering and majority ranking. The authors investigated the effect of irrelevant and inconsistent modules on software fault prediction and tried to decrease it by designing a new framework, in which the entire project modules are clustered. The obtained results showed that fuzzy clustering could decrease the negative effect of irrelevant modules on prediction performance. Eight data sets from NASA and Turkish white-goods software is employed to evaluate our model. Performance evaluation in terms of false positive rate, false negative rate, and overall error showed the superiority of our model compared to other predicting models. The authors proposed majority ranking fuzzy clustering approach showed between 3% to 18% and 1% to 4% improvement in false negative rate and overall error, respectively, compared with other available proposed models (ACF and ACN) in more than half of the testing cases. According to the results, our systems can be used to guide testing effort by identifying fault prone modules to improve the quality of software development and software testing in a limited time and budget.},
journal = {Int. J. Softw. Innov.},
month = oct,
pages = {60–71},
numpages = {12},
keywords = {Software Fault Prediction, NASA, Majority Ranking, Fuzzy Clustering, Available Proposed Models}
}

@article{10.1016/j.csi.2017.02.003,
title = {An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes},
year = {2017},
issue_date = {August 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {53},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2017.02.003},
doi = {10.1016/j.csi.2017.02.003},
abstract = {Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low 48.89%, median- 39.26%, and high 27.86%). HighlightsFault prediction improve the effectiveness of software quality assurance activities.This paper focus on building an effective fault prediction tool.Fault prediction model using ANN and ensemble methods.We perform experiments on 56 Open Source Java projects.Fault prediction model is best suitable for projects with faulty classes less than the threshold value.},
journal = {Comput. Stand. Interfaces},
month = aug,
pages = {1–32},
numpages = {32}
}

@article{10.5555/1718109.1718125,
author = {Lin, Chun-Cheng and Yeh, Cheng-Yu},
title = {Texture defect detection system with image deflection compensation},
year = {2009},
issue_date = {September 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {8},
number = {9},
issn = {1109-2750},
abstract = {Image textural analysis technology has been widely used in the design of automated defect detection systems. Because the presence of defects may change the textural features of an image, a reference image without defects can be compared with the test image to detect whether there are any defects. However, besides defects, the deflection of the input test image could also change its textural features. When there is any angular difference between the reference and test images, their textural features would also be different, even if there is no defect in the test image. As a result, misjudgment of the defect detection system may occur. Most of the previous studies have focused on the development of textural analysis technology which could decrease the effect of test image deflection. This study aimed to estimate the deflection angle of test images through polar Fourier transform and phase correlation analysis, and rotate the reference image by the same angle to compensate for the deflection of the test image. After the angles of the reference and test images were brought into line, the textural analysis based on the gray level co-occurrence matrix was applied to analyze and compare the textural features of the two images. The results of actual texture defect detection demonstrated that the angular differences between the reference and test images could be estimated correctly, with an estimation error of only 0° to 0.5°. By compensating for the deflection of the test image, the accuracy of the texture defect detection could be effectively enhanced.},
journal = {W. Trans. on Comp.},
month = sep,
pages = {1575–1586},
numpages = {12},
keywords = {texture defect detection, polar fourier transform, phase correlation analysis, image deflection compensation, gray level co-occurrence matrix}
}

@inproceedings{10.1109/ETFA.2016.7733668,
author = {Bonnin-Pascual, Francisco and Ortiz, Alberto},
title = {A generic framework for defect detection on vessel structures based on image saliency},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2016.7733668},
doi = {10.1109/ETFA.2016.7733668},
abstract = {Seagoing vessels have to undergo regular visual inspections in order to detect defects such as cracks and corrosion before they result into catastrophic consequences. These inspections are currently performed manually by ship surveyors at a great cost, so that any level of assistance during the inspection process would significatively decrease the inspection cost. In this paper, we describe a novel framework for visually detecting the aforementioned defects. This framework is generic and flexible in the sense that it can be easily configured to compute the features that perform better for the inspection at hand. In this regard, inspired by the idea of conspicuity, this work considers contrast and symmetry as features for detecting defects on vessel structures. A combination operator is additionally tested in order to merge the information provided by these features and improve the detection performance. Experimental results for the different configurations of the detection framework show better classification results than state of the art methods.},
booktitle = {2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1–4},
numpages = {4},
location = {Berlin, Germany}
}

@inproceedings{10.1109/HASE.2007.60,
author = {Shin, Miyoung and Ratanothayanon, Sunida and Goel, Amrit L. and Paul, Raymond A.},
title = {Parsimonious Classifiers for Software Quality Assessment},
year = {2007},
isbn = {0769530435},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HASE.2007.60},
doi = {10.1109/HASE.2007.60},
abstract = {Modeling to predict faultproneness of software modules is an important area of research in software engineering. Most such models employ a large number of basic and derived metrics as predictors. This paper presents modeling results based on only two metrics, lines of code and cyclomatic complexity, using radial basis functions with Gaussian kernels as classifiers. Results from two NASA systems are presented and analyzed.},
booktitle = {Proceedings of the 10th IEEE High Assurance Systems Engineering Symposium},
pages = {411–412},
numpages = {2},
keywords = {Software quality, Software metrics, Parsimonious classifiers, Classification},
series = {HASE '07}
}

@article{10.1007/s00138-011-0335-y,
author = {Tolba, Ahmad Said},
title = {A novel multiscale-multidirectional autocorrelation approach for defect detection in homogeneous flat surfaces},
year = {2012},
issue_date = {July 2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {4},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-011-0335-y},
doi = {10.1007/s00138-011-0335-y},
abstract = {Defect detection in flat web surface products is a challenging task. Reliable vision-based systems for detection of defects require the suitable selection of a huge set of parameters which highly impact the performance of these systems such as image resolution/scale, size of the scanning window, feature extraction, direction of scanning, classifier type and parameters and system performance evaluation measures. This paper addresses these issues and introduces a novel multi-scale and multi-directional (MSMD) autocorrelation function (ACF)-based approach for reliable defect detection and localization in homogeneous web surfaces. The proposed approach has been experimentally tested on samples from the well-known TILDA textiles database and wallboards. Performance evaluation using the system Precision, Recall (Sensitivity), Specificity, Accuracy, Youden’s index, F-measure and Matthews correlation coefficient has shown that the MSMD ACF approach outperforms the state-of-the-art approaches like MSMD Log-Gabor filters. The MSMD ACFs approach results in better performance indicators for defect detection than the Log-Gabor based approach in addition to being about 2–6 times faster in defect detection.},
journal = {Mach. Vision Appl.},
month = jul,
pages = {739–750},
numpages = {12},
keywords = {Performance evaluation, MSMD ACF, Log-Gabor filter banks, Defect detection}
}

@inproceedings{10.1109/ISIE.2011.54,
author = {Guan, Shu-an and Guo, Fenglin},
title = {A New Image Enhancement Algorithm for PCB Defect Detection},
year = {2011},
isbn = {9780769544809},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISIE.2011.54},
doi = {10.1109/ISIE.2011.54},
abstract = {According to the PCB image feature in a PCB defect detection project, we studied a new image enhancement algorithm: double sigmoid transformation and also deduced the transformation arithmetic operator. Practical project experiments show that the new algorithm can effectively sharpen PCB image edges, at same time it can filter out noise in the image. Even if the original PCB image is not distinct enough and uniform brightness, the algorithm is able to precisely locate circuit edge, which can make the edge extracting and edge recognition easier.},
booktitle = {Proceedings of the 2011 International Conference on Intelligence Science and Information Engineering},
pages = {454–456},
numpages = {3},
keywords = {image enhancement, Sigmoid transformation, Sigmoid arithmetic operator, PCB defect detection},
series = {ISIE '11}
}

@inproceedings{10.1145/2245276.2231975,
author = {Banthia, Deepak and Gupta, Atul},
title = {Investigating fault prediction capabilities of five prediction models for software quality},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231975},
doi = {10.1145/2245276.2231975},
abstract = {Predicting faults in software modules can lead to a high quality and more effective software development process to follow. However, the results of a fault prediction model have to be properly interpreted before incorporating them into any decision making. Most of the earlier studies have used the prediction accuracy as the main criteria to compare amongst competing fault prediction models. However, we show that besides accuracy, other criteria like number of false positives and false negatives can equally be important to choose a candidate model for fault prediction. We have used five NASA software data sets in our experiment. Our results suggest that the performance of Simple Logistic is better than the others on raw data sets whereas the performance of Neural Network was found to be better when we applied dimensionality reduction method on raw data sets. When we used data pre-processing techniques, the prediction accuracy of Random Forest was found to be better in both cases i.e. with and without dimensionality reduction but reliability of Simple Logistic was better than Random Forest because it had less number of fault negatives.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1259–1261},
numpages = {3},
keywords = {quality assurance, fault prediction models, fault prediction, effort estimation, attribute selection},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1016/j.jvcir.2013.05.011,
author = {Bissi, Lucia and Baruffa, Giuseppe and Placidi, Pisana and Ricci, Elisa and Scorzoni, Andrea and Valigi, Paolo},
title = {Automated defect detection in uniform and structured fabrics using Gabor filters and PCA},
year = {2013},
issue_date = {October, 2013},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {24},
number = {7},
issn = {1047-3203},
url = {https://doi.org/10.1016/j.jvcir.2013.05.011},
doi = {10.1016/j.jvcir.2013.05.011},
abstract = {This paper describes an algorithm for texture defect detection in uniform and structured fabrics, which has been tested on the TILDA image database. The proposed approach is structured in a feature extraction phase, which relies on a complex symmetric Gabor filter bank and Principal Component Analysis (PCA), and on a defect identification phase, which is based on the Euclidean norm of features and on the comparison with fabric type specific parameters. Our analysis is performed on a patch basis, instead of considering single pixels. The performance has been evaluated with uniformly textured fabrics and fabrics with visible texture and grid-like structures, using as reference defect locations identified by human observers. The results show that our algorithm outperforms previous approaches in most cases, achieving a detection rate of 98.8% and a false alarm rate as low as 0.20-0.37%, whereas for heavily structured yarns misdetection rate can be as low as 5%.},
journal = {J. Vis. Comun. Image Represent.},
month = oct,
pages = {838–845},
numpages = {8},
keywords = {TILDA, Principa Component Analysis, Manual defect annotation, Gabor filters, False alarm rate, Fabric defect detection, Detection rate, Automated textile inspection}
}

@inproceedings{10.1145/2532443.2532461,
author = {Chen, Jiaqiang and Liu, Shulong and Chen, Xiang and Gu, Qing and Chen, Daoxu},
title = {Empirical studies on feature selection for software fault prediction},
year = {2013},
isbn = {9781450323697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2532443.2532461},
doi = {10.1145/2532443.2532461},
abstract = {Classification based software fault prediction methods aim to classify the modules into either fault-prone or non-fault-prone. Feature selection is a preprocess step used to improve the data quality. However most of previous research mainly focus on feature relevance analysis, there is little work focusing on feature redundancy analysis. Therefore we propose a two-stage framework for feature selection to solve this issue. In particular, during the feature relevance phase, we adopt three different relevance measures to obtain the relevant feature subset. Then during the feature redundancy analysis phase, we use a cluster-based method to eliminate redundant features. To verify the effectiveness of our proposed framework, we choose typical real-world software projects, including Eclipse projects and NASA software project KC1. Final empirical result shows the effectiveness of our proposed framework.},
booktitle = {Proceedings of the 5th Asia-Pacific Symposium on Internetware},
articleno = {26},
numpages = {4},
keywords = {software fault prediction, relevance analysis, redundancy analysis, feature selection},
location = {Changsha, China},
series = {Internetware '13}
}

@article{10.1049/trit.2019.0019,
author = {Ding, Runwei and Dai, Linhui and Li, Guangpeng and Liu, Hong},
title = {TDD‐net: a tiny defect detection network for printed circuit boards},
year = {2019},
issue_date = {June 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {4},
number = {2},
url = {https://doi.org/10.1049/trit.2019.0019},
doi = {10.1049/trit.2019.0019},
abstract = {Tiny defect detection (TDD) which aims to perform the quality control of printed circuit boards (PCBs) is a basic and essential task in the production of most electronic products. Though significant progress has been made in PCB defect detection, traditional methods are still difficult to cope with the complex and diverse PCBs. To deal with these problems, this article proposes a tiny defect detection network (TDD‐Net) to improve performance for PCB defect detection. In this method, the inherent multi‐scale and pyramidal hierarchies of deep convolutional networks are exploited to construct feature pyramids. Compared with existing approaches, the TDD‐Net has three novel changes. First, reasonable anchors are designed by using k‐means clustering. Second, TDD‐Net strengthens the relationship of feature maps from different levels and benefits from low‐level structural information, which is suitable for tiny defect detection. Finally, considering the small and imbalance dataset, online hard example mining is adopted in the whole training phase in order to improve the quality of region‐of‐interest (ROI) proposals and make more effective use of data information. Quantitative results on the PCB defect dataset show that the proposed method has better portability and can achieve 98.90% mAP, which outperforms the state‐of‐arts. The code will be publicly available.},
journal = {CAAI Transactions on Intelligence Technology},
month = may,
pages = {110–116},
numpages = {7},
keywords = {E0410D Industrial applications of IT, C7480&nbsp;Production engineering computing, C6170K Knowledge engineering techniques, C5260B Computer vision and image processing techniques, deep convolutional networks, diverse PCBs, complex PCBs, PCB defect detection, printed circuit boards, tiny defect detection network, PCB defect dataset show, TDD‐Net strengthens, feature extraction, pattern clustering, computer vision, learning (artificial intelligence), printed circuits, data mining, production engineering computing, quality control, neural nets}
}

@article{10.1007/s10462-009-9129-2,
author = {Jin, Xiaolong and Jiang, Jianmin and Min, Geyong},
title = {Managing computer files via artificial intelligence approaches},
year = {2009},
issue_date = {June      2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {31},
number = {1–4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-009-9129-2},
doi = {10.1007/s10462-009-9129-2},
abstract = {Agent-oriented computing has been regarded as a very promising methodology to developing intelligent software systems. Intelligent agent technology has, thus, been successfully applied in many industrial and commercial areas. Cased based reasoning (CBR) is an effective and efficient analogical reasoning method for solving problems using the knowledge of past experiences, which are stored in a knowledge base as cases. CBR has been extensively employed to tackle such problems as design, planning, classification, and advising in many different application fields. On the other hand, as various files are created on computers, how to efficiently manage computer files becomes a significant issue. So far, there are a number of file management systems available. However, none of them can deal with these crucial problems of file management: Which files should be deleted after their use? Which files should be temporarily kept or permanently preserved? To the best of our knowledge, these problems have not yet been investigated in the open literature. To bridge this gap, in this paper we explore the value of the above artificial intelligence approaches in managing computer files. We develop an intelligent agent based personal file management system, where CBR is employed to guide users to managing their files. Through extensive practical experiments, we validate the effectiveness and efficiency of the developed system.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {101–117},
numpages = {17},
keywords = {Similarity measurement, Multi-agent systems, Intelligent agents, File management, Case based reasoning}
}

@article{10.1504/IJCAT.2016.080493,
author = {Kayarvizhy, N. and Kanmani, S. and Uthariaraj, V. Rhymend},
title = {Enhancing the fault prediction accuracy of CK metrics using high precision cohesion metric},
year = {2016},
issue_date = {January 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {54},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/IJCAT.2016.080493},
doi = {10.1504/IJCAT.2016.080493},
abstract = {Object-oriented programs can be viewed as a collection of objects communicating with each other to perform a unique task. Many complex commercial applications have taken the object-oriented approach because of the benefits that it offers. The need for a reliable software resulted in the study and analysis of object-oriented metrics. The Chidamber and Kemerer CK metric suite has been considered as a pioneering work on object-oriented metrics and is the default standard for any new metric to be compared against. In this paper we evaluate the fault prediction capability of CK metric suite and validate it empirically. To further improve the accuracy of fault prediction we explore replacing the cohesion metric LCOM in CK suite with the proposed cohesion metric high precision cohesion metric. We have considered data from 500 classes spread across 12 projects for the study. The results show that there is a considerable improvement in the prediction accuracy.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {290–296},
numpages = {7},
keywords = {software reliability, object-oriented programming, object-oriented metrics, high precision cohesion metric, fault prediction accuracy, OOP, HPCM, Chidamber and Kemerer, CK metrics}
}

@article{10.5555/3292849.3292858,
title = {A hybrid approach to improve the quality of software fault prediction using Na\"{\i}ve Bayes and k-NN classification algorithm with ensemble method},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1740-8865},
abstract = {This paper considers an improvisation in software fault prediction research area using supervised classification algorithms and it mainly focuses to increase the performance of fault prediction. In this paper, we propose a hybrid prediction model using Na\"{\i}ve Bayes and k-nearest neighbour classification algorithm with vote ensemble method; in short it called as hNK. The goal of this model is to predict the best classification algorithm for software fault prediction based on the metrics and attributes of datasets. In the work, we have applied training sets and testing sets in hNK model with ensemble vote and we proposed the model to identify a suitable classification algorithm for fault prediction based on the accuracy and precision. We have achieved better results using hNK model for classifying supervised algorithms with different dataset.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {483–496},
numpages = {14}
}

@inproceedings{10.1109/ICMA.2017.8015822,
author = {Gao, Qiang and Liu, Wenjie and Zhao, Xuewen and Li, Junfang and Yu, Xiao},
title = {Research and application of the distillation column process fault prediction based on the improved KPCA},
year = {2017},
isbn = {978-1-5090-6758-9},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2017.8015822},
doi = {10.1109/ICMA.2017.8015822},
abstract = {With the development of modern intelligent, automation and integration of the increasingly complex industrial process control system, the traditional prediction methods of faults perform not well, so it has faced a huge challenge. In this paper, a new improved kernel principal component analysis method is presented which uses the concept of indiscernibility and eigenvector applied to distillation column process fault prediction. Compared with traditional statistical techniques, improved KPCA not only can remove variables with little or no correlation with the fault, but also can reduce the amount of datas calculated by K. Applying this new method to distillation column process fault prediction, the simulation results show that the proposed methods have great advantages. Compared with the traditional KPCA, the improved KPCA improves the ability to predict the process failure caused by small disturbance and becomes more effective.},
booktitle = {2017 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {247–251},
numpages = {5},
location = {Takamatsu, Japan}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {rule mining, product line, multi-objective search, machine learning, configuration},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.5555/1671248.1671311,
author = {Tosun, Ayse and Bener, Ayse},
title = {Reducing false alarms in software defect prediction by decision threshold optimization},
year = {2009},
isbn = {9781424448425},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software defect data has an imbalanced and highly skewed class distribution. The misclassification costs of two classes are not equal nor are known. It is critical to find the optimum bound, i.e. threshold, which would best separate defective and defect-free classes in software data. We have applied decision threshold optimization on Na\"{\i}ve Bayes classifier in order to find the optimum threshold for software defect data. ROC analyses show that decision threshold optimization significantly decreases false alarms (on the average by 11%) without changing probability of detection rates.},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
pages = {477–480},
numpages = {4},
series = {ESEM '09}
}

@article{10.1007/s10664-008-9079-3,
author = {Jiang, Yue and Cukic, Bojan and Ma, Yan},
title = {Techniques for evaluating fault prediction models},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9079-3},
doi = {10.1007/s10664-008-9079-3},
abstract = {Many statistical techniques have been proposed to predict fault-proneness of program modules in software engineering. Choosing the "best" candidate among many available models involves performance assessment and detailed comparison, but these comparisons are not simple due to the applicability of varying performance measures. Classifying a software module as fault-prone implies the application of some verification activities, thus adding to the development cost. Misclassifying a module as fault free carries the risk of system failure, also associated with cost implications. Methodologies for precise evaluation of fault prediction models should be at the core of empirical software engineering research, but have attracted sporadic attention. In this paper, we overview model evaluation techniques. In addition to many techniques that have been used in software engineering studies before, we introduce and discuss the merits of cost curves. Using the data from a public repository, our study demonstrates the strengths and weaknesses of performance evaluation techniques and points to a conclusion that the selection of the "best" model cannot be made without considering project cost characteristics, which are specific in each development environment.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {561–595},
numpages = {35},
keywords = {Predictive models in software engineering, Model evaluation, Fault-prediction models, Empirical studies}
}

@inproceedings{10.1145/1370750.1370759,
author = {Ratzinger, Jacek and Sigmund, Thomas and Gall, Harald C.},
title = {On the relation of refactorings and software defect prediction},
year = {2008},
isbn = {9781605580241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370750.1370759},
doi = {10.1145/1370750.1370759},
abstract = {This paper analyzes the influence of evolution activities such as refactoring on software defects. In a case study of five open source projects we used attributes of software evolution to predict defects in time periods of six months. We use versioning and issue tracking systems to extract 110 data mining features, which are separated into refactoring and non-refactoring related features. These features are used as input into classification algorithms that create prediction models for software defects. We found out that refactoring related features as well as non-refactoring related features lead to high quality prediction models. Additionally, we discovered that refactorings and defects have an inverse correlation: The number of software defects decreases, if the number of refactorings increased in the preceding time period. As a result, refactoring should be a significant part of both bug fixes and other evolutionary changes to reduce software defects.},
booktitle = {Proceedings of the 2008 International Working Conference on Mining Software Repositories},
pages = {35–38},
numpages = {4},
keywords = {software evolution, software analysis, mining},
location = {Leipzig, Germany},
series = {MSR '08}
}

@article{10.2478/amcs-2014-0020,
author = {Bilski, Piotr and Wojciechowski, Jacek},
title = {Artificial intelligence methods in diagnostics of analog systems},
year = {2014},
issue_date = {6 2014},
publisher = {Walter de Gruyter &amp; Co.},
address = {USA},
volume = {24},
number = {2},
issn = {1641-876X},
url = {https://doi.org/10.2478/amcs-2014-0020},
doi = {10.2478/amcs-2014-0020},
abstract = {AbstractThe paper presents the state of the art and advancement of arti\'{z}cial intelligence methods in analog systems diagnostics. Firstly, the diagnostic domain is introduced and its problems explained. Then, computational intelligence approaches usable for fault detection and identi\'{z}cation are reviewed. Particular groups of methods are presented in detail, explaining their usefulness and drawbacks. Examples, such as the induction motor or the electronic \'{z}lter, are provided to show the applicability of the presented approaches for monitoring the state of analog objects from engineering domains. The discussion section reviews the presented approaches, their future prospects and problems to be solved.},
journal = {Int. J. Appl. Math. Comput. Sci.},
month = jun,
pages = {271–282},
numpages = {12},
keywords = {fault detection, arti\'{z}cial intelligence, analog systems}
}

@inproceedings{10.1109/ISSRE.2009.13,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance Analysis in Software Fault Prediction Models},
year = {2009},
isbn = {9780769538785},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2009.13},
doi = {10.1109/ISSRE.2009.13},
abstract = {Software fault prediction models play an important role in softwarequality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults.These subsystems, in turn, receive additional resources forverification and validation activities.Fault prediction models arebinary classifiers typically developed using one of the supervisedlearning techniques from either a subset of the fault data from thecurrent project or from a similar past project.In practice, itis critical that such models provide a reliable predictionperformance on the data not used in training.Variance is animportant reliability indicator of software fault prediction models.However, variance is often ignored or barely mentioned in manypublished studies. In this paper, through the analysis of twelvedata sets from a public software engineering repository from theperspective of variance, we explore the following five questionsregarding fault prediction models:(1) Do different types ofclassification performance measures exhibit different variance? (2)Does the size of the data set imply a more (or less) accurateprediction performance? (3) Does the size of training subset impactmodel's stability? (4) Do different classifiers consistently exhibitdifferent performance in terms of model's variance? (5) Are theredifferences between variance from 1000 runs and 10 runs of 10-fold crossvalidation experiments?Our results indicate that variance is avery important factor in understanding fault prediction models andwe recommend the best practice for reporting variance in empiricalsoftware engineering studies.},
booktitle = {Proceedings of the 2009 20th International Symposium on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
keywords = {variance, machine learning, fault prediction models},
series = {ISSRE '09}
}

@inproceedings{10.1007/978-3-030-38085-4_19,
author = {Christodoulopoulos, Konstantinos and Sartzetakis, Ippokratis and Soumplis, Polizois and Varvarigos, Emmanouel (Manos)},
title = {Machine Learning Assisted Quality of Transmission Estimation and Planning with Reduced Margins},
year = {2019},
isbn = {978-3-030-38084-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38085-4_19},
doi = {10.1007/978-3-030-38085-4_19},
abstract = {In optical transport networks, the Quality of Transmission (QoT) using a physical layer model (PLM) is estimated before establishing new or reconfiguring established optical connections. Traditionally, high margins are added to account for the model’s inaccuracy and the uncertainty in the current and evolving physical layer conditions, targeting uninterrupted operation for several years, until the end-of-life (EOL). Reducing the margins increases network efficiency but requires accurate QoT estimation. We present two machine learning (ML) assisted QoT estimators that leverage monitoring data of existing connections to understand the actual physical layer conditions and achieve high estimation accuracy. We then quantify the benefits of planning/upgrading a network over multiple periods with accurate QoT estimation as opposed to planning with EOL margins.},
booktitle = {Optical Network Design and Modeling: 23rd IFIP WG 6.10 International Conference, ONDM 2019, Athens, Greece, May 13–16, 2019, Proceedings},
pages = {211–222},
numpages = {12},
keywords = {Overprovisioning, Static network planning, End-of-life margins, Physical layer impairments, Monitoring, Cross-layer optimization, Incremental multi-period planning, Marginless},
location = {Athens, Greece}
}

@inproceedings{10.1109/UKSim.2013.95,
author = {Mirmahdavi, Seyyed Abdollah and Ahmadyfard, Alireza and Shahraki, Abdollah Amirkhani and Khojasteh, Parham},
title = {A Novel Modeling of Random Textures Using Fourier Transform for Defect Detection},
year = {2013},
isbn = {9780769549941},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UKSim.2013.95},
doi = {10.1109/UKSim.2013.95},
abstract = {In this paper we are concerned with the problem of detecting defects on random texture surfaces. We propose a novel method for the addressed problem. Due to the nature of random textures, characterizing normal patterns from defects is difficult. In this method we use the approach so called Phase Only Transform from Fourier transform family to extract frequency features from the texture patches in training and test stages. In training stage we use the extracted features from the training image patches to learn the probability density function of patches in the feature space. The training is performed on non-defective training sample using Gaussian mixture model. In the test stage, we divide the test image into small patches and from each patch we extract frequency features similar to training images. We use weighted normalized Euclidean distance measure derived from the model parameters to set a proper threshold. In order to obtain a defect map, distance of feature vectors extracted from image under inspection at each pixel position is calculated against our learned model and compare with threshold. The result of experiments for detecting defects on random texture tiles is very promising},
booktitle = {Proceedings of the 2013 UKSim 15th International Conference on Computer Modelling and Simulation},
pages = {470–475},
numpages = {6},
keywords = {random texture, defect detection, Gaussian Mixture Model, Fourier Transform},
series = {UKSIM '13}
}

@article{10.1109/TSE.2011.103,
author = {Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
title = {A Systematic Literature Review on Fault Prediction Performance in Software Engineering},
year = {2012},
issue_date = {November 2012},
publisher = {IEEE Press},
volume = {38},
number = {6},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2011.103},
doi = {10.1109/TSE.2011.103},
abstract = {Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs, and improve the quality of software. Objective: We investigate how the context of models, the independent variables used, and the modeling techniques applied influence the performance of fault prediction models. Method: We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesize the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modeling techniques such as Naive Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology, and performance comprehensively.},
journal = {IEEE Trans. Softw. Eng.},
month = nov,
pages = {1276–1304},
numpages = {29},
keywords = {software fault prediction, Systematics, Systematic literature review, Software testing, Predictive models, Fault diagnosis, Data models, Context modeling, Analytical models}
}

@inproceedings{10.1145/2979779.2979811,
author = {Kaur, Ishleen and Bajpai, Neha},
title = {An Empirical Study on Fault Prediction using Token-Based Approach},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979811},
doi = {10.1145/2979779.2979811},
abstract = {Since exhaustive testing is not possible, prediction of fault prone modules can be used for prioritizing the components of a software system. Various approaches have been proposed for the prediction of fault prone modules. Most of them uses module metrics as quality estimators. In this study, we proposed a tokenbased approach and combine the metric evaluated from our approach with the module metrics to further improve the prediction results. We conducted the experiment on an open source project for evaluating the approach. The proposed approach is further compared with the existing fault prone filtering technique. The results show that the proposed approach is an improvement over fault prone filtering technique.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {32},
numpages = {7},
keywords = {software testing, software metrics, logistic regression, fault prone modules, fault, Classification},
location = {Bikaner, India},
series = {AICTC '16}
}

@article{10.1016/j.patcog.2007.11.014,
author = {Ngan, Henry Y. T. and Pang, Grantham K. H. and Yung, Nelson H. C.},
title = {Motif-based defect detection for patterned fabric},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {41},
number = {6},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2007.11.014},
doi = {10.1016/j.patcog.2007.11.014},
abstract = {This paper proposes a generalized motif-based method for detecting defects in 16 out of 17 wallpaper groups in 2D patterned texture. It assumes that most patterned texture can be decomposed into lattices and their constituents-motifs. It then utilizes the symmetry property of motifs to calculate the energy of moving subtraction and its variance among different motifs. By learning the distribution of these values over a number of defect-free patterns, boundary conditions for discerning defective and defect-free patterns can be determined. This paper presents the theoretical foundation of the method, and defines the relations between motifs and lattice, from which a new concept called energy of moving subtraction is derived using norm metric measurement between a collection of circular shift matrices of motif and itself. It has been shown in this paper that the energy of moving subtraction amplifies the defect information of the defective motif. Together with its variance, an energy-variance space is further defined where decision boundaries are drawn for classifying defective and defect-free motifs. As the 16 wallpaper groups of patterned fabric can be transformed into three major groups, the proposed method is evaluated over these three major groups, from which 160 defect-free lattices samples are used for defining the decision boundaries, with 140 defect-free and 113 defective samples used for testing. An overall detection success rate of 93.32% is achieved for the proposed method. No other generalized approach can achieve this success rate has been reported before, and hence this result outperforms all other previously published approaches.},
journal = {Pattern Recogn.},
month = jun,
pages = {1878–1894},
numpages = {17},
keywords = {Wallpaper group, Texture analysis, Patterned fabric, Motif, Lattice, Defect detection}
}

@article{10.1145/3092566,
author = {Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza},
title = {Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092566},
doi = {10.1145/3092566},
abstract = {Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {56},
numpages = {36},
keywords = {survey, software vulnerability discovery, software security, review, machine-learning, data-mining, Software vulnerability analysis}
}

@inproceedings{10.5555/2394970.2395098,
author = {Castilho, Hugo Peres and Gon\c{c}alves, Paulo Jorge Sequeira and Pinto, Jo\~{a}o Rog\'{e}rio Caldas and Serafim3, Ant\'{o}nio Limas},
title = {Intelligent real-time fabric defect detection},
year = {2007},
isbn = {3540742581},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents real-time fabric defect detection based in intelligent techniques. Neural networks (NN), fuzzy modeling (FM) based on productspace fuzzy clustering and adaptive network based fuzzy inference system (ANFIS) were used to obtain a clearly classification for defect detection. Their implementation requires thresholding its output, and based in previous studies a confusion matrix based optimization is used to obtain the threshold. Experimental results for real fabric defect detection were obtained from the experimental apparatus presented in the paper, that showed the usefulness of the three intelligent techniques, although the NN has a faster performance. Online implementation of the algorithms showed they can be easily implemented with commonly available resources and may be adapted to industrial applications without great effort.},
booktitle = {Proceedings of the 4th International Conference on Image Analysis and Recognition},
pages = {1297–1307},
numpages = {11},
location = {Montreal, Canada},
series = {ICIAR'07}
}

@article{10.1016/j.mejo.2010.01.015,
author = {Liu, Hongxia and Zhou, Wen and Kuang, Qianwei and Cao, Lei and Gao, Bo},
title = {Defect detection of IC wafer based on two-dimension wavelet transform},
year = {2010},
issue_date = {February, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {41},
number = {2–3},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2010.01.015},
doi = {10.1016/j.mejo.2010.01.015},
abstract = {Defect detection of integrated circuit (IC) wafer based on two-dimension wavelet transform (2-D DWT) is presented in this paper. By utilizing the characteristics many of the same chips in a wafer, three images with defects located in the same position and different chips are obtained. The defect images contain the standard image without any defects. 2-D DWT presented in the paper can extract the standard image from the three defect images. The algorithm complexity of the method is close to that of 2-D DWT. After obtaining the standard image, the speed and accuracy of defects detection can be greatly enhanced using the detection method presented in the paper. Using the image gray-scale matching technology, impact of illumination on IC defect detection is solved. Experiments demonstrate that 2-D DWT is fast and accurate to defects detection in an IC image, and the method has high robustness for illumination.},
journal = {Microelectron. J.},
month = feb,
pages = {171–177},
numpages = {7},
keywords = {Two-dimension wavelet transform, Integrated circuit (IC) wafer, Defect detection}
}

@inproceedings{10.1109/GCIS.2009.356,
author = {Han, Runping and Zhang, Lingmin},
title = {Fabric Defect Detection Method Based on Gabor Filter Mask},
year = {2009},
isbn = {9780769535715},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GCIS.2009.356},
doi = {10.1109/GCIS.2009.356},
abstract = {In this paper, a fabric defect detection method based on Gabor filter masks is proposed. In this method, one even symmetric Gabor filter mask and one odd symmetric Gabor filter mask derived from the impulse response of the optimal Gabor filter are used. The optimal Gabor filter is designed to match with the texture features of defect-free fabric image, whose parameters are obtained by using the genetic algorithm. The performance of the proposed method is evaluated off-line by using a group of fabric sample images containing many kinds of fabric defects. The experimental results exhibit its accurate defect detection with low false alarms. And the effectiveness and robustness of the proposed method are confirmed.},
booktitle = {Proceedings of the 2009 WRI Global Congress on Intelligent Systems - Volume 03},
pages = {184–188},
numpages = {5},
keywords = {fabric defect detection, convolution mask, Gabor filter, GA},
series = {GCIS '09}
}

@inproceedings{10.1145/3375627.3375858,
author = {Zucker, Julian and d'Leeuwen, Myraeka},
title = {Arbiter: A Domain-Specific Language for Ethical Machine Learning},
year = {2020},
isbn = {9781450371100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375627.3375858},
doi = {10.1145/3375627.3375858},
abstract = {The widespread deployment of machine learning models in high- stakes decision making scenarios requires a code of ethics for machine learning practitioners. We identify four of the primary components required for the ethical practice of machine learn- ing: transparency, fairness, accountability, and reproducibility. We introduce Arbiter, a domain-specific programming language for machine learning practitioners that is designed for ethical machine learning. Arbiter provides a notation for recording how machine learning models will be trained, and we show how this notation can encourage the four described components of ethical machine learning.},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
pages = {421–425},
numpages = {5},
keywords = {domain-specific languages, ethical machine learning},
location = {New York, NY, USA},
series = {AIES '20}
}

@inproceedings{10.1145/2463676.2465338,
author = {Condie, Tyson and Mineiro, Paul and Polyzotis, Neoklis and Weimer, Markus},
title = {Machine learning for big data},
year = {2013},
isbn = {9781450320375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2463676.2465338},
doi = {10.1145/2463676.2465338},
abstract = {Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities.The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research.},
booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
pages = {939–942},
numpages = {4},
keywords = {machine learning, databases, big data},
location = {New York, New York, USA},
series = {SIGMOD '13}
}

@article{10.5555/2938006.2938019,
author = {Arcelli Fontana, Francesca and M\"{a}ntyl\"{a}, Mika V. and Zanoni, Marco and Marino, Alessandro},
title = {Comparing and experimenting machine learning techniques for code smell detection},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {3},
issn = {1382-3256},
abstract = {Several code smell detection tools have been developed providing different results, because smells can be subjectively interpreted, and hence detected, in different ways. In this paper, we perform the largest experiment of applying machine learning algorithms to code smells to the best of our knowledge. We experiment 16 different machine-learning algorithms on four code smells (Data Class, Large Class, Feature Envy, Long Method) and 74 software systems, with 1986 manually validated code smell samples. We found that all algorithms achieved high performances in the cross-validation data set, yet the highest performances were obtained by J48 and Random Forest, while the worst performance were achieved by support vector machines. However, the lower prevalence of code smells, i.e., imbalanced data, in the entire data set caused varying performances that need to be addressed in the future studies. We conclude that the application of machine learning to the detection of these code smells can provide high accuracy (&gt;96 %), and only a hundred training examples are needed to reach at least 95 % accuracy.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1143–1191},
numpages = {49},
keywords = {Machine learning techniques, Code smells detection, Benchmark for code smell detection}
}

@inproceedings{10.1007/978-3-030-68821-9_12,
author = {Dementev, Vitalii E. and Gaponova, Maria A. and Suetin, Marat R. and Streltzova, Anastasia S.},
title = {The Use of Machine Learning Methods to Detect Defects in Images of Metal Structures},
year = {2021},
isbn = {978-3-030-68820-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68821-9_12},
doi = {10.1007/978-3-030-68821-9_12},
abstract = {The work is devoted to the study of the possibilities provided by modern neural networks in image processing for solving the problem of monitoring the state of steel and reinforced concrete structures. The paper presents a method for solving problems of such monitoring based on the use of a combination of several neural networks focused on recognizing a fragment of a structure and parts of a structure. Methods for training neural networks on small training samples are proposed. The results of algorithms on real images that show the consistency and efficiency of the proposed solution are presented.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part V},
pages = {120–128},
numpages = {9},
keywords = {Deep learning, Neural networks, Adaptive algorithm, Recognition, Anomaly detection, Prediction}
}

@article{10.1016/j.jss.2009.12.023,
author = {de Carvalho, Andr\'{e} B. and Pozo, Aurora and Vergilio, Silvia Regina},
title = {A symbolic fault-prediction model based on multiobjective particle swarm optimization},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {5},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.12.023},
doi = {10.1016/j.jss.2009.12.023},
abstract = {In the literature the fault-proneness of classes or methods has been used to devise strategies for reducing testing costs and efforts. In general, fault-proneness is predicted through a set of design metrics and, most recently, by using Machine Learning (ML) techniques. However, some ML techniques cannot deal with unbalanced data, characteristic very common of the fault datasets and, their produced results are not easily interpreted by most programmers and testers. Considering these facts, this paper introduces a novel fault-prediction approach based on Multiobjective Particle Swarm Optimization (MOPSO). Exploring Pareto dominance concepts, the approach generates a model composed by rules with specific properties. These rules can be used as an unordered classifier, and because of this, they are more intuitive and comprehensible. Two experiments were accomplished, considering, respectively, fault-proneness of classes and methods. The results show interesting relationships between the studied metrics and fault prediction. In addition to this, the performance of the introduced MOPSO approach is compared with other ML algorithms by using several measures including the area under the ROC curve, which is a relevant criterion to deal with unbalanced data.},
journal = {J. Syst. Softw.},
month = may,
pages = {868–882},
numpages = {15},
keywords = {Rule learning algorithm, Particle swarm optimization, Multiobjective, Fault prediction}
}

@inproceedings{10.1109/iCECE.2010.253,
author = {Luhui, Lin and Jie, Ma},
title = {Fault Prediction Based on Data-Driven Technique},
year = {2010},
isbn = {9780769540313},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/iCECE.2010.253},
doi = {10.1109/iCECE.2010.253},
abstract = {This paper presents principal component analysis (PCA), some improvement of PCA and the development of PCA. PCA does not depend on the accurate mathematical model, is able to implement the feature extraction of the complex process data, and establishes a principal component model of the corresponding process. It can achieve the extraction of the system information and eliminate the interference the system. So there is the existence of a good applications prospect in the complex process of fault diagnosis and prediction maintain.},
booktitle = {Proceedings of the 2010 International Conference on Electrical and Control Engineering},
pages = {997–1001},
numpages = {5},
keywords = {principal component analysis (PCA), improvement, fault prediction, data-driven},
series = {ICECE '10}
}

@article{10.5555/1294141.1294145,
author = {Cucchiara, R. and Mello, P. and Piccardi, M. and Riguzzi, F.},
title = {An application of machine learning and statistics to defect detection},
year = {2001},
issue_date = {April 2001},
publisher = {IOS Press},
address = {NLD},
volume = {5},
number = {2},
issn = {1088-467X},
abstract = {We present an application of machine learning and statistics to the problem of distinguishing between defective and non-defective industrial workpieces, where the defect takes the form of a long and thin crack on the surface of the piece. From the images of pieces a number of features are extracted by using the Hough transform and the Correlated Hough transform. Two datasets are considered, one containing only features related to the Hough transform and the other containing also features related to the Correlated Hough transform. On these datasets we have compared six different learning algorithms: an attribute-value learner, C4.5, a backpropagation neural network, NeuralWorks Predict, a k-nearest neighbour algorithm, and three statistical techniques, linear, logistic and quadratic discriminant. The experiments show that C4.5 performs best for both feature sets and gives an average accuracy of 93.3% for the first dataset and 95.9% for the second dataset.},
journal = {Intell. Data Anal.},
month = apr,
pages = {151–164},
numpages = {14}
}

@article{10.1007/s11334-017-0295-0,
author = {Shatnawi, Raed},
title = {The application of ROC analysis in threshold identification, data imbalance and metrics selection for software fault prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {2–3},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-017-0295-0},
doi = {10.1007/s11334-017-0295-0},
abstract = {Software engineers have limited resources and need metrics analysis tools to investigate software quality such as fault-proneness of modules. There are a large number of software metrics available to investigate quality. However, not all metrics are strongly correlated with faults. In addition, software fault data are imbalanced and affect quality assessment tools such as fault prediction or threshold values that are used to identify risky modules. Software quality is investigated for three purposes. First, the receiver operating characteristics (ROC) analysis is used to identify threshold values to identify risky modules. Second, the ROC analysis is investigated for imbalanced data. Third, the ROC analysis is considered for feature selection. This work validated the use of ROC to identify thresholds for four metrics (WMC, CBO, RFC and LCOM). The ROC results after sampling the data are not significantly different from before sampling. The ROC analysis selects the same metrics (WMC, CBO and RFC) in most datasets, while other techniques have a large variation in selecting metrics.},
journal = {Innov. Syst. Softw. Eng.},
month = sep,
pages = {201–217},
numpages = {17},
keywords = {Software metrics, ROC analysis, Imbalanced data, Feature selection, Fault-proneness models}
}

@article{10.1155/2021/2668761,
author = {Zhang, Xiangquan and Ma, Zhili and Wang, Anmin and Mi, Haifeng and Hang, Junjun and Xiong, Jinbo},
title = {LstFcFedLear: A LSTM-FC with Vertical Federated Learning Network for Fault Prediction},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/2668761},
doi = {10.1155/2021/2668761},
abstract = {The firefighting IoT platform links multiple firefighting subsystems. The data of each subsystem belongs to the sensitive data of the profession. Failure prediction is a crucial topic for firefighting IoT platforms, because failures may cause equipment injuries. Currently, in the maintenance of fire IoT terminal equipment, fault prediction based on equipment time series has not been included. The use of intelligent technology to continuously predict the failure of firefighting IoT equipment can not only eliminate the intervention of regular maintenance but also provide early warning of upcoming failures. In order to solve this problem, we propose a vertical federated learning framework based on LSTM fault classification network (LstFcFedLear). The advantage of this framework is that it can encrypt and integrate the data on the entire firefighting IoT platform to form a new dataset. After the synthesized data is trained through each model, the optimal model parameters can be finally updated. At the same time, it can ensure that the data of each business system is not leaked. The framework can predict when IoT equipment will fail in the future and then provide what measures should be used. The experimental results show that the LstFcFedLear model provides an effective method for fault prediction, and its results are comparable to the baseline.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@article{10.1016/j.patcog.2009.09.006,
author = {Tsneg, Yan-Hsin and Tsai, Du-Ming},
title = {Defect detection of uneven brightness in low-contrast images using basis image representation},
year = {2010},
issue_date = {March, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {43},
number = {3},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2009.09.006},
doi = {10.1016/j.patcog.2009.09.006},
abstract = {In this paper, we propose a machine vision approach for detecting local irregular brightness in low-contrast surface images and, especially, focus on mura (brightness non-uniformity) defects in liquid crystal display (LCD) panels. A mura defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may also present uneven illumination on the surface. All these make the mura defect detection in low-contrast surface images extremely difficult. A set of basis images derived from defect-free surface images are used to represent the general appearance of a clear surface. An image to be inspected is then constructed as a linear combination of the basis images, and the coefficients of the combination form the feature vector for discriminating mura defects from clear surfaces. In order to find minimum number of basis images for efficient and effective representation, the basis images are designed such that they are both statistically independent and spatially exclusive. An independent component analysis-based model that finds both the maximum negentropy for statistical independency and minimum spatial correlation for spatial redundancy is proposed to extract the representative basis images. Experimental results have shown that the proposed method can effectively detect various mura defects in low-contrast LCD panel images.},
journal = {Pattern Recogn.},
month = mar,
pages = {1129–1141},
numpages = {13},
keywords = {Surface inspection, Particle swarm optimization, Independent component analysis, Defect detection, Basis image representation}
}

@article{10.1016/j.eswa.2010.08.022,
author = {Catal, Cagatay and Sevim, Ugur and Diri, Banu},
title = {Practical development of an Eclipse-based software fault prediction tool using Naive Bayes algorithm},
year = {2011},
issue_date = {March, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.08.022},
doi = {10.1016/j.eswa.2010.08.022},
abstract = {Despite the amount of effort software engineers have been putting into developing fault prediction models, software fault prediction still poses great challenges. This research using machine learning and statistical techniques has been ongoing for 15years, and yet we still have not had a breakthrough. Unfortunately, none of these prediction models have achieved widespread applicability in the software industry due to a lack of software tools to automate this prediction process. Historical project data, including software faults and a robust software fault prediction tool, can enable quality managers to focus on fault-prone modules. Thus, they can improve the testing process. We developed an Eclipse-based software fault prediction tool for Java programs to simplify the fault prediction process. We also integrated a machine learning algorithm called Naive Bayes into the plug-in because of its proven high-performance for this problem. This article presents a practical view to software fault prediction problem, and it shows how we managed to combine software metrics with software fault data to apply Naive Bayes technique inside an open source platform.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {2347–2353},
numpages = {7},
keywords = {Software fault prediction, Naive Bayes, Machine learning, Eclipse technology}
}

@inproceedings{10.1145/3472735.3474458,
author = {Boutaba, Raouf and Shahriar, Nashid and Salahuddin, Mohammad A. and Chowdhury, Shihabur R. and Saha, Niloy and James, Alexander},
title = {AI-driven Closed-loop Automation in 5G and beyond Mobile Networks},
year = {2021},
isbn = {9781450386340},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472735.3474458},
doi = {10.1145/3472735.3474458},
abstract = {The 5th Generation (5G) mobile networks support a wide range of services that impose diverse and stringent QoS requirements. This will be further exacerbated with the evolution towards 6th Generation mobile networks. Inevitably, 5G and beyond mobile networks must provide stricter, differentiated QoS guarantees to meet the increasing demands of future applications, which cannot be satisfied with traditional human-in-the-loop service orchestration and network management approaches. In this paper, we lay out our vision for closed-loop service orchestration and network management of 5G and beyond mobile networks. We extend the MAPE (i.e., monitor, analyze, plan, and execute) control loop to facilitate closed-loop automation, and discuss the quintessential role of Artificial Intelligence/Machine Learning in its realization. We also instigate open research challenges for closed-loop automation of 5G and beyond mobile networks.},
booktitle = {Proceedings of the 4th FlexNets Workshop on Flexible Networks Artificial Intelligence Supported Network Flexibility and Agility},
pages = {1–6},
numpages = {6},
keywords = {machine learning, closed-loop orchestration and management, artificial intelligence, 5G},
location = {Virtual Event, USA},
series = {FlexNets '21}
}

@article{10.1007/s00500-019-04047-7,
author = {Sudharson, D. and Prabha, D.},
title = {RETRACTED ARTICLE: A novel machine learning
approach for software reliability growth modelling with pareto distribution
function},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-04047-7},
doi = {10.1007/s00500-019-04047-7},
abstract = {Software reliability is the important quantifiable attribute in gaining
reliability by assessing faults at the time of testing in the software products.
Time-based software reliability models used to identify the defects in the product,
and it is not suitable for dynamic situations. Instead of time, test effect is used
in few explorations through effort function and it is not realistic for infinite
testing time. Identifying number of defects is essential in software reliability
models, and this research work presents a Pareto distribution (PD) to predict the
fault distribution of software under homogenous and nonhomogeneous conditions along
with artificial neural network (ANN). This methodology enables the parallel
evolution of a product through NN models which exhibit estimated Pareto optimality
with respect to multiple error measures. The proposed PD-ANN-based SRGM describes
types of failure data and also improves the accuracy of parameter estimation more
than existing growth models such as homogeneous poison process and two fuzzy time
series-based software reliability models. Experimental evidence is presented for
general application and the proposed framework by generating solutions for different
product and developer indexes.},
journal = {Soft Comput.},
month = sep,
pages = {8379–8387},
numpages = {9},
keywords = {Software reliability, Artificial neural networks, Pareto distribution, Distribution parameter estimation}
}

@article{10.1155/2018/7913952,
author = {Hoang, Nhat-Duc and Peric, Zoran},
title = {Image Processing-Based Recognition of Wall Defects Using Machine Learning Approaches and Steerable Filters},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/7913952},
doi = {10.1155/2018/7913952},
abstract = {Detection of defects including cracks and spalls on wall surface in high-rise buildings is a crucial task of buildings’ maintenance. If left undetected and untreated, these defects can significantly affect the structural integrity and the aesthetic aspect of buildings. Timely and cost-effective methods of building condition survey are of practicing need for the building owners and maintenance agencies to replace the time- and labor-consuming approach of manual survey. This study constructs an image processing approach for periodically evaluating the condition of wall structures. Image processing algorithms of steerable filters and projection integrals are employed to extract useful features from digital images. The newly developed model relies on the Support vector machine and least squares support vector machine to generalize the classification boundaries that categorize conditions of wall into five labels: longitudinal crack, transverse crack, diagonal crack, spall damage, and intact wall. A data set consisting of 500 image samples has been collected to train and test the machine learning based classifiers. Experimental results point out that the proposed model that combines the image processing and machine learning algorithms can achieve a good classification performance with a classification accuracy rate = 85.33%. Therefore, the newly developed method can be a promising alternative to assist maintenance agencies in periodic building surveys.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {18}
}

@inbook{10.1007/978-3-540-89778-1_4,
author = {Feather, Martin S.},
title = {Defect Detection and Prevention (DDP)},
year = {2008},
isbn = {9783540897774},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-89778-1_4},
abstract = {The Defect Detection and Prevention (DDP) decision support process, developed at JPL, has over the last 8 years been applied to assist in making a variety of spacecraft decisions. It was originally conceived of as a means to help select and plan hardware assurance activities (inspections, tests, etc) [1], generally late in the development lifecycle. However, since then it has been used predominantly in early phase of system design, when information is scarce, yet many critical decisions are made. Its range of application has extended to encompass a wide variety of kinds of systems and technologies. Its predominant role has been to assist in planning the maturation of promising new technologies to help guide the next steps in their development as they emerge from the laboratory and seek to mature sufficiently to become acceptable to spacecraft missions [2]. Although this may at first glance seem far removed from terrestrial considerations, the factors that come into play in this kind of decision-making are universal - unclear and inconsistent perceptions about requirements and capabilities, uncertainty of what are the driving concerns that should be addressed and how best to address them, challenges of gathering and combining information from experts of multiple difference disciplines, and inevitably the lack of sufficient resources (money, time, CPU, power, ...) to do everything one would wish. Other significant applications of DDP have been as the risk management tool for entire spacecraft projects in their early phases of development, as an aid to planning portfolios of mission activities (e.g., [3]), and as a means to help guide R&amp;D decisions (e.g., [4], [5]).},
booktitle = {Innovations for Requirement Analysis. From Stakeholders' Needs to Formal Designs: 14th Monterey Workshop 2007, Monterey, CA, USA, September 10-13, 2007. Revised Selected Papers},
pages = {13–14},
numpages = {2}
}

@article{10.1016/j.infsof.2019.05.009,
author = {Nashaat, Mona and Ghosh, Aindrila and Miller, James and Quader, Shaikh and Marston, Chad},
title = {M-Lean: An end-to-end development framework for predictive models in B2B scenarios},
year = {2019},
issue_date = {Sep 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {113},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.05.009},
doi = {10.1016/j.infsof.2019.05.009},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {131–145},
numpages = {15},
keywords = {Case study, User trust, Business-to-business, Machine learning, Big data}
}

@inproceedings{10.1007/978-3-030-05499-1_8,
author = {Kopaczka, Marcin and Saggiomo, Marco and G\"{u}ttler, Moritz and Kielholz, Kevin and Merhof, Dorit},
title = {Detection and Classification of Faulty Weft Threads Using Both Feature-Based and Deep Convolutional Machine Learning Methods},
year = {2018},
isbn = {978-3-030-05498-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-05499-1_8},
doi = {10.1007/978-3-030-05499-1_8},
abstract = {In our work, we analyze how faulty weft threads in air-jet weaving machines can be detected using image processing methods. To this end, we design and construct a multi-camera array for automated acquisition of images of relevant machine areas. These images are subsequently fed into a multi-stage image processing pipeline that allows defect detection using a set of different preprocessing and classification methods. Classification is performed using both image descriptors combined with feature-based machine learning algorithms and deep learning techniques implementing fully convolutional neural networks. To analyze the capabilities of our solution, system performance is thoroughly evaluated under realistic production settings. We show that both approaches show excellent detection rates and that by utilizing semantic segmentation acquired from a fully convolutional network we are not only able to detect defects reliably but also classify defects into different subtypes, allowing more refined strategies for defect removal.},
booktitle = {Pattern Recognition Applications and Methods: 7th International Conference, ICPRAM 2018, Funchal, Madeira, Portugal, January 16-18, 2018, Revised Selected Papers},
pages = {141–163},
numpages = {23},
location = {Funchal, Portugal}
}

@article{10.1016/j.asoc.2016.04.032,
author = {Malhotra, Ruchika},
title = {An empirical framework for defect prediction using machine learning techniques with Android software},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.032},
doi = {10.1016/j.asoc.2016.04.032},
abstract = {Display Omitted Use of appropriate and large number data sets for comparing 18 ML techniques for defect prediction using object-oriented metrics.Effective performance of the predicted models assessed using appropriate performance measures.Reliability of the results evaluated using statistical test and post-hoc analysis.Validating the predicted models using inter-release validation on various releases of seven application packages of Android software. ContextSoftware defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. ObjectiveThe main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. MethodIn this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, MMS, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. ResultsThe results show that the area under the curve measure for Nave Bayes, LogitBoost and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the ML techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. ConclusionThe results confirm the predictive capability of various ML techniques for developing defect prediction models. The results also confirm the superiority of one ML technique over the other ML techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1034–1050},
numpages = {17},
keywords = {Statistical tests, Software defect proneness, Object-oriented metrics, Machine-learning, Inter-release validation}
}

@inproceedings{10.1007/978-3-642-38577-3_68,
author = {D\'{\i}ez-Pastor, Jos\'{e} Francisco and Garc\'{\i}a-Osorio, C\'{e}sar and Barbero-Garc\'{\i}a, V\'{\i}ctor and Blanco-\'{A}lamo, Alan},
title = {Imbalanced learning ensembles for defect detection in X-ray images},
year = {2013},
isbn = {9783642385766},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-38577-3_68},
doi = {10.1007/978-3-642-38577-3_68},
abstract = {This paper describes the process of detection of defects in metallic pieces through the analysis of X-ray images. The images used in this work are highly variable (several different pieces, different views, variability introduced by the inspection process such as positioning the piece). Because of this variability, the sliding window technique has been used, an approach based on data mining. Experiments have been carried out with various window sizes, several feature selection algorithms and different classification algorithms, with a special focus on learning unbalanced data sets. The results show that Bagging achieved significantly better results than decision trees by themselves or combined with SMOTE or Undersampling.},
booktitle = {Proceedings of the 26th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},
pages = {654–663},
numpages = {10},
keywords = {x-ray, undersampling, non destructive testing, ensemble learning, bagging, SMOTE},
location = {Amsterdam, The Netherlands},
series = {IEA/AIE'13}
}

@article{10.1109/TKDE.2011.163,
author = {Bishnu, Partha S. and Bhattacherjee, Vandana},
title = {Software Fault Prediction Using Quad Tree-Based K-Means Clustering Algorithm},
year = {2012},
issue_date = {June 2012},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {24},
number = {6},
issn = {1041-4347},
url = {https://doi.org/10.1109/TKDE.2011.163},
doi = {10.1109/TKDE.2011.163},
abstract = {Unsupervised techniques like clustering may be used for fault prediction in software modules, more so in those cases where fault labels are not available. In this paper a Quad Tree-based K-Means algorithm has been applied for predicting faults in program modules. The aims of this paper are twofold. First, Quad Trees are applied for finding the initial cluster centers to be input to the K-Means Algorithm. An input threshold parameter delta governs the number of initial cluster centers and by varying delta the user can generate desired initial cluster centers. The concept of clustering gain has been used to determine the quality of clusters for evaluation of the Quad Tree-based initialization algorithm as compared to other initialization techniques. The clusters obtained by Quad Tree-based algorithm were found to have maximum gain values. Second, the Quad Tree-based algorithm is applied for predicting faults in program modules. The overall error rates of this prediction approach are compared to other existing algorithms and are found to be better in most of the cases.},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = jun,
pages = {1146–1150},
numpages = {5},
keywords = {software fault prediction., Quad Tree, K-Means clustering}
}

@inproceedings{10.1007/978-3-642-39068-5_56,
author = {Nawaz, Javeria Muhammad and Arshad, Muhammad Zeeshan and Hong, Sang Jeen},
title = {Time series fault prediction in semiconductor equipment using recurrent neural network},
year = {2013},
isbn = {9783642390678},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39068-5_56},
doi = {10.1007/978-3-642-39068-5_56},
abstract = {This paper presents a model of Elman recurrent neural network (ERNN) for time series fault prediction in semiconductor etch equipment. ERNN maintains a copy of previous state of the input in its context units, as well as the current state of the input. Derivative dynamic time warping (DDTW) method is also discussed for the synchronization of time series data set acquired from plasma etcher. For each parameter of the data, the best ERNN structure was selected and trained using Levenberg Marquardt to generate one-step-ahead prediction for 10 experimental runs. The faulty experimental runs were successfully distinguished from healthy experimental runs with one missed alarm out of ten experimental runs.},
booktitle = {Proceedings of the 10th International Conference on Advances in Neural Networks - Volume Part II},
pages = {463–472},
numpages = {10},
keywords = {time series prediction, recurrent neural network, derivative dynamic time warping},
location = {Dalian, China},
series = {ISNN'13}
}

@article{10.1016/j.engappai.2013.01.008,
author = {Rafael Lenz, Alexandre and Pozo, Aurora and Regina Vergilio, Silvia},
title = {Linking software testing results with a machine learning approach},
year = {2013},
issue_date = {May, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {26},
number = {5–6},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2013.01.008},
doi = {10.1016/j.engappai.2013.01.008},
abstract = {Software testing techniques and criteria are considered complementary since they can reveal different kinds of faults and test distinct aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated and are usually manually applied. Structural and fault-based criteria generally provide measures to evaluate test sets. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning techniques to link test results from the application of different testing techniques. The approach groups test data into similar functional clusters. After this, according to the tester's goals, it generates classifiers (rules) that have different uses, including selection and prioritization of test cases. The paper also presents results from experimental evaluations and illustrates such uses.},
journal = {Eng. Appl. Artif. Intell.},
month = may,
pages = {1631–1640},
numpages = {10},
keywords = {Test coverage criteria, Software testing, Machine learning}
}

@article{10.1145/2000799.2000803,
author = {Dehlinger, Josh and Lutz, Robyn R.},
title = {Gaia-PL: A Product Line Engineering Approach for Efficiently Designing Multiagent Systems},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/2000799.2000803},
doi = {10.1145/2000799.2000803},
abstract = {Agent-oriented software engineering (AOSE) has provided powerful and natural, high-level abstractions in which software developers can understand, model and develop complex, distributed systems. Yet, the realization of AOSE partially depends on whether agent-based software systems can achieve reductions in development time and cost similar to other reuse-conscious development methods. Specifically, AOSE does not adequately address requirements specifications as reusable assets. Software product line engineering is a reuse technology that supports the systematic development of a set of similar software systems through understanding, controlling, and managing their common, core characteristics and their differing variation points. In this article, we present an extension to the Gaia AOSE methodology, named Gaia-PL (Gaia-Product Line), for agent-based distributed software systems that enables requirements specifications to be easily reused. We show how our methodology uses a product line perspective to promote reuse in agent-based software systems early in the development life cycle so that software assets can be reused throughout system development and evolution. We also present results from an application to show how Gaia-PL provided reuse that reduced the design and development effort for a large, multiagent system.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {17},
numpages = {27},
keywords = {software product line engineering, Agent-oriented software engineering}
}

@inproceedings{10.1007/978-3-030-55789-8_25,
author = {Saeed, Faisal and Paul, Anand and Rho, Seungmin},
title = {Faster R-CNN Based Fault Detection in Industrial Images},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_25},
doi = {10.1007/978-3-030-55789-8_25},
abstract = {Industry 4.0 requires smart environment to find defects or faults in their products. A defective product in the market can impact negatively on the overall image of the industry. Thus, there is continuous struggle for industrial environment to reduce impulsive downtime, concert deprivation and safety risks. Defect detection in industrial products using the images is very hot topic in era of current research. Machine learning provides various solution but most of the time such solutions are not suitable for environment where product is on conveyor belt and traveling from one point to another. To detect fault using industrial images, we proposed a method which is based on Faster R-CNN which is suitable for smart environment as it can the product efficiently. We simulated our environment using python language and proposed model has almost 99% accuracy. To make our proposed scheme adaptable for the industry 4.0, we also developed an android application which make it easy to interact with the model and industry can train this model according to their needs. Android application is able to take pictures of defective product and feed it to model which improve accuracy and eventually reduces time identify defective product.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {280–287},
numpages = {8},
keywords = {RPN, Fast R-CNN, Convolution neural networks, Fault identification, Defect detection, Industrial images},
location = {Kitakyushu, Japan}
}

@article{10.1016/j.imavis.2006.07.028,
author = {Han, Yanfang and Shi, Pengfei},
title = {An adaptive level-selecting wavelet transform for texture defect detection},
year = {2007},
issue_date = {August, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {25},
number = {8},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2006.07.028},
doi = {10.1016/j.imavis.2006.07.028},
abstract = {We present an effective approach based on wavelet transform (WT) to detect defects on images with high frequency texture background. The original image is decomposed at various levels by WT. Then, by selecting an appropriate level at which the approximation sub-image is reconstructed, textures on the background are effectively removed. Thus, the difficult texture defect detection problem can be settled by non-texture techniques. An adaptive level-selecting scheme is presented by analyzing the co-occurrence matrices (COM) of the approximation sub-images. Experiments are done to detect the stains and broken points on texture surfaces. Comparisons with frequency domain low and high pass filters show that our method is much more effective.},
journal = {Image Vision Comput.},
month = aug,
pages = {1239–1248},
numpages = {10},
keywords = {Wavelet transform, Texture image processing, Defect detection, Co-occurrence matrix}
}

@inproceedings{10.1109/ICPR.2006.419,
author = {Amano, Toshiyuki},
title = {Correlation Based Image Defect Detection},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.419},
doi = {10.1109/ICPR.2006.419},
abstract = {The defect inspection that used image sensing such as automated pattern inspection is a useful solution to automatize the visual check, not limit to factory automation field. Mostly such defect inspection is using the models of defect that described by primitive features. This paper proposes a new defect detection method that is the non-model based approach. In this approach, the method extracts the image description rule from local regions.It is useful for the defect inspection problems that cannot prepare a defect model such as scratch or superimpose detection, texture image analysis, etc. In the experiment, I tried the defect detection to the landscape picture which several types of superimpose were added. From these results, it was confirmed that the proposed method has high ability to detect the defected regions independently with the texture type.Furthermore, I attempted the application to a scene image.Therefrom, the possibility to apply the figure-ground separation of the image understanding basic problem was confirmed.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 01},
pages = {163–166},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.5555/2755753.2757136,
author = {Liaperdos, John and Arapoyanni, Angela and Tsiatouhas, Yiorgos},
title = {A method for the estimation of defect detection probability of analog/RF defect-oriented tests},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {A method to realistically estimate the defect detection probability achieved by defect-oriented analog/RF integrated circuit tests at the circuit design level is presented in this paper. The proposed method also provides insight to the efficiency of the various available defect-oriented testing techniques, thus allowing the selection of the most suitable for a specific circuit. The effect of structural defects in the presence of process variations and device mismatches is taken into account, by the exploitation of the defect probability distributions and the statistical models of the used technology. Although the proposed methodology is generally applicable to the entire class of analog circuits, its application to simple RF circuits which consist of a few elements seems to be more practical, due to the affordable computational cost implied by circuits with shorter defect dictionaries. In order to obtain results without a reliability compromise, the number of required statistical simulation runs is reduced through regression. The application of the proposed method on a typical RF mixer, designed in a 0.18μm CMOS technology, is also presented.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {1395–1400},
numpages = {6},
location = {Grenoble, France},
series = {DATE '15}
}

@article{10.1155/2019/8097213,
author = {Hoang, Nhat-Duc and Tran, Van-Duc and G\'{o}mez-Pulido, Juan A.},
title = {Image Processing-Based Detection of Pipe Corrosion Using Texture Analysis and Metaheuristic-Optimized Machine Learning Approach},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1687-5265},
url = {https://doi.org/10.1155/2019/8097213},
doi = {10.1155/2019/8097213},
abstract = {To maintain the serviceability of buildings, the owners need to be informed about the current condition of the water supply and waste disposal systems. Therefore, timely and accurate detection of corrosion on pipe surface is a crucial task. The conventional manual surveying process performed by human inspectors is notoriously time consuming and labor intensive. Hence, this study proposes an image processing-based method for automating the task of pipe corrosion detection. Image texture including statistical measurement of image colors, gray-level co-occurrence matrix, and gray-level run length is employed to extract features of pipe surface. Support vector machine optimized by differential flower pollination is then used to construct a decision boundary that can recognize corroded and intact pipe surfaces. A dataset consisting of 2000 image samples has been collected and utilized to train and test the proposed hybrid model. Experimental results supported by the Wilcoxon signed-rank test confirm that the proposed method is highly suitable for the task of interest with an accuracy rate of 92.81%. Thus, the model proposed in this study can be a promising tool to assist building maintenance agents during the phase of pipe system survey.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1155/2019/8391425,
author = {Ren, Jiadong and Zheng, Zhangqi and Liu, Qian and Wei, Zhiyao and Yan, Huaizhi and Chen, Jiageng},
title = {A Buffer Overflow Prediction Approach Based on Software Metrics and Machine Learning},
year = {2019},
issue_date = {2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2019},
issn = {1939-0114},
url = {https://doi.org/10.1155/2019/8391425},
doi = {10.1155/2019/8391425},
abstract = {Buffer overflow vulnerability is the most common and serious type of vulnerability in software today, as network security issues have become increasingly critical. To alleviate the security threat, many vulnerability mining methods based on static and dynamic analysis have been developed. However, the current analysis methods have problems regarding high computational time, low test efficiency, low accuracy, and low versatility. This paper proposed a software buffer overflow vulnerability prediction method by using software metrics and a decision tree algorithm. First, the software metrics were extracted from the software source code, and data from the dynamic data stream at the functional level was extracted by a data mining method. Second, a model based on a decision tree algorithm was constructed to measure multiple types of buffer overflow vulnerabilities at the functional level. Finally, the experimental results showed that our method ran in less time than SVM, Bayes, adaboost, and random forest algorithms and achieved 82.53% and 87.51% accuracy in two different data sets. The method presented in this paper achieved the effect of accurately predicting software buffer overflow vulnerabilities in C/C++ and Java programs.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {13}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00032,
author = {Parthy, Abhaya and Silberstein, Leo and Kowalczyk, Emily and High, John-Paul and Nagarajan, Adithya and Memon, Atif},
title = {Using machine learning to recommend correctness checks for geographic map data},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00032},
doi = {10.1109/ICSE-SEIP.2019.00032},
abstract = {Developing an industry application that serves geographic map data to users across the world presents the significant challenge of checking the data using "data correctness checks." The size of data that needs to be checked---the entire world---and data churn rate---thousands per day---makes executing the full set of candidate checks cost prohibitive. Current techniques rely on hand-curated static subsets of checks to be run at different stages of the data production pipeline, These hard-coded subsets are uninformed of data changes, and cause bug detection to be delayed to downstream quality assurance activities. To address these problems, we have developed new representations of map data changes and checks, formally defined "check safety," and built a recommender system that dynamically and automatically selects and ranks a relevant subset of checks using signals from latest data changes. Empirical evaluation shows that it improves (1) efficiency by eliminating 65% of checks unrelated to changes, (2) coverage by recommending and ranking change-related checks from the full set of candidate checks, previously excluded by the manual process, and (3) overall visibility into the data editing process by quickly and automatically identifying latest fault prone parts of the data.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {223–232},
numpages = {10},
keywords = {safe test/check selection, data check recommender, automated data validation},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1109/ICCIT.2008.217,
author = {Choi, Jihee and Jeong, Hong},
title = {Self-Inspection for Defect Detection in Photomask Image},
year = {2008},
isbn = {9780769534077},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCIT.2008.217},
doi = {10.1109/ICCIT.2008.217},
abstract = {This paper describes a new method for the process of extracting photomask defects using a single optical photomask image which is not aligned. The lines of a photomask picture are not parallel with the pixel grid, and so there is always a angle of error. Only one sample image which contains defects was used in our tests. The algorithm is effective because we only need one sample photomask image. It not only extracts general patterns of photomask defects but also relatively small and discontinuous patterns.},
booktitle = {Proceedings of the 2008 Third International Conference on Convergence and Hybrid Information Technology - Volume 01},
pages = {364–368},
numpages = {5},
keywords = {self-inspection, photomask, defect detection, rotation},
series = {ICCIT '08}
}

@inproceedings{10.1109/ICTAI.2010.27,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Seliya, Naeem},
title = {Attribute Selection and Imbalanced Data: Problems in Software Defect Prediction},
year = {2010},
isbn = {9780769542638},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2010.27},
doi = {10.1109/ICTAI.2010.27},
abstract = {The data mining and machine learning community is often faced with two key problems: working with imbalanced data and selecting the best features for machine learning. This paper presents a process involving a feature selection technique for selecting the important attributes and a data sampling technique for addressing class imbalance. The application domain of this study is software engineering, more specifically, software quality prediction using classification models. When using feature selection and data sampling together, different scenarios should be considered. The four possible scenarios are: (1) feature selection based on original data, and modeling (defect prediction) based on original data; (2) feature selection based on original data, and modeling based on sampled data; (3) feature selection based on sampled data, and modeling based on original data; and (4) feature selection based on sampled data, and modeling based on sampled data. The research objective is to compare the software defect prediction performances of models based on the four scenarios. The case study consists of nine software measurement data sets obtained from the PROMISE software project repository. Empirical results suggest that feature selection based on sampled data performs significantly better than feature selection based on original data, and that defect prediction models perform similarly regardless of whether the training data was formed using sampled or original data.},
booktitle = {Proceedings of the 2010 22nd IEEE International Conference on Tools with Artificial Intelligence - Volume 01},
pages = {137–144},
numpages = {8},
keywords = {software measurements, feature selection, defect prediction, data sampling},
series = {ICTAI '10}
}

@article{10.1155/2008/783898,
author = {Tajeripour, F. and Kabir, E. and Sheikhi, A.},
title = {Fabric defect detection using modified local binary patterns},
year = {2008},
issue_date = {January 2008},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2008},
issn = {1110-8657},
url = {https://doi.org/10.1155/2008/783898},
doi = {10.1155/2008/783898},
abstract = {Local binary patterns (LBPs) are one of the features which have been used for texture classification. In this paper, a method based on using these features is proposed for fabric defect detection. In the training stage, at first step, LBP operator is applied to an image of defect free fabric, pixel by pixel, and the reference feature vector is computed. Then this image is divided into windows and LBP operator is applied to each of these windows. Based on comparison with the reference feature vector, a suitable threshold for defect free windows is found. In the detection stage, a test image is divided into windows and using the threshold, defective windows can be detected. The proposed method is multiresolution and gray scale invariant and can be used for defect detection in patterned and unpatterned fabrics. Because of its simplicity, online implementation is possible as well.},
journal = {EURASIP J. Adv. Signal Process},
month = jan,
articleno = {60},
numpages = {12}
}

@article{10.1016/j.engappai.2008.05.006,
author = {Bu, Hong-gang and Wang, Jun and Huang, Xiu-bao},
title = {Fabric defect detection based on multiple fractal features and support vector data description},
year = {2009},
issue_date = {March, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {22},
number = {2},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2008.05.006},
doi = {10.1016/j.engappai.2008.05.006},
abstract = {Computer-vision-based automatic detection of fabric defects is one of the difficult one-class classification tasks in the real world. To overcome the incapacity of a single fractal feature in dealing with this task, multiple fractal features have been extracted in the light of the theory of and problems present in the box-counting method as well as the inherent characteristics of woven fabrics. Based on statistical learning theory, the up-to-date support vector data description (SVDD) is an excellent approach to the problem of one-class classification. A robust new scheme is presented in this paper for optimally selecting values of the parameters especially that of the scale parameter of the Gaussian kernel function involved in the training of the SVDD model. Satisfactory experimental results are finally achieved by jointly applying the extracted multiple fractal features and SVDD to the detection of defects from several datasets of fabric samples with different texture backgrounds.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {224–235},
numpages = {12},
keywords = {Support vector data description, Optimum seeking of parameters, One-class classification, Multiple fractal features, Fabric defect detection}
}

@article{10.1049/iet-sen.2013.0008,
author = {Shatnawi, Raed},
title = {Empirical study of fault prediction for open‐source systems using the Chidamber and Kemerer metrics},
year = {2014},
issue_date = {June 2014},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2013.0008},
doi = {10.1049/iet-sen.2013.0008},
abstract = {Software testers are usually provoked with projects that have faults. Predicting a class's fault‐proneness is vital for minimising cost and improving the effectiveness of the software testing. Previous research on software metrics has shown strong relationships between software metrics and faults in object‐oriented systems using a binary variable. However, these models do not consider the history of faults in classes. In this work, a dependent variable is proposed that uses fault history to rate classes into four categories (none, low risk, medium risk and high risk) and to improve the predictive capability of fault models. The study is conducted on many releases of four open‐source systems. The study tests the statistical differences in seven machine learning algorithms to find whether the proposed variable can be used to build better prediction models. The performance of the classifiers using the four categories is significantly better than the binary variable. In addition, the results show improvements on the reliability of the prediction models as the software matures. Therefore the fault history improves the prediction of fault‐proneness of classes in open‐source systems.},
journal = {IET Software},
month = jun,
pages = {113–119},
numpages = {7},
keywords = {machine learning algorithms, statistical differences, binary variable, object-oriented systems, software metrics, software testing, software testers, Chidamber metrics, Kemerer metrics, open-source systems, fault prediction, software metrics, public domain software, program testing, object-oriented methods, learning (artificial intelligence)}
}

@inproceedings{10.1109/ISISE.2008.139,
author = {Guan, Shengqi and Shi, Xiuhua},
title = {Fabric Defect Detection Based on Wavelet Decomposition with One Resolution Level},
year = {2008},
isbn = {9780769534947},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2008.139},
doi = {10.1109/ISISE.2008.139},
abstract = {According to the property of wavelet transform and fabric texture's Fourier spectrum, a new method for defect detection was presented. The proposed method is based on wavelet lifting transform with one resolution level. By using restoration scheme of the Fourier transform, the normal fabric textures of smooth sub-image in the spatial domain are removed by detecting the high-energy frequency components of sub-image in the Fourier domain, setting them to zero using frequency-domain filter, and back-transforming to a spatial domain sub-image. Then, the smooth and detail sub-images are segmented into many sub-windows, in which standard deviation are calculated as extracted features. The extracted features are compared with normal sub-window's features to determine whether there exists defect. Experimental results show that this method is validity and feasibility.},
booktitle = {Proceedings of the 2008 International Symposium on Information Science and Engieering - Volume 01},
pages = {281–285},
numpages = {5},
keywords = {wavelet transform, lifting scheme, frequency-domain filter, fourier transform, Defect detection},
series = {ISISE '08}
}

@inproceedings{10.5555/2666527.2666533,
author = {Morgado, In\^{e}s Coimbra and Paiva, Ana C. R. and Faria, Jo\~{a}o Pascoal and Camacho, Rui},
title = {GUI reverse engineering with machine learning},
year = {2012},
isbn = {9781467317535},
publisher = {IEEE Press},
abstract = {This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.},
booktitle = {Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering},
pages = {27–31},
numpages = {5},
keywords = {reverse engineering, model-based testing, machine learning, inductive logic programming},
location = {Zurich, Switzerland},
series = {RAISE '12}
}

@inproceedings{10.1109/MICAI.2008.38,
author = {Virk, Shafqat M. and Muhammad, Aslam and Martinez-Enriquez, A. M.},
title = {Fault Prediction Using Artificial Neural Network and Fuzzy Logic},
year = {2008},
isbn = {9780769534411},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICAI.2008.38},
doi = {10.1109/MICAI.2008.38},
abstract = {This paper studies different vehicle fault prediction techniques, using artificial neural network and fuzzy logic based model. With increasing demands for efficiency and product quality as well as progressing integration of automatic control systems in high-cost mechatronics and safety-critical processes, monitoring is necessary to detect and diagnose faults using symptoms and related data. However, beyond protective maintenance services, it is viable to integrate fault prediction services. Thus, we studied different parameters to model a fault prediction service. This service not only helps to predict faults but is also useful to take precautionary measures to avoid tangible and intangible losses.},
booktitle = {Proceedings of the 2008 Seventh Mexican International Conference on Artificial Intelligence},
pages = {149–154},
numpages = {6},
keywords = {Faults, Artificial Neural Network, Fuzzy Logic, Neuro-Fuzzy, Neuro-Neuro, Recurrent Neural Network, Back-propagation},
series = {MICAI '08}
}

@article{10.1016/j.patcog.2008.02.011,
author = {Tsai, Du-Ming and Lai, Shia-Chih},
title = {Defect detection in periodically patterned surfaces using independent component analysis},
year = {2008},
issue_date = {September, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {41},
number = {9},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2008.02.011},
doi = {10.1016/j.patcog.2008.02.011},
abstract = {In this paper, we propose a fast self-comparison scheme for defect detection in structural surfaces containing periodic complicated patterns. It works directly on a one-dimensional line image, instead of a two-dimensional array image, that contains a periodic pattern in the line. The proposed self-comparison scheme is simply carried out by dividing a sensed line image into two segments of equal length. Since the line image contains a periodic pattern, the two divided segments are only translated versions to each other. In this study, an independent component analysis (ICA) model is proposed to obtain the de-mixing matrix that can recover the translation between the two divided segments. The proposed ICA model directly measures the independency of signals by minimizing the difference between the joint probability density function (PDF) and the product of marginal PDFs, in which the PDFs are estimated by relative frequency distributions. The particle swarm optimization (PSO) algorithm is used to search for the de-mixing matrix. The proposed ICA model can effectively separate highly correlated signals, and is well suited for translation recovery between two signals with the same periodic pattern. In the detection stage, each line image is first divided into two segments, and the de-mixing matrix learned off-line from a defect-free line image is used to recover the signals with well aligned translation. The normalized cross-correlation is adopted to measure the similarity between two compared segments. Since the de-mixing matrix is only of a small size of 2x2, the proposed method in the detection stage is very computationally efficient. The performance of the proposed method is demonstrated with test samples of TFT-LCD panels and color filters found in LCD manufacturing. Experimental results have shown that the proposed self-comparison scheme can effectively and efficiently detect the presence of defects in periodically patterned surfaces.},
journal = {Pattern Recogn.},
month = sep,
pages = {2812–2832},
numpages = {21},
keywords = {Patterned surface, Particle swarm optimization, Liquid crystal display, Independent component analysis, Defect detection}
}

@article{10.1145/1943371.1943381,
author = {Bishnu, P. S. and Bhattacherjee, V.},
title = {Application of K-Medoids with Kd-Tree for Software Fault Prediction},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/1943371.1943381},
doi = {10.1145/1943371.1943381},
abstract = {Software fault prediction area is subject to problems like non availability of fault data which makes the application of supervised techniques difficult. In such cases unsupervised approaches like clustering are helpful. In this paper, K-Medoids clustering approach has been applied for software fault prediction. To overcome the inherent computational complexity of KMedoids algorithm a data structure called Kd-Tree has been used to identify data agents in the datasets. Partitioning Around Medoids is applied on these data agents and this results in a set of medoids. All the remaining data points are assigned to the nearest medoids thus obtained to get the final clusters. Software fault prediction error analysis results show that our approach outperforms all unsupervised approaches in the case of one given real dataset and gives best values for the evaluation parameters. For other real datasets, our results are comparable to other techniques. Performance evaluation of our technique with other techniques has been done. Results show that our technique reduces the total number of distance calculations drastically since the number of data agents is much less than the number of data points.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–6},
numpages = {6},
keywords = {Software fault prediction, Kd-Tree, K-Medoids}
}

@inproceedings{10.1145/2837060.2837066,
author = {Han, Ji-Hyeong and Kim, Rockwon and Chi, Su-Young},
title = {Applications of Machine Learning Algorithms to Predictive Manufacturing: Trends and Application of Tool Wear Compensation Parameter Recommendation},
year = {2015},
isbn = {9781450338462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2837060.2837066},
doi = {10.1145/2837060.2837066},
abstract = {The manufacturing industry has become more competitive because of globalization and fast change in the industry. To survive from the global market, manufacturing enterprises should reduce the product cost and increase the productivity. The most promising way is applying the information communication technology especially machine learning algorithms to the traditional manufacturing system. This paper presents recent trends of applying machine learning techniques to manufacturing system and briefly explains each kind of applications. As a representative application of machine learning algorithms to manufacturing system, a generalized tool wear compensation parameter recommendation framework using regression algorithms and preliminary results using real data gathered from local and small manufacturing are also presented.},
booktitle = {Proceedings of the 2015 International Conference on Big Data Applications and Services},
pages = {51–57},
numpages = {7},
keywords = {tool wear compensation parameter recommendation, machine learning, Predictive manufacturing},
location = {Jeju Island, Republic of Korea},
series = {BigDAS '15}
}

@inproceedings{10.1007/11867661_71,
author = {Castilho, Hugo Peres and Pinto, Jo\~{a}o Rog\'{e}rio Caldas and Serafim, Ant\'{o}nio Limas},
title = {NN automated defect detection based on optimized thresholding},
year = {2006},
isbn = {3540448942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11867661_71},
doi = {10.1007/11867661_71},
abstract = {This paper presents a new contribution for the problem of automatic visual inspection. New methods for determining threshold values for fabric defect detection using feedforward neural networks are proposed. Neural networks are one of the fastest most flexible classification systems in use. Their implementation in defect detection, where a clear classification is needed, requires thresholding the output. Two methods are proposed for threshold selection, statistical analysis of the NN output and confusion matrix based optimization. Experimental results obtained from the real fabric defects, for the two approaches proposed in this paper, have confirmed their usefulness.},
booktitle = {Proceedings of the Third International Conference on Image Analysis and Recognition - Volume Part II},
pages = {790–801},
numpages = {12},
location = {P\'{o}voa de Varzim, Portugal},
series = {ICIAR'06}
}

@inproceedings{10.1109/SNPD.2012.41,
author = {Jongsawat, Nipat and Premchaiswadi, Wichian},
title = {Developing a Bayesian Network Model Based on a State and Transition Model for Software Defect Detection},
year = {2012},
isbn = {9780769547619},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SNPD.2012.41},
doi = {10.1109/SNPD.2012.41},
abstract = {This paper describes a Bayesian Network model-to diagnose the causes-effect of software defect detection in the process of software testing. The aim is to use the BN model to identify defective software modules for efficient software test in order to improve the quality of a software system. It can also be used as a decision tool to assist software developers to determine defect priority levels for each phase of a software development project. The BN tool can provide a cause-effect relationship between the software defects found in each phase and other factors affecting software defect detection in software testing. First, we build a State and Transition Model that is used to provide a simple framework for integrating knowledge about software defect detection and various factors. Second, we convert the State and Transition Model into a Bayesian Network model. Third, the probabilities for the BN model are determined through the knowledge of software experts and previous software development projects or phases. Last, we observe the interactions among the variables and allow for prediction of effects of external manipulation. We believe that both STM and BN models can be used as very practical tools for predicting software defects and reliability in varying software development lifecycles.},
booktitle = {Proceedings of the 2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing},
pages = {295–300},
numpages = {6},
keywords = {a State and Transition Model, Software Testing, Software Defect Detection, GeNIe, Evidence or Observations, Bayesian Network, Bayesian Diagnosis},
series = {SNPD '12}
}

@inproceedings{10.1007/978-3-642-12304-7_60,
author = {Zhang, Yu and Lu, Zhaoyang and Li, Jing},
title = {Fabric defect detection and classification using gabor filters and gaussian mixture model},
year = {2009},
isbn = {3642123031},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12304-7_60},
doi = {10.1007/978-3-642-12304-7_60},
abstract = {This work investigates the problem of automatic and robust fabric defect detection and classification which are more essential and important in assuring the fabric quality. Two characteristics of this work are: first, a new scheme combining Gabor filters and Gaussian mixture model (GMM) is proposed for fabric defect detection and classification. In detection, the foreground mask and texture features are extracted using Gabor filters. In classification, a GMM based classifier is trained and assigns each foreground pixel to known classes. The second characteristic of this work is the test data is actually collected from Qinfeng textile factory, China, including nine different fabric defects with more than 1000 samples. All the evaluation of our method is based on these actual fabric images and the experimental results show the proposed algorithm achieved satisfied performance.},
booktitle = {Proceedings of the 9th Asian Conference on Computer Vision - Volume Part II},
pages = {635–644},
numpages = {10},
location = {Xi'an, China},
series = {ACCV'09}
}

@inproceedings{10.1007/978-3-642-02397-2_5,
author = {Cottrell, Marie and Gaubert, Patrice and Eloy, C\'{e}dric and Fran\c{c}ois, Damien and Hallaux, Geoffroy and Lacaille, J\'{e}r\^{o}me and Verleysen, Michel},
title = {Fault Prediction in Aircraft Engines Using Self-Organizing Maps},
year = {2009},
isbn = {9783642023965},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02397-2_5},
doi = {10.1007/978-3-642-02397-2_5},
abstract = {Aircraft engines are designed to be used during several tens of years. Their maintenance is a challenging and costly task, for obvious security reasons. The goal is to ensure a proper operation of the engines, in all conditions, with a zero probability of failure, while taking into account aging. The fact that the same engine is sometimes used on several aircrafts has to be taken into account too.The maintenance can be improved if an efficient procedure for the prediction of failures is implemented. The primary source of information on the health of the engines comes from measurement during flights. Several variables such as the core speed, the oil pressure and quantity, the fan speed, etc. are measured, together with environmental variables such as the outside temperature, altitude, aircraft speed, etc.In this paper, we describe the design of a procedure aiming at visualizing successive data measured on aircraft engines. The data are multi-dimensional measurements on the engines, which are projected on a self-organizing map in order to allow us to follow the trajectories of these data over time. The trajectories consist in a succession of points on the map, each of them corresponding to the two-dimensional projection of the multi-dimensional vector of engine measurements. Analyzing the trajectories aims at visualizing any deviation from a normal behavior, making it possible to anticipate an operation failure.However rough engine measurements are inappropriate for such an analysis; they are indeed influenced by external conditions, and may in addition vary between engines. In this work, we first process the data by a General Linear Model (GLM), to eliminate the effect of engines and of measured environmental conditions. The residuals are then used as inputs to a Self-Organizing Map for the easy visualization of trajectories.},
booktitle = {Proceedings of the 7th International Workshop on Advances in Self-Organizing Maps},
pages = {37–44},
numpages = {8},
keywords = {self-organizing maps, general linear models, fault detection, aircraft engine maintenance},
location = {St. Augustine, FL, USA},
series = {WSOM '09}
}

@inproceedings{10.5555/1802408.1802423,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance analysis in software fault prediction models},
year = {2009},
isbn = {9781424453757},
publisher = {IEEE Press},
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules, components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types of classification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
booktitle = {Proceedings of the 20th IEEE International Conference on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
location = {Bengaluru-Mysuru, India},
series = {ISSRE'09}
}

@inproceedings{10.5555/1819998.1820267,
author = {Fu, Rong and Shi, Meihong and Wei, Hongli and Chen, Huijuan},
title = {Fabric defect detection based on adaptive local binary patterns},
year = {2009},
isbn = {9781424447749},
publisher = {IEEE Press},
abstract = {Adaptive local binary patterns method is proposed in this paper, on which an effective fabric defect detection algorithm is designed. ALBP method selects the frequently occurred patterns to construct the main pattern set, which avoids using the same pattern set to describe different texture structures in uniform local binary patterns method. The features of free defect image are extracted according to the set and the threshold is confirmed. The image to be tested is divided into same size detection windows from which ALBP features are also extracted. Defective window is found through comparing ALBP features with threshold. The experiment exhibited the detection effect of the proposed method is comparatively better than traditional LBP method from human visual aspect and detection accuracy.},
booktitle = {Proceedings of the 2009 International Conference on Robotics and Biomimetics},
pages = {1336–1340},
numpages = {5},
location = {Guilin, China},
series = {ROBIO'09}
}

@inproceedings{10.1145/2593833.2593842,
author = {Malhotra, Ruchika},
title = {Search based techniques for software fault prediction: current trends and future directions},
year = {2014},
isbn = {9781450328524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593833.2593842},
doi = {10.1145/2593833.2593842},
abstract = {The effective allocation of the resources is crucial and essential in the testing phase of the software development life cycle so that the weak areas in the software can be verified and validated efficiently. The prediction of fault prone classes in the early phases of software development can help software developers to focus the limited available resources on those portions of software, which are more prone to fault. Recently, the search based techniques have been successfully applied in the software engineering domain. In this study, we analyze the position of search based techniques for use in software fault prediction by collecting relevant studies from the literature which were conducted during the period January 1991 to October 2013. We further summarize current trends by assessing the performance capability of the search based techniques in the existing research and suggest future directions.},
booktitle = {Proceedings of the 7th International Workshop on Search-Based Software Testing},
pages = {35–36},
numpages = {2},
keywords = {Software Quality, Software Fault proneness, Search Based Techniques},
location = {Hyderabad, India},
series = {SBST 2014}
}

@article{10.1016/j.cie.2011.12.023,
author = {Alzghoul, Ahmad and L\"{o}fstrand, Magnus and Backe, Bj\"{o}rn},
title = {Data stream forecasting for system fault prediction},
year = {2012},
issue_date = {May, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {4},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2011.12.023},
doi = {10.1016/j.cie.2011.12.023},
abstract = {Competition among today's industrial companies is very high. Therefore, system availability plays an important role and is a critical point for most companies. Detecting failures at an early stage or foreseeing them before they occur is crucial for machinery availability. Data analysis is the most common method for machine health condition monitoring. In this paper we propose a fault-detection system based on data stream prediction, data stream mining, and data stream management system (DSMS). Companies that are able to predict and avoid the occurrence of failures have an advantage over their competitors. The literature has shown that data prediction can also reduce the consumption of communication resources in distributed data stream processing. In this paper different data-stream-based linear regression prediction methods have been tested and compared within a newly developed fault detection system. Based on the fault detection system, three DSM algorithms outputs are compared to each other and to real data. The three applied and evaluated data stream mining algorithms were: Grid-based classifier, polygon-based method, and one-class support vector machines (OCSVM). The results showed that the linear regression method generally achieved good performance in predicting short-term data. (The best achieved performance was with a Mean Absolute Error (MAE) around 0.4, representing prediction accuracy of 87.5%). Not surprisingly, results showed that the classification accuracy was reduced when using the predicted data. However, the fault-detection system was able to attain an acceptable performance of around 89% classification accuracy when using predicted data.},
journal = {Comput. Ind. Eng.},
month = may,
pages = {972–978},
numpages = {7},
keywords = {Fault detection system, Fault detection forecasting, Data stream prediction, Data stream mining, Data stream management system, Availability}
}

@article{10.1016/j.future.2018.09.053,
author = {Cecchinel, Cyril and Fouquet, Fran\c{c}ois and Mosser, S\'{e}bastien and Collet, Philippe},
title = {Leveraging live machine learning and deep sleep to support a self-adaptive efficient configuration of battery powered sensors},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.09.053},
doi = {10.1016/j.future.2018.09.053},
journal = {Future Gener. Comput. Syst.},
month = mar,
pages = {225–240},
numpages = {16}
}

@article{10.1016/j.patcog.2009.12.005,
author = {Chao, Shin-Min and Tsai, Du-Ming},
title = {Anisotropic diffusion with generalized diffusion coefficient function for defect detection in low-contrast surface images},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {43},
number = {5},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2009.12.005},
doi = {10.1016/j.patcog.2009.12.005},
abstract = {In this paper, an anisotropic diffusion model with a generalized diffusion coefficient function is presented for defect detection in low-contrast surface images and, especially, aims at material surfaces found in liquid crystal display (LCD) manufacturing. A defect embedded in a low-contrast surface image is extremely difficult to detect, because the intensity difference between the unevenly illuminated background and the defective region is hardly observable and no clear edges are present between the defect and its surroundings. The proposed anisotropic diffusion model provides a generalized diffusion mechanism that can flexibly change the curve of the diffusion coefficient function. It adaptively carries out a smoothing process for faultless areas and performs a sharpening process for defect areas in an image. An entropy criterion is proposed as the performance measure of the diffused image and then a stochastic evolutionary computation algorithm, particle swarm optimization (PSO), is applied to automatically determine the best parameter values of the generalized diffusion coefficient function. Experimental results have shown that the proposed method can effectively and efficiently detect small defects in various low-contrast surface images.},
journal = {Pattern Recogn.},
month = may,
pages = {1917–1931},
numpages = {15},
keywords = {Surface inspection, Particle swarm optimization, Entropy criterion, Defect detection, Anisotropic diffusion}
}

@article{10.1016/j.imavis.2007.10.007,
author = {Lu, Chi-Jie and Tsai, Du-Ming},
title = {Independent component analysis-based defect detection in patterned liquid crystal display surfaces},
year = {2008},
issue_date = {July, 2008},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {26},
number = {7},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2007.10.007},
doi = {10.1016/j.imavis.2007.10.007},
abstract = {In this paper, we propose a machine vision approach for automatic detection of micro defects in periodically patterned surfaces and, especially, aim at thin film transistor liquid crystal display (TFT-LCD) panels. The proposed method is based on an image reconstruction scheme using independent component analysis (ICA). ICA is first applied to a faultless training image to determine the de-mixing matrix and the corresponding independent components (ICs). The ICs representing the global structure of the training image are then identified and the associated row vectors of those ICs in the de-mixing matrix are replaced with a de-mixing row representing the least structured region of the training image. The reformed de-mixing matrix is then used to reconstruct the TFT-LCD image under inspection. The resulting image can effectively remove the global structural pattern and preserve only local anomalies. A number of micro defects in different TFT-LCD panel surfaces are evaluated with the proposed method. The experiments show that the proposed method can well detect various ill-defined defects in periodically patterned surfaces.},
journal = {Image Vision Comput.},
month = jul,
pages = {955–970},
numpages = {16},
keywords = {TFT-LCD panels, Surface inspection, Independent component analysis, Defect detection}
}

@inproceedings{10.1109/ASE.2015.106,
author = {Pietsch, Christopher and Kehrer, Timo and Kelter, Udo and Reuling, Dennis and Ohrndorf, Manuel},
title = {SiPL: a delta-based modeling framework for software product line engineering},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.106},
doi = {10.1109/ASE.2015.106},
abstract = {Model-based development has become a widely-used approach to implement software, e.g. for embedded systems. Models replace source code as primary executable artifacts in these cases. Software product line technologies for these domains must be able to generate models as instances of an SPL. This need is addressed among others by an implementation technology for SPLs known as delta modeling. Current approaches to delta modeling require deltas to be written manually using delta languages, and they offer only very limited support for creating and testing a network of deltas. This paper presents a new approach to delta modeling and a supporting tool suite: the abstract notion of a delta is refined to be a consistency-preserving edit script which is generated by comparing two models. The rich structure of edit scripts allows us to detect conflicts and further relations between deltas statically and to implement restructurings in delta sets such as the merging of two deltas. We illustrate the tooling using a case study.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {852–857},
numpages = {6},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1145/2020976.2020991,
author = {Malhotra, Ruchika and Jain, Ankita},
title = {Software fault prediction for object oriented systems: a literature review},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2020976.2020991},
doi = {10.1145/2020976.2020991},
abstract = {There always has been a demand to produce efficient and high quality software. There are various object oriented metrics that measure various properties of the software like coupling, cohesion, inheritance etc. which affect the software to a large extent. These metrics can be used in predicting important quality attributes such as fault proneness, maintainability, effort, productivity and reliability. Early prediction of fault proneness will help us to focus on testing resources and use them only on the classes which are predicted to be fault-prone. Thus, this will help in early phases of software development to give a measurement of quality assessment.This paper provides the review of the previous studies which are related to software metrics and the fault proneness. In other words, it reviews several journals and conference papers on software fault prediction. There is large number of software metrics proposed in the literature. Each study uses a different subset of these metrics and performs the analysis using different datasets. Also, the researchers have used different approaches such as Support vector machines, naive bayes network, random forest, artificial neural network, decision tree, logistic regression etc. Thus, this study focuses on the metrics used, dataset used and the evaluation or analysis method used by various authors. This review will be beneficial for the future studies as various researchers and practitioners can use it for comparative analysis.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–6},
numpages = {6},
keywords = {software quality, object oriented, metrics, fault proneness, empirical validation}
}

@article{10.1016/j.eswa.2021.114810,
author = {Demirci, Mustafa Yusuf and Be\c{s}li, Nurettin and G\"{u}m\"{u}\c{s}\c{c}\"{u}, Abd\"{u}lkadir},
title = {Efficient deep feature extraction and classification for identifying defective photovoltaic module cells in Electroluminescence images},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114810},
doi = {10.1016/j.eswa.2021.114810},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {15},
keywords = {Deep learning, Deep features, Feature selection, Feature extraction, Defect detection, Electroluminescence imaging}
}

@inproceedings{10.1109/ICICIC.2007.25,
author = {Lin, Lily and Lee, Huey-Ming},
title = {A Fuzzy Software Quality Assessment Model to Evaluate User Satisfaction},
year = {2007},
isbn = {0769528821},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICICIC.2007.25},
doi = {10.1109/ICICIC.2007.25},
abstract = {Information techniques have brought us tremendous benefit, whereas people are increasingly depended on lots of information systems. Therefore, how to establish an assessment model to choose a better software quality suitable for end-users is an important issue. This study presents a new assessment method to obtain the integrated software quality for evaluating user satisfaction using fuzzy set theory. The proposed fuzzy assessment method is easier, closer to evaluator real thinking and more useful than the ones they have presented before. Keywords Fuzzy assessment; Software quality model},
booktitle = {Proceedings of the Second International Conference on Innovative Computing, Informatio and Control},
pages = {438},
series = {ICICIC '07}
}

@article{10.1016/j.patcog.2004.07.009,
author = {Ngan, Henry Y. T. and Pang, Grantham K. H. and Yung, S. P. and Ng, Michael K.},
title = {Wavelet based methods on patterned fabric defect detection},
year = {2005},
issue_date = {April, 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {38},
number = {4},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2004.07.009},
doi = {10.1016/j.patcog.2004.07.009},
abstract = {The wavelet transform (WT) has been developed over 20 years and successfully applied in defect detection on plain (unpatterned) fabric. This paper is on the use of the wavelet transform to develop an automated visual inspection method for defect detection on patterned fabric. A method called direct thresholding (DT) based on WT detailed subimages has been developed. The golden image subtraction method (GIS) is also introduced. GIS is an efficient and fast method, which can segment out the defective regions on patterned fabric effectively. In this paper, the method of wavelet preprocessed golden image subtraction (WGIS) has been developed for defect detection on patterned fabric or repetitive patterned texture. This paper also presents a comparison of the three methods. It can be concluded that the WGIS method provides the best detection result. The overall detection success rate is 96.7% with 30 defect-free images and 30 defective patterned images for one common kind of patterned Jacquard fabric.},
journal = {Pattern Recogn.},
month = apr,
pages = {559–576},
numpages = {18},
keywords = {Wavelet transform, Patterned texture, Patterned fabric inspection, Defect detection}
}

@inproceedings{10.1109/ISM.2005.91,
author = {Chang, Rong-Chi and Sie, Yun-Long and Chou, Su-Mei and Shih, Timothy K.},
title = {Photo Defect Detection for Image Inpainting},
year = {2005},
isbn = {0769524893},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISM.2005.91},
doi = {10.1109/ISM.2005.91},
abstract = {Image inpainting (or image completion) techniques use textural or structural information to repair or fill damaged potions of a picture. However, most techniques request a human to identify the portion to be inpainted. We developed a new mechanism which can automatically detect defect portions in a photo, including damages by color ink spray and scratch drawing. The mechanism is based on several filters and structural information of damages. Old photos from the author's family are used for testing. Preliminary results show that most damages can be automatically detected without human involvement. The mechanism is integrated with our inpainting algorithms to complete a fully automatic photo defects repairing system.},
booktitle = {Proceedings of the Seventh IEEE International Symposium on Multimedia},
pages = {403–407},
numpages = {5},
keywords = {structural features, image restoration, image processing, image inpainting, defect detection},
series = {ISM '05}
}

@inproceedings{10.5555/1818719.1818963,
author = {Niu, Xiaofeng and Yang, Yongyi and Wernick, Miles N.},
title = {Cardiac perfusion defect detection using gated dynamic spect imaging},
year = {2009},
isbn = {9781424456536},
publisher = {IEEE Press},
abstract = {In our previous work we proposed a dynamic image reconstruction procedure for gated cardiac imaging, of which the goal is to obtain a single image sequence that shows simultaneously both cardiac motion and tracer distribution change over time. In this work, we further develop and demonstrate the feasibility of this procedure for perfusion defect detection in gated cardiac imaging. We conduct Fisher's linear discriminant analysis on the reconstructed dynamic images, and derive quantitative measures to differentiate defects from normal myocardial perfusion. Results are presented to demonstrate the proposed development using simulated gated cardiac imaging with the NURBS-based cardiac-torso (NCAT) phantom.},
booktitle = {Proceedings of the 16th IEEE International Conference on Image Processing},
pages = {825–828},
numpages = {4},
keywords = {spatio-temporal processing, gated SPECT, dynamic SPECT, 5D reconstruction},
location = {Cairo, Egypt},
series = {ICIP'09}
}

@article{10.1016/j.ins.2013.04.025,
author = {Yan, Aijun and Wang, Weixian and Zhang, Chunxiao and Zhao, Hui},
title = {A fault prediction method that uses improved case-based reasoning to continuously predict the status of a shaft furnace},
year = {2014},
issue_date = {February, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {259},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.04.025},
doi = {10.1016/j.ins.2013.04.025},
abstract = {For the problem of predicting faults in the status of a shaft furnace, the missed alarm rate and false alarm rate have not been improved significantly by the traditional case-based reasoning (CBR) method. To predict faults more accurately, an improved CBR-based fault prediction method (ICBRP) is proposed in this paper. This ICBRP is composed of a water-filling theory-based weight allocation (WFA) model and a group decision-making-based revision (GDMR) model. According to the optimal allocation mechanism of channel power, a Lagrange function is designed to calculate the weights. Moreover, the credibility of historical results is used to revise the predicted results via the definition of a group utility function. Then, the proposed reasoning strategy can obtain more reasonable weights and take full advantage of comprehensive information from the retrieval results. Finally, the application results indicate that the proposed method is superior to traditional CBR and other methods. This proposed ICBRP significantly reduces the missed alarm rate and the false alarm rate of failure in the furnace status.},
journal = {Inf. Sci.},
month = feb,
pages = {269–281},
numpages = {13},
keywords = {Shaft furnace status, Group decision-making, Fault prediction, Case-based reasoning}
}

@inproceedings{10.1109/IS.2016.7737471,
author = {Marani, Roberto and Palumbo, Davide and Galietti, Umberto and Stella, Ettore and D'Orazio, Tiziana},
title = {Automatic detection of subsurface defects in composite materials using thermography and unsupervised machine learning},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IS.2016.7737471},
doi = {10.1109/IS.2016.7737471},
abstract = {This paper presents a complete framework aimed to nondestructive inspection of composite materials. Starting from the acquisition, performed with lock-in thermography, the method flows through a set of consecutive blocks of data processing: input enhancement, feature extraction, classification and defect detection. Experimental results prove the capability of the presented methodology to detect the presence of defects underneath the surface of a calibrated specimen made of Glass Fiber Reinforced Polymer (GFRP). Results are also compared with those obtained by other techniques, based on different features and unsupervised learning methods. The comparison further proves that the proposed methodology is able to reduce the number of false positives, while ensuring the exact detection of subsurface defects.},
booktitle = {2016 IEEE 8th International Conference on Intelligent Systems (IS)},
pages = {516–521},
numpages = {6},
location = {Sofia, Bulgaria}
}

@article{10.1016/j.ins.2008.12.001,
author = {Catal, Cagatay and Diri, Banu},
title = {Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {179},
number = {8},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2008.12.001},
doi = {10.1016/j.ins.2008.12.001},
abstract = {Software quality engineering comprises of several quality assurance activities such as testing, formal verification, inspection, fault tolerance, and software fault prediction. Until now, many researchers developed and validated several fault prediction models by using machine learning and statistical techniques. There have been used different kinds of software metrics and diverse feature reduction techniques in order to improve the models' performance. However, these studies did not investigate the effect of dataset size, metrics set, and feature selection techniques for software fault prediction. This study is focused on the high-performance fault predictors based on machine learning such as Random Forests and the algorithms based on a new computational intelligence approach called Artificial Immune Systems. We used public NASA datasets from the PROMISE repository to make our predictive models repeatable, refutable, and verifiable. The research questions were based on the effects of dataset size, metrics set, and feature selection techniques. In order to answer these questions, there were defined seven test groups. Additionally, nine classifiers were examined for each of the five public NASA datasets. According to this study, Random Forests provides the best prediction performance for large datasets and Naive Bayes is the best prediction algorithm for small datasets in terms of the Area Under Receiver Operating Characteristics Curve (AUC) evaluation parameter. The parallel implementation of Artificial Immune Recognition Systems (AIRS2Parallel) algorithm is the best Artificial Immune Systems paradigm-based algorithm when the method-level metrics are used.},
journal = {Inf. Sci.},
month = mar,
pages = {1040–1058},
numpages = {19},
keywords = {Software fault prediction, Random Forests, Naive Bayes, Machine learning, J48, Artificial Immune Systems}
}

@article{10.1007/s10836-005-2783-7,
author = {Patel, Chintan and Singh, Abhishek and Plusquellic, Jim},
title = {Defect Detection Using Quiescent Signal Analysis},
year = {2005},
issue_date = {October   2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-005-2783-7},
doi = {10.1007/s10836-005-2783-7},
abstract = {I   DDQ  or steady state current testing has been extensively used in the industry as a mainstream defect detection and reliability screen. The background leakage current has increased significantly with the advent of ultra deep submicron technologies. This increased background leakage noise makes it difficult to differentiate defect-free devices from those with defects that draw significantly small amount of currents. Therefore it is impossible to use single threshold  I   DDQ  testing for today's technologies. Several techniques that improve the resolution of  I   DDQ  testing have been proposed to replace the single threshold detection scheme. However, even these techniques are suffering from loss of resolution that is required for detection of subtle defects in the presence of leakage currents in excess of a few mA. All these techniques use a single  I   DDQ  measurement for detection and thus the scalability of these techniques is limited. Quiescent Signal Analysis (QSA) is a novel  I   DDQ  defect detection and diagnosis technique that uses  I   DDQ  measurements at multiple chip supply pads. Implicit in our methodology is a leakage calibration technique that scales the total leakage current over multiple simultaneous measurements. This helps in decreasing the background leakage component in individual measurements and thus increases the resolution of this technique to subtle defects. Defect detection is accomplished by applying linear regression analysis to the multiple supply port measurements and using outlier analysis to identify defective devices. The effectiveness of this technique is demonstrated in this paper using simulation experiments on portion of a production power grid. Predicted chip size and leakage values from the International Technology Roadmap for semiconductors (ITRS) are used in these experiments. One of the other major concerns expressed in ITRS is that of significant increase in intra-die process variations. The performance of the proposed technique in presence of such variations is evaluated using three different intra-die process variation distribution models.},
journal = {J. Electron. Test.},
month = oct,
pages = {463–483},
numpages = {21},
keywords = {parametric testing, multiple current measurements, defect-based testing, current testing, Quiescent Signal Analysis, IDDQ}
}

@article{10.1016/j.compeleceng.2014.05.013,
author = {Verma, Alok and Sarangi, Somnath and Kolekar, M.H.},
title = {Stator winding fault prediction of induction motors using multiscale entropy and grey fuzzy optimization methods},
year = {2014},
issue_date = {October 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {7},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2014.05.013},
doi = {10.1016/j.compeleceng.2014.05.013},
abstract = {The prediction of stator winding faults using multiscale entropy is performed for the first time.Real-time vibration and current are used as diagnostics to identify faults.The system complexity associated with motors is investigated using multiscale entropy.GFRG is used to predict fault and also to suggest optimal settings for motor operation.The motor condition has a maximum contribution of 54.21%, as determined from the ANOVA analysis. In the present work, stator winding fault prediction is studied using a multiscale entropy (MSE) algorithm combined with a grey-based fuzzy algorithm. Experiments were performed with a normal motor and a motor with faulty stator winding. Real time, motor current and vibration signals were acquired at different operating speeds and were used for the diagnosis of faults. The obtained signals were denoised by wavelet transform. Grey relational analysis (GRA) coupled with fuzzy logic was used to model the stator winding fault and to predict the optimal setting for running the induction motor within its parameters range. Analysis of variance (ANOVA) was performed to determine the effect of each individual parameter on the response. The results indicate that the proposed novel approach is very effective in predicting the stator winding fault. Furthermore, the best running parameters for the induction motor are also reported.},
journal = {Comput. Electr. Eng.},
month = oct,
pages = {2246–2258},
numpages = {13}
}

@article{10.1016/j.jss.2007.07.034,
author = {Vandecruys, Olivier and Martens, David and Baesens, Bart and Mues, Christophe and De Backer, Manu and Haesen, Raf},
title = {Mining software repositories for comprehensible software fault prediction models},
year = {2008},
issue_date = {May, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {5},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.07.034},
doi = {10.1016/j.jss.2007.07.034},
abstract = {Software managers are routinely confronted with software projects that contain errors or inconsistencies and exceed budget and time limits. By mining software repositories with comprehensible data mining techniques, predictive models can be induced that offer software managers the insights they need to tackle these quality and budgeting problems in an efficient way. This paper deals with the role that the Ant Colony Optimization (ACO)-based classification technique AntMiner+ can play as a comprehensible data mining technique to predict erroneous software modules. In an empirical comparison on three real-world public datasets, the rule-based models produced by AntMiner+ are shown to achieve a predictive accuracy that is competitive to that of the models induced by several other included classification techniques, such as C4.5, logistic regression and support vector machines. In addition, we will argue that the intuitiveness and comprehensibility of the AntMiner+ models can be considered superior to the latter models.},
journal = {J. Syst. Softw.},
month = may,
pages = {823–839},
numpages = {17},
keywords = {Software mining, Fault prediction, Comprehensibility, Classification, Ant Colony Optimization}
}

@article{10.1016/j.ins.2008.10.005,
author = {Quah, Tong-Seng},
title = {Estimating software readiness using predictive models},
year = {2009},
issue_date = {February, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {179},
number = {4},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2008.10.005},
doi = {10.1016/j.ins.2008.10.005},
abstract = {In this study, defect tracking is used as a proxy method to predict software readiness. The number of remaining defects in an application under development is one of the most important factors that allow one to decide if a piece of software is ready to be released. By comparing predicted number of faults and number of faults discovered in testing, software manager can decide whether the software is likely ready to be released or not. The predictive model developed in this research can predict: (i) the number of faults (defects) likely to exist, (ii) the estimated number of code changes required to correct a fault and (iii) the estimated amount of time (in minutes) needed to make the changes in respective classes of the application. The model uses product metrics as independent variables to do predictions. These metrics are selected depending on the nature of source code with regards to architecture layers, types of faults and contribution factors of these metrics. The use of neural network model with genetic training strategy is introduced to improve prediction results for estimating software readiness in this study. This genetic-net combines a genetic algorithm with a statistical estimator to produce a model which also shows the usefulness of inputs. The model is divided into three parts: (1) prediction model for presentation logic tier (2) prediction model for business tier and (3) prediction model for data access tier. Existing object-oriented metrics and complexity software metrics are used in the business tier prediction model. New sets of metrics have been proposed for the presentation logic tier and data access tier. These metrics are validated using data extracted from real world applications. The trained models can be used as tools to assist software mangers in making software release decisions.},
journal = {Inf. Sci.},
month = feb,
pages = {430–445},
numpages = {16},
keywords = {Software readiness, Software metrics, Presentation logic tier, Prediction, Neural network, Genetic net, Defect tracking, Data access tier, Business tier}
}

@inproceedings{10.1145/2245276.2231967,
author = {Sarro, F. and Di Martino, S. and Ferrucci, F. and Gravino, C.},
title = {A further analysis on the use of Genetic Algorithm to configure Support Vector Machines for inter-release fault prediction},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231967},
doi = {10.1145/2245276.2231967},
abstract = {Some studies have reported promising results on the use of Support Vector Machines (SVMs) for predicting fault-prone software components. Nevertheless, the performance of the method heavily depends on the setting of some parameters. To address this issue, we investigated the use of a Genetic Algorithm (GA) to search for a suitable configuration of SVMs to be used for inter-release fault prediction. In particular, we report on an assessment of the method on five software systems. As benchmarks we exploited SVMs with random and Grid-search configuration strategies and several other machine learning techniques. The results show that the combined use of GA and SVMs is effective for inter-release fault prediction.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1215–1220},
numpages = {6},
keywords = {support vector machines, genetic algorithm, fault prediction},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1007/s00500-016-2316-6,
author = {Chinna Gounder Dhanajayan, Rajaganapathy and Appavu Pillai, Subramani},
title = {SLMBC: spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2316-6},
doi = {10.1007/s00500-016-2316-6},
abstract = {Software fault prediction and classification plays a vital role in the software development process for assuring high quality and reliability of the software product. Earlier prediction of the fault-prone software modules enables timely correction of the faults and delivery of reliable product. Generally, the fuzzy logic, decision tree and neural networks are deployed for fault prediction. But these techniques suffer due to low accuracy and inconsistency. To overcome these issues, this paper proposes a spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification. In this process, initially the dependent and independent software modules are identified. The spiral life cycle model is used for testing the software modules in each life cycle of the software development process. Bayesian classification is applied to classify the software modules as faulty module and non-faulty module, by using the probability distribution models. Robust similarity-aware clustering algorithm performs clustering of the faulty and non-faulty software modules based on the similarity measure of the features in the dataset. From the experimental results, it is observed that the proposed method enables accurate prediction and classification of the faulty modules. The proposed technique achieves higher accuracy, precision, recall, probability of detection, F-measure and lower error rate than the existing techniques. The misclassification rate of the proposed technique is found to be lower than the existing techniques. Hence, the reliability of the software development process can be improved.},
journal = {Soft Comput.},
month = jan,
pages = {403–415},
numpages = {13},
keywords = {Spiral life cycle model-based Bayesian classification technique (SLMBC), Spiral life cycle model, Software development, Segregate fault prediction algorithm, Robust similarity-aware clustering (RSC) algorithm, Bayesian classification}
}

@inproceedings{10.1109/SERA.2007.41,
author = {Lee, Soon-Bok and Kim, Jin-Woo and Song, Chee-Yang and Baik, Doo-Kwon},
title = {An Approach to Analyzing Commonality and Variability of Features using Ontology in a Software Product Line Engineering},
year = {2007},
isbn = {0769528678},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SERA.2007.41},
doi = {10.1109/SERA.2007.41},
abstract = {In a product line engineering, several studies have been made on analysis of feature which determines commonality and variability of product. Fundamentally, because the studies are based on developer's intuition and domain expert's experience, stakeholders lack common understanding of feature and a feature analysis is informal and subjective. Moreover, the reusability of software products, which were developed, is insufficient. This paper proposes an approach to analyzing commonality and variability of features using semantic-based analysis criteria which is able to change feature model of specific domain to featureontology. For the purpose, first feature attributes were made, create a feature model following the Meta model, transform it into feature-ontology, and save it to Meta feature-ontology repository. Henceforth, when we construct a feature model of the same product line, commonality and variability of the features can be extracted, comparing it with Meta feature ontology through a semantic similarity analysis method, which is proposed. Furthermore, a tool for a semantic similarity-comparing algorithm was implemented and an experiment with an electronic approval system domain in order to show the efficiency of the approach Was conducted. A Meta feature model can definitely be created through this approach, to construct a high-quality feature model based on common understanding of a feature. The main contributions are a formulating a method of extracting commonality and variability from features using ontology based on semantic similarity mapping and a enhancement of reusability of feature model.},
booktitle = {Proceedings of the 5th ACIS International Conference on Software Engineering Research, Management &amp; Applications},
pages = {727–734},
numpages = {8},
series = {SERA '07}
}

@article{10.1016/j.imavis.2011.02.002,
author = {Ngan, Henry Y. T. and Pang, Grantham K. H. and Yung, Nelson H. C.},
title = {Review article: Automated fabric defect detection-A review},
year = {2011},
issue_date = {June, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {29},
number = {7},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2011.02.002},
doi = {10.1016/j.imavis.2011.02.002},
abstract = {This paper provides a review of automated fabric defect detection methods developed in recent years. Fabric defect detection, as a popular topic in automation, is a necessary and essential step of quality control in the textile manufacturing industry. In categorizing these methods broadly, a major group is regarded as non-motif-based while a minor group is treated as motif-based. Non-motif-based approaches are conventional, whereas the motif-based approach is novel in utilizing motif as a basic manipulation unit. Compared with previously published review papers on fabric inspection, this paper firstly offers an up-to-date survey of different defect detection methods and describes their characteristics, strengths and weaknesses. Secondly, it employs a wider classification of methods and divides them into seven approaches (statistical, spectral, model-based, learning, structural, hybrid, and motif-based) and performs a comparative study across these methods. Thirdly, it also presents a qualitative analysis accompanied by results, including detection success rate for every method it has reviewed. Lastly, insights, synergy and future research directions are discussed. This paper shall benefit researchers and practitioners alike in image processing and computer vision fields in understanding the characteristics of the different defect detection approaches.},
journal = {Image Vision Comput.},
month = jun,
pages = {442–458},
numpages = {17},
keywords = {Textile, Quality control, Motif-based, Manufacturing, Fabric defect detection, Automation}
}

@inproceedings{10.1007/978-3-642-10684-2_2,
author = {Lopez, Jose J. and Aguilera, Emanuel and Cobos, Maximo},
title = {Defect Detection and Classification in Citrus Using Computer Vision},
year = {2009},
isbn = {9783642106828},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-10684-2_2},
doi = {10.1007/978-3-642-10684-2_2},
abstract = {In this paper, a system for quality control in citrus is presented. In current citrus manufacturing industries, calliper and color are successfully used for the automatic classification of fruits using vision systems. However, fault detection in the citrus surface is carried out by means of human inspection. In this work, a computer vision system capable of detecting defects in the citrus peel and also classifying the type of flaw is presented. First, a review of citrus illnesses has been carried out in order to build a database of digitalized oranges classified by the kind of fault, which is used as a training set. The segmentation of faulty zones is performed by applying the Sobel gradient to the image. Afterwards, color and texture features of the flaw are extracted, some of them related with high order statistics. Several techniques have been employed for classification purposes: Euler distance to a prototype, to the nearest neighbor and k-nearest neighbors. Additionally, a three layer neural network has been tested and compared, obtaining promising results.},
booktitle = {Proceedings of the 16th International Conference on Neural Information Processing: Part II},
pages = {11–18},
numpages = {8},
keywords = {Texture analysis segmentation, Quality control, Computer vision, Automatic inspection system},
location = {Bangkok, Thailand},
series = {ICONIP '09}
}

@inproceedings{10.1007/978-3-030-79463-7_35,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Continuous Build Outcome Prediction: A Small-N Experiment in Settings of a Real Software Project},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_35},
doi = {10.1007/978-3-030-79463-7_35},
abstract = {We explain the idea of Continuous Build Outcome Prediction (CBOP) practice that uses classification to label the possible build results (success or failure) based on historical data and metrics (features) derived from the software repository. Additionally, we present a preliminary empirical evaluation of CBOP in a real live software project. In a small-n repeated-measure with two conditions and replicates experiment, we study whether CBOP will reduce the Failed Build Ratio (FBR). Surprisingly, the result of the study indicates a slight increase in FBR while using the CBOP, although the effect size is very small. A plausible explanation of the revealed phenomenon may come from the authority principle, which is rarely discussed in the software engineering context in general, and AI-supported software development practices in particular.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {412–425},
numpages = {14},
keywords = {Machine learning, Continuous integration, Agile experimentation, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@phdthesis{10.5555/1354508,
author = {Dehlinger, Joshua Jon},
advisor = {Lutz, Robyn R.},
title = {Incorporating product-line engineering techniques into agent-oriented software engineering for efficiently building safety-critical, multi-agent systems},
year = {2007},
isbn = {9780549154877},
publisher = {Iowa State University},
address = {USA},
abstract = {Safety-critical, agent-based systems are being developed without mechanisms and analysis techniques to discover, analyze and verify software requirements and prevent potential hazards. Agent-oriented, software-based approaches have provided powerful and natural high-level abstractions in which software developers can understand, model and develop complex, distributed systems. Yet, the realization of agent-oriented software development partially depends upon whether agent-based software systems can achieve reductions in development time and cost similar to other reuse-conscious software development methods. Further, agent-oriented software engineering (AOSE) currently does not adequately address: (1)&nbsp;requirements (specification) reuse in a way that is amenable to the reduction of the development cost by utilizing reusable assets, and (2)&nbsp;analysis techniques to evaluate safety. This dissertation offers our AOSE methodology, Gaia-PL (Gaia-Product Line) for open, agent-based distributed software systems to capture requirements specifications that can be easily reused. Our methodology uses a product-line perspective to promote reuse in agent-based, software systems early in the development lifecycle so that software assets can be reused throughout the development lifecycle and system evolution. The main contribution of this work is a requirements specification pattern that captures the dynamically changing design configurations of agents. Reuse is achieved by adopting a product-line approach into AOSE. Requirements specifications reuse is the ability to easily use previously defined requirements specifications from an earlier system and apply them to a new, slightly different system. This can significantly reduce the development time and cost of building an agent-based system.For safety-critical agent-based systems, this dissertation incorporates reuse-oriented safety analysis methods for AOSE to allow the discovery of new safety requirements and the verification that the design satisfies the safety requirements. Specifically, Product-Line Software Fault Tree Analysis (PL-SFTA) and its automated tool, PLFaultCAT (  P roduct-  L ine  Fault  Tree  C reation and  A nalysis  T ool), have been created to provide the technique and tool support for the safety analysis of safety-critical software product lines. The PL-SFTA allows for the identification of new safety requirements and the analysis of safety-critical requirements and requirement interactions. An AOSE-adapted Software Failure Modes, Effects and Criticality Analysis (SFMECA) technique has been created to support the derivation of a safety analysis asset using the specifications of Gaia-PL allowing for the identification of possible hazard scenarios and the failure points of specific agent roles. Using the assets generated via PL-SFTA and SFMECA, Bi-Directional Safety Analysis (BDSA) is shown to aid in the completeness of PL-SFTA and SFMECA, help verify the safety properties and strengthen the safety case when safety compliance to safety standards of the multi-agent system is necessary.Results from an application to a large, safety-critical, multi-agent system product-line show that Gaia-PL provides strong reuse capabilities. Evaluation of the Gaia-PL methodology used in conjunction with the PL-SFTA, SFMECA and BDSA safety analysis techniques shows that safety analysis of an agent-based software system is feasible, reusable and efficient.},
note = {AAI3274890}
}

@inproceedings{10.1109/ICIG.2004.43,
author = {Ng, Hui-Fuang},
title = {Automatic Thresholding for Defect Detection},
year = {2004},
isbn = {0769522440},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICIG.2004.43},
doi = {10.1109/ICIG.2004.43},
abstract = {Automatic thresholding has been widely used in the machine vision industry for automated visual inspection of defects. A commonly use thresholding technique, the Otsu method, provides satisfactory results for thresholding an image with histogram of bimodal distribution. This method, however, fails if the histogram is unimodal or close to unimodal. For defect detection applications, defects range from no defect, small defect, to large defect, which means the gray-level distributions range from unimodal to bimodal. In this paper, we revised and improved the Otsu method for selecting optimal threshold values for both unimodal and bimodal distributions. We also tested the performance of the revised method on common defect detection applications.},
booktitle = {Proceedings of the Third International Conference on Image and Graphics},
pages = {532–535},
numpages = {4},
series = {ICIG '04}
}

@article{10.1016/j.patrec.2005.02.002,
author = {Tsai, Du-Ming and Yang, Cheng-Hsiang},
title = {A quantile-quantile plot based pattern matching for defect detection},
year = {2005},
issue_date = {1 October 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {26},
number = {13},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2005.02.002},
doi = {10.1016/j.patrec.2005.02.002},
abstract = {Pattern matching has been used extensively for many machine vision applications such as optical character recognition, face detection, object detection, and defect detection. The normalized cross correlation (NCC) is the most commonly used technique in pattern matching. However, it is computationally intensive, sensitive to environmental changes such as lighting and shifting, and suffers from false alarms for a complicated image that contains partial uniform regions. In this paper, a pattern-matching scheme based on the quantile-quantile plot (Q-Q plot) is proposed for defect detection applications. In a Q-Q plot, the quantiles of an inspection image are plotted against the corresponding quantiles of the template image. The p-value of Chi-square test from the resulting Q-Q plot is then used as the quantitative measure of similarity between two compared images. The quantile representation transforms the 2D gray-level information into the 1D quantile one. It can therefore efficiently reduce the dimensionality of the data, and accelerate the computation. Experimental results have shown that the proposed pattern-matching scheme is computationally fast and is tolerable to minor displacement and process variation. The proposed similarity measure of p-value has excellent discrimination capability to detect subtle defects, compared with the traditional measure of NCC. With a proper normalization of the Q-Q plot, the p-value measure can be tolerable to moderate light changes. Experimental results from assembled PCB (printed circuit board) samples, IC wafers, and liquid crystal display (LCD) panels have shown the efficacy of the proposed pattern-matching scheme for defect detection.},
journal = {Pattern Recogn. Lett.},
month = oct,
pages = {1948–1962},
numpages = {15},
keywords = {Similarity measure, Quantile-quantile plot, Pattern matching, Defect detection}
}

@inproceedings{10.1145/3372806.3372816,
author = {Chen, Yuhan and Zhong, Shangping and Chen, Kaizhi and Chen, Shoulong and Zheng, Song},
title = {Automated Detection of Sewer Pipe Defects Based on Cost-Sensitive Convolutional Neural Network},
year = {2020},
isbn = {9781450372213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372806.3372816},
doi = {10.1145/3372806.3372816},
abstract = {Regular inspection and repair of drainage pipes is an important part of urban construction. Currently, many classification methods have been used for defect diagnosis using images inside pipelines. However, most of these classification models train the classifier with the goal of maximizing accuracy without considering the unequal error classification cost in defect diagnosis. In this study, the authors analyze the characteristics of sewer pipeline defect detection and design an automated detection framework based on the cost-sensitive deep convolutional neural network (CNN). The method makes the CNN network cost sensitive by introducing learning theories at the structural and loss levels of the network. To minimize misclassification costs, the authors propose a new auxiliary loss function Cost-Mean Loss, which allows the model to obtain the original parameters of the network to maximize the accuracy and improve the performance of the model by minimizing total misclassification costs in the learning process. Theoretical analysis shows that the new auxiliary loss function can be applied to the classification task to optimize the expected value of misclassification costs. The inspection images collected from multiple drainage pipes were used to train and test the network. Results show that after the cost-sensitive strategy was added, the defect detection rate decreased from 2.1% to 0.45%. Moreover, the model with Cost-Mean Loss has better performance than the original model.},
booktitle = {Proceedings of the 2019 2nd International Conference on Signal Processing and Machine Learning},
pages = {8–17},
numpages = {10},
keywords = {Sewer pipe inspection, Defect detection, Deep learning, Cost-sensitive learning, Cost-Mean Loss},
location = {Hangzhou, China},
series = {SPML '19}
}

@article{10.1016/S0167-8655(03)00106-5,
author = {Tsai, Du-Ming and Lin, Chien-Ta},
title = {Fast normalized cross correlation for defect detection},
year = {2003},
issue_date = {November 2003},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {24},
number = {15},
issn = {0167-8655},
url = {https://doi.org/10.1016/S0167-8655(03)00106-5},
doi = {10.1016/S0167-8655(03)00106-5},
abstract = {Normalized cross correlation (NCC) has been used extensively for many machine vision applications, but the traditional normalized correlation operation does not meet speed requirements for time-critical applications. In this paper, we propose a fast NCC computation for defect detection. A sum-table scheme is utilized, which allows the calculations of image mean, image variance and cross-correlation between images to be invariant to the size of template window. For an image of size M \texttimes{} N and a template window of size m \texttimes{} n, the computational complexity of the traditional NCC involves 3 undefined m undefined n undefined M undefined N additions/subtractions and 2 undefined m undefined n undefined M undefined N multiplications. The required numbers of computations of the proposed sum-table scheme can be significantly reduced to only 18 undefined M undefined N additions/subtractions and 2 undefined M undefined N multiplications.},
journal = {Pattern Recogn. Lett.},
month = nov,
pages = {2625–2631},
numpages = {7},
keywords = {sum tables, normalized cross correlation, defect detection}
}

@inproceedings{10.1007/978-3-030-89370-5_18,
author = {Tian, Yuze and Zhong, Xian and Liu, Wenxuan and Jia, Xuemei and Zhao, Shilei and Ye, Mang},
title = {Random Walk Erasing with Attention Calibration for Action Recognition},
year = {2021},
isbn = {978-3-030-89369-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89370-5_18},
doi = {10.1007/978-3-030-89370-5_18},
abstract = {Action recognition in videos has attracted growing research interests because of the explosive surveillance data in social security applications. In this process, due to the distraction and deviation of the network caused by occlusions, human action features usually suffer different degrees of performance degradation. Considering the occlusion scene in the wild, we find that the occluded objects usually move unpredictably but continuously. Thus, we propose a random walk erasing with attention calibration (RWEAC) for action recognition. Specifically, we introduce the random walk erasing (RWE) module to simulate the unknown occluded real conditions in frame sequence, expanding the diversity of data samples. In the case of erasing (or occlusion), the attention area is sparse. We leverage the attention calibration (AC) module to force the attention to stay stable in other regions of interest. In short, our novel RWEAC network enhances the ability to learn comprehensive features in a complex environment and make the feature representation robust. Experiments are conducted on the challenging video action recognition UCF101 and HMDB51 datasets. The extensive comparison results and ablation studies demonstrate the effectiveness and strength of the proposed method.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part III},
pages = {236–251},
numpages = {16},
keywords = {Siamese network, Attention calibration, Data augmentation, Random walk erasing, Action recognition},
location = {Hanoi, Vietnam}
}

@article{10.1007/s10664-011-9165-9,
author = {Shin, Yonghee and Bell, Robert M. and Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {On the use of calling structure information to improve fault prediction},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9165-9},
doi = {10.1007/s10664-011-9165-9},
abstract = {Previous studies have shown that software code attributes, such as lines of source code, and history information, such as the number of code changes and the number of faults in prior releases of software, are useful for predicting where faults will occur. In this study of two large industrial software systems, we investigate the effectiveness of adding information about calling structure to fault prediction models. Adding calling structure information to a model based solely on non-calling structure code attributes modestly improved prediction accuracy. However, the addition of calling structure information to a model that included both history and non-calling structure code attributes produced no improvement.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {390–423},
numpages = {34},
keywords = {Software faults, Negative binomial model, Empirical study, Calling structure attributes}
}

@article{10.1016/j.imavis.2007.03.003,
author = {Chao, Shin-Min and Tsai, Du-Ming},
title = {An anisotropic diffusion-based defect detection for low-contrast glass substrates},
year = {2008},
issue_date = {February, 2008},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {26},
number = {2},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2007.03.003},
doi = {10.1016/j.imavis.2007.03.003},
abstract = {In this paper, we propose an anisotropic diffusion scheme to detect defects in low-contrast surface images and, especially, aim at glass substrates used in TFT-LCDs (Thin Film Transistor-Liquid Crystal Displays). In a sensed image of glass substrate, the gray levels of defects and background are hardly distinguishable and result in a low-contrast image. Therefore, thresholding and edge detection techniques cannot be applied to detect subtle defects in the glass substrates surface. Although the traditional diffusion model can effectively smooth noise and irregularity of a faultless background in an image, it can only passively stop the diffusion process to preserve the original low-contrast gray values of defect edges. The proposed diffusion method in this paper can simultaneously carry out the smoothing and sharpening operations so that a simple thresholding can be used to segment the intensified defects in the resulting image. The method adaptively triggers the smoothing process in faultless areas to make the background uniform, and performs the sharpening process in defective areas to enhance anomalies. Experimental results from a number of glass substrate samples including backlight panels and LCD glass substrates have shown the efficacy of the proposed diffusion scheme in low-contrast surface inspection.},
journal = {Image Vision Comput.},
month = feb,
pages = {187–200},
numpages = {14},
keywords = {Surface inspection, Low-contrast images, Glass substrates, Defect detection, Anisotropic diffusion}
}

@article{10.1016/j.imavis.2005.07.014,
author = {Tsai, Du-Ming and Yang, Ron-Hwa},
title = {An eigenvalue-based similarity measure and its application in defect detection},
year = {2005},
issue_date = {November, 2005},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {23},
number = {12},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2005.07.014},
doi = {10.1016/j.imavis.2005.07.014},
abstract = {In this paper, we propose an eigenvalue-based similarity measure between two gray-level images and, in particular, aim at the application in defect detection. The pair-wise gray levels at coincident pixel locations in two compared images are used as the coordinates to plot the correspondence map. If two compared images are identical, the plot in the correspondence map is a diagonal straight line. Otherwise, it results in a non-linear shape in the correspondence map. The smaller eigenvalue of the covariance matrix of the data points in the correspondence map is used as the similarity measure. It will be approximately zero for two resembled images, and distinctly large for dissimilar images. Experimental results from a number of assembled PCBs (printed circuit boards) have shown the effectiveness of the proposed similarity measure for detecting local defects in complicated images.},
journal = {Image Vision Comput.},
month = nov,
pages = {1094–1101},
numpages = {8},
keywords = {Template matching, Similarity measure, Eigenvalues, Defect detection}
}

@article{10.1145/2556777,
author = {Zhou, Yuming and Xu, Baowen and Leung, Hareton and Chen, Lin},
title = {An in-depth study of the potentially confounding effect of class size in fault prediction},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2556777},
doi = {10.1145/2556777},
abstract = {Background. The extent of the potentially confounding effect of class size in the fault prediction context is not clear, nor is the method to remove the potentially confounding effect, or the influence of this removal on the performance of fault-proneness prediction models. Objective. We aim to provide an in-depth understanding of the effect of class size on the true associations between object-oriented metrics and fault-proneness. Method. We first employ statistical methods to examine the extent of the potentially confounding effect of class size in the fault prediction context. After that, we propose a linear regression-based method to remove the potentially confounding effect. Finally, we empirically investigate whether this removal could improve the prediction performance of fault-proneness prediction models. Results. Based on open-source software systems, we found: (a) the confounding effect of class size on the associations between object-oriented metrics and fault-proneness in general exists; (b) the proposed linear regression-based method can effectively remove the confounding effect; and (c) after removing the confounding effect, the prediction performance of fault prediction models with respect to both ranking and classification can in general be significantly improved. Conclusion. We should remove the confounding effect of class size when building fault prediction models.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {10},
numpages = {51},
keywords = {prediction, fault, confounding effect, class size, Metrics}
}

@inproceedings{10.1145/3379177.3388892,
author = {John, Meenu Mary and Olsson, Helena Holmstr\"{o}m and Bosch, Jan},
title = {Developing ML/DL Models: A Design Framework},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388892},
doi = {10.1145/3379177.3388892},
abstract = {Artificial Intelligence is becoming increasingly popular with organizations due to the success of Machine Learning and Deep Learning techniques. Using these techniques, data scientists learn from vast amounts of data to enhance behaviour in software-intensive systems. Despite the attractiveness of these techniques, however, there is a lack of systematic and structured design process for developing ML/DL models. The study uses a multiple-case study approach to explore the different activities and challenges data scientists face when developing ML/DL models in software-intensive embedded systems. In addition, we have identified seven different phases in the proposed design process leading to effective model development based on the case study. Iterations identified between phases and events which trigger these iterations optimize the design process for ML/DL models. Lessons learned from this study allow data scientists and engineers to develop high-performance ML/DL models and also bridge the gap between high demand and low supply of data scientists.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {1–10},
numpages = {10},
keywords = {Software Engineering, Machine Learning, Design, Deep Learning, Artificial Intelligence},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@inproceedings{10.1145/1370788.1370792,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Comparing negative binomial and recursive partitioning models for fault prediction},
year = {2008},
isbn = {9781605580364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370788.1370792},
doi = {10.1145/1370788.1370792},
abstract = {Two different software fault prediction models have been used to predict the N% of the files of a large software system that are likely to contain the largest numbers of faults. We used the same predictor variables in a negative binomial regression model and a recursive partitioning model, and compared their effectiveness on three large industrial software systems. The negative binomial model identified files that contain 76 to 93 percent of the faults, and recursive partitioning identified files that contain 68 to 85 percent.},
booktitle = {Proceedings of the 4th International Workshop on Predictor Models in Software Engineering},
pages = {3–10},
numpages = {8},
keywords = {empirical study, fault prediction, negative binomial, recursive partition, software testing},
location = {Leipzig, Germany},
series = {PROMISE '08}
}

@article{10.1007/s10489-011-0316-x,
author = {Chatterjee, S. and Nigam, S. and Singh, J. B. and Upadhyaya, L. N.},
title = {Software fault prediction using Nonlinear Autoregressive with eXogenous Inputs (NARX) network},
year = {2012},
issue_date = {July      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {37},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-011-0316-x},
doi = {10.1007/s10489-011-0316-x},
abstract = {This paper explores a new approach for predicting software faults by means of NARX neural network. Also, a careful analysis has been carried out to determine the applicability of NARX network in software reliability. The validation of the proposed approach has been performed using two real software failure data sets. Comparison has been made with some existing parametric software reliability models as well as some neural network (Elman net and TDNN) based SRGM. The results computed shows that the proposed approach outperformed the other existing parametric and neural network based software reliability models with a reasonably good predictive accuracy.},
journal = {Applied Intelligence},
month = jul,
pages = {121–129},
numpages = {9},
keywords = {Time between failures, Software reliability, NARX neural network, Faults}
}

@inproceedings{10.1109/ISSRE.2008.54,
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
title = {Cost Curve Evaluation of Fault Prediction Models},
year = {2008},
isbn = {9780769534053},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2008.54},
doi = {10.1109/ISSRE.2008.54},
abstract = {Prediction of fault prone software components is one of the most researched problems in software engineering. Many statistical techniques have been proposed but there is no consensus on the methodology to select the "best model" for the specific project. In this paper, we introduce and discuss the merits of cost curve analysis of fault prediction models. Cost curves allow software quality engineers to introduce project-specific cost of module misclassification into model evaluation. Classifying a software module as fault-prone implies the application of some verification activities, thus adding to the development cost. Misclassifying a module as fault free carries the risk of system failure, also associated with cost implications. Through the analysis of sixteen projects from public repositories, we observe that software quality does not necessarily benefit from the prediction of fault prone components. The inclusion of misclassification cost in model evaluation may indicate that even the "best" models achieve performance no better than trivial classification. Our results support a recommendation to adopt cost curves as one of the standard methods for software quality model performance evaluation.},
booktitle = {Proceedings of the 2008 19th International Symposium on Software Reliability Engineering},
pages = {197–206},
numpages = {10},
keywords = {software quality, verification and validation, machine learning, classification},
series = {ISSRE '08}
}

@inproceedings{10.1145/1882362.1882409,
author = {Lowry, Michael R.},
title = {Towards predictive models of technology impact on software design productivity},
year = {2010},
isbn = {9781450304276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882362.1882409},
doi = {10.1145/1882362.1882409},
abstract = {In order to advance software engineering research, agencies should fund pilot studies for calibrating software design productivity impacts of potential technology advances. We need a predictive model of technology impacts in order to advocate technology programs and to select individual projects that provide most benefit to society. Current software cost estimation models can provide a starting point, but in the long run are inadequate because they are based on current methods and technologies for software development. Ultimately, the predictive models need to be rooted in fundamental factors affecting productivity, ranging from cognitive facility of different programming language paradigms, mathematical underpinnings for reuse and compositional approaches, and organizational psychology for large development projects. Such a productivity model would enable development of metrics for individual facets of software design productivity, and an understanding of how even narrow technology advances contribute to overall software design productivity.},
booktitle = {Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research},
pages = {223–228},
numpages = {6},
keywords = {cost estimation},
location = {Santa Fe, New Mexico, USA},
series = {FoSER '10}
}

@inproceedings{10.1145/3362789.3362923,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco J. and Ther\'{o}n, Roberto},
title = {Automatic generation of software interfaces for supporting decision-making processes. An application of domain engineering and machine learning},
year = {2019},
isbn = {9781450371919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3362789.3362923},
doi = {10.1145/3362789.3362923},
abstract = {Information dashboards are sophisticated tools. Although they enable users to reach useful insights and support their decision-making challenges, a good design process is essential to obtain powerful tools. Users need to be part of these design processes, as they will be the consumers of the information displayed. But users are very diverse and can have different goals, beliefs, preferences, etc., and creating a new dashboard for each potential user is not viable. There exist several tools that allow users to configure their displays without requiring programming skills. However, users might not exactly know what they want to visualize or explore, also becoming the configuration process a tedious task. This research project aims to explore the automatic generation of user interfaces for supporting these decision-making processes. To tackle these challenges, a domain engineering, and machine learning approach is taken. The main goal is to automatize the design process of dashboards by learning from the context, including the end-users and the target data to be displayed.},
booktitle = {Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {1007–1011},
numpages = {5},
keywords = {Meta-modeling, Information Dashboards, High-level requirements, Domain engineering, Automatic generation},
location = {Le\'{o}n, Spain},
series = {TEEM'19}
}

@article{10.1007/s10664-009-9111-2,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Comparing the effectiveness of several modeling methods for fault prediction},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-009-9111-2},
doi = {10.1007/s10664-009-9111-2},
abstract = {We compare the effectiveness of four modeling methods--negative binomial regression, recursive partitioning, random forests and Bayesian additive regression trees--for predicting the files likely to contain the most faults for 28 to 35 releases of three large industrial software systems. Predictor variables included lines of code, file age, faults in the previous release, changes in the previous two releases, and programming language. To compare the effectiveness of the different models, we use two metrics--the percent of faults contained in the top 20% of files identified by the model, and a new, more general metric, the fault-percentile-average. The negative binomial regression and random forests models performed significantly better than recursive partitioning and Bayesian additive regression trees, as assessed by either of the metrics. For each of the three systems, the negative binomial and random forests models identified 20% of the files in each release that contained an average of 76% to 94% of the faults.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {277–295},
numpages = {19},
keywords = {Recursive partitioning, Random forests, Negative binomial, Fault-percentile-average, Fault prediction, Empirical study, Bayesian trees}
}

@article{10.1016/j.jss.2009.06.055,
author = {Arisholm, Erik and Briand, Lionel C. and Johannessen, Eivind B.},
title = {A systematic and comprehensive investigation of methods to build and evaluate fault prediction models},
year = {2010},
issue_date = {January, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.055},
doi = {10.1016/j.jss.2009.06.055},
abstract = {This paper describes a study performed in an industrial setting that attempts to build predictive models to identify parts of a Java system with a high fault probability. The system under consideration is constantly evolving as several releases a year are shipped to customers. Developers usually have limited resources for their testing and would like to devote extra resources to faulty system parts. The main research focus of this paper is to systematically assess three aspects on how to build and evaluate fault-proneness models in the context of this large Java legacy system development project: (1) compare many data mining and machine learning techniques to build fault-proneness models, (2) assess the impact of using different metric sets such as source code structural measures and change/fault history (process measures), and (3) compare several alternative ways of assessing the performance of the models, in terms of (i) confusion matrix criteria such as accuracy and precision/recall, (ii) ranking ability, using the receiver operating characteristic area (ROC), and (iii) our proposed cost-effectiveness measure (CE). The results of the study indicate that the choice of fault-proneness modeling technique has limited impact on the resulting classification accuracy or cost-effectiveness. There is however large differences between the individual metric sets in terms of cost-effectiveness, and although the process measures are among the most expensive ones to collect, including them as candidate measures significantly improves the prediction models compared with models that only include structural measures and/or their deltas between releases - both in terms of ROC area and in terms of CE. Further, we observe that what is considered the best model is highly dependent on the criteria that are used to evaluate and compare the models. And the regular confusion matrix criteria, although popular, are not clearly related to the problem at hand, namely the cost-effectiveness of using fault-proneness prediction models to focus verification efforts to deliver software with less faults at less cost.},
journal = {J. Syst. Softw.},
month = jan,
pages = {2–17},
numpages = {16},
keywords = {Verification, Fault prediction models, Cost-effectiveness}
}

@inproceedings{10.1007/978-3-030-55789-8_59,
author = {Abeyrathna, Kuruge Darshana and Granmo, Ole-Christoffer and Goodwin, Morten},
title = {Integer Weighted Regression Tsetlin Machines},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_59},
doi = {10.1007/978-3-030-55789-8_59},
abstract = {The Regression Tsetlin Machine (RTM) addresses the lack of interpretability impeding state-of-the-art nonlinear regression models. It does this by using conjunctive clauses in propositional logic to capture the underlying non-linear frequent patterns in the data. These, in turn, are combined into a continuous output through summation, akin to a linear regression function, however, with non-linear components and binary weights. However, the resolution of the RTM output is proportional to the number of clauses employed. This means that computation cost increases with resolution. To address this problem, we here introduce integer weighted RTM clauses. Our integer weighted clause is a compact representation of multiple clauses that capture the same sub-pattern—w repeating clauses are turned into one, with an integer weight w. This reduces computation cost w times, and increases interpretability through a sparser representation. We introduce a novel learning scheme, based on so-called stochastic searching on the line. We evaluate the potential of the integer weighted RTM empirically using two artificial datasets. The results show that the integer weighted RTM is able to acquire on par or better accuracy using significantly less computational resources compared to regular RTM and an RTM with real-valued weights.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {686–694},
numpages = {9},
keywords = {Stochastic searching on the line, Interpretable machine learning, Weighted tsetlin machines, Regression tsetlin machines, Tsetlin machines},
location = {Kitakyushu, Japan}
}

@article{10.1016/j.future.2021.06.009,
author = {Li, Ying and Fan, Binbin and Zhang, Weiping and Jiang, Zhiqiang},
title = {TireNet: A high recall rate method for practical application of tire defect type classification},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {125},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2021.06.009},
doi = {10.1016/j.future.2021.06.009},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {1–9},
numpages = {9},
keywords = {Siamese network, Object detection, Defect detection, Tire X-ray image}
}

@inproceedings{10.1007/978-3-030-78609-0_23,
author = {Peng, Yu and Li, Xiaoyu and Lu, Chao and Tang, Xiaolan and Lin, Bin},
title = {A Light-Weight Prediction Model for Aero-Engine Surge Based on Seq2Seq},
year = {2021},
isbn = {978-3-030-78608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78609-0_23},
doi = {10.1007/978-3-030-78609-0_23},
abstract = {Surge is an abnormal fault caused by compressor in the process of aero-engine flight, which will reduce the performance of aero-engines. When the surge gets serious, it will even cause engine damage, endanger flight safety, and cause a huge loss of personnel and property. Therefore, it is of great significance to predict the aero-engine surge timely and accurately. At present, little research have been done on the prediction task of aero-engine surge, and there are problems of low prediction accuracy and long calculation time. In order to solve these problems, a light-weight prediction model for aero-engine surge based on Seq2Seq (sequence to sequence) is proposed, which is called Ligh4S. Ligh4S uses the one-dimensional convolution neural network instead of the LSTM (long short-term memory network) structure in tradition-al Seq2Seq, which allows the model to compute in parallel, thus greatly improving computational efficiency and reducing prediction time. Experiments on the experimental data of an aero-engine show that the model achieves the performances of 94.3%, 92.1%, 93.2% respectively on precision rate, recall rate and F1 score under the condition of significantly reducing the size of model and the amount of calculation. What’s more, the model takes only 2ms to make a single prediction, which increases the prediction speed by about 98% compared with the LSTM-based Seq2Seq model.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part I},
pages = {265–277},
numpages = {13},
keywords = {seq2seq, Light-weight, Fault prediction, Aero-engine surge},
location = {Dublin, Ireland}
}

@article{10.1016/S0167-8655(03)00098-9,
author = {Tsai, Du-Ming and Lin, Chien-Ta and Chen, Jeng-Fung},
title = {The evaluation of normalized cross correlations for defect detection},
year = {2003},
issue_date = {November 2003},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {24},
number = {15},
issn = {0167-8655},
url = {https://doi.org/10.1016/S0167-8655(03)00098-9},
doi = {10.1016/S0167-8655(03)00098-9},
abstract = {The normalized cross correlation (NCC) has been used extensively in machine vision for industrial inspection, but the traditional NCC suffers from false alarms for a complicated image that contains partial uniform regions. In this paper, we study the use of NCCs for defect detection in complicated images. The performance of NCCs in monochrome and color images, and the effect of image smoothing are empirically evaluated. The proposed NCC in a smoothed color image can effectively alleviate false alarms in defect detection applications.},
journal = {Pattern Recogn. Lett.},
month = nov,
pages = {2525–2535},
numpages = {11},
keywords = {smoothing, normalized cross correlation, defect detection, color images}
}

@article{10.1016/j.asoc.2016.10.040,
author = {Layouni, Mohamed and Hamdi, Mohamed Salah and Tahar, Sofine},
title = {Detection and sizing of metal-loss defects in oil and gas pipelines using pattern-adapted wavelets and machine learning},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {52},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.10.040},
doi = {10.1016/j.asoc.2016.10.040},
abstract = {Graphical abstractDisplay Omitted HighlightsOil and gas pipelines are subject to many types of metal-loss defects.Those defects can pose a high risk to the operational safety of the pipeline.This paper proposes a solution to detect, locate, and estimate the size of defects.The proposed solution uses pattern-adapted wavelets and artificial neural networks.The proposed solution is general and applies to a wide range of defect shapes. Signals collected from the magnetic scans of metal-loss defects have distinct patterns. Experienced pipeline engineers are able to recognize those patterns in magnetic flux leakage (MFL) scans of pipelines, and use them to characterize defect types (e.g., corrosion, cracks, dents, etc.) and estimate their lengths and depths. This task, however, can be highly cumbersome to a human operator, because of the large amount of data to be analyzed. This paper proposes a solution to automate the analysis of MFL signals. The proposed solution uses pattern-adapted wavelets to detect and estimate the length of metal-loss defects. Once the parts of MFL signals corresponding to metal-loss defects are isolated, artificial neural networks are used to predict their depth. The proposed technique is computationally efficient, achieves high levels of accuracy, and works for a wide range of defect shapes.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {247–261},
numpages = {15},
keywords = {Safety assessment, Pattern-adapted wavelets, Pattern recognition, Oil and gas pipelines, Neural networks, Magnetic flux leakage, Machine learning, Defect sizing, Defect location}
}

@article{10.1007/s10115-021-01560-w,
author = {Brzezinski, Dariusz and Minku, Leandro L. and Pewinski, Tomasz and Stefanowski, Jerzy and Szumaczuk, Artur},
title = {The impact of data difficulty factors on classification of imbalanced and concept drifting data streams},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {6},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-021-01560-w},
doi = {10.1007/s10115-021-01560-w},
abstract = {Class imbalance introduces additional challenges when learning classifiers from concept drifting data streams. Most existing work focuses on designing new algorithms for dealing with the global imbalance ratio and does not consider other data complexities. Independent research on static imbalanced data has highlighted the influential role of local data difficulty factors such as minority class decomposition and presence of unsafe types of examples. Despite often being present in real-world data, the interactions between concept drifts and local data difficulty factors have not been investigated in concept drifting data streams yet. We thoroughly study the impact of such interactions on drifting imbalanced streams. For this purpose, we put forward a new categorization of concept drifts for class imbalanced problems. Through comprehensive experiments with synthetic and real data streams, we study the influence of concept drifts, global class imbalance, local data difficulty factors, and their combinations, on predictions of representative online classifiers. Experimental results reveal the high influence of new considered factors and their local drifts, as well as differences in existing classifiers’ reactions to such factors. Combinations of multiple factors are the most challenging for classifiers. Although existing classifiers are partially capable of coping with global class imbalance, new approaches are needed to address challenges posed by imbalanced data streams.},
journal = {Knowl. Inf. Syst.},
month = jun,
pages = {1429–1469},
numpages = {41},
keywords = {Stream classification, Drift categorization, Data difficulty factors, Concept drift, Class imbalance}
}

@inproceedings{10.5555/3507788.3507833,
author = {M\"{u}ller, Hausi A. and Rivera, Luis F. and Jim\'{e}nez, Miguel and Villegas, Norha M. and Tamura, Gabriel and Akkiraju, Rama and Watts, Ian and Erpenbach, Eric},
title = {Proactive AIOps through digital twins},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The rise of advanced IT environments (IT ·Envs) that meet ever increasing user expectations on software quality necessitates innovative practices in the development and operation of software-intensive systems. DevOps teams find themselves searching for ways to deliver value by attacking operational challenges that tend to overwhelm human capabilities. Most of these challenges relate to the structural and behavioural complexities of modern IT·Envs. While the former concerns the orchestration of multiple technologies, the latter involves the exploitation of the huge data streams produced that are integral to DevOps activities. As automation, autonomy, and artificial intelligence technologies are maturing and permeating various activities in the software development lifecycle, opportunities arise from their integration with DevOps practices to improve risk mitigation, root cause analysis, problem resolution, and operational optimization in IT·Envs. This CASCON x EVOKE 2021 workshop discussed challenges and opportunities in developing proactive AIOps through digital twin technologies.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {275–276},
numpages = {2},
keywords = {machine learning, fault prediction, digital twins, cloud, IT operations, DevOps, AIOps, AI},
location = {Toronto, Canada},
series = {CASCON '21}
}

@inproceedings{10.1145/3467707.3467713,
author = {Zhang, Fang and Zhang, Qian and Xiao, ZhiTao and Geng, Lei},
title = {Automatic Detection of Internal Defects of Composite Materials based on ESPI},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3467707.3467713},
doi = {10.1145/3467707.3467713},
abstract = {Composite materials will inevitably have defects and suffer damage during the manufacturing and using. In order to achieve accurate and efficient non-destructive testing of composite materials, an automatic detection system for internal defects of composite materials based on electronic speckle pattern interferometry (ESPI) is designed. The system uses the collected speckle stripes as the defect carrier, and realizes the detection of defects in the composite material by identifying the speckle stripes image. First of all, in order to expand the field of view of the speckle collection light path, we complete the construction of the collection system hardware light path combining the 4f system, and realizes a miniaturized design. Then, the speckle image acquisition control module was designed and combined with the miniaturized instrument to realize the visualization of speckle interference fringes. Finally, in order to realize automatic defect detection, a target detection model is introduced to identify and locate speckle fringes. Experiments have confirmed that the automatic detection of internal defects of composite materials was well completed. The designed miniaturized speckle acquisition system is suitable for defect detection of composite materials. The defect detection network model shows good fringe detection performance, and its mAP reaches 97.91%.},
booktitle = {Proceedings of the 2021 7th International Conference on Computing and Artificial Intelligence},
pages = {39–47},
numpages = {9},
keywords = {Electronic speckle pattern interferometry, Convolutional neural network, Composite material, Automatic defect detection},
location = {Tianjin, China},
series = {ICCAI '21}
}

@phdthesis{10.5555/1144653,
author = {Xiao, Xiangyu and Conners, Richard W. and Kline, D. Earl},
title = {A multiple sensors approach to wood defect detection},
year = {2004},
isbn = {0542363771},
publisher = {Virginia Polytechnic Institute &amp; State University},
address = {USA},
abstract = {This research work reported in this dissertation is the first aimed at creating a vision system utilizes three imaging modalities: a color imaging system, a laser range profiling system and an X-ray imaging system. The objective of in designing this vision system is to detect and identify: (1)&nbsp;surface features such as knots, splits, stains; (2)&nbsp;geometry features such as wane, thin board; and (3)&nbsp;internal features such as voids, knots. The laser range profiling system is used to locate and identify geometry features. The X-ray imaging system is primarily used to detect features such as knots, splits and interior voids. The color imaging system is mainly employed to identify surface features. In this vision system a number of methodologies are used to improve processing speed and identification accuracy. The images from different sensing modalities are analyzed in a special order to offset the larger amount of image data that comes from the multiple sensors and that must be analyzed. The analysis of laser image is performed first. It is used to find defects that have insufficient thickness. These defects are then removed from consideration in the subsequent analysis of the X-ray image. Removing these defects from consideration in the analysis of the X-ray image not only improves the accuracy of detecting and identifying defects but also reduces the amount of time needed to analyze the X-ray image. Similarly, defect areas such as knot and mineral streak that are found in the analysis of the X-ray image are removed from consideration in the analysis of the color image. A fuzzy logic algorithm---the approaching degree method---is used to assign defect labels. The fuzzy logic approach is used to mimic human behavior in identifying defects in hardwood lumber. The initial results obtained from this vision system demonstrate the feasibility of locating and identifying all the major defects that occur in hardwood lumber. This was even true during the initial hardware development phase when only images of unsatisfactory quality from a limited lumber of samples were available. The vision system is capable of locating and identifying defects at the production speed of two linear feet per second that is typical in most hardwood secondary manufacturing plants. This vision system software was designed to run on a relative slow computer (200 MHz Pentium processor) with aid of special image processing hardware, i.e., the MORRPH board that was also designed at Virginia Tech. (Abstract shortened by UMI.)},
note = {AAI3193651}
}

@inproceedings{10.1109/CSIE.2009.501,
author = {Mahmoudi, Abdelhak and Regragui, Fakhita},
title = {Welding Defect Detection by Segmentation of Radiographic Images},
year = {2009},
isbn = {9780769535074},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSIE.2009.501},
doi = {10.1109/CSIE.2009.501},
abstract = {Detection of defects in metallic pieces is an important application in the field of Non-Destructive Testing (NDT), particularly in an industrial setting. These defects are mainly due to manufacturing errors or welding processes. In this article we will focus on this second category of defects using segmentation techniques applied to thewelded joints. Segmentation is one of the most difficulttasks in image processing, particularly in the case of noisy or low contrast images such as radiographic images of welds. In segmenting this type of image, many researchers have used neural networks and fuzzy logic methods. The results are impressive, however the methods require a complex implementation and are time consuming. In this work, we propose a new method for segmenting digitized radiographic images which is based on histogram analysis, contrast enhancement and image thresholding.Computing time is optimized by using integral images to calculate the local thresholds. Although the method gives comparable results to those obtained by previous methods in terms of visual segmentation quality, it is significantly simpler to implement.},
booktitle = {Proceedings of the 2009 WRI World Congress on Computer Science and Information Engineering - Volume 07},
pages = {111–115},
numpages = {5},
keywords = {weld defects, thresholding, radiography, image segmentation},
series = {CSIE '09}
}

@inproceedings{10.1007/978-3-030-37599-7_59,
author = {Jabbar, Eva and Besse, Philippe and Loubes, Jean-Michel and Merle, Christophe},
title = {Conditional Anomaly Detection for Quality and Productivity Improvement of Electronics Manufacturing Systems},
year = {2019},
isbn = {978-3-030-37598-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37599-7_59},
doi = {10.1007/978-3-030-37599-7_59},
abstract = {Today the integration of Artificial Intelligence (AI) solutions is part of the strategy in the industrial environment. We focus on anomaly detection in the framework of manufacturing electronic cards manufacturing under mass production conditions (24/7). Early anomaly detection is critical to avoid defects. Researches and applications of anomaly detection techniques in the industry have been published but when they face production constraints success is not guaranteed. Today’s manufacturing systems are complex and involve different behaviors. We propose and evaluate a new realistic methodology for detecting conditional anomalies that could be successfully implemented in production. The proposed solution is based on Variational Autoencoders (VAEs) which provide interesting scores under the near real-time constraints of the production environment. The results have been thoroughly evaluated and validated with the support of expert process engineers.},
booktitle = {Machine Learning, Optimization, and Data Science: 5th International Conference, LOD 2019, Siena, Italy, September 10–13, 2019, Proceedings},
pages = {711–724},
numpages = {14},
keywords = {Deep conditional anomaly detection, Artificial Intelligence, Electronic circuit manufacturing, Smart factory},
location = {Siena, Italy}
}

@article{10.1016/j.eswa.2006.07.011,
author = {Huang, Chenn-Jung},
title = {Clustered defect detection of high quality chips using self-supervised multilayer perceptron},
year = {2007},
issue_date = {Nov 2007},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2006.07.011},
doi = {10.1016/j.eswa.2006.07.011},
journal = {Expert Syst. Appl.},
month = nov,
pages = {996–1003},
numpages = {8},
keywords = {Defect detection, Median filter, Nearest neighbor, Clustering, Neural networks, Probing, Multilayer perceptron}
}

@inproceedings{10.1109/ICCIMA.2007.152,
author = {Tajeripour, F. and Kabir, E.},
title = {Defect Detection in Patterned Fabrics Using Modified Local Binary Patterns},
year = {2007},
isbn = {0769530508},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCIMA.2007.152},
doi = {10.1109/ICCIMA.2007.152},
abstract = {Local Binary Patterns, LBP, is one of the features which has been used for texture classification. In this paper, a method based on using these features is proposed for detecting defects in patterned fabrics. In the training stage, at first step LBP operator is applied to all rows (columns) of a defect free fabric sample, pixel by pixel, and the reference feature vector is computed. Then this image is divided into windows and LBP operator is applied to each row (column) of these windows. Based on comparison with the reference feature vector a suitable threshold for defect free windows is found. In the detection stage, a test image is divided into windows and using the threshold, defective windows can be detected. The proposed method is simple and gray scale invariant. Because of its simplicity, online implementation is possible as well. Key words: Defect Detection, Texture, Local Binary Patterns, Fabric, Machine Vision.},
booktitle = {Proceedings of the International Conference on Computational Intelligence and Multimedia Applications (ICCIMA 2007) - Volume 02},
pages = {261–267},
numpages = {7},
series = {ICCIMA '07}
}

@article{10.1016/j.infsof.2019.07.003,
author = {Zhou, Tianchi and Sun, Xiaobing and Xia, Xin and Li, Bin and Chen, Xiang},
title = {Improving defect prediction with deep forest},
year = {2019},
issue_date = {Oct 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {114},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.07.003},
doi = {10.1016/j.infsof.2019.07.003},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {204–216},
numpages = {13},
keywords = {Empirical evaluation, Cascade strategy, Deep forest, Software defect prediction}
}

@article{10.1007/s00138-007-0073-3,
author = {Tsai, Du-Ming and Kuo, Chih-Chia},
title = {Defect detection in inhomogeneously textured sputtered surfaces using 3D Fourier image reconstruction},
year = {2007},
issue_date = {November 2007},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-007-0073-3},
doi = {10.1007/s00138-007-0073-3},
abstract = {Texture analysis techniques have been used extensively for surface inspection, in which small defects that appear as local anomalies in textured surfaces must be detected. Traditional surface inspection methods are mainly concentrated on homogeneous textures. In this paper, we propose a 3D Fourier reconstruction scheme to tackle the problem of surface inspection on sputtered glass substrates that contain inhomogeneous textures. Such sputtered surfaces can be found in touch panels and liquid crystal displays (LCDs).Since an inhomogeneously textured surface does not have repetition, self-similarity properties in the image, a sequence of faultless images along with the inspection image are used to construct a 3D image so that the periodic patterns of the surface can be observed in the additional frame-axis. Bandreject filtering is used to eliminate frequency components associated with faultless textures in the spatial domain image, and the 3D inverse Fourier transform is then carried out to reconstruct the image. The resulting image can effectively remove background textures and distinctly preserve anomalies. This converts the difficult defect detection in complicated inhomogeneous textures into a simple thresholding in nontextured images. Experimental results from a number of sputtered glass surfaces have shown the efficacy of the proposed 3D Fourier image reconstruction scheme.},
journal = {Mach. Vision Appl.},
month = nov,
pages = {383–400},
numpages = {18},
keywords = {Surface inspection, Sputtered glass substrates, Inhomogeneous textures, Defect detection, 3D Fourier transforms}
}

@inproceedings{10.5555/1415804.1415849,
author = {Lin, Hong-Dar and Chung, Chung-Yu and Lin, Wan-Ting},
title = {Wavelet-based principal component analysis applied to automated surface defect detection},
year = {2008},
isbn = {9606766671},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Automated visual inspection, a crucial manufacturing step, has been replacing the more time-consuming and less accurate human inspection. This research explores automated visual inspection of surface defects in a light-emitting diode (LED) chip. Commonly found on chip surface are water-spot defects which impair the appearance and functionality of LEDs. Automated inspection of water-spot defects is difficult because they have a semi-opaque appearance and a low intensity contrast with the rough exterior of the LED chip. Moreover, the defect may fall across two different background textures, which further increases detection difficulties. The one-level Haar wavelet transform is first used to decompose a chip image and extract four wavelet characteristics. Then, wavelet-based principal component analysis (WPCA) approach is applied to integrate the multiple wavelet characteristics. Finally, the principal component analysis of WPCA judges the existence of defects. Experimental results show that the proposed method achieves detection rates of above 93.8%, and false alarm rates of below 3.6%. A valid computer-aided visual defect inspection system is contributed to help meet the quality control needs of LED chip manufacturers.},
booktitle = {Proceedings of the WSEAS International Conference on Applied Computing Conference},
pages = {245–250},
numpages = {6},
keywords = {wavelet characteristics, surface defect detection, principal component analysis, computer vision system},
location = {Istanbul, Turkey},
series = {ACC'08}
}

@inproceedings{10.1145/3460268.3460277,
author = {Sun, Han and Wang, Jing and Li, Kunlun and Zhang, Qingwei},
title = {CPDD: A Cascaded-Parallel Defect Detector with Application to Intelligent Inspection in Substation},
year = {2021},
isbn = {9781450389273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460268.3460277},
doi = {10.1145/3460268.3460277},
abstract = {The intelligent inspection is a detection problem that aims to recognize abnormalities in substations. Defects acquired by various devices with small size, truncation, and similar appearance are easily confused, which biases the evaluation metrics. How to correctly explore the relationships between equipment and defects, and fully utilize results from different models is critical for this task. In this work, we propose a novel solution to these problems based on the cascaded-parallel defect detection (CPDD) algorithm. Specifically, it consists of two key components: (1) The cascaded model aims to mine the detailed relationships and filter out the illogical bounding boxes. This way can reduce the miss detection rate. (2) The parallel model is to fuse results from the mentioned cascaded model. It can utilize the information from these two-stage models and promote the detectable rate. Extensive empirical results on the dataset, acquired by our designed inspection system in different voltage-level substations, demonstrate the superiority of our proposed method. It can achieve state-of-the-art performance.},
booktitle = {Proceedings of the 2021 2nd International Conference on Artificial Intelligence in Electronics Engineering},
pages = {60–66},
numpages = {7},
keywords = {Symbiosis and mutually-exclusive relationships, Parallel model, Defect detection, Cascaded model},
location = {Phuket, Thailand},
series = {AIEE '21}
}

@article{10.1016/j.eswa.2007.09.059,
author = {Gebus, S\'{e}bastien and Juuso, Esko and Leivisk\"{a}, Kauko},
title = {Knowledge-based linguistic equations for defect detection through functional testing of printed circuit boards},
year = {2009},
issue_date = {January, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {1},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2007.09.059},
doi = {10.1016/j.eswa.2007.09.059},
abstract = {Increasing globalization of the economy is imposing tough challenges to manufacturing companies. The ability to produce highly customized products, in order to satisfy market niches, requires the introduction of new features in automation systems. Flexible manufacturing processes must be able to handle unforeseen events, but their complexity makes the supervision and maintenance task difficult to perform by human operators. This paper describes how linguistic equations (LE), an intelligent method derived from Fuzzy Algorithms, has been used in a decision-helping tool for electronic manufacturing. In our case the company involved in the project is mainly producing control cards for the automotive industry. In their business, nearly 70% of the cost of a product is material cost. Detecting defects and repairing the printed circuit boards is therefore a necessity. With an ever increasing complexity of the products, defects are very likely to occur, no matter how much attention is put into their prevention. Therefore, the system described in this paper comes into use only during the final testing of the product and is purely oriented towards the detection and localization of defects. Final control is based on functional testing. Using linguistic equations and expert knowledge, the system is able to analyze that data and successfully detect and trace a defect in a small area of the printed circuit board. If sufficient amount of data is provided, self-tuning and self-learning methods can be used. Diagnosis effectiveness can therefore be improved from detection of a functional area towards component level analysis.},
journal = {Expert Syst. Appl.},
month = jan,
pages = {292–302},
numpages = {11},
keywords = {Defect detection, Linguistic equations, Knowledge, Fuzzy logic, Diagnosis}
}

@article{10.1504/IJCAT.2014.060527,
author = {Priya, R. and Aruna, P.},
title = {Automated diagnosis of age-related macular degeneration using machine learning techniques},
year = {2014},
issue_date = {April 2014},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {49},
number = {2},
issn = {0952-8091},
url = {https://doi.org/10.1504/IJCAT.2014.060527},
doi = {10.1504/IJCAT.2014.060527},
abstract = {Age-related macular ARM degeneration is an eye disease, that gradually degrades the macula, a part of the retina, which is responsible for central vision. It occurs in one of the two types, dry and wet age-related macular degeneration. The purpose of this paper is to diagnose the retinal disease age-related macular degeneration. An automated approach is proposed to help in the early detection of age-related macular degeneration using three models and their performances are compared. The amount of the disease spread in the retina can be identified by extracting the features of the retina. Detection of age-related macular degeneration disease has been done using probabilistic neural network PNN, Bayesian classification and support vector machine SVM and the two types of age-related macular degeneration are classified and diagnosed successfully. The results show that SVM achieves a higher performance measure than probabilistic neural network and Bayes classification.},
journal = {Int. J. Comput. Appl. Technol.},
month = apr,
pages = {157–165},
numpages = {9}
}

@inproceedings{10.1109/ICICIC.2007.308,
author = {Li, Bin and Zhang, Wei-guo and Ning, Dong-fang and Yin, Wei},
title = {Fault Prediction System Based on Neural Network Model},
year = {2007},
isbn = {0769528821},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICICIC.2007.308},
doi = {10.1109/ICICIC.2007.308},
abstract = {In the fault diagnosis of the plane steering surface, exact fault prediction is very important for the security of the aircraft. According to design requirement of the plane steering surface fault prediction system, the application of neural network technique is plane fault prediction is presented, and the algorithm based on the neural network model in the prediction system is given. Considering the advantage of neural network technique, the neural network and the fault prediction technique with expert are combined to form a fault prediction system. Finally, taking the steering surface of plane as an example to realize fault prediction, the result proves that the forecast model and algorithm based on the neural network are feasible.},
booktitle = {Proceedings of the Second International Conference on Innovative Computing, Informatio and Control},
pages = {496},
series = {ICICIC '07}
}

@article{10.1016/j.eswa.2010.10.024,
author = {Catal, Cagatay},
title = {Review: Software fault prediction: A literature review and current trends},
year = {2011},
issue_date = {April, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.10.024},
doi = {10.1016/j.eswa.2010.10.024},
abstract = {Software engineering discipline contains several prediction approaches such as test effort prediction, correction cost prediction, fault prediction, reusability prediction, security prediction, effort prediction, and quality prediction. However, most of these prediction approaches are still in preliminary phase and more research should be conducted to reach robust models. Software fault prediction is the most popular research area in these prediction approaches and recently several research centers started new projects on this area. In this study, we investigated 90 software fault prediction papers published between year 1990 and year 2009 and then we categorized these papers according to the publication year. This paper surveys the software engineering literature on software fault prediction and both machine learning based and statistical based approaches are included in this survey. Papers explained in this article reflect the outline of what was published so far, but naturally this is not a complete review of all the papers published so far. This paper will help researchers to investigate the previous studies from metrics, methods, datasets, performance evaluation metrics, and experimental results perspectives in an easy and effective manner. Furthermore, current trends are introduced and discussed.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {4626–4636},
numpages = {11},
keywords = {Automated fault prediction models, Expert systems, Machine learning, Software engineering, Software quality engineering, Statistical methods}
}

@inproceedings{10.5555/1627368.1627435,
author = {Podgorelec, Vili},
title = {On software fault prediction by mining software complexity data with dynamically filtered training sets},
year = {2009},
isbn = {9789604741137},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Software fault prediction methods are very appropriate for improving the software reliability. With the creation of large empirical databases of software projects, as a result of stimulated research on estimation models, metrics and methods for measuring and improving processes and products, intelligent mining of these datasets can largely add to the improvement of software reliability. In the paper we present a study on using decision tree classifiers for predicting software faults. A new training set filtering method is presented that should improve the classification performance when mining the software complexity measures data. The classification improvement should be achieved by removing the identified outliers from a training set. We argue that a classifier trained by a filtered dataset captures a more general knowledge model and should therefore perform better also on unseen cases. The proposed method is applied on a real-world software reliability analysis dataset and the obtained results are discussed.},
booktitle = {Proceedings of the 9th WSEAS International Conference on Simulation, Modelling and Optimization},
pages = {332–337},
numpages = {6},
keywords = {classification, complexity metrics, filtering training set, search-based software engineering, software fault prediction},
location = {Budapest, Hungary},
series = {SMO'09}
}

@article{10.1016/j.rcim.2008.03.014,
author = {S\'{a}enz de Argando\~{n}a, E. and Aztiria, A. and Garc\'{\i}a, C. and Arana, N. and Izaguirre, A. and Fillatreau, P.},
title = {Forming processes control by means of artificial intelligence techniques},
year = {2008},
issue_date = {Dec 2008},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {24},
number = {6},
issn = {0736-5845},
url = {https://doi.org/10.1016/j.rcim.2008.03.014},
doi = {10.1016/j.rcim.2008.03.014},
journal = {Robot. Comput.-Integr. Manuf.},
month = dec,
pages = {773–779},
numpages = {7},
keywords = {Blanking process, Force and acoustic monitoring system, Artificial vision system, Expert system}
}

@article{10.1007/s00521-021-05995-8,
author = {Tyralis, Hristos and Papacharalampous, Georgia},
title = {Boosting algorithms in energy research: a systematic review},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {21},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05995-8},
doi = {10.1007/s00521-021-05995-8},
abstract = {Machine learning algorithms have been extensively exploited in energy research, due to their flexibility, automation and ability to handle big data. Among the most prominent machine learning algorithms are the boosting ones, which are known to be “garnering wisdom from a council of fools”, thereby transforming weak learners to strong learners. Boosting algorithms are characterized by both high flexibility and high interpretability. The latter property is the result of recent developments by the statistical community. In this work, we provide understanding on the properties of boosting algorithms to facilitate a better exploitation of their strengths in energy research. In this respect, (a) we summarize recent advances on boosting algorithms, (b) we review relevant applications in energy research with those focusing on renewable energy (in particular those focusing on wind energy and solar energy) consisting a significant portion of the total ones, and (c) we describe how boosting algorithms are implemented and how their use is related to their properties. We show that boosting has been underexploited so far, while great advances in the energy field are possible both in terms of explanation and interpretation, and in terms of predictive performance.},
journal = {Neural Comput. Appl.},
month = nov,
pages = {14101–14117},
numpages = {17},
keywords = {Artificial intelligence, Energy forecasting, Machine learning, Renewable energy}
}

@inproceedings{10.5555/1710523.1710543,
author = {Kim, Sang Ji and Kim, Nam Yoo and Lee, Byung Gook and Lee, Joon Jae},
title = {Wavelet based uneven illumination compensation for defect detection of flat panel display},
year = {2007},
isbn = {9780889866478},
publisher = {ACTA Press},
address = {USA},
abstract = {FPD(Flat panel displays) are becoming widely acceptable and popular as display devices growing at a rapid pace and making it a promising investment opportunity. Display quality is part of the final FPD inspection process prior to shipping. FPD devices have non-uniform background intensity, and shape and intensity of defects are very various. Due to the uneven illumination of panels it is difficult to detect the defects, Therefore this paper proposes a uneven illumination compensation method using wavelet based multi-resolution structure. This is first done by decomposing the image into multi-resolution levels and selecting some band frequency sub-bands by removing lower sub-bands and higher sub-bands corresponding to low varying signal and high frequency random noise, respectively, resulting in flat background images in reconstruction. A simple binary thresholding technique is then used to separate the defective regions from the restored image. Finally, blob analysis as post-processing is carried out to get rid of false defects.},
booktitle = {Proceedings of the Fourth IASTED International Conference on Signal Processing, Pattern Recognition, and Applications},
pages = {104–108},
numpages = {5},
keywords = {defect detection, flat panel display, illumination compensation, segmentation},
location = {Innsbruck, Austria},
series = {SPPRA '07}
}

@article{10.1016/j.eswa.2019.113122,
author = {Tubishat, Mohammad and Idris, Norisma and Shuib, Liyana and Abushariah, Mohammad A.M. and Mirjalili, Seyedali},
title = {Improved Salp Swarm Algorithm based on opposition based learning and novel local search algorithm for feature selection},
year = {2020},
issue_date = {May 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113122},
doi = {10.1016/j.eswa.2019.113122},
journal = {Expert Syst. Appl.},
month = may,
numpages = {10},
keywords = {Salp Swarm Algorithm, Classification, Feature selection, Optimization, Machine Learning, Algorithm, Opposition Based Learning}
}

@article{10.1504/ijict.2021.117532,
author = {Wang, Hui and Gao, Chunhua and Ling, Yongfa},
title = {A deep learning-based method for aluminium foil-surface defect recognition},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {3},
issn = {1466-6642},
url = {https://doi.org/10.1504/ijict.2021.117532},
doi = {10.1504/ijict.2021.117532},
abstract = {In order to effectively detect and classify various defects on the surface of aluminium foil products, including contaminants, coining, shine marks and scratches, etc., the method of convolution neural network (CNN) is used and the detection of surface defects of aluminium product is realised by machine learning. Firstly, aluminium foil images are collected by CCD camera, and edge detection is performed on these images to obtain a complete picture area. Then, the robust principal component analysis (RPCA) method was used to perform underlying low-rank and sparse decomposition on the data matrix to obtain the defect areas in these images; Finally, using TensorFlow platform to build a CNN model, loading aluminium foil images and training to get the CNN model parameters, according to this CNN network model, the surface defects of aluminium foil images can be detected and classified in real-time. Numerical experiments verified that the proposed algorithm has the following advantages such as high accuracy, favourable expansibility and so on. It can also be easily applied into surface defect detection for other objects.},
journal = {Int. J. Inf. Commun. Techol.},
month = jan,
pages = {231–241},
numpages = {10},
keywords = {defect detection, convolution neural network, CNN, deep learning, TensorFlow, aluminium foil image}
}

@inproceedings{10.1007/11552499_46,
author = {Xie, Xianghua and Mirmehdi, Majid},
title = {Texture exemplars for defect detection on random textures},
year = {2005},
isbn = {3540288333},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11552499_46},
doi = {10.1007/11552499_46},
abstract = {We present a new approach to detecting defects in random textures which requires only very few defect free samples for unsupervised training. Each product image is divided into overlapping patches of various sizes. Then, density mixture models are applied to reduce groupings of patches to a number of textural exemplars, referred to here as texems, characterising the means and covariances of whole sets of image patches. The texems can be viewed as implicit representations of textural primitives. A multiscale approach is used to save computational costs. Finally, we perform novelty detection by applying the lower bound of normal samples likelihoods on the multiscale defect map of an image to localise defects.},
booktitle = {Proceedings of the Third International Conference on Pattern Recognition and Image Analysis - Volume Part II},
pages = {404–413},
numpages = {10},
location = {Bath, UK},
series = {ICAPR'05}
}

@article{10.1049/iet-sen.2019.0278,
author = {Zhu, Kun and Zhang, Nana and Ying, Shi and Zhu, Dandan},
title = {Within‐project and cross‐project just‐in‐time defect prediction based on denoising autoencoder and convolutional neural network},
year = {2020},
issue_date = {June 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2019.0278},
doi = {10.1049/iet-sen.2019.0278},
abstract = {Just‐in‐time defect prediction is an important and useful branch in software defect prediction. At present, deep learning is a research hotspot in the field of artificial intelligence, which can combine basic defect features into deep semantic features and make up for the shortcomings of machine learning algorithms. However, the mainstream deep learning techniques have not been applied yet in just‐in‐time defect prediction. Therefore, the authors propose a novel just‐in‐time defect prediction model named DAECNN‐JDP based on denoising autoencoder and convolutional neural network in this study, which has three main advantages: (i) Different weights for the position vector of each dimension feature are set, which can be automatically trained by adaptive trainable vector. (ii) Through the training of denoising autoencoder, the input features that are not contaminated by noise can be obtained, thus learning more robust feature representation. (iii) The authors leverage a powerful representation‐learning technique, convolution neural network, to construct the basic change features into the abstract deep semantic features. To evaluate the performance of the DAECNN‐JDP model, they conduct extensive within‐project and cross‐project defect prediction experiments on six large open source projects. The experimental results demonstrate that the superiority of DAECNN‐JDP on five evaluation metrics.},
journal = {IET Software},
month = jun,
pages = {185–195},
numpages = {18},
keywords = {neural nets, learning (artificial intelligence), denoising autoencoder, software defect prediction, basic defect features, mainstream deep learning techniques, just-in-time defect prediction model, autoencoder convolutional neural network, convolution neural network, cross-project defect prediction experiments}
}

@article{10.1016/j.eswa.2010.11.046,
author = {Liu, Yi-Hung and Liu, Yan-Chen and Chen, Yen-Zen},
title = {High-speed inline defect detection for TFT-LCD array process using a novel support vector data description},
year = {2011},
issue_date = {May, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {5},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.11.046},
doi = {10.1016/j.eswa.2010.11.046},
abstract = {Research highlights Traditional defect inspection for TFT-LCD is based on sampling inspection, mainly due to the fact that the throughput of TFT-LCD panels is huge, while the inspection speed is slow. In this paper, an automatic inspection scheme which can achieve the goal of full inspection is proposed. To achieve the goal of full inspection, a variant of the well-known one-class classifier SVDD (support vector data description) is proposed. This variant greatly improves the classification speed of SVDD, thus called fast SVDD (F-SVDD). The proposed F-SVDD is a general one-class classifier. Therefore, although the F-SVDD is tested on the TFT-LCD inspection in this paper, it can be implemented in other applications related to novelty detection. In the proposed F-SVDD, a novel preimage-finding method is also presented. This method can be applied to reduce the computational complexities of other classifiers such as support vector machines (SVMs). TFT array process is a critical fabrication process for thin film transistor liquid crystal display (TFT-LCD) manufacturing, and defect detection plays an important role in yield improvement for this process. Due to the diversity of defect modes and their occurrence frequencies, the true distribution of the defective patterns is difficult to obtain. On the contrary, normal patterns are easy to collect and they involve only small variations in uniformity. Hence, one-class classification is an appropriate strategy for the LCD inline defect inspection. Accordingly, as a defect detector, the one-class classifier, support vector data description (SVDD), is a good candidate due to its satisfactory results in many one-class classification problems. However, SVDD has the drawback that its testing complexity is linear in the number of training patterns, which makes SVDD unable to provide a fast-enough classification speed. This is problematic because, although SVDD is accurate in defect detection task, it is difficult to implement for real-time tasks, especially when a full inspection (every LCD panel will be inspected) is required. To address this critical issue, in this paper we propose a novel SVDD, called fast SVDD (F-SVDD). The proposed F-SVDD not only inherits the merit of the traditional SVDD, which can obtain a compact description for a target set, but also can provide a much faster classification speed because its testing complexity is independent of the number of training patterns. Experimental results, carried out on real surface images of LCD panels, indicate that the F-SVDD is able to obtain a high defect detection rate of over 95%. More importantly, compared with the traditional SVDD, the proposed F-SVDD is able to accomplish the inline defect detection task with a relatively faster speed: SVDD needs to spend 30.17min inspecting each LCD panel, while the same task can be done within 0.13min (only 7.8s) by F-SVDD.},
journal = {Expert Syst. Appl.},
month = may,
pages = {6222–6231},
numpages = {10},
keywords = {Defect inspection, Full inspection, Support vector data description (SVDD), TFT array process, Thin film transistor liquid crystal display (TFT-LCD)}
}

@inproceedings{10.5555/1331978.1331996,
author = {Kim, Sang Ji and Kim, Nam Yoo and Lee, Byung Gook and Lee, Joon Jae},
title = {Wavelet based uneven illumination compensation for defect detection of flat panel display},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {FPD(Flat panel displays) are becoming widely acceptable and popular as display devices growing at a rapid pace and making it a promising investment opportunity. Display quality is part of the final FPD inspection process prior to shipping. FPD devices have non-uniform background intensity, and shape and intensity of defects are very various. Due to the uneven illumination of panels it is difficult to detect the defects, Therefore this paper proposes a uneven illumination compensation method using wavelet based multi-resolution structure. This is first done by decomposing the image into multiresolution levels and selecting some band frequency sub-bands by removing lower sub-bands and higher sub-bands corresponding to low varying signal and high frequency random noise, respectively, resulting in flat background images in reconstruction. A simple binary thresholding technique is then used to separate the defective regions from the restored image. Finally, blob analysis as post-processing is carried out to get rid of false defects.},
booktitle = {Proceedings of the Fourth Conference on IASTED International Conference: Signal Processing, Pattern Recognition, and Applications},
pages = {104–108},
numpages = {5},
keywords = {defect detection, flat panel display, illumination compensation, segmentation},
location = {Innsbruck, Austria},
series = {SPPR'07}
}

@article{10.1016/j.patcog.2005.02.004,
author = {Rohrmus, D. R.},
title = {Invariant and adaptive geometrical texture features for defect detection and classification},
year = {2005},
issue_date = {October, 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {38},
number = {10},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2005.02.004},
doi = {10.1016/j.patcog.2005.02.004},
abstract = {Automatic texture defect detection is highly important for many fields of visual inspection. We introduce novel, geometrical texture features for this task, which are Euclidean motion invariant and texture adaptive: An algebraic function (rational, Pade, or polynomial) is integrated over intensities in local, circular neighborhoods on the image including an anisotropical texture analysis. Adaptiveness is achieved through the optimization of this feature kernel and further coefficients based on a simplex energy minimization, constrained by a measure of texture discrimination (Fisher criterion). A backpropagation trained, multilayer perceptron network classifies the textures locally. Our approach contains new properties, usually not common in feature theories: Theoretically implicit, multiple invariances and an automatic and specific adaptation of the features to the texture images. Experiments with a fabric data set and Brodatz textures reveal up to 98.6% recognition accuracy.},
journal = {Pattern Recogn.},
month = oct,
pages = {1546–1559},
numpages = {14},
keywords = {Fisher criterion discrimination, Geometrical texture features, Multi-texture classification, Multilayer perceptron network, Rational- and Pad\'{e}-based features, Rotation/translation invariance, Simplex feature optimization, Surface inspection, Texture adaptive features, Texture defect detection}
}

@article{10.1504/ijaip.2019.101983,
author = {Kumar, Reddi Kiran and Rao, S.V. Achuta},
title = {Severity of defect: an optimised prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {3–4},
issn = {1755-0386},
url = {https://doi.org/10.1504/ijaip.2019.101983},
doi = {10.1504/ijaip.2019.101983},
abstract = {To assure the quality of software an important activity is performed namely software defect prediction (SDP). Historical databases are used to detect software defects using different machine learning techniques. Conversely, there are disadvantages like testing becomes expensive, poor quality and so the product is unreliable for use. This paper classifies the severity of defects by using a method based on optimised neural network (NN). In full search space, a solution is found by many meta-heuristic optimisations and global search ability has been used. Hence, high-quality solutions are finding within a reasonable period of time. SDP performance is improved by the combination of meta-heuristic optimisation methods. For class imbalance problem, meta-heuristic optimisation methods such as genetic algorithm (GA) and shuffled frog leaping algorithm (SFLA) are applied. The above method is based on SFLA and the experimental outputs show that it can do better than Leven berg Marquardt based NN system (LM-NN).},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {334–345},
numpages = {11},
keywords = {software defect prediction, SDP, severity, neural network, Levenberg Marquardt, LM, shuffled frog and fuzzy classifier}
}

@article{10.1016/j.infsof.2006.07.005,
author = {Kanmani, S. and Uthariaraj, V. Rhymend and Sankaranarayanan, V. and Thambidurai, P.},
title = {Object-oriented software fault prediction using neural networks},
year = {2007},
issue_date = {May, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {5},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.07.005},
doi = {10.1016/j.infsof.2006.07.005},
abstract = {This paper introduces two neural network based software fault prediction models using Object-Oriented metrics. They are empirically validated using a data set collected from the software modules developed by the graduate students of our academic institution. The results are compared with two statistical models using five quality attributes and found that neural networks do better. Among the two neural networks, Probabilistic Neural Networks outperform in predicting the fault proneness of the Object-Oriented modules developed.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {483–492},
numpages = {10},
keywords = {Back propagation neural network, Discriminant analysis, Fault proneness, Logistic regression, Object-Oriented metrics, Probabilistic neural network}
}

@article{10.1007/s11219-018-9409-7,
author = {Minku, Leandro L. and Bener, Ay\c{s}e B. and Turhan, Burak},
title = {Guest editorial: special issue on predictive models for software quality},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9409-7},
doi = {10.1007/s11219-018-9409-7},
journal = {Software Quality Journal},
month = jun,
pages = {521–523},
numpages = {3}
}

@article{10.1007/s00138-010-0260-5,
author = {Martin, D. and Guinea, D. M. and Garc\'{\i}a-Alegre, M. C. and Villanueva, E. and Guinea, D.},
title = {Multi-modal defect detection of residual oxide scale on a cold stainless steel strip},
year = {2010},
issue_date = {August 2010},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {5},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-010-0260-5},
doi = {10.1007/s00138-010-0260-5},
abstract = {This work presents two initial approaches and a novel technique for the industrial inspection of residual oxide scale on a cold stainless steel strip. The research aims to develop real-time systems to detect 50-μm defects. Initially, a spectrophotometric analysis provides the wavelength regions where differences between stainless steel and residual oxide scale reflectance are highlighted. The multi-modal approach is based on laser techniques that comprise three different strategies to gradually achieve a robust stainless steel industrial inspection through the evaluation of their performance. First, an inspection system based on a single commercial laser has been designed with a dynamic threshold module. In the second approach, the inspection task is accomplished by volatilizing a reduced area of the stainless steel surface with short pulses of a high-power ultraviolet laser and then analyzing the generated plasma with an intensifier camera. The third technique consists of an innovative smart vision system for surface visual inspection based on laser diode diffuse illumination. This vision system can be configured to work with two laser illumination modes: the diffuse coaxial lighting and the diffuse bright-field lighting. These techniques aim to gradually improve surface defect detection of a cold stainless steel strip. Furthermore, some of the results of the defect detection level obtained with each approach are displayed and discussed.},
journal = {Mach. Vision Appl.},
month = aug,
pages = {653–666},
numpages = {14},
keywords = {Cold stainless steel strip, Diffuse bright-field lighting, Diffuse coaxial lighting, Machine vision, Residual oxide scale, Vision industrial applications}
}

@inproceedings{10.5555/1337691.1338390,
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
title = {Fault Prediction using Early Lifecycle Data},
year = {2007},
isbn = {0769530249},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The prediction of fault-prone modules in a software project has been the topic of many studies. In this paper, we investigate whether metrics available early in the development lifecycle can be used to identify fault-prone software modules. More precisely, we build predictive models using the metrics that characterize textual requirements. We compare the performance of requirements-based models against the performance of code-based models and models that combine requirement and code metrics. Using a range of modeling techniques and the data from three NASA projects, our study indicates that the early lifecycle metrics can play an important role in project management, either by pointing to the need for increased quality monitoring during the development or by using the models to assign verification and validation activities.},
booktitle = {Proceedings of the The 18th IEEE International Symposium on Software Reliability},
pages = {237–246},
numpages = {10},
series = {ISSRE '07}
}

@article{10.1007/s00521-020-04819-5,
author = {Chen, Haiyong and Hu, Qidi and Zhai, Baoshuo and Chen, He and Liu, Kun},
title = {A robust weakly supervised learning of deep Conv-Nets for surface defect inspection},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {15},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04819-5},
doi = {10.1007/s00521-020-04819-5},
abstract = {Automatic defect detection is a challenging task owing to the complex textured background with non-uniform intensity distribution, weak differences between defects and background, diversity of defect types, and high cost of annotated samples. In order to solve these challenges, this paper proposes a novel end-to-end defect classification and segmentation framework based on weakly supervised learning of a convolutional neural network (CNN) with attention architecture. Firstly, a novel end-to-end CNN architecture integrating the robust classifier and spatial attention module is proposed to enhance defect feature representation ability, which significantly improves the classification accuracy. Secondly, a new spatial attention class activation map (SA-CAM) is proposed to improve segmentation adaptability by generating more accurate heatmap. Moreover, for different surface texture, SA-CAM can significantly suppress the background’s inference and highlight defect area. Finally, the proposed weakly supervised learning framework is trained using only global image labels and devoted to two main visual recognition tasks: defect samples classification and area segmentation. At the same time, it is robust to complex backgrounds. Results of the experiments verify the generalization of the proposed method on three distinct datasets with different kinds of textures and backgrounds. In the classification tasks, the proposed method improves accuracy by 0.66–25.50%. In the segmentation tasks, the proposed method improves accuracy by 5.49–7.07%.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {11229–11244},
numpages = {16},
keywords = {Machine vision, Spatial attention, Deep learning, Defect detection, Convolutional neural network}
}

@inproceedings{10.1007/978-3-540-72393-6_94,
author = {Lin, Hong-Dar and Chung, Chung-Yu},
title = {A Wavelet-Based Neural Network Applied to Surface Defect Detection of LED Chips},
year = {2007},
isbn = {9783540723929},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-72393-6_94},
doi = {10.1007/978-3-540-72393-6_94},
abstract = {This research explores the automated detection of surface defects that fall across two different background textures in a light-emitting diode (LED) chip. Water-drop defects, commonly found on chip surface, impair the appearance of LEDs as well as their functionality and security. Automated inspection of a water-drop defect is difficult because the defect has a semi-opaque appearance and a low intensity contrast with the rough exterior of the LED chip. Moreover, the blemish may fall across two different background textures, which further increases the difficulties of defect detection. We first use the one-level Haar wavelet transform to decompose a chip image and extract four wavelet characteristics. Then, the Multi-Layer Perceptron (MLP) neural network with back-propagation (BPN) algorithm is applied to integrate the multiple wavelet characteristics. Finally, the wavelet-based neural network approach judges the existence of water-drop defects. Experimental results show that the proposed method achieves an above 96.8% detection rate and a below 4.8% false alarm rate.},
booktitle = {Proceedings of the 4th International Symposium on Neural Networks: Part II--Advances in Neural Networks},
pages = {785–792},
numpages = {8},
keywords = {Computer vision system, LED chip, Multi-layer perceptron neural network with backpropagation algorithm, Wavelet decomposition, surface defect detection},
location = {Nanjing, China},
series = {ISNN '07}
}

@inproceedings{10.1145/2184751.2184798,
author = {Rao, G. Subrahmanya Vrk and Diwanji, Vivek and Parthasarathi, Jinka},
title = {Application case study of machine learning techniques towards a fault diagnosis system for a manufacturing plant environment},
year = {2012},
isbn = {9781450311724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2184751.2184798},
doi = {10.1145/2184751.2184798},
abstract = {Fault diagnosis is a vital problem in process engineering. It is the fundamental component of anomalous event management (AEM) which has attracted a lot of attention over recent years. AEM deals with the timely detection, diagnosis and correction of abnormal conditions of faults in a process. Early detection and diagnosis of process faults while the plant is still operating in a controllable region can help avoid anomalous event evolution, improve uptime and reduce efficiency loss. There is a great quantity of literature on process fault diagnosis ranging from analytical methods to artificial intelligence and statistical approaches. From a modeling perspective, there are methods that require accurate process models, semi-quantitative models, or qualitative models. At the other end of the gamut, there are methods that do not assume any form of model information and rely only on historical process data. In this paper we present the performance of few approaches of data driven modeling/machine learning techniques on the simulated data from a distillation column.},
booktitle = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication},
articleno = {38},
numpages = {4},
keywords = {artificial intelligence, data mining, fault diagnosis, na\"{\i}ve Bayesian, pattern discovery, process industries, support vector machine},
location = {Kuala Lumpur, Malaysia},
series = {ICUIMC '12}
}

@article{10.1016/j.eswa.2010.04.082,
author = {Valavanis, Ioannis and Kosmopoulos, Dimitrios},
title = {Multiclass defect detection and classification in weld radiographic images using geometric and texture features},
year = {2010},
issue_date = {December, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {12},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.04.082},
doi = {10.1016/j.eswa.2010.04.082},
abstract = {In this paper, a method for the detection and classification of defects in weld radiographs is presented. The method has been applied for detecting and discriminating discontinuities in the weld images that may correspond to false alarms or defects such as worm holes, porosity, linear slag inclusion, gas pores, lack of fusion or crack. A set of 43 descriptors corresponding to texture measurements and geometrical features is extracted for each segmented object and given as input to a classifier. The classifier is trained to classify each of the objects it into one of the defect classes or characterize it as non-defect. Three fold cross validation was utilized and experimental results are reported for three different classifiers (Support Vector Machine, Neural Network, k-NN).},
journal = {Expert Syst. Appl.},
month = dec,
pages = {7606–7614},
numpages = {9},
keywords = {Classification, Defects, Geometrical features, Radiography, Segmentation, Texture, Welds}
}

@article{10.1016/j.eswa.2009.04.047,
author = {Hou, Shumin and Li, Yourong},
title = {Short-term fault prediction based on support vector machines with parameter optimization by evolution strategy},
year = {2009},
issue_date = {December, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.04.047},
doi = {10.1016/j.eswa.2009.04.047},
abstract = {Support vector machines (SVMs) are the effective machine-learning methods based on the structural risk minimization (SRM) principle, which is an approach to minimize the upper bound risk functional related to the generalization performance. The parameter selection is an important factor that impacts the performance of SVMs. Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) is an evolutionary optimization strategy, which is used to optimize the parameters of SVMs in this paper. Compared with the traditional SVMs, the optimal SVMs using CMA-ES have more accuracy in predicting the Lorenz signal. The industry case illustrates that the proposed method is very successfully in forecasting the short-term fault of large machinery.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {12383–12391},
numpages = {9},
keywords = {Evolutionary algorithms, Fault prediction, Support vector machines}
}

@article{10.1007/s10515-011-0086-z,
author = {Thummalapenta, Suresh and Xie, Tao},
title = {Alattin: mining alternative patterns for defect detection},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0086-z},
doi = {10.1007/s10515-011-0086-z},
abstract = {To improve software quality, static or dynamic defect-detection tools accept programming rules as input and detect their violations in software as defects. As these programming rules are often not well documented in practice, previous work developed various approaches that mine programming rules as frequent patterns from program source code. Then these approaches use static or dynamic defect-detection techniques to detect pattern violations in source code under analysis. However, these existing approaches often produce many false positives due to various factors. To reduce false positives produced by these mining approaches, we develop a novel approach, called Alattin, that includes new mining algorithms and a technique for detecting neglected conditions based on our mining algorithm. Our new mining algorithms mine patterns in four pattern formats: conjunctive, disjunctive, exclusive-disjunctive, and combinations of these patterns. We show the benefits and limitations of these four pattern formats with respect to false positives and false negatives among detected violations by applying those patterns to the problem of detecting neglected conditions.},
journal = {Automated Software Engg.},
month = dec,
pages = {293–323},
numpages = {31},
keywords = {Alternative patterns, Code search engine, Mining software engineering data, Static defect detection}
}

@inproceedings{10.1109/SNPD.2012.34,
author = {Uchigaki, Satoshi and Uchida, Shinji and Toda, Koji and Monden, Akito},
title = {An Ensemble Approach of Simple Regression Models to Cross-Project Fault Prediction},
year = {2012},
isbn = {9780769547619},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SNPD.2012.34},
doi = {10.1109/SNPD.2012.34},
abstract = {In software development, prediction of fault-prone modules is an important challenge for effective software testing. However, high prediction accuracy may not be achieved in cross-project prediction, since there is a large difference in distribution of predictor variables between the base project and the target project.@In this paper we propose an prediction technique called gan ensemble of simple regression modelsh to improve the prediction accuracy of cross-project prediction. The proposed method uses weighted sum of outputs of simple logistic regression models to improve the generalization ability of logistic models. To evaluate the performance of the proposed method, we conducted cross-project prediction using datasets of projects from NASA IV&amp;V Facility Metrics Data Program. As a result, the proposed method outperformed conventional logistic regression models in terms of AUC of the Alberg diagram.},
booktitle = {Proceedings of the 2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing},
pages = {476–481},
numpages = {6},
keywords = {empirical study, fault-prone module prediction, product metrics},
series = {SNPD '12}
}

@inproceedings{10.5555/1777292.1777378,
author = {D'Orazio, T. and Leo, M. and Guaragnella, C. and Distante, A.},
title = {Analysis of image sequences for defect detection in composite materials},
year = {2007},
isbn = {3540746064},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The problem of inspecting composite materials to detect internal defects is felt in many industrial contexts both for quality controls through production lines and for maintenance operations during in-service inspections. The analysis of the internal defects (not detectable by a visual inspection) is a difficult task unless invasive techniques are applied. For this reason in the last years there has been an increasing interest for the development of low cost non-destructive inspection techniques that can be applied during normal routine tests without damaging materials but also with automatic analysis tools. In this paper we have addressed the problem of developing an automatic signal processing system that analyzes the time/space variations in a sequence of thermographic images and allows the identification of internal defects in composite materials that otherwise could not be detected. First of all a preprocessing technique was applied to the time /space signals to extract significant information, then an unsupervised classifier was used to extract uniform classes that characterize a range of internal defects. The experimental results demonstrate the ability of the method to recognize different regions containing several types defects.},
booktitle = {Proceedings of the 9th International Conference on Advanced Concepts for Intelligent Vision Systems},
pages = {855–864},
numpages = {10},
location = {Delft, The Netherlands},
series = {ACIVS'07}
}

@article{10.5555/1639385.1639388,
author = {Cheng, Yaoyu and Hu, Yan and Wang, Yu},
title = {Defect detection and characteristics description of auto hub radiographic image based on SUSAN operation},
year = {2009},
issue_date = {July 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {8},
number = {7},
issn = {1109-2769},
abstract = {The collected images' target object is faint in the auto hub real-time X-ray detection, so it is easily making the miscarriage of justice in the auto hub detection. Most of the current method of detection of defects is by manual detection, so it is very difficult to improve detection efficiency and detection accuracy. Aiming at these issues and combining with the characteristics that auto hub's image have so much noise source, it is adopted SUSAN operator for defect images' edge detection, which is based on the image second partition, and it is achieved good results in edge detection by this method. And then it carried through defect detected for the image, such as, the number, level, center of gravity, area, and circle degree of defects. This can effectively improve the detection efficiency and the accuracy of detection. The experimental results show that the method is feasible in practical applications, and it has strong anti-interference ability, good real-time detection and high efficiency compared with traditional methods.},
journal = {WSEAS Trans. Math.},
month = jul,
pages = {289–298},
numpages = {10},
keywords = {SUSAN operation, auto hub, edge detection, feature description, geometrical features, mask, shape features}
}

@article{10.1016/j.patcog.2006.03.005,
author = {Tsai, Du-Ming and Lin, Ping-Chieh and Lu, Chi-Jie},
title = {An independent component analysis-based filter design for defect detection in low-contrast surface images},
year = {2006},
issue_date = {September, 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {39},
number = {9},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2006.03.005},
doi = {10.1016/j.patcog.2006.03.005},
abstract = {In this paper, we propose a convolution filtering scheme for detecting small defects in low-contrast uniform surface images and, especially, focus on the applications for backlight panels and glass substrates found in liquid crystal display (LCD) manufacturing. A defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may present uneven brightness on the surface. All these make the defect detection in low-contrast surface images extremely difficult. In this study, a constrained independent component analysis (ICA) model is proposed to design an optimal filter with the objective that the convolution filter will generate the most representative source intensity of the background surface without noise. The prior constraint incorporated in the ICA model confines the source values of all training image patches of a defect-free image within a small interval of control limits. In the inspection process, the same control parameter used in the constraint is also applied to set up the thresholds that make impulse responses of all pixels in faultless regions within the control limits, and those in defective regions outside the control limits. A stochastic evolutionary computation algorithm, particle swarm optimization (PSO), is applied to solve for the constrained ICA model. Experimental results have shown that the proposed method can effectively detect small defects in low-contrast backlight panels and LCD glass substrate images.},
journal = {Pattern Recogn.},
month = sep,
pages = {1679–1694},
numpages = {16},
keywords = {Convolution filter, Defect detection, Independent component analysis, Particle swarm optimization, Surface inspection}
}

@inproceedings{10.1007/978-3-540-69566-0_21,
author = {Catal, Cagatay and Diri, Banu},
title = {A Fault Prediction Model with Limited Fault Data to Improve Test Process},
year = {2008},
isbn = {9783540695646},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-69566-0_21},
doi = {10.1007/978-3-540-69566-0_21},
abstract = {Software fault prediction models are used to identify the fault-prone software modules and produce reliable software. Performance of a software fault prediction model is correlated with available software metrics and fault data. In some occasions, there may be few software modules having fault data and therefore, prediction models using only labeled data can not provide accurate results. Semi-supervised learning approaches which benefit from unlabeled and labeled data may be applied in this case. In this paper, we propose an artificial immune system based semi-supervised learning approach. Proposed approach uses a recent semi-supervised algorithm called YATSI (Yet Another Two Stage Idea) and in the first stage of YATSI, AIRS (Artificial Immune Recognition Systems) is applied. In addition, AIRS, RF (Random Forests) classifier, AIRS based YATSI, and RF based YATSI are benchmarked. Experimental results showed that while YATSI algorithm improved the performance of AIRS, it diminished the performance of RF for unbalanced datasets. Furthermore, performance of AIRS based YATSI is comparable with RF which is the best machine learning classifier according to some researches.},
booktitle = {Proceedings of the 9th International Conference on Product-Focused Software Process Improvement},
pages = {244–257},
numpages = {14},
keywords = {AIRS, Semi-supervised learning, YATSI, artificial immune systems, software fault prediction},
location = {Monte Porzio Catone, Italy},
series = {PROFES '08}
}

@inproceedings{10.1109/COMPSAC.2015.66,
author = {Liu, Wangshu and Liu, Shulong and Gu, Qing and Chen, Xiang and Chen, Daoxu},
title = {FECS: A Cluster Based Feature Selection Method for Software Fault Prediction with Noises},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.66},
doi = {10.1109/COMPSAC.2015.66},
abstract = {Noises are inevitable when mining software archives for software fault prediction. Although some researchers have investigated the noise tolerance of existing feature selection methods, few studies focus on proposing new feature selection methods with a certain noise tolerance. To solve this issue, we propose a novel method FECS (FEature Clustering with Selection strategies). This method includes two phases: a feature clustering phase and a feature selection phase with three different heuristic search strategies. During empirical studies, we choose real-world software projects, such as Eclipse and NASA and inject class level and feature level noises simultaneously to imitate noisy datasets. After using classical feature selection methods as the baseline, we confirm the effectiveness of FECS and provide a guideline of using FECS after analyzing the effects of varying either the percentage of selected features or the noise rate.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {276–281},
numpages = {6},
keywords = {Classification Model, Feature Selection, Noise Tolerance, Software Fault Prediction, Software Quality Assurance},
series = {COMPSAC '15}
}

@inproceedings{10.5555/646079.676215,
author = {Karras, D. A. and Mertzios, B. G.},
title = {Improved Defect Detection Using Novel Wavelet Feature Extraction Involving Principal Component Analysis and Neural Network Techniques},
year = {2002},
isbn = {3540001972},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper aims at investigating a novel solution to the problem of defect detection from images, that can find applications in the design of robust quality control systems for the production of furniture, textile, integrated circuits, etc. The suggested solution focuses on detecting defects from their wavelet transformation and vector quantization related properties of the associated wavelet coefficients. More specifically, a novel methodology is investigated for discriminating defects by applying a supervised neural classification technique, employing a Multilayer Perceptron (MLP) trained with the conjugate gradients algorithm, to innovative multidimensional wavelet based feature vectors. These vectors are extracted from the K-Level 2-D DWT (Discrete Wavelet Transform) transformed original image using Vector Quantization techniques and a Principal Component Analysis (PCA) applied to these wavelet domain quantization vectors. The results of the proposed methodology are illustrated in defective textile images where the defective areas are recognized with higher accuracy than the one obtained by applying two rival feature extraction methodologies. The first one of them uses all the wavelet coefficients derived from the k-Level 2-D DWT, while the second one uses only image intensities characteristics. Both rival methods involve the same classification stage as the proposed feature extraction approach. The promising results herein obtained outline the importance of judicious selection and processing of 2-D DWT wavelet coefficients for industrial pattern recognition applications.},
booktitle = {Proceedings of the 15th Australian Joint Conference on Artificial Intelligence: Advances in Artificial Intelligence},
pages = {638–647},
numpages = {10},
keywords = {defect detection, neural networks, wavelets},
series = {AI '02}
}

@article{10.1007/s11277-017-5069-3,
author = {Dong, Feng and Wang, Junfeng and Li, Qi and Xu, Guoai and Zhang, Shaodong},
title = {Defect Prediction in Android Binary Executables Using Deep Neural Network},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5069-3},
doi = {10.1007/s11277-017-5069-3},
abstract = {Software defect prediction locates defective code to help developers improve the security of software. However, existing studies on software defect prediction are mostly limited to the source code. Defect prediction for Android binary executables (called apks) has never been explored in previous studies. In this paper, we propose an explorative study of defect prediction in Android apks. We first propose smali2vec, a new approach to generate features that capture the characteristics of smali (decompiled files of apks) files in apks. Smali2vec extracts both token and semantic features of the defective files in apks and such comprehensive features are needed for building accurate prediction models. Then we leverage deep neural network (DNN), which is one of the most common architecture of deep learning networks, to train and build the defect prediction model in order to achieve accuracy. We apply our defect prediction model to more than 90,000 smali files from 50 Android apks and the results show that our model could achieve an AUC (the area under the receiver operating characteristic curve) of 85.98% and it is capable of predicting defects in apks. Furthermore, the DNN is proved to have a better performance than the traditional shallow machine learning algorithms (e.g., support vector machine and naive bayes) used in previous studies. The model has been used in our practical work and helped locate many defective files in apks.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {2261–2285},
numpages = {25},
keywords = {Android binary executables, Deep neural network, Machine learning, Mobile security, Software defect prediction}
}

@inproceedings{10.1109/ISDEA.2010.90,
author = {Zhoufeng, Liu and Erjin, Gao and Chunlei, Li},
title = {A Novel Fabric Defect Detection Scheme Based on Improved Local Binary Pattern Operator},
year = {2010},
isbn = {9780769542126},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISDEA.2010.90},
doi = {10.1109/ISDEA.2010.90},
abstract = {Local binary pattern (LBP) is one of the features which have been used for texture classification. In this paper, we propose a novel fabric detect detection scheme based on an improve LBP operator. In the training stage, LBP operator is applied on the training sets, and a model is generated according to training using support vector machine (SVM). In the test stage, a test image is divided into the image blocks with size. LBP features are extracted from the image blocks, the SVM model is used to classify the fabric defects. Experimental results demonstrate the efficiency of our proposed algorithm. Because of its simplicity, online implementation is possible as well.},
booktitle = {Proceedings of the 2010 International Conference on Intelligent System Design and Engineering Application - Volume 01},
pages = {116–119},
numpages = {4},
keywords = {LBP, SVM, fabric defect, training sets},
series = {ISDEA '10}
}

@inproceedings{10.5555/1792786.1792790,
author = {Weyuker, Elaine J. and Ostrand, Thomas J.},
title = {What can fault prediction do for you?},
year = {2008},
isbn = {354079123X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {It would obviously be very valuable to know in advance which files in the next release of a large software system are most likely to contain the largest numbers of faults. This is true whether the goal is to validate the system by testing or formally verifying it, or by using some hybrid approach. To accomplish this, we developed negative binomial regression models and used them to predict the expected number of faults in each file of the next release of a system. The predictions are based on code characteristics and fault and modification history data. This paper discusses what we have learned from applying the model to several large industrial systems, each with multiple years of field exposure. It also discusses our success in making accurate predictions and some of the issues that had to be considered.},
booktitle = {Proceedings of the 2nd International Conference on Tests and Proofs},
pages = {18–29},
numpages = {12},
location = {Prato, Italy},
series = {TAP'08}
}

@article{10.1093/ietisy/e91-d.7.1937,
author = {Hadizadeh, Hadi and Baradaran Shokouhi, Shahriar},
title = {Random Texture Defect Detection Using 1-D Hidden Markov Models Based on Local Binary Patterns},
year = {2008},
issue_date = {July 2008},
publisher = {Oxford University Press, Inc.},
address = {USA},
volume = {E91-D},
number = {7},
issn = {0916-8532},
url = {https://doi.org/10.1093/ietisy/e91-d.7.1937},
doi = {10.1093/ietisy/e91-d.7.1937},
abstract = {In this paper a novel method for the purpose of random texture defect detection using a collection of 1-D HMMs is presented. The sound textural content of a sample of training texture images is first encoded by a compressed LBP histogram and then the local patterns of the input training textures are learned, in a multiscale framework, through a series of HMMs according to the LBP codes which belong to each bin of this compressed LBP histogram. The hidden states of these HMMs at different scales are used as a texture descriptor that can model the normal behavior of the local texture units inside the training images. The optimal number of these HMMs (models) is determined in an unsupervised manner as a model selection problem. Finally, at the testing stage, the local patterns of the input test image are first predicted by the trained HMMs and a prediction error is calculated for each pixel position in order to obtain a defect map at each scale. The detection results are then merged by an inter-scale post fusion method for novelty detection. The proposed method is tested with a database of grayscale ceramic tile images.},
journal = {IEICE - Trans. Inf. Syst.},
month = jul,
pages = {1937–1945},
numpages = {9},
keywords = {hidden Markov models, local binary patterns, random texture, texture defect detection}
}

@inproceedings{10.1145/1295074.1295080,
author = {Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {How to measure success of fault prediction models},
year = {2007},
isbn = {9781595937247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1295074.1295080},
doi = {10.1145/1295074.1295080},
abstract = {Many fault prediction models have been proposed in the software engineering literature, and their success evaluated according to various metrics that are widely used in the statistics community. To be able to make meaningful comparisons among the proposed models, it is important that the metrics assess meaningful properties of the predictions. We examine several of the more common metrics, discuss the advantages and disadvantages of each, and illustrate their application to predictions made on a large industrial system. We conclude that the most useful metrics are the percentage of faults that occur in the predicted most fault-prone files, and the Type II misclassification rate.},
booktitle = {Fourth International Workshop on Software Quality Assurance: In Conjunction with the 6th ESEC/FSE Joint Meeting},
pages = {25–30},
numpages = {6},
location = {Dubrovnik, Croatia},
series = {SOQUA '07}
}

@inproceedings{10.1109/SMC.2013.282,
author = {Chandrashekar, Girish and Sahin, Ferat and Cinar, Eyup and Radomski, Aaron and Sarosky, Dan},
title = {In-Vivo Fault Analysis and Real-Time Fault Prediction for RF Generators Using State-of-the-Art Classifiers},
year = {2013},
isbn = {9781479906529},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SMC.2013.282},
doi = {10.1109/SMC.2013.282},
abstract = {In this paper we apply various machine learning techniques for fault detection of RF (Radio Frequency) Power Generators. Fast Fourier Transform features are used in our analysis for all experiments. Radial Basis Function Networks (RBF) is used to build a two class classifier to differentiate between normal and one fault condition. We apply three one class classifiers to model the normal operating conditions. The data is obtained from five different generators of the same model type.},
booktitle = {Proceedings of the 2013 IEEE International Conference on Systems, Man, and Cybernetics},
pages = {1634–1639},
numpages = {6},
keywords = {Fault analysis, Novelty detection, One class classification, RF generators, Radial Basis Functions},
series = {SMC '13}
}

@article{10.1016/j.patcog.2006.05.023,
author = {Sezer, O. G. and Ercil, A. and Ertuzun, A.},
title = {Using perceptual relation of regularity and anisotropy in the texture with independent component model for defect detection},
year = {2007},
issue_date = {January, 2007},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {40},
number = {1},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2006.05.023},
doi = {10.1016/j.patcog.2006.05.023},
abstract = {This paper addresses the raw textile defect detection problem using independent components approach with insights from human vision system. Human vision system is known to have specialized receptive fields that respond to certain type of input signals. Orientation-selective bar cells and grating cells are examples of receptive fields in the primary visual cortex that are selective to periodic- and aperiodic-patterns, respectively. Regularity and anisotropy are two high-level features of texture perception, and we can say that disruption in regularity and/or orientation field of the texture pattern causes structural defects. In our research, we observed that independent components extracted from texture images give bar or grating cell like results depending on the structure of the texture. For those textures having lower regularity and dominant local anisotropy (orientation or directionality), independent components look similar to bar cells whereas textures with high regularity and lower anisotropy have independent components acting like grating cells. Thus, we will expect different bar or grating cell like independent components to respond to defective and defect-free regions. With this motivation, statistical analysis of the structure of the texture by means of independent components and then extraction of the disturbance in the structure can be a promising approach to understand perception of local disorder of texture in human vision system. In this paper, we will show how to detect regions of structural defects in raw textile data that have certain regularity and local orientation characteristics with the application of independent component analysis (ICA), and we will present results on real textile images with detailed discussions.},
journal = {Pattern Recogn.},
month = jan,
pages = {121–133},
numpages = {13},
keywords = {Human vision, Independent component analysis, Receptive fields, Texture defect detection}
}

@article{10.1016/j.eswa.2008.02.066,
author = {Wong, W. K. and Yuen, C. W. M. and Fan, D. D. and Chan, L. K. and Fung, E. H. K.},
title = {Stitching defect detection and classification using wavelet transform and BP neural network},
year = {2009},
issue_date = {March, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {2},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.02.066},
doi = {10.1016/j.eswa.2008.02.066},
abstract = {In the textile and clothing industry, much research has been conducted on fabric defect automatic detection and classification. However, little research has been done to evaluate specifically the stitching defects of a garment. In this study, a stitching detection and classification technique is presented, which combines the improved thresholding method based on the wavelet transform with the back propagation (BP) neural network. The smooth subimage at a certain resolution level using the pyramid wavelet transform was obtained. The study uses the direct thresholding method, which is based on wavelet transform smooth subimages from the use of a quadrant mean filtering method, to attenuate the texture background and preserve the anomalies. The images are then segmented by thresholding processing and noise filtering. Nine characteristic variables based on the spectral measure of the binary images were collected and input into a BP neural network to classify the sample images. The classification results demonstrate that the proposed method can identify five classes of stitching defects effectively. Comparisons of the proposed new direct thresholding method with the direct thresholding method based on the wavelet transform detailed subimages and the automatic band selection for wavelet reconstruction method were made and the experimental results show that the proposed method outperforms the other two approaches.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {3845–3856},
numpages = {12},
keywords = {Defect classification, Image segmentation, Neural network, Quadrant mean filter, Stitching defect, Wavelet transform}
}

@article{10.34768/amcs-2021-0035,
author = {Oz, Muhammed Ali Nur and Kaymakci, Ozgur Turay and Mercimek, Muharrem},
title = {A Nested Autoencoder Approach to Automated Defect Inspection on Textured Surfaces},
year = {2021},
issue_date = {Sep 2021},
publisher = {Walter de Gruyter &amp; Co.},
address = {USA},
volume = {31},
number = {3},
issn = {1641-876X},
url = {https://doi.org/10.34768/amcs-2021-0035},
doi = {10.34768/amcs-2021-0035},
abstract = {In recent years, there has been a highly competitive pressure on industrial production. To keep ahead of the competition, emerging technologies must be developed and incorporated. Automated visual inspection systems, which improve the overall mass production quantity and quality in lines, are crucial. The modifications of the inspection system involve excessive time and money costs. Therefore, these systems should be flexible in terms of fulfilling the changing requirements of high capacity production support. A coherent defect detection model as a primary application to be used in a real-time intelligent visual surface inspection system is proposed in this paper. The method utilizes a new approach consisting of nested autoencoders trained with defect-free and defect injected samples to detect defects. Making use of two nested autoencoders, the proposed approach shows great performance in eliminating defects. The first autoencoder is used essentially for feature extraction and reconstructing the image from these features. The second one is employed to identify and fix defects in the feature code. Defects are detected by thresholding the difference between decoded feature code outputs of the first and the second autoencoder. The proposed model has a 96% detection rate and a relatively good segmentation performance while being able to inspect fabrics driven at high speeds.},
journal = {Int. J. Appl. Math. Comput. Sci.},
month = sep,
pages = {515–523},
numpages = {9},
keywords = {autoencoders, defect detection, automatic visual inspection, deep learning}
}

@article{10.1016/j.jss.2021.111050,
author = {Myllyaho, Lalli and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi and Mikkonen, Tommi and Nurminen, Jukka K.},
title = {Systematic literature review of validation methods for AI systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111050},
doi = {10.1016/j.jss.2021.111050},
journal = {J. Syst. Softw.},
month = nov,
numpages = {22},
keywords = {Artificial intelligence, Machine learning, Validation, Testing, V&amp;V, Systematic literature review}
}

@article{10.4018/jaec.2010070104,
author = {Mohanty, Ramakanta and Ravi, V. and Patra, M. R.},
title = {Application of Machine Learning Techniques to Predict Software Reliability},
year = {2010},
issue_date = {July 2010},
publisher = {IGI Global},
address = {USA},
volume = {1},
number = {3},
issn = {1942-3594},
url = {https://doi.org/10.4018/jaec.2010070104},
doi = {10.4018/jaec.2010070104},
abstract = {In this paper, the authors employed machine learning techniques, specifically, Back propagation trained neural network (BPNN), Group method of data handling (GMDH), Counter propagation neural network (CPNN), Dynamic evolving neuro-fuzzy inference system (DENFIS), Genetic Programming (GP), TreeNet, statistical multiple linear regression (MLR), and multivariate adaptive regression splines (MARS), to accurately forecast software reliability. Their effectiveness is demonstrated on three datasets taken from literature, where performance is compared in terms of normalized root mean square error (NRMSE) obtained in the test set. From rigorous experiments conducted, it was observed that GP outperformed all techniques in all datasets, with GMDH coming a close second.},
journal = {Int. J. Appl. Evol. Comput.},
month = jul,
pages = {70–86},
numpages = {17},
keywords = {Back Propagation Trained Neural Network, Counter Propagation Neural Network, Dynamic Evolving Neuro-Fuzzy Inference System, Genetic Programming, Group Method of Data Handling, Machine Learning Techniques, Software Reliability}
}

@inproceedings{10.1109/ICMV.2009.54,
author = {Kaur, Arashdeep and Sandhu, Parvinder S. and Bra, Amanpreet Singh},
title = {Early Software Fault Prediction Using Real Time Defect Data},
year = {2010},
isbn = {9780769539447},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMV.2009.54},
doi = {10.1109/ICMV.2009.54},
abstract = {Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method, machine learning methods, neural network techniques and clustering techniques. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules by using clustering techniques. This approach has been tested with three real time defect datasets of NASA software projects, JM1, PC1 and CM1. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The results show that when all the prediction techniques are evaluated, the best prediction model is found to be the fusion of requirement and code metric model.},
booktitle = {Proceedings of the 2009 Second International Conference on Machine Vision},
pages = {242–245},
numpages = {4},
series = {ICMV '09}
}

@article{10.1162/evco.2008.16.4.529,
author = {Tirronen, Ville and Neri, Ferrante and K\"{a}rkk\"{a}inen, Tommi and Majava, Kirsi and Rossi, Tuomo},
title = {An enhanced memetic differential evolution in filter design for defect detection in paper production},
year = {2008},
issue_date = {Winter 2008},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {16},
number = {4},
issn = {1063-6560},
url = {https://doi.org/10.1162/evco.2008.16.4.529},
doi = {10.1162/evco.2008.16.4.529},
abstract = {This article proposes an Enhanced Memetic Differential Evolution (EMDE) for designing digital filters which aim at detecting defects of the paper produced during an industrial process. Defect detection is handled by means of two Gabor filters and their design is performed by the EMDE. The EMDE is a novel adaptive evolutionary algorithm which combines the powerful explorative features of Differential Evolution with the exploitative features of three local search algorithms employing different pivot rules and neighborhood generating functions. These local search algorithms are the Hooke Jeeves Algorithm, a Stochastic Local Search, and Simulated Annealing. The local search algorithms are adaptively coordinated by means of a control parameter that measures fitness distribution among individuals of the population and a novel probabilistic scheme. Numerical results confirm that Differential Evolution is an efficient evolutionary framework for the image processing problem under investigation and show that the EMDE performs well. As a matter of fact, the application of the EMDE leads to a design of an efficiently tailored filter. A comparison with various popular metaheuristics proves the effectiveness of the EMDE in terms of convergence speed, stagnation prevention, and capability in detecting solutions having high performance.},
journal = {Evol. Comput.},
month = dec,
pages = {529–555},
numpages = {27},
keywords = {FIR filter, Memetic algorithms, differential evolution, digital filter design, edge detection, multimeme algorithms, paper production}
}

@inbook{10.5555/783013.783020,
author = {Forrest, A. K.},
title = {Surface defect detection on ceramics},
year = {2003},
isbn = {1852335254},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Vision for the Inspection of Natural Products},
pages = {191–213},
numpages = {23}
}

@article{10.1016/j.aei.2016.03.002,
author = {Koch, Christian and Doycheva, Kristina and Kasireddy, Varun and Akinci, Burcu and Fieguth, Paul},
title = {Corrigendum to "A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure" Advanced Engineering Informatics 29(2) (2015) 196-210},
year = {2016},
issue_date = {April 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {30},
number = {2},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2016.03.002},
doi = {10.1016/j.aei.2016.03.002},
abstract = {In the article Advanced Engineering Informatics 29(2) (2015) 196-210 in Section 3.2, there is unattributed use of materials from a prior publication, namely Chaiyasarn (2011). This material has been improperly cited and the authors sincerely apologize for this. This corrigendum contains a revised version of Section 3.2 with corrected attributions and citations.},
journal = {Adv. Eng. Inform.},
month = apr,
pages = {208–210},
numpages = {3},
keywords = {Advanced Engineering Informatics 29(2) (2015) 196-210, Corrigendum}
}

@article{10.1016/j.asoc.2014.03.030,
author = {Chatterjee, Subhashish and Roy, Arunava},
title = {Web software fault prediction under fuzzy environment using MODULO-M multivariate overlapping fuzzy clustering algorithm and newly proposed revised prediction algorithm},
year = {2014},
issue_date = {September, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {22},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.03.030},
doi = {10.1016/j.asoc.2014.03.030},
abstract = {In recent years some research works have been carried out on web software error analysis and reliability predictions. In all these works the web environment has been considered as crisp one, which is not a very realistic assumption. Moreover, web error forecasting remains unworthy for the researchers for quite a long time. Furthermore, among various well known forecasting techniques, fuzzy time series based methods are extensively used, though they are suffering from some serious drawbacks, viz., fixed sized intervals, using some fixed membership values (0, 0.5, and 1) and moreover, the defuzzification process only deals with the factor that is to be predicted. Prompted by these facts, the present authors have proposed a novel multivariate fuzzy forecasting algorithm that is able to remove all the aforementioned drawbacks as also can predict the future occurrences of different web failures (considering the web environment as fuzzy) with better predictive accuracy. Also, the complexity analysis of the proposed algorithm is done to unveil its better run time complexity. Moreover, the comparisons with the other existing frequently used forecasting algorithms were performed to demonstrate its better efficiency and predictive accuracy. Additionally, at the very end, the developed algorithm was applied on the real web failure data of http://www.ismdhanbad.ac.in/, the official website of ISM Dhanbad, India, collected from the corresponding HTTP log files.},
journal = {Appl. Soft Comput.},
month = sep,
pages = {372–396},
numpages = {25},
keywords = {Algorithm, Fuzzy clustering, Fuzzy time series, Server logs, Web errors, Web software reliability}
}

@inproceedings{10.5555/1123321.1123330,
author = {Chen, Wei-Chou and Tseng, Shian-Shyong and Wang, Ching-Yao},
title = {A novel manufacturing defect detection method using data mining approach},
year = {2004},
isbn = {3540220070},
publisher = {Springer Springer Verlag Inc},
abstract = {In recent years, the procedure of manufacturing has become more and more complex. In order to meet high expectation on quality target, quick identification of root cause that makes defects is an essential issue. In this paper, we will refer to a typical algorithm of mining association rules and propose a novel interestingness measurement to provide an effective and accurate solution. First, the manufacturing defect detection problem of analyzing the correlation between combinations of machines and the result of defect is defined. Then, we propose an integrated processing procedure RMI (Root cause Machine Identifier) to discover the root cause in this problem. Finally, the results of experiments show the accuracy and efficiency of RMI are both well with real manufacturing cases.},
booktitle = {Proceedings of the 17th International Conference on Innovations in Applied Artificial Intelligence},
pages = {77–86},
numpages = {10},
location = {Ottawa, Canada},
series = {IEA/AIE'2004}
}

@inproceedings{10.1109/ICPR.2006.427,
author = {Chao, Shin-Min and Tsai, Du-Ming and Tseng, Yan-Hsin and Jhang, Yuan-Ruei},
title = {Defect detection in low-contrast glass substrates using anisotropic diffusion},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.427},
doi = {10.1109/ICPR.2006.427},
abstract = {In this research, we propose an anisotropic diffusion scheme to detect defects in low-contrast surface images and, especially, aim at glass substrates used in TFT-LCDs (Thin Film Transistor-Liquid Crystal Displays). In a sensed glass substrate, the gray levels of defects and background are hardly distinguishable and result in a low-contrast image. Therefore, thresholding and edge detection techniques cannot be applied to detect subtle defects in the glass substrates surface. The proposed diffusion method in this paper can simultaneously carry out the smoothing and sharpening operations. It adaptively triggers the smoothing process in faultless areas to make the background uniform, and performs the sharpening process in defective areas to enhance anomalies. Experimental results from a number of glass substrate samples including backlight panels and LCD glass substrates have shown the efficacy of the proposed diffusion scheme in low-contrast surface inspection.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 01},
pages = {654–657},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.1007/978-3-319-47955-2_19,
author = {Murillo-Morera, Juan and Castro-Herrera, Carlos and Arroyo, Javier and Fuentes-Fern\'{a}ndez, Rub\'{e}n},
title = {An Empirical Validation of Learning Schemes Using an Automated Genetic Defect Prediction Framework},
year = {2016},
isbn = {978-3-319-47954-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-47955-2_19},
doi = {10.1007/978-3-319-47955-2_19},
abstract = {Today, it is common for software projects to collect measurement data through development processes. With these data, defect prediction software can try to estimate the defect proneness of a software module, with the objective of assisting and guiding software practitioners. With timely and accurate defect predictions, practitioners can focus their limited testing resources on higher risk areas. This paper reports a benchmarking study that uses a genetic algorithm that automatically generates and compares different learning schemes (preprocessing + attribute selection + learning algorithms). Performance of the software development defect prediction models (using AUC, Area Under the Curve) was validated using NASA-MDP and PROMISE data sets. Twelve data sets from NASA-MDP (8) and PROMISE (4) projects were analyzed running a -fold cross-validation. We used a genetic algorithm to select the components of the learning schemes automatically, and to evaluate and report those with the best performance. In all, 864 learning schemes were studied. The most common learning schemes were: data preprocessors: Log and CoxBox + attribute selectors: Backward Elimination, BestFirst and LinearForwardSelection + learning algorithms: NaiveBayes, NaiveBayesSimple, SimpleLogistic, MultilayerPerceptron, Logistic, LogitBoost, BayesNet, and OneR. The genetic algorithm reported steady performance and runtime among data sets, according to statistical analysis.},
booktitle = {Advances in Artificial Intelligence - IBERAMIA 2016: 15th Ibero-American Conference on AI, San Jos\'{e}, Costa Rica, November 23-25, 2016, Proceedings},
pages = {222–234},
numpages = {13},
keywords = {Software quality, Fault prediction models, Genetic algorithms, Learning schemes, Learning algorithms, Machine learning},
location = {San Jos\'{e}, Costa Rica}
}

@article{10.5555/1028839.1028841,
author = {Mandriota, C. and Nitti, M. and Ancona, N. and Stella, E. and Distante, A.},
title = {Filter-based feature selection for rail defect detection},
year = {2004},
issue_date = {October 2004},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {4},
issn = {0932-8092},
abstract = {Over the last few years research has been oriented toward developing a machine vision system for locating and identifying, automatically, defects on rails. Rail defects exhibit different properties and are divided into various categories related to the type and position of flaws on the rail. Several kinds of interrelated factors cause rail defects such as type of rail, construction conditions, and speed and/or frequency of trains using the rail. The aim of this paper is to present an experimental comparison among three filtering approaches, based on texture analysis of rail surfaces, to detect the presence/absence of a particular class of surface detects: corrugation.},
journal = {Mach. Vision Appl.},
month = oct,
pages = {179–185},
numpages = {7},
keywords = {K-nearest neighbor classifier, filter bank, rail detection, texture feature}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00061,
author = {Liu, Changlin and Xiao, Xusheng},
title = {ProMal: precise window transition graphs for Android via synergy of program analysis and machine learning},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00061},
doi = {10.1109/ICSE-Companion52605.2021.00061},
abstract = {Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a "tribrid" analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {144–146},
numpages = {3},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1613/jair.1.11688,
author = {Mogadala, Aditya and Kalimuthu, Marimuthu and Klakow, Dietrich},
title = {Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods},
year = {2021},
issue_date = {Sep 2021},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {71},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.11688},
doi = {10.1613/jair.1.11688},
abstract = {Interest in Artificial Intelligence (AI) and its applications has seen unprecedented growth in the last few years. This success can be partly attributed to the advancements made in the sub-fields of AI such as machine learning, computer vision, and natural language processing. Much of the growth in these fields has been made possible with deep learning, a sub-area of machine learning that uses artificial neural networks. This has created significant interest in the integration of vision and language. In this survey, we focus on ten prominent tasks that integrate language and vision by discussing their problem formulation, methods, existing datasets, evaluation measures, and compare the results obtained with corresponding state-of-the-art methods. Our efforts go beyond earlier surveys which are either task-specific or concentrate only on one type of visual content, i.e., image or video. Furthermore, we also provide some potential future directions in this field of research with an anticipation that this survey stimulates innovative thoughts and ideas to address the existing challenges and build new applications.},
journal = {J. Artif. Int. Res.},
month = sep,
pages = {1183–1317},
numpages = {135},
keywords = {natural language, machine learning, computer vision, deep learning}
}

@article{10.1016/j.rti.2004.08.001,
author = {Lam, Edmund Y.},
title = {Robust minimization of lighting variation for real-time defect detection},
year = {2004},
issue_date = {December, 2004},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {10},
number = {6},
issn = {1077-2014},
url = {https://doi.org/10.1016/j.rti.2004.08.001},
doi = {10.1016/j.rti.2004.08.001},
abstract = {In machine vision applications that involve comparing two images, it is necessary to match the capture conditions, which can affect their graylevels. Illumination and exposure are two important causes for lighting variation that we should compensate for in the resulting images. A standard technique for this purpose is to map one of the images to achieve the smallest mean square error (MSE) between the two. However, applications in defect detection for manufacturing processes are more challenging, because the existence of defects would affect the mapping significantly. In this paper, we present a robust method that is more tolerant to defects, and discuss its formulation as a linear programming to achieve fast implementations. This algorithm is also flexible and capable of incorporating further constraints, such as ensuring non-negativity of the pixel values.},
journal = {Real-Time Imaging},
month = dec,
pages = {365–370},
numpages = {6}
}

@article{10.1109/TSMCB.2002.1033176,
author = {Kumar, A. and Pang, G. K.H.},
title = {Defect detection in textured materials using optimized filters},
year = {2002},
issue_date = {October 2002},
publisher = {IEEE Press},
volume = {32},
number = {5},
issn = {1083-4419},
url = {https://doi.org/10.1109/TSMCB.2002.1033176},
doi = {10.1109/TSMCB.2002.1033176},
abstract = {The problem of automated defect detection in textured materials is investigated. A new approach for defect detection using linear FIR filters with optimized energy separation is proposed. The performance of different feature separation criteria with reference to fabric defects has been evaluated. The issues relating to the design of optimal filters for supervised and unsupervised web inspection are addressed. A general web inspection system based on the optimal filters is proposed. The experiments on this new approach have yielded excellent results. The low computational requirement confirms the usefulness of the approach for industrial inspection.},
journal = {Trans. Sys. Man Cyber. Part B},
month = oct,
pages = {553–570},
numpages = {18}
}

@inproceedings{10.5555/839286.841747,
author = {Lambert, G. and Bock, F.},
title = {Wavelet methods for texture defect detection},
year = {1997},
isbn = {0818681837},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In this article we introduce our approach to exploit multiscale wavelet methods for texture defect detection. Several wavelet bases and decomposition algorithms are examined in regard of applicability, parameterization and computational costs. The article points out specific problems in localizing texture defects in multiscale wavelet representations. Besides the fast dyadic wavelet transform we demonstrate the application of the translation invariant a trous algorithm on texture samples. Feature extraction methods are proposed and examples of successful defect classification results are shown.},
booktitle = {Proceedings of the 1997 International Conference on Image Processing (ICIP '97) 3-Volume Set-Volume 3 - Volume 3},
pages = {201},
keywords = {computational costs, decomposition algorithms, defect classification, fast dyadic wavelet transform, feature extraction, image texture, image texture analysis, multiscale wavelet methods, multiscale wavelet representations, texture defect detection, texture defects localisation, translation invariant a trous algorithm, wavelet bases},
series = {ICIP '97}
}

@article{10.1145/2347696.2347709,
author = {Rashid, Ekbal and Patnayak, Srikanta and Bhattacherjee, Vandana},
title = {A survey in the area of machine learning and its application for software quality prediction},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2347696.2347709},
doi = {10.1145/2347696.2347709},
abstract = {This paper explores software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The objective of this research is to apply the various machine learning approaches, such as Case-Based Reasoning and Fuzzy logic, to predict software quality. The system predicts the error after accepting the values of certain parameters of the software. This paper advocates the use of case-based reasoning (i.e., CBR) to build a software quality prediction system with the help of human experts. The prediction is based on analogy. We have used different similarity measures to find the best method that increases reliability. This software is compiled using Turbo C++ 3.0 and hence it is very compact and standalone. It can be readily deployed on any configuration without affecting its performance.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–7},
numpages = {7},
keywords = {CBR, analogy, erffort estimation, function, machine learning, similarity, software quality}
}

@inproceedings{10.5555/1768409.1768496,
author = {Salazar, Addisson and Uni\'{o}, Juan M. and Serrano, Arturo and Gosalbez, Jorge},
title = {Neural networks for defect detection in non-destructive evaluation by sonic signals},
year = {2007},
isbn = {9783540730064},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents an application of neural networks in pattern recognition of defects in sonic signals from non-destructive evaluation by multichannel impact-echo. The problem approached consists in allocating parallelepiped-shape materials in four levels of classifications defining material condition (homogeneous or defective), kind of defects (holes and cracks), defect orientation, and defect dimension. Various signal features as centroid frequency, attenuation and amplitude of the principal frequency are estimated per channel and processed by PCA and feature selection methods to reduce dimensionality. Results for simulations and experiments applying Radial Basis Function, Multilayer Perceptron and Linear Vector Quantization neural networks are presented. Neural networks obtain good performance in classifying several 3D finite element models and specimens of aluminum alloy.},
booktitle = {Proceedings of the 9th International Work Conference on Artificial Neural Networks},
pages = {638–645},
numpages = {8},
location = {San Sebasti\'{a}n, Spain},
series = {IWANN'07}
}

@article{10.1007/s10489-020-01877-z,
author = {Zheng, Xiaoqing and Chen, Jie and Wang, Hongcheng and Zheng, Song and Kong, Yaguang},
title = {A deep learning-based approach for the automated surface inspection of copper clad laminate images},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01877-z},
doi = {10.1007/s10489-020-01877-z},
abstract = {Surface quality inspection and control are extremely important for electronic manufacturing. The use of machine vision technology to automatically detect the defects of products has become an indispensable means for better quality control. A machine vision-based surface quality inspection system is usually composed of two processes: image acquisition and automatic defect detection. In this paper, we propose a deep learning-based approach for the defect detection of Copper Clad Laminate (CCL) images acquired from an industrial CCL production line. In the proposed approach, a new convolutional neural network (CNN) that realizes fast defect detection while maintaining high accuracy is designed. Our proposed approach makes four contributions. First, we introduce the depthwise separable convolution to reduce the calculation time. Second, we improve the squeeze-and-excitation block to improve network performance. Third, we introduce the squeeze-and-expand mechanism to reduce the computation cost. Fourth, we employ a smoother activation function (Mish) to allow improved information flow. The proposed network is compared with the benchmark CNNs (including Inception, ResNet and MobileNet). The experimental results show that compared with the benchmark networks, our proposed network has achieved the best results regarding the accuracy and suboptimal results in terms of the speed compared with the benchmark networks. Therefore, our proposed method has been integrated into an industrial CCL production line as a guideline for online defective product rejection.},
journal = {Applied Intelligence},
month = mar,
pages = {1262–1279},
numpages = {18},
keywords = {Machine vision, Defect detection, Deep learning, Convolutional neural network, Efficient network}
}

@phdthesis{10.5555/2519464,
author = {Pelayo Ramirez, Lourdes},
advisor = {Dick, Scott},
title = {Developing and evaluating methods for mitigating sample selection bias in machine learning},
year = {2011},
isbn = {9780494892763},
publisher = {University of Alberta},
address = {CAN},
abstract = {The imbalanced learning problem occurs in a large number of economic and health domains of great importance; consequently, it has drawn a significant amount of interest from academia, industry, and government funding agencies. Several researchers have used stratification to alleviate this problem; however, it is not clear what stratification strategy is in general more effective: under-sampling, over-sampling or the combination of both. Our first topic evaluates the contribution of stratification strategies in the software defect prediction area. We study the statistical contribution of stratification in the new Mozilla dataset, a new large-scale software defect prediction dataset which includes both object-oriented metrics and a count of defects per module. Our second topic responds to the debate about the contribution of over-sampling, under-sampling and the combination of both with the employment of a full-factorial design experiment using the Analysis of Variance (ANOVA) over six software defect prediction datasets. We extend our research to develop a stratification method to mitigate sample selection bias in function approximation problems. The sample selection bias is present when the training and test instances are drawn from a different distribution, with the imbalance dataset problem considered a particular case of sample selection bias. We extend the well-known SMOTE over-sampling technique to continuous-valued response variables. Our new algorithm proves to be a valuable algorithm helping to increase the performance on function approximation problems and effectively reducing the impact of sample selection bias.},
note = {AAINR89276}
}

@inproceedings{10.5555/2394450.2394484,
author = {Catal, Cagatay and Diri, Banu},
title = {Software fault prediction with object-oriented metrics based artificial immune recognition system},
year = {2007},
isbn = {3540734597},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software testing is a time-consuming and expensive process. Software fault prediction models are used to identify fault-prone classes automatically before system testing. These models can reduce the testing duration, project risks, resource and infrastructure costs. In this study, we propose a novel fault prediction model to improve the testing process. Chidamber-Kemerer Object-Oriented metrics and method-level metrics such as Halstead and McCabe are used as independent metrics in our Artificial Immune Recognition System based model. According to this study, class-level metrics based model which applies AIRS algorithm can be used successfully for fault prediction and its performance is higher than J48 based approach. A fault prediction tool which uses this model can be easily integrated into the testing process.},
booktitle = {Proceedings of the 8th International Conference on Product-Focused Software Process Improvement},
pages = {300–314},
numpages = {15},
location = {Riga, Latvia},
series = {PROFES'07}
}

@inproceedings{10.1145/3501409.3501612,
author = {Qu, Rui and Yuan, Guowu and Liu, Jianchen and Zhou, Hao},
title = {Detection of cigarette appearance defects based on improved SSD model},
year = {2022},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501612},
doi = {10.1145/3501409.3501612},
abstract = {The automatic detection of product defects has been applied to the assembly line production of various industries. With the automation of the production of cigarettes, the detection of appearance defects of cigarettes can no longer be completed manually. Aiming at the current low efficiency of cigarette appearance defect detection, this paper proposes a model based on improved SSD network and pyramid convolution for cigarette appearance defect detection. First, replace the original VGG16 feature extraction network with the ResNet50 network, which has better feature expression capabilities, to improve the performance of small target detection while retaining more shallow semantics; Secondly, replace the original 3\texttimes{}3 convolution in the network and use pyramid convolution to expand the receptive field and extract multi-scale information; At the same time, the original loss function is optimized to solve the problem of unbalanced cigarette appearance defect categories in the data set. The experimental results show that the average accuracy of the algorithm in this paper is 90.26%, which is much higher than the accuracy of the original SSD model and other target detection algorithms.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1148–1153},
numpages = {6},
keywords = {Convolutional Neural Network, Defect Detection, Pyramid Convolution, SSD Network, Target Detection},
location = {Xiamen, China},
series = {EITCE '21}
}

@article{10.1007/s00138-002-0074-1,
author = {Fang, Tong and Jafari, Mohsen A. and Danforth, Stephen C. and Safari, Ahmad},
title = {Signature analysis and defect detection in layered manufacturing of ceramic sensors and actuators},
year = {2003},
issue_date = {December 2003},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {2},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-002-0074-1},
doi = {10.1007/s00138-002-0074-1},
abstract = {This paper presents the concept of a process signature for the use of online signature analysis and defect detection in the layered manufacturing (LM) of ceramic sensors and actuators. To achieve the high quality of parts built by the fused deposition of ceramics (FDC), an online process-monitoring system is implemented to detect the processing defects. Using a process signature extracted from the image of a layer captured by the monitoring system, an ideal image is created that is then compared to the original image to detect and identify the defects. Some results of signature analysis and defect detection for single-material and multi-material parts are also presented.},
journal = {Mach. Vision Appl.},
month = dec,
pages = {63–75},
numpages = {13},
keywords = {defect detection, fused deposition of ceramics, inspection system, layered manufacturing, signature analysis}
}

@article{10.1016/j.ins.2018.05.035,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Novel algorithms for cost-sensitive classification and knowledge discovery in class imbalanced datasets with an application to NASA software defects},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {459},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.05.035},
doi = {10.1016/j.ins.2018.05.035},
journal = {Inf. Sci.},
month = aug,
pages = {53–70},
numpages = {18},
keywords = {Software defect prediction, Class imbalance, Cost-sensitive, Decision forest, Knowledge discovery}
}

@inproceedings{10.5555/648286.756269,
author = {Schael, Marc},
title = {Texture Defect Detection Using Invariant Textural Features},
year = {2001},
isbn = {3540425969},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we propose a novel method for the construction of invariant textural features for grey scale images. The textural features are based on an averaging over the 2D Euclidean transformation group with relational kernels. They are invariant against 2D Euclidean motion and strictly increasing grey scale transformations. Beside other fields of texture analysis applications we consider texture defect detection here. We provide a systematic method how to apply these grey scale features to this task. This will include the localization and classification of the defects. First experiments with real textile texture images taken from the TILDA database show promising results. They are presented in this paper.},
booktitle = {Proceedings of the 23rd DAGM-Symposium on Pattern Recognition},
pages = {17–24},
numpages = {8}
}

@article{10.1145/3483424,
author = {Notaro, Paolo and Cardoso, Jorge and Gerndt, Michael},
title = {A Survey of AIOps Methods for Failure Management},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3483424},
doi = {10.1145/3483424},
abstract = {Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {81},
numpages = {45},
keywords = {AIOps, IT operations and maintenance, failure management, artificial intelligence}
}

@article{10.5555/1375858.1375890,
author = {Nacereddine, N. and Hamami, L. and Ziou, D.},
title = {Thresholding techniques and their performance evaluation for weld defect detection in radiographic testing},
year = {2006},
issue_date = {February 2006},
publisher = {Polish Academy of Sciences},
address = {POL},
volume = {15},
number = {3},
issn = {1230-0535},
abstract = {In non-destructive testing with radiography, a perfect knowledge of the weld defect shape is an essential step to appreciate the quality of the weld and make decision on its acceptance or rejection. Because of the complex nature of the considered images, and in order that the detected defect region represent the real defect as accurately as possible, the choice of the thresholding methods must be made judiciously. In this paper, performance criteria are used to conduct a comparative study of the thresholding methods based on the gray level histogram, the 2D histogram and the locally adaptive approach to weld defect detection in radiographic images.},
journal = {MG&amp;V},
month = jan,
pages = {557–566},
numpages = {10},
keywords = {1D and 2D histogram, locally adaptive approach, performance criteria, radiographic image, thresholding, weld defect}
}

@inproceedings{10.1007/11867661_68,
author = {L\'{o}pez, Fernando and Prats, Jos\'{e} Manuel and Ferrer, Alberto and Valiente, Jos\'{e} Miguel},
title = {Defect detection in random colour textures using the MIA t2 defect maps},
year = {2006},
isbn = {3540448942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11867661_68},
doi = {10.1007/11867661_68},
abstract = {In this paper we present a new approach for the detection of defects in random colour textures. This approach is based on the use of the T2 statistic and it is derived from the MIA strategy (Multivariate Image Analysis) developed in recent years in the field of applied statistics. PCA analysis is used to extract a reference eigenspace from a matrix built by unfolding the RGB raw data of defect-free images. The unfolding is performed compiling colour and spatial information of pixels. New testing images are also unfolded and projected onto the reference eigenspace obtaining a score matrix used to compute the T2 images. These images are converted into defect maps which allow the location of defective pixels. Only very few samples are needed to perform unsupervised training. With regard to literature, the method uses one of the simplest approaches providing low computational costs.},
booktitle = {Proceedings of the Third International Conference on Image Analysis and Recognition - Volume Part II},
pages = {752–763},
numpages = {12},
location = {P\'{o}voa de Varzim, Portugal},
series = {ICIAR'06}
}

@article{10.1007/s00138-002-0069-y,
author = {Tsai, Du-Ming and Tsai, Ya-Hui},
title = {Defect detection in textured surfaces using color ring-projection correlation},
year = {2003},
issue_date = {February 2003},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-002-0069-y},
doi = {10.1007/s00138-002-0069-y},
abstract = {In this paper, we present a correlation scheme that incorporates a color ring-projection representation for the automatic inspection of defects in textured surfaces. The proposed color ring projection transforms a 2-D color image into a 1-D color pattern as a function of radius. For a search window of width W, data dimensionality is reduced from O(W2) in the 2-D image to O(W) in the 1-D ring-projection space. The complexity of computing a correlation function is significantly reduced accordingly. Since the color ring-projection representation is invariant to rotation, the proposed method can be applied for both isotropic and oriented textures at arbitrary orientations. Experiments on regular textured surfaces have shown the efficacy of the proposed method.},
journal = {Mach. Vision Appl.},
month = feb,
pages = {194–200},
numpages = {7},
keywords = {colored textures, correlation, defect detection, ring projection, surface inspection}
}

@inproceedings{10.1007/978-3-030-86230-5_43,
author = {Malaguti, Roney and Louren\c{c}o, Nuno and Silva, Cristov\~{a}o},
title = {A Well Lubricated Machine: A Data Driven Model for Lubricant Oil Conditions},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_43},
doi = {10.1007/978-3-030-86230-5_43},
abstract = {Diagnostic and predictive failure processes based on intelligent lubricant oil analysis are a important of the condition-based maintenance (CBM) approaches for diesel vehicle fleets. Companies are equipping each vehicle in the fleet with a large number of sensors, which allows the collection of vast amounts of data about the current state of each asset. With all this information now allows for the research and development of predictive models to help a fleet manager make informed decisions about the operating condition of the vehicles. This allows companies to accurately identify the state of wear and tear of a piece of equipment or system, making CBM more effective and reliable.In this paper we present a supervised machine learning framework based on the Random Forest Classifier (RF) to determine the operating condition of lubricant oil in diesel engines based on data from 5 different vehicles. We describe the how practitioners should collect and process data, and which features can be engineered to help describe the state of the lubrication system. This data will then be used by a RF model to determine the operational condition of the lubricating oil.The results presented show that the proposed approach is able to successfully identify the oil operating conditions, with the predictive model obtaining a Recall of 97.9%, a Precision of 99.5% and a F1-score of 98.7%. In addition, we evaluate the importance is the inclusion of new engineered features projected from raw data for better determination of the operating condition.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {549–560},
numpages = {12},
keywords = {Condition-based maintenance (CBM), Lubricating oils, Diesel vehicle, Random forest classifier}
}

@article{10.3233/JIFS-202614,
author = {Liu, Hui and He, Boxia and He, Yong and Tao, Xiaotian},
title = {Lightweight detection algorithm for fine-grained surface defects of aerospace seal rings},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202614},
doi = {10.3233/JIFS-202614},
abstract = {The existing seal ring surface defect detection methods for aerospace applications have the problems of low detection efficiency, strong specificity, large fine-grained classification errors, and unstable detection results. Considering these problems, a fine-grained seal ring surface defect detection algorithm for aerospace applications is proposed. Based on analysis of the stacking process of standard convolution, heat maps of original pixels in the receptive field participating in the convolution operation are quantified and generated. According to the generated heat map, the feature extraction optimization method of convolution combinations with different dilation rates is proposed, and an efficient convolution feature extraction network containing three kinds of dilated convolutions is designed. Combined with the O-ring surface defect features, a multiscale defect detection network is designed. Before the head of multiscale classification and position regression, feature fusion tree modules are added to ensure the reuse and compression of the responsive features of different receptive fields on the same scale feature maps. Experimental results show that on the O-rings-3000 testing dataset, the mean condition accuracy of the proposed algorithm reaches 95.10% for 5 types of surface defects of aerospace O-rings. Compared with RefineDet, the mean condition accuracy of the proposed algorithm is only reduced by 1.79%, while the parameters and FLOPs are reduced by 35.29% and 64.90%, respectively. Moreover, the proposed algorithm has good adaptability to image blur and light changes caused by the cutting of imaging hardware, thus saving the cost.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {11423–11440},
numpages = {18},
keywords = {Deep learning, feature extraction network, lightweight algorithm, multiscale classification, surface defect detection, O-rings}
}

@article{10.5555/1283100.1283173,
author = {Qu, Gongyuan and Wood, Sally L. and Teh, Cho},
title = {Wafer defect detection using directional morphological gradient techniques},
year = {2002},
issue_date = {January 2002},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2002},
number = {1},
issn = {1110-8657},
abstract = {Accurate detection and classification of wafer defects constitute an important component of the IC production process because together they can immediately improve the yield and also provide information needed for future process improvements. One class of inspection procedures involves analyzing surface images. Because of the characteristics of the design patterns and the irregular size and shape of the defects, linear processing methods, such as Fourier transform domain filtering or Sobel edge detection, are not as well suited as morphological methods for detecting these defects. In this paper, a newly developed morphological gradient technique using directional components is applied to the detection and isolation of wafer defects. The new methods are computationally efficient and do not rely on a priori knowledge of the specific design pattern to detect particles, scratches, stains, or missing pattern areas. The directional components of the morphological gradient technique allow direction specific edge suppression and reduce the noise sensitivity. Theoretical analysis and several examples are used to demonstrate the performance of the directional morphological gradient methods.},
journal = {EURASIP J. Adv. Signal Process},
month = jan,
pages = {686–703},
numpages = {18},
keywords = {edge detection, edge orientation, morphological gradient, wafer inspection}
}

@inproceedings{10.1109/ACVMOT.2005.115,
author = {Hou, Zhen and Parker, Johne M.},
title = {Texture Defect Detection Using Support Vector Machines with Adaptive Gabor Wavelet Features},
year = {2005},
isbn = {07695227181},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACVMOT.2005.115},
doi = {10.1109/ACVMOT.2005.115},
abstract = {This paper aims at investigating a method for detecting defects on textured surfaces using a Support Vector Machines (SVM) classification approach with Gabor wavelet features. Instead of using all the filters in the Gabor wavelets, an adaptive filter selection scheme is applied to reduce the computational cost on feature extraction while keeping a reasonable detection rate. One-Against-All strategy is adopted to prepare the training data for a binary SVM classifier that is learnt to classify pixels as defective or non-defective. Experimental results on comparison with other multiresolution features and the Learning Vector Quantization (LVQ) classifier demonstrate the effectiveness of the proposed method on defect detection on textured surfaces.},
booktitle = {Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION'05) - Volume 1 - Volume 01},
pages = {275–280},
numpages = {6},
series = {WACV-MOTION '05}
}

@inproceedings{10.1145/1370788.1370794,
author = {Watanabe, Shinya and Kaiya, Haruhiko and Kaijiri, Kenji},
title = {Adapting a fault prediction model to allow inter languagereuse},
year = {2008},
isbn = {9781605580364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370788.1370794},
doi = {10.1145/1370788.1370794},
abstract = {An important step in predicting error prone modules in a project is to construct the prediction model by using training data of that project, but the resulting prediction model depends on the training data. Therefore it is difficult to apply the model to other projects. The training data consists of metrics data and bug data, and these data should be prepared for each project. Metrics data can be computed by using metric tools, but it is not so easy to collect bug data. In this paper, we try to reuse the generated prediction model. By using the metrics and bug data which are computed from C++ and Java projects, we have evaluated the possibility of applying the prediction model, which is generated based on one project, to other projects, and have proposed compensation techniques for applying to other projects. We showed the evaluation result based on open source projects.},
booktitle = {Proceedings of the 4th International Workshop on Predictor Models in Software Engineering},
pages = {19–24},
numpages = {6},
keywords = {error prone, inter language prediction, metrics, open source},
location = {Leipzig, Germany},
series = {PROMISE '08}
}

@inproceedings{10.1145/2600428.2609601,
author = {Cormack, Gordon V. and Grossman, Maura R.},
title = {Evaluation of machine-learning protocols for technology-assisted review in electronic discovery},
year = {2014},
isbn = {9781450322577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600428.2609601},
doi = {10.1145/2600428.2609601},
abstract = {Abstract Using a novel evaluation toolkit that simulates a human reviewer in the loop, we compare the effectiveness of three machine-learning protocols for technology-assisted review as used in document review for discovery in legal proceedings. Our comparison addresses a central question in the deployment of technology-assisted review: Should training documents be selected at random, or should they be selected using one or more non-random methods, such as keyword search or active learning? On eight review tasks -- four derived from the TREC 2009 Legal Track and four derived from actual legal matters -- recall was measured as a function of human review effort. The results show that entirely non-random training methods, in which the initial training documents are selected using a simple keyword search, and subsequent training documents are selected by active learning, require substantially and significantly less human review effort (P&lt;0.01) to achieve any given level of recall, than passive learning, in which the machine-learning algorithm plays no role in the selection of training documents. Among passive-learning methods, significantly less human review effort (P&lt;0.01) is required when keywords are used instead of random sampling to select the initial training documents. Among active-learning methods, continuous active learning with relevance feedback yields generally superior results to simple active learning with uncertainty sampling, while avoiding the vexing issue of "stabilization" -- determining when training is adequate, and therefore may stop.},
booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
pages = {153–162},
numpages = {10},
keywords = {e-discovery, electronic discovery, predictive coding, technology-assisted review},
location = {Gold Coast, Queensland, Australia},
series = {SIGIR '14}
}

@article{10.3233/IDA-205143,
author = {Mao, Yulin and Wang, Shuangxin and Yu, Dingli and Zhao, Juchao},
title = {Automatic image detection of multi-type surface defects on wind turbine blades based on cascade deep learning network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1088-467X},
url = {https://doi.org/10.3233/IDA-205143},
doi = {10.3233/IDA-205143},
abstract = {A safe operation protocol of the wind blades is a critical factor to ensure the stability of a wind turbine. Sensors are most commonly applied for defect detection on wind turbine blades (WTBs). However, due to the high cost and the sensitivity to stochastic noise, computer vision-guided automatic detection remains a challenge for surface defect detection on WTBs in particularly, its accuracy in locating defects is yet to be optimized. In this paper, we developed a visual inspection model that can automatically and precisely classify and locate the surface defects, through the utilization of a deep learning framework based on the Cascade R-CNN. In order to obtain high mean average precision (mAP) according to the characteristics of the dataset, a model named Contextual Aligned-Deformable Cascade R-CNN (CAD Cascade R-CNN) using improved strategies of transfer learning, Deformable Convolution and Deformable RoI Align, as well as context information fusion is proposed and a dataset with surface defects categorized and labeled as crack, breakage and oil pollution is generated. Moreover to alleviate the problem of false detection under a complex background, an improved bisecting k-means is presented during the test process. The adaptability and generalization of the proposed CAD Cascade R-CNN model were validated by each type of defects in dataset and different IoU thresholds, whereas, each of the above improved strategies was verified by gradual ablation experiments. Finally experiments that compared with the baseline Cascade R-CNN, Faster R-CNN and YOLO-v3 demonstrate its superiority over these existing approaches with a maximum of 92.1% mAP.},
journal = {Intell. Data Anal.},
month = jan,
pages = {463–482},
numpages = {20},
keywords = {Deep learning, Cascade R-CNN, surface defect detection wind turbine blades, accuracy}
}

@article{10.1007/s10462-018-9667-6,
author = {Fazel Zarandi, Mohammad Hossein and Sadat Asl, Ali Akbar and Sotudian, Shahabeddin and Castillo, Oscar},
title = {A state of the art review of intelligent scheduling},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-018-9667-6},
doi = {10.1007/s10462-018-9667-6},
abstract = {Intelligent scheduling covers various tools and techniques for successfully and efficiently solving the scheduling problems. In this paper, we provide a survey of intelligent scheduling systems by categorizing them into five major techniques containing fuzzy logic, expert systems, machine learning, stochastic local search optimization algorithms and constraint programming. We also review the application case studies of these techniques.},
journal = {Artif. Intell. Rev.},
month = jan,
pages = {501–593},
numpages = {93},
keywords = {Intelligent scheduling, Fuzzy logic, Expert system, Machine learning, Stochastic local search optimization algorithms, Constraint programming}
}

@inproceedings{10.5555/1193214.1193901,
author = {Tseng, Chun-Chieh and Lai, Mao-Fu and Lee, Por-Song},
title = {Image Inspection System for Defect Detection of Multilayer Ceramic Capacitors},
year = {2006},
isbn = {0769527450},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In today's competitive passive components market, the quality and delivery time of products are the key factors to survive. The traditional quality control process is performed by human experts, which is slow and error prone. In recent years, automatic inspection becomes a mainstream and many works have been published. However, the industry still demands a faster and more accurate inspection method. In this paper, a novel image inspection algorithm to detect defects of Multilayer Ceramic Capacitor (MLCC) is proposed. A testing system is developed and integrated into a production line. In our experiment, the proposed algorithm is proved to be very effective. The inspection system speeds up the testing process 2.5 times as well as increases the yield rate considerably.},
booktitle = {Proceedings of the 2006 International Conference on Intelligent Information Hiding and Multimedia},
pages = {659–662},
numpages = {4},
series = {IIH-MSP '06}
}

@inproceedings{10.5555/1018429.1020955,
author = {Jia, Hongbin and Murphey, Yi Lu and Shi, Jianjun and Chang, Tzyy-Shuh},
title = {An Intelligent Real-time Vision System for Surface Defect Detection},
year = {2004},
isbn = {0769521282},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In recent years, there is an increased need for quality control in the manufacturing sectors. In the steel making, the rolling operation is often the last process that significantly affects the bulk microstructure of the steel. The cost of having defects on rolled steel is high because it takes more than 5000 KW-Hr to produce a ton of steel. Early detection of defects can reduce product damage and manufacturing cost. This paper describes a real-time visual inspection system that uses Support Vector Machine to automatically learn complicated defect patterns. Based on the experimental results generated from over one thousand images, the proposed system is found to be effective in detecting steel surface detects. The speed of the system for feature extraction and defect detection is less than 6 msec per one-megabyte image.},
booktitle = {Proceedings of the Pattern Recognition, 17th International Conference on (ICPR'04) Volume 3 - Volume 03},
pages = {239–242},
numpages = {4},
series = {ICPR '04}
}

@inproceedings{10.1109/ICPR.2006.709,
author = {Tsai, Du-Ming and Tseng, Yan-Hsin and Chao, Shin-Min and Yen, Chao-Hsuan},
title = {Independent component analysis based filter design for defect detection in low-contrast textured images},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.709},
doi = {10.1109/ICPR.2006.709},
abstract = {In this paper, we propose a convolution filtering scheme for detecting defects in low-contrast textured surface images and, especially, focus on the application for glass substrates in Liquid Crystal Display (LCD) manufacturing. A defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may present uneven brightness on the surface. All these make the defect detection in lowcontrast surface images extremely difficult. In this study, a constrained ICA (independent component analysis) model is proposed to design an optimal filter with the objective that the convolution filter will generate the most representative source intensity of the background surface without noise. The prior constraint incorporated in the ICA model confines the source values of all training image patches of a defect-free image within a small interval of control limits. In the inspection process, the same control parameter used in the constraint is also applied to set up the thresholds that make impulse responses of all pixels in faultless regions within the control limits, and those in defective regions outside the control limits. A stochastic evolutionary computation algorithm, particle swarm optimization (PSO), is applied to solve for the constrained ICA model. Experimental results have shown that the proposed method can effectively detect defects in textured LCD glass substrate images.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 02},
pages = {231–234},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.1007/978-3-030-95398-0_8,
author = {J\"{o}chl, Robert and Uhl, Andreas},
title = {Effects of&nbsp;Image Compression on&nbsp;Image Age Approximation},
year = {2021},
isbn = {978-3-030-95397-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-95398-0_8},
doi = {10.1007/978-3-030-95398-0_8},
abstract = {In-field sensor defects are at the core of temporal image forensics, as a temporal order among pieces of evidence can be established by knowing their onset time. A characteristic of these single pixel defects is that they appear as point-like image noise. Since sensor defects exhibit noise-like properties, they are vulnerable to image compression. For this reason, it is important to evaluate the effect of image compression on the defect based image age approximation techniques available. In this paper, we assess the robustness of these age approximation methods with respect to four different compression techniques (i.e., ‘JPEG’, ‘JPEG 2000’, ‘JPEG XR’ and ‘Better Portable Graphics’) and different compression strengths. Since the approximation techniques considered require the defect locations to be known in advance, we assess the effect of image compression on the defect detection methods proposed in the context of image age approximation.},
booktitle = {Digital Forensics and Watermarking: 20th International Workshop, IWDW 2021, Beijing, China, November 20–22, 2021, Revised Selected Papers},
pages = {102–116},
numpages = {15},
keywords = {Image compression, Image age approximation, In-field sensor defects, Defect detection, Image forensics},
location = {Beijing, China}
}

@article{10.1016/j.compag.2005.10.002,
author = {Ariana, Diwan and Guyer, Daniel E. and Shrestha, Bim},
title = {Integrating multispectral reflectance and fluorescence imaging for defect detection on apples},
year = {2006},
issue_date = {February, 2006},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {2},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2005.10.002},
doi = {10.1016/j.compag.2005.10.002},
abstract = {This research investigated multispectral imaging to detect various defects on apples. An integrated approach using multispectral imaging in reflectance and fluorescence modes was used to acquire images of three varieties of apples. Eighteen images from a combination of filters ranging from the visible region through the NIR region and from three different imaging modes (reflectance, visible light induced fluorescence, and UV induced fluorescence) were acquired for each apple as a basis for pixel-level classification into normal or disorder tissue. Artificial neural network classification models were developed for two classification schemes, a two-class and a multiple-class. In the two-class scheme, pixels were categorized into normal or disordered tissue, whereas in the multiple-class scheme, pixels were categorized into normal, bitter pit, black rot, decay, soft scald, and superficial scald tissues. A 10-fold cross validation technique was used to assess the performance of the neural network models. The integrated imaging model of reflectance and fluorescence was effective on Honeycrisp variety, whereas single imaging models of reflectance or fluorescence was effective on Redcort and Red Delicious. The technique is promising for accurate recognition of different types of disorder on apple.},
journal = {Comput. Electron. Agric.},
month = feb,
pages = {148–161},
numpages = {14},
keywords = {Apples, Artificial neural network, Fluorescence, Imaging, Multispectral, Reflectance}
}

@inproceedings{10.1109/PROMISE.2007.14,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Using Developer Information as a Factor for Fault Prediction},
year = {2007},
isbn = {0769529542},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/PROMISE.2007.14},
doi = {10.1109/PROMISE.2007.14},
abstract = {We have been investigating different prediction models to identify which files of a large multi-release industrial software system are most likely to contain the largest numbers of faults in the next release. To make predictions we considered a number of different file characteristics and change information about the files, and have built fully-automatable models that do not require that the user have any statistical expertise. We now consider the effect of adding developer information as a prediction factor and assess the extent to which this affects the quality of the predictions.},
booktitle = {Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
pages = {8},
series = {PROMISE '07}
}

@inproceedings{10.1007/978-3-030-63830-6_12,
author = {Lopes, Vasco and Alexandre, Lu\'{\i}s A.},
title = {Auto-Classifier: A Robust Defect Detector Based on an AutoML Head},
year = {2020},
isbn = {978-3-030-63829-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63830-6_12},
doi = {10.1007/978-3-030-63830-6_12},
abstract = {The dominant approach for surface defect detection is the use of hand-crafted feature-based methods. However, this falls short when conditions vary that affect extracted images. So, in this paper, we sought to determine how well several state-of-the-art Convolutional Neural Networks perform in the task of surface defect detection. Moreover, we propose two methods: CNN-Fusion, that fuses the prediction of all the networks into a final one, and Auto-Classifier, which is a novel proposal that improves a Convolutional Neural Network by modifying its classification component using AutoML. We carried out experiments to evaluate the proposed methods in the task of surface defect detection using different datasets from DAGM2007. We show that the use of Convolutional Neural Networks achieves better results than traditional methods, and also, that Auto-Classifier out-performs all other methods, by achieving 100% accuracy and 100% AUC results throughout all the datasets.},
booktitle = {Neural Information Processing: 27th International Conference, ICONIP 2020, Bangkok, Thailand, November 23–27, 2020, Proceedings, Part I},
pages = {137–149},
numpages = {13},
keywords = {Defect detection, CNNs, Deep learning, AutoML},
location = {Bangkok, Thailand}
}

@inproceedings{10.1109/MMIT.2010.11,
author = {Jin, Cong and Dong, En-Mei and Qin, Li-Na},
title = {Software Fault Prediction Model Based on Adaptive Dynamical and Median Particle Swarm Optimization},
year = {2010},
isbn = {9780769540085},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MMIT.2010.11},
doi = {10.1109/MMIT.2010.11},
abstract = {Software quality prediction can play a role of importance in software management, and thus in improve the quality of software systems. By mining software with data mining technique, predictive models can be induced that software managers the insights they need to tackle these quality problems in an efficient way. This paper deals with the adaptive dynamic and median particle swarm optimization (ADMPSO) based on the PSO classification technique. ADMPSO can act as a valid data mining technique to predict erroneous software modules. The predictive model in this paper extracts the relationship rules of software quality and metrics. Information entropy approach is applied to simplify the extraction rule set. The empirical result shows that this method set of rules can be streamlined and the forecast accuracy can be improved.},
booktitle = {Proceedings of the 2010 Second International Conference on MultiMedia and Information Technology - Volume 01},
pages = {44–47},
numpages = {4},
series = {MMIT '10}
}

@inproceedings{10.1007/978-3-030-78612-0_5,
author = {Xu, Haitao and Duan, Ruifeng and Yang, Shengsong and Guo, Lei},
title = {An Empirical Study on Data Sampling for Just-in-Time Defect Prediction},
year = {2021},
isbn = {978-3-030-78611-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78612-0_5},
doi = {10.1007/978-3-030-78612-0_5},
abstract = {In this paper, the impact of Data Sampling on Just-in-Time defect prediction is explored. We find that there is a significant negative relationship between the class imbalance ratio of the dataset and the performance of the instant software defect prediction model. Secondly although most software defect data are not as unbalanced as expected, a moderate degree of imbalance is sufficient to affect the performance of traditional learning. This means that if the training data for immediate software defects show moderate or more severe imbalances, one need not expect good defect prediction performance and the data sampling approach to balancing the training data can improve the performance of the model. Finally, the empirical approach shows that although the under-sampling method slightly improves model performance, the different sampling methods do not have a substantial impact on the evaluation of immediate software defect prediction models.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part II},
pages = {54–69},
numpages = {16},
keywords = {Data sampling, Just-in-time defect, Empirical study},
location = {Dublin, Ireland}
}

@phdthesis{10.5555/269717,
author = {Zhong, Yuan},
title = {Image segmentation for defect detection on veneer surfaces},
year = {1996},
publisher = {Oregon State University},
address = {USA},
abstract = {Machine vision is widely used in scientific areas and non-wood using industries, but the extreme variability of wood has limited its adoption by forest products industries. However, it is now becoming a key factor in further automation of the forest products industry. As a very important part of machine vision, developing image segmentation algorithms that can be used for wood products is an ambitious undertaking. The focus of this research was to adapt existing and develop some new segmentation algorithms which could be used to detect defects on veneer surfaces. Nine algorithms covering three segmentation technique categories were explored. Three existing edge detection algorithms were modified for use on veneer images, and four existing thresholding algorithms were adapted in both global and local versions. Two new region extraction algorithms were developed specifically for defect detection on veneer surfaces.The performances of these nine algorithms were tested and compared under the combinations of two camera resolutions (5-bit and 8-bit), three color spaces (RGB, Lab, and gray-scale), and seven surface features (clear wood, blue stain, loose knot, pitch pocket, pitch streak, tight knot, and wane). Ten sample images for each of seven surface features on Douglas-fir veneer (Pseudotsuga menziesii) were used. Ten measures were proposed for performance evaluation. A multi-factor factorial ANOVA was used in the performance tests and comparisons.The best combinations of camera resolution and color space for each of the algorithms were determined. The 5-bit and 8-bit camera resolutions were not significantly different for the three edge detection and two region extraction algorithms, but the 8-bit camera resolution was better for all but one of the thresholding algorithms. That exception was the global Otsu thresholding algorithm, for which the 5-bit camera resolution was better. The RGB color space was the best for all algorithms. Overall, the two region extraction algorithms were the best. Under the best combination of factors, those two algorithms provided the highest defect detection accuracies of 91% for pitch streak samples and over 95% for loose knot, tight knot, and pitch pocket samples. These results were accomplished while still providing clear wood accuracies of over 95%. The one performance exception was blue stain, for which no satisfactory algorithm was found.},
note = {UMI Order No. GAX95-35991}
}

@article{10.1016/j.jss.2009.06.036,
author = {Binkley, David and Feild, Henry and Lawrie, Dawn and Pighin, Maurizio},
title = {Increasing diversity: Natural language measures for software fault prediction},
year = {2009},
issue_date = {November, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {11},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.036},
doi = {10.1016/j.jss.2009.06.036},
abstract = {While challenging, the ability to predict faulty modules of a program is valuable to a software project because it can reduce the cost of software development, as well as software maintenance and evolution. Three language-processing based measures are introduced and applied to the problem of fault prediction. The first measure is based on the usage of natural language in a program's identifiers. The second measure concerns the conciseness and consistency of identifiers. The third measure, referred to as the QALP score, makes use of techniques from information retrieval to judge software quality. The QALP score has been shown to correlate with human judgments of software quality. Two case studies consider the language processing measures applicability to fault prediction using two programs (one open source, one proprietary). Linear mixed-effects regression models are used to identify relationships between defects and the measures. Results, while complex, show that language processing measures improve fault prediction, especially when used in combination. Overall, the models explain one-third and two-thirds of the faults in the two case studies. Consistent with other uses of language processing, the value of the three measures increases with the size of the program module considered.},
journal = {J. Syst. Softw.},
month = nov,
pages = {1793–1803},
numpages = {11},
keywords = {Code comprehension, Empirical software engineering, Fault prediction, Information retrieval, Linear regression models}
}

@inproceedings{10.5555/829537.831857,
author = {Li, Yueming and Liao, T. Warren},
title = {Weld Defect Detection Based on Gaussian Curve},
year = {1996},
isbn = {0818673524},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We develop a weld defect detection methodology based on the assumption that a line profile of a defect-less weld image can be approximated by a Gaussian distribution curve. The line profile variations of a weld image caused by defects are classified into three defect patterns, defect-peaks, defect-troughs and defect-slant-concaves. Dark image enhancement is used to control the level of the noises which otherwise would have become worse in normalization. Two kinds of B-spline curve fittings, tight fitting and loose fitting, are performed to facilitate defect identification. The purpose of tight fitting is to reduce the noises but keep the profile variations caused by defects, while that of loose fitting is to restore the bell shape as if no defects would have occurred. The roughness of a line image profile is defined and used to estimate the smoothing factor used for fitting the line profile. The results of preliminary tests showed that more than 90% of defects are successfully detected.},
booktitle = {Proceedings of the 28th Southeastern Symposium on System Theory (SSST '96)},
pages = {227},
keywords = {feature identification, image processing, noise reduction, nondestructive testing, weld defect detection},
series = {SSST '96}
}

@inproceedings{10.5555/648287.756369,
author = {Eisele, Heiko and Hamprecht, Fred A.},
title = {A New Approach for Defect Detection in X-ray CT Images},
year = {2002},
isbn = {354044209X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We introduce a novel method to automatically evaluate X-ray computed tomography (CT) images for the purpose of detecting material defects by evaluating the significance of features extracted by first order derivative filters. We estimate the noise of the original image and compute the noise of the filtered image via error propagation. The significance of these features can then be evaluated based on the signal-to-noise ratio in the filtered image. The major benefit of that procedure is, that a sample-independent threshold on the signal-to-noise ratio can be chosen. The results are demonstrated on parts drawn from an industrial manufacturing line.},
booktitle = {Proceedings of the 24th DAGM Symposium on Pattern Recognition},
pages = {345–352},
numpages = {8}
}

@article{10.1007/s10845-021-01765-4,
author = {Escobar, Carlos A. and McGovern, Megan E. and Morales-Menendez, Ruben},
title = {Quality 4.0: a review of big data challenges in manufacturing},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {8},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01765-4},
doi = {10.1007/s10845-021-01765-4},
abstract = {Industrial big data and artificial intelligence are propelling a new era of manufacturing, smart manufacturing. Although these driving technologies have the capacity to advance the state of the art in manufacturing, it is not trivial to do so. Current benchmarks of quality, conformance, productivity, and innovation in industrial manufacturing have set a very high bar for machine learning algorithms. A new concept has recently appeared to address this challenge: Quality 4.0. This name was derived from the pursuit of performance excellence during these times of potentially disruptive digital transformation. The hype surrounding artificial intelligence has influenced many quality leaders take an interest in deploying a Quality 4.0 initiative. According to recent surveys, however, 80–87% of the big data projects never generate a sustainable solution. Moreover, surveys have indicated that most quality leaders do not have a clear vision about how to create value of out these technologies. In this manuscript, the process monitoring for quality initiative, Quality 4.0, is reviewed. Then four relevant issues are identified (paradigm, project selection, process redesign and relearning problems) that must be understood and addressed for successful implementation. Based on this study, a novel 7-step problem solving strategy is introduced. The proposed strategy increases the likelihood of successfully deploying this Quality 4.0 initiative.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {2319–2334},
numpages = {16},
keywords = {Quality 4.0, Quality control, Manufacturing systems, Artificial intelligence, Big data}
}

@inproceedings{10.1145/2915970.2915979,
author = {Petri\'{c}, Jean},
title = {Using different characteristics of machine learners to identify different defect families},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2915979},
doi = {10.1145/2915970.2915979},
abstract = {Background: Software defect prediction has been an active area of research for the last few decades. Many models have been developed with aim to find locations in code likely to contain defects. As of yet, these prediction models are of limited use and rarely used in the software industry.Problem: Current modelling techniques are too coarse grained and fail in finding some defects. Most of the prediction models do not look for targeted defect characteristics, but rather treat them as a black box and homogeneous. No study has investigated in greater detail how well certain defect characteristics work with different prediction modelling techniques.Methodology: This PhD will address three major tasks. First, the relation among software defects, prediction models and static code metrics will be analysed. Second, the possibility of a mapping function between prediction models and defect characteristics shall be investigated. Third, an optimised ensemble model that searches for targeted defects will be developed.Contribution: A few contributions will yield from this work. Characteristics of defects will be identified, allowing other researchers to build on this work to produce more efficient prediction models in future. New modelling techniques that better suit state-of-the-art knowledge in defect prediction shall be designed. Such prediction models should be transformed in a tool that can be used by our industrial collaborator in the real industry environment.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {5},
numpages = {4},
keywords = {machine learning, prediction modeling, software defect prediction},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1145/3277103.3277131,
author = {Castro, Alberto and Richart, Mat\'{\i}as and Baliosian, Javier and Gramp\'{\i}n, Eduardo},
title = {Opportunities for AI/ML in Telecommunications Networks},
year = {2018},
isbn = {9781450359221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277103.3277131},
doi = {10.1145/3277103.3277131},
abstract = {While it is true that we are in the middle of one of the Artificial Intelligence hypes, it is also true that the combination of unprecedented computation-power and data availability with new variations of well seasoned Machine Learning algorithms is dramatically changing the optimization strategies for large ICT industries. Especially, the telecommunications industry has always had to deal with complex systems, stochastic contexts, combinatorial problems, and hard to predict users; Machine Learning-aided optimization was just waiting there to be used by telecoms. In this paper, we introduce some basic Machine Learning concepts, and discuss how it can be used in the context of telecommunications networks, particularly in optical and wireless networks.},
booktitle = {Proceedings of the 10th Latin America Networking Conference},
pages = {89–95},
numpages = {7},
keywords = {Machine Learning, Optical Networks, Wireless Networks},
location = {S\~{a}o Paulo, Brazil},
series = {LANC '18}
}

@inproceedings{10.1007/978-3-030-89370-5_24,
author = {Xu, Lu and Zhong, Xian and Liu, Wenxuan and Zhao, Shilei and Yang, Zhengwei and Zhong, Luo},
title = {Subspace Enhancement and Colorization Network for Infrared Video Action Recognition},
year = {2021},
isbn = {978-3-030-89369-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89370-5_24},
doi = {10.1007/978-3-030-89370-5_24},
abstract = {Human action recognition is an essential area of research in the field of computer vision. However, existing methods ignore the essence of infrared image spectral imaging. Compared with the visible modality with all three channels, the infrared modality with approximate single-channel pays more attention to the lightness contrast and loses the channel information. Therefore, we explore channel duplication and tend to investigate more appropriate feature presentations. We propose a subspace enhancement and colorization network (S2ECNet) to recognize infrared video action recognition. Specifically, we apply the subspace enhancement (S2E) module to promote edge contour extraction with subspace. Meanwhile, a subspace colorization (S2C) module is utilized for better completing missing semantic information. What is more, the optical flow provides effective supplements for temporal information. Experiments conducted on the infrared action recognition dataset InfAR demonstrates the competitiveness of the proposed method compared with the state-of-the-arts.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part III},
pages = {321–336},
numpages = {16},
keywords = {Infrared video action recognition, Subspace enhancement, Subspace colorization, Optical flow, Feature fusion},
location = {Hanoi, Vietnam}
}

@inproceedings{10.1007/978-3-030-58545-7_45,
author = {Li, Junbing and Zhang, Changqing and Zhu, Pengfei and Wu, Baoyuan and Chen, Lei and Hu, Qinghua},
title = {SPL-MLL: Selecting Predictable Landmarks for Multi-label Learning},
year = {2020},
isbn = {978-3-030-58544-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58545-7_45},
doi = {10.1007/978-3-030-58545-7_45},
abstract = {Although significant progress achieved, multi-label classification is still challenging due to the complexity of correlations among different labels. Furthermore, modeling the relationships between input and some (dull) classes further increases the difficulty of accurately predicting all possible labels. In this work, we propose to select a small subset of labels as landmarks which are easy to predict according to input (predictable) and can well recover the other possible labels (representative). Different from existing methods which separate the landmark selection and landmark prediction in the 2-step manner, the proposed algorithm, termed Selecting Predictable Landmarks for Multi-Label Learning (SPL-MLL), jointly conducts landmark selection, landmark prediction, and label recovery in a unified framework, to ensure both the representativeness and predictableness for selected landmarks. We employ the Alternating Direction Method (ADM) to solve our problem. Empirical studies on real-world datasets show that our method achieves superior classification performance over other state-of-the-art methods.},
booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part IX},
pages = {783–799},
numpages = {17},
keywords = {Multi-label learning, Predictable landmarks, A unified framework},
location = {Glasgow, United Kingdom}
}

@article{10.1007/s00138-020-01142-w,
author = {Saeedi, Jamal and Dotta, Matteo and Galli, Andrea and Nasciuti, Adriano and Maradia, Umang and Boccadoro, Marco and Gambardella, Luca Maria and Giusti, Alessandro},
title = {Measurement and inspection of electrical discharge machined steel surfaces using deep neural networks},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-020-01142-w},
doi = {10.1007/s00138-020-01142-w},
abstract = {We propose an industrial measurement and inspection system for steel workpieces eroded by electrical discharge machining, which uses deep neural networks for surface roughness estimation and defect detection. Specifically, a convolutional neural network (CNN) is used as a regressor in order to obtain steel surface roughness and a CNN based on spatial pooling pyramid is applied for defect classification.
 In addition, a new method for the region of interest selection based on morphological reconstruction and mean shift filtering is proposed for defect detection and localization. The regressor and classifier based on deep neural networks proposed here outperform state-of-the-art methods using handcrafted feature extraction. We achieve a mean absolute percentage error of 7.32% on roughness estimation; on defect detection, our approach yields an accuracy of 97.26% and an area under the ROC curve metric of 99.09%.},
journal = {Mach. Vision Appl.},
month = jan,
numpages = {15},
keywords = {Electrical discharge machining, Convolutional neural networks, Spatial pooling pyramid, Morphological reconstruction, Mean shift filtering}
}

@inproceedings{10.5555/1973598.1973711,
author = {Furferi, Rocco and Governi, Lapo},
title = {Machine vision tool for real-time defect detection and classification on circular knitting machines by using statistical parameters and radon transform},
year = {2006},
isbn = {9608457432},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {This work presents a new highly automated artificial vision inspection (AVI) tool for real-time defect detection and classification on circular knitting machines based on the combination of statistical analysis, Image Processing and Radon Transform. The tool (software + hardware) is directly attached to a circular knitting machine and the inspection is performed on-line. The automatic inspection allows the detection and classification of the most frequently occurring types of defects on knitted fabrics, which are significant for purposes of quality control and fabric grading. The reliability of the detection tool is about 93% (defect detected vs. effectively existing defects).},
booktitle = {Proceedings of the 5th WSEAS International Conference on Applied Computer Science},
pages = {590–595},
numpages = {6},
keywords = {image processing, knitting machines, kurtosis, radon transform, real time, skewness},
location = {Hangzhou, China},
series = {ACOS'06}
}

@article{10.1007/s11219-015-9287-1,
author = {Ryu, Duksan and Jang, Jong-In and Baik, Jongmoon},
title = {A transfer cost-sensitive boosting approach for cross-project defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9287-1},
doi = {10.1007/s11219-015-9287-1},
abstract = {Software defect prediction has been regarded as one of the crucial tasks to improve software quality by effectively allocating valuable resources to fault-prone modules. It is necessary to have a sufficient set of historical data for building a predictor. Without a set of sufficient historical data within a company, cross-project defect prediction (CPDP) can be employed where data from other companies are used to build predictors. In such cases, a transfer learning technique, which extracts common knowledge from source projects and transfers it to a target project, can be used to enhance the prediction performance. There exists the class imbalance problem, which causes difficulties for the learner to predict defects. The main impacts of imbalanced data under cross-project settings have not been investigated in depth. We propose a transfer cost-sensitive boosting method that considers both knowledge transfer and class imbalance for CPDP when given a small amount of labeled target data. The proposed approach performs boosting that assigns weights to the training instances with consideration of both distributional characteristics and the class imbalance. Through comparative experiments with the transfer learning and the class imbalance learning techniques, we show that the proposed model provides significantly higher defect detection accuracy while retaining better overall performance. As a result, a combination of transfer learning and class imbalance learning is highly effective for improving the prediction performance under cross-project settings. The proposed approach will help to design an effective prediction model for CPDP. The improved defect prediction performance could help to direct software quality assurance activities and reduce costs. Consequently, the quality of software can be managed effectively.},
journal = {Software Quality Journal},
month = mar,
pages = {235–272},
numpages = {38},
keywords = {Boosting, Class imbalance, Cost-sensitive learning, Cross-project defect prediction, Software defect prediction, Transfer learning}
}

@article{10.1006/rtim.1998.0145,
author = {Hajimowlana, S.Hossain and Muscedere, Roberto and Jullien, Graham A. and Roberts, James W.},
title = {An In-Camera Data Stream Processing System for Defect Detection in Web Inspection Tasks},
year = {1999},
issue_date = {Feb. 1999},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {5},
number = {1},
issn = {1077-2014},
url = {https://doi.org/10.1006/rtim.1998.0145},
doi = {10.1006/rtim.1998.0145},
abstract = {One of the aims of industrial machine vision is to develop computer and electronic systems to replace human vision in quality control of industrial production. Traditionally these systems consist of a line scan camera, host computer, frame grabber and one or more dedicated processing boards. In this paper we discuss the development of a new integrated design environment, developed for real-time defect detection, that eliminates the need for an external frame grabber and other associated host computer peripheral systems. The processing board contains a reconfigurable field programmable gate array FPGA inside a DALSA CCD camera. The FPGA is directly connected to the video data-stream and outputs data to a low bandwidth output bus. The system is targeted for web inspection but has the potential for broader application areas. We describe and show test results of the in-camera prototype system board and discuss some of the algorithms currently simulated and implemented for web inspection applications.},
journal = {Real-Time Imaging},
month = feb,
pages = {23–34},
numpages = {12}
}

@article{10.1016/j.compeleceng.2019.04.011,
author = {G., Geetharamani and J., Arun Pandian},
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
doi = {10.1016/j.compeleceng.2019.04.011},
journal = {Comput. Electr. Eng.},
month = jun,
pages = {323–338},
numpages = {16},
keywords = {Artificial intelligence, Deep convolutional neural networks, Deep learning, Dropout, Image augmentation, Leaf diseases identification, Machine learning, Mini batch, Training epoch, Transfer learning}
}

@inproceedings{10.1145/3468264.3477221,
author = {Winkler, Jordan and Agarwal, Abhimanyu and Tung, Caleb and Ugalde, Dario Rios and Jung, Young Jin and Davis, James C.},
title = {A replication of ‘DeepBugs: a learning approach to name-based bug detection’},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3477221},
doi = {10.1145/3468264.3477221},
abstract = {We replicated the main result of DeepBugs, a bug detection algorithm for name-based bugs. The original authors evaluated it in three contexts: swapped-argument bugs, wrong binary operator,and wrong binary operator operands. We followed the algorithm and replicated the results for swapped-argument bugs. Our replication used independent implementations of the major components: training set generation, token vectorization, and neural network data pipeline, model, and loss function. Using the same dataset and the same testing process, we report comparable performance: within 2% of the accuracy reported by Pradel and Sen.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1604},
numpages = {1},
keywords = {Defect detection, deep learning, machine learning, replication},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1007/978-3-030-27455-9_1,
author = {Sarro, Federica},
title = {Search-Based Predictive Modelling for Software Engineering: How Far Have We Gone?},
year = {2019},
isbn = {978-3-030-27454-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27455-9_1},
doi = {10.1007/978-3-030-27455-9_1},
abstract = {In this keynote I introduce the use of Predictive Analytics for Software Engineering (SE) and then focus on the use of search-based heuristics to tackle long-standing SE prediction problems including (but not limited to) software development effort estimation and software defect prediction. I review recent research in Search-Based Predictive Modelling for SE in order to assess the maturity of the field and point out promising research directions. I conclude my keynote by discussing best practices for a rigorous and realistic empirical evaluation of search-based predictive models, a condicio sine qua non to facilitate the adoption of prediction models in software industry practices.},
booktitle = {Search-Based Software Engineering: 11th International Symposium, SSBSE 2019, Tallinn, Estonia, August 31 – September 1, 2019, Proceedings},
pages = {3–7},
numpages = {5},
keywords = {Predictive analytics, Predictive modelling, Search-based software engineering, Machine learning, Software analytics},
location = {Tallinn, Estonia}
}

@article{10.1007/s10515-013-0129-8,
author = {Bowes, David and Hall, Tracy and Gray, David},
title = {DConfusion: a technique to allow cross study performance evaluation of fault prediction studies},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-013-0129-8},
doi = {10.1007/s10515-013-0129-8},
abstract = {There are many hundreds of fault prediction models published in the literature. The predictive performance of these models is often reported using a variety of different measures. Most performance measures are not directly comparable. This lack of comparability means that it is often difficult to evaluate the performance of one model against another. Our aim is to present an approach that allows other researchers and practitioners to transform many performance measures back into a confusion matrix. Once performance is expressed in a confusion matrix alternative preferred performance measures can then be derived. Our approach has enabled us to compare the performance of 600 models published in 42 studies. We demonstrate the application of our approach on 8 case studies, and discuss the advantages and implications of doing this.},
journal = {Automated Software Engg.},
month = apr,
pages = {287–313},
numpages = {27},
keywords = {Confusion matrix, Fault, Machine learning}
}

@article{10.5555/3455716.3455773,
author = {Ma, Fan and Meng, Deyu and Dong, Xuanyi and Yang, Yi},
title = {Self-paced multi-view co-training},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Co-training is a well-known semi-supervised learning approach which trains classifiers on two or more different views and exchanges pseudo labels of unlabeled instances in an iterative way. During the co-training process, pseudo labels of unlabeled instances are very likely to be false especially in the initial training, while the standard co-training algorithm adopts a "draw without replacement" strategy and does not remove these wrongly labeled instances from training stages. Besides, most of the traditional co-training approaches are implemented for two-view cases, and their extensions in multi-view scenarios are not intuitive. These issues not only degenerate their performance as well as available application range but also hamper their fundamental theory. Moreover, there is no optimization model to explain the objective a co-training process manages to optimize. To address these issues, in this study we design a unified self-paced multi-view co-training (SPamCo) framework which draws unlabeled instances with replacement. Two specified co-regularization terms are formulated to develop different strategies for selecting pseudo-labeled instances during training. Both forms share the same optimization strategy which is consistent with the iteration process in co-training and can be naturally extended to multi-view scenarios. A distributed optimization strategy is also introduced to train the classifier of each view in parallel to further improve the efficiency of the algorithm. Furthermore, the SPamCo algorithm is proved to be PAC learnable, supporting its theoretical soundness. Experiments conducted on synthetic, text categorization, person re-identification, image recognition and object detection data sets substantiate the superiority of the proposed method.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {57},
numpages = {38},
keywords = {co-training, self-paced learning, multi-view learning, semi-supervised learning, ε-expansion theory, probably approximately correct learnable}
}

@article{10.1007/s00500-021-06048-x,
author = {Rathore, Santosh S.},
title = {An exploratory analysis of regression methods for predicting faults in software systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {23},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06048-x},
doi = {10.1007/s00500-021-06048-x},
abstract = {The use of regression methods, for instance, linear regression, decision tree regression, etc., has been used earlier to build software fault prediction (SFP) models. However, these methods showed limited SFP performance with higher misclassification errors. In previous works, issues such as multicollinearity, feature scaling, and imbalance distribution of faulty and non-faulty modules in the dataset have not been considered reasonably, which might be a potential cause behind the poor prediction performance of these regression methods. Motivated from it, in this paper, we investigate the impact of 15 different regression methods for the faults count prediction in the software system and report their interpretation for fault models. We consider different fault data quality issues, and a comprehensive assessment of the regression methods is presented to handle these issues. We believe that many used regression methods have not been explored before for the SFP by considering different data quality issues. In the presented study, 44 fault datasets and their versions are used that are collected from the PROMISE software data repository are used to validate the performance of the regression methods, and absolute relative error (ARE), root mean square error (RSME), and fault-percentile-average (FPA) are used as the performance measures. For the model building, five different scenarios are considered, (1) original dataset without preprocessing; (2) standardized processed dataset; (3) balanced dataset; (4) non-multicollinearity processed dataset; (5) balanced+non-multicollinearity processed dataset. Experimental results showed that overall kernel-based regression methods, KernelRidge and SVR (Support vector regression, both linear and nonlinear kernels), yielded the best performance for predicting the fault counts compared to other methods. Other regression methods, in particular NNR (Nearest neighbor regression), RFR (Random forest regression), and GBR (Gradient boosting regression), are performed significantly accurately. Further, results showed that applying standardization and handling multicollinearity in the fault dataset helped improve regression methods’ performance. It is concluded that regression methods are promising for building software fault prediction models.},
journal = {Soft Comput.},
month = dec,
pages = {14841–14872},
numpages = {32},
keywords = {Software fault prediction, Regression methods, PROMISE data repository, Empirical study}
}

@article{10.1016/j.procs.2017.09.066,
author = {Mehdiyev, Nijat and Lahann, Johannes and Emrich, Andreas and Enke, David and Fettke, Peter and Loos, Peter},
title = {Time Series Classification using Deep Learning for Process Planning},
year = {2017},
issue_date = {November 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {114},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.09.066},
doi = {10.1016/j.procs.2017.09.066},
abstract = {Multivariate time series classification has been broadly applied in diverse domains over the past few decades. However, before applying the classification algorithms, the vast majority of current studies extract hand-engineered features that are assumed to detect local patterns in the time series. Therefore, the efficiency and precision of these classification approaches are heavily dependent on the quality of variables defined by domain experts. Recent improvements in the deep learning domain offer opportunities to avoid such an intensive hand-crafted feature engineering which is particularly important for managing the processes based on time-series data obtained from various sensor networks. In our paper, we propose a framework to extract the features in an unsupervised (or self-supervised) manner using deep learning, particularly stacked LSTM Autoencoder Networks. The compressed representation of the time-series data obtained from LSTM Autoencoders are then provided to Deep Feedforward Neural Networks for classification. We apply the proposed framework on sensor time series data from the process industry to detect the quality of the semi-finished products and accordingly predict the next production process step. To validate the efficiency of the proposed approach, we used real-world data from the steel industry.},
journal = {Procedia Comput. Sci.},
month = nov,
pages = {242–249},
numpages = {8},
keywords = {Deep Learning, Process Industry, Steel Surface Defect Detection, Time Series Classification}
}

@phdthesis{10.5555/221197,
author = {Zhong, Yuan},
title = {Image segmentation for defect detection on veneer surfaces},
year = {1995},
publisher = {Oregon State University},
address = {USA},
note = {UMI Order No. GAX95-35991}
}

@phdthesis{10.5555/AAI29116300,
author = {Coates, Eyler Robert},
advisor = {Warren, Liao, T.},
title = {Internal Defect Detection in Hardwood Logs with Fast Magnetic Resonance Imaging},
year = {1998},
isbn = {9798438712053},
publisher = {Louisiana State University and Agricultural &amp; Mechanical College},
abstract = {Identification of defects such as knots in logs before the cutting operation would allow lumber mills to maximize the value of lumber from each log. This dissertation presented images obtained from scanning an oak log with magnetic resonance imaging (MRI). The unique characteristics of MRI images of hardwood logs were noted and were used to derive a quick algorithm to isolate defects. Defect regions had some pixels that varied considerably in intensity from their neighborhood, providing a seed for initiating the defect region. There was an overlap between the pixel gray level of the defects and clear wood. Therefore, traditional thresholding techniques did not cleanly separate these regions. In this study, region-growing methods were used to extract the defects. The algorithm grew the defect region seed until the border-pixel gray levels approached the average level of the neighborhood. The region-growing methods obtained more accurate defect regions than thresholding methods because of the simultaneous consideration of gray level and adjacency information.Two methods of MRI imaging were considered: spin-echo and echo-planar. Spin-echo imaging provided clear, detailed images but required about 20 seconds of acquisition time, which was too slow to be used in a production environment. Echo-planar images could be acquired in about 1/2 second, which was fast enough for production, but the images were fuzzy and noisy.The dissertation presented an algorithm that found the defect regions in spin-echo images. Region-growing methods use a number of parameters and the best parameters were unique for each image. However, common image statistics could be used to predict the proper parameters.The dissertation also presented an algorithm that found most of the defect regions in echo-planar images. Enhancing the echo-planar images using common general-purpose image-enhancement techniques failed because the lack of discrimination allowed the process to smooth image structures as well as noise. By taking advantage of the structure of a tree, smoothing between MRI frames accomplished the goal of smoothing along homogeneous areas and not across image structures. This "z-axis" smoothing enhanced the echo-planar image visually and reduced the number of false alarm defect regions.},
note = {AAI29116300}
}

@inproceedings{10.1145/3483207.3483208,
author = {Yao, Yong and Yang, Yue and Wang, Jing},
title = {Scratch Detection of Aircraft Bell Tube Based on Improved YOLOv4 Framework},
year = {2021},
isbn = {9781450390170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483207.3483208},
doi = {10.1145/3483207.3483208},
abstract = {To solve the problems of low accuracy, false detection, and high rate of missed detection, a surface scratch detection framework for aircraft bell tubes based on an improved YOLOv4 algorithm is proposed. First, we construct a scratch dataset on the surface of the aircraft bell tubes, which marks scratches with angled boxes. Secondly, convolutional layers are added to improve the ability of network to extract defect features, and the layers change in the backbone feature extraction network output and the spatial pyramid pooling structure in the YOLOv4 network. Finally, due to the uneven distribution of scratches, rotation detection is used to predict the scratches with rotate boxes. Experimental results show that the mAP value of the improved model based on YOLOv4 in scratch detection task is 96.21%, the MR value is 0.07, and the average detection time of a single image is 0.2270s, which proves that our model is better than Faster R-CNN, YOLOv4 and variants of our proposed model.},
booktitle = {Proceedings of the 2021 4th International Conference on Signal Processing and Machine Learning},
pages = {1–6},
numpages = {6},
keywords = {Scratch detection, YOLOv4, deep learning, rotation detection},
location = {Beijing, China},
series = {SPML '21}
}

@article{10.4018/IJDSST.2021010102,
author = {Fenu, Gianni and Malloci, Francesca Maridina},
title = {Lands DSS: A Decision Support System for Forecasting Crop Disease in Southern Sardinia},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {13},
number = {1},
issn = {1941-6296},
url = {https://doi.org/10.4018/IJDSST.2021010102},
doi = {10.4018/IJDSST.2021010102},
abstract = {Decision support systems (DSSs) are used in precision farming to address climate and environmental changes due to human action. However, increments in the amount of data produced continuously by the latest sensor and satellite technologies have recently incentivized the integration of artificial intelligence (AI). A review of research dedicated to the application of DSSs and AI in forecasting crop disease is proposed. In this paper, the authors describe the DSS LANDS developed for monitoring the main crop productions in Sardinia and the case study conducted to forecast potato late blight. A feed-forward neural network was implemented to investigate if weather data provided by regional stations could be used to predict a disease risk index using an AI technique. The test performed by stratified k-fold cross validation achieved an accuracy of 96%.},
journal = {Int. J. Decis Support Syst. Technol.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {Artificial Intelligence, Crop Disease, Decision Support Systems, Late Blight, Neural Network, Precision Farming}
}

@article{10.5555/3322706.3361993,
author = {Glimsdal, Sondre and Granmo, Ole-Christoffer},
title = {Thompson sampling guided stochastic searching on the line for deceptive environments with applications to root-finding problems},
year = {2019},
issue_date = {January 2019},
publisher = {JMLR.org},
volume = {20},
number = {1},
issn = {1532-4435},
abstract = {The multi-armed bandit problem forms the foundation for solving a wide range of online stochastic optimization problems through a simple, yet effective mechanism. One simply casts the problem as a gambler who repeatedly pulls one out of N slot machine arms, eliciting random rewards. Learning of reward probabilities is then combined with reward maximization, by carefully balancing reward exploration against reward exploitation. In this paper, we address a particularly intriguing variant of the multi-armed bandit problem, referred to as the Stochastic Point Location (SPL) problem. The gambler is here only told whether the optimal arm (point) lies to the "left" or to the "right" of the arm pulled, with the feedback being erroneous with probability 1 - π. This formulation thus targets optimization in continuous action spaces with both informative and deceptive feedback. To tackle this class of problems, we formulate a compact and scalable Bayesian representation of the solution space that simultaneously captures both the location of the optimal arm as well as the probability of receiving correct feedback. We further introduce the accompanying Thompson Sampling guided Stochastic Point Location (TS-SPL) scheme for balancing exploration against exploitation. By learning π, TS-SPL also supports deceptive environments that are lying about the direction of the optimal arm. This, in turn, allows us to address the fundamental Stochastic Root Finding (SRF) problem. Empirical results demonstrate that our scheme deals with both deceptive and informative environments, significantly outperforming competing algorithms both for SRF and SPL.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1910–1933},
numpages = {24},
keywords = {deceptive environment, probabilistic bisection search, searching on the line, stochastic point location, thompson sampling}
}

@inproceedings{10.1145/3461002.3473947,
author = {Pinnecke, Marcus},
title = {Product-lining the elinvar wealthtech microservice platform},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473947},
doi = {10.1145/3461002.3473947},
abstract = {Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {60–68},
numpages = {9},
keywords = {configuration management, microservice platforms, product families, technologies and concepts, variability management},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Systematic literature review, Software product lines, Machine learning, Configurable systems}
}

@article{10.5555/3546258.3546440,
author = {Klink, Pascal and Abdulsamad, Hany and Belousov, Boris and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni},
title = {A probabilistic interpretation of self-paced learning with applications to reinforcement learning},
year = {2021},
issue_date = {January 2021},
publisher = {JMLR.org},
volume = {22},
number = {1},
issn = {1532-4435},
abstract = {Across machine learning, the use of curricula has shown strong empirical potential to improve learning from data by avoiding local optima of training objectives. For reinforcement learning (RL), curricula are especially interesting, as the underlying optimization has a strong tendency to get stuck in local optima due to the exploration-exploitation trade-off. Recently, a number of approaches for an automatic generation of curricula for RL have been shown to increase performance while requiring less expert knowledge compared to manually designed curricula. However, these approaches are seldomly investigated from a theoretical perspective, preventing a deeper understanding of their mechanics. In this paper, we present an approach for automated curriculum generation in RL with a clear theoretical underpinning. More precisely, we formalize the well-known self-paced learning paradigm as inducing a distribution over training tasks, which trades off between task complexity and the objective to match a desired task distribution. Experiments show that training on this induced distribution helps to avoid poor local optima across RL algorithms in different tasks with uninformative rewards and challenging exploration requirements.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {182},
numpages = {52},
keywords = {curriculum learning, reinforcement learning, self-paced learning, tempered inference, rl-as-inference}
}

@article{10.1007/s11277-019-06238-9,
author = {Padmakumari, P. and Umamakeswari, A.},
title = {Task Failure Prediction using Combine Bagging Ensemble (CBE) Classification in Cloud Workflow},
year = {2019},
issue_date = {Jul 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {107},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-019-06238-9},
doi = {10.1007/s11277-019-06238-9},
abstract = {Scientific applications adopt cloud environment for executing its workflows as tasks. When a task fails, dependency nature of the workflows affects the overall performance of the execution. An efficient failure prediction mechanism is needed to execute the workflow efficiently. This paper proposes a failure prediction method which is implemented using various machine learning classifiers. Among different classifiers, Na\"{\i}ve Bayes predicts the failure with the highest accuracy of 94.4%. Further, to improve the accuracy of prediction, a novel ensemble method called combine bagging ensemble is introduced and acquires overall accuracy as 95.8%. The validation of proposed method is carried out by comparing simulation and real-time cloud testbed.},
journal = {Wirel. Pers. Commun.},
month = jul,
pages = {23–40},
numpages = {18},
keywords = {Cloud computing, Ensemble, Fault prediction, Machine learning, Scientific workflow, Task failure}
}

@inproceedings{10.1145/3445815.3445853,
author = {Li, Dan and Fu, SongLing and Zhang, QiJun and Mo, Yang and Liu, Li and Xu, ChuanFu},
title = {An Improved PCB Defect Detector Based on Feature Pyramid Networks},
year = {2021},
isbn = {9781450388436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445815.3445853},
doi = {10.1145/3445815.3445853},
abstract = {Aiming at the problem of false alarm in PCB defect detection in the automatic optical inspection process, many researchers have proposed their methods, but most of them only classify the single defect in single image, and there are multiple defects and multiple categories in single image. In this paper, a real PCB data set consisting of 1540 images generated by AOI is introduced for the detection and classification task. In addition, we propose an improved PCB defect detector based on feature pyramid networks. The detector combines Faster R-CNN and FPN as the infrastructure, and has been adjusted and improved, mainly including the following three innovations: 1) SE module is inserted into the feature extraction backbone network resnet-101, which improves the expression ability of network. 2) An enhanced bottom-up structure is introduced to enhance the whole feature level by using accurate low-level positioning signals. 3) ROI Align is used instead of RoI Pooling to reduce the impact of dislocation on small object defect detection. The experimental results show that, compared with the mainstream object detection network, the proposed method achieves better accuracy, reaching 96.3% mAP, and has better performance for defect detection and classification.},
booktitle = {Proceedings of the 2020 4th International Conference on Computer Science and Artificial Intelligence},
pages = {233–239},
numpages = {7},
keywords = {Automatic Optical Inspection, False Alarm, PCB Defect Detector, Printed Circuit Board},
location = {Zhuhai, China},
series = {CSAI '20}
}

@article{10.1007/s13748-021-00236-4,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Classifying multiclass imbalanced data using generalized class-specific extreme learning machine},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {3},
url = {https://doi.org/10.1007/s13748-021-00236-4},
doi = {10.1007/s13748-021-00236-4},
abstract = {Learning from the imbalanced problem is among the most attractive issues in the contemporary machine learning community. However, the extensive majority of attention in this domain is given to the two-class imbalanced problems, while their much more complex multiclass counterparts are comparatively unexplored. It has been shown (Huang et al. in IEEE Trans Syst Man Cybern B (Cybern) 42(2):513–529, 2012) that extreme learning machine (ELM) achieves much better generalization performance compared to support vector machine (SVM) and least-squares support vector machine (LS-SVM) for multiclass classification problems. On this account, this work proposes a novel generalized class-specific extreme learning machine (GCS-ELM), the extension of our recently proposed, class-specific extreme learning machine (CS-ELM) to address the multiclass imbalanced problems more effectively. The proposed GCS-ELM can be applied directly to the multiclass imbalance problems. The proposed method also has reduced computational cost compared to the weighted extreme learning machine (WELM) for multiclass imbalance problems. The proposed method uses class-specific regularization coefficients, which are computed by employing class distribution. The proposed method has lower computational overhead compared to the class-specific cost regulation extreme learning machine (CCR-ELM). The proposed work is assessed by using benchmark real-world imbalanced datasets downloaded from the well-known KEEL dataset repository and synthetic datasets. The experimental results, supported by the extensive statistical analysis, demonstrate that GCS-ELM is capable to improve the generalization performance for multiclass imbalanced classification problems.},
journal = {Prog. in Artif. Intell.},
month = sep,
pages = {259–281},
numpages = {23},
keywords = {Extreme learning machine, Generalized class-specific extreme learning machine, Multiclass imbalance problem, Classification}
}

@inproceedings{10.1145/1540438.1540443,
author = {Fu, Yu and Koru, A. G\"{u}ne\c{s} and Chen, Zhiyuan and El Emam, Khaled},
title = {A tree-based approach to preserve the privacy of software engineering data and predictive models},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540443},
doi = {10.1145/1540438.1540443},
abstract = {In empirical disciplines, data sharing leads to verifiable research and facilitates future research studies. Recent efforts of the PROMISE community contributed to data sharing and reproducible research in software engineering. However, an important portion of data used in empirical software engineering research still remains classified. This situation is unlikely to change because many companies, governments, and defense organizations will be always hesitant to share their project data such as, effort and defect data, due to various confidentiality, privacy, and security concerns. In this paper, we present, demonstrate, and evaluate a novel tree-based data perturbation approach. This approach does not only preserve privacy effectively, but it also preserves the predictive patterns in the original data set. Consequently, the empirical software engineering researchers will have access to another category of data sets, transformed data sets, which will increase the verifiability of research results and facilitate the future research studies in this area. Our approach can be immediately useful to many researchers and organizations who are willing to share their software engineering data but cannot do so due to privacy concerns.},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {3},
numpages = {12},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@inproceedings{10.1109/FBIT.2007.49,
author = {Oh, Jong-Hwan and Yun, Byoung-Ju and Park, Kil-Houm},
title = {The Defect Detection Using Human Visual System and Wavelet Transform in TFT-LCD Image},
year = {2007},
isbn = {9780769529998},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/FBIT.2007.49},
doi = {10.1109/FBIT.2007.49},
abstract = {The thin film transistor liquid crystal display (TFT-LCD) image has non-uniform brightness, which is the major difficulty in finding the defect region called Mura. To facilitate Mura segmentation, globally widely varying background signal has to be flattened and Mura signal must be enlarged. In this paper, Mura signal magnification and background signal flattening method is proposed using wavelet coefficients processing and the properties of human visual system (HVS). The wavelet approximation coefficients are used for background signal flattening while wavelet detail coefficients are employed to magnify Mura signal based on adapted contrast sensitivity function (ACSF). For the enhanced image, tri-modal thresholding segmentation technique is used for finding Dark and White Mura at the same time. For final reliable defect confirmation, false region elimination algorithms based on Weber's Law are also proposed. By the experimental results of TFT-LCD image, the proposed algorithms can have promising results and can be applied to the real automated TFT-LCD inspection system.},
booktitle = {Proceedings of the 2007 Frontiers in the Convergence of Bioscience and Information Technologies},
pages = {498–503},
numpages = {6},
series = {FBIT '07}
}

@article{10.1109/TPAMI.2007.1038,
author = {Xie, Xianghua and Mirmehdi, Majid},
title = {TEXEMS: Texture Exemplars for Defect Detection on Random Textured Surfaces},
year = {2007},
issue_date = {August 2007},
publisher = {IEEE Computer Society},
address = {USA},
volume = {29},
number = {8},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2007.1038},
doi = {10.1109/TPAMI.2007.1038},
abstract = {We present an approach to detecting and localizing defects in random color textures which requires only a few defect free samples for unsupervised training. It is assumed that each image is generated by a superposition of various-size image patches with added variations at each pixel position. These image patches and their corresponding variances are referred to here as textural exemplars or texems. Mixture models are applied to obtain the texems using multiscale analysis to reduce the computational costs. Novelty detection on color texture surfaces is performed by examining the same-source similarity based on the data likelihood in multiscale, followed by logical processes to combine the defect candidates to localize defects. The proposed method is compared against a Gabor filter bank-based novelty detection method. Also, we compare different texem generalization schemes for defect detection in terms of accuracy and efficiency.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = aug,
pages = {1454–1464},
numpages = {11},
keywords = {Defect detection, EM algorithm., mixture model, texem model, texture analysis}
}

@inproceedings{10.5555/839291.842760,
author = {Maalmi, K. and El-Ouaazizi, A. and Benslimane, R. and Voon, L. F. C. Lew Yan and Diou, A. and Gorria, P.},
title = {Crack Defect Detection and Localization Using Genetic-Based Inverse Voting Hough Transform},
year = {2002},
isbn = {076951695X},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In this paper we propose a Genetic-Based Inverse Voting Hough Transform (GBIVHT) method to detect buried crack defects in engineering structures. The method is applied to B-scan images obtained according to the ultrasonic Time Of Flight Diffraction technique. In these image representations of the ultrasound data, crack defects are characterized by multiple arcs of diffraction that can be approximated by a parabolic model. Thus, the crack defect detection problem in non-destructive inspection of engineering structures is transformed into a parabola detection and localization on B-scan images. In the proposed GBIVHT method, the local peak detection problem of conventional HT is converted into a parameter optimization problem that operates directly on the B-scan images. The optimization task is done using the well-knownGenetic Algorithms. Our main goals are an accurate detection of the parabolas while circumventing the computational complexity and huge storage problem tied to conventional HT.},
booktitle = {Proceedings of the 16 Th International Conference on Pattern Recognition (ICPR'02) Volume 3 - Volume 3},
pages = {30257},
series = {ICPR '02}
}

@article{10.1016/j.aei.2021.101318,
author = {Lv, Yaqiong and Zhou, Qianwen and Li, Yifan and Li, Weidong},
title = {A predictive maintenance system for multi-granularity faults based on AdaBelief-BP neural network and fuzzy decision making},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2021.101318},
doi = {10.1016/j.aei.2021.101318},
journal = {Adv. Eng. Inform.},
month = aug,
numpages = {12},
keywords = {Fault prediction, Multi-granularity faults, Predictive maintenance, AdaBelief-BP NN, Fuzzy decision making}
}

@inproceedings{10.5555/3495724.3496169,
author = {Parvaneh, Amin and Abbasnejad, Ehsan and Teney, Damien and Shi, Javen Qinfeng and van den Hengel, Anton},
title = {Counterfactual vision-and-language navigation: unravelling the unseen},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The task of vision-and-language navigation (VLN) requires an agent to follow text instructions to find its way through simulated household environments. A prominent challenge is to train an agent capable of generalising to new environments at test time, rather than one that simply memorises trajectories and visual details observed during training. We propose a new learning strategy that learns both from observations and generated counterfactual environments. We describe an effective algorithm to generate counterfactual observations on the fly for VLN, as linear combinations of existing environments. Simultaneously, we encourage the agent's actions to remain stable between original and counterfactual environments through our novel training objective – effectively removing spurious features that would otherwise bias the agent. Our experiments show that this technique provides significant improvements in generalisation on benchmarks for Room-to-Room navigation and Embodied Question Answering.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {445},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@inproceedings{10.1145/2639490.2639504,
author = {Russo, Barbara},
title = {A proposed method to evaluate and compare fault predictions across studies},
year = {2014},
isbn = {9781450328982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639490.2639504},
doi = {10.1145/2639490.2639504},
abstract = {Studies on fault prediction often pay little attention to empirical rigor and presentation. Researchers might not have full command over the statistical method they use, full understanding of the data they have, or tend not to report key details about their work. What does it happen when we want to compare such studies for building a theory on fault prediction? There are two issues that if not addressed, we believe, prevent building such theory. The first concerns how to compare and report prediction performance across studies on different data sets. The second regards fitting performance of prediction models. Studies tend not to control and report the performance of predictors on historical data underestimating the risk that good predictors may poorly perform on past data. The degree of both fitting and prediction performance determines the risk managers are requested to take when they use such predictors. In this work, we propose a framework to compare studies on categorical fault prediction that aims at addressing the two issues. We propose three algorithms that automate our framework. We finally review baseline studies on fault prediction to discuss the application of the framework.},
booktitle = {Proceedings of the 10th International Conference on Predictive Models in Software Engineering},
pages = {2–11},
numpages = {10},
keywords = {confusion matrix, fault, machine learning, model comparison},
location = {Turin, Italy},
series = {PROMISE '14}
}

@inproceedings{10.1145/3318299.3318337,
author = {Zhang, Zongtang and Chen, Zhe and Dai, Weiguo and Cheng, Yusheng},
title = {An Over-sampling Method Based on Margin Theory},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318337},
doi = {10.1145/3318299.3318337},
abstract = {Imbalanced data widely exists in real life, while the traditional classification method usually takes accuracy as the classification criterion, which is not suitable for the classification of imbalanced data. Resampling is an important method to deal with imbalanced data classification. In this paper, a margin based random over-sampling (MRO) method is proposed, and then MROBoost algorithm is proposed by combining the AdaBoost algorithm. Experimental results on the UCI dataset show that the MROBoost algorithm is superior to AdaBoost for imbalanced data classification problem.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {506–510},
numpages = {5},
keywords = {AdaBoost, Machine learning, imbalanced data, over-sampling},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1016/j.asoc.2021.107870,
author = {Kabir, Md Alamgir and Keung, Jacky and Turhan, Burak and Bennin, Kwabena Ebo},
title = {Inter-release defect prediction with feature selection using temporal chunk-based learning: An empirical study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107870},
doi = {10.1016/j.asoc.2021.107870},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Software defect prediction, Inter-release defect prediction, Feature selection}
}

@inproceedings{10.1007/978-3-030-76352-7_15,
author = {Notaro, Paolo and Cardoso, Jorge and Gerndt, Michael},
title = {A Systematic Mapping Study in AIOps},
year = {2020},
isbn = {978-3-030-76351-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-76352-7_15},
doi = {10.1007/978-3-030-76352-7_15},
abstract = {IT systems of today are becoming larger and more complex, rendering their human supervision more difficult. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to AI and Big Data. However, past AIOps contributions are scattered, unorganized and missing a common terminology convention, which renders their discovery and comparison impractical. In this work, we conduct an in-depth mapping study to collect and organize the numerous scattered contributions to AIOps in a unique reference index. We create an AIOps taxonomy to build a foundation for future contributions and allow an efficient comparison of AIOps papers treating similar problems. We investigate temporal trends and classify AIOps contributions based on the choice of algorithms, data sources and the target components. Our results show a recent and growing interest towards AIOps, specifically to those contributions treating failure-related tasks (62%), such as anomaly detection and root cause analysis.},
booktitle = {Service-Oriented Computing  – ICSOC 2020 Workshops: AIOps, CFTIC, STRAPS, AI-PA, AI-IOTS, and Satellite Events, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {110–123},
numpages = {14},
keywords = {AIOps, Operations and Maintenance, Artificial Intelligence},
location = {Dubai, United Arab Emirates}
}

@article{10.1016/j.artmed.2021.102162,
author = {Naranjo, Lizbeth and P\'{e}rez, Carlos J. and Campos-Roca, Yolanda and Madruga, Mario},
title = {Replication-based regularization approaches to diagnose Reinke's edema by using voice recordings},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102162},
doi = {10.1016/j.artmed.2021.102162},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {10},
keywords = {Acoustic features, Classification, Reinke's edema, Regularization, Replicated measurements, Variable selection}
}

@inbook{10.5555/783013.783024,
author = {Mufti, M. and Vachtsevanos, G. and Dorrity, L.},
title = {An intelligent approach to fabric defect detection in textile processes},
year = {2003},
isbn = {1852335254},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Vision for the Inspection of Natural Products},
pages = {279–304},
numpages = {26}
}

@inproceedings{10.1145/3345629.3345635,
author = {Wang, Song and Bansal, Chetan and Nagappan, Nachiappan and Philip, Adithya Abraham},
title = {Leveraging Change Intents for Characterizing and Identifying Large-Review-Effort Changes},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345635},
doi = {10.1145/3345629.3345635},
abstract = {Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. In most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes regarding review effort---changes with large review effort. Specifically, we first propose a feedback-driven and heuristics-based approach to obtain change intents. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on a large-scale project from Microsoft and three large-scale open source projects, i.e., Qt, Android, and OpenStack. Our results show that, (i) code changes with some intents are more likely to be LRE changes, (ii) machine learning based prediction models can efficiently help identify LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. The tool developed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {46–55},
numpages = {10},
keywords = {Code review, change intent, machine learning, review effort},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3366194.3366327,
author = {Li, Linjing and Zhang, Hua and Pang, Jie and Huang, Jishuang},
title = {Dam surface crack detection based on deep learning},
year = {2019},
isbn = {9781450372985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366194.3366327},
doi = {10.1145/3366194.3366327},
abstract = {According to the statistics of the First National Water Census Bulletin in 2013[1], the number of water conservancy projects in China has exceeded 98,000, and 756 are under construction, with a total storage capacity of more than 930 billion cubic meter, ranking first in the world. While these water conservancy projects bring enormous economic and social benefits to China, they are affected by geology, hydrology, meteorology and other factors, and their buildings such as tunnels are prone to various defects. However, the current methods for detecting cracks on the dam surface are still dominated by humans. This process is not only inefficient, costly, but often incomplete. YOLOv2 lacks the capture of small defects, YOLOv3 uses three scale feature maps for prediction, and enhances the detection of small cracks. This paper aims to propose a new application scenario for applying YOLOv3 to crack detection in floodgate dam surface and share its effects.},
booktitle = {Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {738–743},
numpages = {6},
keywords = {Dam crack, Deep learning, Defect detection, Hydraulic engineering},
location = {Shanghai, China},
series = {RICAI '19}
}

@article{10.1007/s00500-018-3473-6,
author = {Peng, Hu and Deng, Changshou and Wu, Zhijian},
title = {Best neighbor-guided artificial bee colony algorithm for continuous optimization problems},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3473-6},
doi = {10.1007/s00500-018-3473-6},
abstract = {As a relatively recent invented swarm intelligence algorithm, artificial bee colony (ABC) becomes popular and is powerful for solving the tough continuous optimization problems. However, the weak exploitation has greatly affected the performance of basic ABC algorithm. Meanwhile, keeping a proper balance between the exploration and exploitation is critical work. To tackle these problems, this paper introduces a best neighbor-guided ABC algorithm, named NABC. In NABC, the best neighbor-guided solution search strategy is proposed to equilibrate the exploration and exploitation of new algorithm during the search process. Moreover, the global neighbor search operator has displaced the original random method in the scout bee phase aiming to preserve the search experiences. The experimental studies have been tested on a set of widely used benchmark functions (including the CEC 2013 shifted and rotated problems) and one real-world application problem (the software defect prediction). Experimental results and comparison with the state-of-the-art ABC variants indicate that NABC is very competitive and outperforms the other algorithms.},
journal = {Soft Comput.},
month = sep,
pages = {8723–8740},
numpages = {18},
keywords = {Artificial bee colony (ABC), Continuous optimization problems, Best neighbor-guided search, Global neighbor search, Software defect prediction}
}

@inproceedings{10.1145/3368089.3417062,
author = {Suh, Alexander},
title = {Adapting bug prediction models to predict reverted commits at Wayfair},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417062},
doi = {10.1145/3368089.3417062},
abstract = {Researchers have proposed many algorithms to predict software bugs. Given a software entity (e.g., a file or method), these algorithms predict whether the entity is bug-prone. However, since these algorithms cannot identify specific bugs, this does not tend to be particularly useful in practice. In this work, we adapt this prior work to the related problem of predicting whether a commit is likely to be reverted. Given the batch nature of continuous integration deployment at scale, this allows developers to find time-sensitive bugs in production more quickly. The models in this paper are based on features extracted from the revision history of a codebase that are typically used in bug prediction. Our experiments, performed on the three main repositories for the Wayfair website, show that our models can rank reverted commits above 80% of non-reverted commits on average. Moreover, when given to Wayfair developers, our models reduce the amount of time needed to find certain kinds of bugs by 55%. Wayfair continues to use our findings and models today to help find bugs during software deployments.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1251–1262},
numpages = {12},
keywords = {reverted commits, software defect prediction, software deployment},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1504/ijiei.2021.120322,
author = {Lakra, Kirti and Chug, Anuradha},
title = {Application of metaheuristic techniques in software quality prediction: a systematic mapping study},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.120322},
doi = {10.1504/ijiei.2021.120322},
abstract = {This paper focuses on the systematic review of various metaheuristic techniques employed for analysing different software quality aspects, including fault proneness, defect anticipation, change proneness, maintainability prediction, and software reliability prediction. It is observed that machine learning algorithms are still popular models, but metaheuristic algorithms are also gaining popularity in the field of software quality measurement. This is due to the fact that metaheuristic algorithms are more efficient in solving real-world, search-based, and optimisation problems. Initially, 90 papers were considered and analysed for conducting this study from 2010 to 2020, and 55 studies were shortlisted based on predesigned quality evaluation standards. Resultantly, particle swarm optimisation (PSO), and genetic algorithms came out as the most prominently used metaheuristic techniques for developing software quality models in 36.3% and 27.2% of the shortlisted studies, respectively. The current review will benefit other researchers by providing an insight into the current trends in software quality domain.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {355–399},
numpages = {44},
keywords = {metaheuristic techniques, object-oriented metrics, software quality, software fault proneness, software defect prediction, software change prediction, software reliability prediction, software maintainability prediction, software quality improvement}
}

@article{10.1016/j.procs.2019.12.173,
author = {Chemingui, Houssem and Gam, Ines and Mazo, Ra\'{u}l and Salinesi, Camille and Ghezala, Henda Ben},
title = {Product Line Configuration Meets Process Mining},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {164},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.12.173},
doi = {10.1016/j.procs.2019.12.173},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {199–210},
numpages = {12},
keywords = {Product line engineering, configuration process, process mining, enhancing, configuration difficulties}
}

@article{10.1007/s10462-020-09907-5,
author = {Uma Maheswari, S. and Shahina, A. and Nayeemulla Khan, A.},
title = {Understanding Lombard speech: a review of compensation techniques towards improving speech based recognition systems},
year = {2021},
issue_date = {Apr 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09907-5},
doi = {10.1007/s10462-020-09907-5},
abstract = {Building voice-based Artificial Intelligence (AI) systems that can efficiently interact with humans through speech has become plausible today due to rapid strides in efficient data-driven AI techniques. Such a human–machine voice interaction in real world would often involve a noisy ambience, where humans tend to speak with additional vocal effort than in a quiet ambience, to mitigate the noise-induced suppression of vocal self-feedback. This noise induced change in the vocal effort is called Lombard speech. In order to build intelligent conversational devices that can operate in a noisy ambience, it is imperative to study the characteristics and processing of Lombard speech. Though the progress of research on Lombard speech started several decades ago, it needs to be explored further in the current scenario which is seeing an explosion of voice-driven applications. The system designed to work with normal speech spoken in a quiet ambience fails to provide the same performance in changing environmental contexts. Different contexts lead to different styles of Lombard speech and hence there arises a need for efficient ways of handling variations in speaking styles in noise. The Lombard speech is also more intelligible than normal speech of a speaker. Applications like public announcement systems with speech output interface should talk with varying degrees of vocal effort to enhance naturalness in a way that humans adapt to speak in noise, in real time. This review article is an attempt to summarize the progress of work on the possible ways of processing Lombard speech to build smart and robust human–machine interactive systems with speech input–output interface, irrespective of operating environmental contexts, for different application needs. This article is a comprehensive review of the studies on Lombard speech, highlighting the key differences observed in acoustic and perceptual analysis of Lombard speech and detailing the Lombard effect compensation methods towards improving the robustness of speech based recognition systems.},
journal = {Artif. Intell. Rev.},
month = apr,
pages = {2495–2523},
numpages = {29},
keywords = {Lombard speech, Acoustic analysis, Perceptual analysis, Automatic recognition systems, Lombard effect compensation, Lombard speech synthesis}
}

@article{10.1016/j.patcog.2016.11.021,
author = {Hanzaei, Saeed Hosseinzadeh and Afshar, Ahmad and Barazandeh, Farshad},
title = {Automatic detection and classification of the ceramic tiles surface defects},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {66},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2016.11.021},
doi = {10.1016/j.patcog.2016.11.021},
abstract = {Defect detection and classification of ceramic tile surface defects occurred in firing units are usually performed by human observations in most factories. In this paper, an automatic image processing system with high accuracy and time efficient approaches is presented. To this end, first, for defect detection, Rotation Invariant Measure of Local Variance (RIMLV) operator from statistical methods is employed for defect edges detection, and cooperatively a Close morphological operator from structural methods is used to fill and smooth detected regions. Then, all the detected defects of one ceramic tile are labeled, and the corresponding geometric features are extracted. Finally, a multi-class support vector machine classifier with winner-takes-all strategy based on statistical pattern recognition theories is employed to identify the defect type. The production process of Ceramic Tiles (CTs) includes various stages such as forming body of CTs, glazing and decorating, and firing.The main CTs defects occur in firing unit because of the many effective variables especially the temperature of kiln. For instance, these defects are combination of glaze and decorative pattern because of the exceeded air pressure in kiln, or are dimensional faults because of the improper velocity rate of roller conveyers in kiln. A sample of these defects and their reasons has been attached.It is very clear that the main specification of a CT is its surface quality; and in firing unit, the glaze is baked on CTs body to create the glassed surface. Hence, the unsuitable temperature circumstance along the roller kilns effects on surfaces of CTs and causes the surface defects.},
journal = {Pattern Recogn.},
month = jun,
pages = {174–189},
numpages = {16},
keywords = {Ceramic tile, Classification, Defect detection, Defect labeling, Feature extraction, Surface defects}
}

@article{10.1007/s11042-021-11084-8,
author = {Wang, Jin and Yu, Zhiyong and Duan, Zhizhao and Lu, Guodong},
title = {A sub-region one-to-one mapping (SOM) detection algorithm for glass passivation parts wafer surface low-contrast texture defects},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {19},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-11084-8},
doi = {10.1007/s11042-021-11084-8},
abstract = {Glass Passivation Parts (GPP) wafer texture defects are one of the most important factors affecting the accuracy of wafer defect detection. Template matching has local errors and low efficiency, and deep learning requires many training samples. In the early stage, defect training sample sets cannot be provided. This paper discusses the design of an effective GPP wafer grain region texture defect detection algorithm using a sub-region one-to-one mapping. A set of standard wafer datum is selected as the reference of grain region segmentation detection, and then the standard wafer images and test GPP wafer images are automatically calibrated and segmented, respectively. Then, a series of pre-processes were performed to equalize the sizes of the two grain-region images. Then the grain region was divided into an equal number of rectangular sub-regions of the same size according to the measurement precision requirement. The correlation degree of each test sub-region is judged by the designed three-channel RGB gray-scale similarity decision functions. Experiments show that the algorithm successfully achieved the necessary calibration and segmentation for the grain region. Compared with the template and histogram matching algorithms, the proposed method does not require a training set, the detection accuracy is significantly improved and the detection efficiency is up to 29.74 times better on average using the proposed algorithm.},
journal = {Multimedia Tools Appl.},
month = aug,
pages = {28879–28896},
numpages = {18},
keywords = {GPP wafer detection, Texture features, Image matching, Sub-region mapping, Feature extraction, Defect detection}
}

@article{10.1016/j.advengsoft.2021.103031,
author = {Cao, Minh-Tu and Nguyen, Ngoc-Mai and Chang, Kuan-Tsung and Tran, Xuan-Linh and Hoang, Nhat-Duc},
title = {Automatic recognition of concrete spall using image processing and metaheuristic optimized LogitBoost classification tree},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {159},
number = {C},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2021.103031},
doi = {10.1016/j.advengsoft.2021.103031},
journal = {Adv. Eng. Softw.},
month = sep,
numpages = {14},
keywords = {Concrete spall detection, Building maintenance, Image processing, Forensic-based investigation, Classification tree, Ensemble learning}
}

@inproceedings{10.1007/978-3-030-77626-8_35,
author = {To, Alex and Liu, Maican and Hazeeq Bin Muhammad Hairul, Muhammad and Davis, Joseph G. and Lee, Jeannie S. A. and Hesse, Henrik and Nguyen, Hoang D.},
title = {Drone-Based AI and 3D Reconstruction for Digital Twin Augmentation},
year = {2021},
isbn = {978-3-030-77625-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77626-8_35},
doi = {10.1007/978-3-030-77626-8_35},
abstract = {Digital Twin is an emerging technology at the forefront of Industry 4.0, with the ultimate goal of combining the physical space and the virtual space. To date, the Digital Twin concept has been applied in many engineering fields, providing useful insights in the areas of engineering design, manufacturing, automation, and construction industry. While the nexus of various technologies opens up new opportunities with Digital Twin, the technology requires a framework to integrate the different technologies, such as the Building Information Model used in the Building and Construction industry. In this work, an Information Fusion framework is proposed to seamlessly fuse heterogeneous components in a Digital Twin framework from the variety of technologies involved. This study aims to augment Digital Twin in buildings with the use of AI and 3D reconstruction empowered by unmanned aviation vehicles. We proposed a drone-based Digital Twin augmentation framework with reusable and customisable components. A proof of concept is also developed, and extensive evaluation is conducted for 3D reconstruction and applications of AI for defect detection.},
booktitle = {Social Computing and Social Media: Experience Design and Social Network Analysis        : 13th International Conference, SCSM 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part  I},
pages = {511–529},
numpages = {19},
keywords = {Digital Twin, 3D reconstruction, Artificial Intelligence (AI), Information augmentation, Unmanned aerial vehicle (UAV)}
}

@article{10.1016/j.knosys.2019.03.013,
author = {Xu, Peng and Du, Rui and Zhang, Zhongbao},
title = {Predicting pipeline leakage in petrochemical system through GAN and LSTM},
year = {2019},
issue_date = {Jul 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {175},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.03.013},
doi = {10.1016/j.knosys.2019.03.013},
journal = {Know.-Based Syst.},
month = jul,
pages = {50–61},
numpages = {12},
keywords = {Fault prediction, Pipeline leakage, GAN, LSTM}
}

@inproceedings{10.1007/978-3-030-86230-5_34,
author = {Salgueiro, Andr\'{e} and Santos, Sofia and Pereira, Artur and Cunha, Bernardo and Pedrosa, Eurico and Azevedo, Jos\'{e} Luis and Lau, Nuno and Lopes, Paulo and Gomes, Tiago},
title = {Neural Network Classifier and Robotic Manipulation for an Autonomous Industrial Cork Feeder},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_34},
doi = {10.1007/978-3-030-86230-5_34},
abstract = {This paper presents a solution for an autonomous cork puncher feeder with a robotic arm using image processing techniques and a convolutional neural network. Due to the need for cork strips to be inserted into the puncher with a specific orientation, to produce high quality cork stoppers, the identification of the orientation of each cork strip on the conveyor belt is a necessity. In response to this problem a convolutional neural network is used to analyse images processed with subtracted background, to create a robust solution for cork strips classification. In the tests carried out, a classification accuracy of 100% was obtained in a test data set with 12 different cork strips.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {433–444},
numpages = {12},
keywords = {Cork, Deep learning, Convolutional neural network, Universal Robots, Computer vision}
}

@article{10.3233/JIFS-190642,
author = {Tao, Liang and Siqi, Qian and Zhaochao, Meng and Gao Feng, Xie},
title = {Early fault warning of wind turbine based on BRNN and large sliding window},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-190642},
doi = {10.3233/JIFS-190642},
abstract = {With the construction of large-scale wind turbines, how to reduce the operation and maintenance costs has become an urgent problem to be solved. In this paper, by extracting the actual operation data of the wind turbine in Supervisory Control and Data Acquisition (SCADA) system, the Bidirectional Recurrent Neural Networks (BRNN) is used to establish the wind turbine operation prediction model. By eliminating abnormal data points caused by accidental factors through box diagram, the fault risk threshold of wind turbine components is optimized. Then, based on the residual between the actual value and the measured value of the large sliding window, the early fault warning is realized according to Wright criterion. Finally, the model proposed in this paper is applied to the actual wind turbine, which proves the reliability and accuracy of the method.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {3389–3401},
numpages = {13},
keywords = {BRNN, box-plot, large sliding window, Letts’criterion, early fault warning}
}

@inproceedings{10.5555/3504035.3504589,
author = {Zhao, Xibin and Wang, Nan and Shi, Heyuan and Wan, Hai and Huang, Jin and Gao, Yue},
title = {Hypergraph learning with cost interval optimization},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {In many classification tasks, the misclassification costs of different categories usually vary significantly. Under such circumstances, it is essential to identify the importance of different categories and thus assign different misclassifica-tion losses in many applications, such as medical diagnosis, saliency detection and software defect prediction. However, we note that it is infeasible to determine the accurate cost value without great domain knowledge. In most common cases, we may just have the information that which category is more important than the other categories, i.e., the identification of defect-prone softwares is more important than that of defect-free. To tackle these issues, in this paper, we propose a hypergraph learning method with cost interval optimization, which is able to handle cost interval when data is formulated using the high-order relationships. In this way, data correlations are modeled by a hypergraph structure, which has the merit to exploit the underlying relationships behind the data. With a cost-sensitive hypergraph structure, in order to improve the performance of the classifier without precise cost value, we further introduce cost interval optimization to hypergraph learning. In this process, the optimization on cost interval achieves better performance instead of choosing uncertain fixed cost in the learning process. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {554},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@article{10.1145/3450287,
author = {Zhao, Liang},
title = {Event Prediction in the Big Data Era: A Systematic Survey},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450287},
doi = {10.1145/3450287},
abstract = {Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {94},
numpages = {37},
keywords = {Event prediction, artificial intelligence, big data}
}

@article{10.1016/j.ins.2021.08.067,
author = {Gao, Can and Zhou, Jie and Miao, Duoqian and Yue, Xiaodong and Wan, Jun},
title = {Granular-conditional-entropy-based attribute reduction for partially labeled data with proxy labels},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {580},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.08.067},
doi = {10.1016/j.ins.2021.08.067},
journal = {Inf. Sci.},
month = nov,
pages = {111–128},
numpages = {18},
keywords = {Rough sets, Semi-supervised attribute reduction, Conditional entropy, Information granularity, Proxy label}
}

@inproceedings{10.1145/3349341.3349460,
author = {Wang, Xiaojuan and Wang, Defu and Zhang, Yong and Jin, Lei and Song, Mei},
title = {Unsupervised Learning for Log Data Analysis Based on Behavior and Attribute Features},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349460},
doi = {10.1145/3349341.3349460},
abstract = {In some special application environments, network fault can lead to loss of important information or even mission failures, resulting in unpredictable losses. Therefore, it has certain research significance and practical value to evaluate the network status and predict the possible faults before performing the key tasks. Based on the logs collected by the router board in the real network, this paper analyses the behavior type, attribute information and the corresponding status value, and detects the hidden fault or network attack, so as to provide early warning information for operators. We propose a deep neural network model utilizing Long Short-Term Memory (LSTM) to predict the current number of level-1 logs. By comparing the predicted number of level-1 logs, it can detect abnormal behavior such as a surge in the number of logs. What's more, we perform semantic analysis on attribute information to construct attribute syntax forest, which assists maintenance staff to monitor the system through key fingerprint information in the log. In addition, we adopt attribute information and status value to train the unsupervised learning algorithm models such as Isolation Forest, OneClassSVM and LocalOutlierFactor. What's more, this paper analyses the results to find out the causes of log surge, and to assist operators in subsequent maintenance of the system.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {510–518},
numpages = {9},
keywords = {LSTM, Log Analysis, Network Fault, Unsupervised Machine Learning},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@inproceedings{10.1145/3194718.3194730,
author = {Sarro, Federica},
title = {Predictive analytics for software testing: keynote paper},
year = {2018},
isbn = {9781450357418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194718.3194730},
doi = {10.1145/3194718.3194730},
abstract = {This keynote discusses the use of Predictive Analytics for Software Engineering, and in particular for Software Defect Prediction and Software Testing, by presenting the latest results achieved in these fields leveraging Artificial Intelligence, Search-based and Machine Learning methods, and by giving some directions for future work.},
booktitle = {Proceedings of the 11th International Workshop on Search-Based Software Testing},
pages = {1},
numpages = {1},
keywords = {predictive analytics, search-based predictive modelling},
location = {Gothenburg, Sweden},
series = {SBST '18}
}

@inproceedings{10.1145/3396743.3396768,
author = {Wang, Jing-Wein and Wang, Chin-Chiang and Cheng, Tsung-Chieh},
title = {AI-based Automatic Optical Inspection of Glass Bubble Defects},
year = {2020},
isbn = {9781450377065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396743.3396768},
doi = {10.1145/3396743.3396768},
abstract = {Automatic Optical Inspection (AOI) offers a range of solutions to meet the requirements of every production facility, attracting significant interest of manufacturers of various industries. One important AOI application in the glass industry is to detect bubble defects in spherical glass, especially those used for making high-end lenses. Nevertheless, the AOI process must make the inspection decision in a reliable manner. Another challenge is that glass bubble defects are nearly transparent and can be captured by cameras only from certain viewing angles and with the aid of a specially engineered lighting mechanism. In this paper, an Artificial Intelligence method based on AOI (AI-AOI) is proposed to address the need of the glass industry as aforementioned. In specifics, our proposed method employs (1) a specially designed back-lighting mechanism to illuminate the hardly visible glass bubble defects, (2) Otsu thresholding image-segmentation method to obtain the distortion part and the core part of the defects and eliminate the fake defects caused by dust particles, and (3) a novel AI-based bubble-defect detection method capable of capturing the bubble defects as small as a few millimeters in diameter. The initial experimental results validate the feasibility of the proposed AOI method with an accuracy of 95%. If we exclude factors such as scratches by humans or the presence of dust particles in the inspection room, our method can achieve a recognition rate of 100%.},
booktitle = {Proceedings of the 2020 2nd International Conference on Management Science and Industrial Engineering},
pages = {242–246},
numpages = {5},
keywords = {Automated optical inspection, artificial intelligence, glass bubbles},
location = {Osaka, Japan},
series = {MSIE '20}
}

@article{10.1023/A:1008077902102,
author = {Angeli, Chr. and Chatzinikolaou, A.},
title = {Fault Prediction and Compensation Functions in a Diagnostic Knowledge-Based System for Hydraulic Systems},
year = {1999},
issue_date = {June 1999},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {0921-0296},
url = {https://doi.org/10.1023/A:1008077902102},
doi = {10.1023/A:1008077902102},
abstract = {Fault prediction and fault compensation are beneficial for the production technology and give a new dimension to fault diagnosis in technical systems. The overall goal of this paper is the presentation of fault prediction and fault compensation procedures as they are studied, implemented and embedded in a real time expert system. This expert system detects and diagnoses faults in hydraulic systems. For this purpose dynamic modelling information, on-line sensor information, special features of the domain of hydraulic systems and expert systems technology are used co-operatively.},
journal = {J. Intell. Robotics Syst.},
month = jun,
pages = {153–165},
numpages = {13},
keywords = {fault compensation, fault prediction, hydraulic systems, model-based diagnosis, on-line expert systems}
}

@article{10.1007/s10845-018-1458-z,
author = {Chen, Haiyong and Pang, Yue and Hu, Qidi and Liu, Kun},
title = {Solar cell surface defect inspection based on multispectral convolutional neural network},
year = {2020},
issue_date = {Feb 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {2},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-018-1458-z},
doi = {10.1007/s10845-018-1458-z},
abstract = {Similar and indeterminate defect detection of solar cell surface with heterogeneous texture and complex background is a challenge of solar cell manufacturing. The traditional manufacturing process relies on human eye detection which requires a large number of workers without a stable and good detection effect. In order to solve the problem, a visual defect detection method based on multi-spectral deep convolutional neural network (CNN) is designed in this paper. Firstly, a selected CNN model is established. By adjusting the depth and width of the model, the influence of model depth and kernel size on the recognition result is evaluated. The optimal CNN model structure is selected. Secondly, the light spectrum features of solar cell color image are analyzed. It is found that a variety of defects exhibited different distinguishable characteristics in different spectral bands. Thus, a multi-spectral CNN model is constructed to enhance the discrimination ability of the model to distinguish between complex texture background features and defect features. Finally, some experimental results and K-fold cross validation show that the multi-spectral deep CNN model can effectively detect the solar cell surface defects with higher accuracy and greater adaptability. The accuracy of defect recognition reaches 94.30%. Applying such an algorithm can increase the efficiency of solar cell manufacturing and make the manufacturing process smarter.},
journal = {J. Intell. Manuf.},
month = feb,
pages = {453–468},
numpages = {16},
keywords = {Machine vision, Solar cell, Deep learning, Defection inspection}
}

@inproceedings{10.5555/978-3-030-87897-9_fm,
title = {Front Matter},
year = {2021},
isbn = {978-3-030-87896-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Artificial Intelligence and Soft Computing: 20th International Conference, ICAISC 2021, Virtual Event, June 21–23, 2021, Proceedings, Part II},
pages = {i–xx}
}

@inproceedings{10.5555/978-3-030-87986-0_fm,
title = {Front Matter},
year = {2021},
isbn = {978-3-030-87985-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Artificial Intelligence and Soft Computing: 20th International Conference, ICAISC 2021, Virtual Event, June 21–23, 2021, Proceedings, Part I},
pages = {i–xix}
}

@inproceedings{10.1145/3469213.3472779,
author = {Wang, Chengcheng and Wang, Kai},
title = {Research on aeroengine health assessment and life prediction under changing working conditions},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3472779},
doi = {10.1145/3469213.3472779},
abstract = {The working environment of aeroengine is harsh and complex. At present, the research on fault diagnosis and health assessment of aeroengine is mostly focused on single component and subsystem, and few researches on the whole machine. The research on the whole engine also assumes that the engine works under the same condition, and less research is done under the condition of variable and multi working conditions. This paper studies the health assessment and life prediction of aeroengine under variable working conditions, which can provide ideas for the engineering practice of early fault prediction, fault detection, health assessment and life prediction of aeroengine system.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {360},
numpages = {4},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@inproceedings{10.1145/3423423.3423471,
author = {B\"{o}hm, Stefan-Andreas},
title = {AI Approaches to Optimize Human-Machine Collaboration in Manufacturing Facilities with IoT-Ready Machinery},
year = {2020},
isbn = {9781450388207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423423.3423471},
doi = {10.1145/3423423.3423471},
abstract = {Modern production facilities are becoming increasingly complex, as companies battle to meet the increasingly customer-specific demands with shorter lead times and higher efficiency. For the employees in the factory, who often bear the brunt of making short-term process decisions, this complexity is becoming unmanageable. The PhD project presented in the following aims to decrease the complexity of modern manufactory facilities by means of artificial intelligence. The focus is on product data analysis and manufactory process planning. Different approaches of artificial intelligence for use in a Self-Adapting Smart System (SASS) are to be investigated.},
booktitle = {Companion Proceedings of the 10th International Conference on the Internet of Things},
articleno = {23},
numpages = {5},
keywords = {Artificial Intelligence, Internet of Things, Self-Adapting Smart System;},
location = {Malm\"{o}, Sweden},
series = {IoT '20 Companion}
}

@inproceedings{10.1145/3469213.3470417,
author = {Xu, Bin and Liu, Xusheng and Zhao, Wei and Li, Ziqian and Wang, Chenfei and Zhu, Qing},
title = {Research on the Architecture and Key Technologies of the Ubiquitous Customer Service Operating System for State Grid},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3470417},
doi = {10.1145/3469213.3470417},
abstract = {Traditional customer service systems can hardly satisfy the high quality and efficiency requirements in the digital and intelligent era, to tackle this issue, advanced data and artificial intelligence technology are required to be integrated. Based on the ubiquitous operating system theory and take the State Grid customer service as a business scenario, this paper proposes an intelligent customer service platform. The platform takes the ubiquitous power customer service operating system as its core, manages and information multiplexes the massive data resources systematically to support customer service in a high-efficiency and intelligent manner. This paper studies the architecture of the platform and the key technologies involved, and implemented core applications at the industrial level. The paper also discusses the reliability of the system and proposed a reliability guarantee mechanism for customer service operating system. The demonstration system was verified in the actual production environment of the State Grid, and finally proved that this system can effectively improve the work efficiency of the customer service team and reduce operation and maintenance costs.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {210},
numpages = {6},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1016/j.cosrev.2020.100297,
author = {Nayak, Janmenjoy and Vakula, Kanithi and Dinesh, Paidi and Naik, Bighnaraj and Pelusi, Danilo},
title = {Intelligent food processing: Journey from artificial neural network to deep learning},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {38},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100297},
doi = {10.1016/j.cosrev.2020.100297},
journal = {Comput. Sci. Rev.},
month = nov,
numpages = {28},
keywords = {Food processing, Artificial intelligence, Artificial neural network, Machine learning, Deep learning}
}

@article{10.1002/smr.2172,
author = {Gong, Lina and Jiang, Shujuan and Jiang, Li},
title = {An improved transfer adaptive boosting approach for mixed‐project defect prediction},
year = {2019},
issue_date = {October 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {10},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2172},
doi = {10.1002/smr.2172},
abstract = {Software defect prediction (SDP) has been a very important research topic in software engineering, since it can provide high‐quality results when given sufficient historical data of the project. Unfortunately, there are not abundant data to bulid the defect prediction model at the beginning of a project. For this scenario, one possible solution is to use data from other projects in the same company. However, using these data practically would get poor performance because of different distributional characteristics among projects. Also, software has more non‐defective instances than defective instances that may cause a significant bias towards defective instances. Considering these two problems, we propose an improved transfer adaptive boosting (ITrAdaBoost) approach for being given a small number of labeled data in the testing project. In our approach, ITrAdaBoost can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate but also use the asymmetric misclassification costs for non‐defective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that: (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results. Consequently, the proposed approach can build an effective prediction model with a small number of labeled instances for mixed‐project defect prediction (MPDP).For mixed‐project defect prediction, improved transfer adaptive boosting approach (ITrAdaBoost) can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate, but also use the asymmetric misclassification costs for nondefective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results.


image
image},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {23},
keywords = {class imbalance, cross‐project, mixed‐project, software defect prediction, transfer learning}
}

@article{10.1016/j.engappai.2021.104473,
author = {Liu, Ze-yu and Liu, Jian-wei and Zuo, Xin and Hu, Ming-fei},
title = {Multi-scale iterative refinement network for RGB-D salient object detection},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104473},
doi = {10.1016/j.engappai.2021.104473},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
numpages = {16},
keywords = {Salient object detection, RGB-D image, Multi-scale refinement}
}

@article{10.1016/j.engappai.2021.104387,
author = {Yu, Jianbo and Shen, Zongli and Wang, Shijin},
title = {Wafer map defect recognition based on deep transfer learning-based densely connected convolutional network and deep forest},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {105},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104387},
doi = {10.1016/j.engappai.2021.104387},
journal = {Eng. Appl. Artif. Intell.},
month = oct,
numpages = {11},
keywords = {Semiconductor manufacturing, Wafer map defect, Transfer learning, Convolution neural network, Deep forest}
}

@phdthesis{10.5555/1369140,
author = {Challagulla, Venkata Udaya Bhaskar},
advisor = {Bastani, Farokh B.},
title = {A machine learning-based approach for dynamic reliability assessment of mission critical software systems},
year = {2007},
isbn = {9780549270720},
publisher = {University of Texas at Dallas},
address = {USA},
abstract = {Software continues to become more complex and difficult to certify to a high degree of confidence due to the increasing scope and sophistication of the requirements. Consequently, traditional development techniques face growing challenges in satisfying these requirements. Future distributed real-time systems, such as robotic swarm systems, telecontrol systems, and industrial automation systems, may need to dynamically adapt themselves based on the run-time mission-specific requirements and operating conditions. This further compounds the problems of developing highly dependable systems. This is also the case with emerging Service Oriented Architecture (SOA) based systems that perform dynamic discovery of services and reconfiguration and composition of services at run-time. These dynamic features combined with the abstractions provided by the services necessitate the need for high-confidence run-time software reliability assessment techniques. This Dissertation investigates machine learning-based software defect prediction techniques to monitor and assess the services in the synthesized code. Experimental assessment of various prediction algorithms using real-world data shows that memory-based reasoning (MBR) techniques perform relatively better than other methods. Based on these results, a framework is developed to automatically derive the optimal configuration of an MBR classifier for software defect data by logical variations of its configuration parameters. This adaptive MBR technique provides a flexible and effective environment for accurate prediction of mission-critical software defect data. In practice, since these systems are dynamically assembled from existing services, a dearth of sufficient sample data regarding the actual operational environment can reduce the level of confidence in the reliability estimate. The Dissertation investigates the combination of Bayesian Belief Network (BBN) and MBR methodologies to integrate multiple evidences from all the services to obtain high-confidence estimates in the reliability of dynamically assembled mission-critical SOA-based systems. Latent defects in more frequently executed domains affect the reliability of the component much more than the domains tested using random testing strategies. A dynamic monitoring and diagnosis framework is developed to accurately estimate the reliability of the system as it executes. The framework incorporates a Markov model to determine the service reliability from its component reliabilities. This systematic assessment method is evaluated using a simulated system and a real-world case study involving an Enterprise Content Management System. An Intelligent Software Defect Analysis Tool (ISDAT) that implements the above framework is developed, to realize the framework objectives of providing a unified framework for dynamically assessing the reliability of mission-critical SOA-based systems to a high-degree of confidence by using AI-based prediction analysis on the defect metrics data collected from real-time system monitoring.},
note = {AAI3285271}
}

@inproceedings{10.1007/978-3-030-93046-2_7,
author = {Guo, Jingwen and Lu, Zhisheng and Wang, Ti and Huang, Weibo and Liu, Hong},
title = {Object Goal Visual Navigation Using Semantic Spatial Relationships},
year = {2021},
isbn = {978-3-030-93045-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-93046-2_7},
doi = {10.1007/978-3-030-93046-2_7},
abstract = {The target-driven visual navigation is a popular learning-based method and has been successfully applied to a wide range of applications. However, it has some disadvantages, including being ineffective at adapting to unseen environments. In this paper, a navigation method based on Semantic Spatial Relationships (SSR) is proposed and is shown to have more reliable performance when dealing with novel conditions. The construction of joint semantic hierarchical feature vector allows for learning implicit relationship between current observation and target objects, which benefits from construction of prior knowledge graph and semantic space. This differs from the traditional target driven methods, which integrate the visual input vector directly into the reinforcement learning path planning module. Moreover, the proposed method takes both local and global features of observed image into consideration and is thus less conservative and more robust in regards to random scenes. An additional analysis indicates that the proposed SSR performs well on classical metrics. The effectiveness of the proposed SSR model is demonstrated comparing with state-of-the-art methods in unknown scenes.},
booktitle = {Artificial Intelligence: First CAAI International Conference, CICAI 2021, Hangzhou, China, June 5–6, 2021, Proceedings, Part I},
pages = {77–88},
numpages = {12},
keywords = {Visual navigation, Semantic graph, Hierarchical relationship},
location = {Hangzhou, China}
}

@article{10.1016/S0360-8352(99)00040-6,
author = {Hong, G. Y. and Xie, M. and Shanmugan, P.},
title = {A statistical method for controlling software defect detection process},
year = {1999},
issue_date = {Oct. 1999},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {1–2},
issn = {0360-8352},
url = {https://doi.org/10.1016/S0360-8352(99)00040-6},
doi = {10.1016/S0360-8352(99)00040-6},
journal = {Comput. Ind. Eng.},
month = oct,
pages = {137–140},
numpages = {4},
keywords = {Statistical Process Control (SPC), causal analysis, software inspection, software testing}
}

@inproceedings{10.1007/978-3-030-87589-3_19,
author = {Yan, Yutong and Conze, Pierre-Henri and Lamard, Mathieu and Zhang, Heng and Quellec, Gwenol\'{e} and Cochener, B\'{e}atrice and Coatrieux, Gouenou},
title = {Deep Active Learning for Dual-View Mammogram Analysis},
year = {2021},
isbn = {978-3-030-87588-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87589-3_19},
doi = {10.1007/978-3-030-87589-3_19},
abstract = {Supervised deep learning on medical imaging requires massive manual annotations, which are expertise-needed and time-consuming to perform. Active learning aims at reducing annotation efforts by adaptively selecting the most informative samples for labeling. We propose in this paper a novel deep active learning approach for dual-view mammogram analysis, especially for breast mass segmentation and detection, where the necessity of labeling is estimated by exploiting the consistency of predictions arising from craniocaudal (CC) and mediolateral-oblique (MLO) views. Intuitively, if mass segmentation or detection is robustly performed, prediction results achieved on CC and MLO views should be consistent. Exploiting the inter-view consistency is hence a good way to guide the sampling mechanism which iteratively selects the next image pairs to be labeled by an oracle. Experiments on public DDSM-CBIS and INbreast datasets demonstrate that comparable performance with respect to fully-supervised models can be reached using only 6.83% (9.56%) of labeled data for segmentation (detection). This suggests that combining dual-view mammogram analysis and active learning can strongly contribute to the development of computer-aided diagnosis systems.},
booktitle = {Machine Learning in Medical Imaging: 12th International Workshop, MLMI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings},
pages = {180–189},
numpages = {10},
keywords = {Breast cancer, Mass segmentation, Mass detection, Dual-view mammogram analysis, Active learning, Computer-aided diagnosis},
location = {Strasbourg, France}
}

@article{10.1016/j.cie.2021.107630,
author = {Dang, L. Minh and Kyeong, SeonJae and Li, Yanfen and Wang, Hanxiang and Nguyen, Tan N. and Moon, Hyeonjoon},
title = {Deep learning-based sewer defect classification for highly imbalanced dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107630},
doi = {10.1016/j.cie.2021.107630},
journal = {Comput. Ind. Eng.},
month = nov,
numpages = {16},
keywords = {Sewer network, Crack classification, Deep learning, CCTV, Text recognition, Imbalanced data}
}

@article{10.1093/ietfec/e89-a.5.1484,
author = {Meylanundefined, Ru\c{s}en and \"{O}den, Cenker and Ert\"{U}z\"{U}n, Ay\c{s}in and Er\c{C}undefinedl, Ayt\"{u}l},
title = {2-D Iteratively Reweighted Least Squares Lattice Algorithm and Its Application to Defect Detection in Textured Images*This work has been partially supported by Turkish Technology Development Foundation under contract number TTGV-169.},
year = {2006},
issue_date = {May 2006},
publisher = {Oxford University Press, Inc.},
address = {USA},
volume = {E89-A},
number = {5},
issn = {0916-8508},
url = {https://doi.org/10.1093/ietfec/e89-a.5.1484},
doi = {10.1093/ietfec/e89-a.5.1484},
abstract = {In this paper, a 2-D iteratively reweighted least squares lattice algorithm, which is robust to the outliers, is introduced and is applied to defect detection problem in textured images. First, the philosophy of using different optimization functions that results in weighted least squares solution in the theory of 1-D robust regression is extended to 2-D. Then a new algorithm is derived which combines 2-D robust regression concepts with the 2-D recursive least squares lattice algorithm. With this approach, whatever the probability distribution of the prediction error may be, small weights are assigned to the outliers so that the least squares algorithm will be less sensitive to the outliers. Implementation of the proposed iteratively reweighted least squares lattice algorithm to the problem of defect detection in textured images is then considered. The performance evaluation, in terms of defect detection rate, demonstrates the importance of the proposed algorithm in reducing the effect of the outliers that generally correspond to false alarms in classification of textures as defective or nondefective.},
journal = {IEICE Trans. Fundam. Electron. Commun. Comput. Sci.},
month = may,
pages = {1484–1494},
numpages = {11},
keywords = {2-D lattice filters, defect detection, robust least squares lattice algorithm, texture analysis}
}

@article{10.1016/j.neucom.2018.12.057,
author = {Wang, Kangwei and Zhang, Xin and Hao, Qiushi and Wang, Yan and Shen, Yi},
title = {Application of improved least-square generative adversarial networks for rail crack detection by AE technique},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {332},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.12.057},
doi = {10.1016/j.neucom.2018.12.057},
journal = {Neurocomput.},
month = mar,
pages = {236–248},
numpages = {13},
keywords = {Rail defect detection, Acoustic emission, Generative adversarial networks, Least-square, Noise suppression}
}

@article{10.1007/s10462-016-9536-0,
author = {Rajab, Sharifa and Sharma, Vinod},
title = {A review on the applications of neuro-fuzzy systems in business},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-016-9536-0},
doi = {10.1007/s10462-016-9536-0},
abstract = {This paper presents a review of the application of neuro-fuzzy systems (NFS) in business on the basis of the research articles issued in various reputed international journals and conferences during 2005---2015. The use of NFS for tackling various real world problems in different business domains has diversified significantly during this period. In effect NFS has emerged as a dominant technique for addressing various difficult research problems in business. Based on a detailed review of these research papers we have identified finance, marketing, distribution, business planning, information systems, production and operations as the main business application domains of NFS during this period. This paper also discusses the impact of NFS in various business domains and the trend of this application based research during this period. This paper also surveys the various innovations in NFS methodologies employed by the researchers to deal with different business problems in each of these years. Moreover the paper includes some articles published during 2016 in several international journals to present the latest progress in the application of NFS in various business domains.},
journal = {Artif. Intell. Rev.},
month = apr,
pages = {481–510},
numpages = {30},
keywords = {Artificial intelligence, Business, Neural networks, Neuro-fuzzy systems, Review}
}

@inproceedings{10.1007/978-3-030-87571-8_56,
author = {Wang, Ying and Hao, Zhengyang and Zuo, Fang and Su, Zixiang},
title = {Fabric Defect Target Detection Algorithm Based on YOLOv4 Improvement},
year = {2021},
isbn = {978-3-030-87570-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87571-8_56},
doi = {10.1007/978-3-030-87571-8_56},
abstract = {Fabric defect detection is a key part of product quality assessment in the textile industry. It is important to achieve fast, accurate and efficient detection of fabric defects to improve productivity in the textile industry. For the problems of varying scales, irregular shapes and many small objects, an improved YOLOv4 object detection algorithm for fabric defects is proposed. Firstly, in order to improve the detection accuracy of small objects, the RFB module is introduced and fused with shallow features, which can obtain receptive fields of different scales to improve the features extracted from the backbone network. Secondly, the introduction of spatial and channel attention mechanisms can enhance fused features, allowing the network to focus on useful information. Experimental results show that the mean average precision of the improved YOLOv4 object detection algorithm in fabric defect map detection is 71.89%. The improved algorithm can accurately improve the accuracy of fabric defect positioning.},
booktitle = {Web Information Systems and Applications: 18th International Conference, WISA 2021, Kaifeng, China, September 24–26, 2021, Proceedings},
pages = {647–658},
numpages = {12},
keywords = {Fabric defect detection, YOLOv4, RFB, Attention mechanisms},
location = {Kaifeng, China}
}

@article{10.1109/TSE.2005.112,
author = {Gyimothy, Tibor and Ferenc, Rudolf and Siket, Istvan},
title = {Empirical Validation of Object-Oriented Metrics on Open Source Software for Fault Prediction},
year = {2005},
issue_date = {October 2005},
publisher = {IEEE Press},
volume = {31},
number = {10},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2005.112},
doi = {10.1109/TSE.2005.112},
abstract = {Open source software systems are becoming increasingly important these days. Many companies are investing in open source projects and lots of them are also using such software in their own work. But, because open source software is often developed with a different management style than the industrial ones, the quality and reliability of the code needs to be studied. Hence, the characteristics of the source code of these projects need to be measured to obtain more information about it. This paper describes how we calculated the object-oriented metrics given by Chidamber and Kemerer to illustrate how fault-proneness detection of the source code of the open source Web and e-mail suite called Mozilla can be carried out. We checked the values obtained against the number of bugs found in its bug database called Bugzilla using regression and machine learning methods to validate the usefulness of these metrics for fault-proneness prediction. We also compared the metrics of several versions of Mozilla to see how the predicted fault-proneness of the software system changed during its development cycle.},
journal = {IEEE Trans. Softw. Eng.},
month = oct,
pages = {897–910},
numpages = {14},
keywords = {Bugzilla, C++, Columbus., Index Terms- Fact extraction, Mozilla, compiler wrapping, fault-proneness detection, metrics validation, open source software, reverse engineering}
}

@inproceedings{10.1007/978-3-030-97774-0_9,
author = {Wang, Jing and Wan, Meng and Wang, Jue and Wang, Xiaoguang and Wang, Yangang and Liu, Fang and Min, Weixiao and Lei, He and Wang, Lihua},
title = {Defects Detection System of&nbsp;Medical Gloves Based on&nbsp;Deep Learning},
year = {2022},
isbn = {978-3-030-97773-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-97774-0_9},
doi = {10.1007/978-3-030-97774-0_9},
abstract = {In industrial production, medical gloves with tear, stain and other defects will be produced. In traditional manual mode, the efficiency and accuracy of defect detection depend on the proficiency of spot-check workers, which results in uneven glove product quality. In this paper, a surface defect detection system of medical gloves based on deep learning is designed for the automatic detection with high efficiency and accuracy. According to the industrial requirements of high real-time, the system adopts a cache scheme to improve the data reading and writing speed, and an Open Neural Network Exchange (ONNX) to effectively improve the speed of model reasoning. For the demands of high detection accuracy, the system designs a dual model detection strategy, which divides texture detection and edge detection into two steps. The advantage of this strategy is to remove most useless information while ensuring the effective information of the image. Furthermore, two auxiliary models are used to promote the accuracy of detection based on classification methods. Finally, experiments are proposed to verify the functional indicators of the system. After the on-site test of the production line in the medical glove factory, the system has the ability to detect the gloves of two production lines with high real-time. The product missed detection rate is less than 2%, and the product mistakenly picked rate is less than 5/10000. Verified by the industry of gloves, the system can be put into production line.},
booktitle = {Smart Computing and Communication: 6th International Conference, SmartCom 2021, New York City, NY, USA, December 29–31, 2021, Proceedings},
pages = {101–111},
numpages = {11},
keywords = {Medical gloves, Deep learning, Surface defect, Detection system, Image recognition, Auxiliary model},
location = {New York, NY, USA}
}

@inproceedings{10.1145/3273934.3273936,
author = {Ferenc, Rudolf and T\'{o}th, Zolt\'{a}n and Lad\'{a}nyi, Gergely and Siket, Istv\'{a}n and Gyim\'{o}thy, Tibor},
title = {A Public Unified Bug Dataset for Java},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273936},
doi = {10.1145/3273934.3273936},
abstract = {Background: Bug datasets have been created and used by many researchers to build bug prediction models.Aims: In this work we collected existing public bug datasets and unified their contents.Method: We considered 5 public datasets which adhered to all of our criteria. We also downloaded the corresponding source code for each system in the datasets and performed their source code analysis to obtain a common set of source code metrics. This way we produced a unified bug dataset at class and file level that is suitable for further research (e.g. to be used in the building of new bug prediction models). Furthermore, we compared the metric definitions and values of the different bug datasets.Results: We found that (i) the same metric abbreviation can have different definitions or metrics calculated in the same way can have different names, (ii) in some cases different tools give different values even if the metric definitions coincide because (iii) one tool works on source code while the other calculates metrics on bytecode, or (iv) in several cases the downloaded source code contained more files which influenced the afferent metric values significantly.Conclusions: Apart from all these imprecisions, we think that having a common metric set can help in building better bug prediction models and deducing more general conclusions. We made the unified dataset publicly available for everyone. By using a public dataset as an input for different bug prediction related investigations, researchers can make their studies reproducible, thus able to be validated and verified.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–21},
numpages = {10},
keywords = {Bug dataset, code metrics, static code analysis},
location = {Oulu, Finland},
series = {PROMISE'18}
}

@article{10.5555/3455716.3455897,
author = {Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E. and Stone, Peter},
title = {Curriculum learning for reinforcement learning domains: a framework and survey},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Reinforcement learning (RL) is a popular paradigm for addressing sequential decision tasks in which the agent has only limited environmental feedback. Despite many advances over the past three decades, learning in many domains still requires a large amount of interaction with the environment, which can be prohibitively expensive in realistic scenarios. To address this problem, transfer learning has been applied to reinforcement learning such that experience gained in one task can be leveraged when starting to learn the next, harder task. More recently, several lines of research have explored how tasks, or data samples themselves, can be sequenced into a curriculum for the purpose of learning a problem that may otherwise be too difficult to learn from scratch. In this article, we present a framework for curriculum learning (CL) in reinforcement learning, and use it to survey and classify existing CL methods in terms of their assumptions, capabilities, and goals. Finally, we use our framework to find open problems and suggest directions for future RL curriculum learning research.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {181},
numpages = {50},
keywords = {curriculum learning, reinforcement learning, transfer learning}
}

@article{10.3233/JIFS-18473,
author = {Malhotra, Ruchika and Sharma, Anjali},
title = {Empirical assessment of feature selection techniques in defect prediction models using web applications},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-18473},
doi = {10.3233/JIFS-18473},
abstract = {&nbsp;In order to minimize the over-fitting and related factors that are caused by the high dimensionality of the input data in software defect prediction, the attributes are often optimized using various feature selection techniques. However, the comparative performance of these selection techniques in combination with machine learning algorithms remains largely unexplored using web applications. In this work, we investigate the best possible combination of feature selection technique with machine learning algorithms, with the sample space chosen from open source Apache Click and Rave data sets. Our results are based on 945 defect prediction models derived from parametric, non-parametric and ensemble-based machine learning algorithms, for which the metrics are derived from the various filter and threshold-based ranking techniques. Friedman and Nemenyi post-hoc statistical tests are adopted to identify the performance difference of these models. We find that filter-based feature selection in combination with ensemble-based machine learning algorithms not only poise as the best strategy but also yields a maximum feature set redundancy by 94%, with little or no comprise on the performance index.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6567–6578},
numpages = {12},
keywords = {Feature selection, feature ranking, machine learning, web application quality}
}

@article{10.1016/j.cie.2020.106358,
author = {Hsu, Chia-Yu and Chen, Wei-Ju and Chien, Ju-Chien},
title = {Similarity matching of wafer bin maps for manufacturing intelligence to empower Industry 3.5 for semiconductor manufacturing},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2020.106358},
doi = {10.1016/j.cie.2020.106358},
journal = {Comput. Ind. Eng.},
month = apr,
numpages = {14},
keywords = {Wafer bin map, Yield enhancement, Defect diagnosis, Similarity, Manufacturing intelligence, Industry 3.5}
}

@inproceedings{10.1145/2499393.2499395,
author = {Herbold, Steffen},
title = {Training data selection for cross-project defect prediction},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499395},
doi = {10.1145/2499393.2499395},
abstract = {Software defect prediction has been a popular research topic in recent years and is considered as a means for the optimization of quality assurance activities. Defect prediction can be done in a within-project or a cross-project scenario. The within-project scenario produces results with a very high quality, but requires historic data of the project, which is often not available. For the cross-project prediction, the data availability is not an issue as data from other projects is readily available, e.g., in repositories like PROMISE. However, the quality of the defect prediction results is too low for practical use. Recent research showed that the selection of appropriate training data can improve the quality of cross-project defect predictions. In this paper, we propose distance-based strategies for the selection of training data based on distributional characteristics of the available data. We evaluate the proposed strategies in a large case study with 44 data sets obtained from 14 open source projects. Our results show that our training data selection strategy improves the achieved success rate of cross-project defect predictions significantly. However, the quality of the results still cannot compete with within-project defect prediction.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {6},
numpages = {10},
keywords = {cross-project prediction, defect-prediction, machine learning},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@article{10.1504/ijbm.2021.112219,
author = {Gao, Feng and Luo, Daizhong and Ma, Xinqiang},
title = {Research on facial expression recognition of video stream based on OpenCV},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {1},
issn = {1755-8301},
url = {https://doi.org/10.1504/ijbm.2021.112219},
doi = {10.1504/ijbm.2021.112219},
abstract = {In order to overcome the poor performance of expression similarity measurement in traditional video stream facial expression recognition methods, an OpenCV based facial expression recognition method is proposed. In this method, the video stream face detection image is obtained by the window detection of various features in each position for the video stream image through the cascade classifier, and the image preprocessing is implemented. Based on OpenCV, the most important eyes and mouth in the facial expression are modeled, the eye feature model and mouth feature model are constructed, and the facial expression recognition of the video stream is realised through the constructed model. The experimental results show that the performance of expression similarity measurement is better, and the recognition rate of different expressions is more than 90%.},
journal = {Int. J. Biometrics},
month = jan,
pages = {114–129},
numpages = {15},
keywords = {OpenCV, video stream, face, facial expression recognition}
}

@article{10.1016/j.micpro.2020.103807,
author = {Liu, Zhichao and Qu, Baida},
title = {Machine vision based online detection of PCB defect},
year = {2021},
issue_date = {Apr 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {82},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103807},
doi = {10.1016/j.micpro.2020.103807},
journal = {Microprocess. Microsyst.},
month = apr,
numpages = {9},
keywords = {Machine vision, PCB defect, Visual detection algorithm, Mathematical morphology, Defect detection}
}

@article{10.1007/s10462-017-9610-2,
author = {Karaboga, Dervis and Kaya, Ebubekir},
title = {Adaptive network based fuzzy inference system (ANFIS) training approaches: a comprehensive survey},
year = {2019},
issue_date = {Dec 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9610-2},
doi = {10.1007/s10462-017-9610-2},
abstract = {In the structure of ANFIS, there are two different parameter groups: premise and consequence. Training ANFIS means determination of these parameters using an optimization algorithm. In the first ANFIS model developed by Jang, a hybrid learning approach was proposed for training. In this approach, while premise parameters are determined by using gradient descent (GD), consequence parameters are found out with least squares estimation (LSE) method. Since ANFIS has been developed, it is used in modelling and identification of numerous systems and successful results have been achieved. The selection of optimization method utilized in training is very important to get effective results with ANFIS. It is seen that derivate based (GD, LSE etc.) and non-derivative based (heuristic algorithms such us GA, PSO, ABC etc.) algorithms are used in ANFIS training. Nevertheless, it has been observed that there is a trend toward heuristic based ANFIS training algorithms for better performance recently. At the same time, it seems to be proposed in derivative and heuristic based hybrid algorithms. Within the scope of this study, the heuristic and hybrid approaches utilized in ANFIS training are examined in order to guide researchers in their study. In addition, the final status in ANFIS training is evaluated and it is aimed to shed light on further studies related to ANFIS training.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {2263–2293},
numpages = {31},
keywords = {ANFIS, ANFIS training approaches, Heuristic algorithms, Derivate based algorithms}
}

@inproceedings{10.1145/3397481.3450678,
author = {Reyes, Guillermo and Alles, Alexandra},
title = {Multi-modal Multi-scale Attention Guidance in Cyber-Physical Environments},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450678},
doi = {10.1145/3397481.3450678},
abstract = {This work proposes a new method for guiding a user’s attention towards objects of interest in a cyber-physical environment (CPE). CPEs are environments that contain several computing systems that interact with each other and with the physical world. These environments contain several sensors (cameras, eye trackers, etc.) and output devices (lamps, screens, speakers, etc.). These devices can be used to first track the user’s position, orientation, and focus of attention to then find the most suitable output device to guide the user’s attention towards a target object. We argue that the most suitable device in this context is the one that attracts attention closest to the target and is salient enough to capture the user’s attention. The method is implemented as a function which estimates the ”closeness” and ”salience” of each visual and auditive output device in the environment. Some parameters of this method are then evaluated through a user study in the context of a virtual reality supermarket. The results show that multi-modal guidance can lead to better guiding performance. However, this depends on the set parameters.},
booktitle = {Proceedings of the 26th International Conference on Intelligent User Interfaces},
pages = {356–365},
numpages = {10},
keywords = {Attention, Attention Guidance, Cyber-Physical Environments, Intelligent Environments, Multi-modal, Multi-scale},
location = {College Station, TX, USA},
series = {IUI '21}
}

@article{10.1016/j.procs.2018.05.082,
author = {Hitesh and Kumari, A. Charan},
title = {Feature Selection Optimization in SPL using Genetic Algorithm},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.082},
doi = {10.1016/j.procs.2018.05.082},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1477–1486},
numpages = {10},
keywords = {Software product line, Genetic Algorithm, Feature Model, Software Product Line Engineering}
}

@inproceedings{10.1007/978-3-030-90525-5_48,
author = {Pahwa, Ramanpreet Singh and Chang, Richard and Jie, Wang and Satini, Sankeerthana and Viswanathan, Chandrashekar and Yiming, Du and Jain, Vernica and Pang, Chen Tai and Wah, Wan Kong},
title = {A Survey on Object Detection Performance with Different Data Distributions},
year = {2021},
isbn = {978-3-030-90524-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90525-5_48},
doi = {10.1007/978-3-030-90525-5_48},
abstract = {Detecting objects in a dynamic scene is a critical step for robotic navigation. A mobile robot may need to slow down in presence of children, elderly or dense crowds. A robot’s movement needs to be precise and socially adjustable especially in a hospital setting. Identifying key objects in a scene can provide important contextual awareness to a robot. Traditional approaches used handcrafted features along with object proposals to detect objects in images. Recently, object detection has made tremendous progress over the past few years thanks to deep learning and convolutional neural networks. Networks such as SSD, YOLO, and Faster R-CNN have made significant improvements over traditional techniques while maintaining real-time inference speed. However, current existing datasets used for benchmarking these models tend to contain mainly outdoor images using a high-quality camera setup that is usually different from a robotic vision setting where a robot moves around in a dynamic environment resulting in sensor noise, motion blur, and change in data distribution. In this work, we introduce our custom dataset collected in a realistic hospital environment consisting of distinct objects such as hospital beds, tables, and wheelchairs. We also use state-of-art object detectors to showcase the current performance and gaps in a robotic vision setting using our custom CHART dataset and other public datasets.},
booktitle = {Social Robotics: 13th International Conference, ICSR 2021, Singapore, Singapore,  November 10–13, 2021, Proceedings},
pages = {553–563},
numpages = {11},
keywords = {Object detection, Robotic vision, Contextual understanding and navigation},
location = {Singapore, Singapore}
}

@inproceedings{10.1007/978-3-030-58802-1_45,
author = {Han, Yohan and Jeong, Jongpil},
title = {Real-Time Inspection of Multi-sided Surface Defects Based on PANet Model},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_45},
doi = {10.1007/978-3-030-58802-1_45},
abstract = {Quality of products is the most important factor in manufacturing. Machine vision is a technique that mainly performs human cognitive judgment in the industrial field or performs a task that is generally difficult for a human. However the detection of traditional methods of scanning with human eyes has many difficulties due to repetitive tasks. Recently, an artificial intelligence machine vision has been studied to improve these problems. Using the vision inspection system, it is possible to collect information such as the number of products, defect detection, and types without human intervention, which maximizes the operation-al efficiency of a company such as productivity improvement, quality improvement, and cost reduction. Most of the vision inspection systems currently in use are single-sided images, which collect and inspect one image of the product. However, in the actual manufacturing industry, products that are valid for single-sided image inspection are limited to some product groups, and most require multi-sided image inspection. In addition, the inspection system used in the field must meet the production speed required by the actual manufacturing site and inspect the defects of the product. In this paper, we propose a deep neural network-based vision inspection system that satisfies the multi-sided image inspection and fast production speed of products. By implementing seven cameras and optical technology, multi-sided images of the product are collected simultaneously, and a defect in the product can be quickly detected in real time using a PANet (Path Aggregation Network) model. Through the proposed system, it is possible to inspect product defects at the level required at the manufacturing site, and the information obtained in the inspection process will be used as a very important data to evaluate and improve product quality.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {623–633},
numpages = {11},
keywords = {AI, Deep learning, Machine vision, Defect inspection, PANet},
location = {Cagliari, Italy}
}

@article{10.1007/s10845-020-01566-1,
author = {Du, Wangzhe and Shen, Hongyao and Fu, Jianzhong and Zhang, Ge and Shi, Xuanke and He, Quan},
title = {Automated detection of defects with low semantic information in X-ray images based on deep learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01566-1},
doi = {10.1007/s10845-020-01566-1},
abstract = {Nondestructive testing using X-ray imaging has been widely adopted in the defect detection of casting parts for quality management. Deep learning has been proved to be an effective way to detect defects in X-ray images. In this work, Feature Pyramid Network (FPN) which has been utilized broadly in many applications is adopted as our baseline. In FPN, there mainly exits two issues: firstly, down sampling operation in Convolutional Neural Network is often utilized to enhance the perception field, causing the loss of location information in feature maps, and secondly, there exists feature imbalance in feature maps and proposals. DetNet and Path Aggregation Network are adopted to solve the two shortages. To further improve the recall rate, soft Non-Maximum Suppression (soft-NMS) is adopted to remain more proposals that have high classification confidence. Defects in X-ray images of casting parts are provided with low semantic information, causing the different instances between detection results and annotations in the same area. We propose soft Intersection Over Union (soft-IOU) criterion which could evaluate several results or ground truths in the near area, making it more accurate to evaluate detection results. The experimental results demonstrate that the three proposed strategies have better performance than the baseline for our dataset.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {141–156},
numpages = {16},
keywords = {Defect detection, Casting parts, Deep learning, X-ray image, Computer vision}
}

@inproceedings{10.23919/ICCAS52745.2021.9650006,
author = {Jin, Seongho and Bang, Jinwook and Lee, Jangmyung},
title = {Determination of Defects for Dynamic Objects Using Instance Segmentation},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICCAS52745.2021.9650006},
doi = {10.23919/ICCAS52745.2021.9650006},
abstract = {As can be seen from what is also called an intelligent factory, the smart factory aims to maximize productivity or realize customized production by integrating and intelligentizing all manufacturing processes using IT. In this paper, object recognition/analysis using artificial intelligence in the smart factory is used for real-time quality inspection in the manufacturing process. Determining defects in the manufacturing process is a very important process. We use deep learning-based CNNs to build detection models for dynamic defect detection. To track the dynamic object placed on the conveyor, the camera is fixed to the object to be identified, and at the same time, the state of the object learned through deep learning is distinguished to determine the defect. Accordingly, a system for real-time tracking and defect determination on the analyzed defective quality goods is established.},
booktitle = {2021 21st International Conference on Control, Automation and Systems (ICCAS)},
pages = {739–742},
numpages = {4},
location = {Jeju, Korea, Republic of}
}

@article{10.1145/3464423,
author = {Fernando, Tharindu and Gammulle, Harshala and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
title = {Deep Learning for Medical Anomaly Detection – A Survey},
year = {2021},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3464423},
doi = {10.1145/3464423},
abstract = {Machine learning–based medical anomaly detection is an important problem that has been extensively studied. Numerous approaches have been proposed across various medical application domains and we observe several similarities across these distinct applications. Despite this comparability, we observe a lack of structured organisation of these diverse research applications such that their advantages and limitations can be studied. The principal aim of this survey is to provide a thorough theoretical analysis of popular deep learning techniques in medical anomaly detection. In particular, we contribute a coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms. Furthermore, we provide a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions. In addition, we outline the key limitations of existing deep medical anomaly detection techniques and propose key research directions for further investigation.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {141},
numpages = {37},
keywords = {Deep learning, anomaly detection, machine learning, temporal analysis}
}

@article{10.1016/j.rcim.2021.102183,
author = {Zhou, Jian and Wang, Dali and Chen, Jian and Feng, Zhili and Clarson, Blair and Baselhuhn, Amberlee},
title = {Autonomous nondestructive evaluation of resistance spot welded joints},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {72},
number = {C},
issn = {0736-5845},
url = {https://doi.org/10.1016/j.rcim.2021.102183},
doi = {10.1016/j.rcim.2021.102183},
journal = {Robot. Comput.-Integr. Manuf.},
month = dec,
numpages = {10},
keywords = {Artificial intelligence, Nondestructive evaluation, Spot welding, Deep neural network, Autonomous prediction}
}

@inproceedings{10.1609/aaai.v33i01.33019446,
author = {Elmishali, Amir and Stern, Roni and Kalech, Meir},
title = {DeBGUer: a tool for bug prediction and diagnosis},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33019446},
doi = {10.1609/aaai.v33i01.33019446},
abstract = {In this paper, we present the DeBGUer tool, a web-based tool for prediction and isolation of software bugs. DeBGUer is a partial implementation of the Learn, Diagnose, and Plan (LDP) paradigm, which is a recently introduced paradigm for integrating Artificial Intelligence (AI) in the software bug detection and correction process. In LDP, a diagnosis (DX) algorithm is used to suggest possible explanations – diagnoses – for an observed bug. If needed, a test planning algorithm is subsequently used to suggest further testing. Both diagnosis and test planning algorithms consider a fault prediction model, which associates each software component (e.g., class or method) with the likelihood that it contains a bug. DeBGUer implements the first two components of LDP, bug prediction (Learn) and bug diagnosis (Diagnose). It provides an easy-to-use web interface, and has been successfully tested on 12 projects.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1161},
numpages = {6},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.5555/2525512.2525515,
author = {Cesare, Silvio and Xiang, Yang},
title = {Simseer and bugwise: web services for binary-level software similarity and defect detection},
year = {2013},
isbn = {9781921770258},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Simseer and Bugwise are online web services that perform binary program analysis: 1) Simseer identifies similarity between submitted executables based on similarity in the control flow of each binary. A software similarity service provides benefit in identifying malware variants and families, discovering software theft, and revealing plagiarism of software programs. Simseer additionally performs code packing detection and automated unpacking of hidden code using application-level emulation. Finally, Simseer uses the similarity information from a sample set to identify program relationships and families through visualization of an evolutionary tree. 2) Bugwise is a service that identifies software bugs and defects. To achieve this end, it performs decompilation and data flow analysis. Bugwise can identify a subset of use-after-free bugs and has already found defects in Debian Linux. Bugwise and Simseer are both built on Malwise, a platform of binary analysis.},
booktitle = {Proceedings of the Eleventh Australasian Symposium on Parallel and Distributed Computing - Volume 140},
pages = {21–29},
numpages = {9},
keywords = {bug detection, cloud computing, computer security, plagiarism detection, software similarity, software theft detection},
location = {Adelaide, Australia},
series = {AusPDC '13}
}

@inproceedings{10.1007/978-3-030-61609-0_40,
author = {Xia, Bangfeng and Zhang, Yueling and Chen, Weiting and Wang, Xiangfeng and Wang, Jiangtao},
title = {EdgeAugment: Data Augmentation by Fusing and Filling Edge Maps},
year = {2020},
isbn = {978-3-030-61608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61609-0_40},
doi = {10.1007/978-3-030-61609-0_40},
abstract = {Data augmentation is an effective technique for improving the accuracy of network. However, current data augmentation can not generate more diverse training data. In this article, we overcome this problem by proposing a novel form of data augmentation to fuse and fill different edge maps. The edge fusion augmentation pipeline consists of four parts. We first use the Sobel operator to extract the edge maps from the training images. Then a simple integrated strategy is used to integrate the edge maps extracted from different images. After that we use an edge fuse GAN (Generative Adversarial Network) to fuse the integrated edge maps to synthesize new edge maps. Finally, an edge filling GAN is used to fill the edge maps to generate new training images. This augmentation pipeline can augment data effectively by making full use of the features from training set. We verified our edge fusion augmentation pipeline on different datasets combining with different edge integrated strategies. Experimental results illustrate a superior performance of our pipeline comparing to the existing work. Moreover, as far as we know, we are the first using GAN to augment data by fusing and filling feature from multiple edge maps.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part I},
pages = {504–516},
numpages = {13},
keywords = {Data augmentation, Adversarial generation networks, Deep learning, Convolution neural network},
location = {Bratislava, Slovakia}
}

@article{10.1023/B:SQJO.0000042059.16470.f0,
author = {Ohlsson, Niclas and Zhao, Ming and Helander, Mary},
title = {Application of multivariate analysis for software fault prediction},
year = {1998},
issue_date = {1998},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {7},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1023/B:SQJO.0000042059.16470.f0},
doi = {10.1023/B:SQJO.0000042059.16470.f0},
abstract = {Prediction of fault-prone modules provides one way to support software quality engineering through improved scheduling and project control. The primary goal of our research was to develop and refine techniques for early prediction of fault-prone modules. The objective of this paper is to review and improve an approach previously examined in the literature for building prediction models, i.e. principal component analysis (PCA) and discriminant analysis (DA). We present findings of an empirical study at Ericsson Telecom AB for which the previous approach was found inadequate for predicting the most fault-prone modules using software design metrics. Instead of dividing modules into fault-prone and not-fault-prone, modules are categorized into several groups according to the ordered number of faults. It is shown that the first discriminant coordinates (DC) statistically increase with the ordering of modules, thus improving prediction and prioritization efforts. The authors also experienced problems with the smoothing parameter as used previously for DA. To correct this problem and further improve predictability, separate estimation of the smoothing parameter is shown to be required.},
journal = {Software Quality Journal},
month = may,
pages = {51–66},
numpages = {16},
keywords = {empirical study, fault-prone modules, multivariate analysis, prediction, software design metrics}
}

@article{10.1007/s10664-020-09853-4,
author = {Hajri, Ines and Goknil, Arda and Pastore, Fabrizio and Briand, Lionel C.},
title = {Automating system test case classification and prioritization for use case-driven testing in product lines},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09853-4},
doi = {10.1007/s10664-020-09853-4},
abstract = {Product Line Engineering (PLE) is a crucial practice in many software development environments where software systems are complex and developed for multiple customers with varying needs. At the same time, many development processes are use case-driven and this strongly influences their requirements engineering and system testing practices. In this paper, we propose, apply, and assess an automated system test case classification and prioritization approach specifically targeting system testing in the context of use case-driven development of product families. Our approach provides: (i) automated support to classify, for a new product in a product family, relevant and valid system test cases associated with previous products, and (ii) automated prioritization of system test cases using multiple risk factors such as fault-proneness of requirements and requirements volatility in a product family. Our evaluation was performed in the context of an industrial product family in the automotive domain. Results provide empirical evidence that we propose a practical and beneficial way to classify and prioritize system test cases for industrial product lines.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3711–3769},
numpages = {59},
keywords = {Product Line Engineering, Use case driven development, Regression testing, Test case selection and prioritization, Automotive, Requirements engineering}
}

@inproceedings{10.1145/2915970.2916007,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {The jinx on the NASA software defect data sets},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916007},
doi = {10.1145/2915970.2916007},
abstract = {Background: The NASA datasets have previously been used extensively in studies of software defects. In 2013 Shepperd et al. presented an essential set of rules for removing erroneous data from the NASA datasets making this data more reliable to use.Objective: We have now found additional rules necessary for removing problematic data which were not identified by Shepperd et al.Results: In this paper, we demonstrate the level of erroneous data still present even after cleaning using Shepperd et al.'s rules and apply our new rules to remove this erroneous data.Conclusion: Even after systematic data cleaning of the NASA MDP datasets, we found new erroneous data. Data quality should always be explicitly considered by researchers before use.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {13},
numpages = {5},
keywords = {data quality, machine learning, software defect prediction},
location = {Limerick, Ireland},
series = {EASE '16}
}

@article{10.1016/j.compind.2016.09.002,
author = {Mera, Carlos and Orozco-Alzate, Mauricio and Branch, John and Mery, Domingo},
title = {Automatic visual inspection},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {83},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2016.09.002},
doi = {10.1016/j.compind.2016.09.002},
abstract = {HighlightsAn approach for quality inspection with multi-instance learning is proposed.Using weakly labeled images reduces the labeling effort in quality inspection.Experiments show that the approach can be effectively used in real-world applications. One of the industrial applications of computer vision is automatic visual inspection. In the last decade, standard supervised learning methods have been used to detect defects in different kind of products. These methods are trained with a set of images where every image has to be manually segmented and labeled by experts in the application domain. These manual segmentations require a large amount of high quality delineations (on pixels), which can be time consuming and often a difficult task. Multi-instance learning (MIL), in contrast to standard supervised classifiers, avoids this task and can, therefore, be trained with weakly labeled images. In this paper, we propose an approach for the automatic visual inspection that uses MIL for defect detection. The approach has been tested with data from three artificial benchmark datasets and three real-world industrial scenarios: inspection of artificial teeth, weld defect detection and fishbone detection. Results show that the proposed approach can be used with weakly labeled images for defect detection on automatic visual inspection systems. This approach is able to increase the area under the receiver-operating characteristic curve (AUC) up to 6.3% compared with the nave MIL approach of propagating the bag labels.},
journal = {Comput. Ind.},
month = dec,
pages = {46–54},
numpages = {9},
keywords = {Automatic visual inspection, Defect detection, Multi-instance learning, Pattern recognition, Weak labels}
}

@article{10.1155/2021/5298882,
author = {Meng, Meng and Zhu, Kun and Chen, Keqin and Qu, Hang and Perera, Ricardo},
title = {A Modified Fully Convolutional Network for Crack Damage Identification Compared with Conventional Methods},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5591},
url = {https://doi.org/10.1155/2021/5298882},
doi = {10.1155/2021/5298882},
abstract = {Large-scale structural health monitoring and damage detection of concealed underwater structures are always the urgent and state-of-art problems to be solved in the field of civil engineering. With the development of artificial intelligence especially the combination of deep learning and computer vision, greater advantages have been brought to the concrete crack detection based on convolutional neural network (CNN) over the traditional methods. However, these machine learning (ML) methods still have some defects, such as it being inaccurate or not strong, having poor generalization ability, or the accuracy still needs to be improved, and the running speed is slow. In this article, a modified fully convolutional network (FCN) with more robustness and more effectiveness is proposed, which makes it convenient and low cost for long-term structural monitoring and inspection compared with other methods. Meanwhile, to improve the accuracy of recognition and prediction, innovations were conducted in this study as follows. Moreover, differed from the common simple deconvolution, it also includes a subpixel convolution layer, which can greatly reduce the sampling time. Then, the proposed method was verified its practicability with the overall recognition accuracy reaching up to 97.92% and 12% efficiency improvement.},
journal = {Model. Simul. Eng.},
month = jan,
numpages = {14}
}

@inproceedings{10.5555/645526.657125,
author = {Cohen, William W. and Devanbu, Premkumar T.},
title = {A Comparative Study of Inductive Logic Programming Methods for Software Fault Prediction},
year = {1997},
isbn = {1558604863},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Fourteenth International Conference on Machine Learning},
pages = {66–74},
numpages = {9},
series = {ICML '97}
}

@article{10.1016/j.engappai.2019.09.003,
author = {Tan, Juan},
title = {Complex object detection using deep proposal mechanism},
year = {2020},
issue_date = {Jan 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {87},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.09.003},
doi = {10.1016/j.engappai.2019.09.003},
journal = {Eng. Appl. Artif. Intell.},
month = jan,
numpages = {6},
keywords = {Object detection, Region proposal, Deep convolutional neural network, Joint learning}
}

@inproceedings{10.1145/2499393.2499398,
author = {Calikli, Gul and Bener, Ayse},
title = {An algorithmic approach to missing data problem in modeling human aspects in software development},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499398},
doi = {10.1145/2499393.2499398},
abstract = {Background: In our previous research, we built defect prediction models by using confirmation bias metrics. Due to confirmation bias developers tend to perform unit tests to make their programs run rather than breaking their code. This, in turn, leads to an increase in defect density. The performance of prediction model that is built using confirmation bias was as good as the models that were built with static code or churn metrics.Aims: Collection of confirmation bias metrics may result in partially "missing data" due to developers' tight schedules, evaluation apprehension and lack of motivation as well as staff turnover. In this paper, we employ Expectation-Maximization (EM) algorithm to impute missing confirmation bias data.Method: We used four datasets from two large-scale companies. For each dataset, we generated all possible missing data configurations and then employed Roweis' EM algorithm to impute missing data. We built defect prediction models using the imputed data. We compared the performances of our proposed models with the ones that used complete data.Results: In all datasets, when missing data percentage is less than or equal to 50% on average, our proposed model that used imputed data yielded performance results that are comparable with the performance results of the models that used complete data.Conclusions: We may encounter the "missing data" problem in building defect prediction models. Our results in this study showed that instead of discarding missing or noisy data, in our case confirmation bias metrics, we can use effective techniques such as EM based imputation to overcome this problem.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {10},
numpages = {10},
keywords = {confirmation bias, expectation maximisation (EM) algorithm, handling missing data, software defect prediction},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@article{10.1007/s11063-021-10607-6,
author = {Kassaymeh, Sofian and Abdullah, Salwani and Al-Laham, Mohamad and Alweshah, Mohammed and Al-Betar, Mohammed Azmi and Othman, Zalinda},
title = {Salp Swarm Optimizer for Modeling Software Reliability Prediction Problems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {6},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-021-10607-6},
doi = {10.1007/s11063-021-10607-6},
abstract = {In this paper, software effort prediction (SEP) and software test prediction (STP) (i.e., software reliability problems) are tackled by integrating the salp swarm algorithm (SSA) with a backpropagation neural network (BPNN). Software effort and test prediction problems are common in software engineering and arise when seeking to determine the actual software resources needed to develop a project. BPNN is the most popular prediction algorithm used in the literature. The performance of BPNN depends totally on the initial parameter values such as weight and biases. The main objective of this paper is to integrate SSA with the BPNN to find the optimal weight for every training cycle and thereby improve prediction accuracy. The proposed method, abbreviated as SSA-BPNN, is tested on twelve SEP datasets and two STP datasets. All datasets vary in terms of complexity and size. The results obtained by SSA-BPNN are evaluated according to twelve performance measures: MSE, RMSE, RAE, RRSE, MAE, MRE, MMRE, MdMRE, VAF(%), R2(%), ED, and MD. First, the results obtained by BPNN with SSA (i.e., SSA-BPNN) and without SSA are compared. The evaluation of the results indicates that SSA-BPNN performs better than BPNN for all datasets. In the comparative evaluation, the results of SSA-BPNN are compared against thirteen state-of-the-art methods using the same SEP and STP problem datasets. The evaluation of the results reveals that the proposed method outperforms the comparative methods for almost all datasets, both SEP and STP, in the case of most performance measures. In conclusion, integrating SSA with BPNN is a very powerful approach for solving software reliability problems that can be used widely to yield accurate prediction results.},
journal = {Neural Process. Lett.},
month = dec,
pages = {4451–4487},
numpages = {37},
keywords = {Machine learning, Salp swarm optimizer, Backpropagation neural network, Software reliability problems, Software effort estimation, Software test estimation}
}

@inproceedings{10.1145/3368089.3409754,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Is neuron coverage a meaningful measure for testing deep neural networks?},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409754},
doi = {10.1145/3368089.3409754},
abstract = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–862},
numpages = {12},
keywords = {Adversarial Attack, Machine Learning, Neuron Coverage, Software Engineering, Testing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1016/j.jss.2017.06.070,
author = {Yu, Qiao and Jiang, Shujuan and Zhang, Yanmei},
title = {A feature matching and transfer approach for cross-company defect prediction},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.06.070},
doi = {10.1016/j.jss.2017.06.070},
abstract = {A feature matching algorithm is designed to address the heterogeneous features.A feature matching and transfer (FMT) approach for cross-company defect prediction.An empirical study is conducted on 16 datasets from NASA and PROMISE.The results show that FMT is effective for cross-company defect prediction. Software defect prediction has drawn much attention of researchers in software engineering. Traditional defect prediction methods aim to build the prediction model based on historical data. For a new project or a project with limited historical data, we cannot build a good prediction model. Therefore, researchers have proposed the cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) methods to share the historical data among different projects. However, the features of cross-company datasets are often heterogeneous, which may affect the feasibility of CCDP. To address the heterogeneous features of CCDP, this paper presents a feature matching and transfer (FMT) approach. First, we conduct feature selection for the source project and get the distribution curves of selected features. Similarly, we also get the distribution curves of all features in the target project. Second, according to the distance of different distribution curves, we design a feature matching algorithm to convert the heterogeneous features into the matched features. Finally, we can achieve feature transfer from the source project to the target project. All experiments are conducted on 16 datasets from NASA and PROMISE, and the results show that FMT is effective for CCDP.},
journal = {J. Syst. Softw.},
month = oct,
pages = {366–378},
numpages = {13},
keywords = {Feature matching, Feature transfer, Heterogeneous features, Software defect prediction}
}

@inproceedings{10.5555/647460.726104,
author = {Knudsen, Bengt R.},
title = {Fault Prediction in the Telephone Access Loop Using a Neural Network},
year = {1998},
isbn = {3540645756},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 12th Biennial Conference of the Canadian Society for Computational Studies of Intelligence on Advances in Artificial Intelligence},
pages = {239–245},
numpages = {7},
series = {AI '98}
}

@article{10.1007/s10845-021-01845-5,
author = {Le-Hong, Thai and Lin, Pai Chen and Chen, Jian-Zhong and Pham, Thinh Duc Quy and Van Tran, Xuan},
title = {Data-driven models for predictions of geometric characteristics of bead fabricated by selective laser melting},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01845-5},
doi = {10.1007/s10845-021-01845-5},
abstract = {In this paper, the effects of two key process parameters of the selective laser melting process, namely laser power and scanning speed, on the single-track morphologies and the bead characteristics, especially the depth-to-width D/W and height-to-width H/W ratios, were investigated using both experimental and Machine Learning (ML) approaches. A total of 840 single tracks were fabricated with several combinations of laser power and scanning speed levels. Surface morphologies of the single tracks and bead profiles were thoroughly investigated, providing a track-type map and the evolutions of the bead characteristics as a function of laser power and scanning speed. The results indicate neither severe balling nor keyholing effect for all combinations of laser power and scanning speed. Besides, simple relationships cannot accurately describe the evolutions of the D/W and H/W ratios as a function of laser power and scanning speed. Two Machine Learning-based regression models, Random Forest and Artificial Neural Network, were chosen to estimate the D/W and H/W ratios using laser power and scanning speed. The Bayesian optimization algorithm was employed to optimize the model hyperparameter selection. Both Machine Learning-based models appear to be able to predict reasonably well the two aspect ratios, D/W and H/W, with an overall R2 value reaching about 90%, evaluated on the cross-validation dataset after a few seconds of training time, respectively.},
journal = {J. Intell. Manuf.},
month = sep,
pages = {1241–1257},
numpages = {17},
keywords = {Selective melting laser, Bead geometry, Single-track morphology, Machine learning, Artificial neural network, Bayesian optimization}
}

@inproceedings{10.1609/aaai.v33i01.33019005,
author = {Wu, Xiang and Huang, Huaibo and Patel, Vishal M. and He, Ran and Sun, Zhenan},
title = {Disentangled variational representation for heterogeneous face recognition},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33019005},
doi = {10.1609/aaai.v33i01.33019005},
abstract = {Visible (VIS) to near infrared (NIR) face matching is a challenging problem due to the significant domain discrepancy between the domains and a lack of sufficient data for training cross-modal matching algorithms. Existing approaches attempt to tackle this problem by either synthesizing visible faces from NIR faces, extracting domain-invariant features from these modalities, or projecting heterogeneous data onto a common latent space for cross-modal matching. In this paper, we take a different approach in which we make use of the Disentangled Variational Representation (DVR) for cross-modal matching. First, we model a face representation with an intrinsic identity information and its within-person variations. By exploring the disentangled latent variable space, a variational lower bound is employed to optimize the approximate posterior for NIR and VIS representations. Second, aiming at obtaining more compact and discriminative disentangled latent space, we impose a minimization of the identity information for the same subject and a relaxed correlation alignment constraint between the NIR and VIS modality variations. An alternative optimization scheme is proposed for the disentangled variational representation part and the heterogeneous face recognition network part. The mutual promotion between these two parts effectively reduces the NIR and VIS domain discrepancy and alleviates over-fitting. Extensive experiments on three challenging NIR-VIS heterogeneous face recognition databases demonstrate that the proposed method achieves significant improvements over the state-of-the-art methods.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1105},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1145/3438872.3439065,
author = {Bin, Li and Dengli, Yi and Ruyi, Zhao},
title = {On-line Detection System Research of Hot-rolled Slab Based on Robot},
year = {2020},
isbn = {9781450388306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3438872.3439065},
doi = {10.1145/3438872.3439065},
abstract = {Hot-rolled slab number plays an important role in the production process as the identity identification of hot-rolled slab. Slab quality directly affects and determines the quality of subsequent products. Therefore, the detection of hot-rolled slab defects and identification of slab number play an important role in the billet production process. At present, most of the defects detection of hot-rolled slab in our country still use the method of manual detection to sample and inspect the hot-rolled slab. Therefore, it is imperative to design an automatic detection system to automatically detect the surface defects of steel plate and improve the detection rate the traditional manual record number and sampling quality testing methods of steel mills have been unable to meet the actual production needs. This paper studies on-line detection system of hot-rolled slab based on ABB robot.In this paper, ABB robot, CCD camera, sensor and other hardware equipment are constructed, and digital image processing technology is used to study and design the number identification and surface defect detection system of hot-rolled slab. The functions of number identification and surface defect detection of hot rolled billet are realized. The serial number and surface defect image collection of hot-rolled billet are realized by CCD camera installed on ABB robot, and the movement trajectory of the robot is controlled by software programming to achieve the billet multi-angle shooting and image collection. Using OpenCV as the image processing software, preprocess the collected image information, including image noise reduction, locking the billet area and extracting the billet end face image. The system greatly improves the production efficiency, Product quality and safety of the steel plant.},
booktitle = {Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {111–114},
numpages = {4},
keywords = {ABB robot, Detection system, Hot-rolled slab, OpenCV},
location = {Shanghai, China},
series = {RICAI '20}
}

@article{10.1007/s11042-020-09915-1,
author = {Singh, Om Dev and Malik, Anjali and Yadav, Vishakha and Gupta, Shailender and Dora, Shirin},
title = {Deep Segmenter system for recognition of micro cracks in solar cell},
year = {2021},
issue_date = {Feb 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {5},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09915-1},
doi = {10.1007/s11042-020-09915-1},
abstract = {A solar panel is array of Photo-Voltaic modules (PVC) that are mounted together in a mechanical frame and are placed in the open fields so that sunlight impinges on those cells to produce electricity. The effectiveness of solar panels is cogently restricted by the impurities and defects present in the PVC. These imperfections bring profound energy levels in the semiconductor bandgap, depreciating the carrier lifetime and quantum efficiency of cells. It is significant to recognize the defects physics so that apposite methods may be employed to restrain the formation of severe flaws. In various past techniques, image processing, machine learning, and deep learning techniques are implemented to recognize, classify, or predict the probability of defects and their effect on PVC’s overall performance. One of these approaches is an automatic recognition of micro-cracks, which is a compelling but challenging task. To achieve this, a deep learning approach based on the classification and segmentation process is proposed in this paper. This mechanism not only detects the micro-cracks but also effectively locates the area of the defected pixels. For the categorization of defects, VGG16 is used as a CNN classifier, and a Deep crack approach for the segmentation process is used. Thresholding and Decision Making are added to remove redundant pixels related to diverse types of frames present in PVC’s, and finally, a decision is made. An unsharp filter is utilized because of efficient performance. This technique exhibits effective results in decision making, whether the solar cell needs to be replaced or not based on the percentage area of irregularity. The proposed model outperforms state-of-the-art methods with better performance in all aspects.},
journal = {Multimedia Tools Appl.},
month = feb,
pages = {6509–6533},
numpages = {25},
keywords = {CNN, Classification, Crack detection, Deep Segmenter, Image processing, Machine learning, Segmentation, Solar panel, Unsharp filter, VGG16}
}

@article{10.1504/ijcvr.2021.115162,
author = {Liang, Qiaokang and Xiang, Shao and Long, Jianyong and Zhang, Dan and Coppola, Gianmarc and Sun, Wei and Wang, Yaonan},
title = {Automatic defect inspection system for beer bottles based on deep residual learning},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {3},
issn = {1752-9131},
url = {https://doi.org/10.1504/ijcvr.2021.115162},
doi = {10.1504/ijcvr.2021.115162},
abstract = {Automatic detection of defects in recyclable beer bottles would reduce both the cost of the production process and the time spent in the quality inspection. A novel approach is proposed for automatic detection of defects occurring on the beer bottles by deep residual learning. This method extracts the characteristic information of beer bottle defects through the deep learning network and realises the classification of defect characters. In this work, the recognition of three kinds of common defects (defective body, defective mouth, and defective bottom) is realised, and the promising result demonstrated that the proposed method is capable of inspecting defects of beer bottles with outstanding accuracy. Particularly, a state-of-the-art convolutional neural network (CNN) was applied to the detection of beer bottle defects, which improved the accuracy of beer bottle detection comparing with traditional methods. Experimental results show that the new approach satisfies the requirement of defect detection and is able to improve the production efficiency.},
journal = {Int. J. Comput. Vision Robot.},
month = jan,
pages = {299–314},
numpages = {15},
keywords = {detection of defects, deep learning, convolutional neural network, CNN, quality inspection}
}

@inproceedings{10.1145/3325917.3325930,
author = {Zhang, Zhong and Zhang, Borui and Akiduki, Takuma},
title = {Specular reflection Surface Defects Detection by using Deep Learning},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325917.3325930},
doi = {10.1145/3325917.3325930},
abstract = {As you know that defects inspection of specular surface is very difficult because its specular reflection is very strong and defects' reflection is weaker. And the existing computer vision-based industrial parts surface defect detection methods are limited by environmental factors, and the image preprocessing process is complex. On the other hand, with the rapid development of Convolutional Neural Networks (CNN) that is one type of deep learning and has excellent performance for image processing, has led to the rapid development of computer vision research based on deep learning. In this paper, we proposed an ensemble CNN in which integrated two convolutional neural network models for surface defect detection, and obtained better results.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {6–10},
numpages = {5},
keywords = {Convolutional neural network, Defect detection, Machine vision, Networks, Specular surface},
location = {Houston, TX, USA},
series = {ICISDM '19}
}

@inproceedings{10.1007/978-3-030-58811-3_69,
author = {Hegedundefineds, P\'{e}ter},
title = {Inspecting JavaScript Vulnerability Mitigation Patches with Automated Fix Generation in Mind},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_69},
doi = {10.1007/978-3-030-58811-3_69},
abstract = {Software security has become a primary concern for both the industry and academia in recent years. As dependency on critical services provided by software systems grows globally, a potential security threat in such systems poses higher and higher risks (e.g. economical damage, a threat to human life, criminal activity).Finding potential security vulnerabilities at the code level automatically is a very popular approach to aid security testing. However, most of the methods based on machine learning and statistical models stop at listing potentially vulnerable code parts and leave their validation and mitigation to the developers. Automatic program repair could fill this gap by automatically generating vulnerability mitigation code patches. Nonetheless, it is still immature, especially in targeting security-relevant fixes.In this work, we try to establish a path towards automatic vulnerability fix generation techniques in the context of JavaScript programs. We inspect 361 actual vulnerability mitigation patches collected from vulnerability databases and GitHub. We found that vulnerability mitigation patches are not short on average and in many cases affect not just program code but test code as well. These results point towards that a general automatic repair approach targeting all the different types of vulnerabilities is not feasible. The analysis of the code properties and fix patterns for different vulnerability types might help in setting up a more realistic goal in the area of automatic JavaScript vulnerability repair.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {975–988},
numpages = {14},
keywords = {Security, Vulnerability, JavaScript, Prediction models, Automatic repair},
location = {Cagliari, Italy}
}

@article{10.1016/j.neucom.2015.09.011,
author = {Tong, Le and Wong, W.K. and Kwong, C.K.},
title = {Differential evolution-based optimal Gabor filter model for fabric inspection},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {173},
number = {P3},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.09.011},
doi = {10.1016/j.neucom.2015.09.011},
abstract = {In this paper, a defect detection model using optimized Gabor filters, which is suitable for real-time operation, is proposed to tackle the woven fabric inspection problem in fashion industry. Based on the analysis of the particular characteristics of fabric defects, the proposed model utilizes composite differential evolution (CoDE) to optimize the parameters of Gabor filters, which can achieve the optimal feature extraction of fabric defects. Together with thresholding and fusion operations, the optimal Gabor filters can successfully segment the defects from the original image background. By using optimal Gabor filters instead of a Gabor filter bank, the computational cost of the detection model can be significantly reduced. The performance of the proposed defect detection model is evaluated off-line through extensive experiments based on various types of fabric. Experimental results reveal that the proposed detection model is effective and robust, and is superior than four existing models in terms of the high detection rate and low false alarm rate.},
journal = {Neurocomput.},
month = jan,
pages = {1386–1401},
numpages = {16},
keywords = {Defect detection, Differential evolution, Fabric quality inspection, Optimal Gabor filters}
}

@article{10.1007/s10115-013-0721-z,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Detecting software design defects using relational association rule mining},
year = {2015},
issue_date = {March     2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {42},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-013-0721-z},
doi = {10.1007/s10115-013-0721-z},
abstract = {In this paper, we are approaching, from a machine learning perspective, the problem of automatically detecting defective software entities (classes and methods) in existing software systems, a problem of major importance during software maintenance and evolution. In order to improve the internal quality of a software system, identifying faulty entities such as classes, modules, methods is essential for software developers. As defective software entities are hard to identify, machine learning-based classification models are still developed to approach the problem of detecting software design defects. We are proposing a novel method based on relational association rule mining for detecting faulty entities in existing software systems. Relational association rules are a particular type of association rules and describe numerical orderings between attributes that commonly occur over a dataset. Our method is based on the discovery of relational association rules for identifying design defects in software. Experiments on open source software are conducted in order to detect defective classes in object-oriented software systems, and a comparison of our approach with similar existing approaches is provided. The obtained results show that our method is effective for software design defect detection and confirms the potential of our proposal.},
journal = {Knowl. Inf. Syst.},
month = mar,
pages = {545–577},
numpages = {33},
keywords = {Association rule mining, Data mining, Defect detection, Machine learning, Software design}
}

@inproceedings{10.1007/978-3-030-27538-9_44,
author = {Yu, Wenyong and Zhang, Yang and Shi, Hui},
title = {Surface Defect Inspection Under a Small Training Set Condition},
year = {2019},
isbn = {978-3-030-27537-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27538-9_44},
doi = {10.1007/978-3-030-27538-9_44},
abstract = {The detection of surface defects in industrial production is an important technology for controlling product quality. Many researchers have applied deep learning methods to the field of surface defect detection. However, obtaining defect sample data in industrial production is difficult, and the number of samples available to train detection networks is not sufficient. Based on the you only look once (YOLO) detection system, we propose a lightweight small sample detection network (SSDN) to overcome the problem of fewer samples in surface defect detection. The SSDN is demonstrated to be a suitable network to represent defect image features as it is better at feature extraction and easier to train. We used only 10/type images to train the SSDN model without data enhancement techniques and achieved excellent results (average accuracy 99.72%) on defect detection benchmark data. Experimental results verify the robustness of the model.},
booktitle = {Intelligent Robotics and Applications: 12th International Conference, ICIRA 2019, Shenyang, China, August 8–11, 2019, Proceedings, Part IV},
pages = {517–528},
numpages = {12},
keywords = {Surface detection, YOLO, Small training set, Machine vision},
location = {Shenyang, China}
}

@inproceedings{10.1145/3475716.3475790,
author = {Wang, Song and Wang, Junjie and Nam, Jaechang and Nagappan, Nachiappan},
title = {Continuous Software Bug Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475790},
doi = {10.1145/3475716.3475790},
abstract = {Background: Many software bug prediction models have been proposed and evaluated on a set of well-known benchmark datasets. We conducted pilot studies on the widely used benchmark datasets and observed common issues among them. Specifically, most of existing benchmark datasets consist of randomly selected historical versions of software projects, which poses non-trivial threats to the validity of existing bug prediction studies since the real-world software projects often evolve continuously. Yet how to conduct software bug prediction in the real-world continuous software development scenarios is not well studied.Aims: In this paper, to bridge the gap between current software bug prediction practice and real-world continuous software development, we propose new approaches to conduct bug prediction in real-world continuous software development regarding model building, updating, and evaluation.Method: For model building, we propose ConBuild, which leverages distributional characteristics of bug prediction data to guide the training version selection. For model updating, we propose ConUpdate, which leverages the evolution of distributional characteristics of bug prediction data between versions to guide the reuse or update of bug prediction models in continuous software development. For model evaluation, we propose ConEA, which leverages the evolution of buggy probability of files between versions to conduct effort-aware evaluation.Results: Experiments on 120 continuously release versions that span across six large-scale open-source software systems show the practical value of our approaches.Conclusions: This paper provides new insights and guidelines for conducting software bug prediction in the context of continuous software development.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {14},
numpages = {12},
keywords = {Empirical software engineering, continuous software development, software defect prediction, software quality},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3460319.3464819,
author = {Zeng, Zhengran and Zhang, Yuqun and Zhang, Haotian and Zhang, Lingming},
title = {Deep just-in-time defect prediction: how far are we?},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464819},
doi = {10.1145/3460319.3464819},
abstract = {Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {427–438},
numpages = {12},
keywords = {Deep Learning, Just-In-Time Prediction, Software Defect Prediction},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.1007/s11042-020-08976-6,
author = {Xiao, Youzi and Tian, Zhiqiang and Yu, Jiachen and Zhang, Yinshu and Liu, Shuai and Du, Shaoyi and Lan, Xuguang},
title = {A review of object detection based on deep learning},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {33–34},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-08976-6},
doi = {10.1007/s11042-020-08976-6},
abstract = {With the rapid development of deep learning techniques, deep convolutional neural networks (DCNNs) have become more important for object detection. Compared with traditional handcrafted feature-based methods, the deep learning-based object detection methods can learn both low-level and high-level image features. The image features learned through deep learning techniques are more representative than the handcrafted features. Therefore, this review paper focuses on the object detection algorithms based on deep convolutional neural networks, while the traditional object detection algorithms will be simply introduced as well. Through the review and analysis of deep learning-based object detection techniques in recent years, this work includes the following parts: backbone networks, loss functions and training strategies, classical object detection architectures, complex problems, datasets and evaluation metrics, applications and future development directions. We hope this review paper will be helpful for researchers in the field of object detection.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {23729–23791},
numpages = {63},
keywords = {Object detection, Deep learning, Deep convolutional neural networks, Computer vision}
}

@article{10.1007/s10270-020-00803-8,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming},
title = {A framework for automated multi-stage and multi-step product configuration of cyber-physical systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00803-8},
doi = {10.1007/s10270-020-00803-8},
abstract = {Product line engineering (PLE) has been employed to large-scale cyber-physical systems (CPSs) to provide customization based on users’ needs. A PLE methodology can be characterized by its support for capturing and managing the abstractions as commonalities and variabilities and the automation of the configuration process for effective selection and customization of reusable artifacts. The automation of a configuration process heavily relies on the captured abstractions and formally specified constraints using a well-defined modeling methodology. Based on the results of our previous work and a thorough literature review, in this paper, we propose a conceptual framework to support multi-stage and multi-step automated product configuration of CPSs, including a comprehensive classification of constraints and a list of automated functionalities of a CPS configuration solution. Such a framework can serve as a guide for researchers and practitioners to evaluate an existing CPS PLE solution or devise a novel CPS PLE solution. To validate the framework, we conducted three real-world case studies. Results show that the framework fulfills all the requirements of the case studies in terms of capturing and managing variabilities and constraints. Results of the literature review indicate that the framework covers all the functionalities concerned by the literature, suggesting that the framework is complete for enabling the maximum automation of configuration in CPS PLE.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {211–265},
numpages = {55},
keywords = {Cyber-physical systems, Product line engineering, Automated configuration, Multi-stage and multi-step configuration process, Constraint classification, Variability modeling, Real-world case studies}
}

@article{10.1007/s10586-019-03012-1,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e} and Ther\'{o}n, Roberto and Amo Filv\`{a}, Daniel and Fonseca Escudero, David},
title = {Connecting domain-specific features to source code: towards the automatization of dashboard generation},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-03012-1},
doi = {10.1007/s10586-019-03012-1},
abstract = {Dashboards are useful tools for generating knowledge and support decision-making processes, but the extended use of technologies and the increasingly available data asks for user-friendly tools that allow any user profile to exploit their data. Building tailored dashboards for any potential user profile would involve several resources and long development times, taking into account that dashboards can be framed in very different contexts that should be studied during the design processes to provide practical tools. This situation leads to the necessity of searching for methodologies that could accelerate these processes. The software product line paradigm is one recurrent method that can decrease the time-to-market of products by reusing generic core assets that can be tuned or configured to meet specific requirements. However, although this paradigm can solve issues regarding development times, the configuration of the dashboard is still a complex challenge; users’ goals, datasets, and context must be thoroughly studied to obtain a dashboard that fulfills the users’ necessities and that fosters insight delivery. This paper outlines the benefits and a potential approach to automatically configuring information dashboards by leveraging domain commonalities and code templates. The main goal is to test the functionality of a workflow that can connect external algorithms, such as artificial intelligence algorithms, to infer dashboard features and feed a generator based on the software product line paradigm.},
journal = {Cluster Computing},
month = sep,
pages = {1803–1816},
numpages = {14},
keywords = {SPL, Domain engineering, Meta-model, Information dashboards, Feature model, Artificial intelligence, Automatic configuration}
}

@article{10.5555/1283100.1283170,
author = {Plantier, Justin and Boutt\'{e}, Laurent and Lelandais, Sylvie},
title = {Defect detection on inclined textured planes using the shape from texture method and the Delaunay triangulation},
year = {2002},
issue_date = {January 2002},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2002},
number = {1},
issn = {1110-8657},
abstract = {We present one method for detecting defects on an inclined textured plane. This method uses a combination of a shape from texture (SFT) method with the Delaunay triangulation technique. The SFT method provides the theoretical equation of the plane orientation in two steps. First, a wavelet decomposition allows us to build an image of the inverse of the local frequency, that is the scale, that we call the local scales map. Then we perform an interpolation of this map using the equation of the theoretical variation of the scales. With the interpolation parameters it is possible to extract the texels by the use of an adaptive thresholding for each pixel of this map. Then we compute the centers of each texel in order to match a mesh on it after processing a Delaunay triangulation. When there is a defect, the regularity of the triangulation is disturbed, so one hole appears in the mesh.},
journal = {EURASIP J. Adv. Signal Process},
month = jan,
pages = {659–666},
numpages = {8}
}

@article{10.1007/s11334-015-0256-4,
author = {Valles-Barajas, Fernando},
title = {A comparative analysis between two techniques for the prediction of software defects: fuzzy and statistical linear regression},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0256-4},
doi = {10.1007/s11334-015-0256-4},
abstract = {Software engineers should estimate the necessary resources (time, people, software tools among others) to satisfy software project requirements; this activity is carried out in the planning phase. The estimated time for developing software projects is a necessary element to establish the cost of software projects and to assign human resources to every phase of software projects. Most companies fail to finish software projects on time because of a poor estimation technique or the lack of the same. The estimated time must consider the time spent eliminating software defects injected during each of the software phases. A comparative analysis between two techniques (fuzzy linear regression and statistical linear regression) to perform software defect estimation is presented. These two techniques model uncertainty in a different way; statistical linear regression models uncertainty as randomness, whereas fuzzy linear regression models uncertainty as fuzziness. The main objective of this paper was to establish the kind of uncertainty associated with software defect prediction and to contrast these two prediction techniques. The KC1 NASA data set was used to do this analysis. Only six of the metrics included in KC1 data set and lines of code metric were used in this comparative analysis. Descriptive statistics was first used to have an overview of the main characteristics of the data set used in this research. Linearity property between predictor variables and the variable of interest number of defects was checked using scatter plots and Pearson's correlation coefficient. Then the problem of multicollinearity was verified using inter-correlations among metrics and the variance inflation factor. Best subset regression was applied to detect the most influencing subset of predictor variables; this subset was later used to build fuzzy and statistical regression models. Linearity property between metrics and number of defects was confirmed. The problem of multicollinearity was not detected in the predictor variables. Best subset regression found that the subset composed of 5 variables was the most influencing subset. The analysis showed that the statistical regression model in general outperformed the fuzzy regression model. Techniques for making software defect prediction should be carefully employed in order to have quality plans. Software engineers should consider and understand a set of prediction techniques and know their weaknesses and strengths. At least, in the KC1 data set, the uncertainty in the software defect prediction model is due to randomness so it is reasonable to use statistical linear regression instead of fuzzy linear regression to build a prediction model.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {277–287},
numpages = {11},
keywords = {Fuzzy linear regression, Software defect prediction, Statistical linear regression}
}

@article{10.1016/j.compag.2021.106451,
author = {Dolata, Przemys\l{}aw and Wr\'{o}blewski, Pawe\l{} and Mrzyg\l{}\'{o}d, Mariusz and Reiner, Jacek},
title = {Instance segmentation of root crops and simulation-based learning to estimate their physical dimensions for on-line machine vision yield monitoring},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {190},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106451},
doi = {10.1016/j.compag.2021.106451},
journal = {Comput. Electron. Agric.},
month = nov,
numpages = {12},
keywords = {Yield estimation, Machine vision, Machine learning, Image segmentation, Synthetic dataset}
}

@article{10.1016/j.compag.2010.07.008,
author = {Ariana, Diwan P. and Lu, Renfu},
title = {Original paper: Hyperspectral waveband selection for internal defect detection of pickling cucumbers and whole pickles},
year = {2010},
issue_date = {October, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {74},
number = {1},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2010.07.008},
doi = {10.1016/j.compag.2010.07.008},
abstract = {Hyperspectral imaging under transmittance mode has shown potential for detecting internal defect, however, the technique still cannot meet the online speed requirement because of the need to acquire and analyze a large amount of image data. This study was carried out to select important wavebands for further development of an online inspection system to detect internal defect in pickling cucumbers and whole pickles. Hyperspectral transmittance/reflectance images were acquired from normal and defective cucumbers and whole pickles using a prototype hyperspectral reflectance (400-740nm)/transmittance (740-1000nm) imaging system. Up to four-waveband subsets were determined by a branch and bound algorithm combined with the k-nearest neighbor classifier. Different waveband binning operations were also compared to determine the bandwidth requirement for each waveband combination. The highest classification accuracies of 94.7 and 82.9% were achieved using the optimal four-waveband sets of 745, 805, 965, and 985nm at 20nm spectral resolution for cucumbers and of 745, 765, 885, and 965nm at 40nm spectral resolution for whole pickles, respectively. The selected waveband sets will be useful for online quality detection of pickling cucumbers and pickles.},
journal = {Comput. Electron. Agric.},
month = oct,
pages = {137–144},
numpages = {8},
keywords = {Cucumbers, Hyperspectral imaging, Internal defect, Near-infrared, Nondestructive, Pickles, Quality, Reflectance, Transmittance, Waveband selection}
}

@inproceedings{10.1145/3416505.3423563,
author = {Palma, Stefano Dalla and Mohammadi, Majid and Di Nucci, Dario and Tamburri, Damian A.},
title = {Singling the odd ones out: a novelty detection approach to find defects in infrastructure-as-code},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423563},
doi = {10.1145/3416505.3423563},
abstract = {Infrastructure-as-Code (IaC) is increasingly adopted. However, little is known about how to best maintain and evolve it. Previous studies focused on defining Machine-Learning models to predict defect-prone blueprints using supervised binary classification. This class of techniques uses both defective and non-defective instances in the training phase. Furthermore, the high imbalance between defective and non-defective samples makes the training more difficult and leads to unreliable classifiers. In this work, we tackle the defect-prediction problem from a different perspective using novelty detection and evaluate the performance of three techniques, namely OneClassSVM, LocalOutlierFactor, and IsolationForest, and compare their performance with a baseline RandomForest binary classifier. Such models are trained using only non-defective samples: defective data points are treated as novelty because the number of defective samples is too little compared to defective ones. We conduct an empirical study on an extremely-imbalanced dataset consisting of 85 real-world Ansible projects containing only small amounts of defective instances. We found that novelty detection techniques can recognize defects with a high level of precision and recall, an AUC-PR up to 0.86, and an MCC up to 0.31. We deem our results can influence the current trends in defect detection and put forward a new research path toward dealing with this problem.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {31–36},
numpages = {6},
keywords = {Defect Prediction, Infrastructure-as-Code, Novelty Detection},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@article{10.1145/3384517,
author = {Kapur, Ritu and Sodhi, Balwinder},
title = {A Defect Estimator for Source Code: Linking Defect Reports with Programming Constructs Usage Metrics},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3384517},
doi = {10.1145/3384517},
abstract = {An important issue faced during software development is to identify defects and the properties of those defects, if found, in a given source file. Determining defectiveness of source code assumes significance due to its implications on software development and maintenance cost.We present a novel system to estimate the presence of defects in source code and detect attributes of the possible defects, such as the severity of defects. The salient elements of our system are: (i) a dataset of newly introduced source code metrics, called PROgramming CONstruct (PROCON) metrics, and (ii) a novel Machine-Learning (ML)-based system, called Defect Estimator for Source Code (DESCo), that makes use of PROCON dataset for predicting defectiveness in a given scenario. The dataset was created by processing 30,400+ source files written in four popular programming languages, viz., C, C++, Java, and Python.The results of our experiments show that DESCo system outperforms one of the state-of-the-art methods with an improvement of 44.9%. To verify the correctness of our system, we compared the performance of 12 different ML algorithms with 50+ different combinations of their key parameters. Our system achieves the best results with SVM technique with a mean accuracy measure of 80.8%.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {12},
numpages = {35},
keywords = {AI in software engineering, Maintaining software, automated software engineering, software defect prediction, software faults and failures, software metrics, source code mining}
}

@inproceedings{10.5555/3367471.3367606,
author = {Yang, Liang and Chen, Zhiyang and Gu, Junhua and Guo, Yuanfang},
title = {Dual self-paced graph convolutional network: towards reducing attribute distortions induced by topology},
year = {2019},
isbn = {9780999241141},
publisher = {AAAI Press},
abstract = {The success of graph convolutional neural networks (GCNNs) based semi-supervised node classification is credited to the attribute smoothing (propagating) over the topology. However, the attributes may be interfered by the utilization of the topology information. This distortion will induce a certain amount of misclassifications of the nodes, which can be correctly predicted with only the attributes. By analyzing the impact of the edges in attribute propagations, the simple edges, which connect two nodes with similar attributes, should be given priority during the training process compared to the complex ones according to curriculum learning. To reduce the distortions induced by the topology while exploit more potentials of the attribute information, Dual Self-Paced Graph Convolutional Network (DSP-GCN) is proposed in this paper. Specifically, the unlabelled nodes with confidently predicted labels are gradually added into the training set in the node-level self-paced learning, while edges are gradually, from the simple edges to the complex ones, added into the graph during the training process in the edge-level self-paced learning. These two learning strategies are designed to mutually reinforce each other by coupling the selections of the edges and unlabelled nodes. Experimental results of transductive semi-supervised node classification on many real networks indicate that the proposed DSP-GCN has successfully reduced the attribute distortions induced by the topology while it gives superior performances with only one graph convolutional layer.},
booktitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence},
pages = {4062–4069},
numpages = {8},
location = {Macao, China},
series = {IJCAI'19}
}

@article{10.1007/s11042-018-6786-7,
author = {Liu, Li and Zhang, Jianhong and Fu, Xiaodong and Liu, Lijun and Huang, Qingsong},
title = {Unsupervised segmentation and elm for fabric defect image classification},
year = {2019},
issue_date = {May       2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {9},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-6786-7},
doi = {10.1007/s11042-018-6786-7},
abstract = {In order to solve the problem of low accuracy and efficiency for surface defects in common woven fabrics, a novel fabric defect classification method is proposed based on unsupervised segmentation and ELM. The classification method is divided into four steps including defect segmentation, feature extraction, ELM classifier training, and Bayesian probability fusion. Firstly, an unsupervised segmentation is presented for the Grayscale fabric defect image after preprocessing. Secondly, geometric and texture features were extracted by using the segmented image and the undivided Grayscale image. Then, features and labels in fabric defect images are considered as training sets to train the ELM classifier. Finally, the input fabric defect image is classified by the trained ELM classifier and the Bayesian probability fusion method. Experimental results show that the proposed method can classify the fabric defect image with high accuracy and efficiency that can better meet the requirements for practical applications.},
journal = {Multimedia Tools Appl.},
month = may,
pages = {12421–12449},
numpages = {29},
keywords = {Bayesian probability fusion, ELM classifier, Fabric defect detection, Image classification, Unsupervised segmentation}
}

@article{10.1504/ijiei.2021.118275,
author = {Mittal, Shruti and Nagpal, Chander Kumar},
title = {Reinforcement learning based predictive analytics framework for survival in stock market},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {3},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.118275},
doi = {10.1504/ijiei.2021.118275},
abstract = {Contemporary research in stock market domain is limited to forecasting of the stock price from one day to one week. Such small period predictions cannot be of much help for continuous gainful survival in the stock market. In fact, there has to be predictive analytics framework which analyses the current situation in the holistic manner and provides the appropriate advice for selling/buying/no action along with the quantity resulting in significant gain for the user/investor. The proposed framework generates various reinforcement signals by applying statistical and machine learning techniques on historical data and studies their impact on the stock prices by analysing future data. The outcome of the process has been used to generate rewards, through the use of fuzzy logic, for various actions in a given state of the environment. Fully automated implementation of the proposed framework can help both institutional and common investor in taking the rational decision.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {294–327},
numpages = {33},
keywords = {predictive analytics, statistical learning, machine learning, stock market predictions, reinforcement learning, fuzzy sets and logic, finite state machine, fuzzy rule base, stock fundamental, stock technical analysis, single value decomposition}
}

@article{10.1016/j.neucom.2017.02.024,
author = {Diez-Olivan, Alberto and Pagan, Jose A. and Sanz, Ricardo and Sierra, Basilio},
title = {Data-driven prognostics using a combination of constrained K-means clustering, fuzzy modeling and LOF-based score},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {241},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2017.02.024},
doi = {10.1016/j.neucom.2017.02.024},
abstract = {A data-driven prognostics approach for monitoring sensor data is proposed.It relies on a combination of constrained K-means clustering, fuzzy modeling and LOF-based score.Fully comprehensive yet accurate models are obtained and deployed in a CBM+ platform.The approach is tested on a real data set concerning a marine diesel engine.A very small percentage of real faults are present in data.Obtained precision, sensitivity and specificity are above 93% and Cohens kappa is 0.93. Today, failure modes characterization and early detection is a key issue in complex assets. This is due to the negative impact of corrective operations and the conservative strategies usually put in practice, focused on preventive maintenance. In this paper anomaly detection issue is addressed in new monitoring sensor data by characterizing and modeling operational behaviors. The learning framework is performed on the basis of a machine learning approach that combines constrained K-means clustering for outlier detection and fuzzy modeling of distances to normality. A final score is also calculated over time, considering the membership degree to resulting fuzzy sets and a local outlier factor. Proposed solution is deployed in a CBM+ platform for online monitoring of the assets. In order to show the validity of the approach, experiments have been conducted on real operational faults in an auxiliary marine diesel engine. Experimental results show a fully comprehensive yet accurate prognostics approach, improving detection capabilities and knowledge management. The performance achieved is quite high (precision, sensitivity and specificity above 93% and =0.93), even more so given that a very small percentage of real faults are present in data.},
journal = {Neurocomput.},
month = jun,
pages = {97–107},
numpages = {11},
keywords = {Behavior characterization, Condition monitoring, Constrained k-means clustering, Fuzzy modeling, Local outlier factor, Machine learning}
}

@inproceedings{10.1145/2362536.2362548,
author = {Soltani, Samaneh and Asadi, Mohsen and Ga\v{s}evi\'{c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
title = {Automated planning for feature model configuration based on functional and non-functional requirements},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362548},
doi = {10.1145/2362536.2362548},
abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {56–65},
numpages = {10},
keywords = {artificial intelligence, configuration, feature model, planning techniques, software product line engineering},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1016/j.eswa.2017.04.014,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Towards an ensemble based system for predicting the number of software faults},
year = {2017},
issue_date = {October 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {82},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.04.014},
doi = {10.1016/j.eswa.2017.04.014},
abstract = {Paper presents ensemble based system for the prediction of number of software faults.System is based on the heterogeneous ensemble method.System uses three fault prediction techniques as base learners for the ensemble.Results are verified on Eclipse datasets. Software fault prediction using different techniques has been done by various researchers previously. It is observed that the performance of these techniques varied from dataset to dataset, which make them inconsistent for fault prediction in the unknown software project. On the other hand, use of ensemble method for software fault prediction can be very effective, as it takes the advantage of different techniques for the given dataset to come up with better prediction results compared to individual technique. Many works are available on binary class software fault prediction (faulty or non-faulty prediction) using ensemble methods, but the use of ensemble methods for the prediction of number of faults has not been explored so far. The objective of this work is to present a system using the ensemble of various learning techniques for predicting the number of faults in given software modules. We present a heterogeneous ensemble method for the prediction of number of faults and use a linear combination rule and a non-linear combination rule based approaches for the ensemble. The study is designed and conducted for different software fault datasets accumulated from the publicly available data repositories. The results indicate that the presented system predicted number of faults with higher accuracy. The results are consistent across all the datasets. We also use prediction at level l (Pred(l)), and measure of completeness to evaluate the results. Pred(l) shows the number of modules in a dataset for which average relative error value is less than or equal to a threshold value l. The results of prediction at level l analysis and measure of completeness analysis have also confirmed the effectiveness of the presented system for the prediction of number of faults. Compared to the single fault prediction technique, ensemble methods produced improved performance for the prediction of number of software faults. Main impact of this work is to allow better utilization of testing resources helping in early and quick identification of most of the faults in the software system.},
journal = {Expert Syst. Appl.},
month = oct,
pages = {357–382},
numpages = {26},
keywords = {Empirical study, Genetic programming, Gradient boosting, Linear regression, Promise repository, Software fault prediction techniques}
}

@inproceedings{10.5555/3367243.3367442,
author = {Li, Longyuan and Yan, Junchi and Yang, Xiaokang and Jin, Yaohui},
title = {Learning interpretable deep state space model for probabilistic time series forecasting},
year = {2019},
isbn = {9780999241141},
publisher = {AAAI Press},
abstract = {Probabilistic time series forecasting involves estimating the distribution of future based on its history, which is essential for risk management in downstream decision-making. We propose a deep state space model for probabilistic time series forecasting whereby the non-linear emission model and transition model are parameterized by networks and the dependency is modeled by recurrent neural nets. We take the automatic relevance determination (ARD) view and devise a network to exploit the exogenous variables in addition to time series. In particular, our ARD network can incorporate the uncertainty of the exogenous variables and eventually helps identify useful exogenous variables and suppress those irrelevant for forecasting. The distribution of multi-step ahead forecasts are approximated by Monte Carlo simulation. We show in experiments that our model produces accurate and sharp probabilistic forecasts. The estimated uncertainty of our forecasting also realistically increases over time, in a spontaneous manner.},
booktitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence},
pages = {2901–2908},
numpages = {8},
location = {Macao, China},
series = {IJCAI'19}
}

@article{10.1007/s11042-020-09236-3,
author = {Arshaghi, Ali and Ashourian, Mohsen and Ghabeli, Leila},
title = {Feature selection based on buzzard optimization algorithm for potato surface defects detection},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {35–36},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09236-3},
doi = {10.1007/s11042-020-09236-3},
abstract = {Different methods of feature selection find the best subdivision from the candidate subset. In all methods, based on the application and the type of the definition, a subset is selected as the answer; which can optimize the value of an evaluation function. The large number of features, high spatial and temporal complexity, and even reduced accuracy are common problems in such systems. Therefore, research needs to be performed to optimize these systems. In this paper, for increasing the classification accuracy and reducing their complexity; feature selection techniques are used. In addition, a new feature selection method by using the buzzard optimization algorithm (BUOZA) is proposed. These features would be used in segmentation, feature extraction, and classification steps in related applications; to improve the system performance. The results of the performed experiment on the developed method have shown a high performance while optimizing the system’s working parameters.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {26623–26641},
numpages = {19},
keywords = {Buzzard optimization algorithm, Global optimization, Potato defect detection, Feature selection, Image processing}
}

@article{10.1016/j.asoc.2021.107706,
author = {Aydin, Ilhan and Akin, Erhan and Karakose, Mehmet},
title = {Defect classification based on deep features for railway tracks in sustainable transportation},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {111},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107706},
doi = {10.1016/j.asoc.2021.107706},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {14},
keywords = {Railway surface defect, Visual inspection, Deep learning, Image processing, Railway maintenance}
}

@inproceedings{10.1007/978-3-030-62365-4_46,
author = {Go, Gwang-Myong and Bu, Seok-Jun and Cho, Sung-Bae},
title = {A Deep Metric Neural Network with Disentangled Representation for Detecting Smartphone Glass Defects},
year = {2020},
isbn = {978-3-030-62364-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62365-4_46},
doi = {10.1007/978-3-030-62365-4_46},
abstract = {For defect inspection using computer vision, deep learning models have been introduced to improve the conventional rule-based pattern analysis. A lot of data is a prerequisite to the success of them, but the on-the-spot industrial field suffers from lack of data. In this paper, we propose a deep metric neural network to improve the performance even with insufficient data imbalanced in class.&nbsp;The model is verified with the dataset of new products by evaluating the accuracy with 10-fold cross-validation. Our model is based on the data in the smallest category, 1.2&nbsp;K, which achieves the highest performance of 90.42% using sampled pairs without using all the data for training. High accuracy has been achieved and proven applicability in the industry compared to the conventional machine learning models.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4–6, 2020, Proceedings, Part II},
pages = {485–494},
numpages = {10},
keywords = {Metric few-shot learning, Deep learning, Convolutional neural network, Smartphone glass inspection, Defect detection},
location = {Guimaraes, Portugal}
}

@inproceedings{10.1007/978-3-030-86380-7_23,
author = {Krysi\'{n}ska, Izabela and Morzy, Miko\l{}aj and Kajdanowicz, Tomasz},
title = {Curriculum Learning Revisited: Incremental Batch Learning with Instance Typicality Ranking},
year = {2021},
isbn = {978-3-030-86379-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86380-7_23},
doi = {10.1007/978-3-030-86380-7_23},
abstract = {The technique of curriculum learning mimics cognitive mechanisms observed in human learning, where simpler concepts are presented prior to gradual introduction of more difficult concepts. Until now, the major obstacle for curriculum methods was the lack of a reliable method for estimating the difficulty of training instances. In this paper we show that, instead of trying to assess the difficulty of learning instances, a simple graph-based method of computing the typicality of instances can be used in conjunction with curriculum methods. We design new batch schedulers which organize ordered instances into batches of varying size and learning difficulty. Our method does not require any changes to the architecture of trained models, we improve the training merely by manipulating the order and frequency of instance presentation to the model.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2021: 30th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part IV},
pages = {279–291},
numpages = {13},
keywords = {Curriculum learning, Typicality, Batch training},
location = {Bratislava, Slovakia}
}

@article{10.1016/j.neunet.2021.03.024,
author = {Kong, Zelong and Zhang, Nian and Guan, Xinping and Le, Xinyi},
title = {Detecting slender objects with uncertainty based on keypoint-displacement representation},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {139},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2021.03.024},
doi = {10.1016/j.neunet.2021.03.024},
journal = {Neural Netw.},
month = jul,
pages = {246–254},
numpages = {9},
keywords = {Deep learning, Object detection, Uncertainty prediction, Quality evaluation}
}

@article{10.1016/j.neucom.2019.11.001,
author = {Li, Huafeng and Zhou, Weiyan and Yu, Zhengtao and Yang, Biao and Jin, Huaiping},
title = {Person re-identification with dictionary learning regularized by stretching regularization and label consistency constraint},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {379},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.11.001},
doi = {10.1016/j.neucom.2019.11.001},
journal = {Neurocomput.},
month = feb,
pages = {356–369},
numpages = {14},
keywords = {Person re-identification, Dictionary learning, Label consistency constraint, Stretch regularization}
}

@article{10.1007/s10515-021-00285-y,
author = {Goyal, Somya},
title = {Predicting the Defects using Stacked Ensemble Learner with Filtered Dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00285-y},
doi = {10.1007/s10515-021-00285-y},
abstract = {Software defect prediction is a crucial software project management activity to enhance the software quality. It aids the development team to forecast about which modules need extra attention for testing; which part of software is more prone to errors and faults; before the commencement of testing phase. It helps to reduce the testing cost and hence the overall development cost of the software. Though, it ensures in-time delivery of good quality end-product, but there is one major hinderance in making this prediction. This is the class imbalance issue in the training data. Data imbalance in class distribution adversely affects the performance of classifiers. This paper proposes a K-nearest neighbour (KNN) filtering-based data pre-processing technique for stacked ensemble classifier to handle class imbalance issue. First, nearest neighbour-based filtering is applied to filter out the overlapped data-points to reduce Imbalanced Ratio, then, the processed data with static code metrics is supplied to stacked ensemble for prediction. The stacking is achieved with five base classifiers namely Artificial Neural Network, Decision Tree, Na\"{\i}ve Bayes, K-nearest neighbour (KNN) and Support Vector Machine. A comparative analysis among 30 classifiers (5 data pre-processing techniques * 6 prediction techniques) is made. In the experiments, five public datasets from NASA repository namely CM1, JM1, KC1, KC2 and PC1 are used. In total 150 prediction models (5 data pre-processing techniques * 6 classification techniques * 5 datasets) are proposed and their performances are assessed in terms of measures namely Receiver Operator Curve, Area under the Curve and accuracy. The statistical analysis shows that proposed stacked ensemble classifier with KNN filtering performs best among all the predictors independent of datasets.},
journal = {Automated Software Engg.},
month = nov,
numpages = {81},
keywords = {Software quality, Defect prediction, Data pre-processing, Class imbalance, Artificial neural networks (ANN), Stacked ensembles, Decision trees, Nearest neighbour, Support vector machine, ROC and AUC}
}

@article{10.1007/s10462-020-09934-2,
author = {Abid, Anam and Khan, Muhammad Tahir and Iqbal, Javaid},
title = {A review on fault detection and diagnosis techniques: basics and beyond},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09934-2},
doi = {10.1007/s10462-020-09934-2},
abstract = {Safety and reliability are absolutely important for modern sophisticated systems and technologies. Therefore, malfunction monitoring capabilities are instilled in the system for detection of the incipient faults and anticipation of their impact on the future behavior of the system using fault diagnosis techniques. In particular, state-of-the-art applications rely on the quick and efficient treatment of malfunctions within the equipment/system, resulting in increased production and reduced downtimes. This paper presents developments within Fault Detection and Diagnosis (FDD) methods and reviews of research work in this area. The review presents both traditional model-based and relatively new signal processing-based FDD approaches, with a special consideration paid to artificial intelligence-based FDD methods. Typical steps involved in the design and development of automatic FDD system, including system knowledge representation, data-acquisition and signal processing, fault classification, and maintenance related decision actions, are systematically presented to outline the present status of FDD. Future research trends, challenges and prospective solutions are also highlighted.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3639–3664},
numpages = {26},
keywords = {Automatic fault diagnosis, Fault detection, Industrial applications, Signal processing}
}

@inproceedings{10.1145/3325730.3325757,
author = {Memon, Kamran Ali and Xiaoling, Xia},
title = {Deciphering and Analyzing Software Requirements employing the techniques of Natural Language Processing},
year = {2019},
isbn = {9781450362580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325730.3325757},
doi = {10.1145/3325730.3325757},
abstract = {Deciphering human language by Requirement Analysts is the key issue in Software Development. Clients communicate their software requirements in raw form. In this paper, we are presenting certain techniques of Natural Language processing which work out greatly to extract information properly and minimizing the bugs that may generate in later parts of Software Development. In today's era, the latest technological development in Artificial Intelligence has enabled machines to process the text to a certain level. Natural Language understanding is so far the most critical problem; the Software community is facing today in requirements gathering. In this study, using the techniques of Natural Language Interpretation, Testers and Software Developers can chalk out the more exact requirements from customers which can improve the Quality of Software to a certain level.},
booktitle = {Proceedings of the 2019 4th International Conference on Mathematics and Artificial Intelligence},
pages = {153–156},
numpages = {4},
keywords = {Linguistics, NLP Techniques, Natural Language Processing, Natural Language Understanding, Software Requirements},
location = {Chegndu, China},
series = {ICMAI '19}
}

@article{10.1016/j.neunet.2021.03.022,
author = {Zhong, Yongjian and Du, Bo and Xu, Chang},
title = {Learning to reweight examples in multi-label classification},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {142},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2021.03.022},
doi = {10.1016/j.neunet.2021.03.022},
journal = {Neural Netw.},
month = oct,
pages = {428–436},
numpages = {9},
keywords = {Multi-label classification, Self-paced learning, Reweight instance}
}

@article{10.1016/0005-1098(93)90111-6,
author = {Doraiswami, R.},
title = {Performance monitoring and fault prediction using a linear predictive coding algorithm},
year = {1993},
issue_date = {July 1993},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {29},
number = {4},
issn = {0005-1098},
url = {https://doi.org/10.1016/0005-1098(93)90111-6},
doi = {10.1016/0005-1098(93)90111-6},
journal = {Automatica},
month = jul,
pages = {1115–1120},
numpages = {6},
keywords = {artificial intelligence, failure detection, identification, supervisory control}
}

@inproceedings{10.1145/3348445.3348453,
author = {Cynthia, Shamse Tasnim and Ripon, Shamim H.},
title = {Predicting and Classifying Software Faults: A Data Mining Approach},
year = {2019},
isbn = {9781450371957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3348445.3348453},
doi = {10.1145/3348445.3348453},
abstract = {In the field of software engineering, the detection of fault in the software has become a major topic to explore. With the help of data mining and machine learning approaches, this paper aims to denote whether a software is fault prone or not. In order to accomplish that this paper gives importance to compare between different machine learning approaches and by observing their performances we can conclude which models perform better to detect fault in the selected software modules. The dataset we have chosen to work on has imbalanced data. This paper research also worked with the imbalanced dataset and what results the imbalanced dataset gave when examined. The accuracy comparison, the performance of the different metrics can broadly help in software defect detection mechanism.},
booktitle = {Proceedings of the 7th International Conference on Computer and Communications Management},
pages = {143–147},
numpages = {5},
keywords = {Adaboost, SVM, Software faults, association rules, data mining, prediction},
location = {Bangkok, Thailand},
series = {ICCCM '19}
}

@article{10.5555/2946645.3053434,
author = {Szab\'{o}, Zolt\'{a}n and Sriperumbudur, Bharath K. and P\'{o}czos, Barnab\'{a}s and Gretton, Arthur},
title = {Learning theory for distribution regression},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
abstract = {We focus on the distribution regression problem: regressing to vector-valued outputs from probability measures. Many important machine learning and statistical tasks fit into this framework, including multi-instance learning and point estimation problems without analytical solution (such as hyperparameter or entropy estimation). Despite the large number of available heuristics in the literature, the inherent two-stage sampled nature of the problem makes the theoretical analysis quite challenging, since in practice only samples from sampled distributions are observable, and the estimates have to rely on similarities computed between sets of points. To the best of our knowledge, the only existing technique with consistency guarantees for distribution regression requires kernel density estimation as an intermediate step (which often performs poorly in practice), and the domain of the distributions to be compact Euclidean. In this paper, we study a simple, analytically computable, ridge regression-based alternative to distribution regression, where we embed the distributions to a reproducing kernel Hilbert space, and learn the regressor from the embeddings to the outputs. Our main contribution is to prove that this scheme is consistent in the two-stage sampled setup under mild conditions (on separable topological domains enriched with kernels): we present an exact computational-statistical efficiency trade-off analysis showing that our estimator is able to match the one-stage sampled minimax optimal rate (Caponnetto and De Vito, 2007; Steinwart et al., 2009). This result answers a 17-year-old open question, establishing the consistency of the classical set kernel (Haussler, 1999; G\"{a}rtner et al., 2002) in regression. We also cover consistency for more recent kernels on distributions, including those due to Christmann and Steinwart (2010).},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {5272–5311},
numpages = {40},
keywords = {Kernel ridge regression, mean embedding, minimax optimality, multi-instance learning, two-Stage sampled distribution regression}
}

@inproceedings{10.1145/3340482.3342747,
author = {Lenarduzzi, Valentina and Martini, Antonio and Taibi, Davide and Tamburri, Damian Andrew},
title = {Towards surgically-precise technical debt estimation: early results and research roadmap},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342747},
doi = {10.1145/3340482.3342747},
abstract = {The concept of technical debt has been explored from many perspectives but its precise estimation is still under heavy empirical and experimental inquiry. We aim to understand whether, by harnessing approximate, data-driven, machine-learning approaches it is possible to improve the current techniques for technical debt estimation, as represented by a top industry quality analysis tool such as SonarQube. For the sake of simplicity, we focus on relatively simple regression modelling techniques and apply them to modelling the additional project cost connected to the sub-optimal conditions existing in the projects under study. Our results shows that current techniques can be improved towards a more precise estimation of technical debt and the case study shows promising results towards the identification of more accurate estimation of technical debt.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {37–42},
numpages = {6},
keywords = {Empirical Study, Machine Learning, Technical Debt},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@article{10.1016/j.jnca.2021.103213,
author = {Bochie, Kaylani and Gilbert, Mateus S. and Gantert, Luana and Barbosa, Mariana S.M. and Medeiros, Dianne S.V. and Campista, Miguel Elias M.},
title = {A survey on deep learning for challenged networks: Applications and trends},
year = {2021},
issue_date = {Nov 2021},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {194},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2021.103213},
doi = {10.1016/j.jnca.2021.103213},
journal = {J. Netw. Comput. Appl.},
month = nov,
numpages = {30},
keywords = {Challenged networks, Internet of Things, Sensor networks, Industrial networks, Wireless mobile networks, Vehicular networks, Deep learning, Machine learning}
}

@article{10.1007/s10462-017-9574-2,
author = {Saxena, Lalit Prakash},
title = {Niblack's binarization method and its modifications to real-time applications: a review},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9574-2},
doi = {10.1007/s10462-017-9574-2},
abstract = {Local binarization methods deal with the separation of foreground objects (textual content) and background noise (non-text) specifically at the pixel level. This is a much-explored field in the domain of documents image-processing that tends to separate the textual content from a degraded document. Since three decades, many local binarization methods have been developed to binarize documents images suffering from severe deteriorations. This paper presents a review of local binarization methods that are developed based on Niblack's binarization method (NBM, developed in 1986) only. Further, this paper is a review of local binarization methods having more or less modifications to the original Niblack's method, depending on the requirements of their model and the processed output. The modifications to NBM can be seen in various applications, such as deteriorated documents image binarization, manuscripts restoration, finding texts in video frames, revealing engraved wooden stamps, vehicle license plate number recognition, stained cytology nuclei detection and product barcodes reading. However, there could be a possibility of other applications using NBM with modifications based on the input images and the applications' requirements.},
journal = {Artif. Intell. Rev.},
month = apr,
pages = {673–705},
numpages = {33},
keywords = {Binarization, HDIBCO 2016 dataset, Local thresholds, Mean, Niblack's method, Performance measures, Standard deviation, Window size}
}

@article{10.1007/s10462-012-9360-0,
author = {Jenhani, Ilyes and Elouedi, Zied},
title = {Re-visiting the artificial immune recognition system: a survey and an improved version},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-012-9360-0},
doi = {10.1007/s10462-012-9360-0},
abstract = {This paper surveys the major works related to an artificial immune system based classifier that was proposed in the 2000s, namely, the artificial immune recognition system (AIRS) algorithm. This survey has revealed that most works on AIRS was dedicated to the application of the algorithm to real-world problems rather than to theoretical developments of the algorithm. Based on this finding, we propose an improved version of the AIRS algorithm which we dub AIRS3. AIRS3 takes into account an important parameter that was ignored by the original algorithm, namely, the number of training antigens represented by each memory cell at the end of learning (numRepAg). Experiments of the new AIRS3 algorithm on data sets taken from the UCI machine learning repository have shown that taking into account the numRepAg information enhances the classification accuracy of AIRS.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {821–833},
numpages = {13},
keywords = {Artificial immune recognition systems (AIRS), Artificial immune systems, Classification, Machine learning}
}

@inproceedings{10.1007/978-3-030-41299-9_14,
author = {Ji, Xiaotong and Zheng, Yuchen and Suehiro, Daiki and Uchida, Seiichi},
title = {Optimal Rejection Function Meets Character Recognition Tasks},
year = {2019},
isbn = {978-3-030-41298-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41299-9_14},
doi = {10.1007/978-3-030-41299-9_14},
abstract = {In this paper, we propose an optimal rejection method for rejecting ambiguous samples by a rejection function. This rejection function is trained together with a classification function under the framework of Learning-with-Rejection (LwR). The highlights of LwR are: (1) the rejection strategy is not heuristic but has a strong background from a machine learning theory, and (2) the rejection function can be trained on an arbitrary feature space which is different from the feature space for classification. The latter suggests we can choose a feature space which is more suitable for rejection. Although the past research on LwR focused only its theoretical aspect, we propose to utilize LwR for practical pattern classification tasks. Moreover, we propose to use features from different CNN layers for classification and rejection. Our extensive experiments of notMNIST classification and character/non-character classification demonstrate that the proposed method achieves better performance than traditional rejection strategies.},
booktitle = {Pattern Recognition: 5th Asian Conference, ACPR 2019, Auckland, New Zealand, November 26–29, 2019, Revised Selected Papers, Part II},
pages = {169–183},
numpages = {15},
keywords = {Learning with Rejection, Optimal rejection function, Theoretical machine learning},
location = {Auckland, New Zealand}
}

@article{10.1016/j.aei.2018.05.004,
author = {H\"{u}thwohl, Philipp and Brilakis, Ioannis},
title = {Detecting healthy concrete surfaces},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {37},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2018.05.004},
doi = {10.1016/j.aei.2018.05.004},
journal = {Adv. Eng. Inform.},
month = aug,
pages = {150–162},
numpages = {13},
keywords = {Bridge inspection, Defect detection, Automated bridge inspection, Healthy concrete}
}

@inproceedings{10.1145/3098593.3098596,
author = {Gonzalez, Roberto and Manco, Filipe and Garcia-Duran, Alberto and Mendes, Jose and Huici, Felipe and Niccolini, Saverio and Niepert, Mathias},
title = {Net2Vec: Deep Learning for the Network},
year = {2017},
isbn = {9781450350549},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098593.3098596},
doi = {10.1145/3098593.3098596},
abstract = {We present Net2Vec, a flexible high-performance platform that allows the execution of deep learning algorithms in the communication network. Net2Vec is able to capture data from the network at more than 60Gbps, transform it into meaningful tuples and apply predictions over the tuples in real time. This platform can be used for different purposes ranging from traffic classification to network performance analysis.Finally, we showcase the use of Net2Vec by implementing and testing a solution able to profile network users at line rate using traces coming from a real network. We show that the use of deep learning for this case outperforms the baseline method both in terms of accuracy and performance.},
booktitle = {Proceedings of the Workshop on Big Data Analytics and Machine Learning for Data Communication Networks},
pages = {13–18},
numpages = {6},
keywords = {Artificial Intelligence, Deep Learning, Network measurements, User profiling},
location = {Los Angeles, CA, USA},
series = {Big-DAMA '17}
}

@article{10.1007/s10515-011-0091-2,
author = {Liparas, Dimitris and Angelis, Lefteris and Feldt, Robert},
title = {Applying the Mahalanobis-Taguchi strategy for software defect diagnosis},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0091-2},
doi = {10.1007/s10515-011-0091-2},
abstract = {The Mahalanobis-Taguchi (MT) strategy combines mathematical and statistical concepts like Mahalanobis distance, Gram-Schmidt orthogonalization and experimental designs to support diagnosis and decision-making based on multivariate data. The primary purpose is to develop a scale to measure the degree of abnormality of cases, compared to "normal" or "healthy" cases, i.e. a continuous scale from a set of binary classified cases. An optimal subset of variables for measuring abnormality is then selected and rules for future diagnosis are defined based on them and the measurement scale. This maps well to problems in software defect prediction based on a multivariate set of software metrics and attributes. In this paper, the MT strategy combined with a cluster analysis technique for determining the most appropriate training set, is described and applied to well-known datasets in order to evaluate the fault-proneness of software modules. The measurement scale resulting from the MT strategy is evaluated using ROC curves and shows that it is a promising technique for software defect diagnosis. It compares favorably to previously evaluated methods on a number of publically available data sets. The special characteristic of the MT strategy that it quantifies the level of abnormality can also stimulate and inform discussions with engineers and managers in different defect prediction situations.},
journal = {Automated Software Engg.},
month = jun,
pages = {141–165},
numpages = {25},
keywords = {Fault-proneness, Mahalanobis-Taguchi strategy, Software defect prediction, Software testing}
}

@inproceedings{10.1145/3273934.3273939,
author = {Petri\'{c}, Jean and Hall, Tracy and Bowes, David},
title = {How Effectively Is Defective Code Actually Tested? An Analysis of JUnit Tests in Seven Open Source Systems},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273939},
doi = {10.1145/3273934.3273939},
abstract = {Background: Newspaper headlines still regularly report latent software defects. Such defects have often evaded testing for many years. It remains difficult to identify how well a system has been tested. It also remains difficult to assess how successful at finding defects particular tests are. Coverage and mutation testing are frequently used to asses test effectiveness. We look more deeply at the performance of commonly used JUnit testing by assessing how much JUnit testing was done and how effective that testing was at detecting defects in seven open source systems.Aim: We aim to identify whether defective code has been effectively tested by JUnit tests as non-defective code. We also aim to identify the characteristics of JUnit tests that are related to identifying defects.Methodology: We first extract the defects from seven open source projects using the SZZ algorithm. We match those defects with JUnit tests to identify the proportion of defects that were covered by JUnit tests. We also do the same for non-defective code. We then use Principal Component Analysis and machine learning to investigate the characteristics of JUnit tests that were successful in identifying defects.Results: Our findings suggest that most of the open source systems we investigated are under-tested. On average over 66% of defective methods were not linked to any JUnit tests. We show that the number of methods touched by a JUnit test is strongly related to that test uncovering a defect.Conclusion: More JUnit tests need to be produced for the seven open source systems that we investigate. JUnit tests need to be relatively sophisticated, in particular they should touch more than just one method during the test.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {42–51},
numpages = {10},
keywords = {JUnit tests, Software testing, test effectiveness},
location = {Oulu, Finland},
series = {PROMISE'18}
}

@article{10.1504/ijiei.2020.112051,
author = {Kaur, Sandeep and Chahal, Kuljit Kaur},
title = {Hybrid ANFIS-genetic algorithm based forecasting model for predicting Cholera-waterborne disease},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2020.112051},
doi = {10.1504/ijiei.2020.112051},
abstract = {Cholera is one of the rapidly spreading waterborne diseases which are caused by bacteria named Vibrio Cholerae. As population grows, so as the data related to patients, doctors and health staff. So far, different types of machine learning models have been proposed for classification of Cholera infection. However, the majority of these suffers from pre-mature convergence and stuck in local optimal issues. In this paper, ANFIS-GA based forecasting model for the prediction of Cholera virus has been proposed. In the proposed model, non-dominated sorting genetic algorithm (NSGA) is used to tune hyper-parameters of ANFIS. The comparisons are done among the designed NSGA-ANFIS and the existing models on the benchmark Cholera dataset. Performance analysis illustrates that the designed NSGA-ANFIS model performs significantly better than the existing models such as ANFIS, PSO-ANFIS and GA-ANFIS in terms of accuracy, sensitivity, kappa statistics, specificity and F-measure, as 99.2%, 99.04%, 99.11%, 99.49% and 98.85%, respectively.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {374–393},
numpages = {19},
keywords = {ANFIS, Cholera, genetic algorithm, machine learning model, NSGA, non-dominated sorting genetic algorithm, fitness function, data granulation, optimisation}
}

@inproceedings{10.1007/978-3-030-89363-7_28,
author = {Dai, Huan and Zhang, Yupei and Yun, Yue and Shang, Xuequn},
title = {An Improved Deep Model for Knowledge Tracing and Question-Difficulty Discovery},
year = {2021},
isbn = {978-3-030-89362-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89363-7_28},
doi = {10.1007/978-3-030-89363-7_28},
abstract = {Knowledge Tracing (KT) aims to analyze a student’s acquisition of skills over time by examining the student’s performance on questions of those skills. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods. However, DKT and its variants often lead to oscillation results on a skill’s state may due to it ignoring the skill’s difficulty or the question’s difficulty. As a result, even when a student performs well on a skill, the prediction of that skill’s mastery level decreases instead, and vice versa. This is undesirable and unreasonable because student’s performance is expected to transit gradually over time. In this paper, we propose to learn the knowledge tracing model in a “simple-to-difficult” process, leading to a method of Self-paced Deep Knowledge Tracing (SPDKT). SPDKT learns the difficulty of per question from the student’s responses to optimize the question’s order and smooth the learning process. With mitigating the cause of oscillations, SPDKT has the capability of robustness to the puzzling questions. The experiments on real-world datasets show SPDKT achieves state-of-the-art performance on question response prediction and reaches interesting interpretations in education.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part II},
pages = {362–375},
numpages = {14},
keywords = {Knowledge tracing, Self-paced learning, Deep learning, Personalized education},
location = {Hanoi, Vietnam}
}

@article{10.1007/s10586-018-1923-7,
author = {Viji, C. and Rajkumar, N. and Duraisamy, S.},
title = {Prediction of software fault-prone classes using an unsupervised hybrid SOM algorithm},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1923-7},
doi = {10.1007/s10586-018-1923-7},
abstract = {In software engineering fault proneness prediction is one of the important fields for quality measurement using multiple code metrics. The metrics thresholds are very practical in measuring the code quality for fault proneness prediction. It helps to improvise the software quality in short time with very low cost. Many researchers are in the race to develop a measuring attribute for the software quality using various methodologies. Currently so many fault proneness prediction models are available. Among that most of the methods are used to identify the faults either by data history or by special supervising algorithms. In most of the real time cases the fault data bases may not be available so that the process becomes tedious. This article proposes a hybrid model for identifying the faults in the software models and also we proposed coupling model along with the algorithm so that the metrics are used to identify the faults and the coupling model couples the metrics and the faults for the developed system software.},
journal = {Cluster Computing},
month = jan,
pages = {133–143},
numpages = {11},
keywords = {Software metrics, Fault prediction, Coupling, Fault proneness, ANN}
}

@inproceedings{10.1145/3469213.3470226,
author = {Jie, Longmei and Shao, Guoqiang and Shen, Dan},
title = {A Machine Vision Based Medicine Package Printing Three Date Marks Detection Scheme},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3470226},
doi = {10.1145/3469213.3470226},
abstract = {To solve the problem of misprinting or obscure of Three Date Marks (TDMS) including production date, batch number and the validity on the medicine packaging, a delay-based misplaced difference scheme for medical information detection is presented. Firstly, two medical images are Successively captured by a machine vision detection system, and a character image is obtained through misplaced subtraction operation; Then, a convolution kernel is designed according to the size of characters to widen the strokes, and a specific operation with corrosion and dilation is further utilized to remove speckle noise to enhance the quality of object characters. Finally, a modified weighted median filter is employed to further improve the recognition accuracy. Experimental results show that the detection precision and efficiency satisfy the requirements of medical packaging triple tags detection well.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {26},
numpages = {5},
keywords = {Three Date Marks(TDMS), misplaced difference image, convolution kernel, double image overlap, medical information detection, modified weighted median filter},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1016/j.knosys.2016.12.017,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Linear and non-linear heterogeneous ensemble methods to predict the number of faults in software systems},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {119},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2016.12.017},
doi = {10.1016/j.knosys.2016.12.017},
abstract = {This paper expands the use of ensemble methods for the prediction of number of faults unlikely the earlier works on ensemble methods that focused on predicting software modules as faulty or non-faulty.This paper investigates the usage of both heterogeneous ensemble methods as well as homogeneous ensemble methods for the prediction of number of faults.We present two linear combination rules and two non-linear combination rules for combining the outputs of the base learners in the ensemble.In addition, we assess the performance of ensemble methods under two different scenarios, intra-release prediction and inter-releases prediction.The experiments are performed over five open-source software systems with their fifteen releases, collected from the PROMISE data repository. Several classification techniques have been investigated and evaluated earlier for the software fault prediction. These techniques have produced different prediction accuracy for the different software systems and none of the technique has always performed consistently better across different domains. On the other hand, software fault prediction using ensemble methods can be very effective, as they take the advantage of each participating technique for the given dataset and try to come up with better prediction results compared to the individual techniques. Many works are available for classifying software modules being faulty or non-faulty using the ensemble methods. These works are only specifying that whether a given software module is faulty or not, but number of faults in that module are not predicted by them. The use of ensemble methods for the prediction of number of faults has not been explored so far. To fulfill this gap, this paper presents ensemble methods for the prediction of number of faults in the given software modules. The experimental study is designed and conducted for five open-source software projects with their fifteen releases, collected from the PROMISE data repository. The results are evaluated under two different scenarios, intra-release prediction and inter-releases prediction. The prediction accuracy of ensemble methods is evaluated using absolute error, relative error, prediction at level l, and measure of completeness performance measures. Results show that the presented ensemble methods yield improved prediction accuracy over the individual fault prediction techniques under consideration. Further, the results are consistent for all the used datasets. The evidences obtained from the prediction at level l and measure of completeness analysis have also confirmed the effectiveness of the proposed ensemble methods for predicting the number of faults.},
journal = {Know.-Based Syst.},
month = mar,
pages = {232–256},
numpages = {25},
keywords = {Ensemble methods, Heterogeneous ensemble, Prediction of number of faults, Software fault prediction}
}

@inproceedings{10.1145/3452940.3453497,
author = {Liu, Wenjun and Xu, Yuanfu and Han, Qiang and Wang, Yao and Xu, Lei},
title = {Development and Application of State-Sensing Technology for Power Equipment},
year = {2021},
isbn = {9781450388665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452940.3453497},
doi = {10.1145/3452940.3453497},
abstract = {With the increasing expansion of power grid scale, the research and application of artificial intelligence technology in the electrical field will further promote the profound transformation of power grid structure. Power equipment, as core elements of power grid, monitoring information has been quantification and discretization caused by the grid intelligent transformation. Therefore, it is urgent to deeply integrate artificial intelligence technology and take advantage of data driven to improve the perception ability of equipment running status, thereby promoting the utilization ratio of power equipment assets and ensuring safety and reliability of power grid. At present, the traditional equipment status evaluation cannot realize the efficient utilization of massive power data. In addition, the power data obtained by the current sensing technology still has problems such as errors and instability, which leads to the fact that the state perception effect of the power equipment cannot satisfy the development demand of the power grid. However, as a new solution, the introduction of the Internet of Things and big data analysis technology provide new technical support for the power equipment perception technology.In this paper, the mature state perception technology and its application has been summarized. Furthermore, the corresponding parameter performance, advantages and disadvantages has been analyzed. Finally, the future development of state perception technology of power equipment is prospected according to the current situation of power grid.},
booktitle = {Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering},
pages = {361–369},
numpages = {9},
keywords = {Artificial Intelligence (AI), Electrical Equipment, State Perception, the Internet of Things},
location = {Changde City, Hunan, China},
series = {ICITEE '20}
}

@inproceedings{10.1145/3363347.3363366,
author = {Yousefpour, Ashkan and Devic, Siddartha and Nguyen, Brian Q. and Kreidieh, Aboudy and Liao, Alan and Bayen, Alexandre M. and Jue, Jason P.},
title = {Guardians of the Deep Fog: Failure-Resilient DNN Inference from Edge to Cloud},
year = {2019},
isbn = {9781450370134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3363347.3363366},
doi = {10.1145/3363347.3363366},
abstract = {Partitioning and distributing deep neural networks (DNNs) over physical nodes such as edge, fog, or cloud nodes, could enhance sensor fusion, and reduce bandwidth and inference latency. However, when a DNN is distributed over physical nodes, failure of the physical nodes causes the failure of the DNN units that are placed on these nodes. The performance of the inference task will be unpredictable, and most likely, poor, if the distributed DNN is not specifically designed and properly trained for failures. Motivated by this, we introduce deepFogGuard, a DNN architecture augmentation scheme for making the distributed DNN inference task failure-resilient. To articulate deepFogGuard, we introduce the elements and a model for the resiliency of distributed DNN inference. Inspired by the concept of residual connections in DNNs, we introduce skip hyperconnections in distributed DNNs, which are the basis of deepFogGuard's design to provide resiliency. Next, our extensive experiments using two existing datasets for the sensing and vision applications confirm the ability of deepFogGuard to provide resiliency for distributed DNNs in edge-cloud networks.},
booktitle = {Proceedings of the First International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things},
pages = {25–31},
numpages = {7},
keywords = {Distributed DNN Inference, Distributed Neural Networks, Edge Computing, Fog Computing, Reliability, Resiliency, Robust},
location = {New York, NY, USA},
series = {AIChallengeIoT'19}
}

@inproceedings{10.1145/3387904.3389295,
author = {Lenarduzzi, Valentina and Palomba, Fabio and Taibi, Davide and Tamburri, Damian Andrew},
title = {OpenSZZ: A Free, Open-Source, Web-Accessible Implementation of the SZZ Algorithm},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389295},
doi = {10.1145/3387904.3389295},
abstract = {The accurate identification of defect-inducing commits represents a key problem for researchers interested in studying the naturalness of defects and defining defect prediction models. To tackle this problem, software engineering researchers have relied on and proposed several implementations of the well-known Sliwerski-Zimmermann-Zeller (SZZ) algorithm. Despite its popularity and wide usage, no open-source, publicly available, and web-accessible implementation of the algorithm has been proposed so far. In this paper, we prototype and make available one such implementation for further use by practitioners and researchers alike. The evaluation of the proposed prototype showed competitive results and lays the foundation for future work. This paper outlines our prototype, illustrating its usage and reporting on its evaluation in action.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {446–450},
numpages = {5},
keywords = {Open-Source Tools, Software Defect Prediction, Software Defect Proneness, Web APIs},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@inproceedings{10.1145/3373477.3373486,
author = {Aggarwal, Simran},
title = {Software code analysis using ensemble learning techniques},
year = {2020},
isbn = {9781450372916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373477.3373486},
doi = {10.1145/3373477.3373486},
abstract = {Ensuing the advent of advancements in software systems, the probability of them containing high severity defects is exponentially on the rise. With each technological addition, the complexity of software is increasing. Reproduction and rectification of a defect requires time and effort. Current state of the art analysis tools cater to the investigation of static aspects of a production level code. However, it is imperative to assess the dynamic development process of a system so as to be able to timely detect erroneous components early on in the development life cycle of a software. A novel automated defect prediction feature enhancement is proposed that analyses the static structure of the current code and state of the software in past releases to extract relevant static and dynamic feature sets. Data generated is modelled for defect trends in the future release of the software by four ensemble classifiers. Results demonstrate the superiority of Voting algorithm for the problem of defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Advanced Information Science and System},
articleno = {9},
numpages = {7},
keywords = {defect prediction, empirical validation, ensemble learning, machine learning, object-oriented metrics, software quality},
location = {Singapore, Singapore},
series = {AISS '19}
}

@inproceedings{10.1145/3469213.3470349,
author = {Yan, Jishuang and Hao, Yingguang},
title = {Recognition Method of Electrical Components Based on Improved YOLOv3},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3470349},
doi = {10.1145/3469213.3470349},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {146},
numpages = {5},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1145/3381307.3381311,
author = {Varniab, Mahsa Shokri and Hung, Chih-Cheng and Sharghi, Vahid Khalilzad},
title = {Data mining and image analysis using genetic programming},
year = {2020},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1559-6915},
url = {https://doi.org/10.1145/3381307.3381311},
doi = {10.1145/3381307.3381311},
abstract = {Genetic programming (GP) is an artificial intelligence technique that benefits from evolutionary computations allowing computers to solve problems automatically. In this paper, we present an optimized genetic-programming-based classifier that directly solves the multi-class classification problems in data mining and image analysis. A new fitness function is proposed for multiclass classification and brain tumor detection, which is validated by 10-fold cross validation. Instead of defining static thresholds as boundaries to differentiate between multiple labels, our work presents a method of classification where a GP system learns the relationships among experiential data and models them mathematically during the evolutionary process. We propose an optimized GP classifier based on a combination of pruning subtrees and a new fitness function. An orthogonal least squares algorithm is also applied in the training phase to create a robust GP classifier. Our approach has been assessed on six multiclass datasets and on a magnetic resonance imaging (MRI) brain image for tumor detection. The results of data classification for Iris, Wine, Glass, Pima, BUPA Liver and Balance Scale datasets are compared with existing algorithms. The high accuracy of brain tumor classification provided by our GP classifier confirms the strong ability of the developed technique for complicated classification problems. We compared our approach in terms of speed with previous GP algorithms as well. The analyzed results illustrate that the developed classifier produces a productive and rapid method for classification tasks that outperforms the previous methods for more challenging multiclass classification problems.},
journal = {SIGAPP Appl. Comput. Rev.},
month = jan,
pages = {40–49},
numpages = {10},
keywords = {classification, genetic programming, image analysis, machine learning, tumor detection}
}

@inproceedings{10.5220/0005679102800287,
author = {Diedrich, Alexander and B\"{o}ttcher, Bj\"{o}rn and Niggemann, Oliver},
title = {Exposing Design Mistakes During Requirements Engineering by Solving Constraint Satisfaction Problems to Obtain Minimum Correction Subsets},
year = {2016},
isbn = {9789897581724},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005679102800287},
doi = {10.5220/0005679102800287},
abstract = {In recent years, the complexity of production plants and therefore of the underlying automation systems has grown significantly. This makes the manual design of automation systems increasingly difficult. As a result, errors are found only during production, plant modifications are hindered by not maintainable automation solutions and criteria such as energy efficiency or cost are often not optimized. This work shows how utilizing Minimum Correction Subsets (MCS) of a Constraint Satisfaction Problem improves the collaboration of automation system designers and prevents inconsistent requirements and thus subsequent errors in the design. This opens up a new field of application for constraint satisfaction techniques. As a use case, an example from the field of automation system design is presented. To meet the automation industry\^{a} s requirement for standardised solutions that assure reliability, the calculation of MCS is formulated in such a way that most constraint solvers can be used without any extensions. Experimental results with typical problems demonstrate the practicalness concerning runtime and hardware resources.},
booktitle = {Proceedings of the 8th International Conference on Agents and Artificial Intelligence},
pages = {280–287},
numpages = {8},
keywords = {Constraint Satisfaction, Feature Models, Minimum Correction Subsets., Product Line Engineering},
location = {Rome, Italy},
series = {ICAART 2016}
}

@article{10.1016/j.compeleceng.2019.08.001,
author = {Prates, Ricardo M. and Cruz, Ricardo and Marotta, Andr\'{e} P. and Ramos, Rodrigo P. and Simas Filho, Eduardo F. and Cardoso, Jaime S.},
title = {Insulator visual non-conformity detection in overhead power distribution lines using deep learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {78},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.08.001},
doi = {10.1016/j.compeleceng.2019.08.001},
journal = {Comput. Electr. Eng.},
month = sep,
pages = {343–355},
numpages = {13},
keywords = {Overhead Distribution Power Lines (ODPLs), Insulators, Automated inspection, Data augmentation, Convolutional Neural Networks (CNNs), Multi-task learning (MTL)}
}

@inproceedings{10.1609/aaai.v33i01.33014951,
author = {Shu, Yang and Cao, Zhangjie and Long, Mingsheng and Wang, Jianmin},
title = {Transferable curriculum for weakly-supervised domain adaptation},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33014951},
doi = {10.1609/aaai.v33i01.33014951},
abstract = {Domain adaptation improves a target task by knowledge transfer from a source domain with rich annotations. It is not uncommon that "source-domain engineering" becomes a cumbersome process in domain adaptation: the high-quality source domains highly related to the target domain are hardly available. Thus, weakly-supervised domain adaptation has been introduced to address this difficulty, where we can tolerate the source domain with noises in labels, features, or both. As such, for a particular target task, we simply collect the source domain with coarse labeling or corrupted data. In this paper, we try to address two entangled challenges of weakly-supervised domain adaptation: sample noises of the source domain and distribution shift across domains. To disentangle these challenges, a Transferable Curriculum Learning (TCL) approach is proposed to train the deep networks, guided by a transferable curriculum informing which of the source examples are noiseless and transferable. The approach enhances positive transfer from clean source examples to the target and mitigates negative transfer of noisy source examples. A thorough evaluation shows that our approach significantly outperforms the state-of-the-art on weakly-supervised domain adaptation tasks.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {608},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1007/978-3-030-33607-3_41,
author = {Go, Gwang-Myong and Bu, Seok-Jun and Cho, Sung-Bae},
title = {A Deep Learning-Based Surface Defect Inspection System for Smartphone Glass},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_41},
doi = {10.1007/978-3-030-33607-3_41},
abstract = {In recent years, convolutional neural network has become a solution to many image processing problems due to high performance. It is particularly useful for applications in automated optical inspection systems related to industrial applications. This paper proposes a system that combines the defect information, which is meta data, with the defect image by modeling. Our model for classification consists of a separate model for embedding location information in order to utilize the defective locations classified as defective candidates and ensemble with the model for classification to enhance the overall system performance. The proposed system incorporates class activation map for preprocessing and augmentation for image acquisition and classification through optical system, and feedback of classification performance by constructing a system for defect detection. Experiment with real-world dataset shows that the proposed system achieved 97.4% accuracy and through various other experiments, we verified that our system is applicable.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {375–385},
numpages = {11},
keywords = {Deep learning, Convolutional neural network, Class activation map, Smartphone glass inspection, Defect detection, Augmentation, Image preprocessing},
location = {Manchester, United Kingdom}
}

@inproceedings{10.1007/978-3-030-31726-3_42,
author = {Li, Juanjuan and Jing, Xiao-Yuan and Wu, Fei and Sun, Ying and Yang, Yongguang},
title = {A Cost-Sensitive Shared Hidden Layer Autoencoder for Cross-Project Defect Prediction},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_42},
doi = {10.1007/978-3-030-31726-3_42},
abstract = {Cross-project defect prediction means training a classifier model using the historical data of the other source project, and then testing whether the target project instance is defective or not. Since source and target projects have different data distributions, and data distribution difference will degrade the performance of classifier. Furthermore, the class imbalance of datasets increases the difficulty of classification. Therefore, a cost-sensitive shared hidden layer autoencoder (CSSHLA) method is proposed. CSSHLA learns a common feature representation between source and target projects by shared hidden layer autoencoder, and makes the different data distributions more similar. To solve the class imbalance problem, CSSHLA introduces a cost-sensitive factor to assign different importance weights to different instances. Experiments on 10 projects of PROMISE dataset show that CSSHLA improves the performance of cross-project defect prediction compared with baselines.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {491–502},
numpages = {12},
keywords = {Shared hidden layer autoencoder, Cost-sensitive learning, Cross-project software defect prediction},
location = {Xi'an, China}
}

@article{10.1155/2021/5549300,
author = {Museba, Tinofirei and Nelwamondo, Fulufhelo and Ouahada, Khmaies and Yi, Yugen},
title = {ADES: A New Ensemble Diversity-Based Approach for Handling Concept Drift},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/5549300},
doi = {10.1155/2021/5549300},
abstract = {Beyond applying machine learning predictive models to static tasks, a significant corpus of research exists that applies machine learning predictive models to streaming environments that incur concept drift. With the prevalence of streaming real-world applications that are associated with changes in the underlying data distribution, the need for applications that are capable of adapting to evolving and time-varying dynamic environments can be hardly overstated. Dynamic environments are nonstationary and change with time and the target variables to be predicted by the learning algorithm and often evolve with time, a phenomenon known as concept drift. Most work in handling concept drift focuses on updating the prediction model so that it can recover from concept drift while little effort has been dedicated to the formulation of a learning system that is capable of learning different types of drifting concepts at any time with minimum overheads. This work proposes a novel and evolving data stream classifier called Adaptive Diversified Ensemble Selection Classifier (ADES) that significantly optimizes adaptation to different types of concept drifts at any time and improves convergence to new concepts by exploiting different amounts of ensemble diversity. The ADES algorithm generates diverse base classifiers, thereby optimizing the margin distribution to exploit ensemble diversity to formulate an ensemble classifier that generalizes well to unseen instances and provides fast recovery from different types of concept drift. Empirical experiments conducted on both artificial and real-world data streams demonstrate that ADES can adapt to different types of drifts at any given time. The prediction performance of ADES is compared to three other ensemble classifiers designed to handle concept drift using both artificial and real-world data streams. The comparative evaluation performed demonstrated the ability of ADES to handle different types of concept drifts. The experimental results, including statistical test results, indicate comparable performances with other algorithms designed to handle concept drift and prove their significance and effectiveness.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {17}
}

@inproceedings{10.1145/3472716.3472864,
author = {Kelkar, Anupa and Dick, Chris},
title = {Aerial: a GPU hyper-converged platform for 5G},
year = {2021},
isbn = {9781450386296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472716.3472864},
doi = {10.1145/3472716.3472864},
abstract = {In addition to high-throughput, low-latency and high-reliability, softwarization, virtualization and open interfaces are key tenets of 5G wireless. In this paper we present Aerial, a pure software implementation of a MIMO multi-cell gNB. All of the baseband signal processing is implemented as CUDA running on an NVIDA GPU, layer-2 is hosted on a CPU and an O-RAN 7.2 split fronthaul interface is supported with a Mellanox ConnectX-6 DX NIC. The accompanying video demonstrates the three use-cases that are described in this paper.},
booktitle = {Proceedings of the SIGCOMM '21 Poster and Demo Sessions},
pages = {79–81},
numpages = {3},
keywords = {5G and 6G research, AR/VR and computer vision, GPU wireless signal processing, artificial intelligence and machine learning, edge data center vRAN, mobile edge computing, robotics},
location = {Virtual Event},
series = {SIGCOMM '21}
}

@article{10.3233/JIFS-192071,
author = {Ameen, Mustafa and Alrahmawy, Mohammed and AbouEleneen, Amal and Tolba, Ahmad},
title = {Neighborhood preserving perceptual fidelity aware MSE for visual inspection of industrial flat surface products},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-192071},
doi = {10.3233/JIFS-192071},
abstract = {Automated visual inspection is becoming an important field of computer vision in many industries. The real-time inspection of flat surface products is a task full of challenges in industrial aspects that requires fast and accurate algorithms for detection and localisation of defects. Structural, statistical and filter-based approaches, such as Gabor Filter Banks, Log-Gabor filter and Wavelets, have high computational complexity.This paper introduces a fast and accurate model for inspection and localization of industrial flat surface products: Neighborhood Preserving Perceptual Fidelity Aware Mean Squared Error (NP-PAMSE). The Extreme Learning Machine (ELM) is used for classification. ELM is found to be the perfect classifier for detecting defects. The proposed model resulted in defect detection accuracy of 99.86%, with 98.16% sensitivity, and 99.90% specificity.These results show that the proposed model outperforms many existing defect detection approaches. The discriminant power displays the efficiency of ELM in differentiation between normal and abnormal surfaces.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {1183–1196},
numpages = {14},
keywords = {Automated visual inspection (AVI), perceptual fidelity aware mean squared error (PAMSE), extreme learning machine (ELM)}
}

@inproceedings{10.1145/2365324.2365326,
author = {Shepperd, Martin},
title = {The scientific basis for prediction research},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365326},
doi = {10.1145/2365324.2365326},
abstract = {In recent years there has been a huge growth in using statistical and machine learning methods to find useful prediction systems for software engineers. Of particular interest is predicting project effort and duration and defect behaviour. Unfortunately though results are often promising no single technique dominates and there are clearly complex interactions between technique, training methods and the problem domain. Since we lack deep theory our research is of necessity experimental. Minimally, as scientists, we need reproducible studies. We also need comparable studies. I will show through a meta-analysis of many primary studies that we are not presently in that situation and so the scientific basis for our collective research remains in doubt. By way of remedy I will argue that we need to address these issues of reporting protocols and expertise plus ensure blind analysis is routine.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {1–2},
numpages = {2},
keywords = {defect prediction, empirical research, machine learning, software metrics},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@article{10.1007/s11219-020-09525-y,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {An empirical study on predictability of software maintainability using imbalanced data},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09525-y},
doi = {10.1007/s11219-020-09525-y},
abstract = {In software engineering predictive modeling, early prediction of software modules or classes that possess high maintainability effort is a challenging task. Many prediction models are constructed to predict the maintainability of software classes or modules by applying various machine learning (ML) techniques. If the software modules or classes need&nbsp;high maintainability, effort would be reduced&nbsp;in a dataset, and&nbsp;there would be imbalanced data to train the model. The imbalanced datasets make&nbsp;ML techniques bias their predictions towards low maintainability effort or majority classes, and minority class instances get discarded as noise by the machine learning (ML) techniques. In this direction, this paper presents empirical work to improve the performance of software maintainability prediction (SMP) models developed with ML techniques using imbalanced data. For developing the models, the imbalanced data is pre-processed by applying data resampling methods. Fourteen data resampling methods, including oversampling, undersampling, and hybrid resampling, are used in the study. The study results recommend that the safe-level synthetic minority oversampling technique (Safe-Level-SMOTE) is a useful method to deal with the imbalanced datasets and to develop competent prediction models to forecast software maintainability.},
journal = {Software Quality Journal},
month = dec,
pages = {1581–1614},
numpages = {34},
keywords = {Software maintainability prediction, Machine learning, Data resampling, Imbalanced learning}
}

@article{10.1007/s00138-021-01183-9,
author = {Fu, Yongzhong and Ma, Xiaolong and Zhou, Hang},
title = {Automatic detection of multi-crossing crack defects in multi-crystalline solar cells based on machine vision},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01183-9},
doi = {10.1007/s00138-021-01183-9},
abstract = {The detection of defects in solar cells based on machine vision has become the main direction of current development, but the graphical feature extraction of micro-cracks, especially cracks with complex shapes, still faces formidable challenges due to the difficulties associated with the complex background, non-uniform texture, and poor contrast between crack defects and background. In this paper, a novel detection scheme based on machine vision to detect multi-crossing cracks for multi-crystalline solar cells was proposed. First, faced with periodic noise, we improved the filter method in the frequency domain and eliminated the background interference of fingers by filtering out the periodic noise while retaining the integrity of the crack signal. To address the anisotropy of multi-crossing cracks, we designed a special grid-shaped, convolution kernel filter to accurately extract crack features at low contrast and in the presence of a complex textured background. Finally, to address the missing features from the central region of multi-crossing cracks, we designed a method based on the orientation information of mask pattern to implement feature reconstruction for the central region of the crack. The experimental results showed that, compared to other crack detection methods, the strategy designed herein exhibited a better detection performance and stronger robustness.},
journal = {Mach. Vision Appl.},
month = may,
numpages = {14},
keywords = {Defect detection, Machine vision, Solar cells, Multi-crossing crack, Pattern recognition}
}

@article{10.1016/j.image.2021.116392,
author = {Shu, Xin and Song, Zhigang and Shi, Jinlong and Huang, Shucheng and Wu, Xiao-Jun},
title = {Multiple channels local binary pattern for color texture representation and classification},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0923-5965},
url = {https://doi.org/10.1016/j.image.2021.116392},
doi = {10.1016/j.image.2021.116392},
journal = {Image Commun.},
month = oct,
numpages = {11},
keywords = {Texture descriptor, Texture classification, Color texture feature, Local binary pattern, Multiple channels local binary pattern}
}

@article{10.1016/j.ijar.2007.03.006,
author = {Peterson, Leif E. and Coleman, Matthew A.},
title = {Machine learning-based receiver operating characteristic (ROC) curves for crisp and fuzzy classification of DNA microarrays in cancer research},
year = {2008},
issue_date = {January, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {47},
number = {1},
issn = {0888-613X},
url = {https://doi.org/10.1016/j.ijar.2007.03.006},
doi = {10.1016/j.ijar.2007.03.006},
abstract = {Receiver operating characteristic (ROC) curves were generated to obtain classification area under the curve (AUC) as a function of feature standardization, fuzzification, and sample size from nine large sets of cancer-related DNA microarrays. Classifiers used included k-nearest neighbor (kNN), naive Bayes classifier (NBC), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), learning vector quantization (LVQ1), logistic regression (LOG), polytomous logistic regression (PLOG), artificial neural networks (ANN), particle swarm optimization (PSO), constricted particle swarm optimization (CPSO), kernel regression (RBF), radial basis function networks (RBFN), gradient descent support vector machines (SVMGD), and least squares support vector machines (SVMLS). For each data set, AUC was determined for a number of combinations of sample size, total sum[-log(p)] of feature t-tests, with and without feature standardization and with (fuzzy) and without (crisp) fuzzification of features. Altogether, a total of 2,123,530 classification runs were made. At the greatest level of sample size, ANN resulted in a fitted AUC of 90%, while PSO resulted in the lowest fitted AUC of 72.1%. AUC values derived from 4NN were the most dependent on sample size, while PSO was the least. ANN depended the most on total statistical significance of features used based on sum[-log(p)], whereas PSO was the least dependent. Standardization of features increased AUC by 8.1% for PSO and -0.2% for QDA, while fuzzification increased AUC by 9.4% for PSO and reduced AUC by 3.8% for QDA. AUC determination in planned microarray experiments without standardization and fuzzification of features will benefit the most if CPSO is used for lower levels of feature significance (i.e., sum[-log(p)]~50) and ANN is used for greater levels of significance (i.e., sum[-log(p)]~500). When only standardization of features is performed, studies are likely to benefit most by using CPSO for low levels of feature statistical significance and LVQ1 for greater levels of significance. Studies involving only fuzzification of features should employ LVQ1 because of the substantial gain in AUC observed and low expense of LVQ1. Lastly, PSO resulted in significantly greater levels of AUC (89.5% average) when feature standardization and fuzzification were performed. In consideration of the data sets used and factors influencing AUC which were investigated, if low-expense computation is desired then LVQ1 is recommended. However, if computational expense is of less concern, then PSO or CPSO is recommended.},
journal = {Int. J. Approx. Reasoning},
month = jan,
pages = {17–36},
numpages = {20},
keywords = {Area under the curve (AUC), DNA microarrays, Fuzzy classification, Gene expression, Receiver operator characteristic (ROC) curve, Soft computing}
}

@inproceedings{10.1145/3438872.3439072,
author = {Xu, Xin and Gao, Yan},
title = {Reliability Evaluation Methods of Deep Learning Algorithm in Computer Vision},
year = {2020},
isbn = {9781450388306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3438872.3439072},
doi = {10.1145/3438872.3439072},
abstract = {With the rapid development of deep learning technology, the application based on deep learning shows explosive growth, especially in the field of computer vision. However, some characteristics of the deep learning algorithm make it face many unexpected threats in actual use. It has become an urgent problem to ensure the reliability of the algorithm. In this paper, we propose a deep learning algorithm reliability evaluation system and corresponding evaluation indicators from the three aspects of data, model, and operating framework, then describe reliability evaluation methods for each specific indicator.},
booktitle = {Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {140–145},
numpages = {6},
keywords = {Computer vision, Deep learning, Reliability evaluation},
location = {Shanghai, China},
series = {RICAI '20}
}

@inproceedings{10.1007/978-3-030-58577-8_17,
author = {Pan, Lili and Ai, Shijie and Ren, Yazhou and Xu, Zenglin},
title = {Self-Paced Deep Regression Forests with Consideration on Underrepresented Examples},
year = {2020},
isbn = {978-3-030-58576-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58577-8_17},
doi = {10.1007/978-3-030-58577-8_17},
abstract = {Deep discriminative models (e.g.&nbsp;deep regression forests, deep neural decision forests) have achieved remarkable success recently to solve problems such as facial age estimation and head pose estimation. Most existing methods pursue robust and unbiased solutions either through learning discriminative features, or reweighting samples. We argue what is more desirable is learning gradually to discriminate like our human beings, and hence we resort to self-paced learning (SPL). Then, a natural question arises: can self-paced regime lead deep discriminative models to achieve more robust and less biased solutions? To this end, this paper proposes a new deep discriminative model—self-paced deep regression forests with consideration on underrepresented examples (SPUDRFs). It tackles the fundamental ranking and selecting problem in SPL from a new perspective: fairness. This paradigm is fundamental and could be easily combined with a variety of deep discriminative models (DDMs). Extensive experiments on two computer vision tasks, i.e., facial age estimation and head pose estimation, demonstrate the efficacy of SPUDRFs, where state-of-the-art performances are achieved.},
booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXX},
pages = {271–287},
numpages = {17},
keywords = {Underrepresented examples, Self-paced learning, Entropy, Deep regression forests},
location = {Glasgow, United Kingdom}
}

@article{10.1016/j.eswa.2019.113085,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Tripathi, Anil Kumar},
title = {BPDET: An effective software bug prediction model using deep representation and ensemble learning techniques},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113085},
doi = {10.1016/j.eswa.2019.113085},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {22},
keywords = {Software bug prediction, Classification technique, Software metrics, Deep representation, Boosting, Staked denoising auto-encoder, Heterogeneous Ensemble learning technique}
}

@inproceedings{10.1145/3467707.3467710,
author = {Yin, Tianping and Yang, Jie},
title = {Detection of Steel Surface Defect Based on Faster R-CNN and FPN},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3467707.3467710},
doi = {10.1145/3467707.3467710},
abstract = {With the development of economy, steel has been widely used by human beings in various fields of social life, for example, military products, vehicles, aerospace, high-rise buildings and daily necessities. Therefore, it is very important to get high quality steel in industrial production. Detection of steel surface defect is a vital process in steel quality inspection. Traditional method uses artificial feature to detect steel surface defect, which costs lots of time to get features, and it is not robust in new environment. Therefore, this paper proposes an efficient and accurate method to solve the problem. In this paper, we adopt the faster R-CNN algorithm as baseline to train our own model. The feature pyramid network (FPN) is added to the original network of faster R-CNN, so that the network can combine high-level feature information and low-level feature information, furthermore, we replace the region-of-interest (RoI) pooling module with RoI align to reduce quantization error, which helps the mean average precision (mAP) increase about 0.8%. We use cycle GAN to do data enhancement, which helps our network easily to converge. Another problem is that it is quite common to get extreme aspect ratio in steel surface samples, which makes the detection more difficult, we introduce a method called multi-layer RoI align to solve this problem, which makes the mAP increase about 3.2%. According to our experiment results, the proposed method has a quite good performance on detection of steel surface defect.},
booktitle = {Proceedings of the 2021 7th International Conference on Computing and Artificial Intelligence},
pages = {15–20},
numpages = {6},
keywords = {cycle Generative Adversarial Network (GAN), faster R-CNN, feature pyramid network (FPN), multi-layer RoI align},
location = {Tianjin, China},
series = {ICCAI '21}
}

@inproceedings{10.1007/978-3-030-58811-3_67,
author = {ElGhondakly, Roaa and Moussa, Sherin and Badr, Nagwa},
title = {Handling Faults in Service Oriented Computing: A Comprehensive Study},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_67},
doi = {10.1007/978-3-030-58811-3_67},
abstract = {Recently, service-oriented computing paradigms have become a trending development direction, in which software systems are built using a set of loosely coupled services distributed over multiple locations through a service-oriented architecture. Such systems encounter different challenges, as integration, performance, reliability, availability, etc., which made all associated testing activities to be another major challenge to avoid their faults and system failures. Services are considered the substantial element in service-oriented computing. Thus, the quality of services and the service dependability in a web service composition have become essential to manage faults within these software systems. Many studies addressed web service faults from diverse perspectives. In this paper, a comprehensive study is conducted to investigate the different perspectives to manipulate web service faults, including fault tolerance, fault injection, fault prediction and fault localization. An extensive comparison is provided, highlighting the main research gaps, challenges and limitations of each perspective for web services. An analytical discussion is then followed to suggest future research directions that can be adopted to face such obstacles by improving fault handling capabilities for an efficient testing in service-oriented computing systems.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {947–959},
numpages = {13},
keywords = {Fault tolerance, Fault prediction, Fault injection, Quality of Service, Service testing, Service oriented computing},
location = {Cagliari, Italy}
}

@article{10.1007/s00138-021-01244-z,
author = {Honz\'{a}tko, David and T\"{u}retken, Engin and Bigdeli, Siavash A. and Dunbar, L. Andrea and Fua, Pascal},
title = {Defect segmentation for multi-illumination quality control systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {6},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01244-z},
doi = {10.1007/s00138-021-01244-z},
abstract = {Thanks to recent advancements in image processing and deep learning techniques, visual surface inspection in production lines has become an automated process as long as all the defects are visible in a single or a few images. However, it is often necessary to inspect parts under many different illumination conditions to capture all the defects. Training deep networks to perform this task requires large quantities of annotated data, which are rarely available and cumbersome to obtain. To alleviate this problem, we devised an original augmentation approach that, given a small image collection, generates rotated versions of the images while preserving illumination effects, something that random rotations cannot do. We introduce three real multi-illumination datasets, on which we demonstrate the effectiveness of our illumination preserving rotation approach. Training deep neural architectures with our approach delivers a performance increase of up to 51% in terms of AuPRC score over using standard rotations to perform data augmentation.},
journal = {Mach. Vision Appl.},
month = nov,
numpages = {16},
keywords = {Defect detection, Multi-illumination, Deep learning, Data augmentation, Photometric stereo, Quality control}
}

@inproceedings{10.5555/3524938.3525259,
author = {Geng, Sinong and Nassif, Houssam and Manzanares, Carlos A. and Reppen, A. Max and Sircar, Ronnie},
title = {Deep PQR: solving inverse reinforcement learning using anchor actions},
year = {2020},
publisher = {JMLR.org},
abstract = {We propose a reward function estimation framework for inverse reinforcement learning with deep energy-based policies. We name our method PQR, as it sequentially estimates the Policy, the Q- function, and the Reward function by deep learning. PQR does not assume that the reward solely depends on the state, instead it allows for a dependency on the choice of action. Moreover, PQR allows for stochastic state transitions. To accomplish this, we assume the existence of one anchor action whose reward is known, typically the action of doing nothing, yielding no reward. We present both estimators and algorithms for the PQR method. When the environment transition is known, we prove that the PQR reward estimator uniquely recovers the true reward. With unknown transitions, we bound the estimation error of PQR. Finally, the performance of PQR is demonstrated by synthetic and real-world datasets.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {321},
numpages = {11},
series = {ICML'20}
}

@article{10.1016/j.compag.2021.106267,
author = {Ghazal, Sumaira and Qureshi, Waqar S. and Khan, Umar S. and Iqbal, Javaid and Rashid, Nasir and Tiwana, Mohsin I.},
title = {Analysis of visual features and classifiers for Fruit classification problem},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {187},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106267},
doi = {10.1016/j.compag.2021.106267},
journal = {Comput. Electron. Agric.},
month = aug,
numpages = {9},
keywords = {Neural networks, Supervised learning, Fruit classification, K nearest neighbors classifier, Agricultural automation}
}

@article{10.1016/j.patrec.2021.01.034,
author = {Wu, Xinhua and Liu, Xiujie},
title = {Building crack identification and total quality management method based on deep learning},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2021.01.034},
doi = {10.1016/j.patrec.2021.01.034},
journal = {Pattern Recogn. Lett.},
month = may,
pages = {225–231},
numpages = {7},
keywords = {Crack detection, Image segmentation, Deep learning, Quality management, Image recognition}
}

@article{10.1007/s40595-013-0008-z,
author = {Abaei, Golnoush and Selamat, Ali},
title = {A survey on software fault detection based on different prediction approaches},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-013-0008-z},
doi = {10.1007/s40595-013-0008-z},
abstract = {One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Na\"{\i}ve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Na\"{\i}ve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together.},
journal = {Vietnam J. of Computer Science},
month = may,
pages = {79–95},
numpages = {17},
keywords = {AISParallel, Artificial immune system, CSCA, Machine learning, Random forest, Software fault prediction}
}

@article{10.1016/j.patcog.2017.10.005,
author = {Zhou, Sanping and Wang, Jinjun and Meng, Deyu and Xin, Xiaomeng and Li, Yubing and Gong, Yihong and Zheng, Nanning},
title = {Deep self-paced learning for person re-identification},
year = {2018},
issue_date = {April 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2017.10.005},
doi = {10.1016/j.patcog.2017.10.005},
abstract = {We propose a novel deep self-paced learning algorithm to supervise the learning of deep neural network, in which a soft polynomial regularizer term is proposed to gradually involve the faithful samples into training process in a self-paced manner.We optimize the gradient back-propagation of relative distance metric by introducing a symmetric regularizer term, which can convert the back-propagation from the asymmetric mode to a symmetric one.We build an effective part-based deep neural network, in which features of different body parts are first discriminately learned in the convolutional layers and then fused in the fully connected layers. Person re-identification(Re-ID) usually suffers from noisy samples with background clutter and mutual occlusion, which makes it extremely difficult to distinguish different individuals across the disjoint camera views. In this paper, we propose a novel deep self-paced learning(DSPL) algorithm to alleviate this problem, in which we apply a self-paced constraint and symmetric regularization to help the relative distance metric training the deep neural network, so as to learn the stable and discriminative features for person Re-ID. Firstly, we propose a soft polynomial regularizer term which can derive the adaptive weights to samples based on both the training loss and model age. As a result, the high-confidence fidelity samples will be emphasized and the low-confidence noisy samples will be suppressed at early stage of the whole training process. Such a learning regime is naturally implemented under a self-paced learning(SPL) framework, in which samples weights are adaptively updated based on both model age and sample loss using an alternative optimization method. Secondly, we introduce a symmetric regularizer term to revise the asymmetric gradient back-propagation derived by the relative distance metric, so as to simultaneously minimize the intra-class distance and maximize the inter-class distance in each triplet unit. Finally, we build a part-based deep neural network, in which the features of different body parts are first discriminately learned in the lower convolutional layers and then fused in the higher fully connected layers. Experiments on several benchmark datasets have demonstrated the superior performance of our method as compared with the state-of-the-art approaches.},
journal = {Pattern Recogn.},
month = apr,
pages = {739–751},
numpages = {13},
keywords = {Convolutional neural network, Metric learning, Person re-identification, Self-paced learning}
}

@article{10.1016/j.ins.2021.05.008,
author = {Zhang, Nana and Ying, Shi and Ding, Weiping and Zhu, Kun and Zhu, Dandan},
title = {WGNCS: A robust hybrid cross-version defect model via multi-objective optimization and deep enhanced feature representation},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {570},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.05.008},
doi = {10.1016/j.ins.2021.05.008},
journal = {Inf. Sci.},
month = sep,
pages = {545–576},
numpages = {32},
keywords = {Cross-version defect prediction, Multi-objective feature selection, Deep learning techniques, Wasserstein GAN with Gradient Penalty, Convolutional neural network}
}

@inproceedings{10.1007/978-3-030-76423-4_6,
author = {Delconte, Florian and Ngo, Phuc and Debled-Rennesson, Isabelle and Kerautret, Bertrand and Nguyen, Van-Tho and Constant, Thiery},
title = {Tree Defect Segmentation Using Geometric Features and CNN},
year = {2021},
isbn = {978-3-030-76422-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-76423-4_6},
doi = {10.1007/978-3-030-76423-4_6},
abstract = {Estimating the quality of standing trees or roundwood after felling is a crucial step in forest production trading. The on-going revolution in the forest sector resulting from the use of 3D sensors can also contribute to this step. Among them the terrestrial lidar scanning is a reference descriptive method offering the possibility to segment defects. In this paper, we propose a new reproducible method allowing to automatically segment the defects. It is based on the construction of a relief map inspired from a previous strategy and combining with a convolutional neural network to improve the resulting segmentation quality. The proposed method outperforms the previous results and the source code is publicly available with an online demonstration allowing to test the defect detection without any software installation.},
booktitle = {Reproducible Research in Pattern Recognition: Third International Workshop, RRPR 2021, Virtual Event, January 11, 2021, Revised Selected Papers},
pages = {80–100},
numpages = {21},
keywords = {Wood surface defects, Defect segmentation, Relief map, LIDAR, Centerline, U-Net}
}

@inproceedings{10.1145/3302425.3302428,
author = {Shi, Linlin and Jia, Hanguang and Zhou, Zhenwei and Yu, Pengfei and Cheng, Liye and Huang, Yun},
title = {Health and Effectiveness Assessment of Aeronautical General Processing System Based on Feature Analysis of State Parameters},
year = {2018},
isbn = {9781450366250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302425.3302428},
doi = {10.1145/3302425.3302428},
abstract = {This paper uses fault injection to simulate the degradation state of each module of P2020. Based on the time-domain data of the sensitivity parameters of each module under normal and fault injection conditions, a health and effectiveness evaluation method for general aviation processing system based on parameter feature analysis isproposed. Firstly, feature extraction, feature selection and principal component analysis are used to form a sample set of health assessment parameters for each module of P2020 system. Then, mahalanobis distance is used to evaluate the health status of each key module and calculate the health degree. Finally, the system effectiveness of P2020 is obtained by AHP (The analytic hierarchy process) and ADC model. The analysis of test data shows that this method has high accuracy and accuracy for health and effectiveness evaluation of general aviation processing system.},
booktitle = {Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence},
articleno = {2},
numpages = {6},
keywords = {Feature extraction, PCA, effectiveness assessment, feature selection, mahalanobis distance},
location = {Sanya, China},
series = {ACAI '18}
}

@inproceedings{10.1145/1964138.1964139,
author = {Silva, Alan Pedro da and Costa, Evandro and Bittencourt, Ig Ibert and Brito, Patrick H. S. and Holanda, Olavo and Melo, Jean},
title = {Ontology-based software product line for building semantic web applications},
year = {2010},
isbn = {9781450305426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1964138.1964139},
doi = {10.1145/1964138.1964139},
abstract = {The Software Product Lines (SPL) has proved very effective in building large-scale software. However, few works seek to adjust the approach of software product line to applications in the context of semantic web. This is because applications in this context assume the use of semantic services and intelligent agents. As a result, it is necessary that there are assets that provide adequate interoperability both semantic services and intelligent agents. In this sense, it is proposed in this paper the use of ontologies for the specification of entire a project of a SPL. With this, it can be a sufficiently formal specification that can be interpreted by both software engineers and computational algorithms.},
booktitle = {Proceedings of the 2010 Workshop on Knowledge-Oriented Product Line Engineering},
articleno = {1},
numpages = {6},
keywords = {ontology, semantic web, software product line},
location = {Reno, Nevada},
series = {KOPLE '10}
}

@inproceedings{10.1007/978-3-642-27549-4_49,
author = {Ramler, Rudolf and Natschl\"{a}ger, Thomas},
title = {Applying heuristic approaches for predicting defect-prone software components},
year = {2011},
isbn = {9783642275487},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-27549-4_49},
doi = {10.1007/978-3-642-27549-4_49},
abstract = {Effective and efficient quality assurance has to focus on those parts of a software system that are most likely to fail. Defect prediction promises to indicate the defect-prone components of a software system. In this paper we investigate the viability of predicting defect-prone components in upcoming releases of a large industrial software system. Prediction models constructed with heuristic machine learning are used to classify the components of future versions of the software system as defective or defect-free. It could be shown that the accuracy of the predictions made for the next version is significantly higher (around 74%) than guessing even when taking only new or modified components into account. Furthermore, the results reveal that, depending on the specific prediction model, acceptable accuracy can be achieved for up to three versions in the future.},
booktitle = {Proceedings of the 13th International Conference on Computer Aided Systems Theory - Volume Part I},
pages = {384–391},
numpages = {8},
keywords = {machine learning, software defect prediction},
location = {Las Palmas de Gran Canaria, Spain},
series = {EUROCAST'11}
}

@article{10.5555/3455716.3455938,
author = {Weinshall, Daphna and Amir, Dan},
title = {Theory of curriculum learning, with convex loss functions},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Curriculum Learning is motivated by human cognition, where teaching often involves gradually exposing the learner to examples in a meaningful order, from easy to hard. Although methods based on this concept have been empirically shown to improve performance of several machine learning algorithms, no theoretical analysis has been provided even for simple cases. To address this shortfall, we start by formulating an ideal definition of difficulty score - the loss of the optimal hypothesis at a given datapoint. We analyze the possible contribution of curriculum learning based on this score in two convex problems - linear regression, and binary classification by hinge loss minimization. We show that in both cases, the convergence rate of SGD optimization decreases monotonically with the difficulty score, in accordance with earlier empirical results. We also prove that when the difficulty score is fixed, the convergence rate of SGD optimization is monotonically increasing with respect to the loss of the current hypothesis at each point. We discuss how these results settle some confusion in the literature where two apparently opposing heuristics are reported to improve performance: curriculum learning in which easier points are given priority, vs hard data mining where the more difficult points are sought out.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {222},
numpages = {19},
keywords = {curriculum learning, linear regression, hinge loss minimization}
}

@inproceedings{10.5555/3304889.3305050,
author = {Wang, Nan and Zhao, Xibin and Jiang, Yu and Gao, Yue},
title = {Iterative metric learning for imbalance data classification},
year = {2018},
isbn = {9780999241127},
publisher = {AAAI Press},
abstract = {In many classification applications, the amount of data from different categories usually vary significantly, such as software defect predication and medical diagnosis. Under such circumstances, it is essential to propose a proper method to solve the imbalance issue among the data. However, most of the existing methods mainly focus on improving the performance of classifiers rather than searching for an appropriate way to find an effective data space for classification. In this paper, we propose a method named Iterative Metric Learning (IML) to explore the correlations among the imbalance data and construct an effective data space for classification. Given the imbalance training data, it is important to select a subset of training samples for each testing data. Thus, we aim to find a more stable neighborhood for the testing data using the iterative metric learning strategy. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {2805–2811},
numpages = {7},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@inproceedings{10.1007/978-3-030-77004-4_20,
author = {Molefe, Mohale and Tapamo, Jules-Raymond},
title = {Classification of Rail Welding Defects Based on the Bag of Visual Words Approach},
year = {2021},
isbn = {978-3-030-77003-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77004-4_20},
doi = {10.1007/978-3-030-77004-4_20},
abstract = {Railway transportation is one of the safest modes of transportation commonly used to transport heavy freight. Rails are the most critical and maintenance demanding component of the railway infrastructure. Rails are usually welded together during the installation process to form a continuous railway line using the thermite welding process. However, thermite welding is prone to the formation of defects on the welded rails, thus the weld joint is usually inspected. Radiography is the widely used Non-Destructive Testing method to inspect the weld joint for possible defects which could have occurred during the welding process. However, the detection and classification of defects from the generated radiography images is done manually by a trained radiography expert. Furthermore, the process is lengthy, costly and subjective even if conducted by a trained expert. This work presents an automated defect detection and classification method based on the Bag of Visual Words approach where the Speeded Up Robust Feature is used as the low-level feature descriptor. A Support Vector Machine is used as the classifier. The proposed method achieved the average classification accuracy of 94.60%.},
booktitle = {Pattern Recognition: 13th Mexican Conference, MCPR 2021, Mexico City, Mexico, June 23–26, 2021, Proceedings},
pages = {207–218},
numpages = {12},
keywords = {Railway transportation, Thermite welding, Bag of visual words, Support vector machine},
location = {Mexico City, Mexico}
}

@article{10.1016/j.vlsi.2021.08.004,
author = {Saidi, Afef and Ben Othman, Slim and Dhouibi, Meriam and Ben Saoud, Slim},
title = {FPGA-based implementation of classification techniques: A survey},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {81},
number = {C},
issn = {0167-9260},
url = {https://doi.org/10.1016/j.vlsi.2021.08.004},
doi = {10.1016/j.vlsi.2021.08.004},
journal = {Integr. VLSI J.},
month = nov,
pages = {280–299},
numpages = {20},
keywords = {Machine learning, Deep learning, Classification, Implementation, Optimizations, Challenges}
}

@article{10.1016/j.engappai.2018.06.011,
author = {Baltazar, Arturo and Fernandez-Ramirez, Karla I. and Aranda-Sanchez, Jorge I.},
title = {A study of chaotic searching paths for their application in an ultrasonic scanner},
year = {2018},
issue_date = {Sep 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {74},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2018.06.011},
doi = {10.1016/j.engappai.2018.06.011},
journal = {Eng. Appl. Artif. Intell.},
month = sep,
pages = {271–279},
numpages = {9},
keywords = {Chaos, Ultrasonic scanner, Probability of detection}
}

@inproceedings{10.1145/3460268.3460278,
author = {Yu, Qingmin and Huang, Ying and Liu, Yang and Yu, Sicong and Wang, Shijie},
title = {Research on Application of Information Model in Wind Turbine Fault Diagnosis},
year = {2021},
isbn = {9781450389273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460268.3460278},
doi = {10.1145/3460268.3460278},
abstract = {With the increasing proportion of wind power technology in China's energy structure, the fault diagnosis technology of generators, which is the key equipment of wind power generation, is becoming increasingly important. At present, the methods of the fault diagnosis of wind turbines are mostly based on traditional SCADA systems and big data analysis technology. The fault diagnosis process is complicated. Based on the current mature Internet technology, this paper introduces the concept of the Industrial Internet information model into the fault diagnosis of wind turbines and realizes the intelligentization of fault diagnosis of wind turbines. At the same time, the feasibility analysis of this scheme was carried out by studying the existing related cases. The results show that the information model has a stronger application prospect in the fault diagnosis of wind turbines. Compared with traditional methods, the new solution proposed in this paper makes the operation and maintenance and diagnosis of wind turbines more ideal.},
booktitle = {Proceedings of the 2021 2nd International Conference on Artificial Intelligence in Electronics Engineering},
pages = {67–74},
numpages = {8},
keywords = {Digital Twin, Fault Diagnosis, Industrial Internet Information Model, Wind Turbine},
location = {Phuket, Thailand},
series = {AIEE '21}
}

@inproceedings{10.1609/aaai.v33i01.33015725,
author = {Zhang, Biqiao and Kong, Yuqing and Essl, Georg and Provost, Emily Mower},
title = {undefined-similarity preservation loss for soft labels: a demonstration on cross-corpus speech emotion recognition},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33015725},
doi = {10.1609/aaai.v33i01.33015725},
abstract = {In this paper, we propose a Deep Metric Learning (DML) approach that supports soft labels. DML seeks to learn representations that encode the similarity between examples through deep neural networks. DML generally presupposes that data can be divided into discrete classes using hard labels. However, some tasks, such as our exemplary domain of speech emotion recognition (SER), work with inherently subjective data, data for which it may not be possible to identify a single hard label. We propose a family of loss functions, undefined-Similarity Preservation Loss (undefined-SPL), based on the dual form of undefined-divergence for DML with soft labels. We show that the minimizer of undefined-SPL preserves the pairwise label similarities in the learned feature embeddings. We demonstrate the efficacy of the proposed loss function on the task of cross-corpus SER with soft labels. Our approach, which combines undefined-SPL and classification loss, significantly outperforms a baseline SER system with the same structure but trained with only classification loss in most experiments. We show that the presented techniques are more robust to over-training and can learn an embedding space in which the similarity between examples is meaningful.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {702},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1007/978-3-030-78609-0_28,
author = {Sun, Ying and Sun, Yanfei and Wu, Fei and Jing, Xiao-Yuan},
title = {Deep Adversarial Learning Based Heterogeneous Defect Prediction},
year = {2021},
isbn = {978-3-030-78608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78609-0_28},
doi = {10.1007/978-3-030-78609-0_28},
abstract = {Cross-project defect prediction (CPDP) is a hot study that predicts defects in the new project by utilizing the model trained on the data from other projects. However, existing CPDP methods usually assume that source and target projects have the same metrics. Heterogeneous defect prediction (HDP) is proposed and has attracted increasing attention, which refers to the metric sets from source and target projects are different in CPDP. HDP conducts prediction model using the instances with heterogeneous metrics from external projects and then use this model to predict defect-prone software instances in source project. However, building HDP methods is challenging including the distribution difference between source and target projects with heterogeneous metrics. In this paper, we propose a Deep adversarial learning based HDP (DHDP) approach. DHDP leverages deep neural network to learn nonlinear transformation for each project to obtain common feature represent, which the heterogeneous data from different projects can be compared directly. DHDP consists of two parts: a discriminator and a classifier that compete with each other. A classifier tries to minimize the similarity across classes and maximize the inter-class similarity. A discriminator tries to distinguish the source of instances that is source or target project on the common feature space. Expensive experiments are performed on 10 public projects from two datasets in terms of F-measure and G-measure. The experimental results show that DHDP gains superior prediction performance improvement compared to a range of competing methods.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part I},
pages = {326–337},
numpages = {12},
keywords = {Adversarial learning, Metric learning, Heterogeneous defect prediction},
location = {Dublin, Ireland}
}

@inproceedings{10.1145/3177148.3180085,
author = {Surendranath, Ajay and Jayagopi, Dinesh Babu},
title = {Curriculum Learning for Depth Estimation with Deep Convolutional Neural Networks},
year = {2018},
isbn = {9781450352901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177148.3180085},
doi = {10.1145/3177148.3180085},
abstract = {Curriculum learning is a machine learning technique adapted from the way humans acquire knowledge and skills, initially mastering simple tasks and progressing to more complex tasks. The work explores curriculum training by creating multiple levels of dataset with increasing complexity on which the trainings are performed. The experiments demonstrated that there is an average of 12% improvement test loss when compared to a non-curriculum approach. The experiment also demonstrates the advantage of creating synthetic dataset and how it aids in the overall improvement of accuracy. An improvement of 26% is attained on the test error loss when curriculum trained model was compared to training on a limited real world dataset. The work also goes onto propose a novel learning approach, the Self Paced Learning approach with Error-Diversity (SPL-ED) An overall reduction of 32% in the test loss is observed when compared to the non-curriculum training limited to real-world dataset.},
booktitle = {Proceedings of the 2nd Mediterranean Conference on Pattern Recognition and Artificial Intelligence},
pages = {95–100},
numpages = {6},
keywords = {Curriculum Learning, Depth Estimation},
location = {Rabat, Morocco},
series = {MedPRAI '18}
}

@inproceedings{10.1007/978-3-030-22999-3_4,
author = {Havelock, Jessica and Oommen, B. John and Granmo, Ole-Christoffer},
title = {On Using “Stochastic Learning on the Line” to Design Novel Distance Estimation Methods for Three-Dimensional Environments},
year = {2019},
isbn = {978-3-030-22998-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-22999-3_4},
doi = {10.1007/978-3-030-22999-3_4},
abstract = {We consider the unsolved problem of Distance Estimation (DE) when the inputs are the x and y coordinates (i.e., the latitudinal and longitudinal positions) of the points under consideration, and the elevation/altitudes of the points specified, for example, in terms of their z coordinates (3DDE). The aim of the problem is to yield an accurate value for the real (road) distance between the points specified by all the three coordinates of the cities in question (This is a typical problem encountered in a GISs and GPSs.). In our setting, the distance between any pair of cities is assumed to be computed by merely having access to the coordinates and known inter-city distances of a small subset of the cities, where these are also specified in terms of their 3D coordinates. The 2D variant of the problem has, typically, been tackled by utilizing parametric functions called “Distance Estimation Functions” (DEFs). To solve the 3D problem, we resort to the Adaptive Tertiary Search (ATS) strategy, proposed by Oommen et al., to affect the learning. By utilizing the information provided in the 3D coordinates of the nodes and the true road distances from this subset, we propose a scheme to estimate the inter-nodal distances. In this regard, we use the ATS strategy to calculate the best parameters for the DEF. While “Goodness-of-Fit” (GoF) functions can be used to show that the results are competitive, we show that they are rather not necessary to compute the parameters. Our results demonstrate the power of the scheme, even though we completely move away from the traditional GoF-based paradigm that has been used for four decades. Our results conclude that the 3DDE yields results that are far superior to those obtained by the corresponding 2DDE.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 32nd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2019, Graz, Austria, July 9–11, 2019, Proceedings},
pages = {39–49},
numpages = {11},
keywords = {Road distance estimation, Estimating real-life distances, Learning Automata, Adaptive Tertiary Search, Stochastic Point Location},
location = {Graz, Austria}
}

@article{10.1007/s10845-020-01571-4,
author = {Park, Seyoung and Jang, Jaeyeon and Kim, Chang Ouk},
title = {Discriminative feature learning and cluster-based defect label reconstruction for reducing uncertainty in wafer bin map labels},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01571-4},
doi = {10.1007/s10845-020-01571-4},
abstract = {Many studies have been conducted to improve wafer bin map (WBM) defect classification performance because accurate WBM classification can provide information about abnormal processes causing a decrease in yield. However, in the actual manufacturing field, the manual labeling performed by engineers leads to a high level of uncertainty. Label uncertainty has been a major cause of the reduction in WBM classification system performance. In this paper, we propose a class label reconstruction method for subdividing a defect class with various patterns into several groups, creating a new class for defect samples that cannot be categorized into known classes and detecting unknown defects. The proposed method performs discriminative feature learning of the Siamese network and repeated cross-learning of the class label reconstruction based on Gaussian means clustering in a learned feature space. We verified the proposed method using a real-world WBM dataset. In a situation where there the class labels of the training dataset were corrupted, the proposed method could increase the classification accuracy of the test dataset by enabling the corrupted sample to find its original class label. As a result, the accuracy of the proposed method was up to 7.8% higher than that of the convolutional neural network (CNN). Furthermore, through the proposed class label reconstruction, we found a new mixed-type defect class that had not been found until now, and we detected new types of unknown defects that were not used for learning with an average accuracy of over 73%.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {251–263},
numpages = {13},
keywords = {Wafer bin map, Label uncertainty, Class label reconstruction, Unknown defect detection, Siamese network, G-means clustering}
}

@article{10.1016/j.camwa.2011.11.019,
author = {Razmjooy, Navid and Mousavi, B. Somayeh and Soleymani, F.},
title = {A real-time mathematical computer method for potato inspection using machine vision},
year = {2012},
issue_date = {January, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {63},
number = {1},
issn = {0898-1221},
url = {https://doi.org/10.1016/j.camwa.2011.11.019},
doi = {10.1016/j.camwa.2011.11.019},
abstract = {Detection of external defects on potatoes is the most important technology in the realization of automatic potato sorting stations. This paper presents a hierarchical grading method applied to the potatoes. In this work a potato defect detection combining with size sorting system using the machine vision will be proposed. This work also will focus on the mathematics methods used in automation with a particular emphasis on the issues associated with designing, implementing and using classification algorithms to solve equations. In the first step, a simple size sorting based on mathematical binarization is described, and the second step is to segment the defects; to do this, color based classifiers are used. All the detection standards for this work are referenced from the United States Agriculture Department, and Canadian Food Industries. Results show that we have a high accuracy in both size sorting and classification. Experimental results show that support vector machines have very high accuracy and speed between classifiers for defect detection.},
journal = {Comput. Math. Appl.},
month = jan,
pages = {268–279},
numpages = {12},
keywords = {Defect detection, K nearest neighborhood, Mathematical morphology, Otsu thresholding, Potato, Support vector machines}
}

@inproceedings{10.5555/3524938.3525166,
author = {Degenne, R\'{e}my and Shao, Han and Koolen, Wouter M.},
title = {Structure adaptive algorithms for stochastic bandits},
year = {2020},
publisher = {JMLR.org},
abstract = {We study reward maximisation in a wide class of structured stochastic multi-armed bandit problems, where the mean rewards of arms satisfy some given structural constraints, e.g. linear, unimodal, sparse, etc. Our aim is to develop methods that are flexible (in that they easily adapt to different structures), powerful (in that they perform well empirically and/or provably match instance-dependent lower bounds) and efficient in that the per-round computational burden is small. We develop asymptotically optimal algorithms from instance-dependent lower-bounds using iterative saddle-point solvers. Our approach generalises recent iterative methods for pure exploration to reward maximisation, where a major challenge arises from the estimation of the suboptimality gaps and their reciprocals. Still we manage to achieve all the above desiderata. Notably, our technique avoids the computational cost of the full-blown saddle point oracle employed by previous work, while at the same time enabling finite-time regret bounds. Our experiments reveal that our method successfully leverages the structural assumptions, while its regret is at worst comparable to that of vanilla UCB.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {228},
numpages = {10},
series = {ICML'20}
}

@article{10.1007/s10664-018-9596-7,
author = {Ferrari, Alessio and Gori, Gloria and Rosadini, Benedetta and Trotta, Iacopo and Bacherini, Stefano and Fantechi, Alessandro and Gnesi, Stefania},
title = {Detecting requirements defects with NLP patterns: an industrial experience in the railway domain},
year = {2018},
issue_date = {December  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9596-7},
doi = {10.1007/s10664-018-9596-7},
abstract = {In the railway safety-critical domain requirements documents have to abide to strict quality criteria. Rule-based natural language processing (NLP) techniques have been developed to automatically identify quality defects in natural language requirements. However, the literature is lacking empirical studies on the application of these techniques in industrial settings. Our goal is to investigate to which extent NLP can be practically applied to detect defects in the requirements documents of a railway signalling manufacturer. To address this goal, we first identified a set of typical defects classes, and, for each class, an engineer of the company implemented a set of defect-detection patterns by means of the GATE tool for text processing. After a preliminary analysis, we applied the patterns to a large set of 1866 requirements previously annotated for defects. The output of the patterns was further inspected by two domain experts to check the false positive cases. Additional discard-patterns were defined to automatically remove these cases. Finally, SREE, a tool that searches for typically ambiguous terms, was applied to the requirements. The experiments show that SREE and our patterns may play complementary roles in the detection of requirements defects. This is one of the first works in which defect detection NLP techniques are applied on a very large set of industrial requirements annotated by domain experts. We contribute with a comparison between traditional manual techniques used in industry for requirements analysis, and analysis performed with NLP. Our experience shows that several discrepancies can be observed between the two approaches. The analysis of the discrepancies offers hints to improve the capabilities of NLP techniques with company specific solutions, and suggests that also company practices need to be modified to effectively exploit NLP tools.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {3684–3733},
numpages = {50},
keywords = {Ambiguity, Defect detection, Industrial case study, Natural language processing, Natural language requirements, Precision, Railway, Recall, Requirements analysis, Requirements engineering}
}

@inproceedings{10.1007/978-3-030-32409-4_1,
author = {Liu, Yang and Ma, Lei and Zhao, Jianjun},
title = {Secure Deep Learning Engineering: A Road Towards Quality Assurance of Intelligent Systems},
year = {2019},
isbn = {978-3-030-32408-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32409-4_1},
doi = {10.1007/978-3-030-32409-4_1},
abstract = {Over the past decades, deep learning (DL) systems have achieved tremendous success and gained great popularity in various applications, such as intelligent machines, image processing, speech processing, and medical diagnostics. Deep neural networks are the key driving force behind its recent success, but still seem to be a magic black box lacking interpretability and understanding. This brings up many open safety and security issues with enormous and urgent demands on rigorous methodologies and engineering practice for quality enhancement. A plethora of studies have shown that state-of-the-art DL systems suffer from defects and vulnerabilities that can lead to severe loss and tragedies, especially when applied to real-world safety-critical applications.In this paper, we perform a large-scale study and construct a paper repository of 223 relevant works to the quality assurance, security, and interpretation of deep learning. Based on this, we, from a software quality assurance perspective, pinpoint challenges and future opportunities to facilitate drawing the attention of the software engineering community towards addressing the pressing industrial demand of secure intelligent systems.},
booktitle = {Formal Methods and Software Engineering: 21st International Conference on Formal Engineering Methods, ICFEM 2019, Shenzhen, China, November 5–9, 2019, Proceedings},
pages = {3–15},
numpages = {13},
keywords = {Artificial intelligence, Deep learning, Software engineering, Security, Quality assurance, Reliability, Deep learning engineering},
location = {Shenzhen, China}
}

@inproceedings{10.1145/3469213.3470286,
author = {Yu, Tong and Xie, Ming and Li, Xin and Ling, Ying and Bin, Dongmei and Yang, Chunyan},
title = {Network attack detection method for power system terminal based on improved random forest},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3470286},
doi = {10.1145/3469213.3470286},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {85},
numpages = {6},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@inproceedings{10.1145/3467707.3467709,
author = {Xiao, Zhitao and Guo, Quan and Guo, Yongmin and Huang, Yalong},
title = {Ultrasonic A-Scan Image Detection for 3D Braided Composites Based on Convolutional Neural Network},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3467707.3467709},
doi = {10.1145/3467707.3467709},
abstract = {Automatic ultrasonic signal classification of 3D braided composites is finding increasing use in many applications for the interpretation of signals. In this paper, we present a method for ultrasonic A-scan image classification based on deep convolutional neural network (CNN) model. The ultrasonic signal data set was obtained from Olympus Omniscan MX2 and divided into training data set and test data set. The batch normalization layer and the inception layer followed by max pool layer are added to the CNN model, which can speed up convergence of the deep learning network and improve the accuracy. With CNN model used for training the signals with debongding and the non-defect signals, experimental results showed that the accuracy rate of the method we proposed in the test data set reached 99.55%, which was greatly improved compared with AlexNet model and ResNet-34 network.},
booktitle = {Proceedings of the 2021 7th International Conference on Computing and Artificial Intelligence},
pages = {8–14},
numpages = {7},
keywords = {Ultrasonic signal classification • Deep learning • Olympus Omniscan MX2},
location = {Tianjin, China},
series = {ICCAI '21}
}

@inproceedings{10.1145/3297156.3297203,
author = {Hasbi, Muhamad and Budiardjo, Eko K. and Wibowo, Wahyu C.},
title = {Reverse Engineering in Software Product Line - A Systematic Literature Review},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297203},
doi = {10.1145/3297156.3297203},
abstract = {Reverse engineering is the information extraction process on system by identifying and analyzing the components that are part of that system. We analyze existing research that related with reverse engineering process on software product line. There are two product line processes according to Software product line engineering framework they are domain engineering process and application engineering process. We investigate reverse engineering in domain engineering process (domain requirements, domain design, and domain realization, domain quality assurance). We performed a systematic literature review. A manual search resulting 71 papers considered for analysis. Results: The majority of reverse engineering studied in three domain activity in domain engineering process. That is requirement engineering, domain design and domain realization. There are inconsistent correlations between features in the reverse engineering process. These approaches extract features without constraints between its features. Conclusions: Reverse engineering methods are needed that are able to identify and maintain a consistent correlation between features in application engineering and domain engineering in the reverse engineering process. Finally, we provide gaps from existing research and show opportunities for future research.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {174–179},
numpages = {6},
keywords = {Reverse engineering, domain engineering, software product line, systematic review},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1007/978-3-030-89095-7_23,
author = {Lu, Jialei and Ma, Kaiwei and Shi, Wei and Xu, Fengyu},
title = {Testing Method and Experiment of Magnetic Flux Leakage of Spiral Rising Steel Wire Rope},
year = {2021},
isbn = {978-3-030-89094-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89095-7_23},
doi = {10.1007/978-3-030-89095-7_23},
abstract = {In view of the magnetic flux leakage detection of cable wire broken defects, the magnetic flux leakage magnetic circuit is analyzed firstly, and the calculation formula of magnetic induction intensity and the sufficient excitation condition of the wire rope are obtained. Ansoft Maxwell software was used to carry out the finite element simulation analysis of the axial leakage magnetic field of the wire rope to verify the theoretical analysis results of the magnetic circuit model. Secondly, the modularized cable excitation detection device is designed. The filtering effects of Chebyshev digital filter and Fourier transform are compared. Finally, the magnetic detection under the spiral motion and the magnetic detection under the vertical motion are compared through experimental research.},
booktitle = {Intelligent Robotics and Applications: 14th International Conference, ICIRA 2021, Yantai, China, October 22–25, 2021, Proceedings, Part I},
pages = {232–240},
numpages = {9},
keywords = {Wire rope, Magnetic detection, Spiral rising, Experiment},
location = {Yantai, China}
}

@article{10.1016/j.engappai.2019.08.015,
author = {Tavasoli, Hanane and Oommen, B. John and Yazidi, Anis},
title = {On utilizing weak estimators to achieve the online classification of data streams},
year = {2019},
issue_date = {Nov 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {86},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.08.015},
doi = {10.1016/j.engappai.2019.08.015},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
pages = {11–31},
numpages = {21},
keywords = {Weak estimators, Learning automata, Non-stationary environments, Classification in data streams}
}

@inproceedings{10.1007/978-3-030-33709-4_5,
author = {Tasnim Cynthia, Shamse and Rasul, Md. Golam and Ripon, Shamim},
title = {Effect of Feature Selection in Software Fault Detection},
year = {2019},
isbn = {978-3-030-33708-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33709-4_5},
doi = {10.1007/978-3-030-33709-4_5},
abstract = {The quality of software is enormously affected by the faults associated with it. Detection of faults at a proper stage in software development is a challenging task and plays a vital role in the quality of the software. Machine learning is, now a days, a commonly used technique for fault detection and prediction. However, the effectiveness of the fault detection mechanism is impacted by the number of attributes in the publicly available datasets. Feature selection is the process of selecting a subset of all the features that are most influential to the classification and it is a challenging task. This paper thoroughly investigates the effect of various feature selection techniques on software fault classification by using NASA’s some benchmark publicly available datasets. Various metrics are used to analyze the performance of the feature selection techniques. The experiment discovers that the most important and relevant features can be selected by the adopted feature selection techniques without sacrificing the performance of fault detection.},
booktitle = {Multi-Disciplinary Trends in Artificial Intelligence: 13th International Conference, MIWAI 2019, Kuala Lumpur, Malaysia, November 17–19, 2019, Proceedings},
pages = {52–63},
numpages = {12},
keywords = {Fault detection, Feature selection, Feature classification},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3446132.3446133,
author = {Zhu, Li-ming and Zhang, Min and Zhang, Qiang},
title = {An Intelligent Forecasting Method for Cigarette Equipment Maintenance Based on Fuzzy Mathematics Improved Analytic Hierarchy Process},
year = {2021},
isbn = {9781450388115},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3446132.3446133},
doi = {10.1145/3446132.3446133},
abstract = {Predictive maintenance uses improved Fuzzy Analytic Hierarchy Process (FAHP) model to calculate the weight of equipment failure and the comprehensive index information of equipment failure, to identify its deterioration trend, and to judge its trend, to calculate the comprehensive maintenance threshold, to generate maintenance decision information and to identify the equipment locations that need to be disposed of.},
booktitle = {Proceedings of the 2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence},
articleno = {1},
numpages = {4},
location = {Sanya, China},
series = {ACAI '20}
}

@inproceedings{10.1145/3377812.3390902,
author = {Zhang, Xindong and Zhu, Chenguang and Li, Yi and Guo, Jianmei and Liu, Lihua and Gu, Haobo},
title = {Large-scale patch recommendation at Alibaba},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3390902},
doi = {10.1145/3377812.3390902},
abstract = {We present Precfix, a pragmatic approach targeting large-scale industrial codebase and making recommendations based on previously observed debugging activities. Precfix collects defect-patch pairs from development histories, performs clustering, and extracts generic reusable patching patterns as recommendations. Our approach is able to make recommendations within milliseconds and achieves a false positive rate of 22%. Precfix has been rolled out to Alibaba to support various critical businesses.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {252–253},
numpages = {2},
keywords = {defect detection, patch generation, patch recommendation},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.5555/3524938.3524952,
author = {Ahn, Sungsoo and Seo, Younggyo and Shin, Jinwoo},
title = {Learning what to defer for maximum independent sets},
year = {2020},
publisher = {JMLR.org},
abstract = {Designing efficient algorithms for combinatorial optimization appears ubiquitously in various scientific fields. Recently, deep reinforcement learning (DRL) frameworks have gained considerable attention as a new approach: they can automate the design of a solver while relying less on sophisticated domain knowledge of the target problem. However, the existing DRL solvers determine the solution using a number of stages proportional to the number of elements in the solution, which severely limits their applicability to large-scale graphs. In this paper, we seek to resolve this issue by proposing a novel DRL scheme, coined learning what to defer (LwD), where the agent adaptively shrinks or stretch the number of stages by learning to distribute the element-wise decisions of the solution at each stage. We apply the proposed framework to the maximum independent set (MIS) problem, and demonstrate its significant improvement over the current state-of-the-art DRL scheme. We also show that LwD can outperform the conventional MIS solvers on large-scale graphs having millions of vertices, under a limited time budget.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {14},
numpages = {11},
series = {ICML'20}
}

@article{10.5555/1482156.1482157,
author = {Paladini, Edson Pacheco},
title = {A pattern recognition and adaptive approach to quality control},
year = {2008},
issue_date = {July 2008},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {3},
number = {7},
issn = {1991-8763},
abstract = {The present paper describes some quality control tools that develop an interactive and on-line evaluation of industrial products. These tools use pattern recognition techniques in a dynamic way, it means, they control the variations of critical characteristics of industrial products during their effective use. They also make an adaptive evaluation because considers the characteristics of each product under analysis. The tools generate a dynamic and well structured model. The operation of the model considers a set of images of the product or parts of them during some specific use or specific moment. Using a Pattern Recognition Process, the images of the product or some parts of them are captured and they are associated to some special matrices. The model then analyses the properties of these images by evaluating the properties each corresponding matrix have. This process allows determining a set of values which describe the variations the product is showing during its use. We gave so a model which develops a continuous evaluation of product quality. Thus, the model checks whether the variations of the characteristic under study are acceptable or not, considering a set of limits defined by procedures which take into consideration particularities of the product being studied. Thereto, the model itself determines which reference values are to be used to evaluate such variations. In the case of monochromatic analyses, the model seeks to define reference parameters for defect detection using maximum variation limits of gray levels on the product surface (this makes possible to detect the presence of a crack, for instance). In the case of polychromatic analyses, having established a specific property (such as intensity, saturation or chromatic hue), the model determines the most adequate values for that property. Variations complying with those parameters are considered to be acceptable. The top and bottom values of the acceptable variations can accurately define product design characteristics from the effective practical use the product is supposed to have. This paper describes the model, reports the most usual situations for its use, discusses practical cases where it was used and provides a critical evaluation of the results obtained.},
journal = {WSEAS Trans. Sys. Ctrl.},
month = jul,
pages = {627–643},
numpages = {17},
keywords = {artificial intelligence, defect detection, pattern recognition, quality control}
}

@inproceedings{10.1145/2593801.2593803,
author = {Misirli, Ayse Tosun and Bener, Ay\c{s}e Ba\c{s}ar},
title = {A mapping study on bayesian networks for software quality prediction},
year = {2014},
isbn = {9781450328463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593801.2593803},
doi = {10.1145/2593801.2593803},
abstract = {Bayesian Networks (BN) have been used for decision making in software engineering for many years. We investigate the current status of BNs in predicting software quality in three aspects: 1) techniques used for parameter learning, 2) techniques used for structure learning, and 3) type of variables that represent BN nodes. We performed a systematic mapping study on 38 primary studies that employed BNs to predict software quality. The most popular technique for building the final structure of BNs is the use of expert knowledge with different inference algorithms. Variables in BNs are treated as categorical in more than 70% of studies. Compared to other domains, the usage of BNs is still very limited due to high dependency on expert knowledge and tools.},
booktitle = {Proceedings of the 3rd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {7–11},
numpages = {5},
keywords = {Software defect prediction, applications of Bayesian Networks, systematic mapping},
location = {Hyderabad, India},
series = {RAISE 2014}
}

@article{10.1016/0167-9317(95)00311-8,
author = {Cass, T.R. and Hendricks, D. and Jau, J. and Dohse, H.J. and Brodie, A.D. and Meisburger, W.D.},
title = {Application of the SEMSpec electron-beam inspection system to in-process defect detection on semiconductor wafers},
year = {1996},
issue_date = {Jan 1996},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {30},
number = {1},
issn = {0167-9317},
url = {https://doi.org/10.1016/0167-9317(95)00311-8},
doi = {10.1016/0167-9317(95)00311-8},
journal = {Microelectron. Eng.},
month = jan,
pages = {567–570},
numpages = {4}
}

@article{10.1007/s10845-012-0725-7,
author = {Kuo, Chung-Feng Jeffrey and Hsu, Chien-Tung Max and Liu, Zong-Xian and Wu, Han-Cheng},
title = {Automatic inspection system of LED chip using two-stages back-propagation neural network},
year = {2014},
issue_date = {December  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-012-0725-7},
doi = {10.1007/s10845-012-0725-7},
abstract = {This study proposed an automatic LED defect detection system to investigate the defects of LED chips. Such defects include fragment chips, scratch marks and remained gold on the pad area, scratch marks on the luminous zone, and missing luminous zone respectively. The system was based on positioning and image acquisition, appearance feature recognition, and defect classification. The normalized correlation coefficient method was used to locate the chip and acquire its image, the K-means clustering method was used to distinguish the appearance, pad area, and luminous zone of chips. In terms of pad area detection, histogram equalization was used to enhance the pad image contrast, and statistical threshold selection and morphological closing were applied to modify the impure points in the pad. Feature values of the pad area were then calculated. The optimal statistical threshold separated the luminous zone and background from the substrate. After processed with closing operation, features of the luminous zone were extracted. Finally, features of each part were clarified by an efficient two-step back-propagation neural network, where a designed appearance classifier and an internal structure classifier were used for recognition. From experiments, total recognition rate of this study achieved 97.83 %, proving that the detection method proposed by this study can efficiently detect LED chip defects.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {1235–1243},
numpages = {9},
keywords = {Automatic defect detection, Back propagation neural network, LED, Normalized correlation coefficient method}
}

@inproceedings{10.1145/3305275.3305322,
author = {Haixia, Li and Jican, Lin and Zhiyong, Huang and Geng, Li},
title = {Asynchronous Motor Vector Control Based on BP Neural Networks and Sliding Mode Observer},
year = {2018},
isbn = {9781450365703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3305275.3305322},
doi = {10.1145/3305275.3305322},
abstract = {In order to settle the questions of the asynchronous motor in the traditional PI control strategy, the parameters are fixed and easy to overshoot, and the poor robustness to the parameter change in the speed sensor-less is not available, this paper studies a vector control scheme of asynchronous motor speed sensor-less based on backward propagation (back propagation) BP neural network control and sliding mode observer. Sliding mode observer based on the relationship between stator flux and stator current of asynchronous motor, a mathematical state equation is deduced, and an observer model is built on the basis of sliding mode adaptive theory, thus realizing the speed estimation. The outer loop PI of motor speed is tuned by BP iterative optimization, compared with the traditional control scheme, this method is easy to realize, which can effectively improve the control accuracy, suppress the disturbance, and save the sensor cost. The correctness and feasibility of the control scheme are verified by the simulation experiment, the observer can realize the observation of stator flux and rotational speed, and the sliding mode observer is robust in the case of load disturbance and a given speed changes.},
booktitle = {Proceedings of the International Symposium on Big Data and Artificial Intelligence},
pages = {232–237},
numpages = {6},
keywords = {Asynchronous Motor, BP Neural Networks, Vector Control, sliding-mode observer, speed estimator},
location = {Hong Kong, Hong Kong},
series = {ISBDAI '18}
}

@inproceedings{10.5555/3504035.3504869,
author = {Fan, Xin and Liu, Risheng and Huyan, Kang and Feng, Yuyao and Luo, Zhongxuan},
title = {Self-reinforced cascaded regression for face alignment},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Cascaded regression is prevailing in face alignment thanks to its accuracy and robustness, but typically demands manually annotated examples having low discrepancy between shape-indexed features and shape updates. In this paper, we propose a self-reinforced strategy that iteratively expands the quantity and improves the quality of training examples, thus upgrading the performance of cascaded regression itself. The reinforced term evaluates the example quality upon the consistence on both local appearance and global geometry of human faces, and constitutes the example evolution by the philosophy of "survival of the fittest". We train a set of discriminative classifiers, each associated with one landmark label, to prune those examples with inconsistent local appearance, and further validate the geometric relationship among groups of labeled landmarks against the common global geometry derived from a projective invariant. We embed this generic strategy into typical cascaded regressions, and the alignment results on several benchmark data sets demonstrate its effectiveness to predict good examples starting from a small subset.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {834},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1145/3383972.3384008,
author = {Yang, Gao and Hao, Gong and Weijia, Lu and Qinghua, Wang and Chen, Su and Zhang, Ni},
title = {An Attentive Pruning Method for Edge Computing},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3384008},
doi = {10.1145/3383972.3384008},
abstract = {Nowadays, the power of an edge computing hardware is usually the bottleneck of AI application. Most of the embedding devices in factory have no GPU, some of them even using Intel i3 or ARM chips. Model compression is very convenient and effective way to handle this problem. But it still has two major limitations, the arbitrariness in pruning ratio setup and inevitable accuracy drop. In this paper, we propose an adaptive network channel pruning method without a priori knowledge of pruning ratio. This method is based on the attentive weights from modified SE block, establishes a detectable and trainable mask learning module from the original to-be-prune network. Moreover we make innovative modifications on SE block, to enhance the sparsity of attentive weights. Extensive experiments afterwards indicate that our method can not only accelerate model inference process or equivalently decrease model footprint, but also get better performance in test set. Even a tiny network like Yolo cifar-10 with 15 layers can be pruned about 50% FLOPs without accuracy decrease using proposed method.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {6–10},
numpages = {5},
keywords = {Improved SE block, Keep Accuracy, Model Compress},
location = {Shenzhen, China},
series = {ICMLC '20}
}

@inproceedings{10.1145/3445815.3445842,
author = {Zeshan, Muhammad Umar and Gang, Pan},
title = {Automatic Sewer Cracks Localization using Deformable Bounding Boxes},
year = {2021},
isbn = {9781450388436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445815.3445842},
doi = {10.1145/3445815.3445842},
abstract = {The underground sewage system is a crucial part of the infrastructure of any modern municipality across the globe. The underground sewage system is a crucial part of the infrastructure of any modern municipality across the globe. However, with the passage of time, sewer pipes systematically become prone to distortion depending upon the degree of usage and location factors such as the passage of heavy traffic nearby or deep-rooted trees. So, the regular inspection of these pipes requires a lot of technical attention as failure to do so can cause a huge financial and environmental disaster. In this regard, CCTV inspection is considered an effective way of monitoring buried pipes worldwide. As these drainage pipes are extensively spread across several miles, their inspection becomes a time-consuming, tiring, and expensive task. In this study, we propose a crack localization framework by taking the advantages of deep learning algorithms. The framework focuses on the proper organization of input data by using deformable bounding boxes to label the images and prepare them in a suitable format for training the model. An effective Convolutional Neural Network (CNN) model is proposed which addresses the problems of detecting arbitrary-shaped objects, is implemented. The proposed model provides the best tradeoff between speed and accuracy as it uses a segmentation head consisting of a convolutional block with two pivotal attention modules in a sequential manner that can enhance the quality of extracted features with very low computational cost, to support the lightweight ResNet backbone detection algorithm. The model trained with 3150 unique crack image samples, with 700 extra images for validation and testing. To determine the performance of the model, final ground-truth results are compared with testing input bounding box values and other state-of-the-art quantitative metrics e.g. Precision \texttimes{} Recall curve and Average Precision (AP) are explained in which model showed AP value of 80.06%. The model showed the output images in which cracks are localized with excellent accuracy.},
booktitle = {Proceedings of the 2020 4th International Conference on Computer Science and Artificial Intelligence},
pages = {159–167},
numpages = {9},
keywords = {Keywords • Sewer Pipe • Crack Detection • Attention Modules • CNN • Pixel Aggregation},
location = {Zhuhai, China},
series = {CSAI '20}
}

@inproceedings{10.5555/978-3-030-62463-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {i–xv},
location = {Guangzhou, China}
}

@article{10.1145/3369393,
author = {Ding, Yuhang and Fan, Hehe and Xu, Mingliang and Yang, Yi},
title = {Adaptive Exploration for Unsupervised Person Re-identification},
year = {2020},
issue_date = {February 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3369393},
doi = {10.1145/3369393},
abstract = {Due to domain bias, directly deploying a deep person re-identification (re-ID) model trained on one dataset often achieves considerably poor accuracy on another dataset. In this article, we propose an Adaptive Exploration (AE) method to address the domain-shift problem for re-ID in an unsupervised manner. Specifically, in the target domain, the re-ID model is inducted to (1) maximize distances between all person images and (2) minimize distances between similar person images. In the first case, by treating each person image as an individual class, a non-parametric classifier with a feature memory is exploited to encourage person images to move far away from each other. In the second case, according to a similarity threshold, our method adaptively selects neighborhoods for each person image in the feature space. By treating these similar person images as the same class, the non-parametric classifier forces them to stay closer. However, a problem of the adaptive selection is that, when an image has too many neighborhoods, it is more likely to attract other images as its neighborhoods. As a result, a minority of images may select a large number of neighborhoods while a majority of images has only a few neighborhoods. To address this issue, we additionally integrate a balance strategy into the adaptive selection. We evaluate our methods with two protocols. The first one is called “target-only re-ID”, in which only the unlabeled target data is used for training. The second one is called “domain adaptive re-ID”, in which both the source data and the target data are used during training. Experimental results on large-scale re-ID datasets demonstrate the effectiveness of our method. Our code has been released at https://github.com/dyh127/Adaptive-Exploration-for-Unsupervised-Person-Re-Identification.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = feb,
articleno = {3},
numpages = {19},
keywords = {Person re-identification, deep learning, domain adaptation, unsupervised learning}
}

@article{10.1016/j.engappai.2019.03.022,
author = {Para, Jesus and Del Ser, Javier and Nebro, Antonio J. and Zurutuza, Urko and Herrera, Francisco},
title = {Analyze, Sense, Preprocess, Predict, Implement, and Deploy (ASPPID): An incremental methodology based on data analytics for cost-efficiently monitoring the industry 4.0},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {82},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.03.022},
doi = {10.1016/j.engappai.2019.03.022},
journal = {Eng. Appl. Artif. Intell.},
month = jun,
pages = {30–43},
numpages = {14},
keywords = {Industry 4.0, Methodological data analytics, Process monitoring, Cost efficiency, Imbalanced learning}
}

@inproceedings{10.1007/978-3-030-40605-9_31,
author = {Ting, Yu-Chieh and Lin, Daw-Tung and Chen, Chih-Feng and Tsai, Bor-Chen},
title = {Automatic Optical Inspection for Millimeter Scale Probe Surface Stripping Defects Using Convolutional Neural Network},
year = {2020},
isbn = {978-3-030-40604-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-40605-9_31},
doi = {10.1007/978-3-030-40605-9_31},
abstract = {Surface defect inspection is a crucial step during the production process of IC probe. The traditional way of identifying defective IC probes mostly relies on the human visual examination through the microscope screen. However, this approach will be affected by some subjective factors or misjudgments of inspectors, and the accuracy and efficiency are not sufficiently stable. Therefore, we propose an automatic optical inspection system by incorporating the ResNet-101 deep learning architecture into the faster region-based convolutional neural network (Faster R-CNN) to detect the stripping-gold defect on the IC probe surface. The training samples were collected through our designed multi-function investigation platform IMSLAB. To circumvent the challenge of insufficient images in our datasets, we introduce data augmentation using cycle generative adversarial networks (CycleGAN). The proposed system was evaluated using 133 probes. The experimental results revealed our method performed high accuracy in stripping defect detection. The overall mean average precision (mAP) was 0.732, and the defect IC probe classification accuracy rate was 97.74%.},
booktitle = {Advanced Concepts for Intelligent Vision Systems: 20th International Conference, ACIVS 2020, Auckland, New Zealand, February 10–14, 2020, Proceedings},
pages = {360–369},
numpages = {10},
keywords = {Automatic optical inspection, IC probe, Surface defect detection, Object detection, Deep learning},
location = {Auckland, New Zealand}
}

@article{10.1016/j.engappai.2015.02.009,
author = {Prytz, Rune and Nowaczyk, S\l{}awomir and R\"{o}gnvaldsson, Thorsteinn and Byttner, Stefan},
title = {Predicting the need for vehicle compressor repairs using maintenance records and logged vehicle data},
year = {2015},
issue_date = {May 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {41},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.02.009},
doi = {10.1016/j.engappai.2015.02.009},
abstract = {Methods and results are presented for applying supervised machine learning techniques to the task of predicting the need for repairs of air compressors in commercial trucks and buses. Prediction models are derived from logged on-board data that are downloaded during workshop visits and have been collected over three years on a large number of vehicles. A number of issues are identified with the data sources, many of which originate from the fact that the data sources were not designed for data mining. Nevertheless, exploiting this available data is very important for the automotive industry as means to quickly introduce predictive maintenance solutions. It is shown on a large data set from heavy duty trucks in normal operation how this can be done and generate a profit.Random forest is used as the classifier algorithm, together with two methods for feature selection whose results are compared to a human expert. The machine learning based features outperform the human expert features, which supports the idea to use data mining to improve maintenance operations in this domain.},
journal = {Eng. Appl. Artif. Intell.},
month = may,
pages = {139–150},
numpages = {12},
keywords = {Air Compressor, Automotive Industry, Diagnostics, Fault Detection, Machine Learning}
}

@inproceedings{10.1145/3421766.3421810,
author = {Wang, Zhen and Zhou, Jinwen},
title = {The Performance of Radar Heat Dissipation System under Particle Swarm Optimization Algorithm and Structural Design of Front-end Prototype},
year = {2020},
isbn = {9781450375535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421766.3421810},
doi = {10.1145/3421766.3421810},
abstract = {To clarify the problems of aviation radar in heat dissipation, optimize the overall operational capability of radar equipment, and improve the safety of aviation radar equipment, under the premise of studying the structure of the radar heat dissipation system, by analyzing the operation of the radar heat dissipation system and the motor of the front-end prototype structure, the main reasons for heat dissipation faults are deeply analyzed. The method of statistical process control is utilized to predict the performance of the front-end motor and remind maintenance personnel to monitor the radar heat dissipation system in real-time. At the same time, by using the improved particle swarm optimization (PSO) algorithm model, the factors and kernel functions of the support vector machine (SVM) are optimized, and the regression accuracy of the SVM is improved. Furthermore, the motor failure prediction model is established, thereby ensuring the efficient and safe operating state of the radar system. The results show: (1) the failure of the radar motor is the major cause of heat dissipation faults; (2) compared to other algorithms, the efficiency of the PSO algorithm is improved by 30%, but the accuracy rate drops by 5%; (3) the applications of forewarning model for front-end prototype under statistical process control (SPC) can reduce the workload of maintenance personnel by 50%. The simulation results show that the combined method of SPC and SVM can predict the failure of the powering devices in radar heat dissipation systems. Besides, if the classification and regression models are combined, the difference between the predicted voltage and the true voltage will be smaller, and the accuracy will be higher. The above results provide a theoretical basis for the research of radar heat dissipation system and motor failure, which ensures the overall safety of the radar system and provides the necessary guarantee for the crew and the aviation command system.},
booktitle = {Proceedings of the 2nd International Conference on Artificial Intelligence and Advanced Manufacture},
pages = {510–516},
numpages = {7},
keywords = {Front-end prototype, Heat dissipation system, Motor failure, Particle swarm optimization algorithm, Radar},
location = {Manchester, United Kingdom},
series = {AIAM2020}
}

@inproceedings{10.1145/3416508.3417120,
author = {Salimi, Solmaz and Ebrahimzadeh, Maryam and Kharrazi, Mehdi},
title = {Improving real-world vulnerability characterization with vulnerable slices},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417120},
doi = {10.1145/3416508.3417120},
abstract = {Vulnerability detection is an important challenge in the security community. Many different techniques have been proposed, ranging from symbolic execution to fuzzing in order to help in identifying vulnerabilities. Even though there has been considerable improvement in these approaches, they perform poorly on a large scale code basis. There has also been an alternate approach, where software metrics are calculated on the overall code structure with the hope of predicting code segments more likely to be vulnerable. The logic has been that more complex code with respect to the software metrics, will be more likely to contain vulnerabilities.  In this paper, we conduct an empirical study with a large dataset of vulnerable codes to discuss if we can change the way we measure metrics to improve vulnerability characterization. More specifically, we introduce vulnerable slices as vulnerable code units to measure the software metrics and then use these new measured metrics to characterize vulnerable codes. The result shows that vulnerable slices significantly increase the accuracy of vulnerability characterization. Further, we utilize vulnerable slices to analyze the dataset of known vulnerabilities, particularly to observe how by using vulnerable slices the size and complexity changes in real-world vulnerabilities.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {11–20},
numpages = {10},
keywords = {Program Slicing, Static Analysis, Vulnerability Characterization, Vulnerability Prediction},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@article{10.3233/JIFS-169344,
author = {Li, Chen and Wei, Fajie and Wang, Cheng and Zhou, Shenghan and Guirao, Juan L.G. and Gao, Wei},
title = {Fault diagnosis and prediction of complex system based on Hidden Markov model},
year = {2017},
issue_date = {2017},
publisher = {IOS Press},
address = {NLD},
volume = {33},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169344},
doi = {10.3233/JIFS-169344},
abstract = {To guarantee the performance and security of the complex system, in this paper, we focus on the problem of fault diagnosis and fault prediction method for the complex system. The proposed fault diagnosis and prediction system is made up of three parts: 1) Data preprocessing, 2) Degradation state detection, and 3) Fault diagnosis. Afterwards, we exploit the Wavelet transform correlation filter to extract features for complex system fault diagnosis and prediction. Particularly, the direct spatial correlations of wavelet transform contents are used to search the locations of edges. To promote the performance of Hidden Markov model, we propose a HMM-based semi-nonparametric method by the probabilistic transition frequency profile matrix and the average probabilistic emission matrix. Then, the training sequence which is the most similar to a particular sequence can be found by the modified HMM model. Finally, experimental results prove that the proposed algorithm can effectively enhance the accuracy of equipment fault diagnosis and equipment state recognition task.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2937–2944},
numpages = {8},
keywords = {Complex system, Hidden Markov model, fault diagnosis, fault prediction}
}

@article{10.1007/s10489-014-0610-5,
author = {Zhang, Xueying and Song, Qinbao and Wang, Guangtao and Zhang, Kaiyuan and He, Liang and Jia, Xiaolin},
title = {A dissimilarity-based imbalance data classification algorithm},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-014-0610-5},
doi = {10.1007/s10489-014-0610-5},
abstract = {Class imbalances have been reported to compromise the performance of most standard classifiers, such as Naive Bayes, Decision Trees and Neural Networks. Aiming to solve this problem, various solutions have been explored mainly via balancing the skewed class distribution or improving the existing classification algorithms. However, these methods pay more attention on the imbalance distribution, ignoring the discriminative ability of features in the context of class imbalance data. In this perspective, a dissimilarity-based method is proposed to deal with the classification of imbalanced data. Our proposed method first removes the useless and redundant features by feature selection from the given data set; and then, extracts representative instances from the reduced data as prototypes; finally, projects the reduced data into a dissimilarity space by constructing new features, and builds the classification model with data in the dissimilarity space. Extensive experiments over 24 benchmark class imbalance data sets show that, compared with seven other imbalance data tackling solutions, our proposed method greatly improves the performance of imbalance learning, and outperforms the other solutions with all given classification algorithms.},
journal = {Applied Intelligence},
month = apr,
pages = {544–565},
numpages = {22},
keywords = {Class imbalance, Dissimilarity-based classification, Feature selection, Prototype selection, Software defect prediction}
}

@inproceedings{10.5555/3504035.3504690,
author = {Neill, James O' and Buitelaar, Paul},
title = {Few shot transfer learning between word relatedness and similarity tasks using a gated recurrent siamese network},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Word similarity and word relatedness are fundamental to natural language processing and more generally, understanding how humans relate concepts in semantic memory. A growing number of datasets are being proposed as evaluation benchmarks, however, the heterogeneity and focus of each respective dataset makes it difficult to draw plausible conclusions as to how a unified semantic model would perform. Additionally, we want to identify the transferability of knowledge obtained from one task to another, within the same domain and across domains. Hence, this paper first presents an evaluation and comparison of eight chosen datasets tested using the best performing regression models. As a baseline, we present regression models that incorporate both lexical features and word embeddings to produce consistent and competitive results compared to the state of the art. We present our main contribution, the best performing model across seven of the eight datasets - a Gated Recurrent Siamese Network that learns relationships between lexical word definitions. A parameter transfer learning strategy is employed for the Siamese Network. Subsequently, we present a secondary contribution which is the best performing non-sequential model: an Inductive and Transductive Transfer Learning strategy for transferring decision trees within a Random Forest to a target task that is learned from only few instances. The method involves measuring semantic distance between hidden factored matrix representations of decision tree traversal matrices.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {655},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1007/978-3-030-78270-2_74,
author = {Yun, Yue and Dai, Huan and Cao, Ruoqi and Zhang, Yupei and Shang, Xuequn},
title = {Self-paced Graph Memory Network for Student GPA Prediction and Abnormal Student Detection},
year = {2021},
isbn = {978-3-030-78269-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78270-2_74},
doi = {10.1007/978-3-030-78270-2_74},
abstract = {Student learning performance prediction (SLPP) is a crucial step in high school education. However, traditional methods fail to consider abnormal students. In this study, we organized every student’s learning data as a graph to use the schema of graph memory networks (GMNs). To distinguish the students and make GMNs learn robustly, we proposed to train GMNs in an “easy-to-hard” process, leading to self-paced graph memory network (SPGMN). SPGMN chooses the low-difficult samples as a batch to tune the model parameters in each training iteration. This approach not only improves the robustness but also rearranges the student sample from normal to abnormal. The experiment results show that SPGMN achieves a higher prediction accuracy and more robustness in comparison with traditional methods. The resulted student sequence reveals the abnormal student has a different pattern in course selection to normal students.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part II},
pages = {417–421},
numpages = {5},
keywords = {Student learning performance prediction, Self-paced learning, Graph memory networks, Abnormal student detection},
location = {Utrecht, The Netherlands}
}

@inproceedings{10.1109/SMC52423.2021.9659221,
author = {Faula, Yannick and Eglin, V\'{e}ronique and Bres, St\'{e}phane},
title = {One-Class Detection and Classification of Defects on Concrete Surfaces},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9659221},
doi = {10.1109/SMC52423.2021.9659221},
abstract = {Today, railway infrastructure is subject to regular inspections carried out by image acquisition. Experts need automatic tools to process these images and extract defects. These defects can be classified in two categories : linear defects, like cracks, and surface defects, like spall, humidity, graffiti… Cracks detection has been presented in a previous work, and is based on Local Binary Patterns (LBP) extraction and our FLASH algorithm [1]. In this paper, we propose a new method, using the same LBP descriptors, already extracted, to detect surface defects using generative adversarial networks (GAN). The detection is followed by a classification with a potentially scalable system. Experiments show that our detector achieves better performance than the state-of-the art in application to defect detection.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {826–831},
numpages = {6},
location = {Melbourne, Australia}
}

@article{10.1016/j.aei.2020.101037,
author = {Wang, Yuanbin and Liu, Minggao and Zheng, Pai and Yang, Huayong and Zou, Jun},
title = {A smart surface inspection system using faster R-CNN in cloud-edge computing environment},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2020.101037},
doi = {10.1016/j.aei.2020.101037},
journal = {Adv. Eng. Inform.},
month = jan,
numpages = {9},
keywords = {Automated surface inspection, Smart product-service system, Convolutional neural networks, Cloud-edge computing}
}

@article{10.1007/s00500-021-05867-2,
author = {Dhiman, Bhumica and Kumar, Yogesh and Hu, Yu-Chen},
title = {A general purpose multi-fruit system for assessing the quality of fruits with the application of recurrent neural network},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {14},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-05867-2},
doi = {10.1007/s00500-021-05867-2},
abstract = {In the industry of agricultural farming, defected fruits are the major reason for financial calamities across the globe. It affects both the quality and competence of the fruits. Quality detection is a post-harvest process that requires highly skilled labor and time. Therefore, the automatic detection of quality of fruits is an important step in the harvesting process which helps to save the man power and time consumption. Different systems have been designed using image processing and learning techniques that detect the quality of fruits and classify them. To speed up the fruit sorting process, a system has been designed using machine learning and deep learning techniques. The proposed system works with total nine types of fruits: apple, banana, pear, guava, grape, mango, pomegranate, orange and tomato. Recurrent neural network is used as a proposed deep learning classifier which is trained using good and bad extracted features through implementation of principal component analysis. A simple contrast enhancement technique, preceded by grayscale conversion, has been used for balancing the unstable light in the input fruit image that can suppress the object definition. In the segmentation phase, canny edge detection is used for discovering the boundaries of the fruits. The comparative analysis with existing multi-fruit or single-fruit systems clearly shows that the proposed general purpose system overshadows them by achieving better accuracy (98.47%), precision (98.93%), recall (75.44%) and mean square error (1.53%) values.},
journal = {Soft Comput.},
month = jul,
pages = {9255–9272},
numpages = {18},
keywords = {Quality detection, Recurrent neural network, Principal component analysis, Canny edge detection, Accuracy, Deep learning}
}

@inproceedings{10.1007/978-3-031-08999-2_5,
author = {Meissen, Felix and Kaissis, Georgios and Rueckert, Daniel},
title = {Challenging Current Semi-supervised Anomaly Segmentation Methods for&nbsp;Brain MRI},
year = {2021},
isbn = {978-3-031-08998-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08999-2_5},
doi = {10.1007/978-3-031-08999-2_5},
abstract = {In this work, we tackle the problem of Semi-Supervised Anomaly Segmentation (SAS) in Magnetic Resonance Images (MRI) of the brain, which is the task of automatically identifying pathologies in brain images. Our work challenges the effectiveness of current Machine Learning (ML) approaches in this application domain by showing that thresholding Fluid-attenuated inversion recovery (FLAIR) MR scans provides better anomaly segmentation maps than several different ML-based anomaly detection models. Specifically, our method achieves better Dice similarity coefficients and Precision-Recall curves than the competitors on various popular evaluation data sets for the segmentation of tumors and multiple sclerosis lesions. (Code available under: )},
booktitle = {Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 7th International Workshop, BrainLes 2021, Held in Conjunction with MICCAI 2021, Virtual Event, September 27, 2021, Revised Selected Papers, Part I},
pages = {63–74},
numpages = {12},
keywords = {Semi-supervised Anomaly Segmentation, Anomaly detection, Brain MRI}
}

@article{10.1007/s00371-020-01901-w,
author = {Yang, Tiejun and Zhang, Tianshu and Huang, Lin},
title = {Detection of defects in voltage-dependent resistors using stacked-block-based convolutional neural networks},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {37},
number = {6},
issn = {0178-2789},
url = {https://doi.org/10.1007/s00371-020-01901-w},
doi = {10.1007/s00371-020-01901-w},
abstract = {Voltage-dependent resistors (VDRs) are important circuit-protection devices. Their performance is affected by packaging quality. To identify VDR packaging defects more accurately and efficiently, we have proposed a convolutional neural network (CNN)-based VDR appearance quality inspection method that includes four stages: image acquisition, data augmentation, neural architecture design, and CNN training and testing. In designing the neural architecture, we have proposed two VDR-oriented network blocks, which consist of a compressed subnet and a multiscale subnet. Then, a stacking-block-based neural architecture design (BlockNAD) strategy is employed to determine the number of blocks. The last block is connected to a classification layer composed of a global average pooling (GAP) layer and a full connection (FC) layer. Further, using a VDR dataset containing 8058 images, we compared the identification performances of the candidate networks with different structures on 12 categories of VDR defects by adopting a variety of indicators, such as the mean average precision (mAP) and average test time per sample. The experimental results of the proposed method demonstrate competitive results compared to the state-of-the-art methods in identifying VDR defects, with a mAP value of approximately 99.9% and an average test time per sample of approximately 3&nbsp;ms.},
journal = {Vis. Comput.},
month = jun,
pages = {1559–1567},
numpages = {9},
keywords = {Neural architecture design, Deep convolutional neural networks, Defect detection, Voltage-dependent resistors}
}

@inproceedings{10.1145/3178212.3178221,
author = {Rizwan, Syed and Tiantian, Wang and Xiaohong, Su and Salahuddin},
title = {Empirical Study on Software Bug Prediction},
year = {2017},
isbn = {9781450354882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178212.3178221},
doi = {10.1145/3178212.3178221},
abstract = {Software defect prediction is a vital research direction in software engineering field. Software defect prediction predicts whether software errors are present in the software by using machine learning analysis on software metrics. It can help software developers to improve the quality of the software. Software defect prediction is usually a binary classification problem, which relies on software metrics and the use of classifiers. There have been many research efforts to improve accuracy in software defect prediction using a variety of classifiers and data preprocessing techniques. However, the "classic classifier validity" and "data preprocessing techniques can enhance the functionality of software defect prediction" has not yet been answered explicitly. Therefore, it is necessary to conduct an empirical analysis to compare these studies. In software defect prediction, the category of interest is a defective module, and the number of defective modules is much less than that of a non-defective module in data. This leads to a category of imbalance problem that reduces the accuracy of the prediction. Therefore, the problem of imbalance is a key problem that needs to be solved in software defect prediction. In this paper, we proposed an experimental model and used the NASA MDP data set to analyze the software defect prediction. Five research questions were defined and analyzed experimentally. In addition to experimental analysis, this paper focuses on the improvement of SMOTE. SMOTE ASMO algorithm has been proposed to overcome the shortcomings of SMOTE.},
booktitle = {Proceedings of the 2017 International Conference on Software and E-Business},
pages = {55–59},
numpages = {5},
keywords = {Classification, Data preprocessing, Defect prediction, SMOTE},
location = {Hong Kong, Hong Kong},
series = {ICSEB '17}
}

@inproceedings{10.1145/3345629.3351449,
author = {Jahanshahi, Hadi and Jothimani, Dhanya and Ba\c{s}ar, Ay\c{s}e and Cevik, Mucahit},
title = {Does chronology matter in JIT defect prediction? A Partial Replication Study},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3351449},
doi = {10.1145/3345629.3351449},
abstract = {BACKGROUND: Just-In-Time (JIT) models, unlike the traditional defect prediction models, detect the fix-inducing changes (or defect inducing changes). These models are designed based on the assumption that past code change properties are similar to future ones. However, as the system evolves, the expertise of developers and/or the complexity of the system also change.AIM: In this work, we aim to investigate the effect of code change properties on JIT models over time. We also study the impact of using recent data as well as all available data on the performance of JIT models. Further, we analyze the effect of weighted sampling on the performance of fix-inducing properties of JIT models. For this purpose, we used datasets from four open-source projects, namely Eclipse JDT, Mozilla, Eclipse Platform, and PostgreSQL.METHOD: We used five families of change code properties such as size, diffusion, history, experience, and purpose. We used Random Forest to train and test the JIT model and Brier Score (BS) and Area Under Curve (AUC) for performance measurement. We applied the Wilcoxon Signed Rank Test on the output to statistically validate whether the performance of JIT models improves using all the available data or the recent data.RESULTS: Our paper suggest that the predictive power of JIT models does not change by time. Furthermore, we observed that the chronology of data in JIT defect prediction models can be discarded by considering all the available data. On the other hand, the importance score of families of code change properties is found to oscillate over time.CONCLUSION: To mitigate the impact of the evolution of code change properties, it is recommended to use weighted sampling approach in which more emphasis is placed upon the changes occurring closer to the current time. Moreover, since properties such as "Expertise of the Developer" and "Size" evolve with the time, the models obtained from old data may exhibit different characteristics compared to those employing the newer dataset. Hence, practitioners should constantly retrain JIT models to include fresh data.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {90–99},
numpages = {10},
keywords = {Just-In-Time prediction, defect prediction, quality assurance, software engineering},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1007/978-3-030-68851-6_2,
author = {Chen, Jinyin and Wang, Xueke and Zhang, Yan and Zheng, Haibin and Ji, Shouling},
title = {Attention Mechanism Based Adversarial Attack Against Deep Reinforcement Learning},
year = {2020},
isbn = {978-3-030-68850-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68851-6_2},
doi = {10.1007/978-3-030-68851-6_2},
abstract = {Deep reinforcement learning (DRL) aims to maximize long-term future rewards to achieve specific goals by learning polices based on deep learning models. However, existing research has found that machine learning models are vulnerable to maliciously craft adversarial examples, so does the DRL since it uses deep model to learn policies. Usually gradient information is adopted to generate adversarial perturbation on the clean observation states to fail DRL. In order to develop a novel attack method for further defect detection of DRL, we propose a novel attention mechanism based adversarial attack. Instead of gradient information, we make full use of hidden features extracted in the DRL by attention operations to generate more effective adversarial examples. Both channel attention and pixel attention are applied to extract feature to modify the clean state to an adversarial one. Deep Q-Learing Network (DQN), one of the state-of-the-art DRL models, is utilized as the target model to train Flappybird game environment to guarantee continuous running and high success rate. Comprehensive attack experiments are carried out on DQN to testify the attack performance in aspects of reward and loss convergence.},
booktitle = {Security, Privacy, and Anonymity in Computation, Communication, and Storage: 13th International Conference, SpaCCS 2020, Nanjing, China, December 18-20, 2020, Proceedings},
pages = {19–43},
numpages = {25},
keywords = {Deep reinforcement learning, DQN, White-box attack, Attention mechanism, Feature transformation},
location = {Nanjing, China}
}

@article{10.1016/j.peva.2012.09.004,
author = {Cotroneo, Domenico and Natella, Roberto and Pietrantuono, Roberto},
title = {Predicting aging-related bugs using software complexity metrics},
year = {2013},
issue_date = {March, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {70},
number = {3},
issn = {0166-5316},
url = {https://doi.org/10.1016/j.peva.2012.09.004},
doi = {10.1016/j.peva.2012.09.004},
abstract = {Long-running software systems tend to show degraded performance and an increased failure occurrence rate. This problem, known as Software Aging, which is typically related to the runtime accumulation of error conditions, is caused by the activation of the so-called Aging-Related Bugs (ARBs). This paper aims to predict the location of Aging-Related Bugs in complex software systems, so as to aid their identification during testing. First, we carried out a bug data analysis on three large software projects in order to collect data about ARBs. Then, a set of software complexity metrics were selected and extracted from the three projects. Finally, by using such metrics as predictor variables and machine learning algorithms, we built fault prediction models that can be used to predict which source code files are more prone to Aging-Related Bugs.},
journal = {Perform. Eval.},
month = mar,
pages = {163–178},
numpages = {16},
keywords = {Aging-related bugs, Fault prediction, Software aging, Software complexity metrics}
}

@inproceedings{10.1145/3377813.3381356,
author = {Zhang, Xindong and Zhu, Chenguang and Li, Yi and Guo, Jianmei and Liu, Lihua and Gu, Haobo},
title = {Precfix: large-scale patch recommendation by mining defect-patch pairs},
year = {2020},
isbn = {9781450371230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377813.3381356},
doi = {10.1145/3377813.3381356},
abstract = {Patch recommendation is the process of identifying errors in software systems and suggesting suitable fixes for them. Patch recommendation can significantly improve developer productivity by reducing both the debugging and repairing time. Existing techniques usually rely on complete test suites and detailed debugging reports, which are often absent in practical industrial settings. In this paper, we propose Precfix, a pragmatic approach targeting large-scale industrial codebase and making recommendations based on previously observed debugging activities. Precfix collects defect-patch pairs from development histories, performs clustering, and extracts generic reusable patching patterns as recommendations. We conducted experimental study on an industrial codebase with 10K projects involving diverse defect patterns. We managed to extract 3K templates of defect-patch pairs, which have been successfully applied to the entire codebase. Our approach is able to make recommendations within milliseconds and achieves a false positive rate of 22% confirmed by manual review. The majority (10/12) of the interviewed developers appreciated Precfix, which has been rolled out to Alibaba to support various critical businesses.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice},
pages = {41–50},
numpages = {10},
keywords = {defect detection, patch generation, patch recommendation},
location = {Seoul, South Korea},
series = {ICSE-SEIP '20}
}

@article{10.1016/j.compag.2019.105070,
author = {Torres, Irina and S\'{a}nchez, Mar\'{\i}a-Teresa and Cho, Byoung-Kwan and Garrido-Varo, Ana and P\'{e}rez-Mar\'{\i}n, Dolores},
title = {Setting up a methodology to distinguish between green oranges and leaves using hyperspectral imaging},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {167},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2019.105070},
doi = {10.1016/j.compag.2019.105070},
journal = {Comput. Electron. Agric.},
month = dec,
numpages = {7},
keywords = {Orange, Harvest yield, Defect detection, Hyperspectral and multispectral imaging}
}

@article{10.1155/2021/6662932,
author = {Gupta, Mansi and Rajnish, Kumar and Bhattacharjee, Vandana and Gou, Jianping},
title = {Impact of Parameter Tuning for Optimizing Deep Neural Network Models for Predicting Software Faults},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/6662932},
doi = {10.1155/2021/6662932},
abstract = {Deep neural network models built by the appropriate design decisions are crucial to obtain the desired classifier performance. This is especially desired when predicting fault proneness of software modules. When correctly identified, this could help in reducing the testing cost by directing the efforts more towards the modules identified to be fault prone. To be able to build an efficient deep neural network model, it is important that the parameters such as number of hidden layers, number of nodes in each layer, and training details such as learning rate and regularization methods be investigated in detail. The objective of this paper is to show the importance of hyperparameter tuning in developing efficient deep neural network models for predicting fault proneness of software modules and to compare the results with other machine learning algorithms. It is shown that the proposed model outperforms the other algorithms in most cases.},
journal = {Sci. Program.},
month = jan,
numpages = {17}
}

@article{10.3233/JIFS-17888,
author = {Zhai, Junhai and Zhang, Sufang},
title = {Three-way decisions model based on rough fuzzy set},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {34},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-17888},
doi = {10.3233/JIFS-17888},
abstract = {Three-way decisions model proposed by Yao gives a semantic interpretation of positive region, negative region and boundary region. This model was developed in the framework of classical rough set, the approached target concept is a crisp set, the employed knowledge is a equivalence relation. In this paper, we extend the three-way decisions model to rough fuzzy set. Specifically, the target concept is extended to a fuzzy set, while the used knowledge is also a equivalence relation. An example is given to illustrate the computation processes of the proposed three-way decisions model. The extended model can deal with the problems described by fuzzy decision tables with symbolic-valued conditional attributes and fuzzy decision attributes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2051–2059},
numpages = {9},
keywords = {Three-way decisions, rough set, rough fuzzy set, fuzzy set}
}

@article{10.1016/j.micpro.2019.102971,
author = {Subha Seethalakshmi, V. and Karthigaivel, R. and Vengadachalam, N. and Selvakumaran, S.},
title = {RETRACTED: Application of Machine Learning and Big Data in Doubly Fed Induction Generator based Stability Analysis of Multi Machine System using Substantial Transformative Optimization Algorithm},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {73},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2019.102971},
doi = {10.1016/j.micpro.2019.102971},
journal = {Microprocess. Microsyst.},
month = mar,
numpages = {13}
}

@inproceedings{10.5555/978-3-030-62223-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62222-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part I},
pages = {i–xxvii},
location = {Guangzhou, China}
}

@inproceedings{10.1007/978-3-030-39431-8_49,
author = {Zhou, Jianwen and Zhao, Wenjing and Guo, Lei and Xu, Xinying and Xie, Gang},
title = {Real Time Detection of Surface Defects with Inception-Based MobileNet-SSD Detection Network},
year = {2019},
isbn = {978-3-030-39430-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39431-8_49},
doi = {10.1007/978-3-030-39431-8_49},
abstract = {Effective surface defect detection are of great significance for the production of high quality products. Aiming at real-time detection of surface defect, we propose a reusable and high-efficiency Inception-based MobileNet-SSD method for surface defect inspection in industrial environment. First, convolutional layers for feature extraction used in SSD were replaced by depthwise separable convolutions utilized in MobileNet so that the speed of the network can be faster. Then, the layer in the base network as convolutional feature layer is constructed as Inception which can extract more rich features through multiple convolution combinations of different scales. Finally, predictions from multiple feature maps with different resolutions are combined by the network to naturally handle objects of various sizes. Experimental results on a surface defect dataset containing 2750 images of 5 classes we established confirm that our network has competitive accuracy and is much faster. For 300 \texttimes{} 300 input, ours network achieves 96.1% mAP on DAGM 2007 test at 73FPS on a NVIDIA GTX 1080Ti, outperforming a comparable state-of-the-art FCN model.},
booktitle = {Advances in Brain Inspired Cognitive Systems: 10th International Conference, BICS 2019, Guangzhou, China, July 13–14, 2019, Proceedings},
pages = {510–519},
numpages = {10},
keywords = {Surface defect, Real time detection, Inception, MobileNet-SSD},
location = {Guangzhou, China}
}

@article{10.1016/j.compeleceng.2019.106454,
author = {Wu, Ang and Zhu, Juanhua and Ren, Taiyong},
title = {Detection of apple defect using laser-induced light backscattering imaging and convolutional neural network},
year = {2020},
issue_date = {Jan 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {81},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.106454},
doi = {10.1016/j.compeleceng.2019.106454},
journal = {Comput. Electr. Eng.},
month = jan,
numpages = {9},
keywords = {Apple defect, Convolutional neural network, Laser backscattering imaging, Image recognition}
}

@article{10.3233/JIFS-169571,
author = {Kostopoulos, G. and Livieris, I.E. and Kotsiantis, S. and Tampakas, V. and Patnaik, Srikanta},
title = {CST-Voting: A semi-supervised ensemble method for classification problems},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {35},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169571},
doi = {10.3233/JIFS-169571},
abstract = {Semi-supervised learning is an emerging subfield of machine learning, with a view to building efficient classifiers exploiting a limited pool of labeled data together with a large pool of unlabeled ones. Most of the studies regarding semi-supervised learning deal with classification problems, whose goal is to learn a function that maps an unlabeled instance into a finite number of classes. In this paper, a new semi-supervised classification algorithm, which is based on a voting methodology, is proposed. The term attributed to this ensemble method is called CST-Voting. Ensemble methods have been effectively applied in various scientific fields and often perform better than the individual classifiers from which they are originated. The efficiency of the proposed algorithm is compared to three familiar semi-supervised learning methods on a plethora of benchmark datasets using three representative supervised classifiers as base learners. Experimental results demonstrate the predominance of the proposed method, outperforming classical semi-supervised classification algorithms as illustrated from the accuracy measurements and confirmed by the Friedman Aligned Ranks nonparametric test.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {99–109},
numpages = {11},
keywords = {Semi-supervised learning, classification, voting, ensemble methods, accuracy}
}

@inproceedings{10.1007/978-3-030-32692-0_49,
author = {Peng, Shiqi and Lai, Bolin and Yao, Guangyu and Zhang, Xiaoyun and Zhang, Ya and Wang, Yan-Feng and Zhao, Hui},
title = {Learning-Based Bone Quality Classification Method for Spinal Metastasis},
year = {2019},
isbn = {978-3-030-32691-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32692-0_49},
doi = {10.1007/978-3-030-32692-0_49},
abstract = {Spinal metastasis is the most common disease in bone metastasis and may cause pain, instability and neurological injuries. Early detection of spinal metastasis is critical for accurate staging and optimal treatment. The diagnosis is usually facilitated with Computed Tomography (CT) scans, which requires considerable efforts from well-trained radiologists. In this paper, we explore a learning-based automatic bone quality classification method for spinal metastasis based on CT images. We simultaneously take the posterolateral spine involvement classification task into account, and employ multi-task learning (MTL) technique to improve the performance. MTL acts as a form of inductive bias which helps the model generalize better on each task by sharing representations between related tasks. Based on the prior knowledge that the mixed type can be viewed as both blastic and lytic, we model the task of bone quality classification as two binary classification sub-tasks, i.e., whether blastic and whether lytic, and leverage a multiple layer perceptron to combine their predictions. In order to make the model more robust and generalize better, self-paced learning is adopted to gradually involve from easy to more complex samples into the training process. The proposed learning-based method is evaluated on a proprietary spinal metastasis CT dataset. At slice level, our method significantly outperforms an 121-layer DenseNet classifier in sensitivities by +12.54%, +7.23% and +29.06% for blastic, mixed and lytic lesions, respectively, meanwhile +12.33%, +23.21% and +34.25% at vertebrae level.},
booktitle = {Machine Learning in Medical Imaging: 10th International Workshop, MLMI 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings},
pages = {426–434},
numpages = {9},
keywords = {Spinal metastasis, Bone quality classification, Multi-task learning, Self-paced learning},
location = {Shenzhen, China}
}

@article{10.1016/j.knosys.2021.107541,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {DNNAttention: A deep neural network and attention based architecture for cross project defect number prediction},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {233},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107541},
doi = {10.1016/j.knosys.2021.107541},
journal = {Know.-Based Syst.},
month = dec,
numpages = {30},
keywords = {Cross project defect prediction, Deep neural network, Attention layer, Long short term memory (LSTM), Software defect number prediction}
}

@inproceedings{10.1145/2070821.2070829,
author = {Zhang, Dongmei and Dang, Yingnong and Lou, Jian-Guang and Han, Shi and Zhang, Haidong and Xie, Tao},
title = {Software analytics as a learning case in practice: approaches and experiences},
year = {2011},
isbn = {9781450310222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2070821.2070829},
doi = {10.1145/2070821.2070829},
abstract = {Software analytics is to enable software practitioners to perform data exploration and analysis in order to obtain insightful and actionable information for data-driven tasks around software and services. In this position paper, we advocate that when applying analytic technologies in practice of software analytics, one should (1) incorporate a broad spectrum of domain knowledge and expertise, e.g., management, machine learning, large-scale data processing and computing, and information visualization; and (2) investigate how practitioners take actions on the produced information, and provide effective support for such information-based action taking. Our position is based on our experiences of successful technology transfer on software analytics at Microsoft Research Asia.},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
pages = {55–58},
numpages = {4},
keywords = {machine learning, software analytics, technology transfer},
location = {Lawrence, Kansas, USA},
series = {MALETS '11}
}

@inproceedings{10.1145/3467707.3467727,
author = {Zhang, Fang and Zhao, Rui and Wang, Wen and Liu, Yang},
title = {Phase Extraction of Electronic Speckle Interference Fringe Image based on Convolutional Neural Network},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3467707.3467727},
doi = {10.1145/3467707.3467727},
abstract = {Electronic speckle pattern interferometry (ESPI) is a kind of full-field, non-contact nondestructive measurement technology, which is suitable for deformation measurement and nondestructive testing of optical rough surface. Fringe phase is an important information of interference fringe image, and the accuracy of phase estimation plays an important role in the extraction of fringe information. However, because of the discontinuity of fringe image and the influence of noise, phase extraction has always been a challenging problem. In this paper, we propose a fringe image phase extraction technique based on convolutional neural network, and experimental results show that this method has a good effect on phase estimation of the interference fringe.},
booktitle = {Proceedings of the 2021 7th International Conference on Computing and Artificial Intelligence},
pages = {138–145},
numpages = {8},
keywords = {Convolutional Neural Network, Electronic speckle pattern interferometry, The phase estimation},
location = {Tianjin, China},
series = {ICCAI '21}
}

@article{10.1016/j.engappai.2015.11.005,
author = {Fontes, Cristiano Hora and Pereira, Otac\'{\i}lio},
title = {Pattern recognition in multivariate time series - A case study applied to fault detection in a gas turbine},
year = {2016},
issue_date = {March 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {49},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.11.005},
doi = {10.1016/j.engappai.2015.11.005},
abstract = {Advances in information technology, together with the evolution of systems in control, automation and instrumentation have enabled the recovery, storage and manipulation of a large amount of data from industrial plants. This development has motivated the advancement of research in fault detection, especially based on process history data. Although a large amount of work has been conducted in recent years on the diagnostics of gas turbines, few of them present the use of clustering approaches applied to multivariate time series, adopting PCA similarity factor (SPCA) in order to detect and/or prevent failures. This paper presents a comprehensive method for pattern recognition associated to fault prediction in gas turbines using time series mining techniques. Algorithms comprising appropriate similarity metrics, subsequence matching and fuzzy clustering were applied on data extracted from a Plant Information Management System (PIMS) represented by multivariate time series. A real case study comprising the fault detection in a gas turbine was investigated. The results suggest the existence of a safe way to start the turbine that can be useful to support the development of a dynamic system for monitoring and predicting the probability of failure and for decision-making at operational level. Real case study comprising the fault detection in a gas turbine.Comprehensive method for pattern recognition associated to fault prediction in gas turbines.Results show the efficiency of the proposed approach for decision-making at operational level.The whole three step method presented is flexible and portable.An extended version of the FCM algorithm suitable for the clustering of multivariate time series is applied.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {10–18},
numpages = {9},
keywords = {Clustering, Data mining, Fault detection, Gas turbines, Multivariate time series}
}

@inproceedings{10.1145/3297662.3365800,
author = {Elhariri, Esraa and El-Bendary, Nashwa and Taie, Shereen A.},
title = {Performance Analysis of Using Feature Fusion for Crack Detection in Images of Historical Buildings},
year = {2020},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365800},
doi = {10.1145/3297662.3365800},
abstract = {In this paper, three types of feature sets are used for evaluating the performance of a proposed approach for crack detection in images of historical buildings. The feature sets are hand-crafted features, Convolutional Neural Network (CNN) learned features, and fusion of hand-crafted and CNN-learned features. The proposed approach is validated by implementing several Machine Learning (ML) classifiers with applying 3-fold cross validation. Two datasets of crack images are used for developing the feature sets. Experimental results show that both Support Vector Machine (SVM) and stacked ensemble classifiers achieve highest accuracy of 98% for crack detection using the CNN-learned features with dimensionality reduction. The significance of this study is to highlight the impact of different types of feature sets on the performance of the classification process for crack detection.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {308–315},
numpages = {8},
keywords = {Convolutional Neural Network (CNN), Histogram of Gradient (HOG), Local Binary Pattern (LBP), Machine Learning (ML), Principle Component Analysis (PCA), crack detection, data augmentation, dimensionality reduction, feature fusion, hand-crafted features},
location = {Limassol, Cyprus},
series = {MEDES '19}
}

@article{10.1016/0031-3203(90)90052-M,
author = {Brzakovic, D. and Beck, H. and Sufi, N.},
title = {An approach to defect detection in materials characterized by complex textures},
year = {1990},
issue_date = {January 1990},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {23},
number = {1–2},
issn = {0031-3203},
url = {https://doi.org/10.1016/0031-3203(90)90052-M},
doi = {10.1016/0031-3203(90)90052-M},
journal = {Pattern Recogn.},
month = jan,
pages = {99–107},
numpages = {9}
}

@article{10.1016/j.jss.2019.05.001,
author = {Kicsi, Andr\'{a}s and Csuvik, Viktor and Vid\'{a}cs, L\'{a}szl\'{o} and Horv\'{a}th, Ferenc and Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy, Tibor and Kocsis, Ferenc},
title = {Feature analysis using information retrieval, community detection and structural analysis methods in product line adoption},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {155},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.05.001},
doi = {10.1016/j.jss.2019.05.001},
journal = {J. Syst. Softw.},
month = sep,
pages = {70–90},
numpages = {21},
keywords = {Software product line, Feature extraction, Information retrieval, Community detection}
}

@article{10.1016/j.patrec.2018.12.013,
author = {Han, Hui and Gao, Chenqiang and Zhao, Yue and Liao, Shisha and Tang, Lin and Li, Xindou},
title = {Polycrystalline silicon wafer defect segmentation based on deep convolutional neural networks},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {130},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2018.12.013},
doi = {10.1016/j.patrec.2018.12.013},
journal = {Pattern Recogn. Lett.},
month = feb,
pages = {234–241},
numpages = {8},
keywords = {Polycrystalline silicon wafer, RPN, Defects segmentation, CNN, 41A05, 41A10, 65D05, 65D17}
}

@article{10.1007/s10489-020-02026-2,
author = {Van Nguyen, Sinh and Tran, Ha Manh},
title = {An automated fault detection system for communication networks and distributed systems},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02026-2},
doi = {10.1007/s10489-020-02026-2},
abstract = {Automating fault detection in communication networks and distributed systems is a challenging process that usually requires the involvement of supporting tools and the expertise of system operators. Automated event monitoring and correlating systems produce event data that is forwarded to system operators for analyzing error events and creating fault reports. Machine learning methods help not only analyzing event data more precisely but also forecasting possible error events by learning from existing faults. This study introduces an automated fault detection system that assists system operators in detecting and forecasting faults. This system is characterized by the capability of exploiting bug knowledge resources at various online repositories, log events and status parameters from the monitored system; and applying bug analysis and event filtering methods for evaluating events and forecasting faults. The system contains a fault data model to collect bug reports, a feature and semantic filtering method to correlate log events, and machine learning methods to evaluate the severity, priority and relation of log events and forecast the forthcoming critical faults of the monitored system. We have evaluated the prototyping implementation of the proposed system on a high performance computing cluster system and provided analysis with lessons learned.},
journal = {Applied Intelligence},
month = aug,
pages = {5405–5419},
numpages = {15},
keywords = {Fault detection, Automation, Machine learning, Random forest, Bug tracking system}
}

@article{10.3233/JIFS-189693,
author = {Chen, Yonggang and Shu, Yufeng and Li, Xiaomian and Xiong, Changwei and Cao, Shenyi and Wen, Xinyan and Xie, Zicong and Zhou, Shengzong},
title = {Research on detection algorithm of lithium battery surface defects based on embedded machine vision},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-189693},
doi = {10.3233/JIFS-189693},
abstract = {In the production process of lithium battery, the quality inspection requirements of lithium battery are very high. At present, most of the work is done manually. Aiming at the problem of large manual inspection workload and large error, the robot visual inspection technology is applied to the production of lithium battery. In recent years, with the rapid development and progress of science and technology, the rapid development of visual detection hardware and algorithms, making it possible to screen defective products through visual detection algorithms. This paper takes lithium battery as the research object, and studies its vision detection algorithm. As a common commodity, the quality of lithium battery is the key for users to choose. With the increasing requirements of users for battery quality, how to produce high-quality battery is the key problem to be solved by manufacturers. However, at present, the defects of battery surface are mostly carried out manually. There are low efficiency and low detection rate in the process of manual detection. In this paper, the visual detection algorithm is studied to detect the defects such as pits, rust marks and broken skin on the surface of lithium battery, specifically to design the imaging experimental platform of lithium battery; use different lighting schemes to design different battery positioning and extraction algorithms; use Hough detection method to locate the battery surface, and design the battery defect algorithm for this, and compare the algorithm through experiments.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {4327–4335},
numpages = {9},
keywords = {Robot visual inspection, surface defect, embedded, lithium battery}
}

@article{10.1155/2020/8847651,
author = {Yang, Rui and Zhang, Yonglin and Deng, Zhenrong and Huang, Wenming and Lan, Rushi and Luo, Xiaonan and Zhou, Zhili},
title = {SK-FMYOLOV3: A Novel Detection Method for Urine Test Strips},
year = {2020},
issue_date = {2020},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2020},
issn = {1530-8669},
url = {https://doi.org/10.1155/2020/8847651},
doi = {10.1155/2020/8847651},
abstract = {To accurately detect small defects in urine test strips, the SK-FMYOLOV3 defect detection algorithm is proposed. First, the prediction box clustering algorithm of YOLOV3 is improved. The fuzzy C-means clustering algorithm is used to generate the initial clustering centers, and then, the clustering center is passed to the K-means algorithm to cluster the prediction boxes. To better detect smaller defects, the YOLOV3 feature map fusion is increased from the original three-scale prediction to a four-scale prediction. At the same time, 23 convolutional layers of size 3\texttimes{}3 in the YOLOV3 network are replaced with SkNet structures, so that different feature maps can independently select different convolution kernels for training, improving the accuracy of defect classification. We collected and enhanced urine test strip images in industrial production and labeled the small defects in the images. A total of 11634 image sets were used for training and testing. The experimental results show that the algorithm can obtain an anchor frame with an average cross ratio of 86.57, while the accuracy rate and recall rate of nonconforming products are 96.8 and 94.5, respectively. The algorithm can also accurately identify the category of defects in nonconforming products.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {14}
}

@article{10.1016/j.ins.2013.11.019,
author = {Reformat, Marek},
title = {Preface: Special section: Applications of computational intelligence and machine learning to software engineering},
year = {2014},
issue_date = {February, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {259},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.11.019},
doi = {10.1016/j.ins.2013.11.019},
journal = {Inf. Sci.},
month = feb,
pages = {393–395},
numpages = {3}
}

@inproceedings{10.1145/3487075.3487171,
author = {Guo, Jiongyu and Wang, Can and Feng, Yan},
title = {Online Adversarial Knowledge Distillation for Image Synthesis of Bridge Defect},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487075.3487171},
doi = {10.1145/3487075.3487171},
abstract = {Bridge defect detection is an essential task of its daily maintenance, which aims to protect people's life and property safety. However, for a variety of reasons, research institutions have been faced with the scarcity of anomaly samples. One solution is using generative adversarial network (GAN) to generate extra samples for data augmentation. In this paper, we draw on the idea from online knowledge distillation to improve the self-attention GAN, and propose a new framework called Online Knowledge Distillation -Self Attention Generative Adversarial Network (OKD-SAGAN). We introduce a new module called connector which has the same structure with discriminator to train multiple groups of SAGAN together. The role of the connector is to control the output distribution of the corresponding generator to be consistent with the surrounding generators in order to achieve the purpose of mutual learning. We have conducted experiments on the CODEBRIM dataset and in order to further illustrate the effectiveness of OKD structure, we also applied OKD on ACGAN for experiments. The results show that the performance of some generators has exceeded a single set of SAGAN and ACGAN. Compared with SAGAN, OKD-SAGAN ’s FID score decreases by 15.4% and the average FID score decreases by 5.5%. As for ACGAN, OKD-ACGAN ’s FID score decreases by 7.6% and the average FID score decreases by 3.8%, which proves the validity of OKD structure.},
booktitle = {Proceedings of the 5th International Conference on Computer Science and Application Engineering},
articleno = {96},
numpages = {6},
keywords = {Generative adversarial network, Image generation, Online knowledge distillation},
location = {Sanya, China},
series = {CSAE '21}
}

@inproceedings{10.1145/3273934.3273941,
author = {Dey, Tapajit and Mockus, Audris},
title = {Modeling Relationship between Post-Release Faults and Usage in Mobile Software},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273941},
doi = {10.1145/3273934.3273941},
abstract = {Background: The way post-release usage of a software affects the number of faults experienced by users is scarcely explored due to the proprietary nature of such data. The commonly used quality measure of post-release faults may, therefore, reflect usage instead of the quality of the software development process. Aim: To determine how software faults and software use are related in a post-deployment scenario and, based on that, derive post-deployment quality measure that reflects developers' performance more accurately. Method: We analyze Google Analytics data counting daily new users, visits, time-on-site, visits per user, and release start date and duration for 169 releases of a complex communication application for Android OS. We utilize Linear Regression, Bayesian Network, and Random Forest models to explain the interrelationships and to derive release quality measure that is relatively stable with respect to variations in software usage. Results: We found the number of new users and release start date to be the determining factors for the number of exceptions, and found no direct link between the intensity and frequency of software usage and software faults. Furthermore, the relative increase in the number of crashes was found to be stably associated with a power of 1.3 relative increase in the number of new users. Based on the findings we propose a release quality measure: number of crashes per user for a release of the software, which was seen to be independent of any other usage variables, providing us with a usage independent measure of software quality. Conclusions: We expect our result and our proposed quality measure will help gauge release quality of a software more accurately and inspire further research in this area.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {56–65},
numpages = {10},
keywords = {Bayesian Networks, Linear Regression, Random Forest, Software Faults, Software Quality, Software Usage},
location = {Oulu, Finland},
series = {PROMISE'18}
}

